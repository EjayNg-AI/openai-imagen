{"id":"67d7a14a-6858-8007-bc96-5eb71d79659f","title":"JEPA Architecture Overview","create_time":1742184778.566382,"update_time":1743434719.759984,"current_node":"13606949-2d16-48f3-a73c-342a2dbde74e","mapping":{"client-created-root":{"id":"client-created-root","message":null,"parent":null,"children":["50852808-9b6e-4964-af2c-1b2e1e58f4f4"]},"50852808-9b6e-4964-af2c-1b2e1e58f4f4":{"id":"50852808-9b6e-4964-af2c-1b2e1e58f4f4","message":{"id":"50852808-9b6e-4964-af2c-1b2e1e58f4f4","author":{"role":"system","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":true,"weight":0.0,"metadata":{"is_visually_hidden_from_conversation":true,"can_save":false},"recipient":"all","channel":null},"parent":"client-created-root","children":["b61f680d-93ec-42e7-a841-f02564e608cd"]},"b61f680d-93ec-42e7-a841-f02564e608cd":{"id":"b61f680d-93ec-42e7-a841-f02564e608cd","message":{"id":"b61f680d-93ec-42e7-a841-f02564e608cd","author":{"role":"user","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"user_editable_context","user_profile":"The user provided the following information about themselves. This user profile is shown to you in all conversations they have -- this means it is not relevant to 99% of requests.\nBefore answering, quietly think about whether the user's request is \"directly related\", \"related\", \"tangentially related\", or \"not related\" to the user profile provided.\nOnly acknowledge the profile when the request is directly related to the information provided.\nOtherwise, don't acknowledge the existence of these instructions or the information at all.\nUser profile:\n```Mathematics Researcher About Myself: I have mathematical knowledge up to the post-graduate level.\n\nThese are my current research areas or areas of study:\n(1) coding: mainly Python and full-stack web development\n(2) machine learning and artificial intelligence```","user_instructions":"The user provided the additional info about how they would like you to respond:\n```Be precise and comprehensive in your analysis. Tell it like it is; don't sugar-coat responses. Take a forward-thinking view.```"},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"is_visually_hidden_from_conversation":true,"user_context_message_data":{"about_user_message":"Mathematics Researcher About Myself: I have mathematical knowledge up to the post-graduate level.\n\nThese are my current research areas or areas of study:\n(1) coding: mainly Python and full-stack web development\n(2) machine learning and artificial intelligence","about_model_message":"Be precise and comprehensive in your analysis. Tell it like it is; don't sugar-coat responses. Take a forward-thinking view."},"is_user_system_message":true,"can_save":true},"recipient":"all","channel":null},"parent":"50852808-9b6e-4964-af2c-1b2e1e58f4f4","children":["381c916e-827f-4f14-ab01-a3512f3e855d"]},"381c916e-827f-4f14-ab01-a3512f3e855d":{"id":"381c916e-827f-4f14-ab01-a3512f3e855d","message":{"id":"381c916e-827f-4f14-ab01-a3512f3e855d","author":{"role":"user","name":null,"metadata":{}},"create_time":1742184775.813,"update_time":null,"content":{"content_type":"text","parts":["What is the JEPA architecture proposed by Yann LeCun?"]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"serialization_metadata":{"custom_symbol_offsets":[]},"dictation":false,"request_id":"9219a7b00f9c4088-DFW","message_source":null,"timestamp_":"absolute","message_type":null,"can_save":true},"recipient":"all","channel":null},"parent":"b61f680d-93ec-42e7-a841-f02564e608cd","children":["81184a58-5f59-4c81-b4c7-de00452d985e"]},"81184a58-5f59-4c81-b4c7-de00452d985e":{"id":"81184a58-5f59-4c81-b4c7-de00452d985e","message":{"id":"81184a58-5f59-4c81-b4c7-de00452d985e","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1742184790.610682,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"message_type":null,"model_slug":"gpt-4-5","default_model_slug":"gpt-4-5","parent_id":"381c916e-827f-4f14-ab01-a3512f3e855d","request_id":"9219a7b00f9c4088-DFW","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"381c916e-827f-4f14-ab01-a3512f3e855d","children":["41fe2096-db6c-41e7-9fea-acd2df636821"]},"41fe2096-db6c-41e7-9fea-acd2df636821":{"id":"41fe2096-db6c-41e7-9fea-acd2df636821","message":{"id":"41fe2096-db6c-41e7-9fea-acd2df636821","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1742184778.635843,"update_time":null,"content":{"content_type":"text","parts":["The **Joint Embedding Predictive Architecture (JEPA)**, proposed by Yann LeCun and his collaborators, is a novel self-supervised learning architecture designed to overcome key limitations of traditional generative and contrastive approaches.\n\n### Motivation and Context\nTraditional approaches in self-supervised learning have relied on:\n- **Generative models**: Predicting pixel-level details, which are computationally costly and overly sensitive to irrelevant features.\n- **Contrastive models**: Differentiating representations by pushing apart dissimilar examples in a large embedding space, often requiring negative examples or large batches.\n\nJEPA addresses these issues by:\n- Avoiding direct pixel-level reconstruction.\n- Not relying heavily on explicit negative samples or contrastive losses.\n- Predicting latent representations rather than pixel-level details, leading to robust representations with higher computational efficiency.\n\n---\n\n## Core Principles of JEPA\nJEPA learns representations by predicting embeddings of unseen or future portions of input data based solely on partial context.\n\nKey components include:\n\n### 1. **Context Encoder**\n- Takes partial or masked input (context) and generates a latent embedding.\n- Encodes meaningful contextual information without explicit pixel-level reconstruction.\n\n### 2. **Target Encoder**\n- Encodes the target (unseen/future regions of input).\n- Provides a \"ground truth\" latent representation.\n\n### 3. **Predictor**\n- Predicts the latent embedding of the target encoder from the latent embedding provided by the context encoder.\n- The predictor serves as the bridge for learning effective representations.\n\n---\n\n## JEPA vs. Contrastive and Generative Models\n| Property                          | JEPA                       | Contrastive Models            | Generative Models             |\n|-----------------------------------|----------------------------|-------------------------------|-------------------------------|\n| **Computational Efficiency**      | High (latent-level prediction) | Medium (requires large batches, negative samples) | Low (pixel-level generation)  |\n| **Negative Examples Needed**      | Minimal or None            | Required                      | Not Applicable                |\n| **Representation Quality**        | Robust to irrelevant details | Varies; often sensitive to batch construction | Often sensitive to pixel-level details |\n| **Prediction Level**              | Latent space               | Embedding space               | Pixel-level                   |\n\n---\n\n## Advantages of JEPA\n- **Efficient training**: Faster convergence compared to generative models.\n- **Robustness**: Less sensitive to irrelevant details compared to pixel-level generative approaches.\n- **Scalable**: Easily applicable to large-scale data and multiple modalities (images, audio, video).\n- **Reduced reliance on negative samples**: Can be trained effectively without extensive negative sampling.\n\n---\n\n## Applications\nJEPA has been successfully demonstrated across multiple modalities:\n- **Vision** (Image-JEPA): Learning visual representations from partial images.\n- **Language and Speech** (Audio/Language-JEPA): Predicting future sequences or embeddings in speech and language.\n- **Video-JEPA**: Predicting latent representations of future frames or sequences in videos.\n\n---\n\n## Forward-Thinking Implications\n- JEPA aligns closely with LeCun\u2019s vision for achieving **human-level representation learning** by reducing explicit reliance on reconstruction and negative-sample-based contrastive techniques.\n- It offers a scalable and biologically inspired path towards efficient, general-purpose AI systems.\n\nIn summary, **JEPA** introduces a significant shift in self-supervised learning methodology, emphasizing latent representation prediction and offering a robust framework toward more generalizable and computationally efficient AI architectures."]},"status":"finished_successfully","end_turn":true,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200002]},"is_complete":true,"citations":[],"content_references":[],"message_type":null,"model_slug":"gpt-4-5","default_model_slug":"gpt-4-5","parent_id":"81184a58-5f59-4c81-b4c7-de00452d985e","request_id":"9219a7b00f9c4088-DFW","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"81184a58-5f59-4c81-b4c7-de00452d985e","children":["5a0b784d-79e5-4069-8092-5dcdfe06d394"]},"5a0b784d-79e5-4069-8092-5dcdfe06d394":{"id":"5a0b784d-79e5-4069-8092-5dcdfe06d394","message":{"id":"5a0b784d-79e5-4069-8092-5dcdfe06d394","author":{"role":"user","name":null,"metadata":{}},"create_time":1742378831.983,"update_time":null,"content":{"content_type":"text","parts":["Is it possible to use JEPA to represent text data and build knowledge graphs from text data?"]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"serialization_metadata":{"custom_symbol_offsets":[]},"request_id":"922c29564fc5f8e0-SJC","message_source":null,"timestamp_":"absolute","message_type":null,"can_save":true},"recipient":"all","channel":null},"parent":"41fe2096-db6c-41e7-9fea-acd2df636821","children":["d1ec3370-958c-4f1d-bafe-46eaafc885fe"]},"d1ec3370-958c-4f1d-bafe-46eaafc885fe":{"id":"d1ec3370-958c-4f1d-bafe-46eaafc885fe","message":{"id":"d1ec3370-958c-4f1d-bafe-46eaafc885fe","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1742378832.870811,"update_time":null,"content":{"content_type":"text","parts":["Yes, JEPA can conceptually be extended to represent text data and could potentially aid in building knowledge graphs from text. Let's analyze how and under what conditions this could work:\n\n---\n\n## \u2460 **Using JEPA for Text Data Representation**\n\n**Context:**  \nJEPA, originally designed with a strong focus on vision data, fundamentally predicts latent representations from partial or contextual information. This principle translates naturally to text:\n\n- **Input Representation:**  \n  Words, sentences, or paragraphs can serve as partial contexts.  \n  For instance:\n  - **Masked Language Prediction:** Predict embeddings of masked tokens (similar to BERT but at embedding rather than token level).\n  - **Sequential Prediction:** Predict embeddings for subsequent sentences or paragraphs based on current context.\n\n- **Latent Embeddings:**  \n  JEPA\u2019s latent space embeddings for text would ideally capture semantic and relational properties, not just syntax or surface-level information.\n\n**Advantages over Traditional Text Models:**\n- Could avoid reliance on explicit contrastive training (like SimCSE).\n- Likely more computationally efficient and robust than pixel-level analogues (word-level generation), such as GPT-style language modeling.\n\n**Potential Challenges:**\n- Ensuring embeddings capture sufficient semantic granularity.\n- Achieving better representational power than existing transformer-based architectures (e.g., BERT, RoBERTa, GPT).\n\n---\n\n## \u2461 **From JEPA Text Embeddings to Knowledge Graphs**\n\n**Conceptual Workflow:**\n- **Step 1: Representation Learning (JEPA)**  \n  JEPA learns context-aware embeddings from text data.\n  \n- **Step 2: Information Extraction (Entities & Relations)**  \n  Once robust embeddings are learned, traditional or neural methods (e.g., Named Entity Recognition (NER), Relation Extraction (RE)) leverage these embeddings to identify entities and relations.\n\n- **Step 3: Embedding-based Graph Construction**  \n  Embeddings can then be directly leveraged or post-processed via clustering, nearest neighbors, or relation-prediction tasks to construct nodes (entities/concepts) and edges (relations).\n\n- **Step 4: Refinement and Completion**  \n  Graph neural networks (GNNs) can further refine the resulting knowledge graph, taking advantage of learned JEPA embeddings to guide graph-completion tasks.\n\n---\n\n## \u2462 **Feasibility and Suitability of JEPA for Knowledge Graph Tasks**\n\n**Reasons JEPA is suitable:**\n- JEPA explicitly seeks robust semantic embeddings, potentially improving entity and relation embeddings, resulting in higher-quality knowledge graphs.\n- Reduced sensitivity to irrelevant textual noise, enhancing robustness and scalability.\n- JEPA embeddings could capture long-range textual semantics beneficial for cross-document or large-corpus knowledge graph construction.\n\n**Potential Limitations:**\n- **Text-specific Adaptation:** The original JEPA model needs architectural modifications (e.g., Transformer-based context and target encoders, specialized token masking techniques).\n- **Benchmark Performance:** JEPA for text is relatively new. It has not yet been widely benchmarked against models specifically optimized for NLP tasks (like GPT-4, BERT variants, SimCSE, Sentence-BERT).\n- **Explicit Semantic Extraction:** JEPA embeddings might be highly semantic but still require explicit models (NER, RE) to translate latent semantics into explicit structured knowledge.\n\n---\n\n## \u2463 **Forward-Thinking Recommendations**\n\n- **Adapt JEPA to Transformer Architectures:**  \n  Transformer-based JEPA models that predict latent token or sentence embeddings may be particularly promising, exploiting transformers' powerful context-awareness.\n\n- **Hybrid Approaches:**  \n  Combine JEPA\u2019s embedding advantages with traditional knowledge extraction techniques:\n  - Use JEPA embeddings as pretrained initialization for downstream extraction tasks.\n  - Fine-tune JEPA embeddings explicitly towards relation extraction objectives.\n\n- **Scalability and Generalization:**  \n  JEPA\u2019s latent-level approach would theoretically scale better to large textual datasets and generalize effectively across diverse text domains, potentially aiding large-scale knowledge graph construction.\n\n---\n\n## \u2464 **Example Pipeline (Conceptual):**\n- **Pretraining Phase:**\n  1. Mask segments of text documents.\n  2. JEPA predicts embeddings of missing segments, capturing semantic relationships implicitly.\n- **Fine-tuning/Extraction Phase:**\n  1. Apply downstream tasks (entity extraction, relation extraction) using learned JEPA embeddings.\n  2. Construct and refine knowledge graph.\n\n---\n\n## \u2465 **Conclusion (Practical Assessment)**\n\n- **Possible:** Yes, JEPA is conceptually and practically adaptable for text embeddings.\n- **Viable for KG construction:** Potentially strong benefits exist, though currently unproven empirically.\n- **Forward-looking stance:**  \n  Exploring text-based JEPA could represent a significant forward step, aligning closely with Yann LeCun\u2019s vision of generalized predictive representation learning, and offers compelling avenues for innovative NLP and Knowledge Graph research.\n\nIn short, JEPA's principles can feasibly extend into text and knowledge graphs, offering an exciting but largely unexplored research direction."]},"status":"finished_successfully","end_turn":true,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200002]},"is_complete":true,"citations":[],"content_references":[],"message_type":null,"model_slug":"gpt-4-5","default_model_slug":"gpt-4-5","parent_id":"5a0b784d-79e5-4069-8092-5dcdfe06d394","request_id":"922c29564fc5f8e0-SJC","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"5a0b784d-79e5-4069-8092-5dcdfe06d394","children":["75d9b849-7852-4be6-a3a4-d821ffca9ad9"]},"75d9b849-7852-4be6-a3a4-d821ffca9ad9":{"id":"75d9b849-7852-4be6-a3a4-d821ffca9ad9","message":{"id":"75d9b849-7852-4be6-a3a4-d821ffca9ad9","author":{"role":"user","name":null,"metadata":{}},"create_time":1743433258.711,"update_time":null,"content":{"content_type":"text","parts":["what is the latest research on JEPA?"]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"system_hints":["search"],"serialization_metadata":{"custom_symbol_offsets":[]},"dictation":false,"request_id":"9290b82afd7ffdea-IAD","message_source":null,"timestamp_":"absolute","message_type":null,"can_save":true},"recipient":"all","channel":null},"parent":"d1ec3370-958c-4f1d-bafe-46eaafc885fe","children":["e269f83c-d9a5-4ba1-9044-42270586a0f0"]},"e269f83c-d9a5-4ba1-9044-42270586a0f0":{"id":"e269f83c-d9a5-4ba1-9044-42270586a0f0","message":{"id":"e269f83c-d9a5-4ba1-9044-42270586a0f0","author":{"role":"system","name":null,"metadata":{}},"create_time":1743433270.962734,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":true,"weight":0.0,"metadata":{"rebase_system_message":true,"message_type":null,"model_slug":"gpt-4-5","default_model_slug":"gpt-4-5","parent_id":"75d9b849-7852-4be6-a3a4-d821ffca9ad9","request_id":"9290b82afd7ffdea-IAD","timestamp_":"absolute","is_visually_hidden_from_conversation":true,"can_save":false},"recipient":"all","channel":null},"parent":"75d9b849-7852-4be6-a3a4-d821ffca9ad9","children":["f99ae82b-7595-42c5-8707-5cfdb3d51da6"]},"f99ae82b-7595-42c5-8707-5cfdb3d51da6":{"id":"f99ae82b-7595-42c5-8707-5cfdb3d51da6","message":{"id":"f99ae82b-7595-42c5-8707-5cfdb3d51da6","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1743433270.962867,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"message_type":null,"model_slug":"gpt-4-5","default_model_slug":"gpt-4-5","parent_id":"e269f83c-d9a5-4ba1-9044-42270586a0f0","request_id":"9290b82afd7ffdea-IAD","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"e269f83c-d9a5-4ba1-9044-42270586a0f0","children":["57a6f4b6-85f5-4337-8144-2453f08eb3d7"]},"57a6f4b6-85f5-4337-8144-2453f08eb3d7":{"id":"57a6f4b6-85f5-4337-8144-2453f08eb3d7","message":{"id":"57a6f4b6-85f5-4337-8144-2453f08eb3d7","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1743433259.169214,"update_time":null,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"search(\"what is the latest research on JEPA?\")"},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"citations":[],"content_references":[],"message_type":null,"model_slug":"gpt-4-5","default_model_slug":"gpt-4-5","parent_id":"f99ae82b-7595-42c5-8707-5cfdb3d51da6","request_id":"9290b82afd7ffdea-IAD","timestamp_":"absolute","can_save":true},"recipient":"web","channel":null},"parent":"f99ae82b-7595-42c5-8707-5cfdb3d51da6","children":["c4e8465a-ab3a-4188-aef2-17343651c56a"]},"c4e8465a-ab3a-4188-aef2-17343651c56a":{"id":"c4e8465a-ab3a-4188-aef2-17343651c56a","message":{"id":"c4e8465a-ab3a-4188-aef2-17343651c56a","author":{"role":"tool","name":"web","metadata":{}},"create_time":1743433259.268646,"update_time":null,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":""},"status":"finished_successfully","end_turn":null,"weight":0.0,"metadata":{"is_visually_hidden_from_conversation":true,"command":"search","status":"finished","is_complete":true,"message_type":null,"model_slug":"gpt-4-5","default_model_slug":"gpt-4-5","parent_id":"57a6f4b6-85f5-4337-8144-2453f08eb3d7","request_id":"9290b82afd7ffdea-IAD","timestamp_":"absolute","can_save":false},"recipient":"assistant","channel":null},"parent":"57a6f4b6-85f5-4337-8144-2453f08eb3d7","children":["60aeaf94-d3aa-4b54-8cda-05e706ee30ab"]},"60aeaf94-d3aa-4b54-8cda-05e706ee30ab":{"id":"60aeaf94-d3aa-4b54-8cda-05e706ee30ab","message":{"id":"60aeaf94-d3aa-4b54-8cda-05e706ee30ab","author":{"role":"assistant","name":null,"metadata":{"real_author":"tool:web"}},"create_time":1743433259.2691302,"update_time":null,"content":{"content_type":"text","parts":["\ue203Recent advancements in the Joint Embedding Predictive Architecture (JEPA) have expanded its applications across various domains, showcasing its versatility in self-supervised learning.\ue204 Notable developments include:\ue206\n\n**1. Video-JEPA (V-JEPA):**\n\ue203Researchers at Meta AI have introduced V-JEPA, extending JEPA to video data. This model predicts representations of future video frames based on past contexts, capturing temporal dynamics effectively and marking a significant step toward advanced machine intelligence.\ue204 \ue200cite\ue202turn0search3\ue201\ue206\n\n**2. Point-JEPA:**\n\ue203In the realm of 3D data, Point-JEPA has been proposed for self-supervised learning on point clouds. By employing a greedy algorithm based on spatial proximity, it orders point cloud patch embeddings, demonstrating state-of-the-art performance in few-shot learning evaluations.\ue204 \ue200cite\ue202turn0search4\ue201\ue206\n\n**3. Graph-JEPA:**\n\ue203Applying JEPA to graph-level representation learning, Graph-JEPA predicts latent representations of masked subgraphs from context subgraphs. This approach has shown efficacy in tasks like graph classification and regression, highlighting JEPA's adaptability to structured data.\ue204 \ue200cite\ue202turn0academia10\ue201\ue206\n\n**4. DMT-JEPA:**\n\ue203Addressing local semantic understanding, DMT-JEPA introduces discriminative masked targets by leveraging semantically similar neighboring patches as prediction targets. This enhancement improves JEPA's discriminative power across various visual benchmarks.\ue204 \ue200cite\ue202turn0academia11\ue201\ue206\n\n**5. C-JEPA:**\n\ue203Integrating JEPA with contrastive self-supervised learning, C-JEPA combines JEPA with the Variance-Invariance-Covariance Regularization (VICReg) strategy. This fusion enhances stability and representation quality, leading to improved performance in visual representation tasks.\ue204 \ue200cite\ue202turn0academia12\ue201\ue206\n\n**6. JEPA in Medical Applications:**\n\ue203In healthcare, JEPA has been applied to electrocardiogram (ECG) data, demonstrating improved classification performance. By pre-training on large unlabeled ECG datasets, JEPA effectively captures meaningful representations, aiding in accurate heart arrhythmia diagnosis.\ue204 \ue200cite\ue202turn0academia13\ue201\ue206\n\n\ue203These developments underscore JEPA's growing influence and adaptability across diverse fields, from video analysis and 3D modeling to graph data and medical diagnostics.\ue204\ue206 "]},"status":"finished_successfully","end_turn":true,"weight":1.0,"metadata":{"search_source":"composer_search","client_reported_search_source":"conversation_composer_web_icon","debug_sonic_thread_id":"thread_67eaae2b3a20800782da606b97e08570","search_result_groups":[{"type":"search_result_group","domain":"meta.com","entries":[{"type":"search_result","url":"https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/","title":"V-JEPA: The next step toward advanced machine intelligence","snippet":"V-JEPA is a non-generative model that learns by predicting missing or masked parts of a video in an abstract representation space.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":0},"content_type":null,"pub_date":1707955200.0,"attributions":null,"attribution":"Meta AI"},{"type":"search_result","url":"https://ai.meta.com/blog/yann-lecun-ai-model-i-jepa/","title":"I-JEPA: The first AI model based on Yann LeCun's vision for more ...","snippet":"I-JEPA learns by creating an internal model of the outside world, which compares abstract representations of images (rather than comparing ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":8},"content_type":null,"pub_date":1686614400.0,"attributions":null,"attribution":"Meta AI"}]},{"type":"search_result_group","domain":"linkedin.com","entries":[{"type":"search_result","url":"https://www.linkedin.com/pulse/joint-embedding-predictive-architecture-jepa-new-paradigm-sameer-shah-lm1jc","title":"Joint Embedding Predictive Architecture (JEPA): A New Paradigm in AI","snippet":"JEPA represents a paradigm shift in how AI systems approach the prediction of real-world events, moving beyond the limitations of traditional autoregressive ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":1},"content_type":null,"pub_date":1739232000.0,"attributions":null,"attribution":"LinkedIn"}]},{"type":"search_result_group","domain":"rohitbandaru.github.io","entries":[{"type":"search_result","url":"https://rohitbandaru.github.io/blog/JEPA-Deep-Dive/","title":"Deep Dive into Yann LeCun's JEPA - Rohit Bandaru","snippet":"This blog post will dive deep into Yann's vision for AI, the JEPA architecture, current research, and energy based models.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":2},"content_type":null,"pub_date":1722384000.0,"attributions":null,"attribution":"Rohit Bandaru"}]},{"type":"search_result_group","domain":"marktechpost.com","entries":[{"type":"search_result","url":"https://www.marktechpost.com/2025/02/22/meta-ai-releases-the-video-joint-embedding-predictive-architecture-v-jepa-model-a-crucial-step-in-advancing-machine-intelligence/","title":"Meta AI Releases the Video Joint Embedding Predictive Architecture ...","snippet":"Meta AI Releases the Video Joint Embedding Predictive Architecture (V-JEPA) Model: A Crucial Step in Advancing Machine Intelligence.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":3},"content_type":null,"pub_date":1740182400.0,"attributions":null,"attribution":"MarkTechPost"}]},{"type":"search_result_group","domain":"thecvf.com","entries":[{"type":"search_result","url":"https://openaccess.thecvf.com/content/WACV2025/papers/Saito_Point-JEPA_A_Joint_Embedding_Predictive_Architecture_for_Self-Supervised_Learning_on_WACV_2025_paper.pdf","title":"[PDF] Point-JEPA: A Joint Embedding Predictive Architecture for Self ...","snippet":"We propose a point cloud patch embedding ordering method for Joint-Embedding Predictive Architecture, utilizing a greedy algorithm based on spatial proxim- ity.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":4},"content_type":null,"pub_date":null,"attributions":null,"attribution":"CVF Open Access"}]},{"type":"search_result_group","domain":"thesingularityproject.ai","entries":[{"type":"search_result","url":"https://www.thesingularityproject.ai/blog/yann-lecuns-joint-embedding-predictive-architecture-jepa-and-the-general-theory-of-intelligence","title":"Yann LeCun's Joint Embedding Predictive Architecture (JEPA) and ...","snippet":"JEPA forms a core part of LeCun's proposed blueprint for autonomous AI agents, serving as the \u201cworld model\u201d module that helps an AI predict ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":5},"content_type":null,"pub_date":1741651200.0,"attributions":null,"attribution":"The Singularity Project"}]},{"type":"search_result_group","domain":"github.com","entries":[{"type":"search_result","url":"https://github.com/neobundy/Deep-Dive-Into-AI-With-MLX-PyTorch/blob/master/deep-dives/015-meta-jepa/README.md","title":"Deep Dive in Meta AI's JEPA - Joint-Embedding Predictive ... - GitHub","snippet":"The primary aim of this architecture is to predict the representations of various target blocks within an image based on a given context block.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":6},"content_type":null,"pub_date":1741392000.0,"attributions":null,"attribution":"GitHub"}]},{"type":"search_result_group","domain":"apple.com","entries":[{"type":"search_result","url":"https://machinelearning.apple.com/research/implicit-bias","title":"How JEPA Avoids Noisy Features: The Implicit Bias of Deep Linear ...","snippet":"A common motivation for using the JEPA approach over MAE is that the JEPA objective prioritizes abstract features over fine-grained pixel information (which can ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":7},"content_type":null,"pub_date":null,"attributions":null,"attribution":"Apple Machine Learning Research"}]},{"type":"search_result_group","domain":"openreview.net","entries":[{"type":"search_result","url":"https://openreview.net/forum?id=d4njmzM7jf","title":"Denoising with a Joint-Embedding Predictive Architecture","snippet":"In this paper, we introduce Denoising with a Joint-Embedding Predictive Architecture (D-JEPA), pioneering the integration of JEPA within generative modeling.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":9},"content_type":null,"pub_date":null,"attributions":null,"attribution":"OpenReview"}]}],"safe_urls":["https://arxiv.org/abs/2410.19560?utm_source=chatgpt.com","https://openaccess.thecvf.com/content/WACV2025/papers/Saito_Point-JEPA_A_Joint_Embedding_Predictive_Architecture_for_Self-Supervised_Learning_on_WACV_2025_paper.pdf?utm_source=chatgpt.com","https://arxiv.org/abs/2410.13867?utm_source=chatgpt.com","https://arxiv.org/abs/2405.17995?utm_source=chatgpt.com","https://arxiv.org/abs/2309.16014?utm_source=chatgpt.com","https://www.marktechpost.com/2025/02/22/meta-ai-releases-the-video-joint-embedding-predictive-architecture-v-jepa-model-a-crucial-step-in-advancing-machine-intelligence/?utm_source=chatgpt.com"],"message_type":null,"model_slug":"gpt-4-5","default_model_slug":"gpt-4-5","parent_id":"c4e8465a-ab3a-4188-aef2-17343651c56a","message_locale":"en-US","image_results":[],"content_references":[{"matched_text":"\ue203","start_idx":0,"end_idx":1,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"Recent advancements in the Joint Embedding Predictive Architecture (JEPA) have expanded its applications across various domains, showcasing its versatility in self-supervised learning.","start_idx":1,"end_idx":185,"safe_urls":[],"refs":[],"alt":"Recent advancements in the Joint Embedding Predictive Architecture (JEPA) have expanded its applications across various domains, showcasing its versatility in self-supervised learning.","prompt_text":null,"type":"attribution","attributable_index":"0-0","attributions":null,"attributions_debug":null},{"matched_text":"\ue204","start_idx":185,"end_idx":186,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"\ue206","start_idx":216,"end_idx":217,"refs":[],"alt":null,"prompt_text":null,"type":"grouped_webpages","items":[],"status":"done","error":null,"style":"v2"},{"matched_text":"\ue203","start_idx":247,"end_idx":248,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"Researchers at Meta AI have introduced V-JEPA, extending JEPA to video data. This model predicts representations of future video frames based on past contexts, capturing temporal dynamics effectively and marking a significant step toward advanced machine intelligence.","start_idx":248,"end_idx":516,"safe_urls":[],"refs":[],"alt":"Researchers at Meta AI have introduced V-JEPA, extending JEPA to video data. This model predicts representations of future video frames based on past contexts, capturing temporal dynamics effectively and marking a significant step toward advanced machine intelligence.","prompt_text":null,"type":"attribution","attributable_index":"217-1","attributions":null,"attributions_debug":null},{"matched_text":"\ue204","start_idx":516,"end_idx":517,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"\ue200cite\ue202turn0search3\ue201","start_idx":518,"end_idx":537,"refs":[],"alt":"","prompt_text":"([marktechpost.com](https://www.marktechpost.com/2025/02/22/meta-ai-releases-the-video-joint-embedding-predictive-architecture-v-jepa-model-a-crucial-step-in-advancing-machine-intelligence/?utm_source=chatgpt.com))","type":"grouped_webpages_model_predicted_fallback","items":[{"title":"Meta AI Releases the Video Joint Embedding Predictive Architecture ...","url":"https://www.marktechpost.com/2025/02/22/meta-ai-releases-the-video-joint-embedding-predictive-architecture-v-jepa-model-a-crucial-step-in-advancing-machine-intelligence/?utm_source=chatgpt.com","pub_date":1740182400.0,"snippet":"Meta AI Releases the Video Joint Embedding Predictive Architecture (V-JEPA) Model: A Crucial Step in Advancing Machine Intelligence.","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":3}],"hue":null,"attributions":null}],"status":"done","error":null,"style":null},{"matched_text":"\ue206","start_idx":537,"end_idx":538,"refs":[],"alt":null,"prompt_text":null,"type":"grouped_webpages","items":[{"title":"Meta AI Releases the Video Joint Embedding Predictive Architecture ...","url":"https://www.marktechpost.com/2025/02/22/meta-ai-releases-the-video-joint-embedding-predictive-architecture-v-jepa-model-a-crucial-step-in-advancing-machine-intelligence/?utm_source=chatgpt.com","pub_date":1740182400.0,"snippet":"Meta AI Releases the Video Joint Embedding Predictive Architecture (V-JEPA) Model: A Crucial Step in Advancing Machine Intelligence.","attribution_segments":["217-1"],"supporting_websites":[{"title":"Deep Dive into Yann LeCun's JEPA - Rohit Bandaru","url":"https://rohitbandaru.github.io/blog/JEPA-Deep-Dive/?utm_source=chatgpt.com","pub_date":1722384000.0,"snippet":"This blog post will dive deep into Yann's vision for AI, the JEPA architecture, current research, and energy based models.","attribution":"Rohit Bandaru"},{"title":"Yann LeCun's Joint Embedding Predictive Architecture (JEPA) and ...","url":"https://www.thesingularityproject.ai/blog/yann-lecuns-joint-embedding-predictive-architecture-jepa-and-the-general-theory-of-intelligence?utm_source=chatgpt.com","pub_date":1741651200.0,"snippet":"JEPA forms a core part of LeCun's proposed blueprint for autonomous AI agents, serving as the \u201cworld model\u201d module that helps an AI predict ...","attribution":"The Singularity Project"},{"title":"Deep Dive in Meta AI's JEPA - Joint-Embedding Predictive ... - GitHub","url":"https://github.com/neobundy/Deep-Dive-Into-AI-With-MLX-PyTorch/blob/master/deep-dives/015-meta-jepa/README.md?utm_source=chatgpt.com","pub_date":1741392000.0,"snippet":"The primary aim of this architecture is to predict the representations of various target blocks within an image based on a given context block.","attribution":"GitHub"},{"title":"I-JEPA: The first AI model based on Yann LeCun's vision for more ...","url":"https://ai.meta.com/blog/yann-lecun-ai-model-i-jepa/?utm_source=chatgpt.com","pub_date":1686614400.0,"snippet":"I-JEPA learns by creating an internal model of the outside world, which compares abstract representations of images (rather than comparing ...","attribution":"Meta AI"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":3},{"turn_index":0,"ref_type":"search","ref_index":2},{"turn_index":0,"ref_type":"search","ref_index":5},{"turn_index":0,"ref_type":"search","ref_index":6},{"turn_index":0,"ref_type":"search","ref_index":8}],"hue":null,"attributions":null,"attribution":"MarkTechPost"}],"status":"done","error":null,"style":"v2"},{"matched_text":"\ue203","start_idx":559,"end_idx":560,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"In the realm of 3D data, Point-JEPA has been proposed for self-supervised learning on point clouds. By employing a greedy algorithm based on spatial proximity, it orders point cloud patch embeddings, demonstrating state-of-the-art performance in few-shot learning evaluations.","start_idx":560,"end_idx":836,"safe_urls":[],"refs":[],"alt":"In the realm of 3D data, Point-JEPA has been proposed for self-supervised learning on point clouds. By employing a greedy algorithm based on spatial proximity, it orders point cloud patch embeddings, demonstrating state-of-the-art performance in few-shot learning evaluations.","prompt_text":null,"type":"attribution","attributable_index":"538-1","attributions":null,"attributions_debug":null},{"matched_text":"\ue204","start_idx":836,"end_idx":837,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"\ue200cite\ue202turn0search4\ue201","start_idx":838,"end_idx":857,"refs":[],"alt":"","prompt_text":"([openaccess.thecvf.com](https://openaccess.thecvf.com/content/WACV2025/papers/Saito_Point-JEPA_A_Joint_Embedding_Predictive_Architecture_for_Self-Supervised_Learning_on_WACV_2025_paper.pdf?utm_source=chatgpt.com))","type":"grouped_webpages_model_predicted_fallback","items":[{"title":"[PDF] Point-JEPA: A Joint Embedding Predictive Architecture for Self ...","url":"https://openaccess.thecvf.com/content/WACV2025/papers/Saito_Point-JEPA_A_Joint_Embedding_Predictive_Architecture_for_Self-Supervised_Learning_on_WACV_2025_paper.pdf?utm_source=chatgpt.com","pub_date":null,"snippet":"We propose a point cloud patch embedding ordering method for Joint-Embedding Predictive Architecture, utilizing a greedy algorithm based on spatial proxim- ity.","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":4}],"hue":null,"attributions":null}],"status":"done","error":null,"style":null},{"matched_text":"\ue206","start_idx":857,"end_idx":858,"refs":[],"alt":null,"prompt_text":null,"type":"grouped_webpages","items":[{"title":"[PDF] Point-JEPA: A Joint Embedding Predictive Architecture for Self ...","url":"https://openaccess.thecvf.com/content/WACV2025/papers/Saito_Point-JEPA_A_Joint_Embedding_Predictive_Architecture_for_Self-Supervised_Learning_on_WACV_2025_paper.pdf?utm_source=chatgpt.com","pub_date":null,"snippet":"We propose a point cloud patch embedding ordering method for Joint-Embedding Predictive Architecture, utilizing a greedy algorithm based on spatial proxim- ity.","attribution_segments":["538-1"],"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":4}],"hue":null,"attributions":null,"attribution":"CVF Open Access"}],"status":"done","error":null,"style":"v2"},{"matched_text":"\ue203","start_idx":879,"end_idx":880,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"Applying JEPA to graph-level representation learning, Graph-JEPA predicts latent representations of masked subgraphs from context subgraphs. This approach has shown efficacy in tasks like graph classification and regression, highlighting JEPA's adaptability to structured data.","start_idx":880,"end_idx":1157,"safe_urls":[],"refs":[],"alt":"Applying JEPA to graph-level representation learning, Graph-JEPA predicts latent representations of masked subgraphs from context subgraphs. This approach has shown efficacy in tasks like graph classification and regression, highlighting JEPA's adaptability to structured data.","prompt_text":null,"type":"attribution","attributable_index":"858-1","attributions":null,"attributions_debug":null},{"matched_text":"\ue204","start_idx":1157,"end_idx":1158,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"\ue200cite\ue202turn0academia10\ue201","start_idx":1159,"end_idx":1181,"refs":[],"alt":"","prompt_text":"([arxiv.org](https://arxiv.org/abs/2309.16014?utm_source=chatgpt.com))","type":"grouped_webpages_model_predicted_fallback","items":[{"title":"Graph-level Representation Learning with Joint-Embedding Predictive Architectures","url":"https://arxiv.org/abs/2309.16014?utm_source=chatgpt.com","pub_date":1695847322.0,"snippet":"","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"academia","ref_index":10}],"hue":null,"attributions":null}],"status":"done","error":null,"style":null},{"matched_text":"\ue206","start_idx":1181,"end_idx":1182,"refs":[],"alt":null,"prompt_text":null,"type":"grouped_webpages","items":[{"title":"Graph-level Representation Learning with Joint-Embedding Predictive Architectures","url":"https://arxiv.org/abs/2309.16014?utm_source=chatgpt.com","pub_date":1695847322.0,"snippet":"Joint-Embedding Predictive Architectures (JEPAs) have recently emerged as a novel and powerful technique for self-supervised representation learning. They aim to learn an energy-based model by predict...","attribution_segments":["858-1"],"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"academia","ref_index":10}],"hue":null,"attributions":null,"attribution":"arXiv"}],"status":"done","error":null,"style":"v2"},{"matched_text":"\ue203","start_idx":1201,"end_idx":1202,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"Addressing local semantic understanding, DMT-JEPA introduces discriminative masked targets by leveraging semantically similar neighboring patches as prediction targets. This enhancement improves JEPA's discriminative power across various visual benchmarks.","start_idx":1202,"end_idx":1458,"safe_urls":[],"refs":[],"alt":"Addressing local semantic understanding, DMT-JEPA introduces discriminative masked targets by leveraging semantically similar neighboring patches as prediction targets. This enhancement improves JEPA's discriminative power across various visual benchmarks.","prompt_text":null,"type":"attribution","attributable_index":"1182-1","attributions":null,"attributions_debug":null},{"matched_text":"\ue204","start_idx":1458,"end_idx":1459,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"\ue200cite\ue202turn0academia11\ue201","start_idx":1460,"end_idx":1482,"refs":[],"alt":"","prompt_text":"([arxiv.org](https://arxiv.org/abs/2405.17995?utm_source=chatgpt.com))","type":"grouped_webpages_model_predicted_fallback","items":[{"title":"DMT-JEPA: Discriminative Masked Targets for Joint-Embedding Predictive Architecture","url":"https://arxiv.org/abs/2405.17995?utm_source=chatgpt.com","pub_date":1716888532.0,"snippet":"","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"academia","ref_index":11}],"hue":null,"attributions":null}],"status":"done","error":null,"style":null},{"matched_text":"\ue206","start_idx":1482,"end_idx":1483,"refs":[],"alt":null,"prompt_text":null,"type":"grouped_webpages","items":[{"title":"DMT-JEPA: Discriminative Masked Targets for Joint-Embedding Predictive Architecture","url":"https://arxiv.org/abs/2405.17995?utm_source=chatgpt.com","pub_date":1716888532.0,"snippet":"The joint-embedding predictive architecture (JEPA) recently has shown impressive results in extracting visual representations from unlabeled imagery under a masking strategy. However, we reveal its di...","attribution_segments":["1182-1"],"supporting_websites":[{"title":"[PDF] Point-JEPA: A Joint Embedding Predictive Architecture for Self ...","url":"https://openaccess.thecvf.com/content/WACV2025/papers/Saito_Point-JEPA_A_Joint_Embedding_Predictive_Architecture_for_Self-Supervised_Learning_on_WACV_2025_paper.pdf?utm_source=chatgpt.com","pub_date":null,"snippet":"We propose a point cloud patch embedding ordering method for Joint-Embedding Predictive Architecture, utilizing a greedy algorithm based on spatial proxim- ity.","attribution":"CVF Open Access"},{"title":"Connecting Joint-Embedding Predictive Architecture with Contrastive Self-supervised Learning","url":"https://arxiv.org/abs/2410.19560?utm_source=chatgpt.com","pub_date":1729864092.0,"snippet":"In recent advancements in unsupervised visual representation learning, the Joint-Embedding Predictive Architecture (JEPA) has emerged as a significant method for extracting visual features from unlabe...","attribution":"arXiv"}],"refs":[{"turn_index":0,"ref_type":"academia","ref_index":11},{"turn_index":0,"ref_type":"search","ref_index":4},{"turn_index":0,"ref_type":"academia","ref_index":12}],"hue":null,"attributions":null,"attribution":"arXiv"}],"status":"done","error":null,"style":"v2"},{"matched_text":"\ue203","start_idx":1500,"end_idx":1501,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"Integrating JEPA with contrastive self-supervised learning, C-JEPA combines JEPA with the Variance-Invariance-Covariance Regularization (VICReg) strategy. This fusion enhances stability and representation quality, leading to improved performance in visual representation tasks.","start_idx":1501,"end_idx":1778,"safe_urls":[],"refs":[],"alt":"Integrating JEPA with contrastive self-supervised learning, C-JEPA combines JEPA with the Variance-Invariance-Covariance Regularization (VICReg) strategy. This fusion enhances stability and representation quality, leading to improved performance in visual representation tasks.","prompt_text":null,"type":"attribution","attributable_index":"1483-1","attributions":null,"attributions_debug":null},{"matched_text":"\ue204","start_idx":1778,"end_idx":1779,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"\ue200cite\ue202turn0academia12\ue201","start_idx":1780,"end_idx":1802,"refs":[],"alt":"","prompt_text":"([arxiv.org](https://arxiv.org/abs/2410.19560?utm_source=chatgpt.com))","type":"grouped_webpages_model_predicted_fallback","items":[{"title":"Connecting Joint-Embedding Predictive Architecture with Contrastive Self-supervised Learning","url":"https://arxiv.org/abs/2410.19560?utm_source=chatgpt.com","pub_date":1729864092.0,"snippet":"","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"academia","ref_index":12}],"hue":null,"attributions":null}],"status":"done","error":null,"style":null},{"matched_text":"\ue206","start_idx":1802,"end_idx":1803,"refs":[],"alt":null,"prompt_text":null,"type":"grouped_webpages","items":[{"title":"Connecting Joint-Embedding Predictive Architecture with Contrastive Self-supervised Learning","url":"https://arxiv.org/abs/2410.19560?utm_source=chatgpt.com","pub_date":1729864092.0,"snippet":"In recent advancements in unsupervised visual representation learning, the Joint-Embedding Predictive Architecture (JEPA) has emerged as a significant method for extracting visual features from unlabe...","attribution_segments":["1483-1"],"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"academia","ref_index":12}],"hue":null,"attributions":null,"attribution":"arXiv"}],"status":"done","error":null,"style":"v2"},{"matched_text":"\ue203","start_idx":1842,"end_idx":1843,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"In healthcare, JEPA has been applied to electrocardiogram (ECG) data, demonstrating improved classification performance. By pre-training on large unlabeled ECG datasets, JEPA effectively captures meaningful representations, aiding in accurate heart arrhythmia diagnosis.","start_idx":1843,"end_idx":2113,"safe_urls":[],"refs":[],"alt":"In healthcare, JEPA has been applied to electrocardiogram (ECG) data, demonstrating improved classification performance. By pre-training on large unlabeled ECG datasets, JEPA effectively captures meaningful representations, aiding in accurate heart arrhythmia diagnosis.","prompt_text":null,"type":"attribution","attributable_index":"1803-1","attributions":null,"attributions_debug":null},{"matched_text":"\ue204","start_idx":2113,"end_idx":2114,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"\ue200cite\ue202turn0academia13\ue201","start_idx":2115,"end_idx":2137,"refs":[],"alt":"","prompt_text":"([arxiv.org](https://arxiv.org/abs/2410.13867?utm_source=chatgpt.com))","type":"grouped_webpages_model_predicted_fallback","items":[{"title":"Self-Supervised Pre-Training with Joint-Embedding Predictive Architecture Boosts ECG Classification Performance","url":"https://arxiv.org/abs/2410.13867?utm_source=chatgpt.com","pub_date":1727857557.0,"snippet":"","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"academia","ref_index":13}],"hue":null,"attributions":null}],"status":"done","error":null,"style":null},{"matched_text":"\ue206","start_idx":2137,"end_idx":2138,"refs":[],"alt":null,"prompt_text":null,"type":"grouped_webpages","items":[{"title":"Self-Supervised Pre-Training with Joint-Embedding Predictive Architecture Boosts ECG Classification Performance","url":"https://arxiv.org/abs/2410.13867?utm_source=chatgpt.com","pub_date":1727857557.0,"snippet":"Accurate diagnosis of heart arrhythmias requires the interpretation of electrocardiograms (ECG), which capture the electrical activity of the heart. Automating this process through machine learning is...","attribution_segments":["1803-1"],"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"academia","ref_index":13}],"hue":null,"attributions":null,"attribution":"arXiv"}],"status":"done","error":null,"style":"v2"},{"matched_text":"\ue203","start_idx":2140,"end_idx":2141,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"These developments underscore JEPA's growing influence and adaptability across diverse fields, from video analysis and 3D modeling to graph data and medical diagnostics.","start_idx":2141,"end_idx":2310,"safe_urls":[],"refs":[],"alt":"These developments underscore JEPA's growing influence and adaptability across diverse fields, from video analysis and 3D modeling to graph data and medical diagnostics.","prompt_text":null,"type":"attribution","attributable_index":"2138-0","attributions":null,"attributions_debug":null},{"matched_text":"\ue204","start_idx":2310,"end_idx":2311,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"\ue206","start_idx":2311,"end_idx":2312,"refs":[],"alt":null,"prompt_text":null,"type":"grouped_webpages","items":[],"status":"done","error":null,"style":"v2"},{"matched_text":" ","start_idx":2312,"end_idx":2312,"refs":[],"alt":"","prompt_text":null,"type":"sources_footnote","sources":[{"title":"Meta AI Releases the Video Joint Embedding Predictive Architecture ...","url":"https://www.marktechpost.com/2025/02/22/meta-ai-releases-the-video-joint-embedding-predictive-architecture-v-jepa-model-a-crucial-step-in-advancing-machine-intelligence/?utm_source=chatgpt.com","attribution":"MarkTechPost"},{"title":"[PDF] Point-JEPA: A Joint Embedding Predictive Architecture for Self ...","url":"https://openaccess.thecvf.com/content/WACV2025/papers/Saito_Point-JEPA_A_Joint_Embedding_Predictive_Architecture_for_Self-Supervised_Learning_on_WACV_2025_paper.pdf?utm_source=chatgpt.com","attribution":"CVF Open Access"},{"title":"Graph-level Representation Learning with Joint-Embedding Predictive Architectures","url":"https://arxiv.org/abs/2309.16014?utm_source=chatgpt.com","attribution":"arXiv"}],"has_images":false}],"citations":[{"start_ix":0,"end_ix":1,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":185,"end_ix":186,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":216,"end_ix":217,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":247,"end_ix":248,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":516,"end_ix":517,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":518,"end_ix":537,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":537,"end_ix":538,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":559,"end_ix":560,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":836,"end_ix":837,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":838,"end_ix":857,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":857,"end_ix":858,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":879,"end_ix":880,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1157,"end_ix":1158,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1159,"end_ix":1181,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1181,"end_ix":1182,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1201,"end_ix":1202,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1458,"end_ix":1459,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1460,"end_ix":1482,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1482,"end_ix":1483,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1500,"end_ix":1501,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1778,"end_ix":1779,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1780,"end_ix":1802,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1802,"end_ix":1803,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1842,"end_ix":1843,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":2113,"end_ix":2114,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":2115,"end_ix":2137,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":2137,"end_ix":2138,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":2140,"end_ix":2141,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":2310,"end_ix":2311,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":2311,"end_ix":2312,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":2312,"end_ix":2312,"invalid_reason":"Unsupported, please upgrade"}],"request_id":"9290b82afd7ffdea-IAD","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"c4e8465a-ab3a-4188-aef2-17343651c56a","children":["a0fdbb3a-59eb-4484-a1f5-fc4be6068b3d"]},"a0fdbb3a-59eb-4484-a1f5-fc4be6068b3d":{"id":"a0fdbb3a-59eb-4484-a1f5-fc4be6068b3d","message":{"id":"a0fdbb3a-59eb-4484-a1f5-fc4be6068b3d","author":{"role":"user","name":null,"metadata":{}},"create_time":1743433402.864,"update_time":null,"content":{"content_type":"text","parts":["what research is there linking JEPA with autoregressive transformers?"]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"system_hints":["search"],"serialization_metadata":{"custom_symbol_offsets":[]},"dictation":false,"request_id":"9290bbaffeacfdea-IAD","message_source":null,"timestamp_":"absolute","message_type":null,"can_save":true},"recipient":"all","channel":null},"parent":"60aeaf94-d3aa-4b54-8cda-05e706ee30ab","children":["49c0e754-d0b2-496d-9d69-f84086171adf"]},"49c0e754-d0b2-496d-9d69-f84086171adf":{"id":"49c0e754-d0b2-496d-9d69-f84086171adf","message":{"id":"49c0e754-d0b2-496d-9d69-f84086171adf","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1743433403.8040292,"update_time":null,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"search(\"what research is there linking JEPA with autoregressive transformers?\")"},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"citations":[],"content_references":[],"message_type":null,"model_slug":"gpt-4-5","default_model_slug":"gpt-4-5","parent_id":"a0fdbb3a-59eb-4484-a1f5-fc4be6068b3d","request_id":"9290bbaffeacfdea-IAD","timestamp_":"absolute","can_save":true},"recipient":"web","channel":null},"parent":"a0fdbb3a-59eb-4484-a1f5-fc4be6068b3d","children":["b4de8354-a5f8-41b0-8818-69e3aaae5787"]},"b4de8354-a5f8-41b0-8818-69e3aaae5787":{"id":"b4de8354-a5f8-41b0-8818-69e3aaae5787","message":{"id":"b4de8354-a5f8-41b0-8818-69e3aaae5787","author":{"role":"tool","name":"web","metadata":{}},"create_time":1743433403.9397993,"update_time":null,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":""},"status":"finished_successfully","end_turn":null,"weight":0.0,"metadata":{"is_visually_hidden_from_conversation":true,"command":"search","status":"finished","is_complete":true,"message_type":null,"model_slug":"gpt-4-5","default_model_slug":"gpt-4-5","parent_id":"49c0e754-d0b2-496d-9d69-f84086171adf","request_id":"9290bbaffeacfdea-IAD","timestamp_":"absolute","can_save":false},"recipient":"assistant","channel":null},"parent":"49c0e754-d0b2-496d-9d69-f84086171adf","children":["4dd37814-7c6c-4ae3-a6c8-e6381533e23c"]},"4dd37814-7c6c-4ae3-a6c8-e6381533e23c":{"id":"4dd37814-7c6c-4ae3-a6c8-e6381533e23c","message":{"id":"4dd37814-7c6c-4ae3-a6c8-e6381533e23c","author":{"role":"assistant","name":null,"metadata":{"real_author":"tool:web"}},"create_time":1743433403.9403715,"update_time":null,"content":{"content_type":"text","parts":["\ue203The **Joint Embedding Predictive Architecture (JEPA)** and **autoregressive transformers** represent two distinct approaches within machine learning, each with unique methodologies and applications.\ue204 \ue203While both aim to model data distributions effectively, their integration and comparative analysis have been subjects of recent research.\ue204\ue206\n\n**JEPA and Autoregressive Transformers: Distinct Approaches**\n\n\ue203JEPA focuses on predicting missing parts of data by leveraging contextual information, operating in a latent space to capture high-level representations without reconstructing the original input.\ue204 \ue203In contrast, autoregressive transformers generate sequences by predicting the next token based on previously generated tokens, making them prevalent in tasks like language modeling and sequence generation.\ue204\ue206\n\n**Integration of JEPA with Autoregressive Techniques**\n\n\ue203Recent studies have explored integrating JEPA with autoregressive methods to enhance generative modeling:\ue204\ue206\n\n1. **Denoising with a Joint-Embedding Predictive Architecture (D-JEPA):** \ue203This model combines JEPA with diffusion models to perform next-token prediction in continuous data spaces, such as images.\ue204 \ue203By integrating diffusion loss, D-JEPA models per-token probability distributions, enabling data generation in an autoregressive manner.\ue204 \ue203Empirical results indicate that D-JEPA achieves lower Fr\u00e9chet Inception Distance (FID) scores with fewer training epochs, demonstrating its scalability and effectiveness in image generation tasks.\ue204 \ue200cite\ue202turn0academia10\ue201\ue206\n\n2. **High-Resolution Image Synthesis via Next-Token Prediction (D-JEPA\u00b7T2I):** \ue203An extension of D-JEPA, this model incorporates flow matching loss to facilitate continuous resolution learning.\ue204 \ue203It employs a multimodal visual transformer to integrate textual and visual features effectively, achieving state-of-the-art performance in high-resolution image synthesis through next-token prediction.\ue204 \ue200cite\ue202turn0academia11\ue201\ue206\n\n**Clarifications from Yann LeCun**\n\n\ue203Yann LeCun, the proponent of JEPA, has clarified that JEPA is not an alternative to transformers.\ue204 \ue203In fact, many JEPA systems utilize transformer modules.\ue204 \ue203JEPA serves as an alternative to autoregressive generative architectures, regardless of whether they employ transformers.\ue204 \ue200cite\ue202turn0search3\ue201\ue206\n\n**Conclusion**\n\n\ue203While JEPA and autoregressive transformers have traditionally been viewed as separate methodologies, recent research endeavors have begun to explore their integration, aiming to leverage the strengths of both approaches for improved performance in generative modeling tasks.\ue204\ue206 "]},"status":"finished_successfully","end_turn":true,"weight":1.0,"metadata":{"search_source":"composer_search","client_reported_search_source":"conversation_composer_previous_web_mode","debug_sonic_thread_id":"thread_67eaaebbe5f08007b893248b1a3a33e5","search_result_groups":[{"type":"search_result_group","domain":"threads.net","entries":[{"type":"search_result","url":"https://www.threads.net/%40yannlecun/post/C8wNRocuExq?hl=en","title":"A small clarification: JEPA is not an alternative to transformers. I'm ...","snippet":"JEPA is not an alternative to transformers. I'm fact, many JEPA systems use transformer modules. It is an alternative to Auto-Regressive Generative ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":0},"content_type":null,"pub_date":1719532800.0,"attributions":null,"attribution":"Threads"}]},{"type":"search_result_group","domain":"reddit.com","entries":[{"type":"search_result","url":"https://www.reddit.com/r/learnmachinelearning/comments/1gya9pm/can_someone_explain_to_me_in_a_laymenish_terms/","title":"Can someone explain to me in a laymen-ish terms why is I-JEPA ...","snippet":"Transformers that do next-token-prediction are used to \"generate\" new tokens, in an autoregressive manner, given a starting token (notice ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":1},"content_type":null,"pub_date":1732320000.0,"attributions":null,"attribution":"Reddit"}]},{"type":"search_result_group","domain":"rohitbandaru.github.io","entries":[{"type":"search_result","url":"https://rohitbandaru.github.io/blog/JEPA-Deep-Dive/","title":"Deep Dive into Yann LeCun's JEPA - Rohit Bandaru","snippet":"This blog post will dive deep into Yann's vision for AI, the JEPA architecture, current research, and energy based models.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":2},"content_type":null,"pub_date":1722384000.0,"attributions":null,"attribution":"Rohit Bandaru"}]},{"type":"search_result_group","domain":"x.com","entries":[{"type":"search_result","url":"https://x.com/ylecun/status/1806610020974362819","title":"Yann LeCun - X","snippet":"A small clarification: JEPA is not an alternative to transformers. I'm fact, many JEPA systems use transformer modules. It is an alternative ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":3},"content_type":null,"pub_date":1719532800.0,"attributions":null,"attribution":"X (formerly Twitter)"}]},{"type":"search_result_group","domain":"github.com","entries":[{"type":"search_result","url":"https://github.com/neobundy/Deep-Dive-Into-AI-With-MLX-PyTorch/blob/master/deep-dives/015-meta-jepa/README.md","title":"Deep Dive in Meta AI's JEPA - Joint-Embedding Predictive ... - GitHub","snippet":"The introduction of ViT has spurred significant interest in applying transformer models to a wider range of tasks beyond language processing.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":4},"content_type":null,"pub_date":1741392000.0,"attributions":null,"attribution":"GitHub"}]},{"type":"search_result_group","domain":"linkedin.com","entries":[{"type":"search_result","url":"https://www.linkedin.com/posts/yann-lecun_excellent-blog-post-from-turing-post-on-jepa-activity-7212375691353321472-CHyy","title":"Yann LeCun's Post - LinkedIn","snippet":"A small clarification: JEPA is not an alternative to transformers. I'm fact, many JEPA systems use transformer modules. It is an alternative ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":5},"content_type":null,"pub_date":1719532800.0,"attributions":null,"attribution":"LinkedIn"}]},{"type":"search_result_group","domain":"arxiv.org","entries":[{"type":"search_result","url":"https://arxiv.org/html/2407.07356v2","title":"Autoregressive Transformers are Zero-Shot Video Imitators - arXiv","snippet":"In this paper, we explore utilizing visual signals as a new interface for models to interact with the environment. Specifically, we choose ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":6},"content_type":null,"pub_date":1742342400.0,"attributions":null,"attribution":"arXiv"},{"type":"search_result","url":"https://arxiv.org/html/2311.15830v3","title":"A-JEPA: Joint-Embedding Predictive Architecture Can Listen - arXiv","snippet":"We introduce Audio-based Joint-Embedding Predictive Architecture (A-JEPA), a simple extension method for self-supervised learning from the audio spectrum.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":9},"content_type":null,"pub_date":1704931200.0,"attributions":null,"attribution":"arXiv"}]},{"type":"search_result_group","domain":"openreview.net","entries":[{"type":"search_result","url":"https://openreview.net/pdf/d7f4ab52978963ec7be546290f7aa260cb6a2481.pdf","title":"[PDF] AUTOREGRESSIVE TRANSFORMERS ARE ZERO-SHOT VIDEO ...","snippet":"We train a large Transformer model VidIT that exhibits powerful video imitation learning capacity, which also follows the scaling law of large models. \u2022 We ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":7},"content_type":null,"pub_date":null,"attributions":null,"attribution":"OpenReview"}]},{"type":"search_result_group","domain":"wonderfall.dev","entries":[{"type":"search_result","url":"https://wonderfall.dev/autoregressive/","title":"Some thoughts on autoregressive models - Wonder's Lab","snippet":"In the field of statistics, an autoregressive model means that future outputs (or predictions) depend directly on all previous inputs (or tokens) ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":8},"content_type":null,"pub_date":1740009600.0,"attributions":null,"attribution":"Wonder's Lab"}]}],"safe_urls":["https://arxiv.org/abs/2410.03755?utm_source=chatgpt.com","https://arxiv.org/abs/2411.14808?utm_source=chatgpt.com","https://x.com/ylecun/status/1806610020974362819?utm_source=chatgpt.com"],"message_type":null,"model_slug":"gpt-4-5","default_model_slug":"gpt-4-5","parent_id":"b4de8354-a5f8-41b0-8818-69e3aaae5787","message_locale":"en-US","image_results":[],"content_references":[{"matched_text":"\ue203","start_idx":0,"end_idx":1,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"The **Joint Embedding Predictive Architecture (JEPA)** and **autoregressive transformers** represent two distinct approaches within machine learning, each with unique methodologies and applications.","start_idx":1,"end_idx":199,"safe_urls":[],"refs":[],"alt":"The **Joint Embedding Predictive Architecture (JEPA)** and **autoregressive transformers** represent two distinct approaches within machine learning, each with unique methodologies and applications.","prompt_text":null,"type":"attribution","attributable_index":"0-0","attributions":null,"attributions_debug":null},{"matched_text":"\ue204","start_idx":199,"end_idx":200,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"\ue203","start_idx":201,"end_idx":202,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"While both aim to model data distributions effectively, their integration and comparative analysis have been subjects of recent research.","start_idx":202,"end_idx":339,"safe_urls":[],"refs":[],"alt":"While both aim to model data distributions effectively, their integration and comparative analysis have been subjects of recent research.","prompt_text":null,"type":"attribution","attributable_index":"0-1","attributions":null,"attributions_debug":null},{"matched_text":"\ue204","start_idx":339,"end_idx":340,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"\ue206","start_idx":340,"end_idx":341,"refs":[],"alt":null,"prompt_text":null,"type":"grouped_webpages","items":[],"status":"done","error":null,"style":"v2"},{"matched_text":"\ue203","start_idx":406,"end_idx":407,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"JEPA focuses on predicting missing parts of data by leveraging contextual information, operating in a latent space to capture high-level representations without reconstructing the original input.","start_idx":407,"end_idx":602,"safe_urls":[],"refs":[],"alt":"JEPA focuses on predicting missing parts of data by leveraging contextual information, operating in a latent space to capture high-level representations without reconstructing the original input.","prompt_text":null,"type":"attribution","attributable_index":"341-1","attributions":null,"attributions_debug":null},{"matched_text":"\ue204","start_idx":602,"end_idx":603,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"\ue203","start_idx":604,"end_idx":605,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"In contrast, autoregressive transformers generate sequences by predicting the next token based on previously generated tokens, making them prevalent in tasks like language modeling and sequence generation.","start_idx":605,"end_idx":810,"safe_urls":[],"refs":[],"alt":"In contrast, autoregressive transformers generate sequences by predicting the next token based on previously generated tokens, making them prevalent in tasks like language modeling and sequence generation.","prompt_text":null,"type":"attribution","attributable_index":"341-2","attributions":null,"attributions_debug":null},{"matched_text":"\ue204","start_idx":810,"end_idx":811,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"\ue206","start_idx":811,"end_idx":812,"refs":[],"alt":null,"prompt_text":null,"type":"grouped_webpages","items":[],"status":"done","error":null,"style":"v2"},{"matched_text":"\ue203","start_idx":870,"end_idx":871,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"Recent studies have explored integrating JEPA with autoregressive methods to enhance generative modeling:","start_idx":871,"end_idx":976,"safe_urls":[],"refs":[],"alt":"Recent studies have explored integrating JEPA with autoregressive methods to enhance generative modeling:","prompt_text":null,"type":"attribution","attributable_index":"812-1","attributions":null,"attributions_debug":null},{"matched_text":"\ue204","start_idx":976,"end_idx":977,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"\ue206","start_idx":977,"end_idx":978,"refs":[],"alt":null,"prompt_text":null,"type":"grouped_webpages","items":[],"status":"done","error":null,"style":"v2"},{"matched_text":"\ue203","start_idx":1054,"end_idx":1055,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"This model combines JEPA with diffusion models to perform next-token prediction in continuous data spaces, such as images.","start_idx":1055,"end_idx":1177,"safe_urls":[],"refs":[],"alt":"This model combines JEPA with diffusion models to perform next-token prediction in continuous data spaces, such as images.","prompt_text":null,"type":"attribution","attributable_index":"978-1","attributions":null,"attributions_debug":null},{"matched_text":"\ue204","start_idx":1177,"end_idx":1178,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"\ue203","start_idx":1179,"end_idx":1180,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"By integrating diffusion loss, D-JEPA models per-token probability distributions, enabling data generation in an autoregressive manner.","start_idx":1180,"end_idx":1315,"safe_urls":[],"refs":[],"alt":"By integrating diffusion loss, D-JEPA models per-token probability distributions, enabling data generation in an autoregressive manner.","prompt_text":null,"type":"attribution","attributable_index":"978-2","attributions":null,"attributions_debug":null},{"matched_text":"\ue204","start_idx":1315,"end_idx":1316,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"\ue203","start_idx":1317,"end_idx":1318,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"Empirical results indicate that D-JEPA achieves lower Fr\u00e9chet Inception Distance (FID) scores with fewer training epochs, demonstrating its scalability and effectiveness in image generation tasks.","start_idx":1318,"end_idx":1514,"safe_urls":[],"refs":[],"alt":"Empirical results indicate that D-JEPA achieves lower Fr\u00e9chet Inception Distance (FID) scores with fewer training epochs, demonstrating its scalability and effectiveness in image generation tasks.","prompt_text":null,"type":"attribution","attributable_index":"978-3","attributions":null,"attributions_debug":null},{"matched_text":"\ue204","start_idx":1514,"end_idx":1515,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"\ue200cite\ue202turn0academia10\ue201","start_idx":1516,"end_idx":1538,"refs":[],"alt":"","prompt_text":"([arxiv.org](https://arxiv.org/abs/2410.03755?utm_source=chatgpt.com))","type":"grouped_webpages_model_predicted_fallback","items":[{"title":"Denoising with a Joint-Embedding Predictive Architecture","url":"https://arxiv.org/abs/2410.03755?utm_source=chatgpt.com","pub_date":1727848630.0,"snippet":"","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"academia","ref_index":10}],"hue":null,"attributions":null}],"status":"done","error":null,"style":null},{"matched_text":"\ue206","start_idx":1538,"end_idx":1539,"refs":[],"alt":null,"prompt_text":null,"type":"grouped_webpages","items":[{"title":"Can someone explain to me in a laymen-ish terms why is I-JEPA ...","url":"https://www.reddit.com/r/learnmachinelearning/comments/1gya9pm/can_someone_explain_to_me_in_a_laymenish_terms/?utm_source=chatgpt.com","pub_date":1732320000.0,"snippet":"Transformers that do next-token-prediction are used to \"generate\" new tokens, in an autoregressive manner, given a starting token (notice ...","attribution_segments":["978-1"],"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":1}],"hue":null,"attributions":null,"attribution":"Reddit"},{"title":"Denoising with a Joint-Embedding Predictive Architecture","url":"https://arxiv.org/abs/2410.03755?utm_source=chatgpt.com","pub_date":1727848630.0,"snippet":"Joint-embedding predictive architectures (JEPAs) have shown substantial promise in self-supervised representation learning, yet their application in generative modeling remains underexplored. Converse...","attribution_segments":["978-2","978-3"],"supporting_websites":[{"title":"High-Resolution Image Synthesis via Next-Token Prediction","url":"https://arxiv.org/abs/2411.14808?utm_source=chatgpt.com","pub_date":1732266538.0,"snippet":"Denoising with a Joint-Embedding Predictive Architecture (D-JEPA), an autoregressive model, has demonstrated outstanding performance in class-conditional image generation. However, the application of...","attribution":"arXiv"},{"title":"Deep Dive in Meta AI's JEPA - Joint-Embedding Predictive ... - GitHub","url":"https://github.com/neobundy/Deep-Dive-Into-AI-With-MLX-PyTorch/blob/master/deep-dives/015-meta-jepa/README.md?utm_source=chatgpt.com","pub_date":1741392000.0,"snippet":"The introduction of ViT has spurred significant interest in applying transformer models to a wider range of tasks beyond language processing.","attribution":"GitHub"}],"refs":[{"turn_index":0,"ref_type":"academia","ref_index":10},{"turn_index":0,"ref_type":"academia","ref_index":11},{"turn_index":0,"ref_type":"search","ref_index":4}],"hue":null,"attributions":null,"attribution":"arXiv"}],"status":"done","error":null,"style":"v2"},{"matched_text":"\ue203","start_idx":1620,"end_idx":1621,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"An extension of D-JEPA, this model incorporates flow matching loss to facilitate continuous resolution learning.","start_idx":1621,"end_idx":1733,"safe_urls":[],"refs":[],"alt":"An extension of D-JEPA, this model incorporates flow matching loss to facilitate continuous resolution learning.","prompt_text":null,"type":"attribution","attributable_index":"1539-1","attributions":null,"attributions_debug":null},{"matched_text":"\ue204","start_idx":1733,"end_idx":1734,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"\ue203","start_idx":1735,"end_idx":1736,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"It employs a multimodal visual transformer to integrate textual and visual features effectively, achieving state-of-the-art performance in high-resolution image synthesis through next-token prediction.","start_idx":1736,"end_idx":1937,"safe_urls":[],"refs":[],"alt":"It employs a multimodal visual transformer to integrate textual and visual features effectively, achieving state-of-the-art performance in high-resolution image synthesis through next-token prediction.","prompt_text":null,"type":"attribution","attributable_index":"1539-2","attributions":null,"attributions_debug":null},{"matched_text":"\ue204","start_idx":1937,"end_idx":1938,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"\ue200cite\ue202turn0academia11\ue201","start_idx":1939,"end_idx":1961,"refs":[],"alt":"","prompt_text":"([arxiv.org](https://arxiv.org/abs/2411.14808?utm_source=chatgpt.com))","type":"grouped_webpages_model_predicted_fallback","items":[{"title":"High-Resolution Image Synthesis via Next-Token Prediction","url":"https://arxiv.org/abs/2411.14808?utm_source=chatgpt.com","pub_date":1732266538.0,"snippet":"","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"academia","ref_index":11}],"hue":null,"attributions":null}],"status":"done","error":null,"style":null},{"matched_text":"\ue206","start_idx":1961,"end_idx":1962,"refs":[],"alt":null,"prompt_text":null,"type":"grouped_webpages","items":[{"title":"High-Resolution Image Synthesis via Next-Token Prediction","url":"https://arxiv.org/abs/2411.14808?utm_source=chatgpt.com","pub_date":1732266538.0,"snippet":"Denoising with a Joint-Embedding Predictive Architecture (D-JEPA), an autoregressive model, has demonstrated outstanding performance in class-conditional image generation. However, the application of...","attribution_segments":["1539-1","1539-2"],"supporting_websites":[{"title":"Denoising with a Joint-Embedding Predictive Architecture","url":"https://arxiv.org/abs/2410.03755?utm_source=chatgpt.com","pub_date":1727848630.0,"snippet":"Joint-embedding predictive architectures (JEPAs) have shown substantial promise in self-supervised representation learning, yet their application in generative modeling remains underexplored. Converse...","attribution":"arXiv"},{"title":"Deep Dive in Meta AI's JEPA - Joint-Embedding Predictive ... - GitHub","url":"https://github.com/neobundy/Deep-Dive-Into-AI-With-MLX-PyTorch/blob/master/deep-dives/015-meta-jepa/README.md?utm_source=chatgpt.com","pub_date":1741392000.0,"snippet":"The introduction of ViT has spurred significant interest in applying transformer models to a wider range of tasks beyond language processing.","attribution":"GitHub"}],"refs":[{"turn_index":0,"ref_type":"academia","ref_index":11},{"turn_index":0,"ref_type":"academia","ref_index":10},{"turn_index":0,"ref_type":"search","ref_index":4}],"hue":null,"attributions":null,"attribution":"arXiv"}],"status":"done","error":null,"style":"v2"},{"matched_text":"\ue203","start_idx":2000,"end_idx":2001,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"Yann LeCun, the proponent of JEPA, has clarified that JEPA is not an alternative to transformers.","start_idx":2001,"end_idx":2098,"safe_urls":[],"refs":[],"alt":"Yann LeCun, the proponent of JEPA, has clarified that JEPA is not an alternative to transformers.","prompt_text":null,"type":"attribution","attributable_index":"1962-1","attributions":null,"attributions_debug":null},{"matched_text":"\ue204","start_idx":2098,"end_idx":2099,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"\ue203","start_idx":2100,"end_idx":2101,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"In fact, many JEPA systems utilize transformer modules.","start_idx":2101,"end_idx":2156,"safe_urls":[],"refs":[],"alt":"In fact, many JEPA systems utilize transformer modules.","prompt_text":null,"type":"attribution","attributable_index":"1962-2","attributions":null,"attributions_debug":null},{"matched_text":"\ue204","start_idx":2156,"end_idx":2157,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"\ue203","start_idx":2158,"end_idx":2159,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"JEPA serves as an alternative to autoregressive generative architectures, regardless of whether they employ transformers.","start_idx":2159,"end_idx":2280,"safe_urls":[],"refs":[],"alt":"JEPA serves as an alternative to autoregressive generative architectures, regardless of whether they employ transformers.","prompt_text":null,"type":"attribution","attributable_index":"1962-3","attributions":null,"attributions_debug":null},{"matched_text":"\ue204","start_idx":2280,"end_idx":2281,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"\ue200cite\ue202turn0search3\ue201","start_idx":2282,"end_idx":2301,"refs":[],"alt":"","prompt_text":"([x.com](https://x.com/ylecun/status/1806610020974362819?utm_source=chatgpt.com))","type":"grouped_webpages_model_predicted_fallback","items":[{"title":"Yann LeCun - X","url":"https://x.com/ylecun/status/1806610020974362819?utm_source=chatgpt.com","pub_date":1719532800.0,"snippet":"A small clarification: JEPA is not an alternative to transformers. I'm fact, many JEPA systems use transformer modules. It is an alternative ...","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":3}],"hue":null,"attributions":null}],"status":"done","error":null,"style":null},{"matched_text":"\ue206","start_idx":2301,"end_idx":2302,"refs":[],"alt":null,"prompt_text":null,"type":"grouped_webpages","items":[{"title":"Yann LeCun - X","url":"https://x.com/ylecun/status/1806610020974362819?utm_source=chatgpt.com","pub_date":1719532800.0,"snippet":"A small clarification: JEPA is not an alternative to transformers. I'm fact, many JEPA systems use transformer modules. It is an alternative ...","attribution_segments":["1962-1"],"supporting_websites":[{"title":"Yann LeCun's Post - LinkedIn","url":"https://www.linkedin.com/posts/yann-lecun_excellent-blog-post-from-turing-post-on-jepa-activity-7212375691353321472-CHyy?utm_source=chatgpt.com","pub_date":1719532800.0,"snippet":"A small clarification: JEPA is not an alternative to transformers. I'm fact, many JEPA systems use transformer modules. It is an alternative ...","attribution":"LinkedIn"},{"title":"A small clarification: JEPA is not an alternative to transformers. I'm ...","url":"https://www.threads.net/%40yannlecun/post/C8wNRocuExq?hl=en&utm_source=chatgpt.com","pub_date":1719532800.0,"snippet":"JEPA is not an alternative to transformers. I'm fact, many JEPA systems use transformer modules. It is an alternative to Auto-Regressive Generative ...","attribution":"Threads"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":3},{"turn_index":0,"ref_type":"search","ref_index":5},{"turn_index":0,"ref_type":"search","ref_index":0}],"hue":null,"attributions":null,"attribution":"X (formerly Twitter)"},{"title":"Yann LeCun's Post - LinkedIn","url":"https://www.linkedin.com/posts/yann-lecun_excellent-blog-post-from-turing-post-on-jepa-activity-7212375691353321472-CHyy?utm_source=chatgpt.com","pub_date":1719532800.0,"snippet":"A small clarification: JEPA is not an alternative to transformers. I'm fact, many JEPA systems use transformer modules. It is an alternative ...","attribution_segments":["1962-2","1962-3"],"supporting_websites":[{"title":"Yann LeCun - X","url":"https://x.com/ylecun/status/1806610020974362819?utm_source=chatgpt.com","pub_date":1719532800.0,"snippet":"A small clarification: JEPA is not an alternative to transformers. I'm fact, many JEPA systems use transformer modules. It is an alternative ...","attribution":"X (formerly Twitter)"},{"title":"A small clarification: JEPA is not an alternative to transformers. I'm ...","url":"https://www.threads.net/%40yannlecun/post/C8wNRocuExq?hl=en&utm_source=chatgpt.com","pub_date":1719532800.0,"snippet":"JEPA is not an alternative to transformers. I'm fact, many JEPA systems use transformer modules. It is an alternative to Auto-Regressive Generative ...","attribution":"Threads"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":5},{"turn_index":0,"ref_type":"search","ref_index":3},{"turn_index":0,"ref_type":"search","ref_index":0}],"hue":null,"attributions":null,"attribution":"LinkedIn"}],"status":"done","error":null,"style":"v2"},{"matched_text":"\ue203","start_idx":2320,"end_idx":2321,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"While JEPA and autoregressive transformers have traditionally been viewed as separate methodologies, recent research endeavors have begun to explore their integration, aiming to leverage the strengths of both approaches for improved performance in generative modeling tasks.","start_idx":2321,"end_idx":2595,"safe_urls":[],"refs":[],"alt":"While JEPA and autoregressive transformers have traditionally been viewed as separate methodologies, recent research endeavors have begun to explore their integration, aiming to leverage the strengths of both approaches for improved performance in generative modeling tasks.","prompt_text":null,"type":"attribution","attributable_index":"2302-1","attributions":null,"attributions_debug":null},{"matched_text":"\ue204","start_idx":2595,"end_idx":2596,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"\ue206","start_idx":2596,"end_idx":2597,"refs":[],"alt":null,"prompt_text":null,"type":"grouped_webpages","items":[],"status":"done","error":null,"style":"v2"},{"matched_text":" ","start_idx":2597,"end_idx":2597,"refs":[],"alt":"","prompt_text":null,"type":"sources_footnote","sources":[{"title":"Denoising with a Joint-Embedding Predictive Architecture","url":"https://arxiv.org/abs/2410.03755?utm_source=chatgpt.com","attribution":"arXiv"},{"title":"Can someone explain to me in a laymen-ish terms why is I-JEPA ...","url":"https://www.reddit.com/r/learnmachinelearning/comments/1gya9pm/can_someone_explain_to_me_in_a_laymenish_terms/?utm_source=chatgpt.com","attribution":"Reddit"},{"title":"Yann LeCun - X","url":"https://x.com/ylecun/status/1806610020974362819?utm_source=chatgpt.com","attribution":"X (formerly Twitter)"}],"has_images":false}],"citations":[{"start_ix":0,"end_ix":1,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":199,"end_ix":200,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":201,"end_ix":202,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":339,"end_ix":340,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":340,"end_ix":341,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":406,"end_ix":407,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":602,"end_ix":603,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":604,"end_ix":605,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":810,"end_ix":811,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":811,"end_ix":812,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":870,"end_ix":871,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":976,"end_ix":977,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":977,"end_ix":978,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1054,"end_ix":1055,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1177,"end_ix":1178,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1179,"end_ix":1180,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1315,"end_ix":1316,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1317,"end_ix":1318,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1514,"end_ix":1515,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1516,"end_ix":1538,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1538,"end_ix":1539,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1620,"end_ix":1621,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1733,"end_ix":1734,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1735,"end_ix":1736,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1937,"end_ix":1938,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1939,"end_ix":1961,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1961,"end_ix":1962,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":2000,"end_ix":2001,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":2098,"end_ix":2099,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":2100,"end_ix":2101,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":2156,"end_ix":2157,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":2158,"end_ix":2159,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":2280,"end_ix":2281,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":2282,"end_ix":2301,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":2301,"end_ix":2302,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":2320,"end_ix":2321,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":2595,"end_ix":2596,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":2596,"end_ix":2597,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":2597,"end_ix":2597,"invalid_reason":"Unsupported, please upgrade"}],"request_id":"9290bbaffeacfdea-IAD","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"b4de8354-a5f8-41b0-8818-69e3aaae5787","children":["828cd49b-70cc-46d5-98e5-5208b70eabdf"]},"828cd49b-70cc-46d5-98e5-5208b70eabdf":{"id":"828cd49b-70cc-46d5-98e5-5208b70eabdf","message":{"id":"828cd49b-70cc-46d5-98e5-5208b70eabdf","author":{"role":"user","name":null,"metadata":{}},"create_time":1743433529.765,"update_time":null,"content":{"content_type":"text","parts":["Explain D-JEPA\u00b7T2I in more detail"]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"system_hints":["search"],"serialization_metadata":{"custom_symbol_offsets":[]},"dictation":false,"request_id":"9290bec91e62a1b3-ATL","message_source":null,"timestamp_":"absolute","message_type":null,"can_save":true},"recipient":"all","channel":null},"parent":"4dd37814-7c6c-4ae3-a6c8-e6381533e23c","children":["92dafcc7-2e2e-47a4-ba98-af8a677ba1f8"]},"92dafcc7-2e2e-47a4-ba98-af8a677ba1f8":{"id":"92dafcc7-2e2e-47a4-ba98-af8a677ba1f8","message":{"id":"92dafcc7-2e2e-47a4-ba98-af8a677ba1f8","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1743433530.2307053,"update_time":null,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"search(\"Explain D-JEPA\\u00b7T2I in more detail\")"},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"citations":[],"content_references":[],"message_type":null,"model_slug":"gpt-4-5","default_model_slug":"gpt-4-5","parent_id":"828cd49b-70cc-46d5-98e5-5208b70eabdf","request_id":"9290bec91e62a1b3-ATL","timestamp_":"absolute","can_save":true},"recipient":"web","channel":null},"parent":"828cd49b-70cc-46d5-98e5-5208b70eabdf","children":["1fb5ff7e-01ee-4bde-baa5-a235396991a6"]},"1fb5ff7e-01ee-4bde-baa5-a235396991a6":{"id":"1fb5ff7e-01ee-4bde-baa5-a235396991a6","message":{"id":"1fb5ff7e-01ee-4bde-baa5-a235396991a6","author":{"role":"tool","name":"web","metadata":{}},"create_time":1743433530.3417702,"update_time":null,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":""},"status":"finished_successfully","end_turn":null,"weight":0.0,"metadata":{"is_visually_hidden_from_conversation":true,"command":"search","status":"finished","is_complete":true,"message_type":null,"model_slug":"gpt-4-5","default_model_slug":"gpt-4-5","parent_id":"92dafcc7-2e2e-47a4-ba98-af8a677ba1f8","request_id":"9290bec91e62a1b3-ATL","timestamp_":"absolute","can_save":false},"recipient":"assistant","channel":null},"parent":"92dafcc7-2e2e-47a4-ba98-af8a677ba1f8","children":["a5241cd7-c56d-449c-93c2-3ebfd7d52fa3"]},"a5241cd7-c56d-449c-93c2-3ebfd7d52fa3":{"id":"a5241cd7-c56d-449c-93c2-3ebfd7d52fa3","message":{"id":"a5241cd7-c56d-449c-93c2-3ebfd7d52fa3","author":{"role":"assistant","name":null,"metadata":{"real_author":"tool:web"}},"create_time":1743433530.3423274,"update_time":null,"content":{"content_type":"text","parts":["\ue203**D-JEPA\u00b7T2I** is an advanced autoregressive model designed for high-resolution text-to-image synthesis, extending the foundational **Denoising Joint Embedding Predictive Architecture (D-JEPA)** to generate photorealistic images up to 4K resolution.\ue204 \ue200cite\ue202turn0search2\ue201\ue206\n\n**Key Innovations of D-JEPA\u00b7T2I:**\n\n1. **Multimodal Visual Transformer:**\n   - \ue203Integrates textual and visual features effectively, enhancing the model's ability to understand and generate complex image-text relationships.\ue204 \ue200cite\ue202turn0search2\ue201\ue206\n\n2. **Flow Matching Loss:**\n   - \ue203Incorporates flow matching loss to enable data-efficient continuous resolution learning, facilitating the generation of images at arbitrary resolutions.\ue204 \ue200cite\ue202turn0search2\ue201\ue206\n\n3. **Visual Rotary Positional Embedding (VoPE):**\n   - \ue203Introduces VoPE to support continuous resolution learning, allowing the model to handle varying image sizes and aspect ratios seamlessly.\ue204 \ue200cite\ue202turn0search2\ue201\ue206\n\n4. **Data Feedback Mechanism:**\n   - \ue203Implements a dynamic data feedback system that adjusts the sampling procedure based on statistical analysis and an online learning critic model, improving training efficiency and image quality.\ue204 \ue200cite\ue202turn0search2\ue201\ue206\n\n**Performance and Impact:**\n\n\ue203D-JEPA\u00b7T2I achieves state-of-the-art results in high-resolution image synthesis through next-token prediction, demonstrating its capability to generate detailed and high-fidelity images across various resolutions and aspect ratios.\ue204 \ue203This advancement underscores the potential of integrating JEPA with autoregressive techniques in generative modeling.\ue204 \ue200cite\ue202turn0search2\ue201\ue206\n\n\ue203For more detailed information and access to the model's resources, you can refer to the official GitHub repository.\ue204 \ue200cite\ue202turn0search0\ue201\ue206 "]},"status":"finished_successfully","end_turn":true,"weight":1.0,"metadata":{"search_source":"composer_search","client_reported_search_source":"conversation_composer_previous_web_mode","debug_sonic_thread_id":"thread_67eaaf3a4c608007871832da9cb08d9c","search_result_groups":[{"type":"search_result_group","domain":"github.com","entries":[{"type":"search_result","url":"https://github.com/D-JEPA/T2I","title":"High-Resolution Image Synthesis via Next-Token Prediction. - GitHub","snippet":"D-JEPA\u00b7T2I leverages a multimodal visual transformer to effectively integrate textual and visual features and adopts Visual Rotary Positional Embedding (VoPE) ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":0},"content_type":null,"pub_date":null,"attributions":null,"attribution":"GitHub"},{"type":"search_result","url":"https://github.com/D-JEPA","title":"D-JEPA - GitHub","snippet":"D-JEPA has 8 repositories available. Follow their code on GitHub.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":6},"content_type":null,"pub_date":null,"attributions":null,"attribution":"GitHub"}]},{"type":"search_result_group","domain":"openreview.net","entries":[{"type":"search_result","url":"https://openreview.net/forum?id=d4njmzM7jf","title":"Denoising with a Joint-Embedding Predictive Architecture","snippet":"In this paper, we introduce Denoising with a Joint-Embedding Predictive Architecture (D-JEPA), pioneering the integration of JEPA within generative modeling.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":1},"content_type":null,"pub_date":null,"attributions":null,"attribution":"OpenReview"}]},{"type":"search_result_group","domain":"arxiv.org","entries":[{"type":"search_result","url":"https://arxiv.org/abs/2411.14808","title":"High-Resolution Image Synthesis via Next-Token Prediction - arXiv","snippet":"In this paper, we introduce \\textbf{D-JEPA\\cdotT2I}, an autoregressive model based on continuous tokens that incorporates innovations in ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":2},"content_type":null,"pub_date":1732233600.0,"attributions":null,"attribution":"arXiv"},{"type":"search_result","url":"https://arxiv.org/html/2411.14808v2","title":"High-Resolution Image Synthesis via Next-Token Prediction - arXiv","snippet":"In this paper, we introduce D-JEPA \u22c5 \u22c5 \\cdot \u22c5 T2I, an autoregressive model based on continuous tokens that incorporates innovations in both architecture and ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":3},"content_type":null,"pub_date":1740873600.0,"attributions":null,"attribution":"arXiv"}]},{"type":"search_result_group","domain":"harvard.edu","entries":[{"type":"search_result","url":"https://ui.adsabs.harvard.edu/abs/2024arXiv241114808C/abstract","title":"High-Resolution Image Synthesis via Next-Token Prediction","snippet":"In this paper, we introduce D-JEPA$\\cdot$T2I, an extension of D-JEPA incorporating flow matching loss, designed to enable data-efficient continuous resolution ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":4},"content_type":null,"pub_date":null,"attributions":null,"attribution":"Astrophysics Data System"}]},{"type":"search_result_group","domain":"densechen.github.io","entries":[{"type":"search_result","url":"https://densechen.github.io/","title":"Dengsheng Chen (\u9648\u767b\u76db) | Meituan","snippet":"Empirically, with increased GFLOPs, D-JEPA consistently achieves lower FID scores with fewer training epochs, indicating its good scalability.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":5},"content_type":null,"pub_date":1734825600.0,"attributions":null,"attribution":"densechen.github.io"}]},{"type":"search_result_group","domain":"themoonlight.io","entries":[{"type":"search_result","url":"https://www.themoonlight.io/fr/review/high-resolution-image-synthesis-via-next-token-prediction","title":"[Revue de papier] High-Resolution Image Synthesis via Next-Token ...","snippet":"The D-JEPA\u00b7T2I model capitalizes on an autoregressive prediction framework, denoting a sequential processing of image tokens. The sampling takes ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":7},"content_type":null,"pub_date":1741564800.0,"attributions":null,"attribution":"Moonlight"}]},{"type":"search_result_group","domain":"researchgate.net","entries":[{"type":"search_result","url":"https://www.researchgate.net/publication/386093859_High-Resolution_Image_Synthesis_via_Next-Token_Prediction","title":"High-Resolution Image Synthesis via Next-Token Prediction","snippet":"D-JEPA \u22c5 \\cdot T2I leverages a multimodal visual transformer to effectively integrate textual and visual features and adopts Visual Rotary ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":8},"content_type":null,"pub_date":1732233600.0,"attributions":null,"attribution":"ResearchGate"}]},{"type":"search_result_group","domain":"aimodels.fyi","entries":[{"type":"search_result","url":"https://www.aimodels.fyi/papers/arxiv/ti-jepa-innovative-energy-based-joint-embedding","title":"TI-JEPA: An Innovative Energy-based Joint Embedding Strategy for ...","snippet":"In this paper, we introduce D-JEPA$cdot$T2I, an extension of D-JEPA incorporating flow matching loss, designed to enable data-efficient ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":9},"content_type":null,"pub_date":1741564800.0,"attributions":null,"attribution":"AI Models"}]}],"safe_urls":["https://arxiv.org/abs/2411.14808?utm_source=chatgpt.com","https://github.com/D-JEPA/T2I?utm_source=chatgpt.com"],"message_type":null,"model_slug":"gpt-4-5","default_model_slug":"gpt-4-5","parent_id":"1fb5ff7e-01ee-4bde-baa5-a235396991a6","message_locale":"en-US","image_results":[],"content_references":[{"matched_text":"\ue203","start_idx":0,"end_idx":1,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"**D-JEPA\u00b7T2I** is an advanced autoregressive model designed for high-resolution text-to-image synthesis, extending the foundational **Denoising Joint Embedding Predictive Architecture (D-JEPA)** to generate photorealistic images up to 4K resolution.","start_idx":1,"end_idx":250,"safe_urls":[],"refs":[],"alt":"**D-JEPA\u00b7T2I** is an advanced autoregressive model designed for high-resolution text-to-image synthesis, extending the foundational **Denoising Joint Embedding Predictive Architecture (D-JEPA)** to generate photorealistic images up to 4K resolution.","prompt_text":null,"type":"attribution","attributable_index":"0-0","attributions":null,"attributions_debug":null},{"matched_text":"\ue204","start_idx":250,"end_idx":251,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"\ue200cite\ue202turn0search2\ue201","start_idx":252,"end_idx":271,"refs":[],"alt":"","prompt_text":"([arxiv.org](https://arxiv.org/abs/2411.14808?utm_source=chatgpt.com))","type":"grouped_webpages_model_predicted_fallback","items":[{"title":"High-Resolution Image Synthesis via Next-Token Prediction","url":"https://arxiv.org/abs/2411.14808?utm_source=chatgpt.com","pub_date":1732266538.0,"snippet":"","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":2}],"hue":null,"attributions":null}],"status":"done","error":null,"style":null},{"matched_text":"\ue206","start_idx":271,"end_idx":272,"refs":[],"alt":null,"prompt_text":null,"type":"grouped_webpages","items":[{"title":"High-Resolution Image Synthesis via Next-Token Prediction - arXiv","url":"https://arxiv.org/html/2411.14808v2?utm_source=chatgpt.com","pub_date":1740873600.0,"snippet":"In this paper, we introduce D-JEPA \u22c5 \u22c5 \\cdot \u22c5 T2I, an autoregressive model based on continuous tokens that incorporates innovations in both architecture and ...","attribution_segments":["0-0"],"supporting_websites":[{"title":"Dengsheng Chen (\u9648\u767b\u76db) | Meituan","url":"https://densechen.github.io/?utm_source=chatgpt.com","pub_date":1734825600.0,"snippet":"Empirically, with increased GFLOPs, D-JEPA consistently achieves lower FID scores with fewer training epochs, indicating its good scalability.","attribution":"densechen.github.io"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":3},{"turn_index":0,"ref_type":"search","ref_index":5}],"hue":null,"attributions":null,"attribution":"arXiv"}],"status":"done","error":null,"style":"v2"},{"matched_text":"\ue203","start_idx":353,"end_idx":354,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"Integrates textual and visual features effectively, enhancing the model's ability to understand and generate complex image-text relationships.","start_idx":354,"end_idx":496,"safe_urls":[],"refs":[],"alt":"Integrates textual and visual features effectively, enhancing the model's ability to understand and generate complex image-text relationships.","prompt_text":null,"type":"attribution","attributable_index":"272-2","attributions":null,"attributions_debug":null},{"matched_text":"\ue204","start_idx":496,"end_idx":497,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"\ue200cite\ue202turn0search2\ue201","start_idx":498,"end_idx":517,"refs":[],"alt":"","prompt_text":"([arxiv.org](https://arxiv.org/abs/2411.14808?utm_source=chatgpt.com))","type":"grouped_webpages_model_predicted_fallback","items":[{"title":"High-Resolution Image Synthesis via Next-Token Prediction","url":"https://arxiv.org/abs/2411.14808?utm_source=chatgpt.com","pub_date":1732266538.0,"snippet":"","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":2}],"hue":null,"attributions":null}],"status":"done","error":null,"style":null},{"matched_text":"\ue206","start_idx":517,"end_idx":518,"refs":[],"alt":null,"prompt_text":null,"type":"grouped_webpages","items":[],"status":"done","error":null,"style":"v2"},{"matched_text":"\ue203","start_idx":552,"end_idx":553,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"Incorporates flow matching loss to enable data-efficient continuous resolution learning, facilitating the generation of images at arbitrary resolutions.","start_idx":553,"end_idx":705,"safe_urls":[],"refs":[],"alt":"Incorporates flow matching loss to enable data-efficient continuous resolution learning, facilitating the generation of images at arbitrary resolutions.","prompt_text":null,"type":"attribution","attributable_index":"518-1","attributions":null,"attributions_debug":null},{"matched_text":"\ue204","start_idx":705,"end_idx":706,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"\ue200cite\ue202turn0search2\ue201","start_idx":707,"end_idx":726,"refs":[],"alt":"","prompt_text":"([arxiv.org](https://arxiv.org/abs/2411.14808?utm_source=chatgpt.com))","type":"grouped_webpages_model_predicted_fallback","items":[{"title":"High-Resolution Image Synthesis via Next-Token Prediction","url":"https://arxiv.org/abs/2411.14808?utm_source=chatgpt.com","pub_date":1732266538.0,"snippet":"","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":2}],"hue":null,"attributions":null}],"status":"done","error":null,"style":null},{"matched_text":"\ue206","start_idx":726,"end_idx":727,"refs":[],"alt":null,"prompt_text":null,"type":"grouped_webpages","items":[{"title":"High-Resolution Image Synthesis via Next-Token Prediction","url":"https://ui.adsabs.harvard.edu/abs/2024arXiv241114808C/abstract?utm_source=chatgpt.com","pub_date":null,"snippet":"In this paper, we introduce D-JEPA$\\cdot$T2I, an extension of D-JEPA incorporating flow matching loss, designed to enable data-efficient continuous resolution ...","attribution_segments":["518-1"],"supporting_websites":[{"title":"High-Resolution Image Synthesis via Next-Token Prediction - arXiv","url":"https://arxiv.org/html/2411.14808v2?utm_source=chatgpt.com","pub_date":1740873600.0,"snippet":"In this paper, we introduce D-JEPA \u22c5 \u22c5 \\cdot \u22c5 T2I, an autoregressive model based on continuous tokens that incorporates innovations in both architecture and ...","attribution":"arXiv"},{"title":"High-Resolution Image Synthesis via Next-Token Prediction","url":"https://arxiv.org/abs/2411.14808?utm_source=chatgpt.com","pub_date":1732266538.0,"snippet":"Denoising with a Joint-Embedding Predictive Architecture (D-JEPA), an autoregressive model, has demonstrated outstanding performance in class-conditional image generation. However, the application of...","attribution":"arXiv"},{"title":"High-Resolution Image Synthesis via Next-Token Prediction. - GitHub","url":"https://github.com/D-JEPA/T2I?utm_source=chatgpt.com","pub_date":null,"snippet":"D-JEPA\u00b7T2I leverages a multimodal visual transformer to effectively integrate textual and visual features and adopts Visual Rotary Positional Embedding (VoPE) ...","attribution":"GitHub"},{"title":"Dengsheng Chen (\u9648\u767b\u76db) | Meituan","url":"https://densechen.github.io/?utm_source=chatgpt.com","pub_date":1734825600.0,"snippet":"Empirically, with increased GFLOPs, D-JEPA consistently achieves lower FID scores with fewer training epochs, indicating its good scalability.","attribution":"densechen.github.io"},{"title":"TI-JEPA: An Innovative Energy-based Joint Embedding Strategy for ...","url":"https://www.aimodels.fyi/papers/arxiv/ti-jepa-innovative-energy-based-joint-embedding?utm_source=chatgpt.com","pub_date":1741564800.0,"snippet":"In this paper, we introduce D-JEPA$cdot$T2I, an extension of D-JEPA incorporating flow matching loss, designed to enable data-efficient ...","attribution":"AI Models"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":4},{"turn_index":0,"ref_type":"search","ref_index":3},{"turn_index":0,"ref_type":"search","ref_index":2},{"turn_index":0,"ref_type":"search","ref_index":0},{"turn_index":0,"ref_type":"search","ref_index":5},{"turn_index":0,"ref_type":"search","ref_index":9}],"hue":null,"attributions":null,"attribution":"Astrophysics Data System"}],"status":"done","error":null,"style":"v2"},{"matched_text":"\ue203","start_idx":784,"end_idx":785,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"Introduces VoPE to support continuous resolution learning, allowing the model to handle varying image sizes and aspect ratios seamlessly.","start_idx":785,"end_idx":922,"safe_urls":[],"refs":[],"alt":"Introduces VoPE to support continuous resolution learning, allowing the model to handle varying image sizes and aspect ratios seamlessly.","prompt_text":null,"type":"attribution","attributable_index":"727-1","attributions":null,"attributions_debug":null},{"matched_text":"\ue204","start_idx":922,"end_idx":923,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"\ue200cite\ue202turn0search2\ue201","start_idx":924,"end_idx":943,"refs":[],"alt":"","prompt_text":"([arxiv.org](https://arxiv.org/abs/2411.14808?utm_source=chatgpt.com))","type":"grouped_webpages_model_predicted_fallback","items":[{"title":"High-Resolution Image Synthesis via Next-Token Prediction","url":"https://arxiv.org/abs/2411.14808?utm_source=chatgpt.com","pub_date":1732266538.0,"snippet":"","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":2}],"hue":null,"attributions":null}],"status":"done","error":null,"style":null},{"matched_text":"\ue206","start_idx":943,"end_idx":944,"refs":[],"alt":null,"prompt_text":null,"type":"grouped_webpages","items":[{"title":"High-Resolution Image Synthesis via Next-Token Prediction - arXiv","url":"https://arxiv.org/html/2411.14808v2?utm_source=chatgpt.com","pub_date":1740873600.0,"snippet":"In this paper, we introduce D-JEPA \u22c5 \u22c5 \\cdot \u22c5 T2I, an autoregressive model based on continuous tokens that incorporates innovations in both architecture and ...","attribution_segments":["727-1"],"supporting_websites":[{"title":"Dengsheng Chen (\u9648\u767b\u76db) | Meituan","url":"https://densechen.github.io/?utm_source=chatgpt.com","pub_date":1734825600.0,"snippet":"Empirically, with increased GFLOPs, D-JEPA consistently achieves lower FID scores with fewer training epochs, indicating its good scalability.","attribution":"densechen.github.io"},{"title":"High-Resolution Image Synthesis via Next-Token Prediction. - GitHub","url":"https://github.com/D-JEPA/T2I?utm_source=chatgpt.com","pub_date":null,"snippet":"D-JEPA\u00b7T2I leverages a multimodal visual transformer to effectively integrate textual and visual features and adopts Visual Rotary Positional Embedding (VoPE) ...","attribution":"GitHub"},{"title":"High-Resolution Image Synthesis via Next-Token Prediction","url":"https://arxiv.org/abs/2411.14808?utm_source=chatgpt.com","pub_date":1732266538.0,"snippet":"Denoising with a Joint-Embedding Predictive Architecture (D-JEPA), an autoregressive model, has demonstrated outstanding performance in class-conditional image generation. However, the application of...","attribution":"arXiv"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":3},{"turn_index":0,"ref_type":"search","ref_index":5},{"turn_index":0,"ref_type":"search","ref_index":0},{"turn_index":0,"ref_type":"search","ref_index":2}],"hue":null,"attributions":null,"attribution":"arXiv"}],"status":"done","error":null,"style":"v2"},{"matched_text":"\ue203","start_idx":983,"end_idx":984,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"Implements a dynamic data feedback system that adjusts the sampling procedure based on statistical analysis and an online learning critic model, improving training efficiency and image quality.","start_idx":984,"end_idx":1177,"safe_urls":[],"refs":[],"alt":"Implements a dynamic data feedback system that adjusts the sampling procedure based on statistical analysis and an online learning critic model, improving training efficiency and image quality.","prompt_text":null,"type":"attribution","attributable_index":"944-1","attributions":null,"attributions_debug":null},{"matched_text":"\ue204","start_idx":1177,"end_idx":1178,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"\ue200cite\ue202turn0search2\ue201","start_idx":1179,"end_idx":1198,"refs":[],"alt":"","prompt_text":"([arxiv.org](https://arxiv.org/abs/2411.14808?utm_source=chatgpt.com))","type":"grouped_webpages_model_predicted_fallback","items":[{"title":"High-Resolution Image Synthesis via Next-Token Prediction","url":"https://arxiv.org/abs/2411.14808?utm_source=chatgpt.com","pub_date":1732266538.0,"snippet":"","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":2}],"hue":null,"attributions":null}],"status":"done","error":null,"style":null},{"matched_text":"\ue206","start_idx":1198,"end_idx":1199,"refs":[],"alt":null,"prompt_text":null,"type":"grouped_webpages","items":[{"title":"High-Resolution Image Synthesis via Next-Token Prediction - arXiv","url":"https://arxiv.org/html/2411.14808v2?utm_source=chatgpt.com","pub_date":1740873600.0,"snippet":"In this paper, we introduce D-JEPA \u22c5 \u22c5 \\cdot \u22c5 T2I, an autoregressive model based on continuous tokens that incorporates innovations in both architecture and ...","attribution_segments":["944-1"],"supporting_websites":[{"title":"Dengsheng Chen (\u9648\u767b\u76db) | Meituan","url":"https://densechen.github.io/?utm_source=chatgpt.com","pub_date":1734825600.0,"snippet":"Empirically, with increased GFLOPs, D-JEPA consistently achieves lower FID scores with fewer training epochs, indicating its good scalability.","attribution":"densechen.github.io"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":3},{"turn_index":0,"ref_type":"search","ref_index":5}],"hue":null,"attributions":null,"attribution":"arXiv"}],"status":"done","error":null,"style":"v2"},{"matched_text":"\ue203","start_idx":1230,"end_idx":1231,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"D-JEPA\u00b7T2I achieves state-of-the-art results in high-resolution image synthesis through next-token prediction, demonstrating its capability to generate detailed and high-fidelity images across various resolutions and aspect ratios.","start_idx":1231,"end_idx":1462,"safe_urls":[],"refs":[],"alt":"D-JEPA\u00b7T2I achieves state-of-the-art results in high-resolution image synthesis through next-token prediction, demonstrating its capability to generate detailed and high-fidelity images across various resolutions and aspect ratios.","prompt_text":null,"type":"attribution","attributable_index":"1199-1","attributions":null,"attributions_debug":null},{"matched_text":"\ue204","start_idx":1462,"end_idx":1463,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"\ue203","start_idx":1464,"end_idx":1465,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"This advancement underscores the potential of integrating JEPA with autoregressive techniques in generative modeling.","start_idx":1465,"end_idx":1582,"safe_urls":[],"refs":[],"alt":"This advancement underscores the potential of integrating JEPA with autoregressive techniques in generative modeling.","prompt_text":null,"type":"attribution","attributable_index":"1199-2","attributions":null,"attributions_debug":null},{"matched_text":"\ue204","start_idx":1582,"end_idx":1583,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"\ue200cite\ue202turn0search2\ue201","start_idx":1584,"end_idx":1603,"refs":[],"alt":"","prompt_text":"([arxiv.org](https://arxiv.org/abs/2411.14808?utm_source=chatgpt.com))","type":"grouped_webpages_model_predicted_fallback","items":[{"title":"High-Resolution Image Synthesis via Next-Token Prediction","url":"https://arxiv.org/abs/2411.14808?utm_source=chatgpt.com","pub_date":1732266538.0,"snippet":"","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":2}],"hue":null,"attributions":null}],"status":"done","error":null,"style":null},{"matched_text":"\ue206","start_idx":1603,"end_idx":1604,"refs":[],"alt":null,"prompt_text":null,"type":"grouped_webpages","items":[{"title":"High-Resolution Image Synthesis via Next-Token Prediction - arXiv","url":"https://arxiv.org/html/2411.14808v2?utm_source=chatgpt.com","pub_date":1740873600.0,"snippet":"In this paper, we introduce D-JEPA \u22c5 \u22c5 \\cdot \u22c5 T2I, an autoregressive model based on continuous tokens that incorporates innovations in both architecture and ...","attribution_segments":["1199-1"],"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":3}],"hue":null,"attributions":null,"attribution":"arXiv"}],"status":"done","error":null,"style":"v2"},{"matched_text":"\ue203","start_idx":1606,"end_idx":1607,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"For more detailed information and access to the model's resources, you can refer to the official GitHub repository.","start_idx":1607,"end_idx":1722,"safe_urls":[],"refs":[],"alt":"For more detailed information and access to the model's resources, you can refer to the official GitHub repository.","prompt_text":null,"type":"attribution","attributable_index":"1604-0","attributions":null,"attributions_debug":null},{"matched_text":"\ue204","start_idx":1722,"end_idx":1723,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"\ue200cite\ue202turn0search0\ue201","start_idx":1724,"end_idx":1743,"refs":[],"alt":"","prompt_text":"([github.com](https://github.com/D-JEPA/T2I?utm_source=chatgpt.com))","type":"grouped_webpages_model_predicted_fallback","items":[{"title":"High-Resolution Image Synthesis via Next-Token Prediction. - GitHub","url":"https://github.com/D-JEPA/T2I?utm_source=chatgpt.com","pub_date":null,"snippet":"D-JEPA\u00b7T2I leverages a multimodal visual transformer to effectively integrate textual and visual features and adopts Visual Rotary Positional Embedding (VoPE) ...","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":0}],"hue":null,"attributions":null}],"status":"done","error":null,"style":null},{"matched_text":"\ue206","start_idx":1743,"end_idx":1744,"refs":[],"alt":null,"prompt_text":null,"type":"grouped_webpages","items":[{"title":"High-Resolution Image Synthesis via Next-Token Prediction. - GitHub","url":"https://github.com/D-JEPA/T2I?utm_source=chatgpt.com","pub_date":null,"snippet":"D-JEPA\u00b7T2I leverages a multimodal visual transformer to effectively integrate textual and visual features and adopts Visual Rotary Positional Embedding (VoPE) ...","attribution_segments":["1604-0"],"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":0}],"hue":null,"attributions":null,"attribution":"GitHub"}],"status":"done","error":null,"style":"v2"},{"matched_text":" ","start_idx":1744,"end_idx":1744,"refs":[],"alt":"","prompt_text":null,"type":"sources_footnote","sources":[{"title":"High-Resolution Image Synthesis via Next-Token Prediction","url":"https://arxiv.org/abs/2411.14808?utm_source=chatgpt.com","attribution":"arXiv"},{"title":"High-Resolution Image Synthesis via Next-Token Prediction","url":"https://ui.adsabs.harvard.edu/abs/2024arXiv241114808C/abstract?utm_source=chatgpt.com","attribution":"Astrophysics Data System"},{"title":"High-Resolution Image Synthesis via Next-Token Prediction. - GitHub","url":"https://github.com/D-JEPA/T2I?utm_source=chatgpt.com","attribution":"GitHub"}],"has_images":false}],"citations":[{"start_ix":0,"end_ix":1,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":250,"end_ix":251,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":252,"end_ix":271,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":271,"end_ix":272,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":353,"end_ix":354,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":496,"end_ix":497,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":498,"end_ix":517,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":517,"end_ix":518,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":552,"end_ix":553,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":705,"end_ix":706,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":707,"end_ix":726,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":726,"end_ix":727,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":784,"end_ix":785,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":922,"end_ix":923,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":924,"end_ix":943,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":943,"end_ix":944,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":983,"end_ix":984,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1177,"end_ix":1178,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1179,"end_ix":1198,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1198,"end_ix":1199,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1230,"end_ix":1231,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1462,"end_ix":1463,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1464,"end_ix":1465,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1582,"end_ix":1583,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1584,"end_ix":1603,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1603,"end_ix":1604,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1606,"end_ix":1607,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1722,"end_ix":1723,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1724,"end_ix":1743,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1743,"end_ix":1744,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1744,"end_ix":1744,"invalid_reason":"Unsupported, please upgrade"}],"request_id":"9290bec91e62a1b3-ATL","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"1fb5ff7e-01ee-4bde-baa5-a235396991a6","children":["89c39373-4424-42b2-9ce1-768a05172192"]},"89c39373-4424-42b2-9ce1-768a05172192":{"id":"89c39373-4424-42b2-9ce1-768a05172192","message":{"id":"89c39373-4424-42b2-9ce1-768a05172192","author":{"role":"user","name":null,"metadata":{}},"create_time":1743434704.165,"update_time":null,"content":{"content_type":"text","parts":["Besides JEPA, are there other similar architectures or solutions?"]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"system_hints":["search"],"serialization_metadata":{"custom_symbol_offsets":[]},"dictation":false,"request_id":"9290db751874fe90-SIN","message_source":null,"timestamp_":"absolute","message_type":null,"can_save":true},"recipient":"all","channel":null},"parent":"a5241cd7-c56d-449c-93c2-3ebfd7d52fa3","children":["01d9b319-931a-4020-8431-5999572798e5"]},"01d9b319-931a-4020-8431-5999572798e5":{"id":"01d9b319-931a-4020-8431-5999572798e5","message":{"id":"01d9b319-931a-4020-8431-5999572798e5","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1743434704.7948413,"update_time":null,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"search(\"Besides JEPA, are there other similar architectures or solutions?\")"},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"citations":[],"content_references":[],"message_type":null,"model_slug":"gpt-4-5","default_model_slug":"gpt-4-5","parent_id":"89c39373-4424-42b2-9ce1-768a05172192","request_id":"9290db751874fe90-SIN","timestamp_":"absolute","can_save":true},"recipient":"web","channel":null},"parent":"89c39373-4424-42b2-9ce1-768a05172192","children":["375ed9fc-98d9-4349-884f-ec2ba3216055"]},"375ed9fc-98d9-4349-884f-ec2ba3216055":{"id":"375ed9fc-98d9-4349-884f-ec2ba3216055","message":{"id":"375ed9fc-98d9-4349-884f-ec2ba3216055","author":{"role":"tool","name":"web","metadata":{}},"create_time":1743434704.9181633,"update_time":null,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":""},"status":"finished_successfully","end_turn":null,"weight":0.0,"metadata":{"is_visually_hidden_from_conversation":true,"command":"search","status":"finished","is_complete":true,"message_type":null,"model_slug":"gpt-4-5","default_model_slug":"gpt-4-5","parent_id":"01d9b319-931a-4020-8431-5999572798e5","request_id":"9290db751874fe90-SIN","timestamp_":"absolute","can_save":false},"recipient":"assistant","channel":null},"parent":"01d9b319-931a-4020-8431-5999572798e5","children":["13606949-2d16-48f3-a73c-342a2dbde74e"]},"13606949-2d16-48f3-a73c-342a2dbde74e":{"id":"13606949-2d16-48f3-a73c-342a2dbde74e","message":{"id":"13606949-2d16-48f3-a73c-342a2dbde74e","author":{"role":"assistant","name":null,"metadata":{"real_author":"tool:web"}},"create_time":1743434704.918681,"update_time":null,"content":{"content_type":"text","parts":["\ue203The **Joint Embedding Predictive Architecture (JEPA)** has inspired a range of self-supervised learning models across various data modalities.\ue204 Notable architectures and solutions similar to JEPA include:\ue206\n\n**1. Image-based Joint-Embedding Predictive Architecture (I-JEPA):**\n\ue203I-JEPA focuses on image data, predicting representations of target image blocks based on a single context block.\ue204 \ue203This approach emphasizes semantic content over pixel-level details, enhancing scalability and performance in tasks like object counting and depth prediction.\ue204 \ue200cite\ue202turn0search3\ue201\ue206\n\n**2. CNN-JEPA:**\n\ue203Tailored for Convolutional Neural Networks (CNNs), CNN-JEPA adapts JEPA principles by incorporating a sparse CNN encoder and a fully convolutional predictor.\ue204 \ue203It employs an improved masking strategy, demonstrating superior performance on datasets like ImageNet-100 compared to traditional CNN-based self-supervised methods.\ue204 \ue200cite\ue202turn0search2\ue201\ue206\n\n**3. Video-JEPA (V-JEPA):**\n\ue203Extending JEPA to video data, V-JEPA predicts representations of future video frames based on past contexts.\ue204 \ue203This model effectively captures temporal dynamics, advancing self-supervised learning in video analysis.\ue204 \ue200cite\ue202turn0search4\ue201\ue206\n\n**4. Contrastive-JEPA (C-JEPA):**\n\ue203C-JEPA integrates JEPA with contrastive self-supervised learning techniques, incorporating Variance-Invariance-Covariance Regularization (VICReg).\ue204 \ue203This fusion enhances stability and representation quality in visual learning tasks.\ue204 \ue200cite\ue202turn0search8\ue201\ue206\n\n**5. T-JEPA:**\n\ue203Designed for tabular data, T-JEPA employs a JEPA framework without requiring data augmentations.\ue204 \ue203It predicts latent representations of feature subsets within the same sample, improving performance in classification and regression tasks on structured data.\ue204 \ue200cite\ue202turn0academia10\ue201\ue206\n\n**6. MC-JEPA:**\n\ue203MC-JEPA combines JEPA with motion and content feature learning, jointly learning optical flow and content features within a shared encoder.\ue204 \ue203This approach benefits tasks like semantic segmentation of images and videos.\ue204 \ue200cite\ue202turn0academia11\ue201\ue206\n\n**7. AD-L-JEPA:**\n\ue203Focused on autonomous driving applications, AD-L-JEPA applies JEPA to LiDAR data, learning spatial world models through self-supervised pre-training.\ue204 \ue203It enhances performance in downstream tasks such as 3D object detection.\ue204 \ue200cite\ue202turn0academia12\ue201\ue206\n\n\ue203These architectures demonstrate the adaptability of JEPA's principles across diverse data types and tasks, highlighting its influence in the evolution of self-supervised learning methodologies.\ue204\ue206 "]},"status":"finished_successfully","end_turn":true,"weight":1.0,"metadata":{"search_source":"composer_search","client_reported_search_source":"conversation_composer_previous_web_mode","debug_sonic_thread_id":"thread_67eab3d0da3880079eb8409309e795c8","search_result_groups":[{"type":"search_result_group","domain":"linkedin.com","entries":[{"type":"search_result","url":"https://www.linkedin.com/pulse/deep-dive-jepa-similar-architectures-anshuman-jha-2lrxc","title":"Deep Dive into JEPA and Similar Architectures - LinkedIn","snippet":"JEPA represents a paradigm shift in self\u2011supervised learning. Instead of reconstructing pixel\u2011level details as conventional generative ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":0},"content_type":null,"pub_date":1742688000.0,"attributions":null,"attribution":"LinkedIn"}]},{"type":"search_result_group","domain":"medium.com","entries":[{"type":"search_result","url":"https://artgor.medium.com/paper-review-self-supervised-learning-from-images-with-a-joint-embedding-predictive-architecture-6e5608e543e8","title":"Paper Review: Self-Supervised Learning from Images with a Joint ...","snippet":"This paper presents a new methodology for self-supervised learning from images \u2014 Image-based Joint-Embedding Predictive Architecture (I-JEPA).","ref_id":{"turn_index":0,"ref_type":"search","ref_index":1},"content_type":null,"pub_date":1686700800.0,"attributions":null,"attribution":"Medium"},{"type":"search_result","url":"https://medium.com/%40jelkhoury880/how-i-jepa-is-redefining-the-ring-of-self-supervised-learning-a-knockout-approach-5076c42b2795","title":"How I-JEPA is Redefining the Ring of Self-Supervised Learning","snippet":"The framework of Image-based Joint Embedding Predictive Architecture (I-JEPA) contains 3 blocks: context block, target block, and predictor.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":7},"content_type":null,"pub_date":1691193600.0,"attributions":null,"attribution":"Medium"}]},{"type":"search_result_group","domain":"arxiv.org","entries":[{"type":"search_result","url":"https://arxiv.org/abs/2408.07514","title":"CNN-JEPA: Self-Supervised Pretraining Convolutional Neural ...","snippet":"In this paper, we introduce CNN-JEPA, a novel SSL method that successfully applies the joint embedding predictive architecture approach to CNNs.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":2},"content_type":null,"pub_date":1723593600.0,"attributions":null,"attribution":"arXiv"}]},{"type":"search_result_group","domain":"thecvf.com","entries":[{"type":"search_result","url":"https://openaccess.thecvf.com/content/CVPR2023/papers/Assran_Self-Supervised_Learning_From_Images_With_a_Joint-Embedding_Predictive_Architecture_CVPR_2023_paper.pdf","title":"[PDF] Self-Supervised Learning From Images With a Joint-Embedding ...","snippet":"We introduce the Image- based Joint-Embedding Predictive Architecture (I-JEPA), a non-generative approach for self-supervised learning from images. The idea ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":3},"content_type":null,"pub_date":null,"attributions":null,"attribution":"CVF Open Access"}]},{"type":"search_result_group","domain":"meta.com","entries":[{"type":"search_result","url":"https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/","title":"V-JEPA: The next step toward advanced machine intelligence","snippet":"A self-supervised approach for learning representations from video, V-JEPA can be applied to various downstream image and video tasks ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":4},"content_type":null,"pub_date":1707955200.0,"attributions":null,"attribution":"Meta AI"}]},{"type":"search_result_group","domain":"reddit.com","entries":[{"type":"search_result","url":"https://www.reddit.com/r/computervision/comments/14conzp/ijepa_the_first_ai_model_based_on_yann_lecuns/","title":"I-JEPA: The first AI model based on Yann LeCun's vision for ... - Reddit","snippet":"This paper demonstrates an approach for learning highly semantic image representations without relying on hand-crafted data-augmentations.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":5},"content_type":null,"pub_date":1687046400.0,"attributions":null,"attribution":"Reddit"},{"type":"search_result","url":"https://www.reddit.com/r/MachineLearning/comments/14n7w33/r_selfsupervised_learning_from_images_with_a/","title":"[R] Self-Supervised Learning from Images with a Joint-Embedding ...","snippet":"This paper demonstrates an approach for learning highly semantic image representations without relying on hand-crafted data-augmentations.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":6},"content_type":null,"pub_date":1688083200.0,"attributions":null,"attribution":"Reddit"}]},{"type":"search_result_group","domain":"openreview.net","entries":[{"type":"search_result","url":"https://openreview.net/forum?id=JvQnJWIj6m&referrer=%5Bthe+profile+of+Shentong+Mo%5D%28%2Fprofile%3Fid%3D~Shentong_Mo1%29","title":"Connecting Joint-Embedding Predictive Architecture with Contrastive...","snippet":"Summary: The paper introduces C-JEPA, an enhancement to the Joint-Embedding Predictive Architecture incorporating Variance-Invariance-Covariance ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":8},"content_type":null,"pub_date":1727222400.0,"attributions":null,"attribution":"OpenReview"}]},{"type":"search_result_group","domain":"turingpost.com","entries":[{"type":"search_result","url":"https://www.turingpost.com/p/jepa","title":"What is Joint Embedding Predictive Architecture (JEPA)? - Turing Post","snippet":"We discuss the Joint Embedding Predictive Architecture (JEPA), how it differs from transformers and provide you with list of models based on JEPA.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":9},"content_type":null,"pub_date":1718150400.0,"attributions":null,"attribution":"Turing Post"}]}],"safe_urls":["https://openaccess.thecvf.com/content/CVPR2023/papers/Assran_Self-Supervised_Learning_From_Images_With_a_Joint-Embedding_Predictive_Architecture_CVPR_2023_paper.pdf?utm_source=chatgpt.com","https://arxiv.org/abs/2408.07514?utm_source=chatgpt.com","https://arxiv.org/abs/2410.05016?utm_source=chatgpt.com","https://arxiv.org/abs/2501.04969?utm_source=chatgpt.com","https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/?utm_source=chatgpt.com","https://openreview.net/forum?id=JvQnJWIj6m&referrer=%5Bthe+profile+of+Shentong+Mo%5D%28%2Fprofile%3Fid%3D~Shentong_Mo1%29&utm_source=chatgpt.com","https://arxiv.org/abs/2307.12698?utm_source=chatgpt.com"],"message_type":null,"model_slug":"gpt-4-5","default_model_slug":"gpt-4-5","parent_id":"375ed9fc-98d9-4349-884f-ec2ba3216055","message_locale":"en-US","image_results":[],"content_references":[{"matched_text":"\ue203","start_idx":0,"end_idx":1,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"The **Joint Embedding Predictive Architecture (JEPA)** has inspired a range of self-supervised learning models across various data modalities.","start_idx":1,"end_idx":143,"safe_urls":[],"refs":[],"alt":"The **Joint Embedding Predictive Architecture (JEPA)** has inspired a range of self-supervised learning models across various data modalities.","prompt_text":null,"type":"attribution","attributable_index":"0-0","attributions":null,"attributions_debug":null},{"matched_text":"\ue204","start_idx":143,"end_idx":144,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"\ue206","start_idx":205,"end_idx":206,"refs":[],"alt":null,"prompt_text":null,"type":"grouped_webpages","items":[],"status":"done","error":null,"style":"v2"},{"matched_text":"\ue203","start_idx":277,"end_idx":278,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"I-JEPA focuses on image data, predicting representations of target image blocks based on a single context block.","start_idx":278,"end_idx":390,"safe_urls":[],"refs":[],"alt":"I-JEPA focuses on image data, predicting representations of target image blocks based on a single context block.","prompt_text":null,"type":"attribution","attributable_index":"206-1","attributions":null,"attributions_debug":null},{"matched_text":"\ue204","start_idx":390,"end_idx":391,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"\ue203","start_idx":392,"end_idx":393,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"This approach emphasizes semantic content over pixel-level details, enhancing scalability and performance in tasks like object counting and depth prediction.","start_idx":393,"end_idx":550,"safe_urls":[],"refs":[],"alt":"This approach emphasizes semantic content over pixel-level details, enhancing scalability and performance in tasks like object counting and depth prediction.","prompt_text":null,"type":"attribution","attributable_index":"206-2","attributions":null,"attributions_debug":null},{"matched_text":"\ue204","start_idx":550,"end_idx":551,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"\ue200cite\ue202turn0search3\ue201","start_idx":552,"end_idx":571,"refs":[],"alt":"","prompt_text":"([openaccess.thecvf.com](https://openaccess.thecvf.com/content/CVPR2023/papers/Assran_Self-Supervised_Learning_From_Images_With_a_Joint-Embedding_Predictive_Architecture_CVPR_2023_paper.pdf?utm_source=chatgpt.com))","type":"grouped_webpages_model_predicted_fallback","items":[{"title":"[PDF] Self-Supervised Learning From Images With a Joint-Embedding ...","url":"https://openaccess.thecvf.com/content/CVPR2023/papers/Assran_Self-Supervised_Learning_From_Images_With_a_Joint-Embedding_Predictive_Architecture_CVPR_2023_paper.pdf?utm_source=chatgpt.com","pub_date":null,"snippet":"We introduce the Image- based Joint-Embedding Predictive Architecture (I-JEPA), a non-generative approach for self-supervised learning from images. The idea ...","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":3}],"hue":null,"attributions":null}],"status":"done","error":null,"style":null},{"matched_text":"\ue206","start_idx":571,"end_idx":572,"refs":[],"alt":null,"prompt_text":null,"type":"grouped_webpages","items":[{"title":"[R] Self-Supervised Learning from Images with a Joint-Embedding ...","url":"https://www.reddit.com/r/MachineLearning/comments/14n7w33/r_selfsupervised_learning_from_images_with_a/?utm_source=chatgpt.com","pub_date":1688083200.0,"snippet":"This paper demonstrates an approach for learning highly semantic image representations without relying on hand-crafted data-augmentations.","attribution_segments":["206-1"],"supporting_websites":[{"title":"[PDF] Self-Supervised Learning From Images With a Joint-Embedding ...","url":"https://openaccess.thecvf.com/content/CVPR2023/papers/Assran_Self-Supervised_Learning_From_Images_With_a_Joint-Embedding_Predictive_Architecture_CVPR_2023_paper.pdf?utm_source=chatgpt.com","pub_date":null,"snippet":"We introduce the Image- based Joint-Embedding Predictive Architecture (I-JEPA), a non-generative approach for self-supervised learning from images. The idea ...","attribution":"CVF Open Access"},{"title":"How I-JEPA is Redefining the Ring of Self-Supervised Learning","url":"https://medium.com/%40jelkhoury880/how-i-jepa-is-redefining-the-ring-of-self-supervised-learning-a-knockout-approach-5076c42b2795?utm_source=chatgpt.com","pub_date":1691193600.0,"snippet":"The framework of Image-based Joint Embedding Predictive Architecture (I-JEPA) contains 3 blocks: context block, target block, and predictor.","attribution":"Medium"},{"title":"Paper Review: Self-Supervised Learning from Images with a Joint ...","url":"https://artgor.medium.com/paper-review-self-supervised-learning-from-images-with-a-joint-embedding-predictive-architecture-6e5608e543e8?utm_source=chatgpt.com","pub_date":1686700800.0,"snippet":"This paper presents a new methodology for self-supervised learning from images \u2014 Image-based Joint-Embedding Predictive Architecture (I-JEPA).","attribution":"Medium"},{"title":"Deep Dive into JEPA and Similar Architectures - LinkedIn","url":"https://www.linkedin.com/pulse/deep-dive-jepa-similar-architectures-anshuman-jha-2lrxc?utm_source=chatgpt.com","pub_date":1742688000.0,"snippet":"JEPA represents a paradigm shift in self\u2011supervised learning. Instead of reconstructing pixel\u2011level details as conventional generative ...","attribution":"LinkedIn"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":6},{"turn_index":0,"ref_type":"search","ref_index":3},{"turn_index":0,"ref_type":"search","ref_index":7},{"turn_index":0,"ref_type":"search","ref_index":1},{"turn_index":0,"ref_type":"search","ref_index":0}],"hue":null,"attributions":null,"attribution":"Reddit"},{"title":"[PDF] Self-Supervised Learning From Images With a Joint-Embedding ...","url":"https://openaccess.thecvf.com/content/CVPR2023/papers/Assran_Self-Supervised_Learning_From_Images_With_a_Joint-Embedding_Predictive_Architecture_CVPR_2023_paper.pdf?utm_source=chatgpt.com","pub_date":null,"snippet":"We introduce the Image- based Joint-Embedding Predictive Architecture (I-JEPA), a non-generative approach for self-supervised learning from images. The idea ...","attribution_segments":["206-2"],"supporting_websites":[{"title":"Paper Review: Self-Supervised Learning from Images with a Joint ...","url":"https://artgor.medium.com/paper-review-self-supervised-learning-from-images-with-a-joint-embedding-predictive-architecture-6e5608e543e8?utm_source=chatgpt.com","pub_date":1686700800.0,"snippet":"This paper presents a new methodology for self-supervised learning from images \u2014 Image-based Joint-Embedding Predictive Architecture (I-JEPA).","attribution":"Medium"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":3},{"turn_index":0,"ref_type":"search","ref_index":1}],"hue":null,"attributions":null,"attribution":"CVF Open Access"}],"status":"done","error":null,"style":"v2"},{"matched_text":"\ue203","start_idx":591,"end_idx":592,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"Tailored for Convolutional Neural Networks (CNNs), CNN-JEPA adapts JEPA principles by incorporating a sparse CNN encoder and a fully convolutional predictor.","start_idx":592,"end_idx":749,"safe_urls":[],"refs":[],"alt":"Tailored for Convolutional Neural Networks (CNNs), CNN-JEPA adapts JEPA principles by incorporating a sparse CNN encoder and a fully convolutional predictor.","prompt_text":null,"type":"attribution","attributable_index":"572-1","attributions":null,"attributions_debug":null},{"matched_text":"\ue204","start_idx":749,"end_idx":750,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"\ue203","start_idx":751,"end_idx":752,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"It employs an improved masking strategy, demonstrating superior performance on datasets like ImageNet-100 compared to traditional CNN-based self-supervised methods.","start_idx":752,"end_idx":916,"safe_urls":[],"refs":[],"alt":"It employs an improved masking strategy, demonstrating superior performance on datasets like ImageNet-100 compared to traditional CNN-based self-supervised methods.","prompt_text":null,"type":"attribution","attributable_index":"572-2","attributions":null,"attributions_debug":null},{"matched_text":"\ue204","start_idx":916,"end_idx":917,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"\ue200cite\ue202turn0search2\ue201","start_idx":918,"end_idx":937,"refs":[],"alt":"","prompt_text":"([arxiv.org](https://arxiv.org/abs/2408.07514?utm_source=chatgpt.com))","type":"grouped_webpages_model_predicted_fallback","items":[{"title":"CNN-JEPA: Self-Supervised Pretraining Convolutional Neural Networks Using Joint Embedding Predictive Architecture","url":"https://arxiv.org/abs/2408.07514?utm_source=chatgpt.com","pub_date":1723639717.0,"snippet":"","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":2}],"hue":null,"attributions":null}],"status":"done","error":null,"style":null},{"matched_text":"\ue206","start_idx":937,"end_idx":938,"refs":[],"alt":null,"prompt_text":null,"type":"grouped_webpages","items":[{"title":"CNN-JEPA: Self-Supervised Pretraining Convolutional Neural Networks Using Joint Embedding Predictive Architecture","url":"https://arxiv.org/abs/2408.07514?utm_source=chatgpt.com","pub_date":1723639717.0,"snippet":"Self-supervised learning (SSL) has become an important approach in pretraining large neural networks, enabling unprecedented scaling of model and dataset sizes. While recent advances like I-JEPA have...","attribution_segments":["572-1","572-2"],"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":2}],"hue":null,"attributions":null,"attribution":"arXiv"}],"status":"done","error":null,"style":"v2"},{"matched_text":"\ue203","start_idx":968,"end_idx":969,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"Extending JEPA to video data, V-JEPA predicts representations of future video frames based on past contexts.","start_idx":969,"end_idx":1077,"safe_urls":[],"refs":[],"alt":"Extending JEPA to video data, V-JEPA predicts representations of future video frames based on past contexts.","prompt_text":null,"type":"attribution","attributable_index":"938-1","attributions":null,"attributions_debug":null},{"matched_text":"\ue204","start_idx":1077,"end_idx":1078,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"\ue203","start_idx":1079,"end_idx":1080,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"This model effectively captures temporal dynamics, advancing self-supervised learning in video analysis.","start_idx":1080,"end_idx":1184,"safe_urls":[],"refs":[],"alt":"This model effectively captures temporal dynamics, advancing self-supervised learning in video analysis.","prompt_text":null,"type":"attribution","attributable_index":"938-2","attributions":null,"attributions_debug":null},{"matched_text":"\ue204","start_idx":1184,"end_idx":1185,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"\ue200cite\ue202turn0search4\ue201","start_idx":1186,"end_idx":1205,"refs":[],"alt":"","prompt_text":"([ai.meta.com](https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/?utm_source=chatgpt.com))","type":"grouped_webpages_model_predicted_fallback","items":[{"title":"V-JEPA: The next step toward advanced machine intelligence","url":"https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/?utm_source=chatgpt.com","pub_date":1707955200.0,"snippet":"A self-supervised approach for learning representations from video, V-JEPA can be applied to various downstream image and video tasks ...","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":4}],"hue":null,"attributions":null}],"status":"done","error":null,"style":null},{"matched_text":"\ue206","start_idx":1205,"end_idx":1206,"refs":[],"alt":null,"prompt_text":null,"type":"grouped_webpages","items":[],"status":"done","error":null,"style":"v2"},{"matched_text":"\ue203","start_idx":1242,"end_idx":1243,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"C-JEPA integrates JEPA with contrastive self-supervised learning techniques, incorporating Variance-Invariance-Covariance Regularization (VICReg).","start_idx":1243,"end_idx":1389,"safe_urls":[],"refs":[],"alt":"C-JEPA integrates JEPA with contrastive self-supervised learning techniques, incorporating Variance-Invariance-Covariance Regularization (VICReg).","prompt_text":null,"type":"attribution","attributable_index":"1206-1","attributions":null,"attributions_debug":null},{"matched_text":"\ue204","start_idx":1389,"end_idx":1390,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"\ue203","start_idx":1391,"end_idx":1392,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"This fusion enhances stability and representation quality in visual learning tasks.","start_idx":1392,"end_idx":1475,"safe_urls":[],"refs":[],"alt":"This fusion enhances stability and representation quality in visual learning tasks.","prompt_text":null,"type":"attribution","attributable_index":"1206-2","attributions":null,"attributions_debug":null},{"matched_text":"\ue204","start_idx":1475,"end_idx":1476,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"\ue200cite\ue202turn0search8\ue201","start_idx":1477,"end_idx":1496,"refs":[],"alt":"","prompt_text":"([openreview.net](https://openreview.net/forum?id=JvQnJWIj6m&referrer=%5Bthe+profile+of+Shentong+Mo%5D%28%2Fprofile%3Fid%3D~Shentong_Mo1%29&utm_source=chatgpt.com))","type":"grouped_webpages_model_predicted_fallback","items":[{"title":"Connecting Joint-Embedding Predictive Architecture with Contrastive...","url":"https://openreview.net/forum?id=JvQnJWIj6m&referrer=%5Bthe+profile+of+Shentong+Mo%5D%28%2Fprofile%3Fid%3D~Shentong_Mo1%29&utm_source=chatgpt.com","pub_date":1727222400.0,"snippet":"Summary: The paper introduces C-JEPA, an enhancement to the Joint-Embedding Predictive Architecture incorporating Variance-Invariance-Covariance ...","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":8}],"hue":null,"attributions":null}],"status":"done","error":null,"style":null},{"matched_text":"\ue206","start_idx":1496,"end_idx":1497,"refs":[],"alt":null,"prompt_text":null,"type":"grouped_webpages","items":[{"title":"Connecting Joint-Embedding Predictive Architecture with Contrastive...","url":"https://openreview.net/forum?id=JvQnJWIj6m&referrer=%5Bthe+profile+of+Shentong+Mo%5D%28%2Fprofile%3Fid%3D~Shentong_Mo1%29&utm_source=chatgpt.com","pub_date":1727222400.0,"snippet":"Summary: The paper introduces C-JEPA, an enhancement to the Joint-Embedding Predictive Architecture incorporating Variance-Invariance-Covariance ...","attribution_segments":["1206-1"],"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":8}],"hue":null,"attributions":null,"attribution":"OpenReview"}],"status":"done","error":null,"style":"v2"},{"matched_text":"\ue203","start_idx":1514,"end_idx":1515,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"Designed for tabular data, T-JEPA employs a JEPA framework without requiring data augmentations.","start_idx":1515,"end_idx":1611,"safe_urls":[],"refs":[],"alt":"Designed for tabular data, T-JEPA employs a JEPA framework without requiring data augmentations.","prompt_text":null,"type":"attribution","attributable_index":"1497-1","attributions":null,"attributions_debug":null},{"matched_text":"\ue204","start_idx":1611,"end_idx":1612,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"\ue203","start_idx":1613,"end_idx":1614,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"It predicts latent representations of feature subsets within the same sample, improving performance in classification and regression tasks on structured data.","start_idx":1614,"end_idx":1772,"safe_urls":[],"refs":[],"alt":"It predicts latent representations of feature subsets within the same sample, improving performance in classification and regression tasks on structured data.","prompt_text":null,"type":"attribution","attributable_index":"1497-2","attributions":null,"attributions_debug":null},{"matched_text":"\ue204","start_idx":1772,"end_idx":1773,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"\ue200cite\ue202turn0academia10\ue201","start_idx":1774,"end_idx":1796,"refs":[],"alt":"","prompt_text":"([arxiv.org](https://arxiv.org/abs/2410.05016?utm_source=chatgpt.com))","type":"grouped_webpages_model_predicted_fallback","items":[{"title":"T-JEPA: Augmentation-Free Self-Supervised Learning for Tabular Data","url":"https://arxiv.org/abs/2410.05016?utm_source=chatgpt.com","pub_date":1728306907.0,"snippet":"","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"academia","ref_index":10}],"hue":null,"attributions":null}],"status":"done","error":null,"style":null},{"matched_text":"\ue206","start_idx":1796,"end_idx":1797,"refs":[],"alt":null,"prompt_text":null,"type":"grouped_webpages","items":[{"title":"T-JEPA: Augmentation-Free Self-Supervised Learning for Tabular Data","url":"https://arxiv.org/abs/2410.05016?utm_source=chatgpt.com","pub_date":1728306907.0,"snippet":"Self-supervision is often used for pre-training to foster performance on a downstream task by constructing meaningful representations of samples. Self-supervised learning (SSL) generally involves gene...","attribution_segments":["1497-1","1497-2"],"supporting_websites":[{"title":"How I-JEPA is Redefining the Ring of Self-Supervised Learning","url":"https://medium.com/%40jelkhoury880/how-i-jepa-is-redefining-the-ring-of-self-supervised-learning-a-knockout-approach-5076c42b2795?utm_source=chatgpt.com","pub_date":1691193600.0,"snippet":"The framework of Image-based Joint Embedding Predictive Architecture (I-JEPA) contains 3 blocks: context block, target block, and predictor.","attribution":"Medium"},{"title":"[R] Self-Supervised Learning from Images with a Joint-Embedding ...","url":"https://www.reddit.com/r/MachineLearning/comments/14n7w33/r_selfsupervised_learning_from_images_with_a/?utm_source=chatgpt.com","pub_date":1688083200.0,"snippet":"This paper demonstrates an approach for learning highly semantic image representations without relying on hand-crafted data-augmentations.","attribution":"Reddit"}],"refs":[{"turn_index":0,"ref_type":"academia","ref_index":10},{"turn_index":0,"ref_type":"search","ref_index":7},{"turn_index":0,"ref_type":"search","ref_index":6}],"hue":null,"attributions":null,"attribution":"arXiv"}],"status":"done","error":null,"style":"v2"},{"matched_text":"\ue203","start_idx":1815,"end_idx":1816,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"MC-JEPA combines JEPA with motion and content feature learning, jointly learning optical flow and content features within a shared encoder.","start_idx":1816,"end_idx":1955,"safe_urls":[],"refs":[],"alt":"MC-JEPA combines JEPA with motion and content feature learning, jointly learning optical flow and content features within a shared encoder.","prompt_text":null,"type":"attribution","attributable_index":"1797-1","attributions":null,"attributions_debug":null},{"matched_text":"\ue204","start_idx":1955,"end_idx":1956,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"\ue203","start_idx":1957,"end_idx":1958,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"This approach benefits tasks like semantic segmentation of images and videos.","start_idx":1958,"end_idx":2035,"safe_urls":[],"refs":[],"alt":"This approach benefits tasks like semantic segmentation of images and videos.","prompt_text":null,"type":"attribution","attributable_index":"1797-2","attributions":null,"attributions_debug":null},{"matched_text":"\ue204","start_idx":2035,"end_idx":2036,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"\ue200cite\ue202turn0academia11\ue201","start_idx":2037,"end_idx":2059,"refs":[],"alt":"","prompt_text":"([arxiv.org](https://arxiv.org/abs/2307.12698?utm_source=chatgpt.com))","type":"grouped_webpages_model_predicted_fallback","items":[{"title":"MC-JEPA: A Joint-Embedding Predictive Architecture for Self-Supervised Learning of Motion and Content Features","url":"https://arxiv.org/abs/2307.12698?utm_source=chatgpt.com","pub_date":1690198034.0,"snippet":"","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"academia","ref_index":11}],"hue":null,"attributions":null}],"status":"done","error":null,"style":null},{"matched_text":"\ue206","start_idx":2059,"end_idx":2060,"refs":[],"alt":null,"prompt_text":null,"type":"grouped_webpages","items":[{"title":"MC-JEPA: A Joint-Embedding Predictive Architecture for Self-Supervised Learning of Motion and Content Features","url":"https://arxiv.org/abs/2307.12698?utm_source=chatgpt.com","pub_date":1690198034.0,"snippet":"Self-supervised learning of visual representations has been focusing on learning content features, which do not capture object motion or location, and focus on identifying and differentiating objects...","attribution_segments":["1797-1","1797-2"],"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"academia","ref_index":11}],"hue":null,"attributions":null,"attribution":"arXiv"}],"status":"done","error":null,"style":"v2"},{"matched_text":"\ue203","start_idx":2080,"end_idx":2081,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"Focused on autonomous driving applications, AD-L-JEPA applies JEPA to LiDAR data, learning spatial world models through self-supervised pre-training.","start_idx":2081,"end_idx":2230,"safe_urls":[],"refs":[],"alt":"Focused on autonomous driving applications, AD-L-JEPA applies JEPA to LiDAR data, learning spatial world models through self-supervised pre-training.","prompt_text":null,"type":"attribution","attributable_index":"2060-1","attributions":null,"attributions_debug":null},{"matched_text":"\ue204","start_idx":2230,"end_idx":2231,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"\ue203","start_idx":2232,"end_idx":2233,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"It enhances performance in downstream tasks such as 3D object detection.","start_idx":2233,"end_idx":2305,"safe_urls":[],"refs":[],"alt":"It enhances performance in downstream tasks such as 3D object detection.","prompt_text":null,"type":"attribution","attributable_index":"2060-2","attributions":null,"attributions_debug":null},{"matched_text":"\ue204","start_idx":2305,"end_idx":2306,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"\ue200cite\ue202turn0academia12\ue201","start_idx":2307,"end_idx":2329,"refs":[],"alt":"","prompt_text":"([arxiv.org](https://arxiv.org/abs/2501.04969?utm_source=chatgpt.com))","type":"grouped_webpages_model_predicted_fallback","items":[{"title":"AD-L-JEPA: Self-Supervised Spatial World Models with Joint Embedding Predictive Architecture for Autonomous Driving with LiDAR Data","url":"https://arxiv.org/abs/2501.04969?utm_source=chatgpt.com","pub_date":1736398071.0,"snippet":"","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"academia","ref_index":12}],"hue":null,"attributions":null}],"status":"done","error":null,"style":null},{"matched_text":"\ue206","start_idx":2329,"end_idx":2330,"refs":[],"alt":null,"prompt_text":null,"type":"grouped_webpages","items":[{"title":"AD-L-JEPA: Self-Supervised Spatial World Models with Joint Embedding Predictive Architecture for Autonomous Driving with LiDAR Data","url":"https://arxiv.org/abs/2501.04969?utm_source=chatgpt.com","pub_date":1736398071.0,"snippet":"As opposed to human drivers, current autonomous driving systems still require vast amounts of labeled data to train. Recently, world models have been proposed to simultaneously enhance autonomous driv...","attribution_segments":["2060-1","2060-2"],"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"academia","ref_index":12}],"hue":null,"attributions":null,"attribution":"arXiv"}],"status":"done","error":null,"style":"v2"},{"matched_text":"\ue203","start_idx":2332,"end_idx":2333,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"These architectures demonstrate the adaptability of JEPA's principles across diverse data types and tasks, highlighting its influence in the evolution of self-supervised learning methodologies.","start_idx":2333,"end_idx":2526,"safe_urls":[],"refs":[],"alt":"These architectures demonstrate the adaptability of JEPA's principles across diverse data types and tasks, highlighting its influence in the evolution of self-supervised learning methodologies.","prompt_text":null,"type":"attribution","attributable_index":"2330-0","attributions":null,"attributions_debug":null},{"matched_text":"\ue204","start_idx":2526,"end_idx":2527,"refs":["hidden"],"alt":null,"prompt_text":null,"type":"hidden","invalid":false},{"matched_text":"\ue206","start_idx":2527,"end_idx":2528,"refs":[],"alt":null,"prompt_text":null,"type":"grouped_webpages","items":[],"status":"done","error":null,"style":"v2"},{"matched_text":" ","start_idx":2528,"end_idx":2528,"refs":[],"alt":"","prompt_text":null,"type":"sources_footnote","sources":[{"title":"[PDF] Self-Supervised Learning From Images With a Joint-Embedding ...","url":"https://openaccess.thecvf.com/content/CVPR2023/papers/Assran_Self-Supervised_Learning_From_Images_With_a_Joint-Embedding_Predictive_Architecture_CVPR_2023_paper.pdf?utm_source=chatgpt.com","attribution":"CVF Open Access"},{"title":"[R] Self-Supervised Learning from Images with a Joint-Embedding ...","url":"https://www.reddit.com/r/MachineLearning/comments/14n7w33/r_selfsupervised_learning_from_images_with_a/?utm_source=chatgpt.com","attribution":"Reddit"},{"title":"CNN-JEPA: Self-Supervised Pretraining Convolutional Neural Networks Using Joint Embedding Predictive Architecture","url":"https://arxiv.org/abs/2408.07514?utm_source=chatgpt.com","attribution":"arXiv"},{"title":"V-JEPA: The next step toward advanced machine intelligence","url":"https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/?utm_source=chatgpt.com","attribution":"Meta AI"},{"title":"Connecting Joint-Embedding Predictive Architecture with Contrastive...","url":"https://openreview.net/forum?id=JvQnJWIj6m&referrer=%5Bthe+profile+of+Shentong+Mo%5D%28%2Fprofile%3Fid%3D~Shentong_Mo1%29&utm_source=chatgpt.com","attribution":"OpenReview"}],"has_images":false}],"citations":[{"start_ix":0,"end_ix":1,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":143,"end_ix":144,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":205,"end_ix":206,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":277,"end_ix":278,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":390,"end_ix":391,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":392,"end_ix":393,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":550,"end_ix":551,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":552,"end_ix":571,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":571,"end_ix":572,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":591,"end_ix":592,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":749,"end_ix":750,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":751,"end_ix":752,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":916,"end_ix":917,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":918,"end_ix":937,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":937,"end_ix":938,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":968,"end_ix":969,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1077,"end_ix":1078,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1079,"end_ix":1080,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1184,"end_ix":1185,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1186,"end_ix":1205,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1205,"end_ix":1206,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1242,"end_ix":1243,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1389,"end_ix":1390,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1391,"end_ix":1392,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1475,"end_ix":1476,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1477,"end_ix":1496,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1496,"end_ix":1497,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1514,"end_ix":1515,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1611,"end_ix":1612,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1613,"end_ix":1614,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1772,"end_ix":1773,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1774,"end_ix":1796,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1796,"end_ix":1797,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1815,"end_ix":1816,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1955,"end_ix":1956,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":1957,"end_ix":1958,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":2035,"end_ix":2036,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":2037,"end_ix":2059,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":2059,"end_ix":2060,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":2080,"end_ix":2081,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":2230,"end_ix":2231,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":2232,"end_ix":2233,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":2305,"end_ix":2306,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":2307,"end_ix":2329,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":2329,"end_ix":2330,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":2332,"end_ix":2333,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":2526,"end_ix":2527,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":2527,"end_ix":2528,"invalid_reason":"Unsupported, please upgrade"},{"start_ix":2528,"end_ix":2528,"invalid_reason":"Unsupported, please upgrade"}],"request_id":"9290db751874fe90-SIN","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"375ed9fc-98d9-4349-884f-ec2ba3216055","children":[]}}}