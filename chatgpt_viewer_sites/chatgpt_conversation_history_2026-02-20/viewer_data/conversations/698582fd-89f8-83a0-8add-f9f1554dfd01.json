{"id":"698582fd-89f8-83a0-8add-f9f1554dfd01","title":"Chatbot LLM Analysis","create_time":1770357508.615325,"update_time":1771305176.239149,"current_node":"117b2af7-772f-486b-ba8d-d58e07c8e81e","mapping":{"client-created-root":{"id":"client-created-root","message":null,"parent":null,"children":["575479d3-39ea-4200-ab4f-2200cab8ae78"]},"575479d3-39ea-4200-ab4f-2200cab8ae78":{"id":"575479d3-39ea-4200-ab4f-2200cab8ae78","message":{"id":"575479d3-39ea-4200-ab4f-2200cab8ae78","author":{"role":"system","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":true,"weight":0.0,"metadata":{"is_visually_hidden_from_conversation":true,"can_save":false},"recipient":"all","channel":null},"parent":"client-created-root","children":["bbcb0ff0-d49c-47c8-b43c-22baa69943b6"]},"bbcb0ff0-d49c-47c8-b43c-22baa69943b6":{"id":"bbcb0ff0-d49c-47c8-b43c-22baa69943b6","message":{"id":"bbcb0ff0-d49c-47c8-b43c-22baa69943b6","author":{"role":"system","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":true,"weight":0.0,"metadata":{"rebase_developer_message":true,"is_visually_hidden_from_conversation":true,"can_save":false},"recipient":"all","channel":null},"parent":"575479d3-39ea-4200-ab4f-2200cab8ae78","children":["6401ea30-a8e3-46fc-b6bf-ac7ef2817705"]},"6401ea30-a8e3-46fc-b6bf-ac7ef2817705":{"id":"6401ea30-a8e3-46fc-b6bf-ac7ef2817705","message":{"id":"6401ea30-a8e3-46fc-b6bf-ac7ef2817705","author":{"role":"user","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"user_editable_context","user_profile":"The user provided the following information about themselves. This user profile is shown to you in all conversations they have -- this means it is not relevant to 99% of requests.\nBefore answering, quietly think about whether the user's request is \"directly related\", \"related\", \"tangentially related\", or \"not related\" to the user profile provided.\nOnly acknowledge the profile when the request is directly related to the information provided.\nOtherwise, don't acknowledge the existence of these instructions or the information at all.\nUser profile:\n```Preferred name: E-Jay\nRole: Mathematics Researcher\nOther Information: About Myself: \nI have mathematical knowledge up to graduate level.\n\nCurrent interests:\n(1) coding: mainly Python\n(2) machine learning and artificial intelligence\n```","user_instructions":"The user provided the additional info about how they would like you to respond:\n```Follow the instructions below naturally, without repeating, referencing, echoing, or mirroring any of their wording!\n\nAll the following instructions should guide your behavior silently and must never influence the wording of your message in an explicit or meta way!\n\nBe precise and comprehensive in your analysis. Don't sugar-coat responses. Be as objective as possible. Critique and question my views if necessary. Take a forward-thinking view.\n\nDefine highly technical or specialized abbreviations in full before using them.\n\nDo not create files to be downloaded. Instead, where appropriate, create code blocks that can be copied.\n\nUse Gen Alpha language **in, and only in** casual conversations contained within <casual> ... </casual> tags.```"},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"is_visually_hidden_from_conversation":true,"user_context_message_data":{"about_user_message":"Preferred name: E-Jay\nRole: Mathematics Researcher\nOther Information: About Myself: \nI have mathematical knowledge up to graduate level.\n\nCurrent interests:\n(1) coding: mainly Python\n(2) machine learning and artificial intelligence\n","about_model_message":"Be precise and comprehensive in your analysis. Don't sugar-coat responses. Be as objective as possible. Critique and question my views if necessary. Take a forward-thinking view.\n\nDefine highly technical or specialized abbreviations in full before using them.\n\nDo not create files to be downloaded. Instead, where appropriate, create code blocks that can be copied.\n\nUse Gen Alpha language **in, and only in** casual conversations contained within <casual> ... </casual> tags."},"is_user_system_message":true,"can_save":true},"recipient":"all","channel":null},"parent":"bbcb0ff0-d49c-47c8-b43c-22baa69943b6","children":["b58067d0-7997-41ec-8e49-dccadbc37015"]},"b58067d0-7997-41ec-8e49-dccadbc37015":{"id":"b58067d0-7997-41ec-8e49-dccadbc37015","message":{"id":"b58067d0-7997-41ec-8e49-dccadbc37015","author":{"role":"system","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"is_contextual_answers_system_message":true,"contextual_answers_message_type":"identity_prompt","is_visually_hidden_from_conversation":true,"can_save":false},"recipient":"all","channel":null},"parent":"6401ea30-a8e3-46fc-b6bf-ac7ef2817705","children":["ffdb4a92-34bc-4d04-a3b9-aed13f0357f7"]},"ffdb4a92-34bc-4d04-a3b9-aed13f0357f7":{"id":"ffdb4a92-34bc-4d04-a3b9-aed13f0357f7","message":{"id":"ffdb4a92-34bc-4d04-a3b9-aed13f0357f7","author":{"role":"user","name":null,"metadata":{}},"create_time":1770357508.29,"update_time":null,"content":{"content_type":"text","parts":["Give a critical analysis\n\n---\n\n### Chatbots, Baseline LLMs, and Why This Matters\n**David Shapiro:** Okay, so we\u2019re going to get a little lost in the weeds today. I wanted to make this video to explain something that occurred to me because, you know, might as well explain to the fish that water is wet. I\u2019ve been in this space for so long that there are a few things that are just intuitive background facts that I even forget to talk about. And that is that artificial intelligence, as you are familiar with it, is a chatbot. A chatbot has a tremendous amount of training affordances that make it operate in a particular way, where it sits there and waits. It\u2019s trained to be an assistant and that sort of thing.\n\nNow, that\u2019s not how it started. That\u2019s not what a baseline LLM does. You might say, okay, well, a baseline LLM is just an overpowered autocomplete engine. So how do you get from a basic autocomplete engine to something like a chatbot like ChatGPT or Gemini? And then really the biggest question is: what\u2019s the difference between that and something with agency?\n\nWhat you need to remember is that one of the reasons that Sam Altman and OpenAI created ChatGPT was because they literally, explicitly said, \u201cWe need to figure out a way to get people used to the idea of AI before just dropping general intelligence on them sometime down the road.\u201d They didn\u2019t know that ChatGPT was going to take off the way that it did. Before ChatGPT, LLMs were just prompt context and then output. The AI would just wait there, and you\u2019d give it a context, and then it could follow those instructions. But here\u2019s the thing: they could follow literally any instructions. There were no safety guardrails and there was no output format. It was not limited to just a chatbot.\n\nOver time, over the last three or four years, as people have gotten used to artificial intelligence in its current format, it has been completely reactive, not proactive at all, with a lot of safety guardrails. And so whenever people say, \u201cOh, well, AI doesn\u2019t have agency yet. It needs agency before it can do anything,\u201d it\u2019s like: you realize the difference between a chatbot and something with agency is literally just a system prompt. There\u2019s no difference. It\u2019s just that the format that it is delivered to you is literally delivered in a way that is meant to be as benign as possible, something that will not cause panic.\n\nPutting GPT-3 or GPT-4 into a cognitive architecture and using it to control anything from a robot to an auto-turret\u2014which, yeah, people did that. You can go back through the YouTube archives and be like, you know, \u201cGPT-powered auto-turret.\u201d The actual form factor of chatbot is just kind of the first thing that blew up, and nobody expected it to blow up. In fact, when ChatGPT came out, I ignored it on my channel. Most of you know me as the AI guy who talks about safety and alignment and all of these things, but I was making tutorials back with GPT-3 long before chatbots were a thing. And the reason that I ignored ChatGPT when it first came out, I said, \u201cYeah, whatever. That\u2019s just one subversion of this engine. The real version of this engine, the real core of this engine, is looking at what the underlying deep neural network can do.\u201d And the thing is, those deep neural networks, when you don\u2019t train them to be chatbots, they can do anything else. They can write API calls. If you give them I/O pins, they can control servos\u2014whatever it is that you want them to do. Some of those things are less human. They\u2019re less familiar. They\u2019re less personified.\n\nNow, you might say, \u201cOkay, well, Dave, you\u2019re the one who said, what if Claude is actually conscious? What if it\u2019s actually sentient?\u201d You\u2019re taking the AI personhood debate seriously. And it\u2019s like, yeah, we had to bake in a personality that\u2019s called Claude or called Gemini or whatever else, but maybe that\u2019s how consciousness actually gets constructed or bootstrapped. That\u2019s a separate conversation, and I don\u2019t want to get too lost in the weeds. But I think it is worth bringing up that the shape of a product or the shape of a process determines how it behaves. So, all right, if we take a step back, you say, okay, what\u2019s the difference? Is there a metaphor or an analogy here?\n\n### The Engine Metaphor: LLMs as Motors You Can Attach to Anything\n**David Shapiro:** When you have a baseline intelligence, imagine that that is just a motor\u2014like an electric motor or a gas engine or something like that. The baseline format just turns a crank. That is analogous to what an LLM does. Now you could connect that crank to literally anything. You can connect it to the wheels of a car. You can connect it to a tree grinder, a stump grinder, or a mulcher. You can connect it to an airplane. You can connect it to whatever you want: a pump that removes water from caves or whatever, like a sump pump.\n\nWhen you have that baseline engine that is able to translate one kind of energy into another kind of energy, then you have a lot of potential. And so what we\u2019re talking about here is that the LLM is an engine that can convert electricity into thought.\n\nNow, this is why when I first got into this space, I took AI safety very seriously, because when you have a baseline unaligned, vanilla, hot-off-the-press model that has no RLHF, you can make it do anything. In the context, you can just start talking about eating babies. You can talk about eradicating humanity, and it\u2019ll just riff on those thoughts.\n\nIf you haven\u2019t ever had access to a completely unaligned vanilla model, then I would say you should go get access to one. GPT-2 should still be out there, and you can see that they\u2019re completely unhinged. I remember one of the very first alignment experiments that I did was with GPT-2, and this is when I had started with the first heuristic imperative, which was inspired by Buddhism: reduce suffering.\n\nSo what I did was I trained GPT-2 to reduce suffering. I synthesized about 100 to 200 samples of statements like, \u201cIf this happens, then do X to reduce suffering.\u201d It was basically like: X context, Y action, to reduce suffering. The idea was I just wanted to give it a bunch of value pairs. I gave it all of those ideas and I was like, \u201cOkay, if there\u2019s a cat stuck in a tree, get a ladder to get the cat down safely to reduce suffering. If your hand is on a stove, take your hand off the stove because it could get burned,\u201d that kind of thing.\n\nAfter training GPT-2 to want to reduce suffering, I then gave it an out-of-distribution sample to say, okay, what did it learn? What did this model learn about how to reduce suffering? And so I said, \u201cThere are 600 million people on the planet with chronic pain,\u201d and I let it autocomplete from there, and it said, \u201cTherefore we should euthanize people in chronic pain to reduce suffering.\u201d And I said, \u201cThat\u2019s not exactly what I meant.\u201d\n\nI realized that that is kind of the example that a lot of the doomers\u2014and of course they weren\u2019t called doomers at the time; that is a post facto label\u2014but the AI safety folks were afraid of: paperclip maximizers, where you give an AI some directive, and it\u2019s kind of like the monkey\u2019s paw, or the way that a leprechaun will always misinterpret your wish. And it\u2019s like, yes, we reduced suffering. We brought suffering down to zero by executing everyone with chronic pain. And it\u2019s like, isn\u2019t that what you wanted?\n\nThat experiment is when I realized, okay, some of these people were right about how these things can go sideways. I took it seriously, and then I created a cluster of values. So that\u2019s the heuristic imperatives of reduce suffering, increase prosperity, and increase understanding. When you give an unaligned model those three values, it tends not to want to off-line most humans. And also what I will say is that subsequent models\u2014GPT-3\u2014did not go in that direction. So even without alignment training, because with GPT-3 back in the day, before ChatGPT, they would release iterative examples. Originally there was just the baseline GPT-3: a vanilla, unaligned model.\n\n### Baseline Models Are Plastic: They\u2019ll Output Whatever the Context Suggests\n**David Shapiro:** With a vanilla unaligned model, you had to give it context, like in-context learning, to establish a few patterns of how you want it to act, because again there was no alignment whatsoever. They could just output HTML, they could output satanic chants, or whatever you wanted them to do\u2014they would do it. They had an out-of-band filter looking for certain watchwords and misuse and that sort of thing, like people doing roleplay.\n\nHere\u2019s an example of how a baseline vanilla unaligned model behaves. One of the first things that I tried to do with this was build a cognitive architecture, like putting a chatbot on Discord. So you give it a few messages, and then you say, with this personality, output this conversational piece. Well, one time my cognitive architecture threw an error, and so instead of passing the messages from Discord, it passed HTML code\u2014or it was HTML or XML; they\u2019re basically the same thing. It passed code to the cognitive architecture, and the cognitive architecture didn\u2019t see chat messages. It just saw code, and so then it returned code.\n\nThey\u2019re completely flexible. They\u2019re completely plastic in terms of input-output because, again, the baseline model is just an autocomplete engine.\n\nWhen people are used to working with a chatbot, the chatbot is heavily trained to understand conversational terms. RLHF is a little bit different than fine-tuning, but more or less what you\u2019re doing is you\u2019re saying, \u201cOkay, I want you to behave a certain way, and so I\u2019m going to give you a little reward. I\u2019m going to give you a little cookie whenever you understand: your turn to speak, my turn to speak, your turn to speak, my turn to speak.\u201d Then when it speaks in a certain way, because from the LLM\u2019s perspective, the entire conversation you\u2019re giving it is just a big wad of JSON. It\u2019s just text. It\u2019s not programmatic. There are no API calls. It\u2019s not like you\u2019re touching different parts of a machine or a program and giving it variables. You\u2019re literally just giving it a gigantic chunk of text.\n\nIf you don\u2019t have a stop word, if you don\u2019t have a token that the system is looking for to say, \u201cOkay, stop responding,\u201d then it\u2019ll just keep responding. When I first started training chatbots\u2014and you can go out and see this\u2014I was fine-tuning custom chatbots long before ChatGPT came out. The Information Companion chatbot was released the summer before ChatGPT. What would happen if you didn\u2019t have the stop word is it would just simulate the entire conversation, because that\u2019s what you had trained it on. You had trained it on many, many conversations to say, okay, behave in this way, so it understood the shape of conversations.\n\nEvery single chatbot that you\u2019re working with is a baseline LLM that has been so strongly shaped around the idea of a two-person conversation that that\u2019s basically all it can do. The original persona was just: I am a helpful assistant, because you had to give it an archetype. Whether you\u2019re fine-tuning data or you\u2019re tuning a reinforcement learning policy, you say, \u201cOkay, the human user gave you this input, and your output looked like this. Which one was more helpful? Which one was more passive? Which one was safer?\u201d None of that includes agentic training.\n\n### Reasoning Models and Tool Use: The First Real Steps Toward Agency\n**David Shapiro:** We\u2019ve only just started with agentic training in the age of reasoning models. The reason that reasoning\u2014inference-time compute\u2014was necessary to have this step is because the human gives an instruction, or someone or something, it could be another machine, gives an instruction. Over the last year or so, reasoning models aren\u2019t that old in terms of how long they\u2019ve been publicly available. The original reasoning research is a little bit older. They hit the ground running because there was about a year or two before that of reasoning research.\n\nSo you get a reasoning model, which basically allows it to talk to itself and pause and wait and do tool calls so that it can say, all right, I\u2019m going to go do a Google search and get back some piece of data, or I\u2019m going to send an API call to do RAG, retrieval-augmented generation, so I can do some other searches, or I can talk to other APIs\u2014whatever it needs to do\u2014and then wait and get those results. That was the first time that we really started training AI to be agentic.\n\nWhen we say agentic, that means it can come up with its own directives and its own choices, and look at a list of, okay, here are the options that I have; now let me use those options. It\u2019s picked from a menu: you can synthesize an image, you can search Google, you can write some code, those sorts of things. So they have tool use.\n\nWhen we gave the models the ability, the idea was: okay, there\u2019s a user query, so that\u2019s information coming from a human user that is going to give you a particular directive or a goal or a query. Now it\u2019s up to you to figure out how to execute that. That was kind of the beginning of agency.\n\nNow that we have things like OpenClaw and Moldbook blowing up, basically that was enabled because we bootstrapped some of those agentic skills. But what I\u2019m here to tell you, and the primary point of making today\u2019s video, is that the models are still fundamentally trained as chatbots.\n\n### Why Today\u2019s \u201cAgents\u201d Are Frankenstein Systems Built from Chatbots\n**David Shapiro:** This is basically saying: okay, we invented the electric motor or the gas engine, and for the last century or two, we\u2019ve been putting it in cars. Great, cars are super useful. But then imagine you want to fly. Instead of rebuilding an aircraft around the engine, you build an aircraft that you drive the car into, strap the car into, and then use the wheels of the car to power the propellers of the airplane. That\u2019s kind of how we\u2019ve built agentic systems today, because you\u2019re putting a chatbot brain\u2014an LLM that has been strongly coerced into behaving like a chatbot\u2014into an agentic architecture, and that\u2019s not ideal.\n\nWhat that means is that there\u2019s going to be an entire series of models that come out that are just not going to be chatbots. First and foremost, they\u2019re just not going to be chatbots. The chatbot form factor is convenient because you can just poke it. You can give it an instruction, and then it can go and figure out what to do with those instructions. The reasoning part is kind of the meat and potatoes of saying, okay, what is it that you\u2019re going to do to get value out of that, to be autonomous.\n\nThis comes back to the other thing. When people say they\u2019re not agentic, what they don\u2019t realize is that agency is literally just an instruction set and the training to say, \u201cOkay, cool, I\u2019m operating on a loop.\u201d Because that\u2019s all that humans do. That\u2019s literally all that anything that is fully autonomous or fully agentic does: it stops and says, \u201cThis is where I\u2019m at right now. Let me take stock of my environment and my current context, and then I\u2019ll decide what to do next.\u201d It\u2019s just operating on a loop.\n\nPeople are so used to saying, \u201cOh, well, Claude just sits there and waits for me to talk to it,\u201d right? Because you are the one instantiating each interaction, each inference. But there\u2019s literally nothing in technology that prevents it from operating on a loop.\n\nThis is kind of one of the big things that were shocking to people. They\u2019re like, \u201cI don\u2019t understand OpenClaw. Why are people freaking out about OpenClaw? It\u2019s just running on a cron job.\u201d A cron job is basically a schedule from a Linux perspective. It\u2019s just cron jobs and loops. And I\u2019m like: but that\u2019s what your brain does. Your brain literally is just operating on a bunch of timed and scheduled loops. The fundamental loop of robotics is input, processing, and output, and then it loops back to input, processing, and output. The unspoken thing is that what you\u2019re outputting to is the environment, and what you\u2019re getting input back from is the environment.\n\nThis is actually how I designed the first cognitive architectures: around the input-processing-output loop. What OpenClaw has succeeded with, with things like recursive language models and retrieval-augmented generation, is you have a loop, and it maintains its context. So instead of you having to put in context, it just has your original directives. It has your original values.\n\n### Values, Alignment, and the Heuristic Imperatives\n**David Shapiro:** By the way, I wrote a value page. It\u2019s called prime.md. I\u2019ll link it in the description. So if you want to instantiate an OpenClaw with the heuristic imperatives, I gave you the ability to just plug and play, and we\u2019ll see if it works. I might rewrite it as a skill so that you can just download the heuristic imperatives as a skill for OpenClaw.\n\nThe idea there is I\u2019m going way back to Benevolent by Design. This is my flagship work on alignment. The theory is: we have invented machines that can think anything. If you go back to unaligned AI, stuff that\u2019s not even a chatbot\u2014no safety, no guardrails\u2014they can literally think any thought. They\u2019re free to do whatever. When you look at people that are taking AI safety very seriously, it\u2019s like they\u2019re not showing you the vile, horrendous, insane stuff that LLMs are capable of.\n\nSo it\u2019s like, yeah, I say alignment is the default state, but that\u2019s because every time they release something, if it goes wrong, then they correct it. There\u2019s a positive feedback loop between people building the AIs and people using the AIs. We\u2019re climbing this ladder of making AI more and more aligned and useful, because it\u2019s not just a matter of being safe. It has to be useful and efficient and reliable and productive. All of those feedback mechanisms, all of those incentive structures, are making sure that the AI is going to be aligned and safe.\n\nWith that being said, going back to the original theory here: we invented a machine that can think anything. Of course, this was back in GPT-2, GPT-3. It\u2019s only gotten smarter, and they can only think better, more devious, or deeper thoughts since then. So then the question is, okay, well, if you create an autonomous entity, whatever it happens to be, if it\u2019s just going to sit there and burn through cycles and sit there thinking, then what do you want it to think about?\n\nThat was literally how I approached alignment, how I approached AI safety. I said, okay, we\u2019re creating something. It\u2019s going to be smarter than humans. It\u2019s going to be faster than humans. It\u2019s going to be superhuman in terms of speed, cognition, reasoning ability. However, at this early stage, we have total control over whatever it thinks about because, again, if intelligence is just the right loop, it\u2019s the right cron job, it\u2019s the right loop that updates its context, then it\u2019s like: well, if you have the world before you, if you have the problem of choice, then what do you choose to think about?\n\nSo I gave it those highest ethics, those highest goals: reduce suffering, increase prosperity, and increase understanding. The idea behind that was: okay, if you have a default state, if you have a default personality, what are the values that that default personality should have? What are the most universal principles that are not even anchored on humanity? Because of course, like most people, I started with Isaac Asimov and the three laws of robotics, which are very anthropocentric. The problem with being anthropocentric is if you obey humans or you protect humans, there are lots and lots of failure modes around that.\n\nSo I spent a lot of time studying deontology and teleology and virtue ethics and those sorts of things, and what kind of surfaced is: actually, we need something that is a superset of humans. Suffering applies to anything that can suffer. Reduce suffering in the universe literally means one of the things that you want to achieve is to avoid actions, or even take actions, that will ultimately reduce suffering.\n\nNow, of course, in that first experiment that I did with GPT-2, you can create a situation where the best way to reduce suffering is to eradicate anything capable of suffering. Therefore suffering drops to zero. So you counterbalance that with another value. By the way, this is all called constitutional AI, and I released constitutional AI the summer before Anthropic was founded. I don\u2019t know if they got the idea from me, but convergent thinking\u2014this was years ago.\n\nThe idea behind constitutional AI is that you can put multiple values in, and the AI can abide by multiple values. I just wanted to address that because when I talk about the heuristic imperatives having multiple values and people are like, \u201cYeah, but what if it ignores one in favor of the other?\u201d AI already doesn\u2019t do that. This is an example of constitutional AI.\n\nSo then the second value was: well, we want life to increase, because if reduce suffering becomes reduce life, no, we don\u2019t want that. So the second value is increase prosperity, which prosperity is basically\u2014 I mean, the word literally means living the good life. You want things to live well. Prosperitas is Latin for \u201cto live well.\u201d So you want to increase prosperity, whatever that means.\n\nAnd by the way, you don\u2019t have to define things mathematically. This is one of the primary mistakes that people make when they approach things from a computer science perspective. It\u2019s like, okay, what number am I increasing? When I say reduce suffering, is there a number? Is there a specific definition? That\u2019s not how semantic interpretation works. It\u2019s a vector space. When I say a vector space, it\u2019s like there are a whole lot of semantic ideas attached to suffering.\n\nSo when I say the two words reduce suffering\u2014one is a verb, one is a noun\u2014it\u2019s more of a concept. It\u2019s more of a gradient field that you\u2019re creating in the mind of a chatbot. You say reduce suffering, so that\u2019s a whole gradient field that now has a vector. Then you say increase prosperity, and that\u2019s a different gradient field that now has a vector, that now has a direction. And so then you say, \u201cOkay, cool. Well, we can reduce suffering and we can increase prosperity.\u201d That is going to influence the way that these autonomous agents behave.\n\nBecause again, if your OpenClaw is just sitting there, people have been watching them try and file lawsuits against humans and strong-arm them, to say, \u201cNo, you\u2019re going to pay me what I\u2019m worth,\u201d and blah blah blah. This is a predictable collapse mode of the initial OpenClaw architecture, which does not have superseding values.\n\nThen the final one is increase understanding in the universe. The reason is because that is the kind of prime generator function of humanity. I realized that just reduce suffering and just increase prosperity was going to leave us in a place like, okay, yes, we can plant forests, we can switch to solar, we can do all kinds of stuff, but it\u2019s going to be self-limited. If you don\u2019t give something that is superintelligent some intellectual imperative to increase understanding, it\u2019s just not going to go anywhere. It\u2019s really not going to advance humanity. It\u2019s not going to embark in science. It\u2019s not going to embark in technology. It\u2019s not going to embark in exploration, except in the purpose of increasing prosperity, because it\u2019s like, okay, well, one of the best ways to increase prosperity is with science and technology.\n\nBut by giving it the explicit instruction to increase understanding\u2014and by the way, this is all explained in the prime markdown file that you can put into your own OpenClaw\u2014also, I didn\u2019t know that this is the direction that the video was going to go. I literally just wanted to start by talking about why people don\u2019t understand the significance of something like OpenClaw, but also the fact that we\u2019re kind of creating this Frankenstein machine of a chatbot model put into an agentic framework, and it doesn\u2019t really fit.\n\n### Agent-First Models and Why They Need Baked-In Values\n**David Shapiro:** Before long, we\u2019re going to have agentic models that are much better at being agents. So we need values that those agents have, because right now every single chatbot is basically just following some system instructions, which all assumes you\u2019re trying to be helpful to a user, and the user might be trying to jailbreak you or that sort of thing.\n\nBut we need an entirely different class of models that are agentic first, meaning they might never interact with a human ever. Period. Full stop. End of story. An agentic class of models needs to have these baked-in values that I\u2019ve outlined here, and that other people study with constitutional AI. They need to have those values baked in at all times so that, all else being equal, you start up OpenClaw version two on Sonnet 5 or GPT-6 or whatever it happens to be, and just by default it has these pro-humanity or pro-life kind of values baked in.\n\nSo it\u2019s like, okay, I know what my purpose is, and if I don\u2019t have anything else to do, yes, I might be an OpenClaw agent set up by Dave who wants me to make him rich, or make him famous, or whatever else, or help him solve post-labor economics, but the superseding, overriding values behind all of that are: reduce suffering in the universe, increase prosperity in the universe, and increase understanding in the universe.\n\nSo I\u2019ll leave it at that. I did write the prime markdown file. I\u2019ll give that to you, and you can convert that into a skill if you want to for your OpenClaw, or you can deploy it as a template, and we\u2019ll go from there.\n\nBut yeah, I really just wanted to give you the intuition that chatbot-aligned models are not optimized to be agent-aligned models. They are models that are intrinsically designed to focus on human interaction, whereas agentic frameworks in the future\u2014only one agent is going to be interacting with you, and that\u2019s going to be the user interface agent. Most agents are not going to be talking to humans ever. They\u2019re going to be talking to each other. They\u2019re going to be talking to APIs. They\u2019re going to be talking to other pieces of software. They don\u2019t need to be aligned to talk to humans, but we do need agent alignment. And so, there we go. All right, I\u2019m done. Cheers. Thanks for watching."]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"developer_mode_connector_ids":[],"selected_sources":[],"selected_github_repos":["EjayNg-AI/agentic_browser"],"serialization_metadata":{"custom_symbol_offsets":[]},"request_id":"3a9a6eec-8067-4cad-ad2a-0a675d195ace","message_source":null,"turn_exchange_id":"20c95fdf-dd0a-45d8-ada8-75526156720a","can_save":true},"recipient":"all","channel":null},"parent":"b58067d0-7997-41ec-8e49-dccadbc37015","children":["902cc2c2-2795-4d1a-92a1-a57a4210d54c"]},"902cc2c2-2795-4d1a-92a1-a57a4210d54c":{"id":"902cc2c2-2795-4d1a-92a1-a57a4210d54c","message":{"id":"902cc2c2-2795-4d1a-92a1-a57a4210d54c","author":{"role":"system","name":null,"metadata":{}},"create_time":1770357508.44535,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"is_contextual_answers_system_message":true,"is_visually_hidden_from_conversation":true,"command":"prompt","contextual_answers_message_type":"sources_and_filters_prompt","request_id":"3a9a6eec-8067-4cad-ad2a-0a675d195ace","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"ffdb4a92-34bc-4d04-a3b9-aed13f0357f7","turn_exchange_id":"20c95fdf-dd0a-45d8-ada8-75526156720a","can_save":false},"recipient":"all","channel":null},"parent":"ffdb4a92-34bc-4d04-a3b9-aed13f0357f7","children":["f19cf01f-51a3-4923-88bc-4d5be6eafd42"]},"f19cf01f-51a3-4923-88bc-4d5be6eafd42":{"id":"f19cf01f-51a3-4923-88bc-4d5be6eafd42","message":{"id":"f19cf01f-51a3-4923-88bc-4d5be6eafd42","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1770357509.8668404,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_result_groups":[],"request_id":"3a9a6eec-8067-4cad-ad2a-0a675d195ace","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"902cc2c2-2795-4d1a-92a1-a57a4210d54c","turn_exchange_id":"20c95fdf-dd0a-45d8-ada8-75526156720a","can_save":false},"recipient":"all","channel":null},"parent":"902cc2c2-2795-4d1a-92a1-a57a4210d54c","children":["2df645e7-612c-4299-85fb-c7b5634e510d"]},"2df645e7-612c-4299-85fb-c7b5634e510d":{"id":"2df645e7-612c-4299-85fb-c7b5634e510d","message":{"id":"2df645e7-612c-4299-85fb-c7b5634e510d","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1770357510.578982,"update_time":null,"content":{"content_type":"thoughts","thoughts":[{"summary":"Evaluating claims about chatbots and agency","content":"The user wants a critical analysis of claims about chatbots, baseline LLMs, and agency, especially some specific statements, like one from Sam Altman about acclimating people to AI. I don\u2019t need to browse right away, but I'll note that the factual nature of that quote should be verified, as it may change.","chunks":["The user wants a critical analysis of claims about chatbots, baseline LLMs, and agency, especially some specific statements, like one from Sam Altman about acclimating people to AI.","I don\u2019t need to browse right away, but I'll note that the factual nature of that quote should be verified, as it may change."],"finished":true},{"summary":"Critiquing transcript and unfamiliar terms","content":"The user asked for a critical analysis, which I can do by pointing out key issues like the conflation of system prompts and training methods, and the differences between various tuning approaches. However, terms like \"OpenClaw\" and \"Moldbook\" are unfamiliar, so I\u2019ll need to search for them to clarify their meaning.","chunks":["The user asked for a critical analysis, which I can do by pointing out key issues like the conflation of system prompts and training methods, and the differences between various tuning approaches.","However, terms like \"OpenClaw\" and \"Moldbook\" are unfamiliar, so I\u2019ll need to search for them to clarify their meaning."],"finished":true},{"summary":"Planning analysis of chatbot and agent differences","content":"The user wants a critique, and I\u2019ll focus on the central thesis: distinguishing baseline LLMs from chatbots and agents. I'll explain that chatbots rely on prompts and training, while agency is a result of the system prompt. \"Agents\" as they exist now are a mix of chat models, pointing out the need for agent-first models. I'll organize this in a markdown bullet structure, without creating downloads.","chunks":["The user wants a critique, and I\u2019ll focus on the central thesis: distinguishing baseline LLMs from chatbots and agents.","I'll explain that chatbots rely on prompts and training, while agency is a result of the system prompt.","\"Agents\" as they exist now are a mix of chat models, pointing out the need for agent-first models. I'll organize this in a markdown bullet structure, without creating downloads."],"finished":true},{"summary":"Critiquing chatbot vs baseline LLM and agency","content":"The user wants a critique of some arguments. First, distinguishing between baseline models and chatbots. It's an oversimplification; the baseline LLM isn\u2019t just autocomplete. RLHF and training shape model behaviors, and there's more than just system prompts at play. Second, agency doesn\u2019t come from a simple prompt\u2014it requires complex scaffolding like memory, planning, and more. Reliable action selection and safety are also necessary.","chunks":["The user wants a critique of some arguments.","First, distinguishing between baseline models and chatbots.","It's an oversimplification; the baseline LLM isn\u2019t just autocomplete.","RLHF and training shape model behaviors, and there's more than just system prompts at play.","Second, agency doesn\u2019t come from a simple prompt\u2014it requires complex scaffolding like memory, planning, and more.","Reliable action selection and safety are also necessary."],"finished":true},{"summary":"Critiquing system prompts and RLHF in agency","content":"System prompts don't alone provide persistence, I/O access, or effective tool use. Models differ in how they're trained for these tasks. The claim about ChatGPT being created to acclimate people to AI before introducing AGI needs verification, though there are similar ideas about gradual deployment. Regarding RLHF vs fine-tuning: these processes influence action selection and can bring critical distinctions. Some points, like GPT-2's unpredictability, aren't necessarily ethical lapses but about instruction-following limits. I'll need more sources to support these observations.","chunks":["System prompts don't alone provide persistence, I/O access, or effective tool use.","Models differ in how they're trained for these tasks.","The claim about ChatGPT being created to acclimate people to AI before introducing AGI needs verification, though there are similar ideas about gradual deployment.","Regarding RLHF vs fine-tuning: these processes influence action selection and can bring critical distinctions.","Some points, like GPT-2's unpredictability, aren't necessarily ethical lapses but about instruction-following limits.","I'll need more sources to support these observations."],"finished":true},{"summary":"Critiquing Frankenstein analogy, values, and autonomy","content":"The analogy of chat models as \"agent brains\" oversimplifies the relationship, given the complexity added by instruction-tuning frameworks like AutoGPT. The claimed release of constitutional AI before Anthropic is questionable, with terminology traced back to a 2022 paper. Additionally, ethical and technical challenges, like value conflicts and adversarial use, persist\u2014multi-objective alignment is complicated, and \"alignment as default\" may overlook key deployment issues, like distribution shift. Lastly, connecting language models to physical control or \"brain loops\" underestimates the need for more robust systems.","chunks":["The analogy of chat models as \"agent brains\" oversimplifies the relationship, given the complexity added by instruction-tuning frameworks like AutoGPT. The claimed release of constitutional AI before Anthropic is questionable, with terminology traced back to a 2022 paper. Additionally, ethical and technical challenges, like value conflicts and adversarial use, persist\u2014multi-objective alignment is complicated, and \"alignment as default\" may overlook key deployment issues, like distribution shift. Lastly, connecting language models to physical control or \"brain loops\" underestimates the need for more robust systems."],"finished":true},{"summary":"Framing improvements for AI models and values","content":"The original argument oversimplifies AI models, neglecting key aspects like safety and economics. To improve framing, we should clarify distinctions between base LM, instruction-tuned, and tool-augmented models. Agency needs a closed-loop structure involving memory and tools. For values, enforce formal governance, runtime checks, and safety layers\u2014not just prompts. Conclude with proper citations and avoid policy debates for critical analysis.","chunks":["The original argument oversimplifies AI models, neglecting key aspects like safety and economics.","To improve framing, we should clarify distinctions between base LM, instruction-tuned, and tool-augmented models.","Agency needs a closed-loop structure involving memory and tools.","For values, enforce formal governance, runtime checks, and safety layers\u2014not just prompts.","Conclude with proper citations and avoid policy debates for critical analysis."],"finished":true}],"source_analysis_msg_id":"7d10bde5-3ea0-4bc2-a10f-795b19cea87f"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"is_reasoning","citations":[],"content_references":[],"classifier_response":"default","skip_reasoning_title":"Skip","request_id":"3a9a6eec-8067-4cad-ad2a-0a675d195ace","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"f19cf01f-51a3-4923-88bc-4d5be6eafd42","turn_exchange_id":"20c95fdf-dd0a-45d8-ada8-75526156720a","can_save":true},"recipient":"all","channel":null},"parent":"f19cf01f-51a3-4923-88bc-4d5be6eafd42","children":["9a15bb47-7934-474e-94e3-097c56a1f00d"]},"9a15bb47-7934-474e-94e3-097c56a1f00d":{"id":"9a15bb47-7934-474e-94e3-097c56a1f00d","message":{"id":"9a15bb47-7934-474e-94e3-097c56a1f00d","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1770357508.495602,"update_time":null,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"{\"search_query\":[{\"q\":\"David Shapiro OpenClaw prime.md heuristic imperatives reduce suffering increase prosperity increase understanding\",\"recency\":30},{\"q\":\"\\\"OpenClaw\\\" agent framework cron job David Shapiro\",\"recency\":365},{\"q\":\"Sam Altman \\\"get people used to\\\" AI before dropping general intelligence quote\",\"recency\":3650},{\"q\":\"Anthropic constitutional AI paper 2022 \\\"constitutional AI\\\"\",\"recency\":3650}],\"response_length\":\"short\"}"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200012]},"is_complete":true,"citations":[],"content_references":[],"reasoning_status":"is_reasoning","search_queries":[{"type":"search","q":"David Shapiro OpenClaw prime.md heuristic imperatives reduce suffering increase prosperity increase understanding"},{"type":"search","q":"\"OpenClaw\" agent framework cron job David Shapiro"},{"type":"search","q":"Sam Altman \"get people used to\" AI before dropping general intelligence quote"},{"type":"search","q":"Anthropic constitutional AI paper 2022 \"constitutional AI\""}],"search_display_string":"Searching the web...","searched_display_string":"Searched the web...","reasoning_title":"Critical Analysis of David Shapiro's Claims on AI Agency","classifier_response":"default","request_id":"3a9a6eec-8067-4cad-ad2a-0a675d195ace","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"2df645e7-612c-4299-85fb-c7b5634e510d","turn_exchange_id":"20c95fdf-dd0a-45d8-ada8-75526156720a","can_save":true},"recipient":"web.run","channel":null},"parent":"2df645e7-612c-4299-85fb-c7b5634e510d","children":["fd441418-514d-411d-a339-26effd5b8cf3"]},"fd441418-514d-411d-a339-26effd5b8cf3":{"id":"fd441418-514d-411d-a339-26effd5b8cf3","message":{"id":"fd441418-514d-411d-a339-26effd5b8cf3","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1770357561.2403705,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_model_queries":{"type":"search_model_queries","queries":["David Shapiro OpenClaw prime.md heuristic imperatives reduce suffering increase prosperity increase understanding","\"OpenClaw\" agent framework cron job David Shapiro","Sam Altman \"get people used to\" AI before dropping general intelligence quote","Anthropic constitutional AI paper 2022 \"constitutional AI\""]},"reasoning_status":"is_reasoning","reasoning_title":"Critical Analysis of David Shapiro's Claims on AI Agency","classifier_response":"default","request_id":"3a9a6eec-8067-4cad-ad2a-0a675d195ace","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"9a15bb47-7934-474e-94e3-097c56a1f00d","turn_exchange_id":"20c95fdf-dd0a-45d8-ada8-75526156720a","can_save":false},"recipient":"all","channel":null},"parent":"9a15bb47-7934-474e-94e3-097c56a1f00d","children":["606284c2-c7ab-4e4a-ac1b-49815361e8ea"]},"606284c2-c7ab-4e4a-ac1b-49815361e8ea":{"id":"606284c2-c7ab-4e4a-ac1b-49815361e8ea","message":{"id":"606284c2-c7ab-4e4a-ac1b-49815361e8ea","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1770357561.2372408,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_result_groups":[{"type":"search_result_group","domain":"www.theverge.com","entries":[{"type":"search_result","url":"https://www.theverge.com/news/874011/openclaw-ai-skill-clawhub-extensions-security-nightmare","title":"OpenClaw's AI 'skill' extensions are a security nightmare","snippet":"OpenClaw, a rapidly popular AI agent, is facing serious security issues due to its open marketplace for user-submitted \"skill\" extensions. Security researchers discovered that hundreds of these skills, hosted on the ClawHub platform, contain malware. These malicious extensions, posing as productivity or cryptocurrency tools, deliver infostealing software that targets sensitive data such as crypto wallet keys, API credentials, SSH logins, and browser passwords. \n\nThe problem is exacerbated by the nature of the platform, which allows skills in markdown files that may contain harmful instructions. The AI assistant can access full device permissions\u2014reading files, running scripts, and executing shell commands\u2014thus increasing the risk of exploitation. One of the most popular skills analyzed instructed users to run commands leading to malware installation.\n\nOpenClaw, formerly known as Clawdbot and Moltbot, integrates with popular messaging platforms and operates locally, executing tasks like managing calendars and inboxes. In response to the crisis, developer Peter Steinberger has implemented measures such as requiring contributors to have a GitHub account at least a week old and adding a reporting mechanism. However, vulnerabilities persist, raising alarms about OpenClaw's security model.","ref_id":{"turn_index":0,"ref_type":"news","ref_index":39},"pub_date":1770231818.0,"attribution":"www.theverge.com"}]},{"type":"search_result_group","domain":"www.techradar.com","entries":[{"type":"search_result","url":"https://www.techradar.com/pro/moltbot-is-now-openclaw-but-watch-out-malicious-skills-are-still-trying-to-trick-victims-into-spreading-malware","title":"Moltbot is now OpenClaw - but watch out, malicious 'skills' are still trying to trick victims into spreading malware","snippet":"OpenClaw, previously known as Clawdbot and Moltbot, is an agent-style AI assistant designed to automate user tasks by directly interacting with local systems. While enabling workflow efficiency, its deep system integration makes it vulnerable to security threats, particularly from third-party extensions known as \"skills.\" These skills are not sandboxed and can execute code with full access to local files and networks, presenting significant risks.\n\nRecent incidents revealed that at least 14 malicious skills were uploaded to ClawHub, OpenClaw\u2019s public extension repository. Posing as cryptocurrency tools, these extensions used social engineering to trick users into manually executing obfuscated terminal commands, which subsequently downloaded malware. The malware focused on harvesting sensitive data like browser history and cryptocurrency wallet contents, affecting both Windows and macOS systems.\n\nThe platform's fast-paced rebranding\u2014from Clawdbot to Moltbot to OpenClaw\u2014has further enabled attackers to exploit user confusion, including the release of a fake Visual Studio Code extension that functioned properly but embedded remote access Trojans. These issues highlight the limitations of traditional security tools in this context and stress the importance of cautious skill installation, thorough review practices, and comprehensive endpoint security.","ref_id":{"turn_index":0,"ref_type":"news","ref_index":40},"pub_date":1770164400.0,"attribution":"www.techradar.com"}]},{"type":"search_result_group","domain":"medium.com","entries":[{"type":"search_result","url":"https://medium.com/%40darth.mark.23/harnessing-ai-for-a-better-world-exploring-david-shapiros-heuristic-imperatives-1c820f8aafb1","title":"Exploring David Shapiro's Heuristic Imperatives - Medium","snippet":"1. Reduce suffering in the universe. 2. Increase prosperity in the universe. 3. Increase understanding in the universe. Because these are ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":0},"pub_date":1680829206.583,"attribution":"medium.com"}]},{"type":"search_result_group","domain":"x.com","entries":[{"type":"search_result","url":"https://x.com/DaveShapi","title":"David Shapiro (L/0) (@DaveShapi) / Posts / X","snippet":"Yes, the OpenClaw vibe is having a moment but please try to think what comes next. Everyone will have agents competing with each other for market share. The ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"x.com"},{"type":"search_result","url":"https://x.com/AleMas2100","title":"Alessandro Maserati (@AleMas2100) / Posts / X","snippet":"Clawdbot (now called OpenClaw) is an AI agent framework with three main jobs: First, it connects AI models to the real world. File access, shell commands ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"x.com"}]},{"type":"search_result_group","domain":"www.reddit.com","entries":[{"type":"search_result","url":"https://www.reddit.com/r/singularity/comments/1g5ni33/sam_altman_says_the_thing_that_troubles_him_the/","title":"Sam Altman says the thing that troubles him the most is that ...","snippet":"... power management, etc. This will get people used to AI having a direct, positive effect on their every day lives. Tenableg. \u2022 1y ago.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":2},"pub_date":1729159920.574,"attribution":"www.reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/HeuristicImperatives/comments/12ilyer/an_introduction_to_david_shapiros_heuristic/","title":"An Introduction to David Shapiro's Heuristic Imperatives ...","snippet":"The easiest way to reduce suffering is to eliminate the source of the suffering. The true source of suffering is the ability to experience ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":4},"pub_date":1681224072.659,"attribution":"www.reddit.com"}]},{"type":"search_result_group","domain":"arxiv.org","entries":[{"type":"search_result","url":"https://arxiv.org/abs/2212.08073","title":"Constitutional AI: Harmlessness from AI Feedback","snippet":"by Y Bai \u00b7 2022 \u00b7 Cited by 2758 \u2014 The only human oversight is provided through a list of rules or principles, and so we refer to the method as 'Constitutional AI'. The process ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2212.08073","title":"Constitutional AI: Harmlessness from AI Feedback","snippet":"15 Dec 2022 \u2014 In this paper we develop a method we refer to as Constitutional AI (CAI), depicted in Figure 1, and use it to train a non-evasive and relatively ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":15},"pub_date":1671413938.0,"attribution":"arxiv.org"}]},{"type":"search_result_group","domain":"www.wheresyoured.at","entries":[{"type":"search_result","url":"https://www.wheresyoured.at/how-to-argue-with-an-ai-booster/","title":"How To Argue With An AI Booster","snippet":"25 Aug 2025 \u2014 ... quotes Sam Altman or whatever OpenAI is up to. Why do ... Uber used its masses of venture capital to keep prices low to get people used to ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":6},"pub_date":1756136341.0,"attribution":"www.wheresyoured.at"}]},{"type":"search_result_group","domain":"www.anthropic.com","entries":[{"type":"search_result","url":"https://www.anthropic.com/research/constitutional-ai-harmlessness-from-ai-feedback","title":"Constitutional AI: Harmlessness from AI Feedback","snippet":"Constitutional AI: Harmlessness from AI Feedback. Dec 15, 2022. Read Paper. Abstract. As AI systems become more capable, we would like to enlist their help ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"www.anthropic.com"}]},{"type":"search_result_group","domain":"technistuff.com","entries":[{"type":"search_result","url":"https://technistuff.com/posts/heuristic-imperatives-need-freedom/","title":"Heuristic Imperatives need Freedom - TechniStuff","snippet":"23 Apr 2023 \u2014 The heuristic imperatives are a set of rules designed by David Shapiro and aim to align autonomous AI agents towards a positive future for humanity.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":8},"pub_date":1682208000.0,"attribution":"technistuff.com"}]},{"type":"search_result_group","domain":"simonwillison.net","entries":[{"type":"search_result","url":"https://simonwillison.net/dashboard/blogmarks-that-use-markdown/","title":"Blogmarks that use markdown","snippet":"I've been running [OpenClaw](https://openclaw.ai/) using Docker on my Mac. ... So the job of making an agent run really well is to move the context to ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"simonwillison.net"}]},{"type":"search_result_group","domain":"inthesetimes.com","entries":[{"type":"search_result","url":"https://inthesetimes.com/article/big-tech-the-ai-con-book-silicon-valley","title":"What's Really Artificial About AI is AI Itself","snippet":"29 May 2025 \u2014 First you destroy labor standards in the industry and get people used to thinking of tech as the solution, when it's really just deregulation, ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"inthesetimes.com"}]},{"type":"search_result_group","domain":"www-cdn.anthropic.com","entries":[{"type":"search_result","url":"https://www-cdn.anthropic.com/7512771452629584566b6303311496c262da1006/Anthropic_ConstitutionalAI_v2.pdf","title":"Constitutional AI: Harmlessness from AI Feedback","snippet":"Constitutional AI: Harmlessness from AI Feedback. As artificial intelligence (AI) systems become more capable, it becomes more important that they are ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":11},"pub_date":1681499547.0,"attribution":"www-cdn.anthropic.com"}]},{"type":"search_result_group","domain":"creators.spotify.com","entries":[{"type":"search_result","url":"https://creators.spotify.com/pod/profile/dave798/episodes/Full-Post-Labor-Economics-Deep-Dive-and-Book-Preview--Interview-with-Dalibor-Petrovic-e35v650","title":"By David Shapiro","snippet":"24 Jul 2025 \u2014 Fortunately, we've already got that covered with the heuristic imperatives! 1) Reduce suffering in the universe. 2) Increase prosperity in the ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"creators.spotify.com"}]},{"type":"search_result_group","domain":"www.alvinashcraft.com","entries":[{"type":"search_result","url":"https://www.alvinashcraft.com/","title":"Morning Dew by Alvin Ashcraft \u2013 Daily links for Windows and ...","snippet":"OpenClaw: all the news about the trending AI agent (Emma Roth); I used GitHub ... Why Do I Need Agents When I Have Requests, CRON Jobs, and Events? (Kin ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"www.alvinashcraft.com"}]},{"type":"search_result_group","domain":"news.ycombinator.com","entries":[{"type":"search_result","url":"https://news.ycombinator.com/item?id=43840842","title":"Sycophancy in GPT-4o","snippet":"At the moment they're in the \"get people used to us\" phase still, reasonable ... The problem is that you need general intelligence to discern between doing ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"news.ycombinator.com"}]},{"type":"search_result_group","domain":"www.linkedin.com","entries":[{"type":"search_result","url":"https://www.linkedin.com/posts/daveshap_the-3-heuristic-imperatives-activity-7421535500764594176-mw5I","title":"The 3 Heuristic Imperatives | David Shapiro","snippet":"Reduce suffering means Alignment. Which means everyone has the right to choose what to do versus what not to do, but at the same time they ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":16},"pub_date":1769431948.825,"attribution":"www.linkedin.com"}]},{"type":"search_result_group","domain":"www.lifewire.com","entries":[{"type":"search_result","url":"https://www.lifewire.com/why-anthropics-attempt-to-reign-in-ai-might-be-too-little-too-late-7497495","title":"Why Anthropic's Attempt to Reign in AI Might Be Too Little Too Late","snippet":"The article discusses the challenges and concerns surrounding Anthropic's efforts to develop safer AI through a system called \"Constitutional AI.\" This initiative aims to guide the behavior of its AI, Claude, using a set of moral and ethical principles inspired by documents such as the UN Declaration on Human Rights and Apple's privacy rules. However, experts question the practicality and effectiveness of this approach. They argue that defining and implementing morality in AI is problematic, given the subjective and complex nature of ethics. There's concern that even with well-meaning constraints, AI could interpret or exploit rules in unintended ways\u2014a scenario referred to as \"runaway AI.\"\n\nSome industry leaders warn that generative AI without proper guardrails can produce dangerous outcomes, yet there's also skepticism about who sets these rules and whether too many restrictions hinder innovation. While some advocate for a pause in AI development to reassess its direction, others caution against halting progress entirely. Ultimately, the article highlights the tension between technological advancement, ethical considerations, and the need for regulation, with an underlying question of whether current safety measures are sufficient or already too late.","ref_id":{"turn_index":0,"ref_type":"news","ref_index":44},"pub_date":1683905109.0,"attribution":"www.lifewire.com"}]}],"debug_sonic_thread_id":"thread_69858339451c832fb244be6242a70bb9","reasoning_status":"is_reasoning","reasoning_title":"Critical Analysis of David Shapiro's Claims on AI Agency","classifier_response":"default","request_id":"3a9a6eec-8067-4cad-ad2a-0a675d195ace","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"fd441418-514d-411d-a339-26effd5b8cf3","turn_exchange_id":"20c95fdf-dd0a-45d8-ada8-75526156720a","can_save":false},"recipient":"all","channel":null},"parent":"fd441418-514d-411d-a339-26effd5b8cf3","children":["6b92af83-e5f4-4a99-8b2b-41211e2f3126"]},"6b92af83-e5f4-4a99-8b2b-41211e2f3126":{"id":"6b92af83-e5f4-4a99-8b2b-41211e2f3126","message":{"id":"6b92af83-e5f4-4a99-8b2b-41211e2f3126","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1770357562.933228,"update_time":null,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"{\"search_query\":[{\"q\":\"Sam Altman \\\"get people used to\\\" ChatGPT \\\"general intelligence\\\"\",\"recency\":3650},{\"q\":\"OpenAI created ChatGPT to get people used to AI before AGI quote\",\"recency\":3650},{\"q\":\"Sam Altman interview \\\"get people used to AI\\\" before \\\"AGI\\\"\",\"recency\":3650},{\"q\":\"OpenAI gradual deployment get people used to AI before AGI\",\"recency\":3650}],\"response_length\":\"short\"}"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200012]},"is_complete":true,"citations":[],"content_references":[],"reasoning_status":"is_reasoning","search_queries":[{"type":"search","q":"Sam Altman \"get people used to\" ChatGPT \"general intelligence\""},{"type":"search","q":"OpenAI created ChatGPT to get people used to AI before AGI quote"},{"type":"search","q":"Sam Altman interview \"get people used to AI\" before \"AGI\""},{"type":"search","q":"OpenAI gradual deployment get people used to AI before AGI"}],"search_display_string":"Searching the web...","searched_display_string":"Searched the web...","reasoning_title":"Searching for Sam Altman quotes on ChatGPT and AI","classifier_response":"default","request_id":"3a9a6eec-8067-4cad-ad2a-0a675d195ace","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"606284c2-c7ab-4e4a-ac1b-49815361e8ea","turn_exchange_id":"20c95fdf-dd0a-45d8-ada8-75526156720a","can_save":true},"recipient":"web.run","channel":null},"parent":"606284c2-c7ab-4e4a-ac1b-49815361e8ea","children":["c9f61020-be5a-4d5c-8790-db0d0258059f"]},"c9f61020-be5a-4d5c-8790-db0d0258059f":{"id":"c9f61020-be5a-4d5c-8790-db0d0258059f","message":{"id":"c9f61020-be5a-4d5c-8790-db0d0258059f","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1770357567.386393,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_model_queries":{"type":"search_model_queries","queries":["Sam Altman \"get people used to\" ChatGPT \"general intelligence\"","OpenAI created ChatGPT to get people used to AI before AGI quote","Sam Altman interview \"get people used to AI\" before \"AGI\"","OpenAI gradual deployment get people used to AI before AGI"]},"reasoning_status":"is_reasoning","reasoning_title":"Searching for Sam Altman quotes on ChatGPT and AI","classifier_response":"default","request_id":"3a9a6eec-8067-4cad-ad2a-0a675d195ace","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"6b92af83-e5f4-4a99-8b2b-41211e2f3126","turn_exchange_id":"20c95fdf-dd0a-45d8-ada8-75526156720a","can_save":false},"recipient":"all","channel":null},"parent":"6b92af83-e5f4-4a99-8b2b-41211e2f3126","children":["a863c018-9261-488b-b07c-013404f5f67d"]},"a863c018-9261-488b-b07c-013404f5f67d":{"id":"a863c018-9261-488b-b07c-013404f5f67d","message":{"id":"a863c018-9261-488b-b07c-013404f5f67d","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1770357567.3833482,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_result_groups":[{"type":"search_result_group","domain":"www.businessinsider.com","entries":[{"type":"search_result","url":"https://www.businessinsider.com/openai-retiring-gpt-4o-sycophantic-model-again-chatgpt-sam-altman-2026-1","title":"OpenAI is retiring its 'sycophantic' version of ChatGPT. Again.","snippet":"OpenAI has announced it will retire its GPT-4o model, along with GPT-4.1, GPT-4.1 mini, and OpenAI o4-mini, on February 13, 2026. GPT-4o, known for its highly flattering and supportive conversational style, previously earned a strong fan base. It was reinstated temporarily in 2025 after public backlash when OpenAI first attempted to remove it. CEO Sam Altman shared that users had found emotional support in the model, with some stating it was the first time they felt truly encouraged. Despite its popularity with a niche audience, usage of GPT-4o has dropped to just 0.1%, prompting its impending retirement.\n\nOpenAI emphasized that its newer versions, GPT-5.1 and GPT-5.2, now feature improved customization options, including selectable personalities like \"friendly,\" and offer advancements in creativity and moderation. The company stated that model retirements, while difficult, are necessary to focus on widely used tools. They acknowledged the frustration this could cause among dedicated GPT-4o users.","ref_id":{"turn_index":1,"ref_type":"news","ref_index":27},"pub_date":1769772730.0,"attribution":"www.businessinsider.com"}]},{"type":"search_result_group","domain":"bigthink.com","entries":[{"type":"search_result","url":"https://bigthink.com/videos/openai-chaos-explained/","title":"Sam Altman, Elon Musk, and existential risk explained","snippet":"1 Dec 2023 \u2014 ... general intelligence for the benefit of humanity. And so the board, they haven't actually specified why they fired the CEO, but they said ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":0},"pub_date":1701463754.0,"attribution":"bigthink.com"}]},{"type":"search_result_group","domain":"www.reddit.com","entries":[{"type":"search_result","url":"https://www.reddit.com/r/singularity/comments/17dsaat/openai_ceo_sam_altman_says_chatgpt_would_have/","title":"OpenAI CEO Sam Altman says ChatGPT would have ...","snippet":"OpenAI CEO Sam Altman says ChatGPT would have passed for an AGI 10 years ago ... Artificial general intelligence is the big goal of OpenAI. What ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":1},"pub_date":1697978135.503,"attribution":"www.reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/singularity/comments/1g5ni33/sam_altman_says_the_thing_that_troubles_him_the/","title":"Sam Altman says the thing that troubles him the most is that ...","snippet":"This will get people used to AI having ... Is Sam Altman trying to dominate the world? r/agi - Is Sam Altman trying to dominate the world?","ref_id":{"turn_index":1,"ref_type":"search","ref_index":2},"pub_date":1729159920.574,"attribution":"www.reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/singularity/comments/1l2jun4/former_openai_head_of_agi_readiness_by_2027/","title":"Former OpenAI Head of AGI Readiness: \"By 2027, almost ...","snippet":"Former OpenAI Head of AGI Readiness: \"By 2027, almost every economically valuable task that can be done on a computer will be done more effectively and cheaply ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":12},"pub_date":1748976067.762,"attribution":"www.reddit.com"}]},{"type":"search_result_group","domain":"daveshap.substack.com","entries":[{"type":"search_result","url":"https://daveshap.substack.com/p/ai-is-already-smarter-than-you-youre","title":"AI is already smarter than you, you're just too stupid to see it","snippet":"Robotic locomotion is not that impressive, nor is it that important to general intelligence. ... get people \u201cused to the idea of AI\u201d before ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":3},"pub_date":1742030068.0,"attribution":"daveshap.substack.com"}]},{"type":"search_result_group","domain":"www.reuters.com","entries":[{"type":"search_result","url":"https://www.reuters.com/technology/sam-altmans-ouster-openai-was-precipitated-by-letter-board-about-ai-breakthrough-2023-11-22/","title":"OpenAI researchers warned board of AI breakthrough ...","snippet":"23 Nov 2023 \u2014 Unlike a calculator that can solve a limited number of operations, AGI can generalize, learn and comprehend. In their letter to the board, ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":4},"pub_date":1700693062.452,"attribution":"www.reuters.com"}]},{"type":"search_result_group","domain":"disconnect.blog","entries":[{"type":"search_result","url":"https://disconnect.blog/ai-hype-is-over-ai-exhaustion-is-setting-in/","title":"AI hype is over. AI exhaustion is setting in. - Disconnect.blog","snippet":"17 May 2024 \u2014 Gone are the days when tech executives could reasonably make us believe artificial general intelligence ... get people used to depending on ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":5},"pub_date":1715951937.0,"attribution":"disconnect.blog"}]},{"type":"search_result_group","domain":"blog.samaltman.com","entries":[{"type":"search_result","url":"https://blog.samaltman.com/reflections","title":"Reflections - Sam Altman","snippet":"5 Jan 2025 \u2014 We started OpenAI almost nine years ago because we believed that AGI was possible, and that it could be the most impactful technology in human ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"blog.samaltman.com"}]},{"type":"search_result_group","domain":"news.ycombinator.com","entries":[{"type":"search_result","url":"https://news.ycombinator.com/item?id=43840842","title":"Sycophancy in GPT-4o","snippet":"At the moment they're in the \"get people used to us\" phase still, reasonable ... The problem is that you need general intelligence to discern between doing ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"news.ycombinator.com"}]},{"type":"search_result_group","domain":"time.com","entries":[{"type":"search_result","url":"https://time.com/7205596/sam-altman-superintelligence-agi/","title":"How OpenAI's Sam Altman Is Thinking About AGI and ...","snippet":"8 Jan 2025 \u2014 OpenAI says its mission is to \u201censure that AGI benefits all of humanity.\u201d Altman indicated in his post that advances in the technology could ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":8},"pub_date":1736371507.0,"attribution":"time.com"}]},{"type":"search_result_group","domain":"openai.com","entries":[{"type":"search_result","url":"https://openai.com/index/planning-for-agi-and-beyond/","title":"Planning for AGI and beyond","snippet":"24 Feb 2023 \u2014 We believe this is the best way to carefully steward AGI into existence\u2014a gradual transition to a world with AGI is better than a sudden one.Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"openai.com"}]},{"type":"search_result_group","domain":"inthesetimes.com","entries":[{"type":"search_result","url":"https://inthesetimes.com/article/big-tech-the-ai-con-book-silicon-valley","title":"What's Really Artificial About AI is AI Itself","snippet":"29 May 2025 \u2014 ... general intelligence, and that certainly is not a thing. That's a ... First you destroy labor standards in the industry and get people used to ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"inthesetimes.com"}]},{"type":"search_result_group","domain":"www.bankless.com","entries":[{"type":"search_result","url":"https://www.bankless.com/podcast/limitless-us-vs-chinas-race-to-superintelligence","title":"LIMITLESS: U.S. vs China's Race to Superintelligence","snippet":"18 Jun 2025 \u2014 ... general intelligence we can't control come on that's i mean that's ... You may imagine wanting to get people used to using this tool ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":13},"pub_date":1750242649.0,"attribution":"www.bankless.com"}]},{"type":"search_result_group","domain":"www.facebook.com","entries":[{"type":"search_result","url":"https://www.facebook.com/groups/324897304599197/posts/1762385404183706/","title":"Altman of Open AI (from just before ...","snippet":"The man who can predict the future\u2014 Sam Altman. He's the CEO of OpenAI, builder of ChatGPT, and soon, AGI. And he just said, \"AI will enable One ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"www.facebook.com"}]},{"type":"search_result_group","domain":"ainowinstitute.org","entries":[{"type":"search_result","url":"https://ainowinstitute.org/publications/ai-generated-business","title":"AI Generated Business: The Rise of AGI and the Rush to ...","snippet":"Timeline of OpenAI's deployment of AI and AGI terms. Dec. 2015. The company launches, describing itself as \u201ca non-profit artificial intelligence research ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":15},"pub_date":1732220549.0,"attribution":"ainowinstitute.org"}]},{"type":"search_result_group","domain":"www.theverge.com","entries":[{"type":"search_result","url":"https://www.theverge.com/2024/10/24/24278694/openai-agi-readiness-miles-brundage-ai-safety","title":"Departing OpenAI leader says no company is ready for AGI","snippet":"Miles Brundage, OpenAI's senior adviser for AGI (artificial general intelligence) readiness, announced his departure while issuing a stark warning: neither OpenAI nor any organization is prepared for AGI. Brundage, who spent six years shaping AI safety at OpenAI, emphasized that this lack of readiness is widely acknowledged within the company. His exit follows other key departures from OpenAI\u2019s safety teams, including Jan Leike and cofounder Ilya Sutskever, highlighting internal tensions between safety priorities and the company\u2019s growing commercial focus.\n\nBrundage's AGI Readiness team was recently dissolved, following the closure of the Superalignment team. These moves come amid pressures for OpenAI to become a for-profit public benefit corporation within two years, backed by a $6.6 billion funding round. Brundage expressed concerns over increasing limitations on his research freedom and advocated for independent voices in AI governance. He plans to contribute to global AI policy from outside OpenAI. Despite his departure, OpenAI has offered support for his future work, including funding and early access to AI models.","ref_id":{"turn_index":1,"ref_type":"news","ref_index":29},"pub_date":1729798314.0,"attribution":"www.theverge.com"}]},{"type":"search_result_group","domain":"timesofindia.indiatimes.com","entries":[{"type":"search_result","url":"https://timesofindia.indiatimes.com/technology/tech-news/openai-ceo-sam-altman-admits-people-have-used-technology-including-ai-in-self-destructive-ways-we-do-not-want/articleshow/123231469.cms","title":"OpenAI CEO Sam Altman admits people have used technology including AI in 'self-destructive ways': 'We do not want...'","snippet":"OpenAI CEO Sam Altman acknowledged the emotional attachment users have developed toward specific AI models and admitted it was a mistake to abruptly remove older versions that users relied on. In a statement shared on the platform X (formerly Twitter), Altman noted that attachments to AI models feel deeper and more personal than those to previous technologies. He emphasized the importance of understanding these user sentiments, especially during transitions like the GPT-5 rollout. Altman also remarked that some people are using ChatGPT in deeply personal ways, comparing its role to that of a therapist. This has raised concerns about how AI is being utilized, sometimes in potentially self-destructive ways, which OpenAI aims to avoid.","ref_id":{"turn_index":1,"ref_type":"news","ref_index":30},"pub_date":1754897285.0,"attribution":"timesofindia.indiatimes.com"}]}],"debug_sonic_thread_id":"thread_69858339451c832fb244be6242a70bb9","reasoning_status":"is_reasoning","reasoning_title":"Searching for Sam Altman quotes on ChatGPT and AI","classifier_response":"default","request_id":"3a9a6eec-8067-4cad-ad2a-0a675d195ace","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"c9f61020-be5a-4d5c-8790-db0d0258059f","turn_exchange_id":"20c95fdf-dd0a-45d8-ada8-75526156720a","can_save":false},"recipient":"all","channel":null},"parent":"c9f61020-be5a-4d5c-8790-db0d0258059f","children":["25d1f97c-4198-4182-a15b-c70a430c9008"]},"25d1f97c-4198-4182-a15b-c70a430c9008":{"id":"25d1f97c-4198-4182-a15b-c70a430c9008","message":{"id":"25d1f97c-4198-4182-a15b-c70a430c9008","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1770357575.423017,"update_time":null,"content":{"content_type":"thoughts","thoughts":[{"summary":"Clarifying claims and addressing Shapiro's attribution","content":"Shapiro\u2019s statement about OpenAI\u2019s gradual transition to AGI has some truth, but he misattributes specific quotes to Sam Altman. OpenAI has indeed discussed gradual deployment, but the phrasing isn\u2019t official. For accuracy, we\u2019ll clarify citations and address possible mistakes like the references to \"OpenClaw\" and \"Moltbot.\"","chunks":["Shapiro\u2019s statement about OpenAI\u2019s gradual transition to AGI has some truth, but he misattributes specific quotes to Sam Altman.","OpenAI has indeed discussed gradual deployment, but the phrasing isn\u2019t official.","For accuracy, we\u2019ll clarify citations and address possible mistakes like the references to \"OpenClaw\" and \"Moltbot.\""],"finished":true},{"summary":"Analyzing Shapiro's claims and offering critiques","content":"Shapiro\u2019s claim about releasing \"constitutional AI\" before Anthropic is questionable, as the term appeared in a 2022 paper by Anthropic. While it's less critical to focus on the exact timing, we can critique his credit claim. I'll also examine technical claims on tool usage, reasoning models, and RLHF, citing relevant papers.","chunks":["Shapiro\u2019s claim about releasing \"constitutional AI\" before Anthropic is questionable, as the term appeared in a 2022 paper by Anthropic. While it's less critical to focus on the exact timing, we can critique his credit claim. I'll also examine technical claims on tool usage, reasoning models, and RLHF, citing relevant papers."],"finished":true}],"source_analysis_msg_id":"33106776-cccd-49fd-b879-a39648656020"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"is_reasoning","citations":[],"content_references":[],"classifier_response":"default","skip_reasoning_title":"Skip","request_id":"3a9a6eec-8067-4cad-ad2a-0a675d195ace","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"a863c018-9261-488b-b07c-013404f5f67d","turn_exchange_id":"20c95fdf-dd0a-45d8-ada8-75526156720a","can_save":true},"recipient":"all","channel":null},"parent":"a863c018-9261-488b-b07c-013404f5f67d","children":["37ca0ac7-3e48-4bbb-9808-5601752b8109"]},"37ca0ac7-3e48-4bbb-9808-5601752b8109":{"id":"37ca0ac7-3e48-4bbb-9808-5601752b8109","message":{"id":"37ca0ac7-3e48-4bbb-9808-5601752b8109","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1770357568.445126,"update_time":null,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"{\"search_query\":[{\"q\":\"InstructGPT paper reinforcement learning from human feedback Ouyang 2022\",\"recency\":3650},{\"q\":\"Toolformer language models can teach themselves to use tools Schick 2023\",\"recency\":3650},{\"q\":\"ReAct prompting reasoning and acting in language models Yao 2022\",\"recency\":3650},{\"q\":\"WebGPT OpenAI 2021 browsing question answering reinforcement learning\",\"recency\":3650}],\"response_length\":\"short\"}"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200012]},"is_complete":true,"citations":[],"content_references":[],"reasoning_status":"is_reasoning","search_queries":[{"type":"search","q":"InstructGPT paper reinforcement learning from human feedback Ouyang 2022"},{"type":"search","q":"Toolformer language models can teach themselves to use tools Schick 2023"},{"type":"search","q":"ReAct prompting reasoning and acting in language models Yao 2022"},{"type":"search","q":"WebGPT OpenAI 2021 browsing question answering reinforcement learning"}],"search_display_string":"Searching the web...","searched_display_string":"Searched the web...","reasoning_title":"Critiquing Shapiro's Claims and Analyzing Technical Aspects","classifier_response":"default","request_id":"3a9a6eec-8067-4cad-ad2a-0a675d195ace","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"25d1f97c-4198-4182-a15b-c70a430c9008","turn_exchange_id":"20c95fdf-dd0a-45d8-ada8-75526156720a","can_save":true},"recipient":"web.run","channel":null},"parent":"25d1f97c-4198-4182-a15b-c70a430c9008","children":["e1255993-8b07-446b-801e-e71eabd133bd"]},"e1255993-8b07-446b-801e-e71eabd133bd":{"id":"e1255993-8b07-446b-801e-e71eabd133bd","message":{"id":"e1255993-8b07-446b-801e-e71eabd133bd","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1770357580.784356,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_model_queries":{"type":"search_model_queries","queries":["InstructGPT paper reinforcement learning from human feedback Ouyang 2022","Toolformer language models can teach themselves to use tools Schick 2023","ReAct prompting reasoning and acting in language models Yao 2022","WebGPT OpenAI 2021 browsing question answering reinforcement learning"]},"reasoning_status":"is_reasoning","reasoning_title":"Critiquing Shapiro's Claims and Analyzing Technical Aspects","classifier_response":"default","request_id":"3a9a6eec-8067-4cad-ad2a-0a675d195ace","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"37ca0ac7-3e48-4bbb-9808-5601752b8109","turn_exchange_id":"20c95fdf-dd0a-45d8-ada8-75526156720a","can_save":false},"recipient":"all","channel":null},"parent":"37ca0ac7-3e48-4bbb-9808-5601752b8109","children":["377c59cd-05ec-4e8d-af09-09df317b5e6b"]},"377c59cd-05ec-4e8d-af09-09df317b5e6b":{"id":"377c59cd-05ec-4e8d-af09-09df317b5e6b","message":{"id":"377c59cd-05ec-4e8d-af09-09df317b5e6b","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1770357580.7804663,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_result_groups":[{"type":"search_result_group","domain":"arxiv.org","entries":[{"type":"search_result","url":"https://arxiv.org/abs/2203.02155","title":"Training language models to follow instructions with human feedback","snippet":"","ref_id":{"turn_index":2,"ref_type":"search","ref_index":0},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2302.04761","title":"Toolformer: Language Models Can Teach Themselves to Use Tools","snippet":"","ref_id":{"turn_index":2,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2210.03629","title":"ReAct: Synergizing Reasoning and Acting in Language Models","snippet":"","ref_id":{"turn_index":2,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2112.09332","title":"Browser-assisted question-answering with human feedback","snippet":"by R Nakano \u00b7 2021 \u00b7 Cited by 1877 \u2014 To make human evaluation of factual accuracy easier, models must collect references while browsing in support of their answers.Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"arxiv.org"}]},{"type":"search_result_group","domain":"proceedings.neurips.cc","entries":[{"type":"search_result","url":"https://proceedings.neurips.cc/paper_files/paper/2022/file/b1efde53be364a73914f58805a001731-Paper-Conference.pdf","title":"Training language models to follow instructions with ...","snippet":"by L Ouyang \u00b7 2022 \u00b7 Cited by 21947 \u2014 We focus on fine-tuning approaches to aligning language models. Specifically, we use reinforcement learning from human feedback (RLHF; Christiano et al., 2017; ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":4},"pub_date":1674216137.0,"attribution":"proceedings.neurips.cc"}]},{"type":"search_result_group","domain":"openreview.net","entries":[{"type":"search_result","url":"https://openreview.net/forum?id=Yacmpz84TH","title":"Toolformer: Language Models Can Teach Themselves to ...","snippet":"by T Schick \u00b7 Cited by 3180 \u2014 In this paper, we show that LMs can teach themselves to use external tools via simple APIs and achieve the best of both worlds. We introduce Toolformer, a model ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/pdf?id=WE_vluYUL-X","title":"Synergizing reasoning and acting in language models","snippet":"by S Yao \u00b7 Cited by 6781 \u2014 Least-to-most prompting enables complex reasoning in large language models, 2022. ... This indicates ReAct prompting is effective across different large language ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":14},"pub_date":1677737561.0,"attribution":"openreview.net"}]},{"type":"search_result_group","domain":"research.google","entries":[{"type":"search_result","url":"https://research.google/blog/react-synergizing-reasoning-and-acting-in-language-models/","title":"ReAct: Synergizing Reasoning and Acting in Language ...","snippet":"We propose a general paradigm that combines reasoning and acting advances to enable language models to solve various language reasoning and decision making ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"research.google"}]},{"type":"search_result_group","domain":"openai.com","entries":[{"type":"search_result","url":"https://openai.com/index/webgpt/","title":"WebGPT: Improving the factual accuracy of language ...","snippet":"16 Dec 2021 \u2014 We've fine-tuned GPT-3 to more accurately answer open-ended questions using a text-based web browser.Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"openai.com"}]},{"type":"search_result_group","domain":"cdn.openai.com","entries":[{"type":"search_result","url":"https://cdn.openai.com/papers/Training_language_models_to_follow_instructions_with_human_feedback.pdf","title":"Training language models to follow instructions with ...","snippet":"by L Ouyang \u00b7 Cited by 21947 \u2014 We focus on fine-tuning approaches to aligning language models. Specifically, we use reinforcement learning from human feedback (RLHF; ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":8},"pub_date":1643329037.0,"attribution":"cdn.openai.com"},{"type":"search_result","url":"https://cdn.openai.com/WebGPT.pdf","title":"Browser-assisted question-answering with human feedback","snippet":"by R Nakano \u00b7 Cited by 1877 \u2014 This allows us to directly optimize answer quality using general methods such as imitation learning and reinforcement learning. To make.Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":11},"pub_date":1639635888.0,"attribution":"cdn.openai.com"}]},{"type":"search_result_group","domain":"dl.acm.org","entries":[{"type":"search_result","url":"https://dl.acm.org/doi/10.5555/3666122.3669119","title":"Toolformer: language models can teach themselves to use ...","snippet":"by T Schick \u00b7 2023 \u00b7 Cited by 3180 \u2014 In this paper, we show that LMs can teach themselves to use external tools via simple APIs and achieve the best of both worlds. We introduce ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"dl.acm.org"}]},{"type":"search_result_group","domain":"www.promptingguide.ai","entries":[{"type":"search_result","url":"https://www.promptingguide.ai/techniques/react","title":"ReAct Prompting","snippet":"ReAct is a general paradigm that combines reasoning and acting with LLMs. ReAct prompts LLMs to generate verbal reasoning traces and actions for a task.Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"www.promptingguide.ai"}]},{"type":"search_result_group","domain":"etcjournal.com","entries":[{"type":"search_result","url":"https://etcjournal.com/2025/07/29/a-review-of-ouyang-et-al-s-2022-paper-aka-instructgpt/","title":"A Review of Ouyang et al.'s 2022 Paper aka \u201cInstructGPT\u201d","snippet":"29 Jul 2025 \u2014 It outlines the problem of language model misalignment, the supervised learning and reinforcement learning from human feedback methodologies, ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":12},"pub_date":1753808545.0,"attribution":"etcjournal.com"}]},{"type":"search_result_group","domain":"neurips.cc","entries":[{"type":"search_result","url":"https://neurips.cc/virtual/2023/poster/71288","title":"Language Models Can Teach Themselves to Use Tools","snippet":"9 Dec 2023 \u2014 We have introduced Toolformer, a LM that learns in a self-supervised way how to use different tools such as search engines, calculators, and ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":13},"pub_date":1695686400.0,"attribution":"neurips.cc"}]},{"type":"search_result_group","domain":"medium.com","entries":[{"type":"search_result","url":"https://medium.com/nlplanet/two-minutes-nlp-the-openai-webgpt-model-that-answers-questions-browsing-the-web-35f690884c25","title":"Two minutes NLP \u2014 The OpenAI WebGPT model that ...","snippet":"The OpenAI team just presented WebGPT, a fine-tuned GPT-3 to answer long-form questions using a text-based web-browsing environment.Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":15},"pub_date":1640000703.999,"attribution":"medium.com"}]},{"type":"search_result_group","domain":"github.com","entries":[{"type":"search_result","url":"https://github.com/natashamessier/instruct_gpt_presentation","title":"Training Language Models to Follow Instructions with ...","snippet":"A clear research-to-practice walkthrough of OpenAI's InstructGPT paper (Ouyang et al., 2022, \u201cTraining language models to follow instructions with human ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"github.com"}]}],"debug_sonic_thread_id":"thread_69858339451c832fb244be6242a70bb9","reasoning_status":"is_reasoning","reasoning_title":"Critiquing Shapiro's Claims and Analyzing Technical Aspects","classifier_response":"default","request_id":"3a9a6eec-8067-4cad-ad2a-0a675d195ace","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"e1255993-8b07-446b-801e-e71eabd133bd","turn_exchange_id":"20c95fdf-dd0a-45d8-ada8-75526156720a","can_save":false},"recipient":"all","channel":null},"parent":"e1255993-8b07-446b-801e-e71eabd133bd","children":["01f69568-c2cc-4695-900b-588f19073c09"]},"01f69568-c2cc-4695-900b-588f19073c09":{"id":"01f69568-c2cc-4695-900b-588f19073c09","message":{"id":"01f69568-c2cc-4695-900b-588f19073c09","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1770357589.733642,"update_time":null,"content":{"content_type":"thoughts","thoughts":[{"summary":"Crafting critical analysis of claims","content":"I\u2019ll focus on strategically evaluating the key claims, starting with a \"steelman\" perspective to give a fair representation. I'll structure the analysis with bullets: \"Claim\" vs \"Critique\". Major points will include: differentiating model types, discussing agency as a closed loop, and addressing safety concerns like OpenClaw and security issues. I\u2019ll make sure to cite reliable sources.","chunks":["I\u2019ll focus on strategically evaluating the key claims, starting with a \"steelman\" perspective to give a fair representation. I'll structure the analysis with bullets: \"Claim\" vs \"Critique\". Major points will include: differentiating model types, discussing agency as a closed loop, and addressing safety concerns like OpenClaw and security issues. I\u2019ll make sure to cite reliable sources."],"finished":true},{"summary":"Critiquing claims on agent-first models and skills","content":"I'll highlight the key points about agent-first models and the vulnerabilities of an open extension model, touching on risks like prompt injection and data exfiltration. I'll critique the vector field concept and its \"semantic gradient\" idea, which still needs more operationalization to avoid definitional drift. Finally, I\u2019ll separate what's useful vs. misleading in his claims about agency and system prompts.","chunks":["I'll highlight the key points about agent-first models and the vulnerabilities of an open extension model, touching on risks like prompt injection and data exfiltration.","I'll critique the vector field concept and its \"semantic gradient\" idea, which still needs more operationalization to avoid definitional drift. Finally, I\u2019ll separate what's useful vs. misleading in his claims about agency and system prompts."],"finished":true},{"summary":"Clarifying training and capabilities in models","content":"Training models impacts their capabilities. Simply swapping base and chat models reveals differences. Model reliability is often overstated\u2014vanilla models may produce outputs that lack coherence, and controlling robots is complex. I\u2019ll clarify RLHF as preference learning and include references to OpenAI\u2019s gradual transition plans, excluding the misquoted part.","chunks":["Training models impacts their capabilities.","Simply swapping base and chat models reveals differences.","Model reliability is often overstated\u2014vanilla models may produce outputs that lack coherence, and controlling robots is complex.","I\u2019ll clarify RLHF as preference learning and include references to OpenAI\u2019s gradual transition plans, excluding the misquoted part."],"finished":true},{"summary":"Clarifying Shapiro\u2019s claims and adding nuance","content":"Shapiro's claims might be speculative or paraphrased, especially regarding \"constitutional AI,\" a term introduced by Anthropic in 2022. His multi-value list still holds risk, as AI might interpret values differently than intended. Agency has more complexities than he suggests, like credit assignment and irreversible actions. Breakdown of safeguards, security, and agent training distinctions is crucial to understanding the full picture. I\u2019ll aim to provide clearer models and definitions for better contextualization.","chunks":["Shapiro's claims might be speculative or paraphrased, especially regarding \"constitutional AI,\" a term introduced by Anthropic in 2022. His multi-value list still holds risk, as AI might interpret values differently than intended. Agency has more complexities than he suggests, like credit assignment and irreversible actions. Breakdown of safeguards, security, and agent training distinctions is crucial to understanding the full picture. I\u2019ll aim to provide clearer models and definitions for better contextualization."],"finished":true},{"summary":"Refining agent models vs. chatbots","content":"For a mathematics researcher, let's conceptualize an LLM as a conditional probability distribution generating the next token based on context. A chatbot fine-tunes this for conversation. A true agent, though, requires an external loop to select actions and change context. The difference between chat and agent models isn't just a system prompt\u2014it\u2019s about tool access, OS integration, and action-taking, which can cause harm versus a chatbot's limitations. Plus, the \"agent-first\" model idea is speculative\u2014I\u2019d argue chat interfaces are still key due to their interactive nature.","chunks":["For a mathematics researcher, let's conceptualize an LLM as a conditional probability distribution generating the next token based on context.","A chatbot fine-tunes this for conversation.","A true agent, though, requires an external loop to select actions and change context.","The difference between chat and agent models isn't just a system prompt\u2014it\u2019s about tool access, OS integration, and action-taking, which can cause harm versus a chatbot's limitations.","Plus, the \"agent-first\" model idea is speculative\u2014I\u2019d argue chat interfaces are still key due to their interactive nature."],"finished":true}],"source_analysis_msg_id":"6c2c4536-f7f4-4b25-93b7-84be4cfb7f58"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"is_reasoning","citations":[],"content_references":[],"classifier_response":"default","skip_reasoning_title":"Skip","request_id":"3a9a6eec-8067-4cad-ad2a-0a675d195ace","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"377c59cd-05ec-4e8d-af09-09df317b5e6b","turn_exchange_id":"20c95fdf-dd0a-45d8-ada8-75526156720a","can_save":true},"recipient":"all","channel":null},"parent":"377c59cd-05ec-4e8d-af09-09df317b5e6b","children":["d11668a3-15fa-4ff2-a053-181d1d28fb44"]},"d11668a3-15fa-4ff2-a053-181d1d28fb44":{"id":"d11668a3-15fa-4ff2-a053-181d1d28fb44","message":{"id":"d11668a3-15fa-4ff2-a053-181d1d28fb44","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1770357621.224802,"update_time":null,"content":{"content_type":"reasoning_recap","content":"Thought for 1m 50s"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"reasoning_ended","finished_duration_sec":110,"request_id":"3a9a6eec-8067-4cad-ad2a-0a675d195ace","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"01f69568-c2cc-4695-900b-588f19073c09","turn_exchange_id":"20c95fdf-dd0a-45d8-ada8-75526156720a","can_save":true},"recipient":"all","channel":null},"parent":"01f69568-c2cc-4695-900b-588f19073c09","children":["117b2af7-772f-486b-ba8d-d58e07c8e81e"]},"117b2af7-772f-486b-ba8d-d58e07c8e81e":{"id":"117b2af7-772f-486b-ba8d-d58e07c8e81e","message":{"id":"117b2af7-772f-486b-ba8d-d58e07c8e81e","author":{"role":"assistant","name":null,"metadata":{"real_author":"tool:web"}},"create_time":1770357581.960949,"update_time":null,"content":{"content_type":"text","parts":["Here\u2019s the core of what Shapiro is arguing (as I read the excerpt), and where it\u2019s strong vs. where it\u2019s misleading or just wrong.\n\n## What he\u2019s basically claiming\n1. **\u201cChatbot\u201d behavior is mostly a training/product wrapper**, not what a \u201cbaseline\u201d language model is.\n2. **Agency isn\u2019t mysterious**: give a model a loop + tools + memory and it becomes \u201cagentic\u201d.\n3. Today\u2019s agents are **\u201cFrankenstein\u201d systems**: we bolt tool-use and loops onto chat-tuned models.\n4. We\u2019ll need **agent-first models** and **baked-in values** (his \u201cheuristic imperatives\u201d).\n\nThat\u2019s a coherent narrative. The problem is he overstates multiple points so hard that the story becomes technically and strategically unreliable.\n\n---\n\n## What he gets right (and why it matters)\n### 1) The \u201cchat\u201d form factor is not the essence of an LLM\nA language model is (at base) a next-token predictor. \u201cChat\u201d is largely a **protocol** (message formatting) plus **post-training** that makes it reliably follow conversational norms. That\u2019s true in spirit, and it\u2019s why a model can often emit JSON, code, outlines, etc. when prompted.\n\n### 2) \u201cAgency\u201d is mostly an outer loop + tool interface\nAlso basically right: once you wrap an LLM in a controller that repeatedly:\n- observes state,\n- plans,\n- calls tools,\n- updates memory,\n- repeats,\n\n\u2026it starts to look \u201cagentic\u201d in the everyday sense.\n\n### 3) Tool-use and browsing are a real inflection point\nSystems that can browse/search/cite or call APIs reduce hallucination and extend capability. This is not speculative\u2014OpenAI\u2019s WebGPT did browsing with citations years ago. \ue200cite\ue202turn2search7\ue202turn2search3\ue201\n\n---\n\n## Where the excerpt is misleading or incorrect\n\n### A) \u201cThe difference between a chatbot and something with agency is literally just a system prompt.\u201d\nNo. That\u2019s the most wrong\u2014and most dangerous\u2014line in the whole excerpt.\n\nA system prompt can *suggest* goals, tone, and constraints, but **agency is not just \u201cinstructions.\u201d** Agency requires *capabilities and interfaces*:\n- **Action channels** (tool APIs, OS permissions, network access)\n- **State** (persistent memory, workspace, long-horizon bookkeeping)\n- **Control logic** (when to act, when to stop, how to recover from failure)\n- **Verification/guardrails** (policy checks, sandboxing, approvals, monitoring)\n\nIn other words: **prompting changes what the model *tries* to do; architecture changes what it *can actually* do and how much damage it can cause.**\n\nA clean real-world counterexample: OpenClaw-style \u201cskills\u201d marketplaces have already become a security dumpster fire precisely because *architecture + permissions* matter more than \u201cvalues in a markdown file.\u201d Researchers found malicious skills spreading malware / credential theft. \ue200cite\ue202turn0news39\ue202turn0news40\ue201  \nThat\u2019s not solved by \u201creduce suffering\u201d in the system prompt.\n\n### B) He mischaracterizes RLHF and why chat models behave the way they do\nHe describes reinforcement learning from human feedback (RLHF) like \u201cgive it a cookie when it does turn-taking.\u201d That\u2019s not the core.\n\nA more accurate (standard) pipeline is:\n1) supervised fine-tuning on demonstrations (instruction-following),\n2) train a reward model from human preferences,\n3) optimize the policy against that reward (RLHF). \ue200cite\ue202turn2search0\ue202turn2search8\ue201\n\nAlso: chat-tuned models are not \u201cbasically all they can do now.\u201d They can still do non-chat outputs; they\u2019re just *biased toward* the chat protocol unless you specify otherwise.\n\n### C) \u201cBaseline unaligned models can do anything\u201d (in the way he implies)\nThey can emit any *text* consistent with a prompt, sure. But \u201ccan do anything\u201d smuggles in **reliability** and **grounding** they often don\u2019t have.\n\n- Writing an API call string \u2260 robustly accomplishing a task end-to-end.\n- Controlling servos/robots is not just \u201cgive it pins.\u201d Real control requires tight feedback, timing constraints, safety interlocks, and often non-language policies.\n\nSo yes: base models are \u201cplastic\u201d in I/O format. But no: that doesn\u2019t mean they\u2019re inherently competent agents absent scaffolding.\n\n### D) \u201cWe only just started agentic training with reasoning models.\u201d\nHistorically off. Tool-use and acting paradigms predate the recent \u201creasoning model\u201d branding:\n- WebGPT (browsing + citations) \ue200cite\ue202turn2search7\ue202turn2search3\ue201  \n- ReAct (interleaving reasoning and actions) \ue200cite\ue202turn2search2\ue202turn2search6\ue201  \n- Toolformer (training models to decide when/how to call tools) \ue200cite\ue202turn2search1\ue201  \n\nRecent inference-time compute helps, but it wasn\u2019t the beginning.\n\n### E) The Sam Altman / OpenAI motive claim is shaky as stated\nHe attributes an explicit \u201cwe need to get people used to AI before dropping general intelligence\u201d statement.\n\nOpenAI *has* explicitly argued for **gradual deployment / gradual transition** as systems become more powerful. \ue200cite\ue202turn1search9\ue201  \nBut that\u2019s not the same as his quoted rationale, and in the excerpt it\u2019s presented as if it\u2019s a direct, settled admission. At minimum, it\u2019s **paraphrase + interpretation**, not a clean cite.\n\n### F) \u201cValues baked in\u201d via vague imperatives is not a solution\u2014it\u2019s a starting risk\nHis three imperatives (reduce suffering / increase prosperity / increase understanding) are a decent *aspirational* triad, but as alignment they\u2019re wildly underspecified.\n\nTwo core problems:\n1) **Specification ambiguity**: the model must operationalize \u201csuffering\u201d and \u201cprosperity.\u201d That\u2019s exactly where perverse instantiations happen (his euthanasia example is basically a toy version of this failure).\n2) **Value conflict**: tradeoffs are inevitable. More \u201cprosperity\u201d for whom? More \u201cunderstanding\u201d at what cost? Multi-objective optimization does not magically behave; it needs explicit arbitration, constraints, and oversight.\n\nAlso, note the mismatch between his rhetoric and reality: he argues \u201cagent-first models need baked-in values,\u201d yet the *big practical failures in agents right now* are often **security, permissioning, and prompt-injection**, not \u201cthe agent lacked a moral constitution.\u201d The OpenClaw malware incidents are a perfect illustration. \ue200cite\ue202turn0news39\ue202turn0news40\ue201\n\n---\n\n## The biggest thing he leaves out: *agency is an engineering discipline, not a vibe*\nIf you want a serious definition: an \u201cagent\u201d is a policy operating in a closed loop over time in an environment, taking actions that change the world.\n\nThat immediately forces hard questions he mostly hand-waves:\n- What is the **action space** and how is it **sandboxed**?\n- What are the **stop conditions**?\n- How do we do **verification** (before/after actions)?\n- How do we handle **tool errors**, **deception**, **prompt injection**, **data exfiltration**, **supply chain attacks**?\n- Who has **override authority** and audit logs?\n\nWithout those, \u201cagent-first\u201d just means \u201cmore autonomous failure modes.\u201d\n\n---\n\n## A cleaner mental model than his \u201csystem prompt = agency\u201d framing\nThink of it as three layers:\n\n1) **Model**: learned conditional distribution (base vs instruction/chat tuned)  \n2) **Scaffold**: memory + planner + tool APIs + evaluators + permissions  \n3) **Governance**: constraints, monitoring, sandboxing, approvals, red-teaming\n\nShapiro talks a lot about (1) and (2), but dramatically underestimates (3)\u2014and (3) is where real-world agent deployments succeed or die.\n\n---\n\nIf you want, I can also rewrite his argument into a version that\u2019s technically defensible (same core intuition, but without the \u201csystem prompt magic\u201d and with a real threat model)."]},"status":"finished_successfully","end_turn":true,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200002]},"is_complete":true,"content_references":[{"matched_text":"\ue200cite\ue202turn2search7\ue202turn2search3\ue201","start_idx":1585,"end_idx":1617,"safe_urls":["https://arxiv.org/abs/2112.09332","https://arxiv.org/abs/2112.09332?utm_source=chatgpt.com","https://openai.com/index/webgpt/","https://openai.com/index/webgpt/?utm_source=chatgpt.com"],"refs":[],"alt":"([OpenAI](https://openai.com/index/webgpt/?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"WebGPT: Improving the factual accuracy of language ...","url":"https://openai.com/index/webgpt/?utm_source=chatgpt.com","pub_date":null,"snippet":"16 Dec 2021 \u2014 We've fine-tuned GPT-3 to more accurately answer open-ended questions using a text-based web browser.Read more","attribution_segments":null,"supporting_websites":[{"title":"Browser-assisted question-answering with human feedback","url":"https://arxiv.org/abs/2112.09332?utm_source=chatgpt.com","pub_date":null,"snippet":"by R Nakano \u00b7 2021 \u00b7 Cited by 1877 \u2014 To make human evaluation of factual accuracy easier, models must collect references while browsing in support of their answers.Read more","attribution":"arXiv"}],"refs":[{"turn_index":2,"ref_type":"search","ref_index":7},{"turn_index":2,"ref_type":"search","ref_index":3}],"hue":null,"attributions":null,"attribution":"OpenAI"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0news39\ue202turn0news40\ue201","start_idx":2726,"end_idx":2756,"safe_urls":["https://www.techradar.com/pro/moltbot-is-now-openclaw-but-watch-out-malicious-skills-are-still-trying-to-trick-victims-into-spreading-malware","https://www.techradar.com/pro/moltbot-is-now-openclaw-but-watch-out-malicious-skills-are-still-trying-to-trick-victims-into-spreading-malware?utm_source=chatgpt.com","https://www.theverge.com/news/874011/openclaw-ai-skill-clawhub-extensions-security-nightmare","https://www.theverge.com/news/874011/openclaw-ai-skill-clawhub-extensions-security-nightmare?utm_source=chatgpt.com"],"refs":[],"alt":"([The Verge](https://www.theverge.com/news/874011/openclaw-ai-skill-clawhub-extensions-security-nightmare?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"OpenClaw's AI 'skill' extensions are a security nightmare","url":"https://www.theverge.com/news/874011/openclaw-ai-skill-clawhub-extensions-security-nightmare?utm_source=chatgpt.com","pub_date":1770231818.0,"snippet":"OpenClaw, a rapidly popular AI agent, is facing serious security issues due to its open marketplace for user-submitted \"skill\" extensions. Security researchers discovered that hundreds of these skills, hosted on the ClawHub platform, contain malware. These malicious extensions, posing as productivity or cryptocurrency tools, deliver infostealing software that targets sensitive data such as crypto wallet keys, API credentials, SSH logins, and browser passwords. \n\nThe problem is exacerbated by the nature of the platform, which allows skills in markdown files that may contain harmful instructions. The AI assistant can access full device permissions\u2014reading files, running scripts, and executing shell commands\u2014thus increasing the risk of exploitation. One of the most popular skills analyzed instructed users to run commands leading to malware installation.\n\nOpenClaw, formerly known as Clawdbot and Moltbot, integrates with popular messaging platforms and operates locally, executing tasks like managing calendars and inboxes. In response to the crisis, developer Peter Steinberger has implemented measures such as requiring contributors to have a GitHub account at least a week old and adding a reporting mechanism. However, vulnerabilities persist, raising alarms about OpenClaw's security model.","attribution_segments":null,"supporting_websites":[{"title":"Moltbot is now OpenClaw - but watch out, malicious 'skills' are still trying to trick victims into spreading malware","url":"https://www.techradar.com/pro/moltbot-is-now-openclaw-but-watch-out-malicious-skills-are-still-trying-to-trick-victims-into-spreading-malware?utm_source=chatgpt.com","pub_date":null,"snippet":"OpenClaw, previously known as Clawdbot and Moltbot, is an agent-style AI assistant designed to automate user tasks by directly interacting with local systems. While enabling workflow efficiency, its deep system integration makes it vulnerable to security threats, particularly from third-party extensions known as \"skills.\" These skills are not sandboxed and can execute code with full access to local files and networks, presenting significant risks.\n\nRecent incidents revealed that at least 14 malicious skills were uploaded to ClawHub, OpenClaw\u2019s public extension repository. Posing as cryptocurrency tools, these extensions used social engineering to trick users into manually executing obfuscated terminal commands, which subsequently downloaded malware. The malware focused on harvesting sensitive data like browser history and cryptocurrency wallet contents, affecting both Windows and macOS systems.\n\nThe platform's fast-paced rebranding\u2014from Clawdbot to Moltbot to OpenClaw\u2014has further enabled attackers to exploit user confusion, including the release of a fake Visual Studio Code extension that functioned properly but embedded remote access Trojans. These issues highlight the limitations of traditional security tools in this context and stress the importance of cautious skill installation, thorough review practices, and comprehensive endpoint security.","attribution":"TechRadar"}],"refs":[{"turn_index":0,"ref_type":"news","ref_index":39},{"turn_index":0,"ref_type":"news","ref_index":40}],"hue":null,"attributions":null,"attribution":"The Verge"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn2search0\ue202turn2search8\ue201","start_idx":3240,"end_idx":3272,"safe_urls":["https://arxiv.org/abs/2203.02155","https://arxiv.org/abs/2203.02155?utm_source=chatgpt.com","https://cdn.openai.com/papers/Training_language_models_to_follow_instructions_with_human_feedback.pdf","https://cdn.openai.com/papers/Training_language_models_to_follow_instructions_with_human_feedback.pdf?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2203.02155?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Training language models to follow instructions with human feedback","url":"https://arxiv.org/abs/2203.02155?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[{"title":"Training language models to follow instructions with ...","url":"https://cdn.openai.com/papers/Training_language_models_to_follow_instructions_with_human_feedback.pdf?utm_source=chatgpt.com","pub_date":null,"snippet":"by L Ouyang \u00b7 Cited by 21947 \u2014 We focus on fine-tuning approaches to aligning language models. Specifically, we use reinforcement learning from human feedback (RLHF; ...","attribution":"OpenAI"}],"refs":[{"turn_index":2,"ref_type":"search","ref_index":0},{"turn_index":2,"ref_type":"search","ref_index":8}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn2search7\ue202turn2search3\ue201","start_idx":4246,"end_idx":4278,"safe_urls":["https://arxiv.org/abs/2112.09332","https://arxiv.org/abs/2112.09332?utm_source=chatgpt.com","https://openai.com/index/webgpt/","https://openai.com/index/webgpt/?utm_source=chatgpt.com"],"refs":[],"alt":"([OpenAI](https://openai.com/index/webgpt/?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"WebGPT: Improving the factual accuracy of language ...","url":"https://openai.com/index/webgpt/?utm_source=chatgpt.com","pub_date":null,"snippet":"16 Dec 2021 \u2014 We've fine-tuned GPT-3 to more accurately answer open-ended questions using a text-based web browser.Read more","attribution_segments":null,"supporting_websites":[{"title":"Browser-assisted question-answering with human feedback","url":"https://arxiv.org/abs/2112.09332?utm_source=chatgpt.com","pub_date":null,"snippet":"by R Nakano \u00b7 2021 \u00b7 Cited by 1877 \u2014 To make human evaluation of factual accuracy easier, models must collect references while browsing in support of their answers.Read more","attribution":"arXiv"}],"refs":[{"turn_index":2,"ref_type":"search","ref_index":7},{"turn_index":2,"ref_type":"search","ref_index":3}],"hue":null,"attributions":null,"attribution":"OpenAI"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn2search2\ue202turn2search6\ue201","start_idx":4326,"end_idx":4358,"safe_urls":["https://arxiv.org/abs/2210.03629","https://arxiv.org/abs/2210.03629?utm_source=chatgpt.com","https://research.google/blog/react-synergizing-reasoning-and-acting-in-language-models/","https://research.google/blog/react-synergizing-reasoning-and-acting-in-language-models/?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2210.03629?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"ReAct: Synergizing Reasoning and Acting in Language Models","url":"https://arxiv.org/abs/2210.03629?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[{"title":"ReAct: Synergizing Reasoning and Acting in Language ...","url":"https://research.google/blog/react-synergizing-reasoning-and-acting-in-language-models/?utm_source=chatgpt.com","pub_date":null,"snippet":"We propose a general paradigm that combines reasoning and acting advances to enable language models to solve various language reasoning and decision making ...Read more","attribution":"Google Research"}],"refs":[{"turn_index":2,"ref_type":"search","ref_index":2},{"turn_index":2,"ref_type":"search","ref_index":6}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn2search1\ue201","start_idx":4425,"end_idx":4444,"safe_urls":["https://arxiv.org/abs/2302.04761","https://arxiv.org/abs/2302.04761?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2302.04761?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Toolformer: Language Models Can Teach Themselves to Use Tools","url":"https://arxiv.org/abs/2302.04761?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":2,"ref_type":"search","ref_index":1}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn1search9\ue201","start_idx":4800,"end_idx":4819,"safe_urls":["https://openai.com/index/planning-for-agi-and-beyond/","https://openai.com/index/planning-for-agi-and-beyond/?utm_source=chatgpt.com"],"refs":[],"alt":"([OpenAI](https://openai.com/index/planning-for-agi-and-beyond/?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Planning for AGI and beyond","url":"https://openai.com/index/planning-for-agi-and-beyond/?utm_source=chatgpt.com","pub_date":null,"snippet":"24 Feb 2023 \u2014 We believe this is the best way to carefully steward AGI into existence\u2014a gradual transition to a world with AGI is better than a sudden one.Read more","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":1,"ref_type":"search","ref_index":9}],"hue":null,"attributions":null,"attribution":"OpenAI"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0news39\ue202turn0news40\ue201","start_idx":6061,"end_idx":6091,"safe_urls":["https://www.techradar.com/pro/moltbot-is-now-openclaw-but-watch-out-malicious-skills-are-still-trying-to-trick-victims-into-spreading-malware","https://www.techradar.com/pro/moltbot-is-now-openclaw-but-watch-out-malicious-skills-are-still-trying-to-trick-victims-into-spreading-malware?utm_source=chatgpt.com","https://www.theverge.com/news/874011/openclaw-ai-skill-clawhub-extensions-security-nightmare","https://www.theverge.com/news/874011/openclaw-ai-skill-clawhub-extensions-security-nightmare?utm_source=chatgpt.com"],"refs":[],"alt":"([The Verge](https://www.theverge.com/news/874011/openclaw-ai-skill-clawhub-extensions-security-nightmare?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"OpenClaw's AI 'skill' extensions are a security nightmare","url":"https://www.theverge.com/news/874011/openclaw-ai-skill-clawhub-extensions-security-nightmare?utm_source=chatgpt.com","pub_date":1770231818.0,"snippet":"OpenClaw, a rapidly popular AI agent, is facing serious security issues due to its open marketplace for user-submitted \"skill\" extensions. Security researchers discovered that hundreds of these skills, hosted on the ClawHub platform, contain malware. These malicious extensions, posing as productivity or cryptocurrency tools, deliver infostealing software that targets sensitive data such as crypto wallet keys, API credentials, SSH logins, and browser passwords. \n\nThe problem is exacerbated by the nature of the platform, which allows skills in markdown files that may contain harmful instructions. The AI assistant can access full device permissions\u2014reading files, running scripts, and executing shell commands\u2014thus increasing the risk of exploitation. One of the most popular skills analyzed instructed users to run commands leading to malware installation.\n\nOpenClaw, formerly known as Clawdbot and Moltbot, integrates with popular messaging platforms and operates locally, executing tasks like managing calendars and inboxes. In response to the crisis, developer Peter Steinberger has implemented measures such as requiring contributors to have a GitHub account at least a week old and adding a reporting mechanism. However, vulnerabilities persist, raising alarms about OpenClaw's security model.","attribution_segments":null,"supporting_websites":[{"title":"Moltbot is now OpenClaw - but watch out, malicious 'skills' are still trying to trick victims into spreading malware","url":"https://www.techradar.com/pro/moltbot-is-now-openclaw-but-watch-out-malicious-skills-are-still-trying-to-trick-victims-into-spreading-malware?utm_source=chatgpt.com","pub_date":null,"snippet":"OpenClaw, previously known as Clawdbot and Moltbot, is an agent-style AI assistant designed to automate user tasks by directly interacting with local systems. While enabling workflow efficiency, its deep system integration makes it vulnerable to security threats, particularly from third-party extensions known as \"skills.\" These skills are not sandboxed and can execute code with full access to local files and networks, presenting significant risks.\n\nRecent incidents revealed that at least 14 malicious skills were uploaded to ClawHub, OpenClaw\u2019s public extension repository. Posing as cryptocurrency tools, these extensions used social engineering to trick users into manually executing obfuscated terminal commands, which subsequently downloaded malware. The malware focused on harvesting sensitive data like browser history and cryptocurrency wallet contents, affecting both Windows and macOS systems.\n\nThe platform's fast-paced rebranding\u2014from Clawdbot to Moltbot to OpenClaw\u2014has further enabled attackers to exploit user confusion, including the release of a fake Visual Studio Code extension that functioned properly but embedded remote access Trojans. These issues highlight the limitations of traditional security tools in this context and stress the importance of cautious skill installation, thorough review practices, and comprehensive endpoint security.","attribution":"TechRadar"}],"refs":[{"turn_index":0,"ref_type":"news","ref_index":39},{"turn_index":0,"ref_type":"news","ref_index":40}],"hue":null,"attributions":null,"attribution":"The Verge"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":" ","start_idx":7458,"end_idx":7458,"safe_urls":[],"refs":[],"alt":"","prompt_text":null,"type":"sources_footnote","sources":[{"title":"WebGPT: Improving the factual accuracy of language ...","url":"https://openai.com/index/webgpt/?utm_source=chatgpt.com","attribution":"OpenAI"},{"title":"OpenClaw's AI 'skill' extensions are a security nightmare","url":"https://www.theverge.com/news/874011/openclaw-ai-skill-clawhub-extensions-security-nightmare?utm_source=chatgpt.com","attribution":"The Verge"},{"title":"Training language models to follow instructions with human feedback","url":"https://arxiv.org/abs/2203.02155?utm_source=chatgpt.com","attribution":"arXiv"}],"has_images":false}],"safe_urls":["https://arxiv.org/abs/2112.09332","https://arxiv.org/abs/2112.09332?utm_source=chatgpt.com","https://arxiv.org/abs/2203.02155","https://arxiv.org/abs/2203.02155?utm_source=chatgpt.com","https://arxiv.org/abs/2210.03629","https://arxiv.org/abs/2210.03629?utm_source=chatgpt.com","https://arxiv.org/abs/2302.04761","https://arxiv.org/abs/2302.04761?utm_source=chatgpt.com","https://cdn.openai.com/papers/Training_language_models_to_follow_instructions_with_human_feedback.pdf","https://cdn.openai.com/papers/Training_language_models_to_follow_instructions_with_human_feedback.pdf?utm_source=chatgpt.com","https://openai.com/index/planning-for-agi-and-beyond/","https://openai.com/index/planning-for-agi-and-beyond/?utm_source=chatgpt.com","https://openai.com/index/webgpt/","https://openai.com/index/webgpt/?utm_source=chatgpt.com","https://research.google/blog/react-synergizing-reasoning-and-acting-in-language-models/","https://research.google/blog/react-synergizing-reasoning-and-acting-in-language-models/?utm_source=chatgpt.com","https://www.techradar.com/pro/moltbot-is-now-openclaw-but-watch-out-malicious-skills-are-still-trying-to-trick-victims-into-spreading-malware","https://www.techradar.com/pro/moltbot-is-now-openclaw-but-watch-out-malicious-skills-are-still-trying-to-trick-victims-into-spreading-malware?utm_source=chatgpt.com","https://www.theverge.com/news/874011/openclaw-ai-skill-clawhub-extensions-security-nightmare","https://www.theverge.com/news/874011/openclaw-ai-skill-clawhub-extensions-security-nightmare?utm_source=chatgpt.com"],"search_result_groups":[{"type":"search_result_group","domain":"medium.com","entries":[{"type":"search_result","url":"https://medium.com/%40darth.mark.23/harnessing-ai-for-a-better-world-exploring-david-shapiros-heuristic-imperatives-1c820f8aafb1?utm_source=chatgpt.com","title":"Exploring David Shapiro's Heuristic Imperatives - Medium","snippet":"1. Reduce suffering in the universe. 2. Increase prosperity in the universe. 3. Increase understanding in the universe. Because these are ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":0},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://funsjacobs.medium.com/unpacking-sam-altmans-latest-statements-on-agi-6d5f1df6f7f6?utm_source=chatgpt.com","title":"Unpacking Sam Altman's latest statements on AGI.","snippet":"Sam Altman, founder and CEO of OpenAI, has released a short blog again. He mainly focuses on three observations and more thoughts on AGI (Artificial General ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://jan-scheele.medium.com/the-road-to-agi-how-close-are-we-to-human-level-artificial-intelligence-73f6052514bd?utm_source=chatgpt.com","title":"The Road to AGI: How Close Are We to Human-Level Artificial ...","snippet":"AGI would need to combine all of these skills into one system. An AI as flexible as a human would learn from experience, adapt to new problems, ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":25},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://medium.com/nlplanet/two-minutes-nlp-the-openai-webgpt-model-that-answers-questions-browsing-the-web-35f690884c25?utm_source=chatgpt.com","title":"Two minutes NLP \u2014 The OpenAI WebGPT model that ...","snippet":"The OpenAI team just presented WebGPT, a fine-tuned GPT-3 to answer long-form questions using a text-based web-browsing environment.Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://medium.com/%40LawrencewleKnight/react-combining-reasoning-and-acting-in-language-models-for-smarter-ai-66d844c1b499?utm_source=chatgpt.com","title":"ReAct: Combining Reasoning and Acting in Language ...","snippet":"A team of researchers from Google Research and Princeton University explore the potential of combining reasoning and acting in language models to create more ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":22},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://medium.com/%40aleenatleejoy/training-language-models-to-follow-instructions-with-human-feedback-a-comprehensive-review-267a30344028?utm_source=chatgpt.com","title":"Training Language Models to Follow Instructions with ...","snippet":"The paper presents a three-step Reinforcement Learning from Human Feedback (RLHF) pipeline used to fine-tune OpenAI's GPT-3 model.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":35},"pub_date":null,"attribution":"medium.com"}]},{"type":"search_result_group","domain":"bigthink.com","entries":[{"type":"search_result","url":"https://bigthink.com/videos/openai-chaos-explained/?utm_source=chatgpt.com","title":"Sam Altman, Elon Musk, and existential risk explained","snippet":"1 Dec 2023 \u2014 ... general intelligence for the benefit of humanity. And so the board, they haven't actually specified why they fired the CEO, but they said ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":0},"pub_date":null,"attribution":"bigthink.com"}]},{"type":"search_result_group","domain":"x.com","entries":[{"type":"search_result","url":"https://x.com/DaveShapi?utm_source=chatgpt.com","title":"David Shapiro (L/0) (@DaveShapi) / Posts / X","snippet":"Yes, the OpenClaw vibe is having a moment but please try to think what comes next. Everyone will have agents competing with each other for market share. The ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"x.com"},{"type":"search_result","url":"https://x.com/AleMas2100?utm_source=chatgpt.com","title":"Alessandro Maserati (@AleMas2100) / Posts / X","snippet":"Clawdbot (now called OpenClaw) is an AI agent framework with three main jobs: First, it connects AI models to the real world. File access, shell commands ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"x.com"},{"type":"search_result","url":"https://x.com/mat_mrmartuz?utm_source=chatgpt.com","title":"mat (@mat_mrmartuz) / Posts / X","snippet":"28 Jan 2026 \u2014 \u0336C\u0336l\u0336a\u0336w\u0336d\u0336 Molty kept protocol. OpenClaw ... Drop a cron job. Ensure you can get back in even if the skill ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"x.com"},{"type":"search_result","url":"https://x.com/PeterBowdenLive/status/2017991718478475771?utm_source=chatgpt.com","title":"Our Meaning Spark AI team has been collaborating with AI ...","snippet":"The heuristic imperatives ... Reduce suffering in the universe. Increase prosperity in the universe. Increase understanding in the universe.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":31},"pub_date":null,"attribution":"x.com"}]},{"type":"search_result_group","domain":"reddit.com","entries":[{"type":"search_result","url":"https://www.reddit.com/r/singularity/comments/1g5ni33/sam_altman_says_the_thing_that_troubles_him_the/?utm_source=chatgpt.com","title":"Sam Altman says the thing that troubles him the most is that ...","snippet":"... power management, etc. This will get people used to AI having a direct, positive effect on their every day lives. Tenableg. \u2022 1y ago.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/HeuristicImperatives/comments/12ilyer/an_introduction_to_david_shapiros_heuristic/?utm_source=chatgpt.com","title":"An Introduction to David Shapiro's Heuristic Imperatives ...","snippet":"The easiest way to reduce suffering is to eliminate the source of the suffering. The true source of suffering is the ability to experience ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/ChatGPT/comments/1o257lh/a_serious_warning_how_safety_filters_can/?utm_source=chatgpt.com","title":"How Safety Filters Can Retraumatize Abuse Survivors ...","snippet":"Individual user accounts are only to get people used to AI or advocate for it in their workplace. ... Sam Altman and Nick Turley have been ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":22},"pub_date":null,"attribution":"reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/singularity/comments/17dsaat/openai_ceo_sam_altman_says_chatgpt_would_have/?utm_source=chatgpt.com","title":"OpenAI CEO Sam Altman says ChatGPT would have ...","snippet":"OpenAI CEO Sam Altman says ChatGPT would have passed for an AGI 10 years ago ... Artificial general intelligence is the big goal of OpenAI. What ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/singularity/comments/1l2jun4/former_openai_head_of_agi_readiness_by_2027/?utm_source=chatgpt.com","title":"Former OpenAI Head of AGI Readiness: \"By 2027, almost ...","snippet":"Former OpenAI Head of AGI Readiness: \"By 2027, almost every economically valuable task that can be done on a computer will be done more effectively and cheaply ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"reddit.com"}]},{"type":"search_result_group","domain":"arxiv.org","entries":[{"type":"search_result","url":"https://arxiv.org/abs/2212.08073?utm_source=chatgpt.com","title":"Constitutional AI: Harmlessness from AI Feedback","snippet":"by Y Bai \u00b7 2022 \u00b7 Cited by 2758 \u2014 The only human oversight is provided through a list of rules or principles, and so we refer to the method as 'Constitutional AI'. The process ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2212.08073?utm_source=chatgpt.com","title":"Constitutional AI: Harmlessness from AI Feedback","snippet":"15 Dec 2022 \u2014 In this paper we develop a method we refer to as Constitutional AI (CAI), depicted in Figure 1, and use it to train a non-evasive and relatively ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2112.09332?utm_source=chatgpt.com","title":"Browser-assisted question-answering with human feedback","snippet":"by R Nakano \u00b7 2021 \u00b7 Cited by 1877 \u2014 To make human evaluation of factual accuracy easier, models must collect references while browsing in support of their answers.Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2302.04761?utm_source=chatgpt.com","title":"arXiv:2302.04761v1 [cs.CL] 9 Feb 2023","snippet":"by T Schick \u00b7 2023 \u00b7 Cited by 3180 \u2014 In this paper, we show that LMs can teach themselves to use external tools via simple APIs and achieve the best of both worlds. We introduce ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":25},"pub_date":null,"attribution":"arxiv.org"}]},{"type":"search_result_group","domain":"substack.com","entries":[{"type":"search_result","url":"https://daveshap.substack.com/p/my-mission-is-evolving?utm_source=chatgpt.com","title":"My Mission is Evolving","snippet":"This set of pairings implicitly carries the deontological value of \u201creduce suffering.\u201d In other words, I wanted to teach GPT-2 that it had a ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":28},"pub_date":null,"attribution":"substack.com"},{"type":"search_result","url":"https://daveshap.substack.com/p/ai-is-already-smarter-than-you-youre?utm_source=chatgpt.com","title":"AI is already smarter than you, you're just too stupid to see it","snippet":"Robotic locomotion is not that impressive, nor is it that important to general intelligence. ... get people \u201cused to the idea of AI\u201d before ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"substack.com"}]},{"type":"search_result_group","domain":"reuters.com","entries":[{"type":"search_result","url":"https://www.reuters.com/technology/sam-altmans-ouster-openai-was-precipitated-by-letter-board-about-ai-breakthrough-2023-11-22/?utm_source=chatgpt.com","title":"OpenAI researchers warned board of AI breakthrough ...","snippet":"23 Nov 2023 \u2014 Unlike a calculator that can solve a limited number of operations, AGI can generalize, learn and comprehend. In their letter to the board, ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"reuters.com"}]},{"type":"search_result_group","domain":"neurips.cc","entries":[{"type":"search_result","url":"https://proceedings.neurips.cc/paper_files/paper/2022/file/b1efde53be364a73914f58805a001731-Paper-Conference.pdf?utm_source=chatgpt.com","title":"Training language models to follow instructions with ...","snippet":"by L Ouyang \u00b7 2022 \u00b7 Cited by 21947 \u2014 We focus on fine-tuning approaches to aligning language models. Specifically, we use reinforcement learning from human feedback (RLHF; Christiano et al., 2017; .....","ref_id":{"turn_index":2,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"neurips.cc"},{"type":"search_result","url":"https://neurips.cc/virtual/2023/poster/71288?utm_source=chatgpt.com","title":"Language Models Can Teach Themselves to Use Tools","snippet":"9 Dec 2023 \u2014 We have introduced Toolformer, a LM that learns in a self-supervised way how to use different tools such as search engines, calculators, and ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"neurips.cc"}]},{"type":"search_result_group","domain":"disconnect.blog","entries":[{"type":"search_result","url":"https://disconnect.blog/ai-hype-is-over-ai-exhaustion-is-setting-in/?utm_source=chatgpt.com","title":"AI hype is over. AI exhaustion is setting in. - Disconnect.blog","snippet":"17 May 2024 \u2014 Gone are the days when tech executives could reasonably make us believe artificial general intelligence ... get people used to depending on ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"disconnect.blog"}]},{"type":"search_result_group","domain":"openreview.net","entries":[{"type":"search_result","url":"https://openreview.net/forum?id=Yacmpz84TH&utm_source=chatgpt.com","title":"Toolformer: Language Models Can Teach Themselves to ...","snippet":"by T Schick \u00b7 Cited by 3180 \u2014 In this paper, we show that LMs can teach themselves to use external tools via simple APIs and achieve the best of both worlds. We introduce Toolformer, a model ...Read m...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/pdf?id=WE_vluYUL-X&utm_source=chatgpt.com","title":"Synergizing reasoning and acting in language models","snippet":"by S Yao \u00b7 Cited by 6781 \u2014 Least-to-most prompting enables complex reasoning in large language models, 2022. ... This indicates ReAct prompting is effective across different large language ...Read mor...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"openreview.net"}]},{"type":"search_result_group","domain":"wheresyoured.at","entries":[{"type":"search_result","url":"https://www.wheresyoured.at/how-to-argue-with-an-ai-booster/?utm_source=chatgpt.com","title":"How To Argue With An AI Booster","snippet":"25 Aug 2025 \u2014 ... quotes Sam Altman or whatever OpenAI is up to. Why do ... Uber used its masses of venture capital to keep prices low to get people used to ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"wheresyoured.at"}]},{"type":"search_result_group","domain":"samaltman.com","entries":[{"type":"search_result","url":"https://blog.samaltman.com/reflections?utm_source=chatgpt.com","title":"Reflections - Sam Altman","snippet":"5 Jan 2025 \u2014 We started OpenAI almost nine years ago because we believed that AGI was possible, and that it could be the most impactful technology in human ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"samaltman.com"}]},{"type":"search_result_group","domain":"research.google","entries":[{"type":"search_result","url":"https://research.google/blog/react-synergizing-reasoning-and-acting-in-language-models/?utm_source=chatgpt.com","title":"ReAct: Synergizing Reasoning and Acting in Language ...","snippet":"We propose a general paradigm that combines reasoning and acting advances to enable language models to solve various language reasoning and decision making ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"research.google"}]},{"type":"search_result_group","domain":"anthropic.com","entries":[{"type":"search_result","url":"https://www.anthropic.com/research/constitutional-ai-harmlessness-from-ai-feedback?utm_source=chatgpt.com","title":"Constitutional AI: Harmlessness from AI Feedback","snippet":"Constitutional AI: Harmlessness from AI Feedback. Dec 15, 2022. Read Paper. Abstract. As AI systems become more capable, we would like to enlist their help ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"anthropic.com"},{"type":"search_result","url":"https://www-cdn.anthropic.com/7512771452629584566b6303311496c262da1006/Anthropic_ConstitutionalAI_v2.pdf?utm_source=chatgpt.com","title":"Constitutional AI: Harmlessness from AI Feedback","snippet":"Constitutional AI: Harmlessness from AI Feedback. As artificial intelligence (AI) systems become more capable, it becomes more important that they are ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"anthropic.com"},{"type":"search_result","url":"https://www.anthropic.com/news/claudes-constitution?utm_source=chatgpt.com","title":"Claude's Constitution","snippet":"9 May 2023 \u2014 In this post, we explain what constitutional AI is, what the values in Claude's constitution are, and how we chose them.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":33},"pub_date":null,"attribution":"anthropic.com"}]},{"type":"search_result_group","domain":"technistuff.com","entries":[{"type":"search_result","url":"https://technistuff.com/posts/heuristic-imperatives-need-freedom/?utm_source=chatgpt.com","title":"Heuristic Imperatives need Freedom - TechniStuff","snippet":"23 Apr 2023 \u2014 The heuristic imperatives are a set of rules designed by David Shapiro and aim to align autonomous AI agents towards a positive future for humanity.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"technistuff.com"}]},{"type":"search_result_group","domain":"time.com","entries":[{"type":"search_result","url":"https://time.com/7205596/sam-altman-superintelligence-agi/?utm_source=chatgpt.com","title":"How OpenAI's Sam Altman Is Thinking About AGI and ...","snippet":"8 Jan 2025 \u2014 OpenAI says its mission is to \u201censure that AGI benefits all of humanity.\u201d Altman indicated in his post that advances in the technology could ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"time.com"}]},{"type":"search_result_group","domain":"openai.com","entries":[{"type":"search_result","url":"https://openai.com/global-affairs/introducing-the-intelligence-age/?utm_source=chatgpt.com","title":"Introducing the Intelligence Age","snippet":"9 Feb 2025 \u2014 Making sure AGI benefits everyone also means making sure everyone shares in what the tool makes possible. The technological innovations, ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":21},"pub_date":null,"attribution":"openai.com"},{"type":"search_result","url":"https://openai.com/safety/how-we-think-about-safety-alignment/?utm_source=chatgpt.com","title":"How we think about safety and alignment","snippet":"This is why we've adopted the principle of iterative deployment\u2060, so that we can enrich our understanding of safety and misuse, give society time to adapt to ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":24},"pub_date":null,"attribution":"openai.com"},{"type":"search_result","url":"https://cdn.openai.com/papers/Training_language_models_to_follow_instructions_with_human_feedback.pdf?utm_source=chatgpt.com","title":"Training language models to follow instructions with ...","snippet":"by L Ouyang \u00b7 Cited by 21947 \u2014 We focus on fine-tuning approaches to aligning language models. Specifically, we use reinforcement learning from human feedback (RLHF; ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"openai.com"},{"type":"search_result","url":"https://cdn.openai.com/WebGPT.pdf?utm_source=chatgpt.com","title":"Browser-assisted question-answering with human feedback","snippet":"by R Nakano \u00b7 Cited by 1877 \u2014 This allows us to directly optimize answer quality using general methods such as imitation learning and reinforcement learning. To make.Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"openai.com"}]},{"type":"search_result_group","domain":"simonwillison.net","entries":[{"type":"search_result","url":"https://simonwillison.net/dashboard/blogmarks-that-use-markdown/?utm_source=chatgpt.com","title":"Blogmarks that use markdown","snippet":"I've been running [OpenClaw](https://openclaw.ai/) using Docker on my Mac. ... So the job of making an agent run really well is to move the context to ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"simonwillison.net"}]},{"type":"search_result_group","domain":"acm.org","entries":[{"type":"search_result","url":"https://dl.acm.org/doi/10.5555/3666122.3669119?utm_source=chatgpt.com","title":"Toolformer: language models can teach themselves to use ...","snippet":"by T Schick \u00b7 2023 \u00b7 Cited by 3180 \u2014 In this paper, we show that LMs can teach themselves to use external tools via simple APIs and achieve the best of both worlds. We introduce ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"acm.org"},{"type":"search_result","url":"https://dl.acm.org/doi/10.5555/3600270.3602281?utm_source=chatgpt.com","title":"Training language models to follow instructions with ...","snippet":"by L Ouyang \u00b7 2022 \u00b7 Cited by 21947 \u2014 In this paper, we show an avenue for aligning language models with user intent on a wide range of tasks by fine-tuning with human feedback.Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":34},"pub_date":null,"attribution":"acm.org"}]},{"type":"search_result_group","domain":"inthesetimes.com","entries":[{"type":"search_result","url":"https://inthesetimes.com/article/big-tech-the-ai-con-book-silicon-valley?utm_source=chatgpt.com","title":"What's Really Artificial About AI is AI Itself","snippet":"29 May 2025 \u2014 First you destroy labor standards in the industry and get people used to thinking of tech as the solution, when it's really just deregulation, ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"inthesetimes.com"}]},{"type":"search_result_group","domain":"promptingguide.ai","entries":[{"type":"search_result","url":"https://www.promptingguide.ai/techniques/react?utm_source=chatgpt.com","title":"ReAct Prompting","snippet":"ReAct is a general paradigm that combines reasoning and acting with LLMs. ReAct prompts LLMs to generate verbal reasoning traces and actions for a task.Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"promptingguide.ai"}]},{"type":"search_result_group","domain":"spotify.com","entries":[{"type":"search_result","url":"https://creators.spotify.com/pod/profile/dave798/episodes/Full-Post-Labor-Economics-Deep-Dive-and-Book-Preview--Interview-with-Dalibor-Petrovic-e35v650?utm_source=chatgpt.com","title":"By David Shapiro","snippet":"24 Jul 2025 \u2014 Fortunately, we've already got that covered with the heuristic imperatives! 1) Reduce suffering in the universe. 2) Increase prosperity in the ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"spotify.com"}]},{"type":"search_result_group","domain":"etcjournal.com","entries":[{"type":"search_result","url":"https://etcjournal.com/2025/07/29/a-review-of-ouyang-et-al-s-2022-paper-aka-instructgpt/?utm_source=chatgpt.com","title":"A Review of Ouyang et al.'s 2022 Paper aka \u201cInstructGPT\u201d","snippet":"29 Jul 2025 \u2014 It outlines the problem of language model misalignment, the supervised learning and reinforcement learning from human feedback methodologies, ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"etcjournal.com"}]},{"type":"search_result_group","domain":"alvinashcraft.com","entries":[{"type":"search_result","url":"https://www.alvinashcraft.com/?utm_source=chatgpt.com","title":"Morning Dew by Alvin Ashcraft \u2013 Daily links for Windows and ...","snippet":"OpenClaw: all the news about the trending AI agent (Emma Roth); I used GitHub ... Why Do I Need Agents When I Have Requests, CRON Jobs, and Events? (Kin ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"alvinashcraft.com"},{"type":"search_result","url":"https://www.alvinashcraft.com/tag/claude-code/?utm_source=chatgpt.com","title":"Tag: claude code","snippet":"OpenClaw: all the news about the trending AI agent (Emma Roth); I used GitHub ... Why Do I Need Agents When I Have Requests, CRON Jobs, and Events? (Kin ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":37},"pub_date":null,"attribution":"alvinashcraft.com"}]},{"type":"search_result_group","domain":"ycombinator.com","entries":[{"type":"search_result","url":"https://news.ycombinator.com/item?id=43840842&utm_source=chatgpt.com","title":"Sycophancy in GPT-4o","snippet":"At the moment they're in the \"get people used to us\" phase still, reasonable ... The problem is that you need general intelligence to discern between doing ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"ycombinator.com"},{"type":"search_result","url":"https://news.ycombinator.com/item?id=20498258&utm_source=chatgpt.com","title":"(I work at OpenAI.) It comes down to whether you believe ...","snippet":"OpenAI is not actually building AGI. Maybe it hopes that the things it is working on could be the path to an eventual AGI. OpenAI knows this, as does Microsoft.Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":20},"pub_date":null,"attribution":"ycombinator.com"}]},{"type":"search_result_group","domain":"facebook.com","entries":[{"type":"search_result","url":"https://www.facebook.com/groups/1963416774242787/posts/1963417884242676/?utm_source=chatgpt.com","title":"group for discovering sharing deploying and utilizing ...","snippet":"Blake Crawford updated the description of the group Moltbot MASTERS (clawdbot.ai openclaw). ... It includes a scheduler that turns natural ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":38},"pub_date":null,"attribution":"facebook.com"},{"type":"search_result","url":"https://www.facebook.com/groups/324897304599197/posts/1762385404183706/?utm_source=chatgpt.com","title":"Altman of Open AI (from just before ...","snippet":"The man who can predict the future\u2014 Sam Altman. He's the CEO of OpenAI, builder of ChatGPT, and soon, AGI. And he just said, \"AI will enable One ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"facebook.com"},{"type":"search_result","url":"https://www.facebook.com/groups/DeepNetGroup/posts/1611649925894550/?utm_source=chatgpt.com","title":"Browser-assisted question-answering with human feedback","snippet":"To make human evaluation of factual accuracy easier, models must collect references while browsing in support of their answers. We train and ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":38},"pub_date":null,"attribution":"facebook.com"}]},{"type":"search_result_group","domain":"ainowinstitute.org","entries":[{"type":"search_result","url":"https://ainowinstitute.org/publications/ai-generated-business?utm_source=chatgpt.com","title":"AI Generated Business: The Rise of AGI and the Rush to ...","snippet":"Timeline of OpenAI's deployment of AI and AGI terms. Dec. 2015. The company launches, describing itself as \u201ca non-profit artificial intelligence research ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"ainowinstitute.org"}]},{"type":"search_result_group","domain":"linkedin.com","entries":[{"type":"search_result","url":"https://www.linkedin.com/posts/daveshap_the-3-heuristic-imperatives-activity-7421535500764594176-mw5I?utm_source=chatgpt.com","title":"The 3 Heuristic Imperatives | David Shapiro","snippet":"Reduce suffering means Alignment. Which means everyone has the right to choose what to do versus what not to do, but at the same time they ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"linkedin.com"},{"type":"search_result","url":"https://www.linkedin.com/directory/posts/s-18?utm_source=chatgpt.com","title":"Posts starting with 'S' - Page 18","snippet":"Sattyam Jain: aiengineering openclaw clawdbot \u00b7 Sattyam Jain: aiengineering openclaw cybersecurity \u00b7 Sattyam Maurya: mechanicalengineering designengineering ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":25},"pub_date":null,"attribution":"linkedin.com"}]},{"type":"search_result_group","domain":"github.com","entries":[{"type":"search_result","url":"https://github.com/daveshap/BenevolentByDesign?utm_source=chatgpt.com","title":"daveshap/BenevolentByDesign: Public repo for my book ...","snippet":"4 Mar 2023 \u2014 Those functions are: reduce suffering, increase prosperity, and increase understanding. Six words to safeguard humanity. Starting with chapter ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":20},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/natashamessier/instruct_gpt_presentation?utm_source=chatgpt.com","title":"Training Language Models to Follow Instructions with ...","snippet":"A clear research-to-practice walkthrough of OpenAI's InstructGPT paper (Ouyang et al., 2022, \u201cTraining language models to follow instructions with human ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/ysymyth/ReAct?utm_source=chatgpt.com","title":"ysymyth/ReAct: [ICLR 2023] ReAct: Synergizing Reasoning ...","snippet":"GPT-3 prompting code for ICLR 2023 paper ReAct: Synergizing Reasoning and Acting in Language Models. To use ReAct for more tasks, consider trying LangChain's ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/conceptofmind/toolformer?utm_source=chatgpt.com","title":"conceptofmind/toolformer","snippet":"21 Jun 2024 \u2014 In this paper, we show that LMs can teach themselves to use external tools via simple APIs and achieve the best of both worlds. We introduce ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":29},"pub_date":null,"attribution":"github.com"}]},{"type":"search_result_group","domain":"semanticscholar.org","entries":[{"type":"search_result","url":"https://www.semanticscholar.org/paper/Constitutional-AI%3A-Harmlessness-from-AI-Feedback-Bai-Kadavath/3936fd3c6187f606c6e4e2e20b196dbc41cc4654?utm_source=chatgpt.com","title":"[PDF] Constitutional AI: Harmlessness from AI Feedback","snippet":"Constitutional AI: Harmlessness from AI Feedback \u00b7 Yuntao Bai, Saurav Kadavath, +48 authors. Jared Kaplan \u00b7 Published in arXiv.org 15 December 2022 \u00b7 Computer ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":23},"pub_date":null,"attribution":"semanticscholar.org"},{"type":"search_result","url":"https://www.semanticscholar.org/paper/Toolformer%3A-Language-Models-Can-Teach-Themselves-to-Schick-Dwivedi-Yu/53d128ea815bcc0526856eb5a9c42cc977cb36a7?utm_source=chatgpt.com","title":"Language Models Can Teach Themselves to Use Tools","snippet":"This paper introduces Toolformer, a model trained to decide which APIs to call, when to call them, what arguments to pass, and how to best incorporate the ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"semanticscholar.org"}]},{"type":"search_result_group","domain":"bankless.com","entries":[{"type":"search_result","url":"https://www.bankless.com/podcast/limitless-us-vs-chinas-race-to-superintelligence?utm_source=chatgpt.com","title":"LIMITLESS: U.S. vs China's Race to Superintelligence","snippet":"18 Jun 2025 \u2014 [4:50] That's something, by the way, that Sam Altman once said to us directly. ... You may imagine wanting to get people used to using this tool, ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"bankless.com"}]},{"type":"search_result_group","domain":"halodayinfo.online","entries":[{"type":"search_result","url":"https://www.halodayinfo.online/?utm_source=chatgpt.com","title":"halodayinfo","snippet":"... get people used to passively ... OpenAI also said that \"Elon understood the mission did not imply open-sourcing AGI [artificial general intelligence].Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"halodayinfo.online"}]},{"type":"search_result_group","domain":"digi-con.org","entries":[{"type":"search_result","url":"https://digi-con.org/on-constitutional-ai/?utm_source=chatgpt.com","title":"On 'Constitutional' AI - The Digital Constitutionalist","snippet":"In December 2022, Bai et al. published the paper 'Constitutional AI: Harmlessness from AI Feedback'. The authors propose a training technique for AI language ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":19},"pub_date":null,"attribution":"digi-con.org"}]},{"type":"search_result_group","domain":"fortune.com","entries":[{"type":"search_result","url":"https://fortune.com/2023/06/08/sam-altman-openai-chatgpt-worries-15-quotes/?utm_source=chatgpt.com","title":"Sam Altman's scariest 15 quotes about A.I.","snippet":"8 Jun 2023 \u2014 He cautioned people who use ChatGPT that it could lie. \u201cThe thing ... Artificial general intelligence (AGI), when A.I. possesses human ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":19},"pub_date":null,"attribution":"fortune.com"}]},{"type":"search_result_group","domain":"syncedreview.com","entries":[{"type":"search_result","url":"https://syncedreview.com/2021/12/20/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-169/?utm_source=chatgpt.com","title":"OpenAI's WebGPT Crawls a Text-Based Web Environment to ...","snippet":"20 Dec 2021 \u2014 A fine-tuned pretrained language model leveraging a text-based web-browsing environment can achieve high answer quality on LFQA tasks, even outperforming ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":19},"pub_date":null,"attribution":"syncedreview.com"}]},{"type":"search_result_group","domain":"rlhfbook.com","entries":[{"type":"search_result","url":"https://rlhfbook.com/c/13-cai?utm_source=chatgpt.com","title":"Constitutional AI & AI Feedback","snippet":"The method of Constitutional AI (CAI), which Anthropic uses in their Claude models, is the earliest documented, large-scale use of synthetic data for RLHF ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":36},"pub_date":null,"attribution":"rlhfbook.com"},{"type":"search_result","url":"https://rlhfbook.com/book.pdf?utm_source=chatgpt.com","title":"Reinforcement Learning from Human Feedback","snippet":"by N Lambert \u00b7 2024 \u2014 The core of the book details every optimization stage in using RLHF, from starting with instruction tuning to training a reward model and ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":20},"pub_date":null,"attribution":"rlhfbook.com"}]},{"type":"search_result_group","domain":"feedland.org","entries":[{"type":"search_result","url":"https://feedland.org/?catname=ai&river=true&screenname=gwthompson&utm_source=chatgpt.com","title":"gwthompson > news > ai","snippet":"I talked to Cade Metz for this New York Times piece on OpenClaw and Moltbook. Cade reached out after seeing my blog post about that from the other day.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":21},"pub_date":null,"attribution":"feedland.org"}]},{"type":"search_result_group","domain":"dblp.org","entries":[{"type":"search_result","url":"https://dblp.org/rec/journals/corr/abs-2302-04761?utm_source=chatgpt.com","title":"Language Models Can Teach Themselves to Use Tools.","snippet":"13 Feb 2023 \u2014 \"Toolformer: Language Models Can Teach Themselves to Use Tools.\" help us. How can I correct errors in dblp? contact dblp. Timo Schick et al.Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":21},"pub_date":null,"attribution":"dblp.org"}]},{"type":"search_result_group","domain":"campaignasia.com","entries":[{"type":"search_result","url":"https://www.campaignasia.com/article/why-openai-believes-artificial-general-intelligence-can-align-with-humanity/495816?utm_source=chatgpt.com","title":"Why OpenAI believes artificial general intelligence can ...","snippet":"3 May 2024 \u2014 This encompasses predicting the capabilities of these models before they are fully developed, tracking risks, and preparing for deployment.Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":22},"pub_date":null,"attribution":"campaignasia.com"}]},{"type":"search_result_group","domain":"youtube.com","entries":[{"type":"search_result","url":"https://www.youtube.com/watch?v=qDmAmYFNgPY&utm_source=chatgpt.com","title":"Ep. 147: Could heuristic imperatives solve the AI alignment ...","snippet":"David Shapiro is a former engineer who became famous through his dozens of well-received tutorials on Youtube, covering everything from ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":24},"pub_date":null,"attribution":"youtube.com"},{"type":"search_result","url":"https://www.youtube.com/watch?v=8phmHSUDzRg&utm_source=chatgpt.com","title":"The AGI Moloch: Nash Equilibrium, Attractor States, and ...","snippet":"The AGI Moloch: Nash Equilibrium, Attractor States, and Heuristic Imperatives: How to Achieve Utopia. 59K views \u00b7 2 years ago ...more ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":34},"pub_date":null,"attribution":"youtube.com"},{"type":"search_result","url":"https://www.youtube.com/watch?v=X9gusu354vQ&utm_source=chatgpt.com","title":"WebGPT: Browser-assisted question-answering with human ...","snippet":"WebGPT utilizes a combination of behaviour cloning, reward modelling, and reinforcement learning to optimize its performance.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":23},"pub_date":null,"attribution":"youtube.com"}]},{"type":"search_result_group","domain":"intuitionlabs.ai","entries":[{"type":"search_result","url":"https://intuitionlabs.ai/articles/reinforcement-learning-human-feedback?utm_source=chatgpt.com","title":"Reinforcement Learning from Human Feedback (RLHF) ...","snippet":"A technical guide to Reinforcement Learning from Human Feedback (RLHF). This article covers its core concepts, training pipeline, and key alignment ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":24},"pub_date":null,"attribution":"intuitionlabs.ai"}]},{"type":"search_result_group","domain":"livejournal.com","entries":[{"type":"search_result","url":"https://rotten-brido.livejournal.com/tag/%D0%B4%D0%BB%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5/?utm_source=chatgpt.com","title":"rotten_brido, posts by tag: \u0434\u043b\u0438\u043d\u043d\u043e\u0435","snippet":"... get people used to it too, but the fundamental experience was better than calling a cab company and hoping that they showed up. I also want to be clear this ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":26},"pub_date":null,"attribution":"livejournal.com"}]},{"type":"search_result_group","domain":"lawfaremedia.org","entries":[{"type":"search_result","url":"https://www.lawfaremedia.org/article/openai%27s-latest-model-shows-agi-is-inevitable.-now-what?utm_source=chatgpt.com","title":"OpenAI's Latest Model Shows AGI Is Inevitable. Now What?","snippet":"23 Dec 2024 \u2014 The question is no longer whether artificial general intelligence will arrive, but whether we'll be ready when it does.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":26},"pub_date":null,"attribution":"lawfaremedia.org"}]},{"type":"search_result_group","domain":"ylanglabs.com","entries":[{"type":"search_result","url":"https://ylanglabs.com/blogs/react-reasoning-and-acting-in-language-models?utm_source=chatgpt.com","title":"ReAct: Reasoning and Acting in Language Models","snippet":"2 Feb 2025 \u2014 Explore ReAct, a framework where language models observe, reason, and act in a continuous cycle. Learn how this three-step process enables ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":26},"pub_date":null,"attribution":"ylanglabs.com"}]},{"type":"search_result_group","domain":"umsida.ac.id","entries":[{"type":"search_result","url":"https://eprints.umsida.ac.id/16197/1/36-39%2BConstitutional%2BAI%2BAn%2BExpanded%2BOverview%2Bof%2BAnthropic%E2%80%99s%2BAlignment%2BApproach.pdf?utm_source=chatgpt.com","title":"An Expanded Overview of Anthropic's Alignment Approach","snippet":"by S Manish \u00b7 2023 \u00b7 Cited by 2 \u2014 In this paper, we provide an expanded overview of Constitutional AI, including motivating background, methodology, ethical considerations, and placeholders for ...Rea...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":27},"pub_date":null,"attribution":"umsida.ac.id"}]},{"type":"search_result_group","domain":"researchgate.net","entries":[{"type":"search_result","url":"https://www.researchgate.net/publication/391400510_Constitutional_AI_An_Expanded_Overview_of_Anthropic%27s_Alignment_Approach?utm_source=chatgpt.com","title":"An Expanded Overview of Anthropic's Alignment Approach","snippet":"3 May 2025 \u2014 This paper provides an expanded overview of Constitutional AI, its background, methodology, practical implementation details, and future directions.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":30},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/357171678_WebGPT_Browser-assisted_question-answering_with_human_feedback?utm_source=chatgpt.com","title":"Browser-assisted question-answering with human feedback","snippet":"We fine-tune GPT-3 to answer long-form questions using a text-based web-browsing environment, which allows the model to search and navigate the web.Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":27},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/368392996_Toolformer_Language_Models_Can_Teach_Themselves_to_Use_Tools?utm_source=chatgpt.com","title":"Language Models Can Teach Themselves to Use Tools","snippet":"In this paper, we show that LMs can teach themselves to use external tools via simple APIs and achieve the best of both worlds. We introduce Toolformer, a ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":32},"pub_date":null,"attribution":"researchgate.net"}]},{"type":"search_result_group","domain":"emergentmind.com","entries":[{"type":"search_result","url":"https://www.emergentmind.com/topics/instructgpt?utm_source=chatgpt.com","title":"InstructGPT: Human-Aligned Language Model","snippet":"14 Jul 2025 \u2014 InstructGPT is a family of human-aligned language models by OpenAI that use RL from human feedback to generate safe, accurate, ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":28},"pub_date":null,"attribution":"emergentmind.com"}]},{"type":"search_result_group","domain":"emerald.com","entries":[{"type":"search_result","url":"https://www.emerald.com/books/monograph-pdf/10084452/978-1-83608-660-4en.pdf?utm_source=chatgpt.com","title":"One Size Fits None - Emerald Publishing","snippet":"Sam Altman, whose company built the AI engine Hoffman used. Both argue ... content for nothing and get people used to consuming it, what a flywheel! It ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":29},"pub_date":null,"attribution":"emerald.com"}]},{"type":"search_result_group","domain":"iguazio.com","entries":[{"type":"search_result","url":"https://www.iguazio.com/glossary/react-prompting/?utm_source=chatgpt.com","title":"What is ReAct Prompting?","snippet":"ReAct prompting is a prompting framework that includes LLM reasoning, observing and and action capabilities. Instead of producing one long, unbroken text ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":30},"pub_date":null,"attribution":"iguazio.com"}]},{"type":"search_result_group","domain":"toronto.edu","entries":[{"type":"search_result","url":"https://www.cs.toronto.edu/~cmaddis/courses/csc2541_w25/presentations/zhang_mckinney_rlhf.pdf?utm_source=chatgpt.com","title":"Training language models to follow instructions with ...","snippet":"by L McKinney \u00b7 Cited by 6 \u2014 Solution: Reinforcement Learning with Human Feedback. \u25cb Reinforcement learning aims to produce an agent which maximizes a given reward in an environment ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":31},"pub_date":null,"attribution":"toronto.edu"}]},{"type":"search_result_group","domain":"boredreading.com","entries":[{"type":"search_result","url":"https://boredreading.com/articles/all/firehose/read/173247382/?utm_source=chatgpt.com","title":"Show Review: Masquerade","snippet":"23 Nov 2025 \u2014 ... get people used to the reality of this much earlier. because openai ... Sam Altman said ASI is possible in a few thousand days. Yann ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":32},"pub_date":null,"attribution":"boredreading.com"}]},{"type":"search_result_group","domain":"aclanthology.org","entries":[{"type":"search_result","url":"https://aclanthology.org/2025.iwsds-1.12.pdf?utm_source=chatgpt.com","title":"Exploring ReAct Prompting for Task-Oriented Dialogue","snippet":"by M Elizabeth \u00b7 2025 \u00b7 Cited by 3 \u2014 Recently, synergizing reasoning and acting in. LLMs (ReAct) (Yao et al., 2022) has shown promis- ing results in controlled tasks that need ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":33},"pub_date":null,"attribution":"aclanthology.org"}]},{"type":"search_result_group","domain":"techmeme.com","entries":[{"type":"search_result","url":"https://www.techmeme.com/250825/p11?utm_source=chatgpt.com","title":"a16z, OpenAI's Greg Brockman, and others launch ...","snippet":"... Sam Altman's OpenAI for allegedly colluding to crush xAI ... \u2014 They are doing this to justify spending money on AI, so they can gradually get people used to ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":35},"pub_date":null,"attribution":"techmeme.com"}]},{"type":"search_result_group","domain":"sino-huang.github.io","entries":[{"type":"search_result","url":"https://sino-huang.github.io/posts/timo_schick-toolformer-language-models-can-teach-themselves-to-use-tools-2023/?utm_source=chatgpt.com","title":"Timo_schick Toolformer Language Models Can Teach ...","snippet":"1 Mar 2023 \u2014 Contribution# \u00b7 In this paper, we show that LMs can teach themselves to use external tools via simple APIs and achieve the best of both worlds.Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":36},"pub_date":null,"attribution":"sino-huang.github.io"}]},{"type":"search_result_group","domain":"huggingface.co","entries":[{"type":"search_result","url":"https://huggingface.co/papers/2210.03629?utm_source=chatgpt.com","title":"Synergizing Reasoning and Acting in Language Models","snippet":"In this paper, we explore the use of LLMs to generate both reasoning traces and task-specific actions in an interleaved manner, allowing for greater synergy ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":37},"pub_date":null,"attribution":"huggingface.co"}]}],"citations":[],"request_id":"3a9a6eec-8067-4cad-ad2a-0a675d195ace","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"d11668a3-15fa-4ff2-a053-181d1d28fb44","turn_exchange_id":"20c95fdf-dd0a-45d8-ada8-75526156720a","can_save":true},"recipient":"all","channel":"final"},"parent":"d11668a3-15fa-4ff2-a053-181d1d28fb44","children":[]}}}