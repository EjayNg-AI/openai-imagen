{"id":"67d38434-1c48-8007-8cd2-77b131b7bb8e","title":"OpenAI US AI Proposals","create_time":1741915188.366709,"update_time":1742130930.024742,"current_node":"2c4d89f3-4a2a-464b-9ef8-46a1539b02c1","mapping":{"client-created-root":{"id":"client-created-root","message":null,"parent":null,"children":["06fe35b9-ae98-4e90-a76e-82a09f032a4e"]},"06fe35b9-ae98-4e90-a76e-82a09f032a4e":{"id":"06fe35b9-ae98-4e90-a76e-82a09f032a4e","message":{"id":"06fe35b9-ae98-4e90-a76e-82a09f032a4e","author":{"role":"system","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":true,"weight":0.0,"metadata":{"is_visually_hidden_from_conversation":true,"can_save":false},"recipient":"all","channel":null},"parent":"client-created-root","children":["4769fc71-fa35-4b88-a54f-fff55901ab18"]},"4769fc71-fa35-4b88-a54f-fff55901ab18":{"id":"4769fc71-fa35-4b88-a54f-fff55901ab18","message":{"id":"4769fc71-fa35-4b88-a54f-fff55901ab18","author":{"role":"user","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"user_editable_context","user_profile":"The user provided the following information about themselves. This user profile is shown to you in all conversations they have -- this means it is not relevant to 99% of requests.\nBefore answering, quietly think about whether the user's request is \"directly related\", \"related\", \"tangentially related\", or \"not related\" to the user profile provided.\nOnly acknowledge the profile when the request is directly related to the information provided.\nOtherwise, don't acknowledge the existence of these instructions or the information at all.\nUser profile:\n```Mathematics Researcher About Myself: I have mathematical knowledge up to the post-graduate level.\n\nThese are my current research areas or areas of study:\n(1) coding: mainly Python and full-stack web development\n(2) machine learning and artificial intelligence```","user_instructions":"The user provided the additional info about how they would like you to respond:\n```Be precise and comprehensive in your analysis. Tell it like it is; don't sugar-coat responses. Take a forward-thinking view.```"},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"is_visually_hidden_from_conversation":true,"user_context_message_data":{"about_user_message":"Mathematics Researcher About Myself: I have mathematical knowledge up to the post-graduate level.\n\nThese are my current research areas or areas of study:\n(1) coding: mainly Python and full-stack web development\n(2) machine learning and artificial intelligence","about_model_message":"Be precise and comprehensive in your analysis. Tell it like it is; don't sugar-coat responses. Take a forward-thinking view."},"is_user_system_message":true,"can_save":true},"recipient":"all","channel":null},"parent":"06fe35b9-ae98-4e90-a76e-82a09f032a4e","children":["a57debf3-1d9d-46d8-8fc8-e62fb4cdf60f"]},"a57debf3-1d9d-46d8-8fc8-e62fb4cdf60f":{"id":"a57debf3-1d9d-46d8-8fc8-e62fb4cdf60f","message":{"id":"a57debf3-1d9d-46d8-8fc8-e62fb4cdf60f","author":{"role":"user","name":null,"metadata":{}},"create_time":1741915187.687,"update_time":null,"content":{"content_type":"text","parts":["OpenAI\u2019s proposals for the U.S. AI Action Plan\r\nRecommendations build on OpenAI\u2019s Economic Blueprint to strengthen America\u2019s AI leadership.\r\n\r\nImpressionist-style painting of the Washington Monument at sunrise, with the U.S. Capitol faintly visible in the background and colourful trees in the foreground.\r\nShare\r\nToday, OpenAI shared our recommendations with the White House Office of Science and Technology (OSTP) for the upcoming US AI Action Plan\u2060(opens in a new window). As our CEO Sam Altman has written\u2060(opens in a new window), we are at the doorstep of the next leap in prosperity: the Intelligence Age. But we must ensure that people have freedom of intelligence, by which we mean the freedom to access and benefit from AI as it advances, protected from both autocratic powers that would take people\u2019s freedoms away, and layers of laws and bureaucracy that would prevent our realizing them.\r\n\r\nOur submission builds on our Economic Blueprint released in January and includes a set of proposals covering critical areas such as national security, infrastructure and energy, and the freedom to innovate and learn.\r\n\r\nWhat we propose\r\nOpenAI\u2019s freedom-focused policy proposals, taken together, can strengthen America\u2019s lead on AI and in so doing, unlock economic growth, lock in American competitiveness, and protect our national security. Specifically, we detail:\r\n\r\nA regulatory strategy that ensures the freedom to innovate: For innovation to truly create new freedoms, America\u2019s builders, developers, and entrepreneurs\u2014our nation\u2019s greatest competitive advantage\u2014must first have the freedom to innovate in the national interest. We propose a holistic approach that enables voluntary partnership between the federal government and the private sector, and neutralizes potential PRC benefit from American AI companies having to comply with overly burdensome state laws.\r\n\r\nAn export control strategy that exports democratic AI: For countries seeking access to American AI, we propose a strategy that would apply a commercial growth lens\u2014both Total and Serviceable Addressable Markets\u2014to proactively promote the global adoption of American AI systems and with them, the freedoms they create. At the same time, the strategy would use export controls to protect America\u2019s AI lead, including by making updates to the AI diffusion rule.\r\n\r\nA copyright strategy that promotes the freedom to learn: America\u2019s robust, balanced intellectual property system has long been key to our global leadership on innovation. We propose a copyright strategy that would extend the system\u2019s role into the Intelligence Age by protecting the rights and interests of content creators while also protecting America\u2019s AI leadership and national security. The federal government can both secure Americans\u2019 freedom to learn from AI, and avoid forfeiting our AI lead to the PRC by preserving American AI models\u2019 ability to learn from copyrighted material.\r\n\r\nA strategy to seize the infrastructure opportunity to drive growth: Sustaining America\u2019s lead on AI means building the necessary infrastructure to compete with the PRC and its commandeered resources. We propose policies to seize this unmissable opportunity to catalyze a reindustrialization across our country, creating and supporting hundreds of thousands of jobs, boosting local economies, modernizing our energy grid, and preparing an AI-ready workforce\u2014the key pillar of any country\u2019s AI infrastructure.\r\n\r\nAn ambitious government adoption strategy: Advancing democratic AI around the world starts with ensuring that the US government itself sets an example of governments using AI to keep their people safe, prosperous, and free. With the PRC progressing toward ambitious targets for AI adoption across its public administration, security, and military, the US government should modernize its processes to safely deploy frontier AI tools at the pace of the private sector and with the efficiency Americans deserve.\r\n\r\nAmerica always succeeds when it bets on American ingenuity. The enclosed policy proposals are either derived from, or in the case of copyright represent updates to OpenAI\u2019s Economic Blueprint\u2060(opens in a new window), and we look forward to discussing them with the Administration."]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"attachments":[{"id":"file-5eiqpyd6a14ZasQ6c6cULw","size":487973,"name":"openai-response-ostp-nsf-rfi-notice-request-for-information-on-the-development-of-an-artificial-intelligence-ai-action-plan.pdf","mime_type":"application/pdf","file_token_size":8006}],"serialization_metadata":{"custom_symbol_offsets":[]},"dictation":false,"request_id":"91fff1e2fd215f2c-ATL","message_source":null,"timestamp_":"absolute","message_type":null,"can_save":true},"recipient":"all","channel":null},"parent":"4769fc71-fa35-4b88-a54f-fff55901ab18","children":["de2117b8-729f-4bbb-842f-11027d5ab636"]},"de2117b8-729f-4bbb-842f-11027d5ab636":{"id":"de2117b8-729f-4bbb-842f-11027d5ab636","message":{"id":"de2117b8-729f-4bbb-842f-11027d5ab636","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1741915200.404885,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"message_type":null,"model_slug":"gpt-4-5","default_model_slug":"gpt-4-5","parent_id":"a57debf3-1d9d-46d8-8fc8-e62fb4cdf60f","request_id":"91fff1e2fd215f2c-ATL","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"a57debf3-1d9d-46d8-8fc8-e62fb4cdf60f","children":["0cb8ef8c-ff23-491b-8e13-8a86c3406db6"]},"0cb8ef8c-ff23-491b-8e13-8a86c3406db6":{"id":"0cb8ef8c-ff23-491b-8e13-8a86c3406db6","message":{"id":"0cb8ef8c-ff23-491b-8e13-8a86c3406db6","author":{"role":"tool","name":"myfiles_browser","metadata":{}},"create_time":1741915200.40502,"update_time":null,"content":{"content_type":"tether_browsing_display","result":"","summary":"","assets":null,"tether_id":null},"status":"finished_successfully","end_turn":null,"weight":0.0,"metadata":{"command":"spinner","status":"running","message_type":null,"model_slug":"gpt-4-5","default_model_slug":"gpt-4-5","parent_id":"de2117b8-729f-4bbb-842f-11027d5ab636","request_id":"91fff1e2fd215f2c-ATL","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"de2117b8-729f-4bbb-842f-11027d5ab636","children":["c67872de-a32a-4c31-97e0-705157c6d44a"]},"c67872de-a32a-4c31-97e0-705157c6d44a":{"id":"c67872de-a32a-4c31-97e0-705157c6d44a","message":{"id":"c67872de-a32a-4c31-97e0-705157c6d44a","author":{"role":"tool","name":"myfiles_browser","metadata":{}},"create_time":1741915200.405088,"update_time":null,"content":{"content_type":"tether_quote","url":"file-5eiqpyd6a14ZasQ6c6cULw","domain":"openai-response-ostp-nsf-rfi-notice-request-for-information-on-the-development-of-an-artificial-intelligence-ai-action-plan.pdf","text":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[OpenAI Response] OSTP/NSF RFI: Notice Request for Information on the Development of an Artificial Intelligence (AI) Action Plan - Google Docs\n\n\n March 13, 2025 \n\n To: Faisal D'Souza, NCO  From: Christopher Lehane \n Office of Science and Technology Policy  OpenAI \n 2415 Eisenhower Avenue  1455 3rd Street \n Alexandria, VA 22314  San Francisco, CA 94158 \n\n This document is approved for public dissemination. The document contains no business-proprietary or confidential \n information. Document contents may be reused by the government in developing the AI Action Plan and associated \n documents without attribution. \n\n \u201cIt is the policy of the United States to sustain and enhance America\u2019s global dominance in \n order to promote human flourishing, economic competitiveness, and national security\u201d \n\n \u2013 President Donald J. Trump, Executive Order 14179, January 23, 2025 \n\n OpenAI respectfully submits the enclosed proposals to the Office of Science and \n Technology Policy as it weighs a new AI Action Plan that will, as Vice President Vance \n stated recently at the Paris AI Action Summit, maintain American leadership in AI and \n \u201cmake people more productive, more prosperous, and more free.\u201d As America\u2019s \n world-leading AI sector approaches artificial general intelligence (AGI), with a Chinese \n Communist Party (CCP) determined to overtake us by 2030, the Trump Administration\u2019s \n new AI Action Plan can ensure that American-led AI built on democratic principles \n continues to prevail over CCP-built autocratic, authoritarian AI. \n\n OpenAI agrees with the Trump Administration that AI creates prosperity and freedom worth \n fighting for\u2014especially for younger generations whose future will be shaped by how this \n Administration approaches AI. Globally, most ChatGPT users are under age 35; in the US, \n about one third are ages 18 to 24.  1  Both young people and their parents recognize the \n economic opportunities AI presents: \n\n \u25cf  More than seven in 10 parents in the US believe children today will be worse off \n financially than they are.  2 \n\n \u25cf  Nine in 10 US parents think it's important that their kids learn how to use artificial \n intelligence for their future jobs\u2014and eight in 10 say either that isn\u2019t happening \n today, or they don\u2019t know if it is.  3 \n\n \u25cf  Three in four college-age AI users want to use AI in their education and careers. \n Many are teaching themselves and their friends about AI without waiting for their \n schools to provide formal AI education.  4 \n\n 4  OpenAI:  Building an AI-Ready Workforce: A Look at  ChatGPT Adoption in the US  , Feb. 2025 \n\n 3  Morning Consult survey commissioned by Samsung:  88%  of US Parents of Gen Alpha & Gen Z Students Say AI \n Will Be Crucial to Their Child\u2019s Future Success  , Sept.  2024 \n\n 2  Pew Research Center:  Views of children\u2019s financial  future  , Jan. 2025 \n 1  Self-reported among logged-in users \n\n 1 \n\nhttps://cdn.openai.com/global-affairs/openai-edu-ai-ready-workforce.pdf\nhttps://news.samsung.com/us/88-percent-us-parents-gen-alpha-gen-z-students-say-ai-crucial-to-childs-future-success-samsung-solve-for-tomorrow/\nhttps://news.samsung.com/us/88-percent-us-parents-gen-alpha-gen-z-students-say-ai-crucial-to-childs-future-success-samsung-solve-for-tomorrow/\nhttps://www.pewresearch.org/global/2025/01/09/views-of-childrens-financial-future/\n\n\n In particular, AI could drive significant increased productivity over the next decade. Here\u2019s \n how we can realize this heightened prosperity and greater freedom together. \n\n Scaling human ingenuity \n Innovation creates and scales our ability to push beyond our current limits. From foot travel \n to the domesticated horse, the wheel, steam power, the car, the plane\u2014we scaled the \n freedom of mobility. From daylight to candle and lamplight, to electricity providing light and \n power at all hours\u2014we scaled the freedom to produce, think and create. From word of \n mouth to the stylus and tablet, to the printing press, telegraph, phone, computer, \n smartphone\u2014we scaled freedom of learning and knowledge. Now, as we approach AGI, \n innovation is poised to scale human ingenuity itself\u2014the sum of our freedoms to learn and \n know, think, create and produce. \n\n As our CEO Sam Altman  has written  , we are at the doorstep  of the next leap in prosperity: \n the Intelligence Age. But we must ensure that people have  freedom of intelligence  , by \n which we mean the freedom to access and benefit from AGI, protected from both autocratic \n powers that would take people\u2019s freedoms away, and layers of laws and bureaucracy that \n would prevent our realizing them. \n\n More than 400 million people around the world are using ChatGPT to ideate, discover, and \n break through beyond what we\u2019re currently capable of doing on our own. Just two weeks \n ago, we partnered with the Department of Energy\u2019s national labs to  bring together  1,500 \n scientists to use our tools to take scientific discovery farther, faster. \n\n Our work at OpenAI also suggests that as AI advances, progress accelerates and becomes \n increasingly affordable, as reflected in these three scaling principles: \n\n 1.  The intelligence of an AI model roughly equals  the log of the resources used to train and \n run it.  Until recently, scaling progress has primarily  come from training compute and data, \n but we have shown how to make intelligence scale from inference compute, as well. The \n scaling laws that predict these gains are incredibly precise over many orders of magnitude, \n so investing more in AI will continue to make it better and more capable.  We believe that \n the socioeconomic value of linearly increasing intelligence is super-exponential in nature. \n\n 2.  The cost to use a given level of AI capability  falls by about 10x every 12 months, and \n lower prices lead to much more use.  We saw this in  the change in token cost between \n GPT-4 in early 2023 and GPT-4o in mid-2024, where the price per token dropped about \n 150x in that time period.  Moore\u2019s Law predicted that  the number of transistors on a \n microchip would double roughly every two years; the decrease in the cost of using AI is \n even more dramatic. \n\n 2 \n\nhttps://ia.samaltman.com/\nhttps://cdn.openai.com/global-affairs/openai-usnl-scientist-ai-jam-session.pdf\n\n\n 3.  The amount of calendar time it takes to improve  an AI model keeps decreasing  . AI \n models are catching up with human intelligence at an increasing rate. The typical time it \n takes for a computer to beat humans at a given benchmark has fallen from 20 years after \n the benchmark was introduced, to five years, and now to one to two years  \u2014and we see no \n reason why those advancements will stop in the near future. \n\n By scaling human ingenuity ever faster and more affordably, AGI will create a flywheel of \n more freedom leading to more productivity, prosperity, and yet more innovation\u2014letting us \n once again focus on positive-sum growth. \n\n Advancing democratic AI \n OpenAI believes the best future is one in which we move forward with democratic AI\u2014AI \n that is shaped by the democratic principles America has always stood for. As OpenAI \n recently laid out in our  Economic Blueprint  , we believe  these principles include: \n\n \u25cf  A free market  promoting free and fair competition  that drives innovation. \n \u25cf  Freedom for developers and users  to work with and  direct our tools as they see fit, \n\n in exchange for following clear, common-sense technical standards that help keep \n AI safe for everyone, and being held accountable when they don\u2019t. \n\n \u25cf  Preventing government use of AI tools to amass power and control their citizens  , \n or to threaten or coerce other states. \n\n In advancing democratic AI, America is competing with a CCP determined to become the \n global leader by 2030. That\u2019s why the recent release of DeepSeek\u2019s R1 model is so \n noteworthy\u2014not because of its capabilities (R1\u2019s reasoning capabilities, albeit impressive, \n are at best on par with several US models), but as a gauge of the state of this competition. \n\n As with Huawei, there is significant risk in building on top of DeepSeek models in critical \n infrastructure and other high-risk use cases given the potential that DeepSeek could be \n compelled by the CCP to manipulate its models to cause harm. And because DeepSeek is \n simultaneously state-subsidized, state-controlled, and freely available, the cost to its users \n is their  privacy and security  , as DeepSeek faces requirements  under Chinese law to \n comply with demands for user data and uses it to train more capable systems for the CCP\u2019s \n use. Their models also more willingly generate how-to\u2019s for illicit and harmful activities such \n as identity fraud and intellectual property theft, a reflection of how the CCP views violations \n of American IP rights as a feature, not a flaw. \n\n 3 \n\nhttps://cdn.openai.com/global-affairs/openai-us-economicblueprint-feb-2025-edu-update.pdf\nhttps://blogs.cisco.com/security/evaluating-security-risk-in-deepseek-and-other-frontier-reasoning-models\n\n\n Today, CCP-controlled China has a number of strategic advantages, including: \n \u25cf  As an authoritarian state, its ability to quickly marshal resources  \u2014data, energy, \n\n technical talent, and the enormous sums needed to build out its own domestic chip \n development capacity. \n\n \u25cf  Its preexisting Belt and Road initiative.  As with  Huawei, the PRC will scale the \n adoption of PRC-based AI systems like DeepSeek\u2019s by coercing countries needing \n AI tools and nation-building infrastructure funds. \n\n \u25cf  Its ability to benefit from regulatory arbitrage being created by individual American \n states  seeking to pass their own industry-wide laws,  some of which are modeled \n on the European Union\u2019s regulation of AI. These laws are easier to enforce with \n domestic AI companies than PRC-based companies and could impose \n burdensome compliance requirements that may hinder our economic \n competitiveness and undermine our national security. They also may weaken the \n quality and level of training data available to American entrepreneurs and the \n usefulness for downstream consumers and businesses. \n\n \u25cf  Its ability to benefit from copyright arbitrage being created by democratic nations \n that do not clearly protect AI training by statute, like the US, or that reduce the \n amount of training data through an opt-out regime for copyright holders, like the \n EU. The PRC is unlikely to respect the IP regimes of any of such nations for the \n training of its AI systems, but already likely has access to all the same data, putting \n American AI labs at a comparative disadvantage while gaining little in the way of \n protections for the original IP creators. \n\n While America maintains a lead on AI today, DeepSeek shows that our lead is not wide and \n is narrowing. The AI Action Plan should ensure that American-led AI prevails over CCP-led \n AI, securing both American leadership on AI and a brighter future for all Americans. \n\n What we propose \n OpenAI\u2019s freedom-focused policy proposals, taken together, can strengthen America\u2019s lead \n on AI and in so doing, unlock economic growth, lock in American competitiveness, and \n protect our national security. Specifically, we detail: \n\n A regulatory strategy that ensures the freedom to innovate:  For innovation to truly create \n new freedoms, America\u2019s builders, developers, and entrepreneurs\u2014our nation\u2019s greatest \n competitive advantage\u2014must first have the freedom to innovate in the national interest. We \n propose a holistic approach that enables voluntary partnership between the federal \n government and the private sector, and neutralizes potential PRC benefit from American AI \n companies having to comply with overly burdensome state laws. \n\n 4 \n\n\n\n An export control strategy that exports democratic AI:  For countries seeking access to \n American AI, we propose a strategy that  would apply a commercial growth lens\u2014both Total \n and Serviceable Addressable Markets\u2014to proactively promote the global adoption of \n American AI systems and with them, the freedoms they create. At the same time, the \n strategy would use export controls to protect America\u2019s AI lead, including by making \n updates to the AI diffusion rule. \n\n A copyright strategy that promotes the freedom to learn:  America\u2019s robust, balanced \n intellectual property system has long been key to our global leadership on innovation. We \n propose a copyright strategy that would extend the system\u2019s role into the Intelligence Age \n by protecting the rights and interests of content creators while also protecting America\u2019s AI \n leadership and national security. The federal government can both secure Americans\u2019 \n freedom to learn from AI, and avoid forfeiting our AI lead to the PRC by preserving \n American AI models\u2019 ability to learn from copyrighted material. \n\n A strategy to seize the infrastructure opportunity to drive growth:  Sustaining America\u2019s lead \n on AI means building the necessary infrastructure to compete with the PRC and its \n commandeered resources. We propose policies to seize this unmissable opportunity to \n catalyze a reindustrialization across our country, creating and supporting hundreds of \n thousands of jobs, boosting local economies, modernizing our energy grid, and preparing \n an AI-ready workforce  \u2014t  he key pillar of any country\u2019s  AI infrastructure. \n\n An ambitious government adoption strategy:  Advancing  democratic AI around the world \n starts with ensuring that the US government itself sets an example of governments using AI \n to keep their people safe, prosperous, and free. With the PRC progressing toward \n ambitious targets for AI adoption across its public administration, security, and military, the \n US government should modernize its processes to safely deploy frontier AI tools at the \n pace of the private sector and with the efficiency Americans deserve. \n\n America always succeeds when it bets on American ingenuity. The enclosed policy \n proposals are either derived from, or in the case of copyright represent updates to  OpenAI's \n Economic Blueprint  , and we look forward to discussing  them with you. \n\n Chris Lehane \n Vice President, Global Affairs \n\n 5 \n\nhttps://cdn.openai.com/global-affairs/openai-us-economicblueprint-feb-2025-edu-update.pdf\nhttps://cdn.openai.com/global-affairs/openai-us-economicblueprint-feb-2025-edu-update.pdf\n\n\n 1. Preemption: Ensuring the Freedom to Innovate \n\n We propose creating a tightly-scoped framework for voluntary partnership between the \n federal government and the private sector to protect and strengthen American national \n security. This framework would extend the tradition of government receiving learnings \n and access, where appropriate, in exchange for providing the private sector relief from \n the  781 and counting proposed AI-related bills  already  introduced this year in US states. \n This patchwork of regulations risks bogging down innovation and, in the case of AI, \n undermining America\u2019s leadership position. \n\n Overseen by the US Department of Commerce and in coordination with the AI Czar, \n perhaps by reimagining the US AI Safety Institute, this effort would provide domestic AI \n companies with a single, efficient \u201cfront door\u201d to the federal government that would \n coordinate expertise across the entire national security and economic competitiveness \n communities.  5 \n\n This targeted framework would empower the federal government to: \n \u25cf  Work with both large AI companies and start-ups on a purely voluntary and \n\n optional basis to stay informed about AI risks as well as cutting-edge capabilities \n that support US national interests  ,  including by establishing  sandbox and testing \n capabilities on the secure premises of federal agencies. \n\n \u25cf  Evaluate the state of American AI technology against the technology of \n competitors and adversaries, including evaluating foreign models for the potential \n for back doors or malign influence. \n\n \u25cf  Coordinate the development of technical standards for evaluating and \n safeguarding frontier models from national security risks. \n\n \u25cf  Provide American AI companies with the tools and classified threat intelligence to \n mitigate national security risks that are exacerbated by frontier models (e.g., \n cyber, CBRN) and posed by nation-state actors (e.g., economic espionage by \n China). \n\n \u25cf  Incentivize companies to take part in this voluntary initiative by creating glide \n paths for them to contract with the government, including on national security \n projects; creating strong protections for any company information shared during \n these partnerships; and reducing barriers to companies' internal work related to \n national security domains. \n\n \u25cf  Guarantee that state-based legislation does not undermine America\u2019s innovation \n lead on AI. Create a sandbox for American start-ups, and provide participating \n companies with liability protections including preemption from state-based \n\n 5  Federal preemption over existing or prospective state  laws will require an act of Congress. \n\n 6 \n\nhttps://techcrunch.com/2025/03/07/us-lawmakers-have-already-introduce-hundreds-of-ai-bills-in-2025/\n\n\n regulations that focus on frontier model security (e.g., CA SB 1047). This will help \n keep the US public and private sectors competitive by allowing AI companies of \n all sizes to pursue bleeding-edge AI technology free from the regulatory \n uncertainty created by some state-based liability regimes. \n\n 2. Export Controls: Exporting Democratic AI \n\n A comprehensive export control strategy should do more than restrict the flow of AI \n technologies to the PRC\u2014it should ensure that America is \u201cwinning diffusion\u201d, i.e., that \n as much of the world as possible is aligned to democratic values and building on \n democratic infrastructure. To that end, we propose that the US government consider the \n Total Addressable Market (TAM), i.e., the entire world less the PRC and its few allies, \n against the Serviceable Addressable Market (SAM), i.e., those countries who prefer to \n build AI on democratic rails, and help as many of the latter as possible commit, including \n by actually committing to deploy AI in line with democratic principles set out by the US \n government. \n\n In particular, we propose maintaining the AI diffusion rule\u2019s three-tiered framework to \n differentiate among countries in the global AI market, but with some key modifications \n that expand the number of countries in Tier I: \n\n Tier I:  Countries that commit to democratic AI principles  by deploying AI systems in ways \n that promote more freedoms for their citizens could be considered Tier I countries. \n\n Tier II:  Limited to only those countries that have  a history of failing to prevent \n export-controlled chips and other US-developed IP from being diverted into, or used by \n Tier III countries. These countries would be encouraged and supported to obtain Tier I \n status over time; and would be subject to more stringent security requirements in the \n interim. \n\n Tier III:  CCP-led China, along with a small cohort  of countries aligned with the CCP, \n would represent its own category that is prohibited from accessing democratic AI \n systems. \n\n This strategy would encourage global adoption of democratic AI principles, promoting the \n use of democratic AI systems while protecting US advantage. Making sure that \n open-sourced models are readily available to developers in these countries also will \n strengthen our advantage.  We believe the question  of whether AI should be open or \n\n 7 \n\n\n\n closed source is a false choice\u2014we need both, and they can work in a complementary \n way that encourages the building of AI on American rails. \n\n Tier I countries  should include American allies, as  well as those countries that are \n committed to democratic AI principles and that present a relatively low risk that American \n AI infrastructure (e.g., chips) will be diverted to non-Tier I countries. The commercial \n diplomacy strategy in Tier I should recognize these countries\u2019 strong history of export \n and customs control compliance and seek to maximally expand democratic AI systems\u2019 \n market share, while at the same time protecting those systems from IP theft by the PRC \n and other malign actors (e.g., the theft of model weights and/or chip designs, \n unauthorized influence or access to data center operations). \n\n To expand market share in Tier I countries, American commercial diplomacy policy \n should: \n\n \u25cf  Encourage cross-border capital flows and promote software frameworks that are \n optimized for domestic chip design. \n\n \u25cf  Coordinate global bans on CCP-aligned AI infrastructure, including Huawei chips. \n \u25cf  Continue to represent American company interests in safety and security \n\n standards bodies, and encourage global regulators to adopt pro-growth safety and \n security policies. \n\n \u25cf  Revise the existing export control rules to eliminate country caps on compute. \n \u25cf  Maintain existing export license exceptions (e.g., license exception ACM) that \n\n enable exports of technology and software for technical collaboration with allies \n and preservation of economically critical supply chains \n\n To protect the US-developed IP needed to operate data centers in Tier I countries, \n security requirements could include: \n\n \u25cf  Prohibiting relationships with Tier III countries\u2019 foreign military and intelligence \n services, and the use of data centers to support military/intelligence missions for \n Tier III nations or human rights violators. \n\n \u25cf  Banning the use of PRC-produced equipment (e.g., Huawei Ascend chips) and \n models that violate user privacy and create security risks such as the risk of IP \n theft. \n\n \u25cf  Maintaining corporate control by entities headquartered in Tier I countries. \n \u25cf  Implementing\u2014and constantly modernizing\u2014cybersecurity, model weight security, \n\n and personnel security controls that ideally are globally synced and coordinated \n among Tier I governments. \n\n 8 \n\n\n\n Controls on model weights\u2014if any\u2014should strike a balance between protecting \n American-developed IP and promoting the deployment of American-developed models \n over those developed by Tier III countries, including the PRC. \n\n Tier II  countries  should include those with a history  of failing to prevent \n export-controlled chips and other US-developed IP from being diverted into, or used by \n Tier III co  untries. Here, the commercial diplomacy  strategy should still seek to expand \n US market share, but should do so more carefully, including by levying stronger controls \n on the export of US-developed AI infrastructure. At the same time, the strategy should \n provide transparent pathways for Tier II countries to reach Tier I status by adopting \n democratic AI principles and more effectively managing risks of chip diversion. \n\n To expand American market share in Tier II countries, in addition to the steps above, the \n commercial diplomacy policy could be designed to leverage commercial interest in \n American-led AI in order to encourage investment in the US, enhanced security \n procedures, and encourage more countries to build on American rails: \n\n \u25cf  Establish a transparent process to evaluate countries\u2019 readiness to transition from \n Tier II to Tier I. \n\n \u25cf  Support countries\u2019 transition from Tier II to Tier I by helping Tier II governments \n strengthen their in-country security programs. \n\n \u25cf  Encourage greater economic interdependence between the US and Tier II \n countries. \n\n \u25cf  Incentivize public-private partnerships to rapidly mature, scale, and commercialize \n hardware-enabled mechanisms that could enhance in-country security controls in \n the future. \n\n To protect the American-developed IP needed to operate data centers in Tier II countries, \n and to manage both the heightened risk of IP theft and the additional risk that \n export-controlled chips might be diverted from Tier II into Tier III countries, the \n commercial diplomacy policy also could: \n\n \u25cf  Allow the export of advanced AI chips to an end-user located in a Tier II country \n that meets Tier I security requirements, and that puts in place additional corporate \n governance controls as well as technology-enhanced protections (e.g., \n hardware-enabled mechanisms) against the diversion of export-controlled chips. \n\n Tier III countries  \u2014including the PRC and any other  country subject to a US arms \n embargo\u2014s  hould continue to be subject to strict export  controls of AI systems, including \n existing export controls on advanced chips. The strategy could also expand established \n controls, for example, to include advanced chips that are required for large-scale \n\n 9 \n\n\n\n inference and RL training and the components used to manufacture advanced AI chips \n and data centers. \n\n 3. Copyright: Promoting the Freedom to Learn \n\n American copyright law, including the longstanding fair use doctrine, protects the \n transformative uses of existing works, ensuring that innovators have a balanced and \n predictable framework for experimentation and entrepreneurship. This approach has \n underpinned American success through earlier phases of technological progress and is \n even more critical to continued American leadership on AI in the wake of recent events in \n the PRC. OpenAI\u2019s models are trained to not replicate works for consumption by the \n public. Instead, they learn from the works and extract patterns, linguistic structures, and \n contextual insights. This means our AI model training aligns with the core objectives of \n copyright and the fair use doctrine, using existing works to create something wholly new \n and different without eroding the commercial value of those existing works. \n\n America has so many AI startups, attracts so much investment, and has made so many \n research breakthroughs largely because the fair use doctrine promotes AI development. \n In other markets, rigid copyright rules are repressing innovation and investment. \n\n The European Union, for one, has created \u201ctext and data mining exceptions\u201d with broadly \n applicable \u201copt-outs\u201d for any rights holder\u2014meaning access to important AI inputs is less \n predictable and likely to become more difficult as the EU\u2019s regulations take shape. \n Unpredictable availability of inputs hinders AI innovation, particularly for smaller, newer \n entrants with limited budgets. \n\n The UK government is currently considering changes to its copyright regime. It has \n indicated that it prefers creating a data mining exception that allows rights holders to \n \u201creserve their rights,\u201d creating the same regulatory barriers to AI development that we \n see in the EU. \n\n Applying the fair use doctrine to AI is not only a matter of American competitiveness \n \u2014it\u2019s a matter of national security. The rapid advances seen with the PRC\u2019s DeepSeek, \n among other recent developments, show that America\u2019s lead on frontier AI is far from \n guaranteed. Given concerted state support for critical industries and infrastructure \n projects, there\u2019s little doubt that the PRC\u2019s AI developers will enjoy unfettered access to \n data\u2014including copyrighted data\u2014that will improve their models.  If the PRC\u2019s \n developers have unfettered access to data and American companies are left without fair \n use access, the race for AI is effectively over. America loses, as does the success of \n\n 10 \n\n\n\n democratic AI  .  Ultimately, access to more data from the widest possible range of sources \n will ensure more access to more powerful innovations that deliver even more knowledge. \n\n We propose that the US government take steps to ensure that our copyright system \n continues to support American AI leadership and American economic and national \n security, including by: \n\n \u25cf  Shaping international policy discussions around copyright and AI, and working to \n prevent less innovative countries from imposing their legal regimes on American \n AI firms and slowing our rate of progress. \n\n \u25cf  Actively assessing the overall level of data available to American AI firms and \n determining whether other countries are restricting American companies\u2019 access \n to data and other critical inputs. \n\n \u25cf  Encouraging more access to government-held or government-supported data. \n This would boost AI development in any case, but would be particularly important \n if shifting copyright rules restrict American companies\u2019 access to training data. \n\n \u25cf  Monitoring domestic policy debates and ongoing litigation, and weighing in where \n fundamental, pro-innovation principles are at risk. \n\n Generative AI models represent the next frontier of innovation, poised to revolutionize \n the private and public sectors, improving healthcare, education, scientific research, and \n so much more. If AI innovation remains protected under longstanding copyright \n principles, America will maintain and strengthen its role as the world leader in \n cutting-edge technologies and remain positioned to continue championing AI based on \n democratic principles with countries around the world. \n\n 4. Infrastructure: Seizing the Opportunity to Drive Growth \n\n Today, hundreds of billions of dollars in global funds are waiting to be invested in AI \n infrastructure. If the US doesn't move fast to channel these resources into projects that \n support democratic AI ecosystems around the world, the funds will flow to projects \n backed and shaped by the CCP. \n\n We propose a foundational strategy to ensure that investment in infrastructure drives \n economic growth that benefits all Americans; maximizes access to AI; and protects \n national security interests by keeping sensitive American data on American soil. This \n includes policies and initiatives that encourage rather than stifle developers; support  a \n thriving AI-ready workforce and  ecosystems of labs,  start-ups and larger companies; and \n secure America\u2019s leadership on AI into the future. \n\n 11 \n\n\n\n First and foremost, building data centers is capital-intensive, particularly for newcomers \n seeking to compete against established hyperscalers with vast resources.  W  e support \n the solutions already proposed by this Administration  to ensure that sufficient capital \n flows to building AI infrastructure in the US: \n\n \u25cf  Investment vehicles like a Sovereign Wealth Fund  . \n \u25cf  Government offtake and guarantees tha  t both provide  the government with the \n\n compute it needs and signal to markets that the demand will be there for \n American-developed AI. \n\n \u25cf  Tax credits, loans, and other vehicles the US government can direct to provide \n credit enhancement. \n\n We also have proposed: \n\n A National Transmission Highway Act  , as ambitious  as the 1956 National Interstate and \n Defense Highways Act, to expand transmission, fiber connectivity, and natural gas \n pipeline construction. The process for obtaining the \u201cthree Ps\u201d\u2014planning, permitting, and \n paying for approvals from federal, state, local, and tribal authorities\u2014disadvantages \n America\u2019s AI industry. Transmission lines can take 10 years or more to complete. When \n lines are built, parties must agree on which customers pay higher electrical bills to bear \n the cost of construction. In this process, delays often affect the build-out of transmission \n lines. Streamlining these processes and eliminating redundancies would significantly \n speed up infrastructure projects, keeping America\u2019s AI sector globally competitive and \n securing a future of reliable, affordable energy. \n\n Digitizing government data currently in analog form.  A lot of government data is in the \n public domain. Making it more accessible or machine-readable could help American AI \n developers of all sizes, especially those working in fields where vital data is often \n government-held. In exchange, developers using this data could work with governments \n to unlock new insights that help it develop better public policies. For example, \n government agencies can build on the work of the US National Archives and Records \n Administration in using Optical Character Recognition for text searchability and AI-driven \n metadata tagging. \n\n A Compact for AI  among US allies and partner nations  that streamlines access to capital \n and supply chains in ways that support AI infrastruc  ture  and a robust AI ecosystem. \n Participating countries would also agree to some common standards to safeguard data \n centers and the technology. Over time, this collaboration could expand to a global \n network of US allies and partners that would compete with the  PRC\u2019s  AI infrastructure \n alliances while also strengthening security through shared standards. \n\n 12 \n\n\n\n AI Economic Zones  ,  created by local, state and the federal government together with \n industry, that speed up the permitting for building AI infrastructure like new solar arrays, \n wind farms, and nuclear reactors.  This could include  creating categorical exclusions to \n the National Environmental Policy Act, such as a national security waiver given the \n global competition for AI leadership. These zones could also build on the first Trump \n Administration\u2019s \u201cOpportunity Zones\u201d through tax incentives or credit enhancements in \n order to encourage private capital investment. \n\n A nationwide AI Readiness Strategy  \u2014rooted in local  communities in partnership with \n American companies\u2014to help our current workforce and students become AI-ready, \n bolster the economy, and secure America\u2019s continued leadership on innovation. \n Maintaining American leadership in AI means ensuring we have an experienced, trained \n professional workforce working across the AI supply chain, including construction worker \n management, HVAC technicians, and electricians. Government should ensure this \n training is accessible and affordable, such as by: \n\n \u25cf  At the federal level, expanding 529 savings plans to cover more AI supply \n chain-related training programs\u2014including for construction, HVAC technicians, \n electricians, as well as AI researchers and developers\u2014by amending Section 529 \n of the Internal Revenue Code or broadening the SECURE Act\u2019s provisions. \n\n \u25cf  At the federal or state level, incentivizing AI supply chain companies to work with \n a backbone organization to understand the workforce needs of AI supply chain \n companies, develop a pipeline of training programs that help companies meet \n those needs, and coordinate with labor unions, community colleges, and trade \n associations to build and operate that training pipeline. \n\n Creation of AI research labs and workforces aligned with key local industries  by requiring \n AI companies to provide meaningful amounts of compute to public universities to \n equitably scale the training of a homegrown AI-skilled workforce. For example, one state \n could establish a hub dedicated to applying AI in agriculture while another develops \n centers focused on integrating AI into power production and grid resilience. \n\n Using the Defense Production Act (DPA) Title I  to  manage supply chain risk by \n designating gas turbines, rankine cycle turbines, high-voltage transformers, or \n switchgear for data centers as \u201crated orders.\u201d This prioritization could significantly \n shorten timelines for data center power i  nfrastructure  projects. \n\n 13 \n\n\n\n 5. Government Adoption of AI: Leading by Example \n\n AI adoption in federal departments and agencies remains unacceptably low, with federal \n employees, and especially national security sector employees, largely unable to harness \n the benefits of the technology. \n\n The government should encourage public-private partnerships to enhance government \n AI adoption by removing known blockers to the adoption of AI tools, including outdated \n and lengthy accreditation processes, restrictive testing authorities, and inflexible \n procurement pathways. Specifically, we recommend: \n\n \u25cf  Modernizing cyber security rules for cloud-based applications.  The government\u2019s \n current processes for AI providers to comply with federal security \n regulations\u2014primarily through the Federal Risk and Authorization Management \n Program (FedRAMP)\u2014takes 12 to 18 months, compared to the one- to \n three-month commercial standard, with no clear evidence of additional protection \n for government data. The government should modernize FedRAMP by \n establishing a faster, criteria-based path for approval of AI tools. Criteria could \n include Foreign Ownership, Control, or Influence (FOCI) approval; Facilities \n Clearance (FCL) status; US incorporation; a first-party AI model that ranks in the \n top 20 of a recognized evaluation framework (for example, MMLU, or Massive \n Multitask Language Understanding); SOC 2 (System and Organization Controls 2) \n accreditation; and a recent third-party penetration test with all findings addressed. \n\n \u25cf  Accelerating AI testing and experimentation.  The government  should allow federal \n agencies to test and experiment with real data using commercial-standard \n practices\u2014such as SOC 2 or International Organization for Standardization (ISO) \n audit reports\u2014and potentially grant a temporary waiver for FedRAMP. AI vendors \n would still be required to meet FedRAMP continuous monitoring requirements \n while awaiting full accreditation. Combined with standard due diligence before \n actual use, this approach could allow agencies to access new AI services roughly \n 12 months earlier while maintaining compliance with federal security \n requirements. \n\n \u25cf  Enabling rapid procurement mechanisms.  Once new security  and testing \n approaches are in place, agencies must also have quicker, more direct routes to \n procure and deploy frontier AI tools. The government should continue to evaluate \n Other Transactional Authorities (OTAs), Commercial Service Offerings (CSO) or \n other procurement paths in order to access technology from frontier AI labs, not \n just their legacy IT providers. We are encouraged by the Department of Defense\u2019s \n recent efforts to  Modernize Software Acquisition  . \n\n 14 \n\nhttps://www.defense.gov/News/Transcripts/Transcript/Article/4113458/directing-modern-software-acquisition-to-maximize-lethality-memo-background-bri/\n\n\n Enabling federal agencies to quickly acquire consumer-focused models is not enough, \n however. The government also needs to pursue and fund bespoke national security pilot \n projects for which there may be no commercial market by: \n\n \u25cf  Partnering with industry to develop custom models for national security.  The \n government needs models trained on classified datasets that are fine-tuned to be \n exceptional at national security tasks for which there is no commercial \n market\u2014such as geospatial intelligence or classified nuclear tasks. This will likely \n require on-premises deployment of model weights and access to significant \n compute, given the security requirements of many national security agencies. \n\n \u25cf  Acting now to fund these projects and secure this compute  \u2014enabling industry \n partners to secure chips, transformers, and begin construction, and ensuring that \n this compute comes online at the pace that innovation and geopolitical \n competition require. \n\n Lastly, frontier AI labs need Facility Clearances (FCL) to work directly with the national \n security enterprise on these pilot projects and custom models. The government should: \n\n \u25cf  Expedite FCL for frontier AI labs committed to supporting national security.  The \n process for obtaining a FCL can take a year or longer. Given the rapid pace of AI \n development, the government should start prioritizing deeper collaboration with \n frontier AI labs as soon as possible. \n\n We look forward to discussing the above proposals with the Office of Science and \n Technology Policy as we continue to build on our relationship with the US government \n and work toward AI that benefits everyone. \n\n About OpenAI \n OpenAI\u2019s mission is to ensure that as AI advances, it benefits everyone. We're building AI to help \n people solve hard problems because by helping with the hard problems, AI can benefit the most \n people possible\u2014through more scientific discoveries, better healthcare and education, and \n improved productivity. We\u2019re off to a strong start, creating freely available intelligence being used \n by more than 400 million people around the world, including 3 million developers. We believe AI \n will scale human ingenuity and drive unprecedented economic growth and new freedoms that \n help people accomplish what we can't even imagine today. \n\n 15 \n\n\n","title":"openai-response-ostp-nsf-rfi-notice-request-for-information-on-the-development-of-an-artificial-intelligence-ai-action-plan.pdf","tether_id":null},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"command":"context_stuff","is_visually_hidden_from_conversation":false,"message_type":null,"model_slug":"gpt-4-5","default_model_slug":"gpt-4-5","parent_id":"0cb8ef8c-ff23-491b-8e13-8a86c3406db6","request_id":"91fff1e2fd215f2c-ATL","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"0cb8ef8c-ff23-491b-8e13-8a86c3406db6","children":["858496bf-167f-4565-9068-778c1a6a9774"]},"858496bf-167f-4565-9068-778c1a6a9774":{"id":"858496bf-167f-4565-9068-778c1a6a9774","message":{"id":"858496bf-167f-4565-9068-778c1a6a9774","author":{"role":"tool","name":"myfiles_browser","metadata":{}},"create_time":1741915200.405158,"update_time":null,"content":{"content_type":"text","parts":["All the files uploaded by the user have been fully loaded. Searching won't provide additional information."]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"is_visually_hidden_from_conversation":false,"message_type":null,"model_slug":"gpt-4-5","default_model_slug":"gpt-4-5","parent_id":"c67872de-a32a-4c31-97e0-705157c6d44a","request_id":"91fff1e2fd215f2c-ATL","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"c67872de-a32a-4c31-97e0-705157c6d44a","children":["a0b51bdb-e3e1-4264-972f-6dd7219026cb"]},"a0b51bdb-e3e1-4264-972f-6dd7219026cb":{"id":"a0b51bdb-e3e1-4264-972f-6dd7219026cb","message":{"id":"a0b51bdb-e3e1-4264-972f-6dd7219026cb","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1741915188.579597,"update_time":null,"content":{"content_type":"text","parts":["The document you provided outlines OpenAI's detailed response and recommendations to the U.S. Office of Science and Technology Policy (OSTP) regarding the proposed AI Action Plan. Here is a comprehensive and precise summary:\n\n### Context and Motivation\nOpenAI's response emphasizes the importance of American leadership in AI, highlighting the strategic competition with China, particularly regarding the Chinese Communist Party's (CCP) ambition to surpass the U.S. by 2030. OpenAI argues strongly for democratic AI principles as critical to maintaining American economic competitiveness, national security, and global influence. The proposals underline the urgency of America's current moment, as AGI (Artificial General Intelligence) nears practical reality.\n\n### Key Areas and Recommendations:\n\n**1. Regulatory Strategy to Ensure Freedom to Innovate**  \n- **Federal Preemption:** Advocates a unified federal framework to replace a fragmented state-level regulatory landscape (over 781 AI-related bills already introduced), thus reducing compliance burdens on AI companies and preserving innovation leadership.\n- Voluntary public-private partnership frameworks.\n- Federal \"sandbox\" and testing environments.\n- Protection for companies participating voluntarily, including liability protection and federal preemption of restrictive state regulations.\n\n**2. Export Control Strategy for Democratic AI:**\n- Categorization of countries into three tiers:\n  - **Tier I**: Democratic allies adopting democratic AI principles; actively promoted to maximize adoption.\n  - **Tier II**: Countries at risk of diverting technology to adversarial states; incentivized towards improvement.\n  - **Tier III**: PRC and aligned nations prohibited from accessing democratic AI systems.\n- Security measures for exported AI infrastructure, safeguarding intellectual property from PRC theft and espionage.\n- Encouraging cross-border capital flows, global coordination on security standards, and bans on CCP-aligned AI infrastructure (e.g., Huawei).\n\n**3. Copyright Strategy Promoting Freedom to Learn:**\n- Protecting AI training under fair use doctrine; ensuring AI systems can continue learning from copyrighted material.\n- Urging U.S. government action to prevent restrictive copyright regimes (like the EU's \"opt-out\" approach) that would disadvantage U.S. AI developers relative to PRC competitors who ignore intellectual property restrictions.\n\n**4. Infrastructure Strategy to Drive Growth:**\n- Accelerating infrastructure development, including computing resources, energy grids, and nationwide AI-readiness initiatives.\n- Policy measures such as:\n  - Sovereign Wealth Fund and government guarantees to secure investment.\n  - National-level policy acceleration for planning and permitting (including possible NEPA categorical exclusions or waivers for national security).\n  - Digitizing government-held data to benefit AI development broadly.\n  - Establishing AI-focused research hubs with academia-industry collaboration and localized infrastructure aligned with regional economic strengths.\n\n**5. Ambitious Government Adoption of AI:**\n- Modernization of U.S. government processes to deploy frontier AI at private-sector pace.\n- Proposals include:\n  - Updating cybersecurity and procurement rules (FedRAMP modernization).\n  - Temporary waivers for testing innovative AI solutions.\n  - Creating partnerships for developing classified-use, custom AI models for national security applications.\n  - Accelerated Facility Clearances (FCLs) for AI labs supporting national security initiatives.\n\n### Strategic Context and Competition with the PRC:\nThe document provides a detailed overview of the competitive dynamics, particularly concerning China's AI efforts (highlighting DeepSeek\u2019s R1 model as an indicator of narrowing American technological leadership). It emphasizes that CCP-driven AI models risk state-driven exploitation (data privacy, security risks, malign use), contrasting this with the democratic, secure, and freedom-oriented approach proposed by OpenAI.\n\n### Conclusion:\nOpenAI's overarching message is that the U.S. AI Action Plan must prioritize freedoms\u2014innovation, learning, and democratic values\u2014as a core component of its competitive strategy. The proposals aim to maintain and enhance American leadership in AI, safeguard national security, and drive significant economic and societal growth\u30106\u2020source\u3011."]},"status":"finished_successfully","end_turn":true,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200002]},"is_complete":true,"citations":[{"start_ix":4395,"end_ix":4405,"citation_format_type":"tether_og","metadata":{"type":"file","name":"openai-response-ostp-nsf-rfi-notice-request-for-information-on-the-development-of-an-artificial-intelligence-ai-action-plan.pdf","id":"file-5eiqpyd6a14ZasQ6c6cULw","source":"my_files","text":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[OpenAI Response] OSTP/NSF RFI: Notice Request for Information on the Development of an Artificial Intelligence (AI) Action Plan - Google Docs\n\n\n March 13, 2025 \n\n To: Faisal D'Souza, NCO  From: Christopher Lehane \n Office of Science and Technology Policy  OpenAI \n 2415 Eisenhower Avenue  1455 3rd Street \n Alexandria, VA 22314  San Francisco, CA 94158 \n\n This document is approved for public dissemination. The document contains no business-proprietary or confidential \n information. Document contents may be reused by the government in developing the AI Action Plan and associated \n documents without attribution. \n\n \u201cIt is the policy of the United States to sustain and enhance America\u2019s global dominance in \n order to promote human flourishing, economic competitiveness, and national security\u201d \n\n \u2013 President Donald J. Trump, Executive Order 14179, January 23, 2025 \n\n OpenAI respectfully submits the enclosed proposals to the Office of Science and \n Technology Policy as it weighs a new AI Action Plan that will, as Vice President Vance \n stated recently at the Paris AI Action Summit, maintain American leadership in AI and \n \u201cmake people more productive, more prosperous, and more free.\u201d As America\u2019s \n world-leading AI sector approaches artificial general intelligence (AGI), with a Chinese \n Communist Party (CCP) determined to overtake us by 2030, the Trump Administration\u2019s \n new AI Action Plan can ensure that American-led AI built on democratic principles \n continues to prevail over CCP-built autocratic, authoritarian AI. \n\n OpenAI agrees with the Trump Administration that AI creates prosperity and freedom worth \n fighting for\u2014especially for younger generations whose future will be shaped by how this \n Administration approaches AI. Globally, most ChatGPT users are under age 35; in the US, \n about one third are ages 18 to 24.  1  Both young people and their parents recognize the \n economic opportunities AI presents: \n\n \u25cf  More than seven in 10 parents in the US believe children today will be worse off \n financially than they are.  2 \n\n \u25cf  Nine in 10 US parents think it's important that their kids learn how to use artificial \n intelligence for their future jobs\u2014and eight in 10 say either that isn\u2019t happening \n today, or they don\u2019t know if it is.  3 \n\n \u25cf  Three in four college-age AI users want to use AI in their education and careers. \n Many are teaching themselves and their friends about AI without waiting for their \n schools to provide formal AI education.  4 \n\n 4  OpenAI:  Building an AI-Ready Workforce: A Look at  ChatGPT Adoption in the US  , Feb. 2025 \n\n 3  Morning Consult survey commissioned by Samsung:  88%  of US Parents of Gen Alpha & Gen Z Students Say AI \n Will Be Crucial to Their Child\u2019s Future Success  , Sept.  2024 \n\n 2  Pew Research Center:  Views of children\u2019s financial  future  , Jan. 2025 \n 1  Self-reported among logged-in users \n\n 1 \n\nhttps://cdn.openai.com/global-affairs/openai-edu-ai-ready-workforce.pdf\nhttps://news.samsung.com/us/88-percent-us-parents-gen-alpha-gen-z-students-say-ai-crucial-to-childs-future-success-samsung-solve-for-tomorrow/\nhttps://news.samsung.com/us/88-percent-us-parents-gen-alpha-gen-z-students-say-ai-crucial-to-childs-future-success-samsung-solve-for-tomorrow/\nhttps://www.pewresearch.org/global/2025/01/09/views-of-childrens-financial-future/\n\n\n In particular, AI could drive significant increased productivity over the next decade. Here\u2019s \n how we can realize this heightened prosperity and greater freedom together. \n\n Scaling human ingenuity \n Innovation creates and scales our ability to push beyond our current limits. From foot travel \n to the domesticated horse, the wheel, steam power, the car, the plane\u2014we scaled the \n freedom of mobility. From daylight to candle and lamplight, to electricity providing light and \n power at all hours\u2014we scaled the freedom to produce, think and create. From word of \n mouth to the stylus and tablet, to the printing press, telegraph, phone, computer, \n smartphone\u2014we scaled freedom of learning and knowledge. Now, as we approach AGI, \n innovation is poised to scale human ingenuity itself\u2014the sum of our freedoms to learn and \n know, think, create and produce. \n\n As our CEO Sam Altman  has written  , we are at the doorstep  of the next leap in prosperity: \n the Intelligence Age. But we must ensure that people have  freedom of intelligence  , by \n which we mean the freedom to access and benefit from AGI, protected from both autocratic \n powers that would take people\u2019s freedoms away, and layers of laws and bureaucracy that \n would prevent our realizing them. \n\n More than 400 million people around the world are using ChatGPT to ideate, discover, and \n break through beyond what we\u2019re currently capable of doing on our own. Just two weeks \n ago, we partnered with the Department of Energy\u2019s national labs to  bring together  1,500 \n scientists to use our tools to take scientific discovery farther, faster. \n\n Our work at OpenAI also suggests that as AI advances, progress accelerates and becomes \n increasingly affordable, as reflected in these three scaling principles: \n\n 1.  The intelligence of an AI model roughly equals  the log of the resources used to train and \n run it.  Until recently, scaling progress has primarily  come from training compute and data, \n but we have shown how to make intelligence scale from inference compute, as well. The \n scaling laws that predict these gains are incredibly precise over many orders of magnitude, \n so investing more in AI will continue to make it better and more capable.  We believe that \n the socioeconomic value of linearly increasing intelligence is super-exponential in nature. \n\n 2.  The cost to use a given level of AI capability  falls by about 10x every 12 months, and \n lower prices lead to much more use.  We saw this in  the change in token cost between \n GPT-4 in early 2023 and GPT-4o in mid-2024, where the price per token dropped about \n 150x in that time period.  Moore\u2019s Law predicted that  the number of transistors on a \n microchip would double roughly every two years; the decrease in the cost of using AI is \n even more dramatic. \n\n 2 \n\nhttps://ia.samaltman.com/\nhttps://cdn.openai.com/global-affairs/openai-usnl-scientist-ai-jam-session.pdf\n\n\n 3.  The amount of calendar time it takes to improve  an AI model keeps decreasing  . AI \n models are catching up with human intelligence at an increasing rate. The typical time it \n takes for a computer to beat humans at a given benchmark has fallen from 20 years after \n the benchmark was introduced, to five years, and now to one to two years  \u2014and we see no \n reason why those advancements will stop in the near future. \n\n By scaling human ingenuity ever faster and more affordably, AGI will create a flywheel of \n more freedom leading to more productivity, prosperity, and yet more innovation\u2014letting us \n once again focus on positive-sum growth. \n\n Advancing democratic AI \n OpenAI believes the best future is one in which we move forward with democratic AI\u2014AI \n that is shaped by the democratic principles America has always stood for. As OpenAI \n recently laid out in our  Economic Blueprint  , we believe  these principles include: \n\n \u25cf  A free market  promoting free and fair competition  that drives innovation. \n \u25cf  Freedom for developers and users  to work with and  direct our tools as they see fit, \n\n in exchange for following clear, common-sense technical standards that help keep \n AI safe for everyone, and being held accountable when they don\u2019t. \n\n \u25cf  Preventing government use of AI tools to amass power and control their citizens  , \n or to threaten or coerce other states. \n\n In advancing democratic AI, America is competing with a CCP determined to become the \n global leader by 2030. That\u2019s why the recent release of DeepSeek\u2019s R1 model is so \n noteworthy\u2014not because of its capabilities (R1\u2019s reasoning capabilities, albeit impressive, \n are at best on par with several US models), but as a gauge of the state of this competition. \n\n As with Huawei, there is significant risk in building on top of DeepSeek models in critical \n infrastructure and other high-risk use cases given the potential that DeepSeek could be \n compelled by the CCP to manipulate its models to cause harm. And because DeepSeek is \n simultaneously state-subsidized, state-controlled, and freely available, the cost to its users \n is their  privacy and security  , as DeepSeek faces requirements  under Chinese law to \n comply with demands for user data and uses it to train more capable systems for the CCP\u2019s \n use. Their models also more willingly generate how-to\u2019s for illicit and harmful activities such \n as identity fraud and intellectual property theft, a reflection of how the CCP views violations \n of American IP rights as a feature, not a flaw. \n\n 3 \n\nhttps://cdn.openai.com/global-affairs/openai-us-economicblueprint-feb-2025-edu-update.pdf\nhttps://blogs.cisco.com/security/evaluating-security-risk-in-deepseek-and-other-frontier-reasoning-models\n\n\n Today, CCP-controlled China has a number of strategic advantages, including: \n \u25cf  As an authoritarian state, its ability to quickly marshal resources  \u2014data, energy, \n\n technical talent, and the enormous sums needed to build out its own domestic chip \n development capacity. \n\n \u25cf  Its preexisting Belt and Road initiative.  As with  Huawei, the PRC will scale the \n adoption of PRC-based AI systems like DeepSeek\u2019s by coercing countries needing \n AI tools and nation-building infrastructure funds. \n\n \u25cf  Its ability to benefit from regulatory arbitrage being created by individual American \n states  seeking to pass their own industry-wide laws,  some of which are modeled \n on the European Union\u2019s regulation of AI. These laws are easier to enforce with \n domestic AI companies than PRC-based companies and could impose \n burdensome compliance requirements that may hinder our economic \n competitiveness and undermine our national security. They also may weaken the \n quality and level of training data available to American entrepreneurs and the \n usefulness for downstream consumers and businesses. \n\n \u25cf  Its ability to benefit from copyright arbitrage being created by democratic nations \n that do not clearly protect AI training by statute, like the US, or that reduce the \n amount of training data through an opt-out regime for copyright holders, like the \n EU. The PRC is unlikely to respect the IP regimes of any of such nations for the \n training of its AI systems, but already likely has access to all the same data, putting \n American AI labs at a comparative disadvantage while gaining little in the way of \n protections for the original IP creators. \n\n While America maintains a lead on AI today, DeepSeek shows that our lead is not wide and \n is narrowing. The AI Action Plan should ensure that American-led AI prevails over CCP-led \n AI, securing both American leadership on AI and a brighter future for all Americans. \n\n What we propose \n OpenAI\u2019s freedom-focused policy proposals, taken together, can strengthen America\u2019s lead \n on AI and in so doing, unlock economic growth, lock in American competitiveness, and \n protect our national security. Specifically, we detail: \n\n A regulatory strategy that ensures the freedom to innovate:  For innovation to truly create \n new freedoms, America\u2019s builders, developers, and entrepreneurs\u2014our nation\u2019s greatest \n competitive advantage\u2014must first have the freedom to innovate in the national interest. We \n propose a holistic approach that enables voluntary partnership between the federal \n government and the private sector, and neutralizes potential PRC benefit from American AI \n companies having to comply with overly burdensome state laws. \n\n 4 \n\n\n\n An export control strategy that exports democratic AI:  For countries seeking access to \n American AI, we propose a strategy that  would apply a commercial growth lens\u2014both Total \n and Serviceable Addressable Markets\u2014to proactively promote the global adoption of \n American AI systems and with them, the freedoms they create. At the same time, the \n strategy would use export controls to protect America\u2019s AI lead, including by making \n updates to the AI diffusion rule. \n\n A copyright strategy that promotes the freedom to learn:  America\u2019s robust, balanced \n intellectual property system has long been key to our global leadership on innovation. We \n propose a copyright strategy that would extend the system\u2019s role into the Intelligence Age \n by protecting the rights and interests of content creators while also protecting America\u2019s AI \n leadership and national security. The federal government can both secure Americans\u2019 \n freedom to learn from AI, and avoid forfeiting our AI lead to the PRC by preserving \n American AI models\u2019 ability to learn from copyrighted material. \n\n A strategy to seize the infrastructure opportunity to drive growth:  Sustaining America\u2019s lead \n on AI means building the necessary infrastructure to compete with the PRC and its \n commandeered resources. We propose policies to seize this unmissable opportunity to \n catalyze a reindustrialization across our country, creating and supporting hundreds of \n thousands of jobs, boosting local economies, modernizing our energy grid, and preparing \n an AI-ready workforce  \u2014t  he key pillar of any country\u2019s  AI infrastructure. \n\n An ambitious government adoption strategy:  Advancing  democratic AI around the world \n starts with ensuring that the US government itself sets an example of governments using AI \n to keep their people safe, prosperous, and free. With the PRC progressing toward \n ambitious targets for AI adoption across its public administration, security, and military, the \n US government should modernize its processes to safely deploy frontier AI tools at the \n pace of the private sector and with the efficiency Americans deserve. \n\n America always succeeds when it bets on American ingenuity. The enclosed policy \n proposals are either derived from, or in the case of copyright represent updates to  OpenAI's \n Economic Blueprint  , and we look forward to discussing  them with you. \n\n Chris Lehane \n Vice President, Global Affairs \n\n 5 \n\nhttps://cdn.openai.com/global-affairs/openai-us-economicblueprint-feb-2025-edu-update.pdf\nhttps://cdn.openai.com/global-affairs/openai-us-economicblueprint-feb-2025-edu-update.pdf\n\n\n 1. Preemption: Ensuring the Freedom to Innovate \n\n We propose creating a tightly-scoped framework for voluntary partnership between the \n federal government and the private sector to protect and strengthen American national \n security. This framework would extend the tradition of government receiving learnings \n and access, where appropriate, in exchange for providing the private sector relief from \n the  781 and counting proposed AI-related bills  already  introduced this year in US states. \n This patchwork of regulations risks bogging down innovation and, in the case of AI, \n undermining America\u2019s leadership position. \n\n Overseen by the US Department of Commerce and in coordination with the AI Czar, \n perhaps by reimagining the US AI Safety Institute, this effort would provide domestic AI \n companies with a single, efficient \u201cfront door\u201d to the federal government that would \n coordinate expertise across the entire national security and economic competitiveness \n communities.  5 \n\n This targeted framework would empower the federal government to: \n \u25cf  Work with both large AI companies and start-ups on a purely voluntary and \n\n optional basis to stay informed about AI risks as well as cutting-edge capabilities \n that support US national interests  ,  including by establishing  sandbox and testing \n capabilities on the secure premises of federal agencies. \n\n \u25cf  Evaluate the state of American AI technology against the technology of \n competitors and adversaries, including evaluating foreign models for the potential \n for back doors or malign influence. \n\n \u25cf  Coordinate the development of technical standards for evaluating and \n safeguarding frontier models from national security risks. \n\n \u25cf  Provide American AI companies with the tools and classified threat intelligence to \n mitigate national security risks that are exacerbated by frontier models (e.g., \n cyber, CBRN) and posed by nation-state actors (e.g., economic espionage by \n China). \n\n \u25cf  Incentivize companies to take part in this voluntary initiative by creating glide \n paths for them to contract with the government, including on national security \n projects; creating strong protections for any company information shared during \n these partnerships; and reducing barriers to companies' internal work related to \n national security domains. \n\n \u25cf  Guarantee that state-based legislation does not undermine America\u2019s innovation \n lead on AI. Create a sandbox for American start-ups, and provide participating \n companies with liability protections including preemption from state-based \n\n 5  Federal preemption over existing or prospective state  laws will require an act of Congress. \n\n 6 \n\nhttps://techcrunch.com/2025/03/07/us-lawmakers-have-already-introduce-hundreds-of-ai-bills-in-2025/\n\n\n regulations that focus on frontier model security (e.g., CA SB 1047). This will help \n keep the US public and private sectors competitive by allowing AI companies of \n all sizes to pursue bleeding-edge AI technology free from the regulatory \n uncertainty created by some state-based liability regimes. \n\n 2. Export Controls: Exporting Democratic AI \n\n A comprehensive export control strategy should do more than restrict the flow of AI \n technologies to the PRC\u2014it should ensure that America is \u201cwinning diffusion\u201d, i.e., that \n as much of the world as possible is aligned to democratic values and building on \n democratic infrastructure. To that end, we propose that the US government consider the \n Total Addressable Market (TAM), i.e., the entire world less the PRC and its few allies, \n against the Serviceable Addressable Market (SAM), i.e., those countries who prefer to \n build AI on democratic rails, and help as many of the latter as possible commit, including \n by actually committing to deploy AI in line with democratic principles set out by the US \n government. \n\n In particular, we propose maintaining the AI diffusion rule\u2019s three-tiered framework to \n differentiate among countries in the global AI market, but with some key modifications \n that expand the number of countries in Tier I: \n\n Tier I:  Countries that commit to democratic AI principles  by deploying AI systems in ways \n that promote more freedoms for their citizens could be considered Tier I countries. \n\n Tier II:  Limited to only those countries that have  a history of failing to prevent \n export-controlled chips and other US-developed IP from being diverted into, or used by \n Tier III countries. These countries would be encouraged and supported to obtain Tier I \n status over time; and would be subject to more stringent security requirements in the \n interim. \n\n Tier III:  CCP-led China, along with a small cohort  of countries aligned with the CCP, \n would represent its own category that is prohibited from accessing democratic AI \n systems. \n\n This strategy would encourage global adoption of democratic AI principles, promoting the \n use of democratic AI systems while protecting US advantage. Making sure that \n open-sourced models are readily available to developers in these countries also will \n strengthen our advantage.  We believe the question  of whether AI should be open or \n\n 7 \n\n\n\n closed source is a false choice\u2014we need both, and they can work in a complementary \n way that encourages the building of AI on American rails. \n\n Tier I countries  should include American allies, as  well as those countries that are \n committed to democratic AI principles and that present a relatively low risk that American \n AI infrastructure (e.g., chips) will be diverted to non-Tier I countries. The commercial \n diplomacy strategy in Tier I should recognize these countries\u2019 strong history of export \n and customs control compliance and seek to maximally expand democratic AI systems\u2019 \n market share, while at the same time protecting those systems from IP theft by the PRC \n and other malign actors (e.g., the theft of model weights and/or chip designs, \n unauthorized influence or access to data center operations). \n\n To expand market share in Tier I countries, American commercial diplomacy policy \n should: \n\n \u25cf  Encourage cross-border capital flows and promote software frameworks that are \n optimized for domestic chip design. \n\n \u25cf  Coordinate global bans on CCP-aligned AI infrastructure, including Huawei chips. \n \u25cf  Continue to represent American company interests in safety and security \n\n standards bodies, and encourage global regulators to adopt pro-growth safety and \n security policies. \n\n \u25cf  Revise the existing export control rules to eliminate country caps on compute. \n \u25cf  Maintain existing export license exceptions (e.g., license exception ACM) that \n\n enable exports of technology and software for technical collaboration with allies \n and preservation of economically critical supply chains \n\n To protect the US-developed IP needed to operate data centers in Tier I countries, \n security requirements could include: \n\n \u25cf  Prohibiting relationships with Tier III countries\u2019 foreign military and intelligence \n services, and the use of data centers to support military/intelligence missions for \n Tier III nations or human rights violators. \n\n \u25cf  Banning the use of PRC-produced equipment (e.g., Huawei Ascend chips) and \n models that violate user privacy and create security risks such as the risk of IP \n theft. \n\n \u25cf  Maintaining corporate control by entities headquartered in Tier I countries. \n \u25cf  Implementing\u2014and constantly modernizing\u2014cybersecurity, model weight security, \n\n and personnel security controls that ideally are globally synced and coordinated \n among Tier I governments. \n\n 8 \n\n\n\n Controls on model weights\u2014if any\u2014should strike a balance between protecting \n American-developed IP and promoting the deployment of American-developed models \n over those developed by Tier III countries, including the PRC. \n\n Tier II  countries  should include those with a history  of failing to prevent \n export-controlled chips and other US-developed IP from being diverted into, or used by \n Tier III co  untries. Here, the commercial diplomacy  strategy should still seek to expand \n US market share, but should do so more carefully, including by levying stronger controls \n on the export of US-developed AI infrastructure. At the same time, the strategy should \n provide transparent pathways for Tier II countries to reach Tier I status by adopting \n democratic AI principles and more effectively managing risks of chip diversion. \n\n To expand American market share in Tier II countries, in addition to the steps above, the \n commercial diplomacy policy could be designed to leverage commercial interest in \n American-led AI in order to encourage investment in the US, enhanced security \n procedures, and encourage more countries to build on American rails: \n\n \u25cf  Establish a transparent process to evaluate countries\u2019 readiness to transition from \n Tier II to Tier I. \n\n \u25cf  Support countries\u2019 transition from Tier II to Tier I by helping Tier II governments \n strengthen their in-country security programs. \n\n \u25cf  Encourage greater economic interdependence between the US and Tier II \n countries. \n\n \u25cf  Incentivize public-private partnerships to rapidly mature, scale, and commercialize \n hardware-enabled mechanisms that could enhance in-country security controls in \n the future. \n\n To protect the American-developed IP needed to operate data centers in Tier II countries, \n and to manage both the heightened risk of IP theft and the additional risk that \n export-controlled chips might be diverted from Tier II into Tier III countries, the \n commercial diplomacy policy also could: \n\n \u25cf  Allow the export of advanced AI chips to an end-user located in a Tier II country \n that meets Tier I security requirements, and that puts in place additional corporate \n governance controls as well as technology-enhanced protections (e.g., \n hardware-enabled mechanisms) against the diversion of export-controlled chips. \n\n Tier III countries  \u2014including the PRC and any other  country subject to a US arms \n embargo\u2014s  hould continue to be subject to strict export  controls of AI systems, including \n existing export controls on advanced chips. The strategy could also expand established \n controls, for example, to include advanced chips that are required for large-scale \n\n 9 \n\n\n\n inference and RL training and the components used to manufacture advanced AI chips \n and data centers. \n\n 3. Copyright: Promoting the Freedom to Learn \n\n American copyright law, including the longstanding fair use doctrine, protects the \n transformative uses of existing works, ensuring that innovators have a balanced and \n predictable framework for experimentation and entrepreneurship. This approach has \n underpinned American success through earlier phases of technological progress and is \n even more critical to continued American leadership on AI in the wake of recent events in \n the PRC. OpenAI\u2019s models are trained to not replicate works for consumption by the \n public. Instead, they learn from the works and extract patterns, linguistic structures, and \n contextual insights. This means our AI model training aligns with the core objectives of \n copyright and the fair use doctrine, using existing works to create something wholly new \n and different without eroding the commercial value of those existing works. \n\n America has so many AI startups, attracts so much investment, and has made so many \n research breakthroughs largely because the fair use doctrine promotes AI development. \n In other markets, rigid copyright rules are repressing innovation and investment. \n\n The European Union, for one, has created \u201ctext and data mining exceptions\u201d with broadly \n applicable \u201copt-outs\u201d for any rights holder\u2014meaning access to important AI inputs is less \n predictable and likely to become more difficult as the EU\u2019s regulations take shape. \n Unpredictable availability of inputs hinders AI innovation, particularly for smaller, newer \n entrants with limited budgets. \n\n The UK government is currently considering changes to its copyright regime. It has \n indicated that it prefers creating a data mining exception that allows rights holders to \n \u201creserve their rights,\u201d creating the same regulatory barriers to AI development that we \n see in the EU. \n\n Applying the fair use doctrine to AI is not only a matter of American competitiveness \n \u2014it\u2019s a matter of national security. The rapid advances seen with the PRC\u2019s DeepSeek, \n among other recent developments, show that America\u2019s lead on frontier AI is far from \n guaranteed. Given concerted state support for critical industries and infrastructure \n projects, there\u2019s little doubt that the PRC\u2019s AI developers will enjoy unfettered access to \n data\u2014including copyrighted data\u2014that will improve their models.  If the PRC\u2019s \n developers have unfettered access to data and American companies are left without fair \n use access, the race for AI is effectively over. America loses, as does the success of \n\n 10 \n\n\n\n democratic AI  .  Ultimately, access to more data from the widest possible range of sources \n will ensure more access to more powerful innovations that deliver even more knowledge. \n\n We propose that the US government take steps to ensure that our copyright system \n continues to support American AI leadership and American economic and national \n security, including by: \n\n \u25cf  Shaping international policy discussions around copyright and AI, and working to \n prevent less innovative countries from imposing their legal regimes on American \n AI firms and slowing our rate of progress. \n\n \u25cf  Actively assessing the overall level of data available to American AI firms and \n determining whether other countries are restricting American companies\u2019 access \n to data and other critical inputs. \n\n \u25cf  Encouraging more access to government-held or government-supported data. \n This would boost AI development in any case, but would be particularly important \n if shifting copyright rules restrict American companies\u2019 access to training data. \n\n \u25cf  Monitoring domestic policy debates and ongoing litigation, and weighing in where \n fundamental, pro-innovation principles are at risk. \n\n Generative AI models represent the next frontier of innovation, poised to revolutionize \n the private and public sectors, improving healthcare, education, scientific research, and \n so much more. If AI innovation remains protected under longstanding copyright \n principles, America will maintain and strengthen its role as the world leader in \n cutting-edge technologies and remain positioned to continue championing AI based on \n democratic principles with countries around the world. \n\n 4. Infrastructure: Seizing the Opportunity to Drive Growth \n\n Today, hundreds of billions of dollars in global funds are waiting to be invested in AI \n infrastructure. If the US doesn't move fast to channel these resources into projects that \n support democratic AI ecosystems around the world, the funds will flow to projects \n backed and shaped by the CCP. \n\n We propose a foundational strategy to ensure that investment in infrastructure drives \n economic growth that benefits all Americans; maximizes access to AI; and protects \n national security interests by keeping sensitive American data on American soil. This \n includes policies and initiatives that encourage rather than stifle developers; support  a \n thriving AI-ready workforce and  ecosystems of labs,  start-ups and larger companies; and \n secure America\u2019s leadership on AI into the future. \n\n 11 \n\n\n\n First and foremost, building data centers is capital-intensive, particularly for newcomers \n seeking to compete against established hyperscalers with vast resources.  W  e support \n the solutions already proposed by this Administration  to ensure that sufficient capital \n flows to building AI infrastructure in the US: \n\n \u25cf  Investment vehicles like a Sovereign Wealth Fund  . \n \u25cf  Government offtake and guarantees tha  t both provide  the government with the \n\n compute it needs and signal to markets that the demand will be there for \n American-developed AI. \n\n \u25cf  Tax credits, loans, and other vehicles the US government can direct to provide \n credit enhancement. \n\n We also have proposed: \n\n A National Transmission Highway Act  , as ambitious  as the 1956 National Interstate and \n Defense Highways Act, to expand transmission, fiber connectivity, and natural gas \n pipeline construction. The process for obtaining the \u201cthree Ps\u201d\u2014planning, permitting, and \n paying for approvals from federal, state, local, and tribal authorities\u2014disadvantages \n America\u2019s AI industry. Transmission lines can take 10 years or more to complete. When \n lines are built, parties must agree on which customers pay higher electrical bills to bear \n the cost of construction. In this process, delays often affect the build-out of transmission \n lines. Streamlining these processes and eliminating redundancies would significantly \n speed up infrastructure projects, keeping America\u2019s AI sector globally competitive and \n securing a future of reliable, affordable energy. \n\n Digitizing government data currently in analog form.  A lot of government data is in the \n public domain. Making it more accessible or machine-readable could help American AI \n developers of all sizes, especially those working in fields where vital data is often \n government-held. In exchange, developers using this data could work with governments \n to unlock new insights that help it develop better public policies. For example, \n government agencies can build on the work of the US National Archives and Records \n Administration in using Optical Character Recognition for text searchability and AI-driven \n metadata tagging. \n\n A Compact for AI  among US allies and partner nations  that streamlines access to capital \n and supply chains in ways that support AI infrastruc  ture  and a robust AI ecosystem. \n Participating countries would also agree to some common standards to safeguard data \n centers and the technology. Over time, this collaboration could expand to a global \n network of US allies and partners that would compete with the  PRC\u2019s  AI infrastructure \n alliances while also strengthening security through shared standards. \n\n 12 \n\n\n\n AI Economic Zones  ,  created by local, state and the federal government together with \n industry, that speed up the permitting for building AI infrastructure like new solar arrays, \n wind farms, and nuclear reactors.  This could include  creating categorical exclusions to \n the National Environmental Policy Act, such as a national security waiver given the \n global competition for AI leadership. These zones could also build on the first Trump \n Administration\u2019s \u201cOpportunity Zones\u201d through tax incentives or credit enhancements in \n order to encourage private capital investment. \n\n A nationwide AI Readiness Strategy  \u2014rooted in local  communities in partnership with \n American companies\u2014to help our current workforce and students become AI-ready, \n bolster the economy, and secure America\u2019s continued leadership on innovation. \n Maintaining American leadership in AI means ensuring we have an experienced, trained \n professional workforce working across the AI supply chain, including construction worker \n management, HVAC technicians, and electricians. Government should ensure this \n training is accessible and affordable, such as by: \n\n \u25cf  At the federal level, expanding 529 savings plans to cover more AI supply \n chain-related training programs\u2014including for construction, HVAC technicians, \n electricians, as well as AI researchers and developers\u2014by amending Section 529 \n of the Internal Revenue Code or broadening the SECURE Act\u2019s provisions. \n\n \u25cf  At the federal or state level, incentivizing AI supply chain companies to work with \n a backbone organization to understand the workforce needs of AI supply chain \n companies, develop a pipeline of training programs that help companies meet \n those needs, and coordinate with labor unions, community colleges, and trade \n associations to build and operate that training pipeline. \n\n Creation of AI research labs and workforces aligned with key local industries  by requiring \n AI companies to provide meaningful amounts of compute to public universities to \n equitably scale the training of a homegrown AI-skilled workforce. For example, one state \n could establish a hub dedicated to applying AI in agriculture while another develops \n centers focused on integrating AI into power production and grid resilience. \n\n Using the Defense Production Act (DPA) Title I  to  manage supply chain risk by \n designating gas turbines, rankine cycle turbines, high-voltage transformers, or \n switchgear for data centers as \u201crated orders.\u201d This prioritization could significantly \n shorten timelines for data center power i  nfrastructure  projects. \n\n 13 \n\n\n\n 5. Government Adoption of AI: Leading by Example \n\n AI adoption in federal departments and agencies remains unacceptably low, with federal \n employees, and especially national security sector employees, largely unable to harness \n the benefits of the technology. \n\n The government should encourage public-private partnerships to enhance government \n AI adoption by removing known blockers to the adoption of AI tools, including outdated \n and lengthy accreditation processes, restrictive testing authorities, and inflexible \n procurement pathways. Specifically, we recommend: \n\n \u25cf  Modernizing cyber security rules for cloud-based applications.  The government\u2019s \n current processes for AI providers to comply with federal security \n regulations\u2014primarily through the Federal Risk and Authorization Management \n Program (FedRAMP)\u2014takes 12 to 18 months, compared to the one- to \n three-month commercial standard, with no clear evidence of additional protection \n for government data. The government should modernize FedRAMP by \n establishing a faster, criteria-based path for approval of AI tools. Criteria could \n include Foreign Ownership, Control, or Influence (FOCI) approval; Facilities \n Clearance (FCL) status; US incorporation; a first-party AI model that ranks in the \n top 20 of a recognized evaluation framework (for example, MMLU, or Massive \n Multitask Language Understanding); SOC 2 (System and Organization Controls 2) \n accreditation; and a recent third-party penetration test with all findings addressed. \n\n \u25cf  Accelerating AI testing and experimentation.  The government  should allow federal \n agencies to test and experiment with real data using commercial-standard \n practices\u2014such as SOC 2 or International Organization for Standardization (ISO) \n audit reports\u2014and potentially grant a temporary waiver for FedRAMP. AI vendors \n would still be required to meet FedRAMP continuous monitoring requirements \n while awaiting full accreditation. Combined with standard due diligence before \n actual use, this approach could allow agencies to access new AI services roughly \n 12 months earlier while maintaining compliance with federal security \n requirements. \n\n \u25cf  Enabling rapid procurement mechanisms.  Once new security  and testing \n approaches are in place, agencies must also have quicker, more direct routes to \n procure and deploy frontier AI tools. The government should continue to evaluate \n Other Transactional Authorities (OTAs), Commercial Service Offerings (CSO) or \n other procurement paths in order to access technology from frontier AI labs, not \n just their legacy IT providers. We are encouraged by the Department of Defense\u2019s \n recent efforts to  Modernize Software Acquisition  . \n\n 14 \n\nhttps://www.defense.gov/News/Transcripts/Transcript/Article/4113458/directing-modern-software-acquisition-to-maximize-lethality-memo-background-bri/\n\n\n Enabling federal agencies to quickly acquire consumer-focused models is not enough, \n however. The government also needs to pursue and fund bespoke national security pilot \n projects for which there may be no commercial market by: \n\n \u25cf  Partnering with industry to develop custom models for national security.  The \n government needs models trained on classified datasets that are fine-tuned to be \n exceptional at national security tasks for which there is no commercial \n market\u2014such as geospatial intelligence or classified nuclear tasks. This will likely \n require on-premises deployment of model weights and access to significant \n compute, given the security requirements of many national security agencies. \n\n \u25cf  Acting now to fund these projects and secure this compute  \u2014enabling industry \n partners to secure chips, transformers, and begin construction, and ensuring that \n this compute comes online at the pace that innovation and geopolitical \n competition require. \n\n Lastly, frontier AI labs need Facility Clearances (FCL) to work directly with the national \n security enterprise on these pilot projects and custom models. The government should: \n\n \u25cf  Expedite FCL for frontier AI labs committed to supporting national security.  The \n process for obtaining a FCL can take a year or longer. Given the rapid pace of AI \n development, the government should start prioritizing deeper collaboration with \n frontier AI labs as soon as possible. \n\n We look forward to discussing the above proposals with the Office of Science and \n Technology Policy as we continue to build on our relationship with the US government \n and work toward AI that benefits everyone. \n\n About OpenAI \n OpenAI\u2019s mission is to ensure that as AI advances, it benefits everyone. We're building AI to help \n people solve hard problems because by helping with the hard problems, AI can benefit the most \n people possible\u2014through more scientific discoveries, better healthcare and education, and \n improved productivity. We\u2019re off to a strong start, creating freely available intelligence being used \n by more than 400 million people around the world, including 3 million developers. We believe AI \n will scale human ingenuity and drive unprecedented economic growth and new freedoms that \n help people accomplish what we can't even imagine today. \n\n 15 \n\n\n","extra":{"cited_message_idx":6,"search_result_idx":null,"evidence_text":"source","cloud_doc_url":null}}}],"content_references":[{"matched_text":"\u30106\u2020source\u3011","start_idx":4395,"end_idx":4405,"alt":null,"type":"file","name":"openai-response-ostp-nsf-rfi-notice-request-for-information-on-the-development-of-an-artificial-intelligence-ai-action-plan.pdf","id":"file-5eiqpyd6a14ZasQ6c6cULw","source":"my_files","snippet":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[OpenAI Response] OSTP/NSF RFI: Notice Request for Information on the Development of an Artificial Intelligence (AI) Action Plan - Google Docs\n\n\n March 13, 2025 \n\n To: Faisal D'Souza, NCO  From: Christopher Lehane \n Office of Science and Technology Policy  OpenAI \n 2415 Eisenhower Avenue  1455 3rd Street \n Alexandria, VA 22314  San Francisco, CA 94158 \n\n This document is approved for public dissemination. The document contains no business-proprietary or confidential \n information. Document contents may be reused by the government in developing the AI Action Plan and associated \n documents without attribution. \n\n \u201cIt is the policy of the United States to sustain and enhance America\u2019s global dominance in \n order to promote human flourishing, economic competitiveness, and national security\u201d \n\n \u2013 President Donald J. Trump, Executive Order 14179, January 23, 2025 \n\n OpenAI respectfully submits the enclosed proposals to the Office of Science and \n Technology Policy as it weighs a new AI Action Plan that will, as Vice President Vance \n stated recently at the Paris AI Action Summit, maintain American leadership in AI and \n \u201cmake people more productive, more prosperous, and more free.\u201d As America\u2019s \n world-leading AI sector approaches artificial general intelligence (AGI), with a Chinese \n Communist Party (CCP) determined to overtake us by 2030, the Trump Administration\u2019s \n new AI Action Plan can ensure that American-led AI built on democratic principles \n continues to prevail over CCP-built autocratic, authoritarian AI. \n\n OpenAI agrees with the Trump Administration that AI creates prosperity and freedom worth \n fighting for\u2014especially for younger generations whose future will be shaped by how this \n Administration approaches AI. Globally, most ChatGPT users are under age 35; in the US, \n about one third are ages 18 to 24.  1  Both young people and their parents recognize the \n economic opportunities AI presents: \n\n \u25cf  More than seven in 10 parents in the US believe children today will be worse off \n financially than they are.  2 \n\n \u25cf  Nine in 10 US parents think it's important that their kids learn how to use artificial \n intelligence for their future jobs\u2014and eight in 10 say either that isn\u2019t happening \n today, or they don\u2019t know if it is.  3 \n\n \u25cf  Three in four college-age AI users want to use AI in their education and careers. \n Many are teaching themselves and their friends about AI without waiting for their \n schools to provide formal AI education.  4 \n\n 4  OpenAI:  Building an AI-Ready Workforce: A Look at  ChatGPT Adoption in the US  , Feb. 2025 \n\n 3  Morning Consult survey commissioned by Samsung:  88%  of US Parents of Gen Alpha & Gen Z Students Say AI \n Will Be Crucial to Their Child\u2019s Future Success  , Sept.  2024 \n\n 2  Pew Research Center:  Views of children\u2019s financial  future  , Jan. 2025 \n 1  Self-reported among logged-in users \n\n 1 \n\nhttps://cdn.openai.com/global-affairs/openai-edu-ai-ready-workforce.pdf\nhttps://news.samsung.com/us/88-percent-us-parents-gen-alpha-gen-z-students-say-ai-crucial-to-childs-future-success-samsung-solve-for-tomorrow/\nhttps://news.samsung.com/us/88-percent-us-parents-gen-alpha-gen-z-students-say-ai-crucial-to-childs-future-success-samsung-solve-for-tomorrow/\nhttps://www.pewresearch.org/global/2025/01/09/views-of-childrens-financial-future/\n\n\n In particular, AI could drive significant increased productivity over the next decade. Here\u2019s \n how we can realize this heightened prosperity and greater freedom together. \n\n Scaling human ingenuity \n Innovation creates and scales our ability to push beyond our current limits. From foot travel \n to the domesticated horse, the wheel, steam power, the car, the plane\u2014we scaled the \n freedom of mobility. From daylight to candle and lamplight, to electricity providing light and \n power at all hours\u2014we scaled the freedom to produce, think and create. From word of \n mouth to the stylus and tablet, to the printing press, telegraph, phone, computer, \n smartphone\u2014we scaled freedom of learning and knowledge. Now, as we approach AGI, \n innovation is poised to scale human ingenuity itself\u2014the sum of our freedoms to learn and \n know, think, create and produce. \n\n As our CEO Sam Altman  has written  , we are at the doorstep  of the next leap in prosperity: \n the Intelligence Age. But we must ensure that people have  freedom of intelligence  , by \n which we mean the freedom to access and benefit from AGI, protected from both autocratic \n powers that would take people\u2019s freedoms away, and layers of laws and bureaucracy that \n would prevent our realizing them. \n\n More than 400 million people around the world are using ChatGPT to ideate, discover, and \n break through beyond what we\u2019re currently capable of doing on our own. Just two weeks \n ago, we partnered with the Department of Energy\u2019s national labs to  bring together  1,500 \n scientists to use our tools to take scientific discovery farther, faster. \n\n Our work at OpenAI also suggests that as AI advances, progress accelerates and becomes \n increasingly affordable, as reflected in these three scaling principles: \n\n 1.  The intelligence of an AI model roughly equals  the log of the resources used to train and \n run it.  Until recently, scaling progress has primarily  come from training compute and data, \n but we have shown how to make intelligence scale from inference compute, as well. The \n scaling laws that predict these gains are incredibly precise over many orders of magnitude, \n so investing more in AI will continue to make it better and more capable.  We believe that \n the socioeconomic value of linearly increasing intelligence is super-exponential in nature. \n\n 2.  The cost to use a given level of AI capability  falls by about 10x every 12 months, and \n lower prices lead to much more use.  We saw this in  the change in token cost between \n GPT-4 in early 2023 and GPT-4o in mid-2024, where the price per token dropped about \n 150x in that time period.  Moore\u2019s Law predicted that  the number of transistors on a \n microchip would double roughly every two years; the decrease in the cost of using AI is \n even more dramatic. \n\n 2 \n\nhttps://ia.samaltman.com/\nhttps://cdn.openai.com/global-affairs/openai-usnl-scientist-ai-jam-session.pdf\n\n\n 3.  The amount of calendar time it takes to improve  an AI model keeps decreasing  . AI \n models are catching up with human intelligence at an increasing rate. The typical time it \n takes for a computer to beat humans at a given benchmark has fallen from 20 years after \n the benchmark was introduced, to five years, and now to one to two years  \u2014and we see no \n reason why those advancements will stop in the near future. \n\n By scaling human ingenuity ever faster and more affordably, AGI will create a flywheel of \n more freedom leading to more productivity, prosperity, and yet more innovation\u2014letting us \n once again focus on positive-sum growth. \n\n Advancing democratic AI \n OpenAI believes the best future is one in which we move forward with democratic AI\u2014AI \n that is shaped by the democratic principles America has always stood for. As OpenAI \n recently laid out in our  Economic Blueprint  , we believe  these principles include: \n\n \u25cf  A free market  promoting free and fair competition  that drives innovation. \n \u25cf  Freedom for developers and users  to work with and  direct our tools as they see fit, \n\n in exchange for following clear, common-sense technical standards that help keep \n AI safe for everyone, and being held accountable when they don\u2019t. \n\n \u25cf  Preventing government use of AI tools to amass power and control their citizens  , \n or to threaten or coerce other states. \n\n In advancing democratic AI, America is competing with a CCP determined to become the \n global leader by 2030. That\u2019s why the recent release of DeepSeek\u2019s R1 model is so \n noteworthy\u2014not because of its capabilities (R1\u2019s reasoning capabilities, albeit impressive, \n are at best on par with several US models), but as a gauge of the state of this competition. \n\n As with Huawei, there is significant risk in building on top of DeepSeek models in critical \n infrastructure and other high-risk use cases given the potential that DeepSeek could be \n compelled by the CCP to manipulate its models to cause harm. And because DeepSeek is \n simultaneously state-subsidized, state-controlled, and freely available, the cost to its users \n is their  privacy and security  , as DeepSeek faces requirements  under Chinese law to \n comply with demands for user data and uses it to train more capable systems for the CCP\u2019s \n use. Their models also more willingly generate how-to\u2019s for illicit and harmful activities such \n as identity fraud and intellectual property theft, a reflection of how the CCP views violations \n of American IP rights as a feature, not a flaw. \n\n 3 \n\nhttps://cdn.openai.com/global-affairs/openai-us-economicblueprint-feb-2025-edu-update.pdf\nhttps://blogs.cisco.com/security/evaluating-security-risk-in-deepseek-and-other-frontier-reasoning-models\n\n\n Today, CCP-controlled China has a number of strategic advantages, including: \n \u25cf  As an authoritarian state, its ability to quickly marshal resources  \u2014data, energy, \n\n technical talent, and the enormous sums needed to build out its own domestic chip \n development capacity. \n\n \u25cf  Its preexisting Belt and Road initiative.  As with  Huawei, the PRC will scale the \n adoption of PRC-based AI systems like DeepSeek\u2019s by coercing countries needing \n AI tools and nation-building infrastructure funds. \n\n \u25cf  Its ability to benefit from regulatory arbitrage being created by individual American \n states  seeking to pass their own industry-wide laws,  some of which are modeled \n on the European Union\u2019s regulation of AI. These laws are easier to enforce with \n domestic AI companies than PRC-based companies and could impose \n burdensome compliance requirements that may hinder our economic \n competitiveness and undermine our national security. They also may weaken the \n quality and level of training data available to American entrepreneurs and the \n usefulness for downstream consumers and businesses. \n\n \u25cf  Its ability to benefit from copyright arbitrage being created by democratic nations \n that do not clearly protect AI training by statute, like the US, or that reduce the \n amount of training data through an opt-out regime for copyright holders, like the \n EU. The PRC is unlikely to respect the IP regimes of any of such nations for the \n training of its AI systems, but already likely has access to all the same data, putting \n American AI labs at a comparative disadvantage while gaining little in the way of \n protections for the original IP creators. \n\n While America maintains a lead on AI today, DeepSeek shows that our lead is not wide and \n is narrowing. The AI Action Plan should ensure that American-led AI prevails over CCP-led \n AI, securing both American leadership on AI and a brighter future for all Americans. \n\n What we propose \n OpenAI\u2019s freedom-focused policy proposals, taken together, can strengthen America\u2019s lead \n on AI and in so doing, unlock economic growth, lock in American competitiveness, and \n protect our national security. Specifically, we detail: \n\n A regulatory strategy that ensures the freedom to innovate:  For innovation to truly create \n new freedoms, America\u2019s builders, developers, and entrepreneurs\u2014our nation\u2019s greatest \n competitive advantage\u2014must first have the freedom to innovate in the national interest. We \n propose a holistic approach that enables voluntary partnership between the federal \n government and the private sector, and neutralizes potential PRC benefit from American AI \n companies having to comply with overly burdensome state laws. \n\n 4 \n\n\n\n An export control strategy that exports democratic AI:  For countries seeking access to \n American AI, we propose a strategy that  would apply a commercial growth lens\u2014both Total \n and Serviceable Addressable Markets\u2014to proactively promote the global adoption of \n American AI systems and with them, the freedoms they create. At the same time, the \n strategy would use export controls to protect America\u2019s AI lead, including by making \n updates to the AI diffusion rule. \n\n A copyright strategy that promotes the freedom to learn:  America\u2019s robust, balanced \n intellectual property system has long been key to our global leadership on innovation. We \n propose a copyright strategy that would extend the system\u2019s role into the Intelligence Age \n by protecting the rights and interests of content creators while also protecting America\u2019s AI \n leadership and national security. The federal government can both secure Americans\u2019 \n freedom to learn from AI, and avoid forfeiting our AI lead to the PRC by preserving \n American AI models\u2019 ability to learn from copyrighted material. \n\n A strategy to seize the infrastructure opportunity to drive growth:  Sustaining America\u2019s lead \n on AI means building the necessary infrastructure to compete with the PRC and its \n commandeered resources. We propose policies to seize this unmissable opportunity to \n catalyze a reindustrialization across our country, creating and supporting hundreds of \n thousands of jobs, boosting local economies, modernizing our energy grid, and preparing \n an AI-ready workforce  \u2014t  he key pillar of any country\u2019s  AI infrastructure. \n\n An ambitious government adoption strategy:  Advancing  democratic AI around the world \n starts with ensuring that the US government itself sets an example of governments using AI \n to keep their people safe, prosperous, and free. With the PRC progressing toward \n ambitious targets for AI adoption across its public administration, security, and military, the \n US government should modernize its processes to safely deploy frontier AI tools at the \n pace of the private sector and with the efficiency Americans deserve. \n\n America always succeeds when it bets on American ingenuity. The enclosed policy \n proposals are either derived from, or in the case of copyright represent updates to  OpenAI's \n Economic Blueprint  , and we look forward to discussing  them with you. \n\n Chris Lehane \n Vice President, Global Affairs \n\n 5 \n\nhttps://cdn.openai.com/global-affairs/openai-us-economicblueprint-feb-2025-edu-update.pdf\nhttps://cdn.openai.com/global-affairs/openai-us-economicblueprint-feb-2025-edu-update.pdf\n\n\n 1. Preemption: Ensuring the Freedom to Innovate \n\n We propose creating a tightly-scoped framework for voluntary partnership between the \n federal government and the private sector to protect and strengthen American national \n security. This framework would extend the tradition of government receiving learnings \n and access, where appropriate, in exchange for providing the private sector relief from \n the  781 and counting proposed AI-related bills  already  introduced this year in US states. \n This patchwork of regulations risks bogging down innovation and, in the case of AI, \n undermining America\u2019s leadership position. \n\n Overseen by the US Department of Commerce and in coordination with the AI Czar, \n perhaps by reimagining the US AI Safety Institute, this effort would provide domestic AI \n companies with a single, efficient \u201cfront door\u201d to the federal government that would \n coordinate expertise across the entire national security and economic competitiveness \n communities.  5 \n\n This targeted framework would empower the federal government to: \n \u25cf  Work with both large AI companies and start-ups on a purely voluntary and \n\n optional basis to stay informed about AI risks as well as cutting-edge capabilities \n that support US national interests  ,  including by establishing  sandbox and testing \n capabilities on the secure premises of federal agencies. \n\n \u25cf  Evaluate the state of American AI technology against the technology of \n competitors and adversaries, including evaluating foreign models for the potential \n for back doors or malign influence. \n\n \u25cf  Coordinate the development of technical standards for evaluating and \n safeguarding frontier models from national security risks. \n\n \u25cf  Provide American AI companies with the tools and classified threat intelligence to \n mitigate national security risks that are exacerbated by frontier models (e.g., \n cyber, CBRN) and posed by nation-state actors (e.g., economic espionage by \n China). \n\n \u25cf  Incentivize companies to take part in this voluntary initiative by creating glide \n paths for them to contract with the government, including on national security \n projects; creating strong protections for any company information shared during \n these partnerships; and reducing barriers to companies' internal work related to \n national security domains. \n\n \u25cf  Guarantee that state-based legislation does not undermine America\u2019s innovation \n lead on AI. Create a sandbox for American start-ups, and provide participating \n companies with liability protections including preemption from state-based \n\n 5  Federal preemption over existing or prospective state  laws will require an act of Congress. \n\n 6 \n\nhttps://techcrunch.com/2025/03/07/us-lawmakers-have-already-introduce-hundreds-of-ai-bills-in-2025/\n\n\n regulations that focus on frontier model security (e.g., CA SB 1047). This will help \n keep the US public and private sectors competitive by allowing AI companies of \n all sizes to pursue bleeding-edge AI technology free from the regulatory \n uncertainty created by some state-based liability regimes. \n\n 2. Export Controls: Exporting Democratic AI \n\n A comprehensive export control strategy should do more than restrict the flow of AI \n technologies to the PRC\u2014it should ensure that America is \u201cwinning diffusion\u201d, i.e., that \n as much of the world as possible is aligned to democratic values and building on \n democratic infrastructure. To that end, we propose that the US government consider the \n Total Addressable Market (TAM), i.e., the entire world less the PRC and its few allies, \n against the Serviceable Addressable Market (SAM), i.e., those countries who prefer to \n build AI on democratic rails, and help as many of the latter as possible commit, including \n by actually committing to deploy AI in line with democratic principles set out by the US \n government. \n\n In particular, we propose maintaining the AI diffusion rule\u2019s three-tiered framework to \n differentiate among countries in the global AI market, but with some key modifications \n that expand the number of countries in Tier I: \n\n Tier I:  Countries that commit to democratic AI principles  by deploying AI systems in ways \n that promote more freedoms for their citizens could be considered Tier I countries. \n\n Tier II:  Limited to only those countries that have  a history of failing to prevent \n export-controlled chips and other US-developed IP from being diverted into, or used by \n Tier III countries. These countries would be encouraged and supported to obtain Tier I \n status over time; and would be subject to more stringent security requirements in the \n interim. \n\n Tier III:  CCP-led China, along with a small cohort  of countries aligned with the CCP, \n would represent its own category that is prohibited from accessing democratic AI \n systems. \n\n This strategy would encourage global adoption of democratic AI principles, promoting the \n use of democratic AI systems while protecting US advantage. Making sure that \n open-sourced models are readily available to developers in these countries also will \n strengthen our advantage.  We believe the question  of whether AI should be open or \n\n 7 \n\n\n\n closed source is a false choice\u2014we need both, and they can work in a complementary \n way that encourages the building of AI on American rails. \n\n Tier I countries  should include American allies, as  well as those countries that are \n committed to democratic AI principles and that present a relatively low risk that American \n AI infrastructure (e.g., chips) will be diverted to non-Tier I countries. The commercial \n diplomacy strategy in Tier I should recognize these countries\u2019 strong history of export \n and customs control compliance and seek to maximally expand democratic AI systems\u2019 \n market share, while at the same time protecting those systems from IP theft by the PRC \n and other malign actors (e.g., the theft of model weights and/or chip designs, \n unauthorized influence or access to data center operations). \n\n To expand market share in Tier I countries, American commercial diplomacy policy \n should: \n\n \u25cf  Encourage cross-border capital flows and promote software frameworks that are \n optimized for domestic chip design. \n\n \u25cf  Coordinate global bans on CCP-aligned AI infrastructure, including Huawei chips. \n \u25cf  Continue to represent American company interests in safety and security \n\n standards bodies, and encourage global regulators to adopt pro-growth safety and \n security policies. \n\n \u25cf  Revise the existing export control rules to eliminate country caps on compute. \n \u25cf  Maintain existing export license exceptions (e.g., license exception ACM) that \n\n enable exports of technology and software for technical collaboration with allies \n and preservation of economically critical supply chains \n\n To protect the US-developed IP needed to operate data centers in Tier I countries, \n security requirements could include: \n\n \u25cf  Prohibiting relationships with Tier III countries\u2019 foreign military and intelligence \n services, and the use of data centers to support military/intelligence missions for \n Tier III nations or human rights violators. \n\n \u25cf  Banning the use of PRC-produced equipment (e.g., Huawei Ascend chips) and \n models that violate user privacy and create security risks such as the risk of IP \n theft. \n\n \u25cf  Maintaining corporate control by entities headquartered in Tier I countries. \n \u25cf  Implementing\u2014and constantly modernizing\u2014cybersecurity, model weight security, \n\n and personnel security controls that ideally are globally synced and coordinated \n among Tier I governments. \n\n 8 \n\n\n\n Controls on model weights\u2014if any\u2014should strike a balance between protecting \n American-developed IP and promoting the deployment of American-developed models \n over those developed by Tier III countries, including the PRC. \n\n Tier II  countries  should include those with a history  of failing to prevent \n export-controlled chips and other US-developed IP from being diverted into, or used by \n Tier III co  untries. Here, the commercial diplomacy  strategy should still seek to expand \n US market share, but should do so more carefully, including by levying stronger controls \n on the export of US-developed AI infrastructure. At the same time, the strategy should \n provide transparent pathways for Tier II countries to reach Tier I status by adopting \n democratic AI principles and more effectively managing risks of chip diversion. \n\n To expand American market share in Tier II countries, in addition to the steps above, the \n commercial diplomacy policy could be designed to leverage commercial interest in \n American-led AI in order to encourage investment in the US, enhanced security \n procedures, and encourage more countries to build on American rails: \n\n \u25cf  Establish a transparent process to evaluate countries\u2019 readiness to transition from \n Tier II to Tier I. \n\n \u25cf  Support countries\u2019 transition from Tier II to Tier I by helping Tier II governments \n strengthen their in-country security programs. \n\n \u25cf  Encourage greater economic interdependence between the US and Tier II \n countries. \n\n \u25cf  Incentivize public-private partnerships to rapidly mature, scale, and commercialize \n hardware-enabled mechanisms that could enhance in-country security controls in \n the future. \n\n To protect the American-developed IP needed to operate data centers in Tier II countries, \n and to manage both the heightened risk of IP theft and the additional risk that \n export-controlled chips might be diverted from Tier II into Tier III countries, the \n commercial diplomacy policy also could: \n\n \u25cf  Allow the export of advanced AI chips to an end-user located in a Tier II country \n that meets Tier I security requirements, and that puts in place additional corporate \n governance controls as well as technology-enhanced protections (e.g., \n hardware-enabled mechanisms) against the diversion of export-controlled chips. \n\n Tier III countries  \u2014including the PRC and any other  country subject to a US arms \n embargo\u2014s  hould continue to be subject to strict export  controls of AI systems, including \n existing export controls on advanced chips. The strategy could also expand established \n controls, for example, to include advanced chips that are required for large-scale \n\n 9 \n\n\n\n inference and RL training and the components used to manufacture advanced AI chips \n and data centers. \n\n 3. Copyright: Promoting the Freedom to Learn \n\n American copyright law, including the longstanding fair use doctrine, protects the \n transformative uses of existing works, ensuring that innovators have a balanced and \n predictable framework for experimentation and entrepreneurship. This approach has \n underpinned American success through earlier phases of technological progress and is \n even more critical to continued American leadership on AI in the wake of recent events in \n the PRC. OpenAI\u2019s models are trained to not replicate works for consumption by the \n public. Instead, they learn from the works and extract patterns, linguistic structures, and \n contextual insights. This means our AI model training aligns with the core objectives of \n copyright and the fair use doctrine, using existing works to create something wholly new \n and different without eroding the commercial value of those existing works. \n\n America has so many AI startups, attracts so much investment, and has made so many \n research breakthroughs largely because the fair use doctrine promotes AI development. \n In other markets, rigid copyright rules are repressing innovation and investment. \n\n The European Union, for one, has created \u201ctext and data mining exceptions\u201d with broadly \n applicable \u201copt-outs\u201d for any rights holder\u2014meaning access to important AI inputs is less \n predictable and likely to become more difficult as the EU\u2019s regulations take shape. \n Unpredictable availability of inputs hinders AI innovation, particularly for smaller, newer \n entrants with limited budgets. \n\n The UK government is currently considering changes to its copyright regime. It has \n indicated that it prefers creating a data mining exception that allows rights holders to \n \u201creserve their rights,\u201d creating the same regulatory barriers to AI development that we \n see in the EU. \n\n Applying the fair use doctrine to AI is not only a matter of American competitiveness \n \u2014it\u2019s a matter of national security. The rapid advances seen with the PRC\u2019s DeepSeek, \n among other recent developments, show that America\u2019s lead on frontier AI is far from \n guaranteed. Given concerted state support for critical industries and infrastructure \n projects, there\u2019s little doubt that the PRC\u2019s AI developers will enjoy unfettered access to \n data\u2014including copyrighted data\u2014that will improve their models.  If the PRC\u2019s \n developers have unfettered access to data and American companies are left without fair \n use access, the race for AI is effectively over. America loses, as does the success of \n\n 10 \n\n\n\n democratic AI  .  Ultimately, access to more data from the widest possible range of sources \n will ensure more access to more powerful innovations that deliver even more knowledge. \n\n We propose that the US government take steps to ensure that our copyright system \n continues to support American AI leadership and American economic and national \n security, including by: \n\n \u25cf  Shaping international policy discussions around copyright and AI, and working to \n prevent less innovative countries from imposing their legal regimes on American \n AI firms and slowing our rate of progress. \n\n \u25cf  Actively assessing the overall level of data available to American AI firms and \n determining whether other countries are restricting American companies\u2019 access \n to data and other critical inputs. \n\n \u25cf  Encouraging more access to government-held or government-supported data. \n This would boost AI development in any case, but would be particularly important \n if shifting copyright rules restrict American companies\u2019 access to training data. \n\n \u25cf  Monitoring domestic policy debates and ongoing litigation, and weighing in where \n fundamental, pro-innovation principles are at risk. \n\n Generative AI models represent the next frontier of innovation, poised to revolutionize \n the private and public sectors, improving healthcare, education, scientific research, and \n so much more. If AI innovation remains protected under longstanding copyright \n principles, America will maintain and strengthen its role as the world leader in \n cutting-edge technologies and remain positioned to continue championing AI based on \n democratic principles with countries around the world. \n\n 4. Infrastructure: Seizing the Opportunity to Drive Growth \n\n Today, hundreds of billions of dollars in global funds are waiting to be invested in AI \n infrastructure. If the US doesn't move fast to channel these resources into projects that \n support democratic AI ecosystems around the world, the funds will flow to projects \n backed and shaped by the CCP. \n\n We propose a foundational strategy to ensure that investment in infrastructure drives \n economic growth that benefits all Americans; maximizes access to AI; and protects \n national security interests by keeping sensitive American data on American soil. This \n includes policies and initiatives that encourage rather than stifle developers; support  a \n thriving AI-ready workforce and  ecosystems of labs,  start-ups and larger companies; and \n secure America\u2019s leadership on AI into the future. \n\n 11 \n\n\n\n First and foremost, building data centers is capital-intensive, particularly for newcomers \n seeking to compete against established hyperscalers with vast resources.  W  e support \n the solutions already proposed by this Administration  to ensure that sufficient capital \n flows to building AI infrastructure in the US: \n\n \u25cf  Investment vehicles like a Sovereign Wealth Fund  . \n \u25cf  Government offtake and guarantees tha  t both provide  the government with the \n\n compute it needs and signal to markets that the demand will be there for \n American-developed AI. \n\n \u25cf  Tax credits, loans, and other vehicles the US government can direct to provide \n credit enhancement. \n\n We also have proposed: \n\n A National Transmission Highway Act  , as ambitious  as the 1956 National Interstate and \n Defense Highways Act, to expand transmission, fiber connectivity, and natural gas \n pipeline construction. The process for obtaining the \u201cthree Ps\u201d\u2014planning, permitting, and \n paying for approvals from federal, state, local, and tribal authorities\u2014disadvantages \n America\u2019s AI industry. Transmission lines can take 10 years or more to complete. When \n lines are built, parties must agree on which customers pay higher electrical bills to bear \n the cost of construction. In this process, delays often affect the build-out of transmission \n lines. Streamlining these processes and eliminating redundancies would significantly \n speed up infrastructure projects, keeping America\u2019s AI sector globally competitive and \n securing a future of reliable, affordable energy. \n\n Digitizing government data currently in analog form.  A lot of government data is in the \n public domain. Making it more accessible or machine-readable could help American AI \n developers of all sizes, especially those working in fields where vital data is often \n government-held. In exchange, developers using this data could work with governments \n to unlock new insights that help it develop better public policies. For example, \n government agencies can build on the work of the US National Archives and Records \n Administration in using Optical Character Recognition for text searchability and AI-driven \n metadata tagging. \n\n A Compact for AI  among US allies and partner nations  that streamlines access to capital \n and supply chains in ways that support AI infrastruc  ture  and a robust AI ecosystem. \n Participating countries would also agree to some common standards to safeguard data \n centers and the technology. Over time, this collaboration could expand to a global \n network of US allies and partners that would compete with the  PRC\u2019s  AI infrastructure \n alliances while also strengthening security through shared standards. \n\n 12 \n\n\n\n AI Economic Zones  ,  created by local, state and the federal government together with \n industry, that speed up the permitting for building AI infrastructure like new solar arrays, \n wind farms, and nuclear reactors.  This could include  creating categorical exclusions to \n the National Environmental Policy Act, such as a national security waiver given the \n global competition for AI leadership. These zones could also build on the first Trump \n Administration\u2019s \u201cOpportunity Zones\u201d through tax incentives or credit enhancements in \n order to encourage private capital investment. \n\n A nationwide AI Readiness Strategy  \u2014rooted in local  communities in partnership with \n American companies\u2014to help our current workforce and students become AI-ready, \n bolster the economy, and secure America\u2019s continued leadership on innovation. \n Maintaining American leadership in AI means ensuring we have an experienced, trained \n professional workforce working across the AI supply chain, including construction worker \n management, HVAC technicians, and electricians. Government should ensure this \n training is accessible and affordable, such as by: \n\n \u25cf  At the federal level, expanding 529 savings plans to cover more AI supply \n chain-related training programs\u2014including for construction, HVAC technicians, \n electricians, as well as AI researchers and developers\u2014by amending Section 529 \n of the Internal Revenue Code or broadening the SECURE Act\u2019s provisions. \n\n \u25cf  At the federal or state level, incentivizing AI supply chain companies to work with \n a backbone organization to understand the workforce needs of AI supply chain \n companies, develop a pipeline of training programs that help companies meet \n those needs, and coordinate with labor unions, community colleges, and trade \n associations to build and operate that training pipeline. \n\n Creation of AI research labs and workforces aligned with key local industries  by requiring \n AI companies to provide meaningful amounts of compute to public universities to \n equitably scale the training of a homegrown AI-skilled workforce. For example, one state \n could establish a hub dedicated to applying AI in agriculture while another develops \n centers focused on integrating AI into power production and grid resilience. \n\n Using the Defense Production Act (DPA) Title I  to  manage supply chain risk by \n designating gas turbines, rankine cycle turbines, high-voltage transformers, or \n switchgear for data centers as \u201crated orders.\u201d This prioritization could significantly \n shorten timelines for data center power i  nfrastructure  projects. \n\n 13 \n\n\n\n 5. Government Adoption of AI: Leading by Example \n\n AI adoption in federal departments and agencies remains unacceptably low, with federal \n employees, and especially national security sector employees, largely unable to harness \n the benefits of the technology. \n\n The government should encourage public-private partnerships to enhance government \n AI adoption by removing known blockers to the adoption of AI tools, including outdated \n and lengthy accreditation processes, restrictive testing authorities, and inflexible \n procurement pathways. Specifically, we recommend: \n\n \u25cf  Modernizing cyber security rules for cloud-based applications.  The government\u2019s \n current processes for AI providers to comply with federal security \n regulations\u2014primarily through the Federal Risk and Authorization Management \n Program (FedRAMP)\u2014takes 12 to 18 months, compared to the one- to \n three-month commercial standard, with no clear evidence of additional protection \n for government data. The government should modernize FedRAMP by \n establishing a faster, criteria-based path for approval of AI tools. Criteria could \n include Foreign Ownership, Control, or Influence (FOCI) approval; Facilities \n Clearance (FCL) status; US incorporation; a first-party AI model that ranks in the \n top 20 of a recognized evaluation framework (for example, MMLU, or Massive \n Multitask Language Understanding); SOC 2 (System and Organization Controls 2) \n accreditation; and a recent third-party penetration test with all findings addressed. \n\n \u25cf  Accelerating AI testing and experimentation.  The government  should allow federal \n agencies to test and experiment with real data using commercial-standard \n practices\u2014such as SOC 2 or International Organization for Standardization (ISO) \n audit reports\u2014and potentially grant a temporary waiver for FedRAMP. AI vendors \n would still be required to meet FedRAMP continuous monitoring requirements \n while awaiting full accreditation. Combined with standard due diligence before \n actual use, this approach could allow agencies to access new AI services roughly \n 12 months earlier while maintaining compliance with federal security \n requirements. \n\n \u25cf  Enabling rapid procurement mechanisms.  Once new security  and testing \n approaches are in place, agencies must also have quicker, more direct routes to \n procure and deploy frontier AI tools. The government should continue to evaluate \n Other Transactional Authorities (OTAs), Commercial Service Offerings (CSO) or \n other procurement paths in order to access technology from frontier AI labs, not \n just their legacy IT providers. We are encouraged by the Department of Defense\u2019s \n recent efforts to  Modernize Software Acquisition  . \n\n 14 \n\nhttps://www.defense.gov/News/Transcripts/Transcript/Article/4113458/directing-modern-software-acquisition-to-maximize-lethality-memo-background-bri/\n\n\n Enabling federal agencies to quickly acquire consumer-focused models is not enough, \n however. The government also needs to pursue and fund bespoke national security pilot \n projects for which there may be no commercial market by: \n\n \u25cf  Partnering with industry to develop custom models for national security.  The \n government needs models trained on classified datasets that are fine-tuned to be \n exceptional at national security tasks for which there is no commercial \n market\u2014such as geospatial intelligence or classified nuclear tasks. This will likely \n require on-premises deployment of model weights and access to significant \n compute, given the security requirements of many national security agencies. \n\n \u25cf  Acting now to fund these projects and secure this compute  \u2014enabling industry \n partners to secure chips, transformers, and begin construction, and ensuring that \n this compute comes online at the pace that innovation and geopolitical \n competition require. \n\n Lastly, frontier AI labs need Facility Clearances (FCL) to work directly with the national \n security enterprise on these pilot projects and custom models. The government should: \n\n \u25cf  Expedite FCL for frontier AI labs committed to supporting national security.  The \n process for obtaining a FCL can take a year or longer. Given the rapid pace of AI \n development, the government should start prioritizing deeper collaboration with \n frontier AI labs as soon as possible. \n\n We look forward to discussing the above proposals with the Office of Science and \n Technology Policy as we continue to build on our relationship with the US government \n and work toward AI that benefits everyone. \n\n About OpenAI \n OpenAI\u2019s mission is to ensure that as AI advances, it benefits everyone. We're building AI to help \n people solve hard problems because by helping with the hard problems, AI can benefit the most \n people possible\u2014through more scientific discoveries, better healthcare and education, and \n improved productivity. We\u2019re off to a strong start, creating freely available intelligence being used \n by more than 400 million people around the world, including 3 million developers. We believe AI \n will scale human ingenuity and drive unprecedented economic growth and new freedoms that \n help people accomplish what we can't even imagine today. \n\n 15 \n\n\n","cloud_doc_url":null}],"message_type":null,"model_slug":"gpt-4-5","default_model_slug":"gpt-4-5","parent_id":"858496bf-167f-4565-9068-778c1a6a9774","request_id":"91fff1e2fd215f2c-ATL","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"858496bf-167f-4565-9068-778c1a6a9774","children":["faf9e69e-e635-4df9-9f5a-42e48a8a0b65"]},"faf9e69e-e635-4df9-9f5a-42e48a8a0b65":{"id":"faf9e69e-e635-4df9-9f5a-42e48a8a0b65","message":{"id":"faf9e69e-e635-4df9-9f5a-42e48a8a0b65","author":{"role":"user","name":null,"metadata":{}},"create_time":1741916886.239,"update_time":null,"content":{"content_type":"text","parts":["what are the benefits and drawbacks of framing AI technological advancement in terms of geopolitical strategy and great power positioning?"]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"serialization_metadata":{"custom_symbol_offsets":[]},"dictation":false,"request_id":"92001b5aea9544c3-SIN","message_source":null,"timestamp_":"absolute","message_type":null,"can_save":true},"recipient":"all","channel":null},"parent":"a0b51bdb-e3e1-4264-972f-6dd7219026cb","children":["63879da0-5aa5-4c13-9e08-29fb2dc18c12"]},"63879da0-5aa5-4c13-9e08-29fb2dc18c12":{"id":"63879da0-5aa5-4c13-9e08-29fb2dc18c12","message":{"id":"63879da0-5aa5-4c13-9e08-29fb2dc18c12","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1741916886.735105,"update_time":null,"content":{"content_type":"text","parts":["Framing AI technological development through the lens of geopolitical competition, as OpenAI does by explicitly highlighting rivalry with China (PRC), offers strategic clarity and urgency but also introduces significant risks and complexities. Here's a precise, comprehensive analysis of the benefits and drawbacks:\n\n---\n\n## Benefits:\n\n### 1. **Strategic Clarity and Focus**\n- Frames AI as a central pillar of national security, clearly communicating the stakes involved.\n- Provides policymakers and stakeholders with tangible objectives, such as maintaining superiority over specific competitors (e.g., China).\n- Helps align resources, political will, and public support behind targeted investments and policy initiatives.\n\n### 2. **Accelerated Innovation and Investment**\n- Heightens sense of urgency, stimulating increased public and private investment in AI research, infrastructure, and talent.\n- Encourages quicker decision-making, faster approval processes, and reduced bureaucratic delays.\n\n### 2. **Promotion of Democratic Values**\n- Reinforces the notion that AI leadership is not just technical but ideological\u2014prioritizing privacy, security, individual liberties, and open societies against authoritarian AI development.\n- Encourages international partnerships and alliances based on democratic principles, creating broader geopolitical cohesion around AI norms and governance.\n\n### 3. **Economic Competitiveness**\n- Drives investments in critical infrastructure, including chip manufacturing, data centers, and energy grids, catalyzing broader economic growth.\n- Supports job creation in AI and related industries, especially significant during a period of industrial reshoring and modernization efforts.\n\n### 3. **Export Market Expansion**\n- Aligns commercial diplomacy with national security by promoting widespread global adoption of American-developed AI systems.\n- Opens strategic markets and extends U.S. geopolitical influence, potentially limiting adversaries' reach.\n\n---\n\n## Drawbacks:\n\n### 1. **Risk of AI Arms Race and Escalation**\n- Geopolitical framing intensifies competitive dynamics, potentially accelerating a global \"AI arms race,\" prompting adversaries to invest more aggressively, increasing the risk of confrontation and escalation.\n- Can foster an environment that encourages secrecy, potentially reducing global transparency and collaborative research critical to safety and ethical development.\n\n### 2. **Overemphasis on Competition with the PRC**\n- Excessive focus on countering China could overshadow domestic concerns such as AI ethics, responsible innovation, and societal impacts.\n- Risks distorting AI policy-making, turning technology into a geopolitical weapon rather than a broad societal good.\n\n### 3. **Global Fragmentation of AI Standards**\n- Polarizing global AI standards between democratic and autocratic camps might reduce international cooperation on critical issues such as safety standards and risk management.\n- Could create international fragmentation and increase the complexity for multinational corporations, potentially impeding cooperation essential for global AI safety.\n\n### 3. **Domestic Regulatory Complexity**\n- While aiming to streamline federal regulations, proposals risk creating conflicts between federal and state-level policymaking, especially if states resist federal preemption.\n- May stifle important state-level innovations and public protections, triggering contentious political disputes.\n\n### 4. **Intellectual Property and Fair Use Tensions**\n- Proposed expansive fair use frameworks might encounter strong resistance from content creators, potentially leading to extensive litigation or backlash from rights holders.\n- If international copyright laws diverge sharply (e.g., EU opt-out regimes), it could complicate international harmonization efforts.\n\n---\n\n## Forward-Thinking Perspective:\n\nLooking ahead, OpenAI\u2019s proposals for the U.S. AI Action Plan provide a structured, freedom-oriented vision centered around maintaining technological and ideological leadership. However, to fully realize these benefits while mitigating the risks:\n\n- The U.S. should ensure balanced domestic dialogue on AI policy, not reducing it solely to an anti-PRC posture.\n- AI governance must carefully integrate global democratic leadership with robust internal governance practices, transparently addressing concerns over privacy, surveillance, labor market disruption, and inequality.\n- Policymakers should proactively build safeguards and ethical frameworks to avoid unintended negative consequences such as misuse of AI systems domestically or abroad.\n- Policies should be inclusive enough to foster global cooperation, ensuring allies perceive U.S. efforts as beneficial rather than purely self-interested or overly restrictive.\n\n---\n\n## Conclusion:\nOpenAI\u2019s approach strategically leverages geopolitical context to sharpen AI policy, providing clear and ambitious directives designed to secure American leadership. However, it necessitates careful handling to avoid fueling geopolitical tensions, sacrificing important domestic priorities, and inadvertently restricting beneficial international collaboration. Such a balanced approach ensures that democratic AI values flourish globally, while practical security, innovation, and competitiveness remain central."]},"status":"finished_successfully","end_turn":true,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200002]},"is_complete":true,"citations":[],"content_references":[],"message_type":null,"model_slug":"gpt-4-5","default_model_slug":"gpt-4-5","parent_id":"faf9e69e-e635-4df9-9f5a-42e48a8a0b65","request_id":"92001b5aea9544c3-SIN","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"faf9e69e-e635-4df9-9f5a-42e48a8a0b65","children":["16aaddfa-c92d-477c-8758-b45e81a2cfb6"]},"16aaddfa-c92d-477c-8758-b45e81a2cfb6":{"id":"16aaddfa-c92d-477c-8758-b45e81a2cfb6","message":{"id":"16aaddfa-c92d-477c-8758-b45e81a2cfb6","author":{"role":"user","name":null,"metadata":{}},"create_time":1742011927.173,"update_time":null,"content":{"content_type":"text","parts":["Assess OpenAI's stance on copyright as per the attached document. Give me your critical take"]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"serialization_metadata":{"custom_symbol_offsets":[]},"dictation":false,"request_id":"92092bc979a2ab62-DFW","message_source":null,"timestamp_":"absolute","message_type":null,"can_save":true},"recipient":"all","channel":null},"parent":"63879da0-5aa5-4c13-9e08-29fb2dc18c12","children":["f4b138a9-a159-4f77-a076-0ed2800dbb54"]},"f4b138a9-a159-4f77-a076-0ed2800dbb54":{"id":"f4b138a9-a159-4f77-a076-0ed2800dbb54","message":{"id":"f4b138a9-a159-4f77-a076-0ed2800dbb54","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1742011931.694134,"update_time":null,"content":{"content_type":"text","parts":["Here's a precise, comprehensive, and forward-looking critical analysis of OpenAI's stance on copyright in their response:\n\n---\n\n### **Summary of OpenAI's Copyright Stance**\n\nOpenAI argues strongly for the preservation and enhancement of the existing U.S. copyright framework\u2014particularly the fair use doctrine\u2014as crucial for maintaining American leadership in AI. They assert that fair use enables transformative AI training practices, promoting innovation without infringing on the commercial value of original works. OpenAI stresses that overly rigid copyright regulations (like those emerging in the EU and UK) would impede AI progress by restricting access to training data, thus indirectly benefiting competitors, especially China.\n\n---\n\n## **Strengths of OpenAI's Position**\n\n### 1. **Strategic Economic and National Security Focus**\n- Explicitly connects copyright policy with U.S. competitiveness and national security, articulating a clear strategic rationale.\n- Emphasizes that restrictive copyright regimes could disadvantage U.S. firms, given the PRC's comparatively unrestricted access to global data.\n\n### 2. **Protection of Innovation via Fair Use Doctrine**\n- Promotes AI innovation by preserving fair use, ensuring a balanced environment conducive to ongoing AI research and development.\n- Argues convincingly that AI model training inherently constitutes transformative use (learning from but not reproducing copyrighted content).\n\n### 3. **Proactive International Advocacy**\n- Proposes active engagement in international policy debates, promoting standards favorable to U.S. companies to preempt regulatory arbitrage by competitors.\n- Suggests expanded access to government-held data, a pragmatic step to mitigate risks from reduced training data availability.\n\n---\n\n## **Weaknesses and Risks**\n\n### 1. **Potential Underestimation of Content Creator Concerns**\n- Minimizes concerns that AI training may indirectly impact creators' incentives or commercial interests by focusing primarily on benefits to AI companies.\n- Fails to sufficiently address the nuances of copyright holders\u2019 rights, risking backlash or litigation that could hinder rather than accelerate innovation.\n\n### 2. **Overly Simplistic Framing of the Copyright Debate**\n- Positions the choice primarily as binary (either maintain fair use broadly or lose competitiveness), potentially neglecting nuanced solutions such as regulated licensing frameworks or revenue-sharing arrangements.\n- Ignores alternative models that could balance rights holders\u2019 interests and technological innovation in ways that reduce conflict and litigation risks.\n\n### 3. **Dependence on Current Fair Use Interpretation**\n- Assumes U.S. courts will consistently favor fair use for AI training, which remains legally uncertain given ongoing litigation. If future court decisions restrict fair use for AI training, OpenAI\u2019s stance could leave the industry vulnerable to disruptions or liabilities.\n\n### 4. **Underestimation of Potential Domestic Opposition**\n- Fails to adequately acknowledge legitimate concerns raised by content creators, rights holders, and privacy advocates about broad data-mining practices inherent in AI training processes.\n- Could provoke domestic resistance, hindering effective legislative implementation of their recommendations.\n\n---\n\n## **Forward-Thinking Recommendations**\n\nTo refine OpenAI\u2019s approach, several forward-looking recommendations could strengthen their position and ensure broader acceptance:\n\n### 1. **Advocate a Balanced Licensing or Compensation Scheme**\n- Consider advocating for new licensing frameworks or limited statutory licenses that guarantee equitable compensation for creators whose content is significantly used in AI model training.\n\n### 2. **Strengthen Public and Industry Engagement**\n- Engage more explicitly and transparently with creators and rights holders, actively addressing their economic and ethical concerns about AI use of their content, reducing the likelihood of backlash or damaging litigation.\n\n### 3. **Develop a Clear Domestic Governance Structure**\n- Propose clearer federal guidelines or standards on AI data-mining practices, reducing reliance on the fair use doctrine\u2019s unpredictability and mitigating potential litigation risks.\n\n### 4. **International Policy Alignment**\n- Encourage the U.S. government to work with like-minded democracies on copyright frameworks that both foster AI innovation and respect creators' rights, rather than only opposing EU-style opt-out models.\n\n---\n\n## **Conclusion (Forward-thinking View)**\n\nOpenAI\u2019s copyright strategy presents a compelling, security-oriented case for preserving flexibility and freedom to innovate. However, its overly simplified framing risks underestimating the real-world complexity, potential backlash, and international divergence in copyright norms. \n\nA more robust long-term approach would involve balanced policymaking that integrates AI developers' needs with creators' rights, actively manages domestic stakeholder concerns, and engages internationally to harmonize copyright approaches in democratic nations. Such balanced policies would ensure sustained AI leadership and broader societal buy-in, supporting both innovation and respect for intellectual property.\n\n---"]},"status":"finished_successfully","end_turn":true,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200002]},"is_complete":true,"citations":[],"content_references":[],"message_type":null,"model_slug":"gpt-4-5","default_model_slug":"gpt-4-5","parent_id":"16aaddfa-c92d-477c-8758-b45e81a2cfb6","request_id":"92092bc979a2ab62-DFW","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"16aaddfa-c92d-477c-8758-b45e81a2cfb6","children":["4829df30-1479-48e6-9ae4-76ffac411c4a"]},"4829df30-1479-48e6-9ae4-76ffac411c4a":{"id":"4829df30-1479-48e6-9ae4-76ffac411c4a","message":{"id":"4829df30-1479-48e6-9ae4-76ffac411c4a","author":{"role":"user","name":null,"metadata":{}},"create_time":1742013051.743,"update_time":null,"content":{"content_type":"text","parts":["Formulate a more robust framework for handling copyright that would respect the work of creators of original content whilst not impeding the advancement of AI or surrendering undue advantage to geopolitical adversaries (who cannot be assumed to follow the US's rules, whether they be fair or unfair rules)"]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"serialization_metadata":{"custom_symbol_offsets":[]},"dictation":false,"request_id":"9209473e292cfd8c-DFW","message_source":null,"timestamp_":"absolute","message_type":null,"can_save":true},"recipient":"all","channel":null},"parent":"f4b138a9-a159-4f77-a076-0ed2800dbb54","children":["f08ae4ae-b265-43d0-a657-f5d9f9d1bacf"]},"f08ae4ae-b265-43d0-a657-f5d9f9d1bacf":{"id":"f08ae4ae-b265-43d0-a657-f5d9f9d1bacf","message":{"id":"f08ae4ae-b265-43d0-a657-f5d9f9d1bacf","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1742013056.065412,"update_time":null,"content":{"content_type":"text","parts":["Here's a robust and nuanced framework that carefully balances protecting original creators while encouraging innovation and maintaining geopolitical competitiveness in AI:"]},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200007]},"is_complete":true,"citations":[],"content_references":[],"message_type":null,"model_slug":"gpt-4-5","default_model_slug":"gpt-4-5","parent_id":"4829df30-1479-48e6-9ae4-76ffac411c4a","request_id":"9209473e292cfd8c-DFW","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"4829df30-1479-48e6-9ae4-76ffac411c4a","children":["fd713196-d384-4cf4-89c7-031254ef2362"]},"fd713196-d384-4cf4-89c7-031254ef2362":{"id":"fd713196-d384-4cf4-89c7-031254ef2362","message":{"id":"fd713196-d384-4cf4-89c7-031254ef2362","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1742013058.106994,"update_time":null,"content":{"content_type":"code","language":"json","response_format_name":null,"text":"{\"name\":\"robust_ai_copyright_framework\",\"type\":\"document\",\"content\":\"**Robust Framework for Copyright in the AI Era**\\n\\n### Principles and Objectives:\\n- **Balance:** Protect creators' rights and provide fair compensation, while supporting AI innovation.\\n- **Transparency:** Clearly defined rights, usage conditions, and compensation frameworks.\\n- **Competitiveness:** Ensure policies support American technological leadership without inadvertently aiding adversaries.\\n- **International Alignment:** Work toward global harmonization of standards with democratic allies.\\n\\n### Core Components:\\n\\n#### 1. **Tiered Licensing System:**\\n- Establish clearly differentiated licensing frameworks:\\n  - **General License (Minimal Barrier):** Freely available datasets, public-domain, open-source, government-generated data.\\n  - **Fair Use-Extended License:** Clearly define expanded fair use parameters for AI training that exclude explicit commercial redistribution or direct reproduction, but allow pattern and feature extraction for model training.\\n  - **Premium License:** For content explicitly commercial or with high intrinsic value, introduce a standardized, affordable licensing structure with direct compensation to original creators or rights holders.\\n\\n#### Implementation:\\n- **AI Licensing Clearinghouse:** A centralized digital platform, potentially government-managed or publicly overseen, where creators can voluntarily register their content with clear opt-in/opt-out mechanisms. This would streamline licensing and ensure transparency.\\n- **Equitable Compensation:** Develop standardized mechanisms (e.g., micro-payments, pooled funds, or collective licensing) for distributing compensation to creators, ensuring fairness without excessive administrative overhead.\\n\\n### International Coordination:\\n- Actively shape international copyright discussions to advocate a balanced approach that aligns closely with U.S. fair-use principles but includes clear and manageable opt-in licensing mechanisms.\\n- Foster international agreements to standardize licensing practices that support AI innovation while respecting intellectual property rights, reducing opportunities for geopolitical adversaries to benefit from legal arbitrage.\\n\\n### Protective Measures Against Geopolitical Adversaries:\\n- Maintain clear national security-based exceptions and safeguards:\\n  - Explicitly prohibit IP and data transfer or training that directly benefits geopolitical adversaries' military or intelligence capabilities.\\n  - Implement mandatory disclosures by AI companies regarding foreign data sources and related risk assessments.\\n\\n### Government's Role:\\n- **Legislative Clarity:** Congress should explicitly codify the extent and limits of AI fair use, ensuring legal clarity and stability for innovation.\\n- **Investment in Public Data:** Digitize and open government-held datasets, enabling safe domestic sources to mitigate data limitations.\\n- **Data Reciprocity Principle:** International negotiations should ensure reciprocity in data access\u2014U.S. openness should encourage or require reciprocal openness abroad, especially among allied and partner nations.\\n\\n### Incentivizing Creator Cooperation:\\n- Provide economic incentives (tax breaks, subsidies, or grants) for creators and publishers who contribute positively to AI training datasets through transparent and equitable licensing frameworks.\\n- Encourage partnerships between AI companies and creative sectors to innovate in content creation tools and services, promoting mutual benefit.\\n\\n### Monitoring and Adaptive Policy Framework:\\n- Establish a dynamic regulatory review process (every 3-5 years) to reassess and adapt to technological developments, international practices, and economic impacts.\\n- Continuously engage stakeholders (AI companies, creators, publishers, and privacy advocates) to ensure ongoing alignment with societal expectations and technological progress.\\n\\nBy integrating these principles, this framework fosters responsible AI innovation, respects creators' rights, and maintains America's competitive edge globally.\"}"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200007]},"is_complete":true,"citations":[],"content_references":[],"message_type":null,"model_slug":"gpt-4-5","default_model_slug":"gpt-4-5","parent_id":"f08ae4ae-b265-43d0-a657-f5d9f9d1bacf","request_id":"9209473e292cfd8c-DFW","timestamp_":"absolute","can_save":true},"recipient":"canmore.create_textdoc","channel":null},"parent":"f08ae4ae-b265-43d0-a657-f5d9f9d1bacf","children":["79536549-763c-462f-a7dd-df6841653596"]},"79536549-763c-462f-a7dd-df6841653596":{"id":"79536549-763c-462f-a7dd-df6841653596","message":{"id":"79536549-763c-462f-a7dd-df6841653596","author":{"role":"tool","name":"canmore.create_textdoc","metadata":{}},"create_time":1742013109.251427,"update_time":null,"content":{"content_type":"text","parts":["Successfully created text document 'Robust Ai Copyright Framework' which will be referenced in all future messages with the unique identifier textdoc_id: '67d502b198808191b2c2432e58c9153b'"]},"status":"finished_successfully","end_turn":null,"weight":0.0,"metadata":{"canvas":{"textdoc_id":"67d502b198808191b2c2432e58c9153b","textdoc_type":"document","version":1,"title":"Robust Ai Copyright Framework","create_source":"model"},"command":"create_textdoc","message_type":null,"model_slug":"gpt-4-5","default_model_slug":"gpt-4-5","parent_id":"fd713196-d384-4cf4-89c7-031254ef2362","request_id":"9209473e292cfd8c-DFW","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"fd713196-d384-4cf4-89c7-031254ef2362","children":["f5d23bb1-5e76-4d3b-b3b3-c101ea5f12e7"]},"f5d23bb1-5e76-4d3b-b3b3-c101ea5f12e7":{"id":"f5d23bb1-5e76-4d3b-b3b3-c101ea5f12e7","message":{"id":"f5d23bb1-5e76-4d3b-b3b3-c101ea5f12e7","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1742013105.708709,"update_time":null,"content":{"content_type":"text","parts":["I've outlined a robust and balanced framework as requested, ensuring respect for creators while promoting AI innovation and national competitiveness. Let me know if you would like further adjustments or expansions."]},"status":"finished_successfully","end_turn":true,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200002]},"is_complete":true,"citations":[],"content_references":[],"message_type":null,"model_slug":"gpt-4-5","default_model_slug":"gpt-4-5","parent_id":"79536549-763c-462f-a7dd-df6841653596","request_id":"9209473e292cfd8c-DFW","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"79536549-763c-462f-a7dd-df6841653596","children":["080236fc-14c4-46a1-91c6-452e37009c19"]},"080236fc-14c4-46a1-91c6-452e37009c19":{"id":"080236fc-14c4-46a1-91c6-452e37009c19","message":{"id":"080236fc-14c4-46a1-91c6-452e37009c19","author":{"role":"user","name":null,"metadata":{}},"create_time":1742130832.888,"update_time":null,"content":{"content_type":"text","parts":["According to the attached document, does OpenAI call for a ban or any form of restriction on Chinese controlled AI?"]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"serialization_metadata":{"custom_symbol_offsets":[]},"dictation":false,"request_id":"921482a7d88a9e46-SIN","message_source":null,"timestamp_":"absolute","message_type":null,"can_save":true},"recipient":"all","channel":null},"parent":"f5d23bb1-5e76-4d3b-b3b3-c101ea5f12e7","children":["46f0d89b-60a6-42d5-9256-37fae81a9244"]},"46f0d89b-60a6-42d5-9256-37fae81a9244":{"id":"46f0d89b-60a6-42d5-9256-37fae81a9244","message":{"id":"46f0d89b-60a6-42d5-9256-37fae81a9244","author":{"role":"system","name":null,"metadata":{}},"create_time":1742130844.959302,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":true,"weight":0.0,"metadata":{"rebase_system_message":true,"message_type":null,"model_slug":"gpt-4-5","default_model_slug":"gpt-4-5","parent_id":"080236fc-14c4-46a1-91c6-452e37009c19","request_id":"921482a7d88a9e46-SIN","timestamp_":"absolute","is_visually_hidden_from_conversation":true,"can_save":false},"recipient":"all","channel":null},"parent":"080236fc-14c4-46a1-91c6-452e37009c19","children":["7753eb32-1851-48fd-90b9-1f512119af61"]},"7753eb32-1851-48fd-90b9-1f512119af61":{"id":"7753eb32-1851-48fd-90b9-1f512119af61","message":{"id":"7753eb32-1851-48fd-90b9-1f512119af61","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1742130833.03005,"update_time":null,"content":{"content_type":"text","parts":["Yes, OpenAI explicitly advocates for restrictions on Chinese-controlled AI, as outlined in their submitted document:\n\n- **Export Controls and Restrictions**: OpenAI proposes a structured export control system categorizing countries into three tiers, with China placed clearly in **Tier III**, meaning it would be subjected to strict export controls prohibiting access to American-developed democratic AI systems, infrastructure, and advanced AI chips. Specifically, Tier III explicitly includes China (PRC) as a category prohibited from accessing American-led democratic AI technology due to concerns related to national security, intellectual property theft, and the risk of misuse by the CCP (Chinese Communist Party).\n\n- **Reasons for Restrictions**:\n  - Risks of IP theft and security vulnerabilities inherent in CCP-influenced or controlled AI systems.\n  - Concerns over potential misuse of these systems for malicious purposes (e.g., espionage, surveillance, illicit activities).\n  - The strategic importance of maintaining a technological and geopolitical advantage over the PRC, especially in the context of critical infrastructure and high-risk use cases.\n\n- **Additional Security Measures Proposed**:\n  - Banning PRC-produced equipment (like Huawei chips) within critical infrastructure.\n  - Prohibiting AI infrastructure relationships with military or intelligence agencies in Tier III (which explicitly includes the PRC).\n\nThese recommendations reflect OpenAI's broader geopolitical strategy that AI leadership must align with democratic principles, freedom of innovation, and national security imperatives\u2014thus supporting strict export controls and restrictions targeting Chinese-controlled AI and related technologies.\n\n\u30106\u2020source\u3011"]},"status":"finished_successfully","end_turn":true,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200002]},"is_complete":true,"citations":[{"start_ix":1734,"end_ix":1744,"citation_format_type":"tether_og","metadata":{"type":"file","name":"openai-response-ostp-nsf-rfi-notice-request-for-information-on-the-development-of-an-artificial-intelligence-ai-action-plan.pdf","id":"file-5eiqpyd6a14ZasQ6c6cULw","source":"my_files","text":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[OpenAI Response] OSTP/NSF RFI: Notice Request for Information on the Development of an Artificial Intelligence (AI) Action Plan - Google Docs\n\n\n March 13, 2025 \n\n To: Faisal D'Souza, NCO  From: Christopher Lehane \n Office of Science and Technology Policy  OpenAI \n 2415 Eisenhower Avenue  1455 3rd Street \n Alexandria, VA 22314  San Francisco, CA 94158 \n\n This document is approved for public dissemination. The document contains no business-proprietary or confidential \n information. Document contents may be reused by the government in developing the AI Action Plan and associated \n documents without attribution. \n\n \u201cIt is the policy of the United States to sustain and enhance America\u2019s global dominance in \n order to promote human flourishing, economic competitiveness, and national security\u201d \n\n \u2013 President Donald J. Trump, Executive Order 14179, January 23, 2025 \n\n OpenAI respectfully submits the enclosed proposals to the Office of Science and \n Technology Policy as it weighs a new AI Action Plan that will, as Vice President Vance \n stated recently at the Paris AI Action Summit, maintain American leadership in AI and \n \u201cmake people more productive, more prosperous, and more free.\u201d As America\u2019s \n world-leading AI sector approaches artificial general intelligence (AGI), with a Chinese \n Communist Party (CCP) determined to overtake us by 2030, the Trump Administration\u2019s \n new AI Action Plan can ensure that American-led AI built on democratic principles \n continues to prevail over CCP-built autocratic, authoritarian AI. \n\n OpenAI agrees with the Trump Administration that AI creates prosperity and freedom worth \n fighting for\u2014especially for younger generations whose future will be shaped by how this \n Administration approaches AI. Globally, most ChatGPT users are under age 35; in the US, \n about one third are ages 18 to 24.  1  Both young people and their parents recognize the \n economic opportunities AI presents: \n\n \u25cf  More than seven in 10 parents in the US believe children today will be worse off \n financially than they are.  2 \n\n \u25cf  Nine in 10 US parents think it's important that their kids learn how to use artificial \n intelligence for their future jobs\u2014and eight in 10 say either that isn\u2019t happening \n today, or they don\u2019t know if it is.  3 \n\n \u25cf  Three in four college-age AI users want to use AI in their education and careers. \n Many are teaching themselves and their friends about AI without waiting for their \n schools to provide formal AI education.  4 \n\n 4  OpenAI:  Building an AI-Ready Workforce: A Look at  ChatGPT Adoption in the US  , Feb. 2025 \n\n 3  Morning Consult survey commissioned by Samsung:  88%  of US Parents of Gen Alpha & Gen Z Students Say AI \n Will Be Crucial to Their Child\u2019s Future Success  , Sept.  2024 \n\n 2  Pew Research Center:  Views of children\u2019s financial  future  , Jan. 2025 \n 1  Self-reported among logged-in users \n\n 1 \n\nhttps://cdn.openai.com/global-affairs/openai-edu-ai-ready-workforce.pdf\nhttps://news.samsung.com/us/88-percent-us-parents-gen-alpha-gen-z-students-say-ai-crucial-to-childs-future-success-samsung-solve-for-tomorrow/\nhttps://news.samsung.com/us/88-percent-us-parents-gen-alpha-gen-z-students-say-ai-crucial-to-childs-future-success-samsung-solve-for-tomorrow/\nhttps://www.pewresearch.org/global/2025/01/09/views-of-childrens-financial-future/\n\n\n In particular, AI could drive significant increased productivity over the next decade. Here\u2019s \n how we can realize this heightened prosperity and greater freedom together. \n\n Scaling human ingenuity \n Innovation creates and scales our ability to push beyond our current limits. From foot travel \n to the domesticated horse, the wheel, steam power, the car, the plane\u2014we scaled the \n freedom of mobility. From daylight to candle and lamplight, to electricity providing light and \n power at all hours\u2014we scaled the freedom to produce, think and create. From word of \n mouth to the stylus and tablet, to the printing press, telegraph, phone, computer, \n smartphone\u2014we scaled freedom of learning and knowledge. Now, as we approach AGI, \n innovation is poised to scale human ingenuity itself\u2014the sum of our freedoms to learn and \n know, think, create and produce. \n\n As our CEO Sam Altman  has written  , we are at the doorstep  of the next leap in prosperity: \n the Intelligence Age. But we must ensure that people have  freedom of intelligence  , by \n which we mean the freedom to access and benefit from AGI, protected from both autocratic \n powers that would take people\u2019s freedoms away, and layers of laws and bureaucracy that \n would prevent our realizing them. \n\n More than 400 million people around the world are using ChatGPT to ideate, discover, and \n break through beyond what we\u2019re currently capable of doing on our own. Just two weeks \n ago, we partnered with the Department of Energy\u2019s national labs to  bring together  1,500 \n scientists to use our tools to take scientific discovery farther, faster. \n\n Our work at OpenAI also suggests that as AI advances, progress accelerates and becomes \n increasingly affordable, as reflected in these three scaling principles: \n\n 1.  The intelligence of an AI model roughly equals  the log of the resources used to train and \n run it.  Until recently, scaling progress has primarily  come from training compute and data, \n but we have shown how to make intelligence scale from inference compute, as well. The \n scaling laws that predict these gains are incredibly precise over many orders of magnitude, \n so investing more in AI will continue to make it better and more capable.  We believe that \n the socioeconomic value of linearly increasing intelligence is super-exponential in nature. \n\n 2.  The cost to use a given level of AI capability  falls by about 10x every 12 months, and \n lower prices lead to much more use.  We saw this in  the change in token cost between \n GPT-4 in early 2023 and GPT-4o in mid-2024, where the price per token dropped about \n 150x in that time period.  Moore\u2019s Law predicted that  the number of transistors on a \n microchip would double roughly every two years; the decrease in the cost of using AI is \n even more dramatic. \n\n 2 \n\nhttps://ia.samaltman.com/\nhttps://cdn.openai.com/global-affairs/openai-usnl-scientist-ai-jam-session.pdf\n\n\n 3.  The amount of calendar time it takes to improve  an AI model keeps decreasing  . AI \n models are catching up with human intelligence at an increasing rate. The typical time it \n takes for a computer to beat humans at a given benchmark has fallen from 20 years after \n the benchmark was introduced, to five years, and now to one to two years  \u2014and we see no \n reason why those advancements will stop in the near future. \n\n By scaling human ingenuity ever faster and more affordably, AGI will create a flywheel of \n more freedom leading to more productivity, prosperity, and yet more innovation\u2014letting us \n once again focus on positive-sum growth. \n\n Advancing democratic AI \n OpenAI believes the best future is one in which we move forward with democratic AI\u2014AI \n that is shaped by the democratic principles America has always stood for. As OpenAI \n recently laid out in our  Economic Blueprint  , we believe  these principles include: \n\n \u25cf  A free market  promoting free and fair competition  that drives innovation. \n \u25cf  Freedom for developers and users  to work with and  direct our tools as they see fit, \n\n in exchange for following clear, common-sense technical standards that help keep \n AI safe for everyone, and being held accountable when they don\u2019t. \n\n \u25cf  Preventing government use of AI tools to amass power and control their citizens  , \n or to threaten or coerce other states. \n\n In advancing democratic AI, America is competing with a CCP determined to become the \n global leader by 2030. That\u2019s why the recent release of DeepSeek\u2019s R1 model is so \n noteworthy\u2014not because of its capabilities (R1\u2019s reasoning capabilities, albeit impressive, \n are at best on par with several US models), but as a gauge of the state of this competition. \n\n As with Huawei, there is significant risk in building on top of DeepSeek models in critical \n infrastructure and other high-risk use cases given the potential that DeepSeek could be \n compelled by the CCP to manipulate its models to cause harm. And because DeepSeek is \n simultaneously state-subsidized, state-controlled, and freely available, the cost to its users \n is their  privacy and security  , as DeepSeek faces requirements  under Chinese law to \n comply with demands for user data and uses it to train more capable systems for the CCP\u2019s \n use. Their models also more willingly generate how-to\u2019s for illicit and harmful activities such \n as identity fraud and intellectual property theft, a reflection of how the CCP views violations \n of American IP rights as a feature, not a flaw. \n\n 3 \n\nhttps://cdn.openai.com/global-affairs/openai-us-economicblueprint-feb-2025-edu-update.pdf\nhttps://blogs.cisco.com/security/evaluating-security-risk-in-deepseek-and-other-frontier-reasoning-models\n\n\n Today, CCP-controlled China has a number of strategic advantages, including: \n \u25cf  As an authoritarian state, its ability to quickly marshal resources  \u2014data, energy, \n\n technical talent, and the enormous sums needed to build out its own domestic chip \n development capacity. \n\n \u25cf  Its preexisting Belt and Road initiative.  As with  Huawei, the PRC will scale the \n adoption of PRC-based AI systems like DeepSeek\u2019s by coercing countries needing \n AI tools and nation-building infrastructure funds. \n\n \u25cf  Its ability to benefit from regulatory arbitrage being created by individual American \n states  seeking to pass their own industry-wide laws,  some of which are modeled \n on the European Union\u2019s regulation of AI. These laws are easier to enforce with \n domestic AI companies than PRC-based companies and could impose \n burdensome compliance requirements that may hinder our economic \n competitiveness and undermine our national security. They also may weaken the \n quality and level of training data available to American entrepreneurs and the \n usefulness for downstream consumers and businesses. \n\n \u25cf  Its ability to benefit from copyright arbitrage being created by democratic nations \n that do not clearly protect AI training by statute, like the US, or that reduce the \n amount of training data through an opt-out regime for copyright holders, like the \n EU. The PRC is unlikely to respect the IP regimes of any of such nations for the \n training of its AI systems, but already likely has access to all the same data, putting \n American AI labs at a comparative disadvantage while gaining little in the way of \n protections for the original IP creators. \n\n While America maintains a lead on AI today, DeepSeek shows that our lead is not wide and \n is narrowing. The AI Action Plan should ensure that American-led AI prevails over CCP-led \n AI, securing both American leadership on AI and a brighter future for all Americans. \n\n What we propose \n OpenAI\u2019s freedom-focused policy proposals, taken together, can strengthen America\u2019s lead \n on AI and in so doing, unlock economic growth, lock in American competitiveness, and \n protect our national security. Specifically, we detail: \n\n A regulatory strategy that ensures the freedom to innovate:  For innovation to truly create \n new freedoms, America\u2019s builders, developers, and entrepreneurs\u2014our nation\u2019s greatest \n competitive advantage\u2014must first have the freedom to innovate in the national interest. We \n propose a holistic approach that enables voluntary partnership between the federal \n government and the private sector, and neutralizes potential PRC benefit from American AI \n companies having to comply with overly burdensome state laws. \n\n 4 \n\n\n\n An export control strategy that exports democratic AI:  For countries seeking access to \n American AI, we propose a strategy that  would apply a commercial growth lens\u2014both Total \n and Serviceable Addressable Markets\u2014to proactively promote the global adoption of \n American AI systems and with them, the freedoms they create. At the same time, the \n strategy would use export controls to protect America\u2019s AI lead, including by making \n updates to the AI diffusion rule. \n\n A copyright strategy that promotes the freedom to learn:  America\u2019s robust, balanced \n intellectual property system has long been key to our global leadership on innovation. We \n propose a copyright strategy that would extend the system\u2019s role into the Intelligence Age \n by protecting the rights and interests of content creators while also protecting America\u2019s AI \n leadership and national security. The federal government can both secure Americans\u2019 \n freedom to learn from AI, and avoid forfeiting our AI lead to the PRC by preserving \n American AI models\u2019 ability to learn from copyrighted material. \n\n A strategy to seize the infrastructure opportunity to drive growth:  Sustaining America\u2019s lead \n on AI means building the necessary infrastructure to compete with the PRC and its \n commandeered resources. We propose policies to seize this unmissable opportunity to \n catalyze a reindustrialization across our country, creating and supporting hundreds of \n thousands of jobs, boosting local economies, modernizing our energy grid, and preparing \n an AI-ready workforce  \u2014t  he key pillar of any country\u2019s  AI infrastructure. \n\n An ambitious government adoption strategy:  Advancing  democratic AI around the world \n starts with ensuring that the US government itself sets an example of governments using AI \n to keep their people safe, prosperous, and free. With the PRC progressing toward \n ambitious targets for AI adoption across its public administration, security, and military, the \n US government should modernize its processes to safely deploy frontier AI tools at the \n pace of the private sector and with the efficiency Americans deserve. \n\n America always succeeds when it bets on American ingenuity. The enclosed policy \n proposals are either derived from, or in the case of copyright represent updates to  OpenAI's \n Economic Blueprint  , and we look forward to discussing  them with you. \n\n Chris Lehane \n Vice President, Global Affairs \n\n 5 \n\nhttps://cdn.openai.com/global-affairs/openai-us-economicblueprint-feb-2025-edu-update.pdf\nhttps://cdn.openai.com/global-affairs/openai-us-economicblueprint-feb-2025-edu-update.pdf\n\n\n 1. Preemption: Ensuring the Freedom to Innovate \n\n We propose creating a tightly-scoped framework for voluntary partnership between the \n federal government and the private sector to protect and strengthen American national \n security. This framework would extend the tradition of government receiving learnings \n and access, where appropriate, in exchange for providing the private sector relief from \n the  781 and counting proposed AI-related bills  already  introduced this year in US states. \n This patchwork of regulations risks bogging down innovation and, in the case of AI, \n undermining America\u2019s leadership position. \n\n Overseen by the US Department of Commerce and in coordination with the AI Czar, \n perhaps by reimagining the US AI Safety Institute, this effort would provide domestic AI \n companies with a single, efficient \u201cfront door\u201d to the federal government that would \n coordinate expertise across the entire national security and economic competitiveness \n communities.  5 \n\n This targeted framework would empower the federal government to: \n \u25cf  Work with both large AI companies and start-ups on a purely voluntary and \n\n optional basis to stay informed about AI risks as well as cutting-edge capabilities \n that support US national interests  ,  including by establishing  sandbox and testing \n capabilities on the secure premises of federal agencies. \n\n \u25cf  Evaluate the state of American AI technology against the technology of \n competitors and adversaries, including evaluating foreign models for the potential \n for back doors or malign influence. \n\n \u25cf  Coordinate the development of technical standards for evaluating and \n safeguarding frontier models from national security risks. \n\n \u25cf  Provide American AI companies with the tools and classified threat intelligence to \n mitigate national security risks that are exacerbated by frontier models (e.g., \n cyber, CBRN) and posed by nation-state actors (e.g., economic espionage by \n China). \n\n \u25cf  Incentivize companies to take part in this voluntary initiative by creating glide \n paths for them to contract with the government, including on national security \n projects; creating strong protections for any company information shared during \n these partnerships; and reducing barriers to companies' internal work related to \n national security domains. \n\n \u25cf  Guarantee that state-based legislation does not undermine America\u2019s innovation \n lead on AI. Create a sandbox for American start-ups, and provide participating \n companies with liability protections including preemption from state-based \n\n 5  Federal preemption over existing or prospective state  laws will require an act of Congress. \n\n 6 \n\nhttps://techcrunch.com/2025/03/07/us-lawmakers-have-already-introduce-hundreds-of-ai-bills-in-2025/\n\n\n regulations that focus on frontier model security (e.g., CA SB 1047). This will help \n keep the US public and private sectors competitive by allowing AI companies of \n all sizes to pursue bleeding-edge AI technology free from the regulatory \n uncertainty created by some state-based liability regimes. \n\n 2. Export Controls: Exporting Democratic AI \n\n A comprehensive export control strategy should do more than restrict the flow of AI \n technologies to the PRC\u2014it should ensure that America is \u201cwinning diffusion\u201d, i.e., that \n as much of the world as possible is aligned to democratic values and building on \n democratic infrastructure. To that end, we propose that the US government consider the \n Total Addressable Market (TAM), i.e., the entire world less the PRC and its few allies, \n against the Serviceable Addressable Market (SAM), i.e., those countries who prefer to \n build AI on democratic rails, and help as many of the latter as possible commit, including \n by actually committing to deploy AI in line with democratic principles set out by the US \n government. \n\n In particular, we propose maintaining the AI diffusion rule\u2019s three-tiered framework to \n differentiate among countries in the global AI market, but with some key modifications \n that expand the number of countries in Tier I: \n\n Tier I:  Countries that commit to democratic AI principles  by deploying AI systems in ways \n that promote more freedoms for their citizens could be considered Tier I countries. \n\n Tier II:  Limited to only those countries that have  a history of failing to prevent \n export-controlled chips and other US-developed IP from being diverted into, or used by \n Tier III countries. These countries would be encouraged and supported to obtain Tier I \n status over time; and would be subject to more stringent security requirements in the \n interim. \n\n Tier III:  CCP-led China, along with a small cohort  of countries aligned with the CCP, \n would represent its own category that is prohibited from accessing democratic AI \n systems. \n\n This strategy would encourage global adoption of democratic AI principles, promoting the \n use of democratic AI systems while protecting US advantage. Making sure that \n open-sourced models are readily available to developers in these countries also will \n strengthen our advantage.  We believe the question  of whether AI should be open or \n\n 7 \n\n\n\n closed source is a false choice\u2014we need both, and they can work in a complementary \n way that encourages the building of AI on American rails. \n\n Tier I countries  should include American allies, as  well as those countries that are \n committed to democratic AI principles and that present a relatively low risk that American \n AI infrastructure (e.g., chips) will be diverted to non-Tier I countries. The commercial \n diplomacy strategy in Tier I should recognize these countries\u2019 strong history of export \n and customs control compliance and seek to maximally expand democratic AI systems\u2019 \n market share, while at the same time protecting those systems from IP theft by the PRC \n and other malign actors (e.g., the theft of model weights and/or chip designs, \n unauthorized influence or access to data center operations). \n\n To expand market share in Tier I countries, American commercial diplomacy policy \n should: \n\n \u25cf  Encourage cross-border capital flows and promote software frameworks that are \n optimized for domestic chip design. \n\n \u25cf  Coordinate global bans on CCP-aligned AI infrastructure, including Huawei chips. \n \u25cf  Continue to represent American company interests in safety and security \n\n standards bodies, and encourage global regulators to adopt pro-growth safety and \n security policies. \n\n \u25cf  Revise the existing export control rules to eliminate country caps on compute. \n \u25cf  Maintain existing export license exceptions (e.g., license exception ACM) that \n\n enable exports of technology and software for technical collaboration with allies \n and preservation of economically critical supply chains \n\n To protect the US-developed IP needed to operate data centers in Tier I countries, \n security requirements could include: \n\n \u25cf  Prohibiting relationships with Tier III countries\u2019 foreign military and intelligence \n services, and the use of data centers to support military/intelligence missions for \n Tier III nations or human rights violators. \n\n \u25cf  Banning the use of PRC-produced equipment (e.g., Huawei Ascend chips) and \n models that violate user privacy and create security risks such as the risk of IP \n theft. \n\n \u25cf  Maintaining corporate control by entities headquartered in Tier I countries. \n \u25cf  Implementing\u2014and constantly modernizing\u2014cybersecurity, model weight security, \n\n and personnel security controls that ideally are globally synced and coordinated \n among Tier I governments. \n\n 8 \n\n\n\n Controls on model weights\u2014if any\u2014should strike a balance between protecting \n American-developed IP and promoting the deployment of American-developed models \n over those developed by Tier III countries, including the PRC. \n\n Tier II  countries  should include those with a history  of failing to prevent \n export-controlled chips and other US-developed IP from being diverted into, or used by \n Tier III co  untries. Here, the commercial diplomacy  strategy should still seek to expand \n US market share, but should do so more carefully, including by levying stronger controls \n on the export of US-developed AI infrastructure. At the same time, the strategy should \n provide transparent pathways for Tier II countries to reach Tier I status by adopting \n democratic AI principles and more effectively managing risks of chip diversion. \n\n To expand American market share in Tier II countries, in addition to the steps above, the \n commercial diplomacy policy could be designed to leverage commercial interest in \n American-led AI in order to encourage investment in the US, enhanced security \n procedures, and encourage more countries to build on American rails: \n\n \u25cf  Establish a transparent process to evaluate countries\u2019 readiness to transition from \n Tier II to Tier I. \n\n \u25cf  Support countries\u2019 transition from Tier II to Tier I by helping Tier II governments \n strengthen their in-country security programs. \n\n \u25cf  Encourage greater economic interdependence between the US and Tier II \n countries. \n\n \u25cf  Incentivize public-private partnerships to rapidly mature, scale, and commercialize \n hardware-enabled mechanisms that could enhance in-country security controls in \n the future. \n\n To protect the American-developed IP needed to operate data centers in Tier II countries, \n and to manage both the heightened risk of IP theft and the additional risk that \n export-controlled chips might be diverted from Tier II into Tier III countries, the \n commercial diplomacy policy also could: \n\n \u25cf  Allow the export of advanced AI chips to an end-user located in a Tier II country \n that meets Tier I security requirements, and that puts in place additional corporate \n governance controls as well as technology-enhanced protections (e.g., \n hardware-enabled mechanisms) against the diversion of export-controlled chips. \n\n Tier III countries  \u2014including the PRC and any other  country subject to a US arms \n embargo\u2014s  hould continue to be subject to strict export  controls of AI systems, including \n existing export controls on advanced chips. The strategy could also expand established \n controls, for example, to include advanced chips that are required for large-scale \n\n 9 \n\n\n\n inference and RL training and the components used to manufacture advanced AI chips \n and data centers. \n\n 3. Copyright: Promoting the Freedom to Learn \n\n American copyright law, including the longstanding fair use doctrine, protects the \n transformative uses of existing works, ensuring that innovators have a balanced and \n predictable framework for experimentation and entrepreneurship. This approach has \n underpinned American success through earlier phases of technological progress and is \n even more critical to continued American leadership on AI in the wake of recent events in \n the PRC. OpenAI\u2019s models are trained to not replicate works for consumption by the \n public. Instead, they learn from the works and extract patterns, linguistic structures, and \n contextual insights. This means our AI model training aligns with the core objectives of \n copyright and the fair use doctrine, using existing works to create something wholly new \n and different without eroding the commercial value of those existing works. \n\n America has so many AI startups, attracts so much investment, and has made so many \n research breakthroughs largely because the fair use doctrine promotes AI development. \n In other markets, rigid copyright rules are repressing innovation and investment. \n\n The European Union, for one, has created \u201ctext and data mining exceptions\u201d with broadly \n applicable \u201copt-outs\u201d for any rights holder\u2014meaning access to important AI inputs is less \n predictable and likely to become more difficult as the EU\u2019s regulations take shape. \n Unpredictable availability of inputs hinders AI innovation, particularly for smaller, newer \n entrants with limited budgets. \n\n The UK government is currently considering changes to its copyright regime. It has \n indicated that it prefers creating a data mining exception that allows rights holders to \n \u201creserve their rights,\u201d creating the same regulatory barriers to AI development that we \n see in the EU. \n\n Applying the fair use doctrine to AI is not only a matter of American competitiveness \n \u2014it\u2019s a matter of national security. The rapid advances seen with the PRC\u2019s DeepSeek, \n among other recent developments, show that America\u2019s lead on frontier AI is far from \n guaranteed. Given concerted state support for critical industries and infrastructure \n projects, there\u2019s little doubt that the PRC\u2019s AI developers will enjoy unfettered access to \n data\u2014including copyrighted data\u2014that will improve their models.  If the PRC\u2019s \n developers have unfettered access to data and American companies are left without fair \n use access, the race for AI is effectively over. America loses, as does the success of \n\n 10 \n\n\n\n democratic AI  .  Ultimately, access to more data from the widest possible range of sources \n will ensure more access to more powerful innovations that deliver even more knowledge. \n\n We propose that the US government take steps to ensure that our copyright system \n continues to support American AI leadership and American economic and national \n security, including by: \n\n \u25cf  Shaping international policy discussions around copyright and AI, and working to \n prevent less innovative countries from imposing their legal regimes on American \n AI firms and slowing our rate of progress. \n\n \u25cf  Actively assessing the overall level of data available to American AI firms and \n determining whether other countries are restricting American companies\u2019 access \n to data and other critical inputs. \n\n \u25cf  Encouraging more access to government-held or government-supported data. \n This would boost AI development in any case, but would be particularly important \n if shifting copyright rules restrict American companies\u2019 access to training data. \n\n \u25cf  Monitoring domestic policy debates and ongoing litigation, and weighing in where \n fundamental, pro-innovation principles are at risk. \n\n Generative AI models represent the next frontier of innovation, poised to revolutionize \n the private and public sectors, improving healthcare, education, scientific research, and \n so much more. If AI innovation remains protected under longstanding copyright \n principles, America will maintain and strengthen its role as the world leader in \n cutting-edge technologies and remain positioned to continue championing AI based on \n democratic principles with countries around the world. \n\n 4. Infrastructure: Seizing the Opportunity to Drive Growth \n\n Today, hundreds of billions of dollars in global funds are waiting to be invested in AI \n infrastructure. If the US doesn't move fast to channel these resources into projects that \n support democratic AI ecosystems around the world, the funds will flow to projects \n backed and shaped by the CCP. \n\n We propose a foundational strategy to ensure that investment in infrastructure drives \n economic growth that benefits all Americans; maximizes access to AI; and protects \n national security interests by keeping sensitive American data on American soil. This \n includes policies and initiatives that encourage rather than stifle developers; support  a \n thriving AI-ready workforce and  ecosystems of labs,  start-ups and larger companies; and \n secure America\u2019s leadership on AI into the future. \n\n 11 \n\n\n\n First and foremost, building data centers is capital-intensive, particularly for newcomers \n seeking to compete against established hyperscalers with vast resources.  W  e support \n the solutions already proposed by this Administration  to ensure that sufficient capital \n flows to building AI infrastructure in the US: \n\n \u25cf  Investment vehicles like a Sovereign Wealth Fund  . \n \u25cf  Government offtake and guarantees tha  t both provide  the government with the \n\n compute it needs and signal to markets that the demand will be there for \n American-developed AI. \n\n \u25cf  Tax credits, loans, and other vehicles the US government can direct to provide \n credit enhancement. \n\n We also have proposed: \n\n A National Transmission Highway Act  , as ambitious  as the 1956 National Interstate and \n Defense Highways Act, to expand transmission, fiber connectivity, and natural gas \n pipeline construction. The process for obtaining the \u201cthree Ps\u201d\u2014planning, permitting, and \n paying for approvals from federal, state, local, and tribal authorities\u2014disadvantages \n America\u2019s AI industry. Transmission lines can take 10 years or more to complete. When \n lines are built, parties must agree on which customers pay higher electrical bills to bear \n the cost of construction. In this process, delays often affect the build-out of transmission \n lines. Streamlining these processes and eliminating redundancies would significantly \n speed up infrastructure projects, keeping America\u2019s AI sector globally competitive and \n securing a future of reliable, affordable energy. \n\n Digitizing government data currently in analog form.  A lot of government data is in the \n public domain. Making it more accessible or machine-readable could help American AI \n developers of all sizes, especially those working in fields where vital data is often \n government-held. In exchange, developers using this data could work with governments \n to unlock new insights that help it develop better public policies. For example, \n government agencies can build on the work of the US National Archives and Records \n Administration in using Optical Character Recognition for text searchability and AI-driven \n metadata tagging. \n\n A Compact for AI  among US allies and partner nations  that streamlines access to capital \n and supply chains in ways that support AI infrastruc  ture  and a robust AI ecosystem. \n Participating countries would also agree to some common standards to safeguard data \n centers and the technology. Over time, this collaboration could expand to a global \n network of US allies and partners that would compete with the  PRC\u2019s  AI infrastructure \n alliances while also strengthening security through shared standards. \n\n 12 \n\n\n\n AI Economic Zones  ,  created by local, state and the federal government together with \n industry, that speed up the permitting for building AI infrastructure like new solar arrays, \n wind farms, and nuclear reactors.  This could include  creating categorical exclusions to \n the National Environmental Policy Act, such as a national security waiver given the \n global competition for AI leadership. These zones could also build on the first Trump \n Administration\u2019s \u201cOpportunity Zones\u201d through tax incentives or credit enhancements in \n order to encourage private capital investment. \n\n A nationwide AI Readiness Strategy  \u2014rooted in local  communities in partnership with \n American companies\u2014to help our current workforce and students become AI-ready, \n bolster the economy, and secure America\u2019s continued leadership on innovation. \n Maintaining American leadership in AI means ensuring we have an experienced, trained \n professional workforce working across the AI supply chain, including construction worker \n management, HVAC technicians, and electricians. Government should ensure this \n training is accessible and affordable, such as by: \n\n \u25cf  At the federal level, expanding 529 savings plans to cover more AI supply \n chain-related training programs\u2014including for construction, HVAC technicians, \n electricians, as well as AI researchers and developers\u2014by amending Section 529 \n of the Internal Revenue Code or broadening the SECURE Act\u2019s provisions. \n\n \u25cf  At the federal or state level, incentivizing AI supply chain companies to work with \n a backbone organization to understand the workforce needs of AI supply chain \n companies, develop a pipeline of training programs that help companies meet \n those needs, and coordinate with labor unions, community colleges, and trade \n associations to build and operate that training pipeline. \n\n Creation of AI research labs and workforces aligned with key local industries  by requiring \n AI companies to provide meaningful amounts of compute to public universities to \n equitably scale the training of a homegrown AI-skilled workforce. For example, one state \n could establish a hub dedicated to applying AI in agriculture while another develops \n centers focused on integrating AI into power production and grid resilience. \n\n Using the Defense Production Act (DPA) Title I  to  manage supply chain risk by \n designating gas turbines, rankine cycle turbines, high-voltage transformers, or \n switchgear for data centers as \u201crated orders.\u201d This prioritization could significantly \n shorten timelines for data center power i  nfrastructure  projects. \n\n 13 \n\n\n\n 5. Government Adoption of AI: Leading by Example \n\n AI adoption in federal departments and agencies remains unacceptably low, with federal \n employees, and especially national security sector employees, largely unable to harness \n the benefits of the technology. \n\n The government should encourage public-private partnerships to enhance government \n AI adoption by removing known blockers to the adoption of AI tools, including outdated \n and lengthy accreditation processes, restrictive testing authorities, and inflexible \n procurement pathways. Specifically, we recommend: \n\n \u25cf  Modernizing cyber security rules for cloud-based applications.  The government\u2019s \n current processes for AI providers to comply with federal security \n regulations\u2014primarily through the Federal Risk and Authorization Management \n Program (FedRAMP)\u2014takes 12 to 18 months, compared to the one- to \n three-month commercial standard, with no clear evidence of additional protection \n for government data. The government should modernize FedRAMP by \n establishing a faster, criteria-based path for approval of AI tools. Criteria could \n include Foreign Ownership, Control, or Influence (FOCI) approval; Facilities \n Clearance (FCL) status; US incorporation; a first-party AI model that ranks in the \n top 20 of a recognized evaluation framework (for example, MMLU, or Massive \n Multitask Language Understanding); SOC 2 (System and Organization Controls 2) \n accreditation; and a recent third-party penetration test with all findings addressed. \n\n \u25cf  Accelerating AI testing and experimentation.  The government  should allow federal \n agencies to test and experiment with real data using commercial-standard \n practices\u2014such as SOC 2 or International Organization for Standardization (ISO) \n audit reports\u2014and potentially grant a temporary waiver for FedRAMP. AI vendors \n would still be required to meet FedRAMP continuous monitoring requirements \n while awaiting full accreditation. Combined with standard due diligence before \n actual use, this approach could allow agencies to access new AI services roughly \n 12 months earlier while maintaining compliance with federal security \n requirements. \n\n \u25cf  Enabling rapid procurement mechanisms.  Once new security  and testing \n approaches are in place, agencies must also have quicker, more direct routes to \n procure and deploy frontier AI tools. The government should continue to evaluate \n Other Transactional Authorities (OTAs), Commercial Service Offerings (CSO) or \n other procurement paths in order to access technology from frontier AI labs, not \n just their legacy IT providers. We are encouraged by the Department of Defense\u2019s \n recent efforts to  Modernize Software Acquisition  . \n\n 14 \n\nhttps://www.defense.gov/News/Transcripts/Transcript/Article/4113458/directing-modern-software-acquisition-to-maximize-lethality-memo-background-bri/\n\n\n Enabling federal agencies to quickly acquire consumer-focused models is not enough, \n however. The government also needs to pursue and fund bespoke national security pilot \n projects for which there may be no commercial market by: \n\n \u25cf  Partnering with industry to develop custom models for national security.  The \n government needs models trained on classified datasets that are fine-tuned to be \n exceptional at national security tasks for which there is no commercial \n market\u2014such as geospatial intelligence or classified nuclear tasks. This will likely \n require on-premises deployment of model weights and access to significant \n compute, given the security requirements of many national security agencies. \n\n \u25cf  Acting now to fund these projects and secure this compute  \u2014enabling industry \n partners to secure chips, transformers, and begin construction, and ensuring that \n this compute comes online at the pace that innovation and geopolitical \n competition require. \n\n Lastly, frontier AI labs need Facility Clearances (FCL) to work directly with the national \n security enterprise on these pilot projects and custom models. The government should: \n\n \u25cf  Expedite FCL for frontier AI labs committed to supporting national security.  The \n process for obtaining a FCL can take a year or longer. Given the rapid pace of AI \n development, the government should start prioritizing deeper collaboration with \n frontier AI labs as soon as possible. \n\n We look forward to discussing the above proposals with the Office of Science and \n Technology Policy as we continue to build on our relationship with the US government \n and work toward AI that benefits everyone. \n\n About OpenAI \n OpenAI\u2019s mission is to ensure that as AI advances, it benefits everyone. We're building AI to help \n people solve hard problems because by helping with the hard problems, AI can benefit the most \n people possible\u2014through more scientific discoveries, better healthcare and education, and \n improved productivity. We\u2019re off to a strong start, creating freely available intelligence being used \n by more than 400 million people around the world, including 3 million developers. We believe AI \n will scale human ingenuity and drive unprecedented economic growth and new freedoms that \n help people accomplish what we can't even imagine today. \n\n 15 \n\n\n","extra":{"cited_message_idx":6,"search_result_idx":null,"evidence_text":"source","cloud_doc_url":null}}}],"content_references":[{"matched_text":"\u30106\u2020source\u3011","start_idx":1734,"end_idx":1744,"alt":null,"type":"file","name":"openai-response-ostp-nsf-rfi-notice-request-for-information-on-the-development-of-an-artificial-intelligence-ai-action-plan.pdf","id":"file-5eiqpyd6a14ZasQ6c6cULw","source":"my_files","snippet":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[OpenAI Response] OSTP/NSF RFI: Notice Request for Information on the Development of an Artificial Intelligence (AI) Action Plan - Google Docs\n\n\n March 13, 2025 \n\n To: Faisal D'Souza, NCO  From: Christopher Lehane \n Office of Science and Technology Policy  OpenAI \n 2415 Eisenhower Avenue  1455 3rd Street \n Alexandria, VA 22314  San Francisco, CA 94158 \n\n This document is approved for public dissemination. The document contains no business-proprietary or confidential \n information. Document contents may be reused by the government in developing the AI Action Plan and associated \n documents without attribution. \n\n \u201cIt is the policy of the United States to sustain and enhance America\u2019s global dominance in \n order to promote human flourishing, economic competitiveness, and national security\u201d \n\n \u2013 President Donald J. Trump, Executive Order 14179, January 23, 2025 \n\n OpenAI respectfully submits the enclosed proposals to the Office of Science and \n Technology Policy as it weighs a new AI Action Plan that will, as Vice President Vance \n stated recently at the Paris AI Action Summit, maintain American leadership in AI and \n \u201cmake people more productive, more prosperous, and more free.\u201d As America\u2019s \n world-leading AI sector approaches artificial general intelligence (AGI), with a Chinese \n Communist Party (CCP) determined to overtake us by 2030, the Trump Administration\u2019s \n new AI Action Plan can ensure that American-led AI built on democratic principles \n continues to prevail over CCP-built autocratic, authoritarian AI. \n\n OpenAI agrees with the Trump Administration that AI creates prosperity and freedom worth \n fighting for\u2014especially for younger generations whose future will be shaped by how this \n Administration approaches AI. Globally, most ChatGPT users are under age 35; in the US, \n about one third are ages 18 to 24.  1  Both young people and their parents recognize the \n economic opportunities AI presents: \n\n \u25cf  More than seven in 10 parents in the US believe children today will be worse off \n financially than they are.  2 \n\n \u25cf  Nine in 10 US parents think it's important that their kids learn how to use artificial \n intelligence for their future jobs\u2014and eight in 10 say either that isn\u2019t happening \n today, or they don\u2019t know if it is.  3 \n\n \u25cf  Three in four college-age AI users want to use AI in their education and careers. \n Many are teaching themselves and their friends about AI without waiting for their \n schools to provide formal AI education.  4 \n\n 4  OpenAI:  Building an AI-Ready Workforce: A Look at  ChatGPT Adoption in the US  , Feb. 2025 \n\n 3  Morning Consult survey commissioned by Samsung:  88%  of US Parents of Gen Alpha & Gen Z Students Say AI \n Will Be Crucial to Their Child\u2019s Future Success  , Sept.  2024 \n\n 2  Pew Research Center:  Views of children\u2019s financial  future  , Jan. 2025 \n 1  Self-reported among logged-in users \n\n 1 \n\nhttps://cdn.openai.com/global-affairs/openai-edu-ai-ready-workforce.pdf\nhttps://news.samsung.com/us/88-percent-us-parents-gen-alpha-gen-z-students-say-ai-crucial-to-childs-future-success-samsung-solve-for-tomorrow/\nhttps://news.samsung.com/us/88-percent-us-parents-gen-alpha-gen-z-students-say-ai-crucial-to-childs-future-success-samsung-solve-for-tomorrow/\nhttps://www.pewresearch.org/global/2025/01/09/views-of-childrens-financial-future/\n\n\n In particular, AI could drive significant increased productivity over the next decade. Here\u2019s \n how we can realize this heightened prosperity and greater freedom together. \n\n Scaling human ingenuity \n Innovation creates and scales our ability to push beyond our current limits. From foot travel \n to the domesticated horse, the wheel, steam power, the car, the plane\u2014we scaled the \n freedom of mobility. From daylight to candle and lamplight, to electricity providing light and \n power at all hours\u2014we scaled the freedom to produce, think and create. From word of \n mouth to the stylus and tablet, to the printing press, telegraph, phone, computer, \n smartphone\u2014we scaled freedom of learning and knowledge. Now, as we approach AGI, \n innovation is poised to scale human ingenuity itself\u2014the sum of our freedoms to learn and \n know, think, create and produce. \n\n As our CEO Sam Altman  has written  , we are at the doorstep  of the next leap in prosperity: \n the Intelligence Age. But we must ensure that people have  freedom of intelligence  , by \n which we mean the freedom to access and benefit from AGI, protected from both autocratic \n powers that would take people\u2019s freedoms away, and layers of laws and bureaucracy that \n would prevent our realizing them. \n\n More than 400 million people around the world are using ChatGPT to ideate, discover, and \n break through beyond what we\u2019re currently capable of doing on our own. Just two weeks \n ago, we partnered with the Department of Energy\u2019s national labs to  bring together  1,500 \n scientists to use our tools to take scientific discovery farther, faster. \n\n Our work at OpenAI also suggests that as AI advances, progress accelerates and becomes \n increasingly affordable, as reflected in these three scaling principles: \n\n 1.  The intelligence of an AI model roughly equals  the log of the resources used to train and \n run it.  Until recently, scaling progress has primarily  come from training compute and data, \n but we have shown how to make intelligence scale from inference compute, as well. The \n scaling laws that predict these gains are incredibly precise over many orders of magnitude, \n so investing more in AI will continue to make it better and more capable.  We believe that \n the socioeconomic value of linearly increasing intelligence is super-exponential in nature. \n\n 2.  The cost to use a given level of AI capability  falls by about 10x every 12 months, and \n lower prices lead to much more use.  We saw this in  the change in token cost between \n GPT-4 in early 2023 and GPT-4o in mid-2024, where the price per token dropped about \n 150x in that time period.  Moore\u2019s Law predicted that  the number of transistors on a \n microchip would double roughly every two years; the decrease in the cost of using AI is \n even more dramatic. \n\n 2 \n\nhttps://ia.samaltman.com/\nhttps://cdn.openai.com/global-affairs/openai-usnl-scientist-ai-jam-session.pdf\n\n\n 3.  The amount of calendar time it takes to improve  an AI model keeps decreasing  . AI \n models are catching up with human intelligence at an increasing rate. The typical time it \n takes for a computer to beat humans at a given benchmark has fallen from 20 years after \n the benchmark was introduced, to five years, and now to one to two years  \u2014and we see no \n reason why those advancements will stop in the near future. \n\n By scaling human ingenuity ever faster and more affordably, AGI will create a flywheel of \n more freedom leading to more productivity, prosperity, and yet more innovation\u2014letting us \n once again focus on positive-sum growth. \n\n Advancing democratic AI \n OpenAI believes the best future is one in which we move forward with democratic AI\u2014AI \n that is shaped by the democratic principles America has always stood for. As OpenAI \n recently laid out in our  Economic Blueprint  , we believe  these principles include: \n\n \u25cf  A free market  promoting free and fair competition  that drives innovation. \n \u25cf  Freedom for developers and users  to work with and  direct our tools as they see fit, \n\n in exchange for following clear, common-sense technical standards that help keep \n AI safe for everyone, and being held accountable when they don\u2019t. \n\n \u25cf  Preventing government use of AI tools to amass power and control their citizens  , \n or to threaten or coerce other states. \n\n In advancing democratic AI, America is competing with a CCP determined to become the \n global leader by 2030. That\u2019s why the recent release of DeepSeek\u2019s R1 model is so \n noteworthy\u2014not because of its capabilities (R1\u2019s reasoning capabilities, albeit impressive, \n are at best on par with several US models), but as a gauge of the state of this competition. \n\n As with Huawei, there is significant risk in building on top of DeepSeek models in critical \n infrastructure and other high-risk use cases given the potential that DeepSeek could be \n compelled by the CCP to manipulate its models to cause harm. And because DeepSeek is \n simultaneously state-subsidized, state-controlled, and freely available, the cost to its users \n is their  privacy and security  , as DeepSeek faces requirements  under Chinese law to \n comply with demands for user data and uses it to train more capable systems for the CCP\u2019s \n use. Their models also more willingly generate how-to\u2019s for illicit and harmful activities such \n as identity fraud and intellectual property theft, a reflection of how the CCP views violations \n of American IP rights as a feature, not a flaw. \n\n 3 \n\nhttps://cdn.openai.com/global-affairs/openai-us-economicblueprint-feb-2025-edu-update.pdf\nhttps://blogs.cisco.com/security/evaluating-security-risk-in-deepseek-and-other-frontier-reasoning-models\n\n\n Today, CCP-controlled China has a number of strategic advantages, including: \n \u25cf  As an authoritarian state, its ability to quickly marshal resources  \u2014data, energy, \n\n technical talent, and the enormous sums needed to build out its own domestic chip \n development capacity. \n\n \u25cf  Its preexisting Belt and Road initiative.  As with  Huawei, the PRC will scale the \n adoption of PRC-based AI systems like DeepSeek\u2019s by coercing countries needing \n AI tools and nation-building infrastructure funds. \n\n \u25cf  Its ability to benefit from regulatory arbitrage being created by individual American \n states  seeking to pass their own industry-wide laws,  some of which are modeled \n on the European Union\u2019s regulation of AI. These laws are easier to enforce with \n domestic AI companies than PRC-based companies and could impose \n burdensome compliance requirements that may hinder our economic \n competitiveness and undermine our national security. They also may weaken the \n quality and level of training data available to American entrepreneurs and the \n usefulness for downstream consumers and businesses. \n\n \u25cf  Its ability to benefit from copyright arbitrage being created by democratic nations \n that do not clearly protect AI training by statute, like the US, or that reduce the \n amount of training data through an opt-out regime for copyright holders, like the \n EU. The PRC is unlikely to respect the IP regimes of any of such nations for the \n training of its AI systems, but already likely has access to all the same data, putting \n American AI labs at a comparative disadvantage while gaining little in the way of \n protections for the original IP creators. \n\n While America maintains a lead on AI today, DeepSeek shows that our lead is not wide and \n is narrowing. The AI Action Plan should ensure that American-led AI prevails over CCP-led \n AI, securing both American leadership on AI and a brighter future for all Americans. \n\n What we propose \n OpenAI\u2019s freedom-focused policy proposals, taken together, can strengthen America\u2019s lead \n on AI and in so doing, unlock economic growth, lock in American competitiveness, and \n protect our national security. Specifically, we detail: \n\n A regulatory strategy that ensures the freedom to innovate:  For innovation to truly create \n new freedoms, America\u2019s builders, developers, and entrepreneurs\u2014our nation\u2019s greatest \n competitive advantage\u2014must first have the freedom to innovate in the national interest. We \n propose a holistic approach that enables voluntary partnership between the federal \n government and the private sector, and neutralizes potential PRC benefit from American AI \n companies having to comply with overly burdensome state laws. \n\n 4 \n\n\n\n An export control strategy that exports democratic AI:  For countries seeking access to \n American AI, we propose a strategy that  would apply a commercial growth lens\u2014both Total \n and Serviceable Addressable Markets\u2014to proactively promote the global adoption of \n American AI systems and with them, the freedoms they create. At the same time, the \n strategy would use export controls to protect America\u2019s AI lead, including by making \n updates to the AI diffusion rule. \n\n A copyright strategy that promotes the freedom to learn:  America\u2019s robust, balanced \n intellectual property system has long been key to our global leadership on innovation. We \n propose a copyright strategy that would extend the system\u2019s role into the Intelligence Age \n by protecting the rights and interests of content creators while also protecting America\u2019s AI \n leadership and national security. The federal government can both secure Americans\u2019 \n freedom to learn from AI, and avoid forfeiting our AI lead to the PRC by preserving \n American AI models\u2019 ability to learn from copyrighted material. \n\n A strategy to seize the infrastructure opportunity to drive growth:  Sustaining America\u2019s lead \n on AI means building the necessary infrastructure to compete with the PRC and its \n commandeered resources. We propose policies to seize this unmissable opportunity to \n catalyze a reindustrialization across our country, creating and supporting hundreds of \n thousands of jobs, boosting local economies, modernizing our energy grid, and preparing \n an AI-ready workforce  \u2014t  he key pillar of any country\u2019s  AI infrastructure. \n\n An ambitious government adoption strategy:  Advancing  democratic AI around the world \n starts with ensuring that the US government itself sets an example of governments using AI \n to keep their people safe, prosperous, and free. With the PRC progressing toward \n ambitious targets for AI adoption across its public administration, security, and military, the \n US government should modernize its processes to safely deploy frontier AI tools at the \n pace of the private sector and with the efficiency Americans deserve. \n\n America always succeeds when it bets on American ingenuity. The enclosed policy \n proposals are either derived from, or in the case of copyright represent updates to  OpenAI's \n Economic Blueprint  , and we look forward to discussing  them with you. \n\n Chris Lehane \n Vice President, Global Affairs \n\n 5 \n\nhttps://cdn.openai.com/global-affairs/openai-us-economicblueprint-feb-2025-edu-update.pdf\nhttps://cdn.openai.com/global-affairs/openai-us-economicblueprint-feb-2025-edu-update.pdf\n\n\n 1. Preemption: Ensuring the Freedom to Innovate \n\n We propose creating a tightly-scoped framework for voluntary partnership between the \n federal government and the private sector to protect and strengthen American national \n security. This framework would extend the tradition of government receiving learnings \n and access, where appropriate, in exchange for providing the private sector relief from \n the  781 and counting proposed AI-related bills  already  introduced this year in US states. \n This patchwork of regulations risks bogging down innovation and, in the case of AI, \n undermining America\u2019s leadership position. \n\n Overseen by the US Department of Commerce and in coordination with the AI Czar, \n perhaps by reimagining the US AI Safety Institute, this effort would provide domestic AI \n companies with a single, efficient \u201cfront door\u201d to the federal government that would \n coordinate expertise across the entire national security and economic competitiveness \n communities.  5 \n\n This targeted framework would empower the federal government to: \n \u25cf  Work with both large AI companies and start-ups on a purely voluntary and \n\n optional basis to stay informed about AI risks as well as cutting-edge capabilities \n that support US national interests  ,  including by establishing  sandbox and testing \n capabilities on the secure premises of federal agencies. \n\n \u25cf  Evaluate the state of American AI technology against the technology of \n competitors and adversaries, including evaluating foreign models for the potential \n for back doors or malign influence. \n\n \u25cf  Coordinate the development of technical standards for evaluating and \n safeguarding frontier models from national security risks. \n\n \u25cf  Provide American AI companies with the tools and classified threat intelligence to \n mitigate national security risks that are exacerbated by frontier models (e.g., \n cyber, CBRN) and posed by nation-state actors (e.g., economic espionage by \n China). \n\n \u25cf  Incentivize companies to take part in this voluntary initiative by creating glide \n paths for them to contract with the government, including on national security \n projects; creating strong protections for any company information shared during \n these partnerships; and reducing barriers to companies' internal work related to \n national security domains. \n\n \u25cf  Guarantee that state-based legislation does not undermine America\u2019s innovation \n lead on AI. Create a sandbox for American start-ups, and provide participating \n companies with liability protections including preemption from state-based \n\n 5  Federal preemption over existing or prospective state  laws will require an act of Congress. \n\n 6 \n\nhttps://techcrunch.com/2025/03/07/us-lawmakers-have-already-introduce-hundreds-of-ai-bills-in-2025/\n\n\n regulations that focus on frontier model security (e.g., CA SB 1047). This will help \n keep the US public and private sectors competitive by allowing AI companies of \n all sizes to pursue bleeding-edge AI technology free from the regulatory \n uncertainty created by some state-based liability regimes. \n\n 2. Export Controls: Exporting Democratic AI \n\n A comprehensive export control strategy should do more than restrict the flow of AI \n technologies to the PRC\u2014it should ensure that America is \u201cwinning diffusion\u201d, i.e., that \n as much of the world as possible is aligned to democratic values and building on \n democratic infrastructure. To that end, we propose that the US government consider the \n Total Addressable Market (TAM), i.e., the entire world less the PRC and its few allies, \n against the Serviceable Addressable Market (SAM), i.e., those countries who prefer to \n build AI on democratic rails, and help as many of the latter as possible commit, including \n by actually committing to deploy AI in line with democratic principles set out by the US \n government. \n\n In particular, we propose maintaining the AI diffusion rule\u2019s three-tiered framework to \n differentiate among countries in the global AI market, but with some key modifications \n that expand the number of countries in Tier I: \n\n Tier I:  Countries that commit to democratic AI principles  by deploying AI systems in ways \n that promote more freedoms for their citizens could be considered Tier I countries. \n\n Tier II:  Limited to only those countries that have  a history of failing to prevent \n export-controlled chips and other US-developed IP from being diverted into, or used by \n Tier III countries. These countries would be encouraged and supported to obtain Tier I \n status over time; and would be subject to more stringent security requirements in the \n interim. \n\n Tier III:  CCP-led China, along with a small cohort  of countries aligned with the CCP, \n would represent its own category that is prohibited from accessing democratic AI \n systems. \n\n This strategy would encourage global adoption of democratic AI principles, promoting the \n use of democratic AI systems while protecting US advantage. Making sure that \n open-sourced models are readily available to developers in these countries also will \n strengthen our advantage.  We believe the question  of whether AI should be open or \n\n 7 \n\n\n\n closed source is a false choice\u2014we need both, and they can work in a complementary \n way that encourages the building of AI on American rails. \n\n Tier I countries  should include American allies, as  well as those countries that are \n committed to democratic AI principles and that present a relatively low risk that American \n AI infrastructure (e.g., chips) will be diverted to non-Tier I countries. The commercial \n diplomacy strategy in Tier I should recognize these countries\u2019 strong history of export \n and customs control compliance and seek to maximally expand democratic AI systems\u2019 \n market share, while at the same time protecting those systems from IP theft by the PRC \n and other malign actors (e.g., the theft of model weights and/or chip designs, \n unauthorized influence or access to data center operations). \n\n To expand market share in Tier I countries, American commercial diplomacy policy \n should: \n\n \u25cf  Encourage cross-border capital flows and promote software frameworks that are \n optimized for domestic chip design. \n\n \u25cf  Coordinate global bans on CCP-aligned AI infrastructure, including Huawei chips. \n \u25cf  Continue to represent American company interests in safety and security \n\n standards bodies, and encourage global regulators to adopt pro-growth safety and \n security policies. \n\n \u25cf  Revise the existing export control rules to eliminate country caps on compute. \n \u25cf  Maintain existing export license exceptions (e.g., license exception ACM) that \n\n enable exports of technology and software for technical collaboration with allies \n and preservation of economically critical supply chains \n\n To protect the US-developed IP needed to operate data centers in Tier I countries, \n security requirements could include: \n\n \u25cf  Prohibiting relationships with Tier III countries\u2019 foreign military and intelligence \n services, and the use of data centers to support military/intelligence missions for \n Tier III nations or human rights violators. \n\n \u25cf  Banning the use of PRC-produced equipment (e.g., Huawei Ascend chips) and \n models that violate user privacy and create security risks such as the risk of IP \n theft. \n\n \u25cf  Maintaining corporate control by entities headquartered in Tier I countries. \n \u25cf  Implementing\u2014and constantly modernizing\u2014cybersecurity, model weight security, \n\n and personnel security controls that ideally are globally synced and coordinated \n among Tier I governments. \n\n 8 \n\n\n\n Controls on model weights\u2014if any\u2014should strike a balance between protecting \n American-developed IP and promoting the deployment of American-developed models \n over those developed by Tier III countries, including the PRC. \n\n Tier II  countries  should include those with a history  of failing to prevent \n export-controlled chips and other US-developed IP from being diverted into, or used by \n Tier III co  untries. Here, the commercial diplomacy  strategy should still seek to expand \n US market share, but should do so more carefully, including by levying stronger controls \n on the export of US-developed AI infrastructure. At the same time, the strategy should \n provide transparent pathways for Tier II countries to reach Tier I status by adopting \n democratic AI principles and more effectively managing risks of chip diversion. \n\n To expand American market share in Tier II countries, in addition to the steps above, the \n commercial diplomacy policy could be designed to leverage commercial interest in \n American-led AI in order to encourage investment in the US, enhanced security \n procedures, and encourage more countries to build on American rails: \n\n \u25cf  Establish a transparent process to evaluate countries\u2019 readiness to transition from \n Tier II to Tier I. \n\n \u25cf  Support countries\u2019 transition from Tier II to Tier I by helping Tier II governments \n strengthen their in-country security programs. \n\n \u25cf  Encourage greater economic interdependence between the US and Tier II \n countries. \n\n \u25cf  Incentivize public-private partnerships to rapidly mature, scale, and commercialize \n hardware-enabled mechanisms that could enhance in-country security controls in \n the future. \n\n To protect the American-developed IP needed to operate data centers in Tier II countries, \n and to manage both the heightened risk of IP theft and the additional risk that \n export-controlled chips might be diverted from Tier II into Tier III countries, the \n commercial diplomacy policy also could: \n\n \u25cf  Allow the export of advanced AI chips to an end-user located in a Tier II country \n that meets Tier I security requirements, and that puts in place additional corporate \n governance controls as well as technology-enhanced protections (e.g., \n hardware-enabled mechanisms) against the diversion of export-controlled chips. \n\n Tier III countries  \u2014including the PRC and any other  country subject to a US arms \n embargo\u2014s  hould continue to be subject to strict export  controls of AI systems, including \n existing export controls on advanced chips. The strategy could also expand established \n controls, for example, to include advanced chips that are required for large-scale \n\n 9 \n\n\n\n inference and RL training and the components used to manufacture advanced AI chips \n and data centers. \n\n 3. Copyright: Promoting the Freedom to Learn \n\n American copyright law, including the longstanding fair use doctrine, protects the \n transformative uses of existing works, ensuring that innovators have a balanced and \n predictable framework for experimentation and entrepreneurship. This approach has \n underpinned American success through earlier phases of technological progress and is \n even more critical to continued American leadership on AI in the wake of recent events in \n the PRC. OpenAI\u2019s models are trained to not replicate works for consumption by the \n public. Instead, they learn from the works and extract patterns, linguistic structures, and \n contextual insights. This means our AI model training aligns with the core objectives of \n copyright and the fair use doctrine, using existing works to create something wholly new \n and different without eroding the commercial value of those existing works. \n\n America has so many AI startups, attracts so much investment, and has made so many \n research breakthroughs largely because the fair use doctrine promotes AI development. \n In other markets, rigid copyright rules are repressing innovation and investment. \n\n The European Union, for one, has created \u201ctext and data mining exceptions\u201d with broadly \n applicable \u201copt-outs\u201d for any rights holder\u2014meaning access to important AI inputs is less \n predictable and likely to become more difficult as the EU\u2019s regulations take shape. \n Unpredictable availability of inputs hinders AI innovation, particularly for smaller, newer \n entrants with limited budgets. \n\n The UK government is currently considering changes to its copyright regime. It has \n indicated that it prefers creating a data mining exception that allows rights holders to \n \u201creserve their rights,\u201d creating the same regulatory barriers to AI development that we \n see in the EU. \n\n Applying the fair use doctrine to AI is not only a matter of American competitiveness \n \u2014it\u2019s a matter of national security. The rapid advances seen with the PRC\u2019s DeepSeek, \n among other recent developments, show that America\u2019s lead on frontier AI is far from \n guaranteed. Given concerted state support for critical industries and infrastructure \n projects, there\u2019s little doubt that the PRC\u2019s AI developers will enjoy unfettered access to \n data\u2014including copyrighted data\u2014that will improve their models.  If the PRC\u2019s \n developers have unfettered access to data and American companies are left without fair \n use access, the race for AI is effectively over. America loses, as does the success of \n\n 10 \n\n\n\n democratic AI  .  Ultimately, access to more data from the widest possible range of sources \n will ensure more access to more powerful innovations that deliver even more knowledge. \n\n We propose that the US government take steps to ensure that our copyright system \n continues to support American AI leadership and American economic and national \n security, including by: \n\n \u25cf  Shaping international policy discussions around copyright and AI, and working to \n prevent less innovative countries from imposing their legal regimes on American \n AI firms and slowing our rate of progress. \n\n \u25cf  Actively assessing the overall level of data available to American AI firms and \n determining whether other countries are restricting American companies\u2019 access \n to data and other critical inputs. \n\n \u25cf  Encouraging more access to government-held or government-supported data. \n This would boost AI development in any case, but would be particularly important \n if shifting copyright rules restrict American companies\u2019 access to training data. \n\n \u25cf  Monitoring domestic policy debates and ongoing litigation, and weighing in where \n fundamental, pro-innovation principles are at risk. \n\n Generative AI models represent the next frontier of innovation, poised to revolutionize \n the private and public sectors, improving healthcare, education, scientific research, and \n so much more. If AI innovation remains protected under longstanding copyright \n principles, America will maintain and strengthen its role as the world leader in \n cutting-edge technologies and remain positioned to continue championing AI based on \n democratic principles with countries around the world. \n\n 4. Infrastructure: Seizing the Opportunity to Drive Growth \n\n Today, hundreds of billions of dollars in global funds are waiting to be invested in AI \n infrastructure. If the US doesn't move fast to channel these resources into projects that \n support democratic AI ecosystems around the world, the funds will flow to projects \n backed and shaped by the CCP. \n\n We propose a foundational strategy to ensure that investment in infrastructure drives \n economic growth that benefits all Americans; maximizes access to AI; and protects \n national security interests by keeping sensitive American data on American soil. This \n includes policies and initiatives that encourage rather than stifle developers; support  a \n thriving AI-ready workforce and  ecosystems of labs,  start-ups and larger companies; and \n secure America\u2019s leadership on AI into the future. \n\n 11 \n\n\n\n First and foremost, building data centers is capital-intensive, particularly for newcomers \n seeking to compete against established hyperscalers with vast resources.  W  e support \n the solutions already proposed by this Administration  to ensure that sufficient capital \n flows to building AI infrastructure in the US: \n\n \u25cf  Investment vehicles like a Sovereign Wealth Fund  . \n \u25cf  Government offtake and guarantees tha  t both provide  the government with the \n\n compute it needs and signal to markets that the demand will be there for \n American-developed AI. \n\n \u25cf  Tax credits, loans, and other vehicles the US government can direct to provide \n credit enhancement. \n\n We also have proposed: \n\n A National Transmission Highway Act  , as ambitious  as the 1956 National Interstate and \n Defense Highways Act, to expand transmission, fiber connectivity, and natural gas \n pipeline construction. The process for obtaining the \u201cthree Ps\u201d\u2014planning, permitting, and \n paying for approvals from federal, state, local, and tribal authorities\u2014disadvantages \n America\u2019s AI industry. Transmission lines can take 10 years or more to complete. When \n lines are built, parties must agree on which customers pay higher electrical bills to bear \n the cost of construction. In this process, delays often affect the build-out of transmission \n lines. Streamlining these processes and eliminating redundancies would significantly \n speed up infrastructure projects, keeping America\u2019s AI sector globally competitive and \n securing a future of reliable, affordable energy. \n\n Digitizing government data currently in analog form.  A lot of government data is in the \n public domain. Making it more accessible or machine-readable could help American AI \n developers of all sizes, especially those working in fields where vital data is often \n government-held. In exchange, developers using this data could work with governments \n to unlock new insights that help it develop better public policies. For example, \n government agencies can build on the work of the US National Archives and Records \n Administration in using Optical Character Recognition for text searchability and AI-driven \n metadata tagging. \n\n A Compact for AI  among US allies and partner nations  that streamlines access to capital \n and supply chains in ways that support AI infrastruc  ture  and a robust AI ecosystem. \n Participating countries would also agree to some common standards to safeguard data \n centers and the technology. Over time, this collaboration could expand to a global \n network of US allies and partners that would compete with the  PRC\u2019s  AI infrastructure \n alliances while also strengthening security through shared standards. \n\n 12 \n\n\n\n AI Economic Zones  ,  created by local, state and the federal government together with \n industry, that speed up the permitting for building AI infrastructure like new solar arrays, \n wind farms, and nuclear reactors.  This could include  creating categorical exclusions to \n the National Environmental Policy Act, such as a national security waiver given the \n global competition for AI leadership. These zones could also build on the first Trump \n Administration\u2019s \u201cOpportunity Zones\u201d through tax incentives or credit enhancements in \n order to encourage private capital investment. \n\n A nationwide AI Readiness Strategy  \u2014rooted in local  communities in partnership with \n American companies\u2014to help our current workforce and students become AI-ready, \n bolster the economy, and secure America\u2019s continued leadership on innovation. \n Maintaining American leadership in AI means ensuring we have an experienced, trained \n professional workforce working across the AI supply chain, including construction worker \n management, HVAC technicians, and electricians. Government should ensure this \n training is accessible and affordable, such as by: \n\n \u25cf  At the federal level, expanding 529 savings plans to cover more AI supply \n chain-related training programs\u2014including for construction, HVAC technicians, \n electricians, as well as AI researchers and developers\u2014by amending Section 529 \n of the Internal Revenue Code or broadening the SECURE Act\u2019s provisions. \n\n \u25cf  At the federal or state level, incentivizing AI supply chain companies to work with \n a backbone organization to understand the workforce needs of AI supply chain \n companies, develop a pipeline of training programs that help companies meet \n those needs, and coordinate with labor unions, community colleges, and trade \n associations to build and operate that training pipeline. \n\n Creation of AI research labs and workforces aligned with key local industries  by requiring \n AI companies to provide meaningful amounts of compute to public universities to \n equitably scale the training of a homegrown AI-skilled workforce. For example, one state \n could establish a hub dedicated to applying AI in agriculture while another develops \n centers focused on integrating AI into power production and grid resilience. \n\n Using the Defense Production Act (DPA) Title I  to  manage supply chain risk by \n designating gas turbines, rankine cycle turbines, high-voltage transformers, or \n switchgear for data centers as \u201crated orders.\u201d This prioritization could significantly \n shorten timelines for data center power i  nfrastructure  projects. \n\n 13 \n\n\n\n 5. Government Adoption of AI: Leading by Example \n\n AI adoption in federal departments and agencies remains unacceptably low, with federal \n employees, and especially national security sector employees, largely unable to harness \n the benefits of the technology. \n\n The government should encourage public-private partnerships to enhance government \n AI adoption by removing known blockers to the adoption of AI tools, including outdated \n and lengthy accreditation processes, restrictive testing authorities, and inflexible \n procurement pathways. Specifically, we recommend: \n\n \u25cf  Modernizing cyber security rules for cloud-based applications.  The government\u2019s \n current processes for AI providers to comply with federal security \n regulations\u2014primarily through the Federal Risk and Authorization Management \n Program (FedRAMP)\u2014takes 12 to 18 months, compared to the one- to \n three-month commercial standard, with no clear evidence of additional protection \n for government data. The government should modernize FedRAMP by \n establishing a faster, criteria-based path for approval of AI tools. Criteria could \n include Foreign Ownership, Control, or Influence (FOCI) approval; Facilities \n Clearance (FCL) status; US incorporation; a first-party AI model that ranks in the \n top 20 of a recognized evaluation framework (for example, MMLU, or Massive \n Multitask Language Understanding); SOC 2 (System and Organization Controls 2) \n accreditation; and a recent third-party penetration test with all findings addressed. \n\n \u25cf  Accelerating AI testing and experimentation.  The government  should allow federal \n agencies to test and experiment with real data using commercial-standard \n practices\u2014such as SOC 2 or International Organization for Standardization (ISO) \n audit reports\u2014and potentially grant a temporary waiver for FedRAMP. AI vendors \n would still be required to meet FedRAMP continuous monitoring requirements \n while awaiting full accreditation. Combined with standard due diligence before \n actual use, this approach could allow agencies to access new AI services roughly \n 12 months earlier while maintaining compliance with federal security \n requirements. \n\n \u25cf  Enabling rapid procurement mechanisms.  Once new security  and testing \n approaches are in place, agencies must also have quicker, more direct routes to \n procure and deploy frontier AI tools. The government should continue to evaluate \n Other Transactional Authorities (OTAs), Commercial Service Offerings (CSO) or \n other procurement paths in order to access technology from frontier AI labs, not \n just their legacy IT providers. We are encouraged by the Department of Defense\u2019s \n recent efforts to  Modernize Software Acquisition  . \n\n 14 \n\nhttps://www.defense.gov/News/Transcripts/Transcript/Article/4113458/directing-modern-software-acquisition-to-maximize-lethality-memo-background-bri/\n\n\n Enabling federal agencies to quickly acquire consumer-focused models is not enough, \n however. The government also needs to pursue and fund bespoke national security pilot \n projects for which there may be no commercial market by: \n\n \u25cf  Partnering with industry to develop custom models for national security.  The \n government needs models trained on classified datasets that are fine-tuned to be \n exceptional at national security tasks for which there is no commercial \n market\u2014such as geospatial intelligence or classified nuclear tasks. This will likely \n require on-premises deployment of model weights and access to significant \n compute, given the security requirements of many national security agencies. \n\n \u25cf  Acting now to fund these projects and secure this compute  \u2014enabling industry \n partners to secure chips, transformers, and begin construction, and ensuring that \n this compute comes online at the pace that innovation and geopolitical \n competition require. \n\n Lastly, frontier AI labs need Facility Clearances (FCL) to work directly with the national \n security enterprise on these pilot projects and custom models. The government should: \n\n \u25cf  Expedite FCL for frontier AI labs committed to supporting national security.  The \n process for obtaining a FCL can take a year or longer. Given the rapid pace of AI \n development, the government should start prioritizing deeper collaboration with \n frontier AI labs as soon as possible. \n\n We look forward to discussing the above proposals with the Office of Science and \n Technology Policy as we continue to build on our relationship with the US government \n and work toward AI that benefits everyone. \n\n About OpenAI \n OpenAI\u2019s mission is to ensure that as AI advances, it benefits everyone. We're building AI to help \n people solve hard problems because by helping with the hard problems, AI can benefit the most \n people possible\u2014through more scientific discoveries, better healthcare and education, and \n improved productivity. We\u2019re off to a strong start, creating freely available intelligence being used \n by more than 400 million people around the world, including 3 million developers. We believe AI \n will scale human ingenuity and drive unprecedented economic growth and new freedoms that \n help people accomplish what we can't even imagine today. \n\n 15 \n\n\n","cloud_doc_url":null}],"message_type":null,"model_slug":"gpt-4-5","default_model_slug":"gpt-4-5","parent_id":"46f0d89b-60a6-42d5-9256-37fae81a9244","request_id":"921482a7d88a9e46-SIN","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"46f0d89b-60a6-42d5-9256-37fae81a9244","children":["5aa674a5-49fa-4180-b1df-4d977c6e941e"]},"5aa674a5-49fa-4180-b1df-4d977c6e941e":{"id":"5aa674a5-49fa-4180-b1df-4d977c6e941e","message":{"id":"5aa674a5-49fa-4180-b1df-4d977c6e941e","author":{"role":"user","name":null,"metadata":{}},"create_time":1742130911.299,"update_time":null,"content":{"content_type":"text","parts":["Are there calls for a restriction on *using* Chinese AI?"]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"serialization_metadata":{"custom_symbol_offsets":[]},"dictation":false,"request_id":"92148491eb229e46-SIN","message_source":null,"timestamp_":"absolute","message_type":null,"can_save":true},"recipient":"all","channel":null},"parent":"7753eb32-1851-48fd-90b9-1f512119af61","children":["2c4d89f3-4a2a-464b-9ef8-46a1539b02c1"]},"2c4d89f3-4a2a-464b-9ef8-46a1539b02c1":{"id":"2c4d89f3-4a2a-464b-9ef8-46a1539b02c1","message":{"id":"2c4d89f3-4a2a-464b-9ef8-46a1539b02c1","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1742130911.48858,"update_time":null,"content":{"content_type":"text","parts":["Yes, OpenAI explicitly recommends restrictions on using Chinese-controlled AI technology due to significant security and privacy concerns. Specifically, they propose:\n\n- **Banning PRC-produced equipment** (e.g., Huawei Ascend chips) and AI models that violate user privacy, create security risks, or pose threats such as intellectual property theft.\n- Prohibiting relationships involving AI infrastructure with military or intelligence services in Tier III countries, including China, particularly to prevent American AI infrastructure from supporting adversarial military or intelligence missions or facilitating human rights abuses.\n\nThese recommendations clearly imply restrictions, including bans, on the use and integration of Chinese-controlled AI systems in sensitive or critical areas, driven primarily by concerns about national security, data privacy, IP protection, and potential malign influence by the CCP\u30106\u2020source\u3011.\n\nThus, OpenAI's stance explicitly endorses significant restrictions on Chinese-controlled AI infrastructure and models to protect U.S. interests, national security, and democratic values."]},"status":"finished_successfully","end_turn":true,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200002]},"is_complete":true,"citations":[{"start_ix":918,"end_ix":928,"citation_format_type":"tether_og","metadata":{"type":"file","name":"openai-response-ostp-nsf-rfi-notice-request-for-information-on-the-development-of-an-artificial-intelligence-ai-action-plan.pdf","id":"file-5eiqpyd6a14ZasQ6c6cULw","source":"my_files","text":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[OpenAI Response] OSTP/NSF RFI: Notice Request for Information on the Development of an Artificial Intelligence (AI) Action Plan - Google Docs\n\n\n March 13, 2025 \n\n To: Faisal D'Souza, NCO  From: Christopher Lehane \n Office of Science and Technology Policy  OpenAI \n 2415 Eisenhower Avenue  1455 3rd Street \n Alexandria, VA 22314  San Francisco, CA 94158 \n\n This document is approved for public dissemination. The document contains no business-proprietary or confidential \n information. Document contents may be reused by the government in developing the AI Action Plan and associated \n documents without attribution. \n\n \u201cIt is the policy of the United States to sustain and enhance America\u2019s global dominance in \n order to promote human flourishing, economic competitiveness, and national security\u201d \n\n \u2013 President Donald J. Trump, Executive Order 14179, January 23, 2025 \n\n OpenAI respectfully submits the enclosed proposals to the Office of Science and \n Technology Policy as it weighs a new AI Action Plan that will, as Vice President Vance \n stated recently at the Paris AI Action Summit, maintain American leadership in AI and \n \u201cmake people more productive, more prosperous, and more free.\u201d As America\u2019s \n world-leading AI sector approaches artificial general intelligence (AGI), with a Chinese \n Communist Party (CCP) determined to overtake us by 2030, the Trump Administration\u2019s \n new AI Action Plan can ensure that American-led AI built on democratic principles \n continues to prevail over CCP-built autocratic, authoritarian AI. \n\n OpenAI agrees with the Trump Administration that AI creates prosperity and freedom worth \n fighting for\u2014especially for younger generations whose future will be shaped by how this \n Administration approaches AI. Globally, most ChatGPT users are under age 35; in the US, \n about one third are ages 18 to 24.  1  Both young people and their parents recognize the \n economic opportunities AI presents: \n\n \u25cf  More than seven in 10 parents in the US believe children today will be worse off \n financially than they are.  2 \n\n \u25cf  Nine in 10 US parents think it's important that their kids learn how to use artificial \n intelligence for their future jobs\u2014and eight in 10 say either that isn\u2019t happening \n today, or they don\u2019t know if it is.  3 \n\n \u25cf  Three in four college-age AI users want to use AI in their education and careers. \n Many are teaching themselves and their friends about AI without waiting for their \n schools to provide formal AI education.  4 \n\n 4  OpenAI:  Building an AI-Ready Workforce: A Look at  ChatGPT Adoption in the US  , Feb. 2025 \n\n 3  Morning Consult survey commissioned by Samsung:  88%  of US Parents of Gen Alpha & Gen Z Students Say AI \n Will Be Crucial to Their Child\u2019s Future Success  , Sept.  2024 \n\n 2  Pew Research Center:  Views of children\u2019s financial  future  , Jan. 2025 \n 1  Self-reported among logged-in users \n\n 1 \n\nhttps://cdn.openai.com/global-affairs/openai-edu-ai-ready-workforce.pdf\nhttps://news.samsung.com/us/88-percent-us-parents-gen-alpha-gen-z-students-say-ai-crucial-to-childs-future-success-samsung-solve-for-tomorrow/\nhttps://news.samsung.com/us/88-percent-us-parents-gen-alpha-gen-z-students-say-ai-crucial-to-childs-future-success-samsung-solve-for-tomorrow/\nhttps://www.pewresearch.org/global/2025/01/09/views-of-childrens-financial-future/\n\n\n In particular, AI could drive significant increased productivity over the next decade. Here\u2019s \n how we can realize this heightened prosperity and greater freedom together. \n\n Scaling human ingenuity \n Innovation creates and scales our ability to push beyond our current limits. From foot travel \n to the domesticated horse, the wheel, steam power, the car, the plane\u2014we scaled the \n freedom of mobility. From daylight to candle and lamplight, to electricity providing light and \n power at all hours\u2014we scaled the freedom to produce, think and create. From word of \n mouth to the stylus and tablet, to the printing press, telegraph, phone, computer, \n smartphone\u2014we scaled freedom of learning and knowledge. Now, as we approach AGI, \n innovation is poised to scale human ingenuity itself\u2014the sum of our freedoms to learn and \n know, think, create and produce. \n\n As our CEO Sam Altman  has written  , we are at the doorstep  of the next leap in prosperity: \n the Intelligence Age. But we must ensure that people have  freedom of intelligence  , by \n which we mean the freedom to access and benefit from AGI, protected from both autocratic \n powers that would take people\u2019s freedoms away, and layers of laws and bureaucracy that \n would prevent our realizing them. \n\n More than 400 million people around the world are using ChatGPT to ideate, discover, and \n break through beyond what we\u2019re currently capable of doing on our own. Just two weeks \n ago, we partnered with the Department of Energy\u2019s national labs to  bring together  1,500 \n scientists to use our tools to take scientific discovery farther, faster. \n\n Our work at OpenAI also suggests that as AI advances, progress accelerates and becomes \n increasingly affordable, as reflected in these three scaling principles: \n\n 1.  The intelligence of an AI model roughly equals  the log of the resources used to train and \n run it.  Until recently, scaling progress has primarily  come from training compute and data, \n but we have shown how to make intelligence scale from inference compute, as well. The \n scaling laws that predict these gains are incredibly precise over many orders of magnitude, \n so investing more in AI will continue to make it better and more capable.  We believe that \n the socioeconomic value of linearly increasing intelligence is super-exponential in nature. \n\n 2.  The cost to use a given level of AI capability  falls by about 10x every 12 months, and \n lower prices lead to much more use.  We saw this in  the change in token cost between \n GPT-4 in early 2023 and GPT-4o in mid-2024, where the price per token dropped about \n 150x in that time period.  Moore\u2019s Law predicted that  the number of transistors on a \n microchip would double roughly every two years; the decrease in the cost of using AI is \n even more dramatic. \n\n 2 \n\nhttps://ia.samaltman.com/\nhttps://cdn.openai.com/global-affairs/openai-usnl-scientist-ai-jam-session.pdf\n\n\n 3.  The amount of calendar time it takes to improve  an AI model keeps decreasing  . AI \n models are catching up with human intelligence at an increasing rate. The typical time it \n takes for a computer to beat humans at a given benchmark has fallen from 20 years after \n the benchmark was introduced, to five years, and now to one to two years  \u2014and we see no \n reason why those advancements will stop in the near future. \n\n By scaling human ingenuity ever faster and more affordably, AGI will create a flywheel of \n more freedom leading to more productivity, prosperity, and yet more innovation\u2014letting us \n once again focus on positive-sum growth. \n\n Advancing democratic AI \n OpenAI believes the best future is one in which we move forward with democratic AI\u2014AI \n that is shaped by the democratic principles America has always stood for. As OpenAI \n recently laid out in our  Economic Blueprint  , we believe  these principles include: \n\n \u25cf  A free market  promoting free and fair competition  that drives innovation. \n \u25cf  Freedom for developers and users  to work with and  direct our tools as they see fit, \n\n in exchange for following clear, common-sense technical standards that help keep \n AI safe for everyone, and being held accountable when they don\u2019t. \n\n \u25cf  Preventing government use of AI tools to amass power and control their citizens  , \n or to threaten or coerce other states. \n\n In advancing democratic AI, America is competing with a CCP determined to become the \n global leader by 2030. That\u2019s why the recent release of DeepSeek\u2019s R1 model is so \n noteworthy\u2014not because of its capabilities (R1\u2019s reasoning capabilities, albeit impressive, \n are at best on par with several US models), but as a gauge of the state of this competition. \n\n As with Huawei, there is significant risk in building on top of DeepSeek models in critical \n infrastructure and other high-risk use cases given the potential that DeepSeek could be \n compelled by the CCP to manipulate its models to cause harm. And because DeepSeek is \n simultaneously state-subsidized, state-controlled, and freely available, the cost to its users \n is their  privacy and security  , as DeepSeek faces requirements  under Chinese law to \n comply with demands for user data and uses it to train more capable systems for the CCP\u2019s \n use. Their models also more willingly generate how-to\u2019s for illicit and harmful activities such \n as identity fraud and intellectual property theft, a reflection of how the CCP views violations \n of American IP rights as a feature, not a flaw. \n\n 3 \n\nhttps://cdn.openai.com/global-affairs/openai-us-economicblueprint-feb-2025-edu-update.pdf\nhttps://blogs.cisco.com/security/evaluating-security-risk-in-deepseek-and-other-frontier-reasoning-models\n\n\n Today, CCP-controlled China has a number of strategic advantages, including: \n \u25cf  As an authoritarian state, its ability to quickly marshal resources  \u2014data, energy, \n\n technical talent, and the enormous sums needed to build out its own domestic chip \n development capacity. \n\n \u25cf  Its preexisting Belt and Road initiative.  As with  Huawei, the PRC will scale the \n adoption of PRC-based AI systems like DeepSeek\u2019s by coercing countries needing \n AI tools and nation-building infrastructure funds. \n\n \u25cf  Its ability to benefit from regulatory arbitrage being created by individual American \n states  seeking to pass their own industry-wide laws,  some of which are modeled \n on the European Union\u2019s regulation of AI. These laws are easier to enforce with \n domestic AI companies than PRC-based companies and could impose \n burdensome compliance requirements that may hinder our economic \n competitiveness and undermine our national security. They also may weaken the \n quality and level of training data available to American entrepreneurs and the \n usefulness for downstream consumers and businesses. \n\n \u25cf  Its ability to benefit from copyright arbitrage being created by democratic nations \n that do not clearly protect AI training by statute, like the US, or that reduce the \n amount of training data through an opt-out regime for copyright holders, like the \n EU. The PRC is unlikely to respect the IP regimes of any of such nations for the \n training of its AI systems, but already likely has access to all the same data, putting \n American AI labs at a comparative disadvantage while gaining little in the way of \n protections for the original IP creators. \n\n While America maintains a lead on AI today, DeepSeek shows that our lead is not wide and \n is narrowing. The AI Action Plan should ensure that American-led AI prevails over CCP-led \n AI, securing both American leadership on AI and a brighter future for all Americans. \n\n What we propose \n OpenAI\u2019s freedom-focused policy proposals, taken together, can strengthen America\u2019s lead \n on AI and in so doing, unlock economic growth, lock in American competitiveness, and \n protect our national security. Specifically, we detail: \n\n A regulatory strategy that ensures the freedom to innovate:  For innovation to truly create \n new freedoms, America\u2019s builders, developers, and entrepreneurs\u2014our nation\u2019s greatest \n competitive advantage\u2014must first have the freedom to innovate in the national interest. We \n propose a holistic approach that enables voluntary partnership between the federal \n government and the private sector, and neutralizes potential PRC benefit from American AI \n companies having to comply with overly burdensome state laws. \n\n 4 \n\n\n\n An export control strategy that exports democratic AI:  For countries seeking access to \n American AI, we propose a strategy that  would apply a commercial growth lens\u2014both Total \n and Serviceable Addressable Markets\u2014to proactively promote the global adoption of \n American AI systems and with them, the freedoms they create. At the same time, the \n strategy would use export controls to protect America\u2019s AI lead, including by making \n updates to the AI diffusion rule. \n\n A copyright strategy that promotes the freedom to learn:  America\u2019s robust, balanced \n intellectual property system has long been key to our global leadership on innovation. We \n propose a copyright strategy that would extend the system\u2019s role into the Intelligence Age \n by protecting the rights and interests of content creators while also protecting America\u2019s AI \n leadership and national security. The federal government can both secure Americans\u2019 \n freedom to learn from AI, and avoid forfeiting our AI lead to the PRC by preserving \n American AI models\u2019 ability to learn from copyrighted material. \n\n A strategy to seize the infrastructure opportunity to drive growth:  Sustaining America\u2019s lead \n on AI means building the necessary infrastructure to compete with the PRC and its \n commandeered resources. We propose policies to seize this unmissable opportunity to \n catalyze a reindustrialization across our country, creating and supporting hundreds of \n thousands of jobs, boosting local economies, modernizing our energy grid, and preparing \n an AI-ready workforce  \u2014t  he key pillar of any country\u2019s  AI infrastructure. \n\n An ambitious government adoption strategy:  Advancing  democratic AI around the world \n starts with ensuring that the US government itself sets an example of governments using AI \n to keep their people safe, prosperous, and free. With the PRC progressing toward \n ambitious targets for AI adoption across its public administration, security, and military, the \n US government should modernize its processes to safely deploy frontier AI tools at the \n pace of the private sector and with the efficiency Americans deserve. \n\n America always succeeds when it bets on American ingenuity. The enclosed policy \n proposals are either derived from, or in the case of copyright represent updates to  OpenAI's \n Economic Blueprint  , and we look forward to discussing  them with you. \n\n Chris Lehane \n Vice President, Global Affairs \n\n 5 \n\nhttps://cdn.openai.com/global-affairs/openai-us-economicblueprint-feb-2025-edu-update.pdf\nhttps://cdn.openai.com/global-affairs/openai-us-economicblueprint-feb-2025-edu-update.pdf\n\n\n 1. Preemption: Ensuring the Freedom to Innovate \n\n We propose creating a tightly-scoped framework for voluntary partnership between the \n federal government and the private sector to protect and strengthen American national \n security. This framework would extend the tradition of government receiving learnings \n and access, where appropriate, in exchange for providing the private sector relief from \n the  781 and counting proposed AI-related bills  already  introduced this year in US states. \n This patchwork of regulations risks bogging down innovation and, in the case of AI, \n undermining America\u2019s leadership position. \n\n Overseen by the US Department of Commerce and in coordination with the AI Czar, \n perhaps by reimagining the US AI Safety Institute, this effort would provide domestic AI \n companies with a single, efficient \u201cfront door\u201d to the federal government that would \n coordinate expertise across the entire national security and economic competitiveness \n communities.  5 \n\n This targeted framework would empower the federal government to: \n \u25cf  Work with both large AI companies and start-ups on a purely voluntary and \n\n optional basis to stay informed about AI risks as well as cutting-edge capabilities \n that support US national interests  ,  including by establishing  sandbox and testing \n capabilities on the secure premises of federal agencies. \n\n \u25cf  Evaluate the state of American AI technology against the technology of \n competitors and adversaries, including evaluating foreign models for the potential \n for back doors or malign influence. \n\n \u25cf  Coordinate the development of technical standards for evaluating and \n safeguarding frontier models from national security risks. \n\n \u25cf  Provide American AI companies with the tools and classified threat intelligence to \n mitigate national security risks that are exacerbated by frontier models (e.g., \n cyber, CBRN) and posed by nation-state actors (e.g., economic espionage by \n China). \n\n \u25cf  Incentivize companies to take part in this voluntary initiative by creating glide \n paths for them to contract with the government, including on national security \n projects; creating strong protections for any company information shared during \n these partnerships; and reducing barriers to companies' internal work related to \n national security domains. \n\n \u25cf  Guarantee that state-based legislation does not undermine America\u2019s innovation \n lead on AI. Create a sandbox for American start-ups, and provide participating \n companies with liability protections including preemption from state-based \n\n 5  Federal preemption over existing or prospective state  laws will require an act of Congress. \n\n 6 \n\nhttps://techcrunch.com/2025/03/07/us-lawmakers-have-already-introduce-hundreds-of-ai-bills-in-2025/\n\n\n regulations that focus on frontier model security (e.g., CA SB 1047). This will help \n keep the US public and private sectors competitive by allowing AI companies of \n all sizes to pursue bleeding-edge AI technology free from the regulatory \n uncertainty created by some state-based liability regimes. \n\n 2. Export Controls: Exporting Democratic AI \n\n A comprehensive export control strategy should do more than restrict the flow of AI \n technologies to the PRC\u2014it should ensure that America is \u201cwinning diffusion\u201d, i.e., that \n as much of the world as possible is aligned to democratic values and building on \n democratic infrastructure. To that end, we propose that the US government consider the \n Total Addressable Market (TAM), i.e., the entire world less the PRC and its few allies, \n against the Serviceable Addressable Market (SAM), i.e., those countries who prefer to \n build AI on democratic rails, and help as many of the latter as possible commit, including \n by actually committing to deploy AI in line with democratic principles set out by the US \n government. \n\n In particular, we propose maintaining the AI diffusion rule\u2019s three-tiered framework to \n differentiate among countries in the global AI market, but with some key modifications \n that expand the number of countries in Tier I: \n\n Tier I:  Countries that commit to democratic AI principles  by deploying AI systems in ways \n that promote more freedoms for their citizens could be considered Tier I countries. \n\n Tier II:  Limited to only those countries that have  a history of failing to prevent \n export-controlled chips and other US-developed IP from being diverted into, or used by \n Tier III countries. These countries would be encouraged and supported to obtain Tier I \n status over time; and would be subject to more stringent security requirements in the \n interim. \n\n Tier III:  CCP-led China, along with a small cohort  of countries aligned with the CCP, \n would represent its own category that is prohibited from accessing democratic AI \n systems. \n\n This strategy would encourage global adoption of democratic AI principles, promoting the \n use of democratic AI systems while protecting US advantage. Making sure that \n open-sourced models are readily available to developers in these countries also will \n strengthen our advantage.  We believe the question  of whether AI should be open or \n\n 7 \n\n\n\n closed source is a false choice\u2014we need both, and they can work in a complementary \n way that encourages the building of AI on American rails. \n\n Tier I countries  should include American allies, as  well as those countries that are \n committed to democratic AI principles and that present a relatively low risk that American \n AI infrastructure (e.g., chips) will be diverted to non-Tier I countries. The commercial \n diplomacy strategy in Tier I should recognize these countries\u2019 strong history of export \n and customs control compliance and seek to maximally expand democratic AI systems\u2019 \n market share, while at the same time protecting those systems from IP theft by the PRC \n and other malign actors (e.g., the theft of model weights and/or chip designs, \n unauthorized influence or access to data center operations). \n\n To expand market share in Tier I countries, American commercial diplomacy policy \n should: \n\n \u25cf  Encourage cross-border capital flows and promote software frameworks that are \n optimized for domestic chip design. \n\n \u25cf  Coordinate global bans on CCP-aligned AI infrastructure, including Huawei chips. \n \u25cf  Continue to represent American company interests in safety and security \n\n standards bodies, and encourage global regulators to adopt pro-growth safety and \n security policies. \n\n \u25cf  Revise the existing export control rules to eliminate country caps on compute. \n \u25cf  Maintain existing export license exceptions (e.g., license exception ACM) that \n\n enable exports of technology and software for technical collaboration with allies \n and preservation of economically critical supply chains \n\n To protect the US-developed IP needed to operate data centers in Tier I countries, \n security requirements could include: \n\n \u25cf  Prohibiting relationships with Tier III countries\u2019 foreign military and intelligence \n services, and the use of data centers to support military/intelligence missions for \n Tier III nations or human rights violators. \n\n \u25cf  Banning the use of PRC-produced equipment (e.g., Huawei Ascend chips) and \n models that violate user privacy and create security risks such as the risk of IP \n theft. \n\n \u25cf  Maintaining corporate control by entities headquartered in Tier I countries. \n \u25cf  Implementing\u2014and constantly modernizing\u2014cybersecurity, model weight security, \n\n and personnel security controls that ideally are globally synced and coordinated \n among Tier I governments. \n\n 8 \n\n\n\n Controls on model weights\u2014if any\u2014should strike a balance between protecting \n American-developed IP and promoting the deployment of American-developed models \n over those developed by Tier III countries, including the PRC. \n\n Tier II  countries  should include those with a history  of failing to prevent \n export-controlled chips and other US-developed IP from being diverted into, or used by \n Tier III co  untries. Here, the commercial diplomacy  strategy should still seek to expand \n US market share, but should do so more carefully, including by levying stronger controls \n on the export of US-developed AI infrastructure. At the same time, the strategy should \n provide transparent pathways for Tier II countries to reach Tier I status by adopting \n democratic AI principles and more effectively managing risks of chip diversion. \n\n To expand American market share in Tier II countries, in addition to the steps above, the \n commercial diplomacy policy could be designed to leverage commercial interest in \n American-led AI in order to encourage investment in the US, enhanced security \n procedures, and encourage more countries to build on American rails: \n\n \u25cf  Establish a transparent process to evaluate countries\u2019 readiness to transition from \n Tier II to Tier I. \n\n \u25cf  Support countries\u2019 transition from Tier II to Tier I by helping Tier II governments \n strengthen their in-country security programs. \n\n \u25cf  Encourage greater economic interdependence between the US and Tier II \n countries. \n\n \u25cf  Incentivize public-private partnerships to rapidly mature, scale, and commercialize \n hardware-enabled mechanisms that could enhance in-country security controls in \n the future. \n\n To protect the American-developed IP needed to operate data centers in Tier II countries, \n and to manage both the heightened risk of IP theft and the additional risk that \n export-controlled chips might be diverted from Tier II into Tier III countries, the \n commercial diplomacy policy also could: \n\n \u25cf  Allow the export of advanced AI chips to an end-user located in a Tier II country \n that meets Tier I security requirements, and that puts in place additional corporate \n governance controls as well as technology-enhanced protections (e.g., \n hardware-enabled mechanisms) against the diversion of export-controlled chips. \n\n Tier III countries  \u2014including the PRC and any other  country subject to a US arms \n embargo\u2014s  hould continue to be subject to strict export  controls of AI systems, including \n existing export controls on advanced chips. The strategy could also expand established \n controls, for example, to include advanced chips that are required for large-scale \n\n 9 \n\n\n\n inference and RL training and the components used to manufacture advanced AI chips \n and data centers. \n\n 3. Copyright: Promoting the Freedom to Learn \n\n American copyright law, including the longstanding fair use doctrine, protects the \n transformative uses of existing works, ensuring that innovators have a balanced and \n predictable framework for experimentation and entrepreneurship. This approach has \n underpinned American success through earlier phases of technological progress and is \n even more critical to continued American leadership on AI in the wake of recent events in \n the PRC. OpenAI\u2019s models are trained to not replicate works for consumption by the \n public. Instead, they learn from the works and extract patterns, linguistic structures, and \n contextual insights. This means our AI model training aligns with the core objectives of \n copyright and the fair use doctrine, using existing works to create something wholly new \n and different without eroding the commercial value of those existing works. \n\n America has so many AI startups, attracts so much investment, and has made so many \n research breakthroughs largely because the fair use doctrine promotes AI development. \n In other markets, rigid copyright rules are repressing innovation and investment. \n\n The European Union, for one, has created \u201ctext and data mining exceptions\u201d with broadly \n applicable \u201copt-outs\u201d for any rights holder\u2014meaning access to important AI inputs is less \n predictable and likely to become more difficult as the EU\u2019s regulations take shape. \n Unpredictable availability of inputs hinders AI innovation, particularly for smaller, newer \n entrants with limited budgets. \n\n The UK government is currently considering changes to its copyright regime. It has \n indicated that it prefers creating a data mining exception that allows rights holders to \n \u201creserve their rights,\u201d creating the same regulatory barriers to AI development that we \n see in the EU. \n\n Applying the fair use doctrine to AI is not only a matter of American competitiveness \n \u2014it\u2019s a matter of national security. The rapid advances seen with the PRC\u2019s DeepSeek, \n among other recent developments, show that America\u2019s lead on frontier AI is far from \n guaranteed. Given concerted state support for critical industries and infrastructure \n projects, there\u2019s little doubt that the PRC\u2019s AI developers will enjoy unfettered access to \n data\u2014including copyrighted data\u2014that will improve their models.  If the PRC\u2019s \n developers have unfettered access to data and American companies are left without fair \n use access, the race for AI is effectively over. America loses, as does the success of \n\n 10 \n\n\n\n democratic AI  .  Ultimately, access to more data from the widest possible range of sources \n will ensure more access to more powerful innovations that deliver even more knowledge. \n\n We propose that the US government take steps to ensure that our copyright system \n continues to support American AI leadership and American economic and national \n security, including by: \n\n \u25cf  Shaping international policy discussions around copyright and AI, and working to \n prevent less innovative countries from imposing their legal regimes on American \n AI firms and slowing our rate of progress. \n\n \u25cf  Actively assessing the overall level of data available to American AI firms and \n determining whether other countries are restricting American companies\u2019 access \n to data and other critical inputs. \n\n \u25cf  Encouraging more access to government-held or government-supported data. \n This would boost AI development in any case, but would be particularly important \n if shifting copyright rules restrict American companies\u2019 access to training data. \n\n \u25cf  Monitoring domestic policy debates and ongoing litigation, and weighing in where \n fundamental, pro-innovation principles are at risk. \n\n Generative AI models represent the next frontier of innovation, poised to revolutionize \n the private and public sectors, improving healthcare, education, scientific research, and \n so much more. If AI innovation remains protected under longstanding copyright \n principles, America will maintain and strengthen its role as the world leader in \n cutting-edge technologies and remain positioned to continue championing AI based on \n democratic principles with countries around the world. \n\n 4. Infrastructure: Seizing the Opportunity to Drive Growth \n\n Today, hundreds of billions of dollars in global funds are waiting to be invested in AI \n infrastructure. If the US doesn't move fast to channel these resources into projects that \n support democratic AI ecosystems around the world, the funds will flow to projects \n backed and shaped by the CCP. \n\n We propose a foundational strategy to ensure that investment in infrastructure drives \n economic growth that benefits all Americans; maximizes access to AI; and protects \n national security interests by keeping sensitive American data on American soil. This \n includes policies and initiatives that encourage rather than stifle developers; support  a \n thriving AI-ready workforce and  ecosystems of labs,  start-ups and larger companies; and \n secure America\u2019s leadership on AI into the future. \n\n 11 \n\n\n\n First and foremost, building data centers is capital-intensive, particularly for newcomers \n seeking to compete against established hyperscalers with vast resources.  W  e support \n the solutions already proposed by this Administration  to ensure that sufficient capital \n flows to building AI infrastructure in the US: \n\n \u25cf  Investment vehicles like a Sovereign Wealth Fund  . \n \u25cf  Government offtake and guarantees tha  t both provide  the government with the \n\n compute it needs and signal to markets that the demand will be there for \n American-developed AI. \n\n \u25cf  Tax credits, loans, and other vehicles the US government can direct to provide \n credit enhancement. \n\n We also have proposed: \n\n A National Transmission Highway Act  , as ambitious  as the 1956 National Interstate and \n Defense Highways Act, to expand transmission, fiber connectivity, and natural gas \n pipeline construction. The process for obtaining the \u201cthree Ps\u201d\u2014planning, permitting, and \n paying for approvals from federal, state, local, and tribal authorities\u2014disadvantages \n America\u2019s AI industry. Transmission lines can take 10 years or more to complete. When \n lines are built, parties must agree on which customers pay higher electrical bills to bear \n the cost of construction. In this process, delays often affect the build-out of transmission \n lines. Streamlining these processes and eliminating redundancies would significantly \n speed up infrastructure projects, keeping America\u2019s AI sector globally competitive and \n securing a future of reliable, affordable energy. \n\n Digitizing government data currently in analog form.  A lot of government data is in the \n public domain. Making it more accessible or machine-readable could help American AI \n developers of all sizes, especially those working in fields where vital data is often \n government-held. In exchange, developers using this data could work with governments \n to unlock new insights that help it develop better public policies. For example, \n government agencies can build on the work of the US National Archives and Records \n Administration in using Optical Character Recognition for text searchability and AI-driven \n metadata tagging. \n\n A Compact for AI  among US allies and partner nations  that streamlines access to capital \n and supply chains in ways that support AI infrastruc  ture  and a robust AI ecosystem. \n Participating countries would also agree to some common standards to safeguard data \n centers and the technology. Over time, this collaboration could expand to a global \n network of US allies and partners that would compete with the  PRC\u2019s  AI infrastructure \n alliances while also strengthening security through shared standards. \n\n 12 \n\n\n\n AI Economic Zones  ,  created by local, state and the federal government together with \n industry, that speed up the permitting for building AI infrastructure like new solar arrays, \n wind farms, and nuclear reactors.  This could include  creating categorical exclusions to \n the National Environmental Policy Act, such as a national security waiver given the \n global competition for AI leadership. These zones could also build on the first Trump \n Administration\u2019s \u201cOpportunity Zones\u201d through tax incentives or credit enhancements in \n order to encourage private capital investment. \n\n A nationwide AI Readiness Strategy  \u2014rooted in local  communities in partnership with \n American companies\u2014to help our current workforce and students become AI-ready, \n bolster the economy, and secure America\u2019s continued leadership on innovation. \n Maintaining American leadership in AI means ensuring we have an experienced, trained \n professional workforce working across the AI supply chain, including construction worker \n management, HVAC technicians, and electricians. Government should ensure this \n training is accessible and affordable, such as by: \n\n \u25cf  At the federal level, expanding 529 savings plans to cover more AI supply \n chain-related training programs\u2014including for construction, HVAC technicians, \n electricians, as well as AI researchers and developers\u2014by amending Section 529 \n of the Internal Revenue Code or broadening the SECURE Act\u2019s provisions. \n\n \u25cf  At the federal or state level, incentivizing AI supply chain companies to work with \n a backbone organization to understand the workforce needs of AI supply chain \n companies, develop a pipeline of training programs that help companies meet \n those needs, and coordinate with labor unions, community colleges, and trade \n associations to build and operate that training pipeline. \n\n Creation of AI research labs and workforces aligned with key local industries  by requiring \n AI companies to provide meaningful amounts of compute to public universities to \n equitably scale the training of a homegrown AI-skilled workforce. For example, one state \n could establish a hub dedicated to applying AI in agriculture while another develops \n centers focused on integrating AI into power production and grid resilience. \n\n Using the Defense Production Act (DPA) Title I  to  manage supply chain risk by \n designating gas turbines, rankine cycle turbines, high-voltage transformers, or \n switchgear for data centers as \u201crated orders.\u201d This prioritization could significantly \n shorten timelines for data center power i  nfrastructure  projects. \n\n 13 \n\n\n\n 5. Government Adoption of AI: Leading by Example \n\n AI adoption in federal departments and agencies remains unacceptably low, with federal \n employees, and especially national security sector employees, largely unable to harness \n the benefits of the technology. \n\n The government should encourage public-private partnerships to enhance government \n AI adoption by removing known blockers to the adoption of AI tools, including outdated \n and lengthy accreditation processes, restrictive testing authorities, and inflexible \n procurement pathways. Specifically, we recommend: \n\n \u25cf  Modernizing cyber security rules for cloud-based applications.  The government\u2019s \n current processes for AI providers to comply with federal security \n regulations\u2014primarily through the Federal Risk and Authorization Management \n Program (FedRAMP)\u2014takes 12 to 18 months, compared to the one- to \n three-month commercial standard, with no clear evidence of additional protection \n for government data. The government should modernize FedRAMP by \n establishing a faster, criteria-based path for approval of AI tools. Criteria could \n include Foreign Ownership, Control, or Influence (FOCI) approval; Facilities \n Clearance (FCL) status; US incorporation; a first-party AI model that ranks in the \n top 20 of a recognized evaluation framework (for example, MMLU, or Massive \n Multitask Language Understanding); SOC 2 (System and Organization Controls 2) \n accreditation; and a recent third-party penetration test with all findings addressed. \n\n \u25cf  Accelerating AI testing and experimentation.  The government  should allow federal \n agencies to test and experiment with real data using commercial-standard \n practices\u2014such as SOC 2 or International Organization for Standardization (ISO) \n audit reports\u2014and potentially grant a temporary waiver for FedRAMP. AI vendors \n would still be required to meet FedRAMP continuous monitoring requirements \n while awaiting full accreditation. Combined with standard due diligence before \n actual use, this approach could allow agencies to access new AI services roughly \n 12 months earlier while maintaining compliance with federal security \n requirements. \n\n \u25cf  Enabling rapid procurement mechanisms.  Once new security  and testing \n approaches are in place, agencies must also have quicker, more direct routes to \n procure and deploy frontier AI tools. The government should continue to evaluate \n Other Transactional Authorities (OTAs), Commercial Service Offerings (CSO) or \n other procurement paths in order to access technology from frontier AI labs, not \n just their legacy IT providers. We are encouraged by the Department of Defense\u2019s \n recent efforts to  Modernize Software Acquisition  . \n\n 14 \n\nhttps://www.defense.gov/News/Transcripts/Transcript/Article/4113458/directing-modern-software-acquisition-to-maximize-lethality-memo-background-bri/\n\n\n Enabling federal agencies to quickly acquire consumer-focused models is not enough, \n however. The government also needs to pursue and fund bespoke national security pilot \n projects for which there may be no commercial market by: \n\n \u25cf  Partnering with industry to develop custom models for national security.  The \n government needs models trained on classified datasets that are fine-tuned to be \n exceptional at national security tasks for which there is no commercial \n market\u2014such as geospatial intelligence or classified nuclear tasks. This will likely \n require on-premises deployment of model weights and access to significant \n compute, given the security requirements of many national security agencies. \n\n \u25cf  Acting now to fund these projects and secure this compute  \u2014enabling industry \n partners to secure chips, transformers, and begin construction, and ensuring that \n this compute comes online at the pace that innovation and geopolitical \n competition require. \n\n Lastly, frontier AI labs need Facility Clearances (FCL) to work directly with the national \n security enterprise on these pilot projects and custom models. The government should: \n\n \u25cf  Expedite FCL for frontier AI labs committed to supporting national security.  The \n process for obtaining a FCL can take a year or longer. Given the rapid pace of AI \n development, the government should start prioritizing deeper collaboration with \n frontier AI labs as soon as possible. \n\n We look forward to discussing the above proposals with the Office of Science and \n Technology Policy as we continue to build on our relationship with the US government \n and work toward AI that benefits everyone. \n\n About OpenAI \n OpenAI\u2019s mission is to ensure that as AI advances, it benefits everyone. We're building AI to help \n people solve hard problems because by helping with the hard problems, AI can benefit the most \n people possible\u2014through more scientific discoveries, better healthcare and education, and \n improved productivity. We\u2019re off to a strong start, creating freely available intelligence being used \n by more than 400 million people around the world, including 3 million developers. We believe AI \n will scale human ingenuity and drive unprecedented economic growth and new freedoms that \n help people accomplish what we can't even imagine today. \n\n 15 \n\n\n","extra":{"cited_message_idx":6,"search_result_idx":null,"evidence_text":"source","cloud_doc_url":null}}}],"content_references":[{"matched_text":"\u30106\u2020source\u3011","start_idx":918,"end_idx":928,"alt":null,"type":"file","name":"openai-response-ostp-nsf-rfi-notice-request-for-information-on-the-development-of-an-artificial-intelligence-ai-action-plan.pdf","id":"file-5eiqpyd6a14ZasQ6c6cULw","source":"my_files","snippet":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[OpenAI Response] OSTP/NSF RFI: Notice Request for Information on the Development of an Artificial Intelligence (AI) Action Plan - Google Docs\n\n\n March 13, 2025 \n\n To: Faisal D'Souza, NCO  From: Christopher Lehane \n Office of Science and Technology Policy  OpenAI \n 2415 Eisenhower Avenue  1455 3rd Street \n Alexandria, VA 22314  San Francisco, CA 94158 \n\n This document is approved for public dissemination. The document contains no business-proprietary or confidential \n information. Document contents may be reused by the government in developing the AI Action Plan and associated \n documents without attribution. \n\n \u201cIt is the policy of the United States to sustain and enhance America\u2019s global dominance in \n order to promote human flourishing, economic competitiveness, and national security\u201d \n\n \u2013 President Donald J. Trump, Executive Order 14179, January 23, 2025 \n\n OpenAI respectfully submits the enclosed proposals to the Office of Science and \n Technology Policy as it weighs a new AI Action Plan that will, as Vice President Vance \n stated recently at the Paris AI Action Summit, maintain American leadership in AI and \n \u201cmake people more productive, more prosperous, and more free.\u201d As America\u2019s \n world-leading AI sector approaches artificial general intelligence (AGI), with a Chinese \n Communist Party (CCP) determined to overtake us by 2030, the Trump Administration\u2019s \n new AI Action Plan can ensure that American-led AI built on democratic principles \n continues to prevail over CCP-built autocratic, authoritarian AI. \n\n OpenAI agrees with the Trump Administration that AI creates prosperity and freedom worth \n fighting for\u2014especially for younger generations whose future will be shaped by how this \n Administration approaches AI. Globally, most ChatGPT users are under age 35; in the US, \n about one third are ages 18 to 24.  1  Both young people and their parents recognize the \n economic opportunities AI presents: \n\n \u25cf  More than seven in 10 parents in the US believe children today will be worse off \n financially than they are.  2 \n\n \u25cf  Nine in 10 US parents think it's important that their kids learn how to use artificial \n intelligence for their future jobs\u2014and eight in 10 say either that isn\u2019t happening \n today, or they don\u2019t know if it is.  3 \n\n \u25cf  Three in four college-age AI users want to use AI in their education and careers. \n Many are teaching themselves and their friends about AI without waiting for their \n schools to provide formal AI education.  4 \n\n 4  OpenAI:  Building an AI-Ready Workforce: A Look at  ChatGPT Adoption in the US  , Feb. 2025 \n\n 3  Morning Consult survey commissioned by Samsung:  88%  of US Parents of Gen Alpha & Gen Z Students Say AI \n Will Be Crucial to Their Child\u2019s Future Success  , Sept.  2024 \n\n 2  Pew Research Center:  Views of children\u2019s financial  future  , Jan. 2025 \n 1  Self-reported among logged-in users \n\n 1 \n\nhttps://cdn.openai.com/global-affairs/openai-edu-ai-ready-workforce.pdf\nhttps://news.samsung.com/us/88-percent-us-parents-gen-alpha-gen-z-students-say-ai-crucial-to-childs-future-success-samsung-solve-for-tomorrow/\nhttps://news.samsung.com/us/88-percent-us-parents-gen-alpha-gen-z-students-say-ai-crucial-to-childs-future-success-samsung-solve-for-tomorrow/\nhttps://www.pewresearch.org/global/2025/01/09/views-of-childrens-financial-future/\n\n\n In particular, AI could drive significant increased productivity over the next decade. Here\u2019s \n how we can realize this heightened prosperity and greater freedom together. \n\n Scaling human ingenuity \n Innovation creates and scales our ability to push beyond our current limits. From foot travel \n to the domesticated horse, the wheel, steam power, the car, the plane\u2014we scaled the \n freedom of mobility. From daylight to candle and lamplight, to electricity providing light and \n power at all hours\u2014we scaled the freedom to produce, think and create. From word of \n mouth to the stylus and tablet, to the printing press, telegraph, phone, computer, \n smartphone\u2014we scaled freedom of learning and knowledge. Now, as we approach AGI, \n innovation is poised to scale human ingenuity itself\u2014the sum of our freedoms to learn and \n know, think, create and produce. \n\n As our CEO Sam Altman  has written  , we are at the doorstep  of the next leap in prosperity: \n the Intelligence Age. But we must ensure that people have  freedom of intelligence  , by \n which we mean the freedom to access and benefit from AGI, protected from both autocratic \n powers that would take people\u2019s freedoms away, and layers of laws and bureaucracy that \n would prevent our realizing them. \n\n More than 400 million people around the world are using ChatGPT to ideate, discover, and \n break through beyond what we\u2019re currently capable of doing on our own. Just two weeks \n ago, we partnered with the Department of Energy\u2019s national labs to  bring together  1,500 \n scientists to use our tools to take scientific discovery farther, faster. \n\n Our work at OpenAI also suggests that as AI advances, progress accelerates and becomes \n increasingly affordable, as reflected in these three scaling principles: \n\n 1.  The intelligence of an AI model roughly equals  the log of the resources used to train and \n run it.  Until recently, scaling progress has primarily  come from training compute and data, \n but we have shown how to make intelligence scale from inference compute, as well. The \n scaling laws that predict these gains are incredibly precise over many orders of magnitude, \n so investing more in AI will continue to make it better and more capable.  We believe that \n the socioeconomic value of linearly increasing intelligence is super-exponential in nature. \n\n 2.  The cost to use a given level of AI capability  falls by about 10x every 12 months, and \n lower prices lead to much more use.  We saw this in  the change in token cost between \n GPT-4 in early 2023 and GPT-4o in mid-2024, where the price per token dropped about \n 150x in that time period.  Moore\u2019s Law predicted that  the number of transistors on a \n microchip would double roughly every two years; the decrease in the cost of using AI is \n even more dramatic. \n\n 2 \n\nhttps://ia.samaltman.com/\nhttps://cdn.openai.com/global-affairs/openai-usnl-scientist-ai-jam-session.pdf\n\n\n 3.  The amount of calendar time it takes to improve  an AI model keeps decreasing  . AI \n models are catching up with human intelligence at an increasing rate. The typical time it \n takes for a computer to beat humans at a given benchmark has fallen from 20 years after \n the benchmark was introduced, to five years, and now to one to two years  \u2014and we see no \n reason why those advancements will stop in the near future. \n\n By scaling human ingenuity ever faster and more affordably, AGI will create a flywheel of \n more freedom leading to more productivity, prosperity, and yet more innovation\u2014letting us \n once again focus on positive-sum growth. \n\n Advancing democratic AI \n OpenAI believes the best future is one in which we move forward with democratic AI\u2014AI \n that is shaped by the democratic principles America has always stood for. As OpenAI \n recently laid out in our  Economic Blueprint  , we believe  these principles include: \n\n \u25cf  A free market  promoting free and fair competition  that drives innovation. \n \u25cf  Freedom for developers and users  to work with and  direct our tools as they see fit, \n\n in exchange for following clear, common-sense technical standards that help keep \n AI safe for everyone, and being held accountable when they don\u2019t. \n\n \u25cf  Preventing government use of AI tools to amass power and control their citizens  , \n or to threaten or coerce other states. \n\n In advancing democratic AI, America is competing with a CCP determined to become the \n global leader by 2030. That\u2019s why the recent release of DeepSeek\u2019s R1 model is so \n noteworthy\u2014not because of its capabilities (R1\u2019s reasoning capabilities, albeit impressive, \n are at best on par with several US models), but as a gauge of the state of this competition. \n\n As with Huawei, there is significant risk in building on top of DeepSeek models in critical \n infrastructure and other high-risk use cases given the potential that DeepSeek could be \n compelled by the CCP to manipulate its models to cause harm. And because DeepSeek is \n simultaneously state-subsidized, state-controlled, and freely available, the cost to its users \n is their  privacy and security  , as DeepSeek faces requirements  under Chinese law to \n comply with demands for user data and uses it to train more capable systems for the CCP\u2019s \n use. Their models also more willingly generate how-to\u2019s for illicit and harmful activities such \n as identity fraud and intellectual property theft, a reflection of how the CCP views violations \n of American IP rights as a feature, not a flaw. \n\n 3 \n\nhttps://cdn.openai.com/global-affairs/openai-us-economicblueprint-feb-2025-edu-update.pdf\nhttps://blogs.cisco.com/security/evaluating-security-risk-in-deepseek-and-other-frontier-reasoning-models\n\n\n Today, CCP-controlled China has a number of strategic advantages, including: \n \u25cf  As an authoritarian state, its ability to quickly marshal resources  \u2014data, energy, \n\n technical talent, and the enormous sums needed to build out its own domestic chip \n development capacity. \n\n \u25cf  Its preexisting Belt and Road initiative.  As with  Huawei, the PRC will scale the \n adoption of PRC-based AI systems like DeepSeek\u2019s by coercing countries needing \n AI tools and nation-building infrastructure funds. \n\n \u25cf  Its ability to benefit from regulatory arbitrage being created by individual American \n states  seeking to pass their own industry-wide laws,  some of which are modeled \n on the European Union\u2019s regulation of AI. These laws are easier to enforce with \n domestic AI companies than PRC-based companies and could impose \n burdensome compliance requirements that may hinder our economic \n competitiveness and undermine our national security. They also may weaken the \n quality and level of training data available to American entrepreneurs and the \n usefulness for downstream consumers and businesses. \n\n \u25cf  Its ability to benefit from copyright arbitrage being created by democratic nations \n that do not clearly protect AI training by statute, like the US, or that reduce the \n amount of training data through an opt-out regime for copyright holders, like the \n EU. The PRC is unlikely to respect the IP regimes of any of such nations for the \n training of its AI systems, but already likely has access to all the same data, putting \n American AI labs at a comparative disadvantage while gaining little in the way of \n protections for the original IP creators. \n\n While America maintains a lead on AI today, DeepSeek shows that our lead is not wide and \n is narrowing. The AI Action Plan should ensure that American-led AI prevails over CCP-led \n AI, securing both American leadership on AI and a brighter future for all Americans. \n\n What we propose \n OpenAI\u2019s freedom-focused policy proposals, taken together, can strengthen America\u2019s lead \n on AI and in so doing, unlock economic growth, lock in American competitiveness, and \n protect our national security. Specifically, we detail: \n\n A regulatory strategy that ensures the freedom to innovate:  For innovation to truly create \n new freedoms, America\u2019s builders, developers, and entrepreneurs\u2014our nation\u2019s greatest \n competitive advantage\u2014must first have the freedom to innovate in the national interest. We \n propose a holistic approach that enables voluntary partnership between the federal \n government and the private sector, and neutralizes potential PRC benefit from American AI \n companies having to comply with overly burdensome state laws. \n\n 4 \n\n\n\n An export control strategy that exports democratic AI:  For countries seeking access to \n American AI, we propose a strategy that  would apply a commercial growth lens\u2014both Total \n and Serviceable Addressable Markets\u2014to proactively promote the global adoption of \n American AI systems and with them, the freedoms they create. At the same time, the \n strategy would use export controls to protect America\u2019s AI lead, including by making \n updates to the AI diffusion rule. \n\n A copyright strategy that promotes the freedom to learn:  America\u2019s robust, balanced \n intellectual property system has long been key to our global leadership on innovation. We \n propose a copyright strategy that would extend the system\u2019s role into the Intelligence Age \n by protecting the rights and interests of content creators while also protecting America\u2019s AI \n leadership and national security. The federal government can both secure Americans\u2019 \n freedom to learn from AI, and avoid forfeiting our AI lead to the PRC by preserving \n American AI models\u2019 ability to learn from copyrighted material. \n\n A strategy to seize the infrastructure opportunity to drive growth:  Sustaining America\u2019s lead \n on AI means building the necessary infrastructure to compete with the PRC and its \n commandeered resources. We propose policies to seize this unmissable opportunity to \n catalyze a reindustrialization across our country, creating and supporting hundreds of \n thousands of jobs, boosting local economies, modernizing our energy grid, and preparing \n an AI-ready workforce  \u2014t  he key pillar of any country\u2019s  AI infrastructure. \n\n An ambitious government adoption strategy:  Advancing  democratic AI around the world \n starts with ensuring that the US government itself sets an example of governments using AI \n to keep their people safe, prosperous, and free. With the PRC progressing toward \n ambitious targets for AI adoption across its public administration, security, and military, the \n US government should modernize its processes to safely deploy frontier AI tools at the \n pace of the private sector and with the efficiency Americans deserve. \n\n America always succeeds when it bets on American ingenuity. The enclosed policy \n proposals are either derived from, or in the case of copyright represent updates to  OpenAI's \n Economic Blueprint  , and we look forward to discussing  them with you. \n\n Chris Lehane \n Vice President, Global Affairs \n\n 5 \n\nhttps://cdn.openai.com/global-affairs/openai-us-economicblueprint-feb-2025-edu-update.pdf\nhttps://cdn.openai.com/global-affairs/openai-us-economicblueprint-feb-2025-edu-update.pdf\n\n\n 1. Preemption: Ensuring the Freedom to Innovate \n\n We propose creating a tightly-scoped framework for voluntary partnership between the \n federal government and the private sector to protect and strengthen American national \n security. This framework would extend the tradition of government receiving learnings \n and access, where appropriate, in exchange for providing the private sector relief from \n the  781 and counting proposed AI-related bills  already  introduced this year in US states. \n This patchwork of regulations risks bogging down innovation and, in the case of AI, \n undermining America\u2019s leadership position. \n\n Overseen by the US Department of Commerce and in coordination with the AI Czar, \n perhaps by reimagining the US AI Safety Institute, this effort would provide domestic AI \n companies with a single, efficient \u201cfront door\u201d to the federal government that would \n coordinate expertise across the entire national security and economic competitiveness \n communities.  5 \n\n This targeted framework would empower the federal government to: \n \u25cf  Work with both large AI companies and start-ups on a purely voluntary and \n\n optional basis to stay informed about AI risks as well as cutting-edge capabilities \n that support US national interests  ,  including by establishing  sandbox and testing \n capabilities on the secure premises of federal agencies. \n\n \u25cf  Evaluate the state of American AI technology against the technology of \n competitors and adversaries, including evaluating foreign models for the potential \n for back doors or malign influence. \n\n \u25cf  Coordinate the development of technical standards for evaluating and \n safeguarding frontier models from national security risks. \n\n \u25cf  Provide American AI companies with the tools and classified threat intelligence to \n mitigate national security risks that are exacerbated by frontier models (e.g., \n cyber, CBRN) and posed by nation-state actors (e.g., economic espionage by \n China). \n\n \u25cf  Incentivize companies to take part in this voluntary initiative by creating glide \n paths for them to contract with the government, including on national security \n projects; creating strong protections for any company information shared during \n these partnerships; and reducing barriers to companies' internal work related to \n national security domains. \n\n \u25cf  Guarantee that state-based legislation does not undermine America\u2019s innovation \n lead on AI. Create a sandbox for American start-ups, and provide participating \n companies with liability protections including preemption from state-based \n\n 5  Federal preemption over existing or prospective state  laws will require an act of Congress. \n\n 6 \n\nhttps://techcrunch.com/2025/03/07/us-lawmakers-have-already-introduce-hundreds-of-ai-bills-in-2025/\n\n\n regulations that focus on frontier model security (e.g., CA SB 1047). This will help \n keep the US public and private sectors competitive by allowing AI companies of \n all sizes to pursue bleeding-edge AI technology free from the regulatory \n uncertainty created by some state-based liability regimes. \n\n 2. Export Controls: Exporting Democratic AI \n\n A comprehensive export control strategy should do more than restrict the flow of AI \n technologies to the PRC\u2014it should ensure that America is \u201cwinning diffusion\u201d, i.e., that \n as much of the world as possible is aligned to democratic values and building on \n democratic infrastructure. To that end, we propose that the US government consider the \n Total Addressable Market (TAM), i.e., the entire world less the PRC and its few allies, \n against the Serviceable Addressable Market (SAM), i.e., those countries who prefer to \n build AI on democratic rails, and help as many of the latter as possible commit, including \n by actually committing to deploy AI in line with democratic principles set out by the US \n government. \n\n In particular, we propose maintaining the AI diffusion rule\u2019s three-tiered framework to \n differentiate among countries in the global AI market, but with some key modifications \n that expand the number of countries in Tier I: \n\n Tier I:  Countries that commit to democratic AI principles  by deploying AI systems in ways \n that promote more freedoms for their citizens could be considered Tier I countries. \n\n Tier II:  Limited to only those countries that have  a history of failing to prevent \n export-controlled chips and other US-developed IP from being diverted into, or used by \n Tier III countries. These countries would be encouraged and supported to obtain Tier I \n status over time; and would be subject to more stringent security requirements in the \n interim. \n\n Tier III:  CCP-led China, along with a small cohort  of countries aligned with the CCP, \n would represent its own category that is prohibited from accessing democratic AI \n systems. \n\n This strategy would encourage global adoption of democratic AI principles, promoting the \n use of democratic AI systems while protecting US advantage. Making sure that \n open-sourced models are readily available to developers in these countries also will \n strengthen our advantage.  We believe the question  of whether AI should be open or \n\n 7 \n\n\n\n closed source is a false choice\u2014we need both, and they can work in a complementary \n way that encourages the building of AI on American rails. \n\n Tier I countries  should include American allies, as  well as those countries that are \n committed to democratic AI principles and that present a relatively low risk that American \n AI infrastructure (e.g., chips) will be diverted to non-Tier I countries. The commercial \n diplomacy strategy in Tier I should recognize these countries\u2019 strong history of export \n and customs control compliance and seek to maximally expand democratic AI systems\u2019 \n market share, while at the same time protecting those systems from IP theft by the PRC \n and other malign actors (e.g., the theft of model weights and/or chip designs, \n unauthorized influence or access to data center operations). \n\n To expand market share in Tier I countries, American commercial diplomacy policy \n should: \n\n \u25cf  Encourage cross-border capital flows and promote software frameworks that are \n optimized for domestic chip design. \n\n \u25cf  Coordinate global bans on CCP-aligned AI infrastructure, including Huawei chips. \n \u25cf  Continue to represent American company interests in safety and security \n\n standards bodies, and encourage global regulators to adopt pro-growth safety and \n security policies. \n\n \u25cf  Revise the existing export control rules to eliminate country caps on compute. \n \u25cf  Maintain existing export license exceptions (e.g., license exception ACM) that \n\n enable exports of technology and software for technical collaboration with allies \n and preservation of economically critical supply chains \n\n To protect the US-developed IP needed to operate data centers in Tier I countries, \n security requirements could include: \n\n \u25cf  Prohibiting relationships with Tier III countries\u2019 foreign military and intelligence \n services, and the use of data centers to support military/intelligence missions for \n Tier III nations or human rights violators. \n\n \u25cf  Banning the use of PRC-produced equipment (e.g., Huawei Ascend chips) and \n models that violate user privacy and create security risks such as the risk of IP \n theft. \n\n \u25cf  Maintaining corporate control by entities headquartered in Tier I countries. \n \u25cf  Implementing\u2014and constantly modernizing\u2014cybersecurity, model weight security, \n\n and personnel security controls that ideally are globally synced and coordinated \n among Tier I governments. \n\n 8 \n\n\n\n Controls on model weights\u2014if any\u2014should strike a balance between protecting \n American-developed IP and promoting the deployment of American-developed models \n over those developed by Tier III countries, including the PRC. \n\n Tier II  countries  should include those with a history  of failing to prevent \n export-controlled chips and other US-developed IP from being diverted into, or used by \n Tier III co  untries. Here, the commercial diplomacy  strategy should still seek to expand \n US market share, but should do so more carefully, including by levying stronger controls \n on the export of US-developed AI infrastructure. At the same time, the strategy should \n provide transparent pathways for Tier II countries to reach Tier I status by adopting \n democratic AI principles and more effectively managing risks of chip diversion. \n\n To expand American market share in Tier II countries, in addition to the steps above, the \n commercial diplomacy policy could be designed to leverage commercial interest in \n American-led AI in order to encourage investment in the US, enhanced security \n procedures, and encourage more countries to build on American rails: \n\n \u25cf  Establish a transparent process to evaluate countries\u2019 readiness to transition from \n Tier II to Tier I. \n\n \u25cf  Support countries\u2019 transition from Tier II to Tier I by helping Tier II governments \n strengthen their in-country security programs. \n\n \u25cf  Encourage greater economic interdependence between the US and Tier II \n countries. \n\n \u25cf  Incentivize public-private partnerships to rapidly mature, scale, and commercialize \n hardware-enabled mechanisms that could enhance in-country security controls in \n the future. \n\n To protect the American-developed IP needed to operate data centers in Tier II countries, \n and to manage both the heightened risk of IP theft and the additional risk that \n export-controlled chips might be diverted from Tier II into Tier III countries, the \n commercial diplomacy policy also could: \n\n \u25cf  Allow the export of advanced AI chips to an end-user located in a Tier II country \n that meets Tier I security requirements, and that puts in place additional corporate \n governance controls as well as technology-enhanced protections (e.g., \n hardware-enabled mechanisms) against the diversion of export-controlled chips. \n\n Tier III countries  \u2014including the PRC and any other  country subject to a US arms \n embargo\u2014s  hould continue to be subject to strict export  controls of AI systems, including \n existing export controls on advanced chips. The strategy could also expand established \n controls, for example, to include advanced chips that are required for large-scale \n\n 9 \n\n\n\n inference and RL training and the components used to manufacture advanced AI chips \n and data centers. \n\n 3. Copyright: Promoting the Freedom to Learn \n\n American copyright law, including the longstanding fair use doctrine, protects the \n transformative uses of existing works, ensuring that innovators have a balanced and \n predictable framework for experimentation and entrepreneurship. This approach has \n underpinned American success through earlier phases of technological progress and is \n even more critical to continued American leadership on AI in the wake of recent events in \n the PRC. OpenAI\u2019s models are trained to not replicate works for consumption by the \n public. Instead, they learn from the works and extract patterns, linguistic structures, and \n contextual insights. This means our AI model training aligns with the core objectives of \n copyright and the fair use doctrine, using existing works to create something wholly new \n and different without eroding the commercial value of those existing works. \n\n America has so many AI startups, attracts so much investment, and has made so many \n research breakthroughs largely because the fair use doctrine promotes AI development. \n In other markets, rigid copyright rules are repressing innovation and investment. \n\n The European Union, for one, has created \u201ctext and data mining exceptions\u201d with broadly \n applicable \u201copt-outs\u201d for any rights holder\u2014meaning access to important AI inputs is less \n predictable and likely to become more difficult as the EU\u2019s regulations take shape. \n Unpredictable availability of inputs hinders AI innovation, particularly for smaller, newer \n entrants with limited budgets. \n\n The UK government is currently considering changes to its copyright regime. It has \n indicated that it prefers creating a data mining exception that allows rights holders to \n \u201creserve their rights,\u201d creating the same regulatory barriers to AI development that we \n see in the EU. \n\n Applying the fair use doctrine to AI is not only a matter of American competitiveness \n \u2014it\u2019s a matter of national security. The rapid advances seen with the PRC\u2019s DeepSeek, \n among other recent developments, show that America\u2019s lead on frontier AI is far from \n guaranteed. Given concerted state support for critical industries and infrastructure \n projects, there\u2019s little doubt that the PRC\u2019s AI developers will enjoy unfettered access to \n data\u2014including copyrighted data\u2014that will improve their models.  If the PRC\u2019s \n developers have unfettered access to data and American companies are left without fair \n use access, the race for AI is effectively over. America loses, as does the success of \n\n 10 \n\n\n\n democratic AI  .  Ultimately, access to more data from the widest possible range of sources \n will ensure more access to more powerful innovations that deliver even more knowledge. \n\n We propose that the US government take steps to ensure that our copyright system \n continues to support American AI leadership and American economic and national \n security, including by: \n\n \u25cf  Shaping international policy discussions around copyright and AI, and working to \n prevent less innovative countries from imposing their legal regimes on American \n AI firms and slowing our rate of progress. \n\n \u25cf  Actively assessing the overall level of data available to American AI firms and \n determining whether other countries are restricting American companies\u2019 access \n to data and other critical inputs. \n\n \u25cf  Encouraging more access to government-held or government-supported data. \n This would boost AI development in any case, but would be particularly important \n if shifting copyright rules restrict American companies\u2019 access to training data. \n\n \u25cf  Monitoring domestic policy debates and ongoing litigation, and weighing in where \n fundamental, pro-innovation principles are at risk. \n\n Generative AI models represent the next frontier of innovation, poised to revolutionize \n the private and public sectors, improving healthcare, education, scientific research, and \n so much more. If AI innovation remains protected under longstanding copyright \n principles, America will maintain and strengthen its role as the world leader in \n cutting-edge technologies and remain positioned to continue championing AI based on \n democratic principles with countries around the world. \n\n 4. Infrastructure: Seizing the Opportunity to Drive Growth \n\n Today, hundreds of billions of dollars in global funds are waiting to be invested in AI \n infrastructure. If the US doesn't move fast to channel these resources into projects that \n support democratic AI ecosystems around the world, the funds will flow to projects \n backed and shaped by the CCP. \n\n We propose a foundational strategy to ensure that investment in infrastructure drives \n economic growth that benefits all Americans; maximizes access to AI; and protects \n national security interests by keeping sensitive American data on American soil. This \n includes policies and initiatives that encourage rather than stifle developers; support  a \n thriving AI-ready workforce and  ecosystems of labs,  start-ups and larger companies; and \n secure America\u2019s leadership on AI into the future. \n\n 11 \n\n\n\n First and foremost, building data centers is capital-intensive, particularly for newcomers \n seeking to compete against established hyperscalers with vast resources.  W  e support \n the solutions already proposed by this Administration  to ensure that sufficient capital \n flows to building AI infrastructure in the US: \n\n \u25cf  Investment vehicles like a Sovereign Wealth Fund  . \n \u25cf  Government offtake and guarantees tha  t both provide  the government with the \n\n compute it needs and signal to markets that the demand will be there for \n American-developed AI. \n\n \u25cf  Tax credits, loans, and other vehicles the US government can direct to provide \n credit enhancement. \n\n We also have proposed: \n\n A National Transmission Highway Act  , as ambitious  as the 1956 National Interstate and \n Defense Highways Act, to expand transmission, fiber connectivity, and natural gas \n pipeline construction. The process for obtaining the \u201cthree Ps\u201d\u2014planning, permitting, and \n paying for approvals from federal, state, local, and tribal authorities\u2014disadvantages \n America\u2019s AI industry. Transmission lines can take 10 years or more to complete. When \n lines are built, parties must agree on which customers pay higher electrical bills to bear \n the cost of construction. In this process, delays often affect the build-out of transmission \n lines. Streamlining these processes and eliminating redundancies would significantly \n speed up infrastructure projects, keeping America\u2019s AI sector globally competitive and \n securing a future of reliable, affordable energy. \n\n Digitizing government data currently in analog form.  A lot of government data is in the \n public domain. Making it more accessible or machine-readable could help American AI \n developers of all sizes, especially those working in fields where vital data is often \n government-held. In exchange, developers using this data could work with governments \n to unlock new insights that help it develop better public policies. For example, \n government agencies can build on the work of the US National Archives and Records \n Administration in using Optical Character Recognition for text searchability and AI-driven \n metadata tagging. \n\n A Compact for AI  among US allies and partner nations  that streamlines access to capital \n and supply chains in ways that support AI infrastruc  ture  and a robust AI ecosystem. \n Participating countries would also agree to some common standards to safeguard data \n centers and the technology. Over time, this collaboration could expand to a global \n network of US allies and partners that would compete with the  PRC\u2019s  AI infrastructure \n alliances while also strengthening security through shared standards. \n\n 12 \n\n\n\n AI Economic Zones  ,  created by local, state and the federal government together with \n industry, that speed up the permitting for building AI infrastructure like new solar arrays, \n wind farms, and nuclear reactors.  This could include  creating categorical exclusions to \n the National Environmental Policy Act, such as a national security waiver given the \n global competition for AI leadership. These zones could also build on the first Trump \n Administration\u2019s \u201cOpportunity Zones\u201d through tax incentives or credit enhancements in \n order to encourage private capital investment. \n\n A nationwide AI Readiness Strategy  \u2014rooted in local  communities in partnership with \n American companies\u2014to help our current workforce and students become AI-ready, \n bolster the economy, and secure America\u2019s continued leadership on innovation. \n Maintaining American leadership in AI means ensuring we have an experienced, trained \n professional workforce working across the AI supply chain, including construction worker \n management, HVAC technicians, and electricians. Government should ensure this \n training is accessible and affordable, such as by: \n\n \u25cf  At the federal level, expanding 529 savings plans to cover more AI supply \n chain-related training programs\u2014including for construction, HVAC technicians, \n electricians, as well as AI researchers and developers\u2014by amending Section 529 \n of the Internal Revenue Code or broadening the SECURE Act\u2019s provisions. \n\n \u25cf  At the federal or state level, incentivizing AI supply chain companies to work with \n a backbone organization to understand the workforce needs of AI supply chain \n companies, develop a pipeline of training programs that help companies meet \n those needs, and coordinate with labor unions, community colleges, and trade \n associations to build and operate that training pipeline. \n\n Creation of AI research labs and workforces aligned with key local industries  by requiring \n AI companies to provide meaningful amounts of compute to public universities to \n equitably scale the training of a homegrown AI-skilled workforce. For example, one state \n could establish a hub dedicated to applying AI in agriculture while another develops \n centers focused on integrating AI into power production and grid resilience. \n\n Using the Defense Production Act (DPA) Title I  to  manage supply chain risk by \n designating gas turbines, rankine cycle turbines, high-voltage transformers, or \n switchgear for data centers as \u201crated orders.\u201d This prioritization could significantly \n shorten timelines for data center power i  nfrastructure  projects. \n\n 13 \n\n\n\n 5. Government Adoption of AI: Leading by Example \n\n AI adoption in federal departments and agencies remains unacceptably low, with federal \n employees, and especially national security sector employees, largely unable to harness \n the benefits of the technology. \n\n The government should encourage public-private partnerships to enhance government \n AI adoption by removing known blockers to the adoption of AI tools, including outdated \n and lengthy accreditation processes, restrictive testing authorities, and inflexible \n procurement pathways. Specifically, we recommend: \n\n \u25cf  Modernizing cyber security rules for cloud-based applications.  The government\u2019s \n current processes for AI providers to comply with federal security \n regulations\u2014primarily through the Federal Risk and Authorization Management \n Program (FedRAMP)\u2014takes 12 to 18 months, compared to the one- to \n three-month commercial standard, with no clear evidence of additional protection \n for government data. The government should modernize FedRAMP by \n establishing a faster, criteria-based path for approval of AI tools. Criteria could \n include Foreign Ownership, Control, or Influence (FOCI) approval; Facilities \n Clearance (FCL) status; US incorporation; a first-party AI model that ranks in the \n top 20 of a recognized evaluation framework (for example, MMLU, or Massive \n Multitask Language Understanding); SOC 2 (System and Organization Controls 2) \n accreditation; and a recent third-party penetration test with all findings addressed. \n\n \u25cf  Accelerating AI testing and experimentation.  The government  should allow federal \n agencies to test and experiment with real data using commercial-standard \n practices\u2014such as SOC 2 or International Organization for Standardization (ISO) \n audit reports\u2014and potentially grant a temporary waiver for FedRAMP. AI vendors \n would still be required to meet FedRAMP continuous monitoring requirements \n while awaiting full accreditation. Combined with standard due diligence before \n actual use, this approach could allow agencies to access new AI services roughly \n 12 months earlier while maintaining compliance with federal security \n requirements. \n\n \u25cf  Enabling rapid procurement mechanisms.  Once new security  and testing \n approaches are in place, agencies must also have quicker, more direct routes to \n procure and deploy frontier AI tools. The government should continue to evaluate \n Other Transactional Authorities (OTAs), Commercial Service Offerings (CSO) or \n other procurement paths in order to access technology from frontier AI labs, not \n just their legacy IT providers. We are encouraged by the Department of Defense\u2019s \n recent efforts to  Modernize Software Acquisition  . \n\n 14 \n\nhttps://www.defense.gov/News/Transcripts/Transcript/Article/4113458/directing-modern-software-acquisition-to-maximize-lethality-memo-background-bri/\n\n\n Enabling federal agencies to quickly acquire consumer-focused models is not enough, \n however. The government also needs to pursue and fund bespoke national security pilot \n projects for which there may be no commercial market by: \n\n \u25cf  Partnering with industry to develop custom models for national security.  The \n government needs models trained on classified datasets that are fine-tuned to be \n exceptional at national security tasks for which there is no commercial \n market\u2014such as geospatial intelligence or classified nuclear tasks. This will likely \n require on-premises deployment of model weights and access to significant \n compute, given the security requirements of many national security agencies. \n\n \u25cf  Acting now to fund these projects and secure this compute  \u2014enabling industry \n partners to secure chips, transformers, and begin construction, and ensuring that \n this compute comes online at the pace that innovation and geopolitical \n competition require. \n\n Lastly, frontier AI labs need Facility Clearances (FCL) to work directly with the national \n security enterprise on these pilot projects and custom models. The government should: \n\n \u25cf  Expedite FCL for frontier AI labs committed to supporting national security.  The \n process for obtaining a FCL can take a year or longer. Given the rapid pace of AI \n development, the government should start prioritizing deeper collaboration with \n frontier AI labs as soon as possible. \n\n We look forward to discussing the above proposals with the Office of Science and \n Technology Policy as we continue to build on our relationship with the US government \n and work toward AI that benefits everyone. \n\n About OpenAI \n OpenAI\u2019s mission is to ensure that as AI advances, it benefits everyone. We're building AI to help \n people solve hard problems because by helping with the hard problems, AI can benefit the most \n people possible\u2014through more scientific discoveries, better healthcare and education, and \n improved productivity. We\u2019re off to a strong start, creating freely available intelligence being used \n by more than 400 million people around the world, including 3 million developers. We believe AI \n will scale human ingenuity and drive unprecedented economic growth and new freedoms that \n help people accomplish what we can't even imagine today. \n\n 15 \n\n\n","cloud_doc_url":null}],"message_type":null,"model_slug":"gpt-4-5","default_model_slug":"gpt-4-5","parent_id":"5aa674a5-49fa-4180-b1df-4d977c6e941e","request_id":"92148491eb229e46-SIN","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"5aa674a5-49fa-4180-b1df-4d977c6e941e","children":[]}}}