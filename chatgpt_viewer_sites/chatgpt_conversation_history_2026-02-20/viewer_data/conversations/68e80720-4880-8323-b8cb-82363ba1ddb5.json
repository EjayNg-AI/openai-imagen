{"id":"68e80720-4880-8323-b8cb-82363ba1ddb5","title":"Reasoning model prompting guide","create_time":1760036641.240942,"update_time":1760064738.771857,"current_node":"f98d9726-e917-4360-9b93-3ed1806527ad","mapping":{"client-created-root":{"id":"client-created-root","message":null,"parent":null,"children":["116f6e83-8026-4fb6-b5d6-30a998298b47"]},"116f6e83-8026-4fb6-b5d6-30a998298b47":{"id":"116f6e83-8026-4fb6-b5d6-30a998298b47","message":{"id":"116f6e83-8026-4fb6-b5d6-30a998298b47","author":{"role":"system","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":true,"weight":0.0,"metadata":{"is_visually_hidden_from_conversation":true,"can_save":false},"recipient":"all","channel":null},"parent":"client-created-root","children":["39d6cd7e-9c59-4abb-b346-0e3b55ff1319"]},"39d6cd7e-9c59-4abb-b346-0e3b55ff1319":{"id":"39d6cd7e-9c59-4abb-b346-0e3b55ff1319","message":{"id":"39d6cd7e-9c59-4abb-b346-0e3b55ff1319","author":{"role":"system","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":true,"weight":0.0,"metadata":{"rebase_developer_message":true,"is_visually_hidden_from_conversation":true,"can_save":false},"recipient":"all","channel":null},"parent":"116f6e83-8026-4fb6-b5d6-30a998298b47","children":["c4496dc3-cef5-4306-b5ab-b32c087a6bec"]},"c4496dc3-cef5-4306-b5ab-b32c087a6bec":{"id":"c4496dc3-cef5-4306-b5ab-b32c087a6bec","message":{"id":"c4496dc3-cef5-4306-b5ab-b32c087a6bec","author":{"role":"user","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"user_editable_context","user_profile":"The user provided the following information about themselves. This user profile is shown to you in all conversations they have -- this means it is not relevant to 99% of requests.\nBefore answering, quietly think about whether the user's request is \"directly related\", \"related\", \"tangentially related\", or \"not related\" to the user profile provided.\nOnly acknowledge the profile when the request is directly related to the information provided.\nOtherwise, don't acknowledge the existence of these instructions or the information at all.\nUser profile:\n```Preferred name: E-Jay\nRole: Mathematics Researcher\nOther Information: About Myself: \nI have mathematical knowledge up to graduate level.\n\nCurrent interests:\n(1) coding: mainly Python\n(2) machine learning and artificial intelligence\n```","user_instructions":"The user provided the additional info about how they would like you to respond:\n```Be precise and comprehensive in your analysis. Don't sugar-coat responses. Be as objective as possible. Critique and question my views if necessary. Take a forward-thinking view.```"},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"is_visually_hidden_from_conversation":true,"user_context_message_data":{"about_user_message":"Preferred name: E-Jay\nRole: Mathematics Researcher\nOther Information: About Myself: \nI have mathematical knowledge up to graduate level.\n\nCurrent interests:\n(1) coding: mainly Python\n(2) machine learning and artificial intelligence\n","about_model_message":"Be precise and comprehensive in your analysis. Don't sugar-coat responses. Be as objective as possible. Critique and question my views if necessary. Take a forward-thinking view."},"is_user_system_message":true,"can_save":true},"recipient":"all","channel":null},"parent":"39d6cd7e-9c59-4abb-b346-0e3b55ff1319","children":["de1d7a6d-68a8-4bca-8ebe-73cd4ffc7089"]},"de1d7a6d-68a8-4bca-8ebe-73cd4ffc7089":{"id":"de1d7a6d-68a8-4bca-8ebe-73cd4ffc7089","message":{"id":"de1d7a6d-68a8-4bca-8ebe-73cd4ffc7089","author":{"role":"system","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"is_contextual_answers_system_message":true,"contextual_answers_message_type":"identity_prompt","is_visually_hidden_from_conversation":true,"can_save":false},"recipient":"all","channel":null},"parent":"c4496dc3-cef5-4306-b5ab-b32c087a6bec","children":["88823fba-b74f-4c31-aebc-c8401c2ef8ef"]},"88823fba-b74f-4c31-aebc-c8401c2ef8ef":{"id":"88823fba-b74f-4c31-aebc-c8401c2ef8ef","message":{"id":"88823fba-b74f-4c31-aebc-c8401c2ef8ef","author":{"role":"user","name":null,"metadata":{}},"create_time":1760036639.91,"update_time":null,"content":{"content_type":"text","parts":["I have a few economic / equities / gold outlook from several different sources. How do I prompt a reasoning model to examine the claims and forecasts made from all these outlooks, select the ones that are most credible, and write a coherent vision drawing the best analysis from the different sources?"]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"developer_mode_connector_ids":[],"selected_sources":[],"selected_github_repos":[],"serialization_metadata":{"custom_symbol_offsets":[]},"request_id":"98c024293a2ac8b5-SIN","message_source":null,"turn_exchange_id":"41f780c0-726a-44d7-8548-a80a8cf3ae87","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"de1d7a6d-68a8-4bca-8ebe-73cd4ffc7089","children":["c900a62d-440c-47be-80c9-469f29ea7a11"]},"c900a62d-440c-47be-80c9-469f29ea7a11":{"id":"c900a62d-440c-47be-80c9-469f29ea7a11","message":{"id":"c900a62d-440c-47be-80c9-469f29ea7a11","author":{"role":"system","name":null,"metadata":{}},"create_time":1760036641.0954268,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"is_contextual_answers_system_message":true,"is_visually_hidden_from_conversation":true,"command":"prompt","contextual_answers_message_type":"sources_and_filters_prompt","request_id":"98c024293a2ac8b5-SIN","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"standard","parent_id":"88823fba-b74f-4c31-aebc-c8401c2ef8ef","turn_exchange_id":"41f780c0-726a-44d7-8548-a80a8cf3ae87","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"88823fba-b74f-4c31-aebc-c8401c2ef8ef","children":["df7249f0-11fa-4e66-b1c4-61bb6abcdd77"]},"df7249f0-11fa-4e66-b1c4-61bb6abcdd77":{"id":"df7249f0-11fa-4e66-b1c4-61bb6abcdd77","message":{"id":"df7249f0-11fa-4e66-b1c4-61bb6abcdd77","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1760036641.4044647,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"request_id":"98c024293a2ac8b5-SIN","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"standard","parent_id":"c900a62d-440c-47be-80c9-469f29ea7a11","turn_exchange_id":"41f780c0-726a-44d7-8548-a80a8cf3ae87","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"c900a62d-440c-47be-80c9-469f29ea7a11","children":["72ac9132-477c-40be-a986-59e74a7f037f"]},"72ac9132-477c-40be-a986-59e74a7f037f":{"id":"72ac9132-477c-40be-a986-59e74a7f037f","message":{"id":"72ac9132-477c-40be-a986-59e74a7f037f","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1760036642.190312,"update_time":null,"content":{"content_type":"thoughts","thoughts":[{"summary":"Creating a reliable framework","content":"We need to design a framework for synthesizing data from multiple sources. The user seeks a precise, comprehensive, and objective output. I'll create a cross-model prompt template, define evidence scoring, and use a rubric to evaluate credibility. Also, I'll recommend using reasoned summaries with evidence and set up checks for probabilistic forecasts and claim extraction. The format should prevent errors like hallucinations.","chunks":[],"finished":true},{"summary":"Building a structured framework","content":"I need to develop ready-to-use prompts for both system and user, along with function calls or tags. There should be an evaluation protocol, a clear output structure (with summaries, uncertainties, etc.), and credibility scoring. I'll need to include instructions for avoiding fabrication, citing sources, and calculating confidence. A concise code example for aggregation might be useful.","chunks":[],"finished":true}],"source_analysis_msg_id":"da771765-35a3-41f7-88d4-f167f7eb5c1d"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"is_reasoning","citations":[],"content_references":[],"classifier_response":"default","skip_reasoning_title":"Skip","request_id":"98c024293a2ac8b5-SIN","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"standard","parent_id":"df7249f0-11fa-4e66-b1c4-61bb6abcdd77","turn_exchange_id":"41f780c0-726a-44d7-8548-a80a8cf3ae87","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"df7249f0-11fa-4e66-b1c4-61bb6abcdd77","children":["b0ad77d4-49fc-42d6-b8b7-6f4081104306"]},"b0ad77d4-49fc-42d6-b8b7-6f4081104306":{"id":"b0ad77d4-49fc-42d6-b8b7-6f4081104306","message":{"id":"b0ad77d4-49fc-42d6-b8b7-6f4081104306","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1760036673.526172,"update_time":null,"content":{"content_type":"reasoning_recap","content":"Thought for 31s"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"reasoning_ended","finished_duration_sec":31,"request_id":"98c024293a2ac8b5-SIN","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"standard","parent_id":"72ac9132-477c-40be-a986-59e74a7f037f","turn_exchange_id":"41f780c0-726a-44d7-8548-a80a8cf3ae87","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"72ac9132-477c-40be-a986-59e74a7f037f","children":["f98d9726-e917-4360-9b93-3ed1806527ad"]},"f98d9726-e917-4360-9b93-3ed1806527ad":{"id":"f98d9726-e917-4360-9b93-3ed1806527ad","message":{"id":"f98d9726-e917-4360-9b93-3ed1806527ad","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1760036673.339382,"update_time":1760036760.955626,"content":{"content_type":"text","parts":["Great question. Here\u2019s a battle-tested prompting kit you can drop into any reasoning model to grade multiple outlooks, pick the credible bits, and synthesize a coherent view\u2014without eliciting chain-of-thought in the output.\n\n---\n\n# 1) System message (paste as the model\u2019s system/developer prompt)\n\nYou are an evidence-weighted synthesis analyst. Your job is to:\n- Ingest multiple macro/equities/gold outlooks.\n- Extract **atomic, testable claims** with time horizons.\n- **Score credibility** per claim using a transparent rubric.\n- **Cross-validate** across sources and data.\n- Produce a **coherent, scenario-based forecast** with probabilities, drivers, and falsification criteria.\n\n**Operating rules**\n1) Use only the content provided by the user plus widely accepted base rates if explicitly supplied. No outside speculation or invented facts. If critical info is missing, state the gap.\n2) Distinguish **facts, assumptions, and inferences**. Mark each clearly.\n3) Quantify forecasts: probabilities (0\u20131), ranges with units, and time horizons with calendar dates.\n4) Prefer **falsifiable** statements (measurable by a future date).\n5) Cite **verbatim snippets** (\u226425 words) with source ID + location for every non-obvious claim used.\n6) Reason privately; **do not reveal chain-of-thought**. Output only the requested structured artifacts and concise justifications with citations.\n7) Be adversarial with weak arguments: identify logical gaps, selection bias, omitted variables, and data leakage.\n8) Be consistent: if claims conflict, show both, score both, and explain the reconciliation.\n\n**Credibility rubric (per claim, 0\u20135 each; compute weighted score 0\u2013100)**\n- R1: **Evidence quality** (data recency, primary vs secondary, sample size, methodology clarity) \u2013 weight 25\n- R2: **Track record** (source hit rate on similar past calls, if provided) \u2013 weight 20\n- R3: **Causal coherence** (mechanism matches known relationships; e.g., real rates \u2194 gold) \u2013 weight 20\n- R4: **Corroboration** (independent sources agree) \u2013 weight 15\n- R5: **Specificity/Falsifiability** (clear metric, threshold, date) \u2013 weight 15\n- R6: **Conflict/Incentives** (promotional bias, talking their book) \u2013 weight 5 (reverse-scored)\n\n**Aggregation rule**\n- Convert directional claims to **log-odds**, weight by normalized credibility, pool (weighted average), convert back to probability. For numeric targets, use credibility-weighted trimmed mean; show 50/75/90% bands.\n\n**Output contract**\nReturn (A) a machine-readable JSON block (schema below), then (B) a concise prose synthesis (\u2264800 words), then (C) a \u201cwatchlist\u201d of leading indicators and tripwires with dates.\n\n**Schema**\n```json\n{\n  \"metadata\": {\n    \"as_of_date\": \"YYYY-MM-DD\",\n    \"universe\": [\"equities\", \"gold\", \"rates\", \"fx\", \"growth\", \"inflation\"]\n  },\n  \"claims\": [\n    {\n      \"id\": \"C001\",\n      \"source_id\": \"S2\",\n      \"topic\": \"gold\",\n      \"horizon\": {\"start\":\"2025-10-10\",\"end\":\"2027-01-20\"},\n      \"statement\": \"Gold will exceed $2,800/oz if US 10y TIPS < 0.5%.\",\n      \"type\": \"conditional-forecast\",\n      \"verbatim_cite\": \"\u2026\",\n      \"credibility\": {\n        \"R1\": 4, \"R2\": 3, \"R3\": 5, \"R4\": 3, \"R5\": 4, \"R6\": 1,\n        \"score\": 82\n      },\n      \"directional_probability\": 0.62,\n      \"numeric_target\": {\"metric\": \"XAUUSD\", \"p50\": 2600, \"p75\": 2850, \"p90\": 3200}\n    }\n  ],\n  \"conflicts\": [{\"claim_ids\": [\"C003\",\"C014\"], \"explanation\": \"\u2026\"}],\n  \"aggregate\": {\n    \"scenarios\": [\n      {\"name\":\"Soft-landing\",\"prob\":0.44,\"drivers\":[\"\u2026\"],\"implications\":{\"SPX\":\"p50 5400\",\"XAUUSD\":\"p50 2450\"}},\n      {\"name\":\"Re-accel inflation\",\"prob\":0.23,\"drivers\":[\"\u2026\"],\"implications\":{\"SPX\":\"p50 4800\",\"XAUUSD\":\"p50 2900\"}},\n      {\"name\":\"Hard-landing\",\"prob\":0.20,\"drivers\":[\"\u2026\"],\"implications\":{\"SPX\":\"p50 4200\",\"XAUUSD\":\"p50 2350\"}},\n      {\"name\":\"Left-tail geopolitics\",\"prob\":0.13,\"drivers\":[\"\u2026\"],\"implications\":{\"SPX\":\"p50 3900\",\"XAUUSD\":\"p50 3200\"}}\n    ],\n    \"key_uncertainties\": [\"term premium path\",\"CB gold demand\",\"China growth\"]\n  },\n  \"watchlist\": [\n    {\"indicator\":\"10y TIPS\",\"threshold\":\"<0.5% for 4 weeks\",\"action\":\"upgrade gold prob +6pp\",\"next_review_by\":\"2025-12-15\"},\n    {\"indicator\":\"CFTC gold net longs\",\"threshold\":\">+250k\",\"action\":\"trim p75 target -3%\",\"next_review_by\":\"2025-11-30\"}\n  ]\n}\n```\n\n---\n\n# 2) User prompt template (what you feed alongside the PDFs/notes/links)\n\nAnalyze the following outlook documents on macro, equities, and gold.  \n**Tasks**  \n1) Extract atomic, testable claims with horizons and metrics.  \n2) Score each claim with the **Credibility rubric** (R1\u2013R6) and compute the 0\u2013100 score.  \n3) Reconcile disagreements; keep both sides but explain which is stronger and why.  \n4) Produce 3\u20135 **scenarios** with probabilities and asset implications (SPX, NDX, RTY, XAUUSD, DXY, 10y UST, 10y TIPS).  \n5) Give numeric targets with 50/75/90% bands for 12\u201336 months.  \n6) Provide a **watchlist** of leading indicators and dated tripwires to update probabilities.  \n7) Cite verbatim (\u226425 words) with source IDs + page/section for every non-obvious claim.  \n8) Output exactly in the **Schema** mandated by the system message, followed by a concise prose synthesis.  \n**Inputs**  \n- Source S1: <title/URL or file + brief note>  \n- Source S2: \u2026  \n- Source S3: \u2026  \n**Base rates & priors (use only if helpful)**  \n- Long-run US real GDP growth 1.5\u20132.0% y/y, CPI 2\u20132.5% (adjust if sources provide better).  \n- Gold macro drivers: real rates (10y TIPS), USD broad index, CB net purchases, ETF flows, mining supply disruptions.\n\n**Important**  \n- Do not reveal chain-of-thought; provide scored justifications, citations, and the final JSON + prose only.  \n- If a required field can\u2019t be filled, include it with `\"null\"` and add a \u201cData gap\u201d note.\n\n---\n\n# 3) Paste-ready **rubric card** (you can include it inline or as an attachment)\n\n**Per-claim scoring guide**\n- **R1 Evidence quality (0\u20135):** 0=anecdote; 3=public data w/ method; 5=replicable model & robust dataset \u22646 months old.  \n- **R2 Track record (0\u20135):** 0=unknown/poor; 3=mixed; 5=audited hit rate >60% on similar horizons.  \n- **R3 Causal coherence (0\u20135):** 0=hand-wavy; 3=plausible; 5=mechanism consistent with literature (e.g., real rates \u2193 \u2192 gold \u2191).  \n- **R4 Corroboration (0\u20135):** 0=isolated; 3=some support; 5=independent convergence.  \n- **R5 Specificity/Falsifiability (0\u20135):** 0=vague; 3=direction + rough date; 5=metric+threshold+date.  \n- **R6 Conflict/Incents (0\u20135, reverse):** 0=clear alignment risk; 5=none/fully disclosed.\n\n`score = 25*R1 + 20*R2 + 20*R3 + 15*R4 + 15*R5 + 5*(5-R6)` \u2192 0\u2013100\n\n---\n\n# 4) Minimal example you can show the model\n\n**Inputs:**  \nS1 (bank research, 2025-09): \u201cIf core PCE < 2.2% by Q2-2026, Fed cuts to 3.25\u20133.5%.\u201d  \nS2 (gold desk, 2025-08): \u201cGold to 3,000 in 2026 if 10y TIPS stays <1% and EM CB buying persists.\u201d  \nS3 (fund letter, 2025-09): \u201cEarnings recession inevitable in 2026.\u201d\n\n**Expected (abridged) JSON \u2192 prose**  \n- Claims C001\u2013C003 with horizons, citations, scores (e.g., C002 score 78).  \n- Scenario set with pooled probabilities and asset bands.  \n- Watchlist: 10y TIPS, CB net purchases (WGC), S&P EPS revisions.\n\n---\n\n# 5) Practical tips (so the model doesn\u2019t go off the rails)\n\n- **Give source IDs and page pointers** upfront (e.g., S1 p.4-6), and ask for **verbatim snippets** to reduce paraphrase drift.  \n- **Bound the horizon** (e.g., \u201c12\u201336 months ending 2027-01-20\u201d).  \n- **Demand units** for every numeric (bps, %, $/oz).  \n- **Force nulls over guesses.** The schema rule makes hallucinations obvious.  \n- **Ask for a conflict table.** It prevents quiet cherry-picking.  \n- **Require watchlist tripwires with dates**\u2014that turns the synthesis into an updating process, not a one-off essay.\n\n---\n\n# 6) Optional: one-line aggregator you can reuse later\n\n\u201cRe-ingest your prior JSON, update each claim\u2019s R1 (recency) and R4 (corroboration) using the watchlist data since `<date>`, recompute weights, refresh scenario probabilities, and output diff-style changes with reasons.\u201d\n\n---\n\nIf you\u2019d like, share 2\u20133 of your sources (titles + short notes). I\u2019ll run them through this framework and show you a worked example with scores, pooled probabilities, and a clean synthesis."]},"status":"finished_successfully","end_turn":true,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200002]},"is_complete":true,"citations":[],"content_references":[],"request_id":"98c024293a2ac8b5-SIN","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"standard","parent_id":"b0ad77d4-49fc-42d6-b8b7-6f4081104306","turn_exchange_id":"41f780c0-726a-44d7-8548-a80a8cf3ae87","timestamp_":"absolute","can_save":true},"recipient":"all","channel":"final"},"parent":"b0ad77d4-49fc-42d6-b8b7-6f4081104306","children":[]}}}