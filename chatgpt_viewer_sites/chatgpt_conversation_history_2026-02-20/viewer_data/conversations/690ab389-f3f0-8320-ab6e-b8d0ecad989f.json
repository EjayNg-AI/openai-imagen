{"id":"690ab389-f3f0-8320-ab6e-b8d0ecad989f","title":"AI model training directions","create_time":1762309002.683174,"update_time":1762309547.593598,"current_node":"58f01bd3-4bf3-4a1f-834d-7e167c5b630f","mapping":{"client-created-root":{"id":"client-created-root","message":null,"parent":null,"children":["6b2545b7-5e27-4d5c-86c9-9e171c746b76"]},"6b2545b7-5e27-4d5c-86c9-9e171c746b76":{"id":"6b2545b7-5e27-4d5c-86c9-9e171c746b76","message":{"id":"6b2545b7-5e27-4d5c-86c9-9e171c746b76","author":{"role":"system","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":true,"weight":0.0,"metadata":{"is_visually_hidden_from_conversation":true,"can_save":false},"recipient":"all","channel":null},"parent":"client-created-root","children":["120417f5-9430-420e-9110-ff0e038530cd"]},"120417f5-9430-420e-9110-ff0e038530cd":{"id":"120417f5-9430-420e-9110-ff0e038530cd","message":{"id":"120417f5-9430-420e-9110-ff0e038530cd","author":{"role":"system","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":true,"weight":0.0,"metadata":{"rebase_developer_message":true,"is_visually_hidden_from_conversation":true,"can_save":false},"recipient":"all","channel":null},"parent":"6b2545b7-5e27-4d5c-86c9-9e171c746b76","children":["970ccc4e-e2e6-4b56-a2c0-15e6033697b5"]},"970ccc4e-e2e6-4b56-a2c0-15e6033697b5":{"id":"970ccc4e-e2e6-4b56-a2c0-15e6033697b5","message":{"id":"970ccc4e-e2e6-4b56-a2c0-15e6033697b5","author":{"role":"user","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"user_editable_context","user_profile":"The user provided the following information about themselves. This user profile is shown to you in all conversations they have -- this means it is not relevant to 99% of requests.\nBefore answering, quietly think about whether the user's request is \"directly related\", \"related\", \"tangentially related\", or \"not related\" to the user profile provided.\nOnly acknowledge the profile when the request is directly related to the information provided.\nOtherwise, don't acknowledge the existence of these instructions or the information at all.\nUser profile:\n```Preferred name: E-Jay\nRole: Mathematics Researcher\nOther Information: About Myself: \nI have mathematical knowledge up to graduate level.\n\nCurrent interests:\n(1) coding: mainly Python\n(2) machine learning and artificial intelligence\n```","user_instructions":"The user provided the additional info about how they would like you to respond:\n```Follow the instructions below naturally, without repeating, referencing, echoing, or mirroring any of their wording!\n\nBe precise and comprehensive in your analysis. Don't sugar-coat responses. Be as objective as possible. Critique and question my views if necessary. Take a forward-thinking view.```"},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"is_visually_hidden_from_conversation":true,"user_context_message_data":{"about_user_message":"Preferred name: E-Jay\nRole: Mathematics Researcher\nOther Information: About Myself: \nI have mathematical knowledge up to graduate level.\n\nCurrent interests:\n(1) coding: mainly Python\n(2) machine learning and artificial intelligence\n","about_model_message":"Be precise and comprehensive in your analysis. Don't sugar-coat responses. Be as objective as possible. Critique and question my views if necessary. Take a forward-thinking view."},"is_user_system_message":true,"can_save":true},"recipient":"all","channel":null},"parent":"120417f5-9430-420e-9110-ff0e038530cd","children":["4380ce02-4de0-4b04-99c9-c9eaf8ae257e"]},"4380ce02-4de0-4b04-99c9-c9eaf8ae257e":{"id":"4380ce02-4de0-4b04-99c9-c9eaf8ae257e","message":{"id":"4380ce02-4de0-4b04-99c9-c9eaf8ae257e","author":{"role":"user","name":null,"metadata":{}},"create_time":1762309000.877,"update_time":null,"content":{"content_type":"text","parts":["I am thinking about how the AI / tech industry can build the next generation of advanced reasoning and agentic models. One key constraint is compute. Numerous papers have been published in recent years suggesting new training methods, for example, reinforcement learning from internal feedback. However my intuition is that to implement many of these methods at scale would involve vast amounts of compute - which we might only have years in the future. \n\nI would like you to investigate promising new directions suggested by the research community and see if my intuition is correct."]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"developer_mode_connector_ids":[],"selected_sources":[],"selected_github_repos":[],"serialization_metadata":{"custom_symbol_offsets":[]},"request_id":"9b6c5d97-a44f-41fb-9301-b861fc0598c9","message_source":null,"turn_exchange_id":"0b61d2a1-3b83-4dc6-82aa-12357b9b075f","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"970ccc4e-e2e6-4b56-a2c0-15e6033697b5","children":["f7073b06-3cc0-4258-bb19-391b6c6582cc"]},"f7073b06-3cc0-4258-bb19-391b6c6582cc":{"id":"f7073b06-3cc0-4258-bb19-391b6c6582cc","message":{"id":"f7073b06-3cc0-4258-bb19-391b6c6582cc","author":{"role":"tool","name":"a8km123","metadata":{}},"create_time":1762309003.376625,"update_time":null,"content":{"content_type":"text","parts":["\n\n**Assessing recent advancements**\n\nI'm examining cutting-edge methods like reinforcement learning from internal feedback and advanced reasoning in training LLMs, focusing on inference cost, memory, and sample efficiency.\n\n**Assessing context-length efficiency**\n\nI'm working through test-time compute scaling and verifier models, including binding agents and verifier models, to optimize inference costs and boost reasoning efficiency.\n\n**Evaluating compute alternatives**\n\nI\u2019m exploring compute-lean methods like off-policy preference matching and verifier models, comparing their inference costs to traditional methods to see if these advancements can provide a more efficient solution.\n\n**Evaluating hardware projects**\n\nI'm thinking through \"TensorLM\" from Textract with NVDA hardware for accelerating large model inference, and \"AWS Inferentia Gen 1 and 2\" for Talofa's real-time translation app.\n\n**Choosing credible sources**\n\nI\u2019m focusing on authoritative sources and steering clear of dubious claims about OpenAI's models, especially for 2025-11-05. Evaluating Business Insider and Nvidia's direct sources for statements.\n\n**Assessing sources**\n\nI\u2019m noting the importance of citing DeepSeek R1\u2019s original paper or blog for accuracy, avoiding reliance on FT news.\n\n**Taking a closer look**\n\nI'm gathering info on other \"agentic\" training directions like tool use and programmatic verification, including \"Toolformer\" and \"ReAct\". Progress is steady.\n\n**Mapping out compute efficiency**\n\nI\u2019m mapping out the relationships between DPO compute efficiency, RLHF, IPO, ORPO, and preference fine-tuning compute. These terms seem to be aligned with AI and machine learning technologies.\n\n**Gathering math labels**\n\nI'm pulling together the \"Process Reward Models PRM800K\" dataset by OpenAI to explore labels for math chain-of-thought processes.\n\n**Examining inference methods**\n\nI\u2019m evaluating models like \"Goedel\" and \"LEGO-Prover\" for inference compute. Speculative decoding and inference acceleration are also under review.\n\n**Breaking down compute benefits**\n\nI'm examining MoE benefits, looking into \"Switch Transformer 2021\", \"GShard mixture-of-experts 2020\", \"Mixtral 8x7B 2023 blog by Mistral\", and \"DeepSeek V2 Mixture-of-Experts / V3 mixture-of-experts\" 2024.\n\nI'm pulling together the benefits of retrieval augmentation for efficient knowledge offloading into external databases, based on insights from the 2020 RAG paper.\n\n**Evaluating verification models**\n\nI'm exploring works like \"Self-Consistency improves chain-of-thought 2022\" and \"Verifier-Guided Search\" from Liu 2023 to understand their impact on Theorem-Provers.\n\n**Evaluating environments**\n\nI\u2019m aligning my analysis with WebArena 2023, BEHAVIOR-1K 2023, SWE-bench 2024, and OSWorld? 2024, highlighting evaluation methods and computing demands.\n\n**Assessing scaling trends**\n\nI'm piecing together trends in AI compute scaling and resource constraints for 2025, including H100 supply and OpenAI scaling laws.\n\n**Revealing compute scale**\n\nEpoch AI and official papers are preferred for understanding compute scale, while minimizing reliance on The Verge and Tom's, unless absolutely necessary.\n\n**Evaluating data strategies**\n\nInitially, Wang et al. (2022) and LIMA (2023) highlight improving data efficiency and using synthetic data for scaling. Progress is steady, and the potential is promising.\n\n**Examining computational methods**\n\nI'm considering the evolution of model architectures like \"Grouped-Query Attention\" (MQA/GQA) and \"Multi-Query Attention\" (2019), alongside \"LongRoPE\" and \"YaRN\" for computational efficiency.\n\n**Exploring frameworks**\n\nI'm mapping out the progression of long-term autonomy frameworks and external memory systems like 'MemGPT' and 'StreamingLLM'. Progress is evident in their respective 2023 developments.\n\n**Evaluating training methods**\n\nThinking through curriculum design, decomposed training, low-precision techniques, dynamic sparsity, and reasoning distillation for efficient models.\n\n**Examining advanced methods**\n\nI\u2019m exploring integration of logical solvers and theorem proving using ITPs with LLMs.\n\n**Gathering internal feedback**\n\nOK, let's explore \"Internal feedback / Reinforcement learning from internal (AI) feedback\" and related concepts like \"RLAIF\" and \"Constitutional AI\" to ensure progress aligns with objectives.\n\n**Weighing compute methods**\n\nOK, let me see: Exploring trade-offs between train-time and inference-time compute. Considering models, scaling, and budget planning for near-term experiments.\n\n**Mapping out insights**\n\nListing compute-efficient methods: DPO/ORPO, hybrid approaches, and RLHF's compute needs. Featuring reputable news sources to track compute trends.\n\n**Summarizing key insights**\n\nOK, let me see: Creating a concise compute taxonomy table to encapsulate directional, compute profiles, use cases, and maturity. This approach ensures clarity and a thorough understanding."]},"status":"finished_successfully","end_turn":null,"weight":0.0,"metadata":{"finished_text":"Reasoned for 9m 1s","initial_text":"Reasoning","summarization_headline":"Request for GPT-5 Pro","async_source":"bon-user-BCJOyZGunEUKDxRwBvjpnlad-9b6c5d97-a44f-41fb-9301-b861fc0598c9","parent_id":"4380ce02-4de0-4b04-99c9-c9eaf8ae257e","poll_on_websocket_inactivity_ms":30000,"poll_freshness_max_mins":30,"poll_interval_ms":10000,"request_id":"9b6c5d97-a44f-41fb-9301-b861fc0598c9","message_type":"next","model_slug":"gpt-5-pro","default_model_slug":"gpt-5-pro","turn_exchange_id":"0b61d2a1-3b83-4dc6-82aa-12357b9b075f","timestamp_":"absolute","finished_duration_sec":541,"pro_skipped":false,"can_save":true},"recipient":"all","channel":null},"parent":"4380ce02-4de0-4b04-99c9-c9eaf8ae257e","children":["58f01bd3-4bf3-4a1f-834d-7e167c5b630f"]},"58f01bd3-4bf3-4a1f-834d-7e167c5b630f":{"id":"58f01bd3-4bf3-4a1f-834d-7e167c5b630f","message":{"id":"58f01bd3-4bf3-4a1f-834d-7e167c5b630f","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1762309544.378643,"update_time":1762309412.1807,"content":{"content_type":"text","parts":["Below is a compact, opinionated survey of directions that the community is exploring for **advanced reasoning and agentic models**, with a compute lens. I group methods by what they *buy* (reasoning quality, safety, or latency) and what they *cost* (train-time FLOPs, inference-time FLOPs, data/labeling). I then give a concrete \u201cwhat to do now vs. later\u201d plan.\n\n---\n\n## 0) Executive takeaways\n\n- **Your intuition is partly right:** the strongest recent jumps in reasoning (e.g., o1/o3, DeepSeek\u2011R1) lean on **compute\u2011hungry post\u2011training RL** *and* **test\u2011time compute** (long internal \u201cthinking\u201d traces, multi\u2011sample search). That\u2019s expensive both to train and to serve. \ue200cite\ue202turn21search1\ue202turn21search17\ue202turn19view0\ue201  \n- **But there are compute\u2011savvy alternatives** that work today:  \n  - **Offline preference optimization** (DPO/ORPO and variants) gives large alignment/quality gains at **SFT\u2011like cost**, avoiding on\u2011policy rollouts. \ue200cite\ue202turn22search0\ue202turn22search3\ue202turn14search1\ue201  \n  - **AI/self feedback** (RLAIF, Self\u2011Rewarding) **trades human labels for model labels**, cutting labeling cost without requiring expensive PPO\u2011style RL; training cost is similar to SFT/DPO plus the cost of generating labels. \ue200cite\ue202turn16search1\ue202turn16search5\ue202turn16search0\ue201  \n  - **Verifier/Process\u2011Reward pipelines** (PRMs, rule/verifier rewards for math/code) let you push reasoning quality **without human step labels** and avoid training a brittle global reward\u2014often more compute\u2011efficient than full RLHF. \ue200cite\ue202turn7search1\ue202turn9search0\ue201  \n  - **System & architecture tricks** (FlashAttention\u20113, vLLM/PagedAttention, speculative decoding, MoE/SSM backbones) give **1.5\u20133\u00d7 inference speedups or longer contexts** at modest engineering cost. \ue200cite\ue202turn22search2\ue202turn22search1\ue202turn24search2\ue202turn6search1\ue202turn11search0\ue201  \n- **Compute reality:** Pretraining still dominates total FLOPs, so **compute\u2011optimal training** (data\u2011rich, not just parameter\u2011rich) matters for everything downstream. Chinchilla remains the practical north star. \ue200cite\ue202turn23search0\ue201\n\n---\n\n## 1) Post\u2011training methods for reasoning: what\u2019s promising vs. compute\n\n### A. Preference optimization that avoids online RL (compute\u2011light)\n\n- **DPO** (Direct Preference Optimization). Offline, stable, *no* on\u2011policy rollouts or separate reward model. **Train\u2011time compute \u2248 SFT on preference pairs**, inference unchanged. Strong baseline for alignment/quality. \ue200cite\ue202turn22search0\ue202turn22search3\ue201  \n- **ORPO** (Odds\u2011Ratio Preference Optimization). Removes the need for a reference model; even closer to SFT. **Compute: SFT\u2011like**, sometimes better data\u2011efficiency on UltraFeedback\u2011style corpora. \ue200cite\ue202turn14search1\ue202turn14search5\ue201  \n- Takeaway: If you\u2019re not doing tool\u2011use or verifiable RL, these are **the best $/FLOP** ways to upgrade behavior and robustness.\n\n### B. AI/self supervision to cut human labels (label\u2011cheap, compute\u2011moderate)\n\n- **RLAIF / Constitutional AI.** Use an assistant model to provide preference labels or critiques under a \u201cconstitution\u201d. Compute dominated by label generation + offline training; **far cheaper than human\u2011labeled RLHF**, and avoids reward\u2011model training instability. \ue200cite\ue202turn16search1\ue202turn16search5\ue201  \n- **Self\u2011Rewarding LMs.** Model judges its own outputs (LLM\u2011as\u2011a\u2011Judge) and iteratively improves via DPO\u2011like training. **No human labels;** compute adds from generating judgments and extra training passes. Promising for alignment and general helpfulness. \ue200cite\ue202turn16search0\ue201  \n- **Weak\u2011to\u2011strong supervision** & **scalable oversight.** Use weaker models/verifiers to supervise stronger ones; empirically helps but **doesn\u2019t eliminate** the supervision gap\u2014careful protocol design still required. **Compute:** mostly offline finetuning + verifier training. \ue200cite\ue202turn17search1\ue201\n\n### C. Process supervision / verifiers (safety & reasoning quality at reasonable cost)\n\n- **Process Reward Models (PRMs).** Train a step\u2011wise evaluator (or rule/verifier) to score intermediate reasoning; then use re\u2011ranking, DPO, or *light* RL. **Compute:** train a medium PRM + generate step\u2011labeled or verifiable data; often cheaper and more stable than full PPO. \ue200cite\ue202turn7search1\ue202turn9search0\ue201  \n- **Verifiable\u2011reward RL** for math/coding. Replace a neural reward with **unit tests, compilers, or numeric checkers**; use PPO/GRPO only where rewards are robust. This is the most **compute\u2011surgical** RL application. (DeepSeek\u2011R1 uses rule\u2011based accuracy/format rewards to avoid reward hacking.) \ue200cite\ue202turn19view0\ue201  \n\n### D. Online RL for internal \u201cthinking\u201d (compute\u2011heavy but frontier\u2011pushing)\n\n- **o1/o3\u2011style \u201creasoning models.\u201d** Trained with large\u2011scale RL to produce long internal chains before answering; **performance scales with both train\u2011time RL compute and test\u2011time \u201cthinking\u201d tokens**. Tremendous gains, but **serving cost rises** (long traces, sometimes multiple samples). \ue200cite\ue202turn21search1\ue202turn21search17\ue201  \n- **DeepSeek\u2011R1.** Pure\u2011RL (GRPO) + small cold\u2011start SFT + distillation. At eval they often use **pass@k / majority vote (k up to 64)**\u2014an explicit **inference compute multiplier**. Distillation back into 14\u201370B students amortizes some cost. \ue200cite\ue202turn19view0\ue201  \n- Bottom line: **State\u2011of\u2011the\u2011art jumps are here, but they pay twice**\u2014once in RL compute, and again at inference.\n\n---\n\n## 2) Test\u2011time compute: when spending tokens helps (and how to claw it back)\n\n- **Self\u2011Consistency / Multi\u2011Sample / ToT/MCTS.** Accuracy improves as you sample more chains or search deeper; **cost grows \u2248 linearly in samples \u00d7 chain length**. Good for hard cases; unaffordable as a default policy.  \n- **Speculative decoding** & **self\u2011speculative/early\u2011exit**: practical **2\u20133\u00d7 decoding speedups** by drafting and verifying tokens with a smaller model or auxiliary heads. Critical if you *must* generate long traces. \ue200cite\ue202turn24search2\ue202turn24search3\ue201  \n- **Distillation of reasoning**: Train a student on teacher chains (CoT/PoT). Substantially **reduces test\u2011time compute** while keeping much of the gain; capacity matters (very small students lose nuance). \ue200cite\ue202turn15search0\ue202turn15search4\ue201\n\n---\n\n## 3) Agent foundations that move compute *outside* the LM\n\n- **Tool\u2011use training** (Toolformer, Gorilla). Teach models to call calculators, search, code runners, APIs. This **offloads reasoning to external systems** (cheap FLOPs), improving reliability without larger models. Training is **self\u2011supervised or light finetuning**; serving cost is mainly tool calls. \ue200cite\ue202turn10search0\ue202turn10search2\ue202turn10search13\ue201  \n- **Retrieval & graph\u2011structured RAG.** Retrieval reduces param\u2011budget pressure and improves verifiability. GraphRAG/Self\u2011RAG variants further **lower hallucinations** and **sharpen reasoning context** with modest compute. \ue200cite\ue202turn8search1\ue202turn8search0\ue201\n\n---\n\n## 4) Architectures & systems that bend the compute curve\n\n- **Sparse MoE.** High parameter count for capacity; **only a few experts active per token**, so per\u2011token compute stays low. DeepSeek\u2011V3 and others push scalable MoE training and routing stability. **Best current option** to raise capacity under a serving budget. \ue200cite\ue202turn6search1\ue201  \n- **State\u2011Space & sub\u2011quadratic backbones** (Mamba, Hyena, RWKV). **Linear or sub\u2011quadratic** sequence cost enables long contexts and streaming; evidence is strongest at small\u2013mid scale today, but steadily improving. \ue200cite\ue202turn11search0\ue202turn11search3\ue201  \n- **Kernel/serving wins**: **FlashAttention\u20113** (1.5\u20132\u00d7 H100 attention speedups, FP8\u2011ready), **PagedAttention/vLLM** (huge throughput gains via KV cache paging), both **material to total TCO**. \ue200cite\ue202turn22search2\ue202turn22search1\ue201  \n- **Hardware:** **Blackwell** adds FP4 transformer engine and higher attention throughput; TPU v5p pods improve price/perf; these **shift the frontier every 12\u201318 months** but don\u2019t change algorithmic scaling. \ue200cite\ue202turn12search0\ue202turn12search4\ue201\n\n---\n\n## 5) Data remains king (and compute\u2011optimality matters)\n\n- **Chinchilla law:** For a given compute budget, **more tokens with a smaller model** often beats a larger, under\u2011trained model; rule\u2011of\u2011thumb \u2248 **20 tokens per parameter**. If you\u2019re not compute\u2011optimal, you\u2019re donating FLOPs. \ue200cite\ue202turn23search0\ue201  \n- Curate high\u2011quality reasoning corpora (math/code/science), deduplicate, and **pre\u2011train/continue\u2011pretrain** before any fancy post\u2011training. This is still the most cost\u2011efficient boost per FLOP.\n\n---\n\n## 6) Approximate compute multipliers (vs. a \u201cplain SFT + greedy decode\u201d baseline)\n\n> Ranges are indicative; actuals vary with prompt lengths, batch sizes, routing, and checkpoint choice.\n\n| Method | Train\u2011time compute | Inference\u2011time compute | Notes |\n|---|---:|---:|---|\n| **DPO/ORPO** | **~1\u00d7\u20132\u00d7** SFT (pairs double tokens; no rollouts) | **1\u00d7** | Simple pipelines, stable. \ue200cite\ue202turn22search0\ue202turn14search1\ue201 |\n| **RLAIF / Self\u2011Rewarding** | **~1\u20133\u00d7** SFT (label generation + finetune) | **1\u00d7** | Cheap labels; watch for feedback bias. \ue200cite\ue202turn16search1\ue202turn16search0\ue201 |\n| **PRM + re\u2011rank** | **~1\u20133\u00d7** SFT (train PRM + extra generations) | **1\u20132\u00d7** (if re\u2011rank k) | Good for math/code; avoids PPO brittleness. \ue200cite\ue202turn7search1\ue201 |\n| **Verifier\u2011based RL (GRPO/PPO)** | **Multi\u2011\u00d7 SFT** (on\u2011policy rollouts + updates) | **1\u20133\u00d7** (if sample\u2011filter) | Use only where rewards are verifiable. \ue200cite\ue202turn19view0\ue201 |\n| **o1/R1\u2011style Reasoners** | **Large** (multi\u2011stage RL + SFT) | **5\u201330\u00d7** (long traces; often k\u2011samples) | Performance scales with train\u2011 and test\u2011compute. \ue200cite\ue202turn21search1\ue202turn19view0\ue201 |\n| **Tree/graph search (ToT/MCTS)** | **0\u20131\u00d7** | **k\u00d7** (samples/branches) | Use adaptively on hard cases. |\n| **Speculative decoding** | **0\u00d7** | **\u00f7(2\u20133)** latency/speedup | Lossless speedup, pairs well with long traces. \ue200cite\ue202turn24search2\ue201 |\n| **MoE (inference)** | **\u2248 dense with active experts** | **\u2248 dense with active experts** | Capacity \u2191 with similar per\u2011token FLOPs. \ue200cite\ue202turn6search1\ue201 |\n| **Mamba/Hyena** | **varies** | **sub\u2011quadratic** | Big wins as sequence length grows. \ue200cite\ue202turn11search0\ue202turn11search3\ue201 |\n| **vLLM/FlashAttn\u20113** | **0\u00d7** | **\u00f7(1.5\u20133)** infra throughput | Engineering change; no quality change. \ue200cite\ue202turn22search2\ue202turn22search1\ue201 |\n\n---\n\n## 7) What\u2019s over\u2011 or under\u2011hyped?\n\n- **Over\u2011hyped:** \u201cJust add ToT/MCTS and profit.\u201d The gains are real, but **k scales cost linearly**, and without good value functions/verifiers, you\u2019ll just sample more mediocre thoughts expensively.  \n- **Under\u2011used:** **Process supervision + re\u2011ranking** on verifiable domains (math, code). It **competes with RLHF** in quality and is usually **cheaper and stabler**. \ue200cite\ue202turn7search1\ue201  \n- **Real but pricey:** o1/R1\u2011style RL. It\u2019s the current top of the leaderboard, but be prepared for **higher serving TCO** unless you distill and aggressively deploy speculative decoding. \ue200cite\ue202turn21search1\ue202turn19view0\ue202turn24search2\ue201\n\n---\n\n## 8) A concrete, compute\u2011aware roadmap (what to do now vs. later)\n\n**Now (commodity H100/A100/TPU\u2011v5e scale, 7\u201332B models):**\n\n1) **Pretrain/continue\u2011pretrain compute\u2011optimally** (Chinchilla ratio, high\u2011quality STEM/code/maths corpora). \ue200cite\ue202turn23search0\ue201  \n2) **DPO/ORPO pass** on preference data (human + AI\u2011labeled) to align style/helpfulness at **SFT\u2011like cost**. \ue200cite\ue202turn22search0\ue202turn14search1\ue201  \n3) **Teach tool\u2011use** (Toolformer\u2011style self\u2011supervision or Gorilla\u2011style API finetunes). This offloads costly symbolic work at inference. \ue200cite\ue202turn10search0\ue202turn10search13\ue201  \n4) **Domain PRMs + re\u2011ranking** for math/code: generate multiple chains, **score steps**, choose best; **avoid PPO unless rewards are robust**. \ue200cite\ue202turn7search1\ue201  \n5) **Serve with vLLM + FlashAttention\u20113 + speculative decoding** to keep latency/TCO low even with longer chains. \ue200cite\ue202turn22search1\ue202turn22search2\ue202turn24search2\ue201  \n6) **Distill reasoning traces** from your best checkpoint into 7\u201314B students for cheap serving; keep a 32\u201370B \u201cteacher\u201d for hard cases. \ue200cite\ue202turn15search0\ue201\n\n**Next (add Blackwell/TPU\u2011v5p scale):**\n\n7) **Targeted RL** (e.g., GRPO) **only** where you have **verifiable rewards** (unit tests, numeric answers). Use process supervision to reduce reward\u2011hacking risk; **cap chain lengths** and **gate multi\u2011sample** to \u201chard mode\u201d calls. \ue200cite\ue202turn19view0\ue201  \n8) **Adopt MoE** for capacity under a constant per\u2011token budget; integrate **Mamba/Hyena** variants if your workloads need long contexts/streaming. \ue200cite\ue202turn6search1\ue202turn11search0\ue201\n\n**Later (abundant compute):**\n\n9) **General\u2011domain RL for internal reasoning** with safety\u2011aware PRMs/verifiers and **automated scalable oversight**; expect to run **longer chains + more samples** and then **distill aggressively** for production. \ue200cite\ue202turn21search1\ue201\n\n---\n\n## 9) If you need a single slide: \u201ccompute\u2011shifting toolkit\u201d\n\n- **Shift *train*\u2011compute down:** DPO/ORPO, RLAIF, PRM re\u2011ranking, distillation.  \n- **Shift *test*\u2011compute up only when needed:** adaptive multi\u2011sample, confidence gating, verifiers.  \n- **Shift compute *outside* the LM:** tool\u2011use, retrieval.  \n- **Make each FLOP count:** MoE capacity, Mamba/Hyena for long contexts, FlashAttention\u20113, vLLM, speculative decoding. \ue200cite\ue202turn22search2\ue202turn22search1\ue202turn24search2\ue201\n\n---\n\n## 10) Closing on your question\n\nYou\u2019re right that **many of the splashy \u201cinternal feedback\u201d and \u201cagentic\u201d ideas become expensive when scaled to production**\u2014especially anything that relies on *on\u2011policy* rollouts or **long internal traces + multi\u2011sample search**. But the **compute\u2011efficient frontier has also moved**: offline preference optimization, AI/self feedback, verifier/PRM pipelines, and strong serving kernels/hardware let you **harvest much of the gain today** without waiting for another order of magnitude in cluster size. The winning strategy in 2025 is to **combine** these: use **cheap training** to get most of the way there, **spend test\u2011time compute only where it pays**, and **distill** the result back down.\n\n---\n\n### Selected sources (representative, not exhaustive)\n- **Compute\u2011optimal training:** Chinchilla scaling laws. \ue200cite\ue202turn23search0\ue201  \n- **Offline preference optimization:** DPO; ORPO. \ue200cite\ue202turn22search0\ue202turn14search1\ue201  \n- **AI/self feedback:** Constitutional AI (RLAIF); Self\u2011Rewarding LMs. \ue200cite\ue202turn16search1\ue202turn16search0\ue201  \n- **Process supervision / PRMs:** OpenAI process supervision; Qwen2.5 PRM lessons. \ue200cite\ue202turn7search1\ue202turn9search0\ue201  \n- **Reasoning RL & test\u2011time scaling:** OpenAI o1 system card/blog; DeepSeek\u2011R1 paper. \ue200cite\ue202turn21search1\ue202turn21search17\ue202turn19view0\ue201  \n- **Tool\u2011use training:** Toolformer; Gorilla/API agents. \ue200cite\ue202turn10search0\ue202turn10search13\ue201  \n- **Systems speedups:** FlashAttention\u20113; vLLM/PagedAttention; speculative decoding. \ue200cite\ue202turn22search2\ue202turn22search1\ue202turn24search2\ue201  \n- **Architectures:** MoE (DeepSeek\u2011V3); Mamba/Hyena. \ue200cite\ue202turn6search1\ue202turn11search0\ue202turn11search3\ue201\n\n---\n\nIf you want, I can turn this into a **compute\u2011budgeted plan** (e.g., \u201cwhat you can do with 1e22 vs. 1e23 FLOPs\u201d), with concrete token/epoch counts, PRM sizes, and expected accuracy deltas on math/code benchmarks."]},"status":"finished_successfully","end_turn":true,"weight":1.0,"metadata":{"content_references":[{"matched_text":"\ue200cite\ue202turn21search1\ue202turn21search17\ue202turn19view0\ue201","start_idx":673,"end_idx":720,"safe_urls":["https://arxiv.org/pdf/2501.12948","https://cdn.openai.com/o1-system-card-20241205.pdf?utm_source=chatgpt.com","https://openai.com/index/learning-to-reason-with-llms/?utm_source=chatgpt.com"],"refs":[],"alt":"([OpenAI](https://cdn.openai.com/o1-system-card-20241205.pdf?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"OpenAI o1 System Card","url":"https://cdn.openai.com/o1-system-card-20241205.pdf?utm_source=chatgpt.com","pub_date":1739576680,"snippet":"Dec 5, 2024 \u2014 Through training, the models learn to refine their thinking process, try different strategies, and recognize their mistakes. Reasoning allows o1 ...","attribution_segments":null,"supporting_websites":[{"title":"Learning to reason with LLMs","url":"https://openai.com/index/learning-to-reason-with-llms/?utm_source=chatgpt.com","pub_date":null,"snippet":"Sep 12, 2024 \u2014 We are introducing OpenAI o1, a new large language model trained with reinforcement learning to perform complex reasoning. o1 thinks before ...","attribution":"OpenAI"},{"title":"","url":"https://arxiv.org/pdf/2501.12948","pub_date":null,"snippet":null,"attribution":"arXiv"}],"refs":[{"turn_index":21,"ref_type":"search","ref_index":1},{"turn_index":21,"ref_type":"search","ref_index":17},{"turn_index":19,"ref_type":"view","ref_index":0}],"hue":null,"attributions":null,"attribution":"OpenAI"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn22search0\ue202turn22search3\ue202turn14search1\ue201","start_idx":940,"end_idx":988,"safe_urls":["https://arxiv.org/abs/2305.18290?utm_source=chatgpt.com","https://arxiv.org/abs/2403.07691?utm_source=chatgpt.com","https://arxiv.org/pdf/2305.18290?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2305.18290?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Direct Preference Optimization: Your Language Model is Secretly a Reward Model","url":"https://arxiv.org/abs/2305.18290?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[{"title":"Direct Preference Optimization: Your Language Model is ...","url":"https://arxiv.org/pdf/2305.18290?utm_source=chatgpt.com","pub_date":null,"snippet":"by R Rafailov \u00b7 2023 \u00b7 Cited by 5990 \u2014 In this paper, we show how to directly optimize a language model to adhere to human preferences, without explicit reward modeling or ...","attribution":"arXiv"},{"title":"ORPO: Monolithic Preference Optimization without Reference Model","url":"https://arxiv.org/abs/2403.07691?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution":"arXiv"}],"refs":[{"turn_index":22,"ref_type":"search","ref_index":0},{"turn_index":22,"ref_type":"search","ref_index":3},{"turn_index":14,"ref_type":"search","ref_index":1}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn16search1\ue202turn16search5\ue202turn16search0\ue201","start_idx":1218,"end_idx":1266,"safe_urls":["https://arxiv.org/abs/2212.08073?utm_source=chatgpt.com","https://arxiv.org/abs/2401.10020?utm_source=chatgpt.com","https://www-cdn.anthropic.com/7512771452629584566b6303311496c262da1006/Anthropic_ConstitutionalAI_v2.pdf?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2212.08073?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Constitutional AI: Harmlessness from AI Feedback","url":"https://arxiv.org/abs/2212.08073?utm_source=chatgpt.com","pub_date":null,"snippet":"by Y Bai \u00b7 2022 \u00b7 Cited by 2272 \u2014 We experiment with methods for training a harmless AI assistant through self-improvement, without any human labels identifying harmful outputs.","attribution_segments":null,"supporting_websites":[{"title":"Constitutional AI: Harmlessness from AI Feedback","url":"https://www-cdn.anthropic.com/7512771452629584566b6303311496c262da1006/Anthropic_ConstitutionalAI_v2.pdf?utm_source=chatgpt.com","pub_date":null,"snippet":"The approach is called Constitutional AI ... The model's self-critique and -revision approach can be framed as reinforcement learning from AI feedback (RLAIF).","attribution":"www-cdn.anthropic.com"},{"title":"Self-Rewarding Language Models","url":"https://arxiv.org/abs/2401.10020?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution":"arXiv"}],"refs":[{"turn_index":16,"ref_type":"search","ref_index":1},{"turn_index":16,"ref_type":"search","ref_index":5},{"turn_index":16,"ref_type":"search","ref_index":0}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn7search1\ue202turn9search0\ue201","start_idx":1504,"end_idx":1536,"safe_urls":["https://arxiv.org/abs/2211.12588?utm_source=chatgpt.com","https://arxiv.org/abs/2402.03300?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2402.03300?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"DeepSeekMath: Pushing the Limits of Mathematical ...","url":"https://arxiv.org/abs/2402.03300?utm_source=chatgpt.com","pub_date":null,"snippet":"by Z Shao \u00b7 2024 \u00b7 Cited by 2460 \u2014 Second, we introduce Group Relative Policy Optimization (GRPO), a variant of Proximal Policy Optimization (PPO), that enhances mathematical ...","attribution_segments":null,"supporting_websites":[{"title":"Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks","url":"https://arxiv.org/abs/2211.12588?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution":"arXiv"}],"refs":[{"turn_index":7,"ref_type":"search","ref_index":1},{"turn_index":9,"ref_type":"search","ref_index":0}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn22search2\ue202turn22search1\ue202turn24search2\ue202turn6search1\ue202turn11search0\ue201","start_idx":1739,"end_idx":1814,"safe_urls":["https://arxiv.org/abs/2203.14465?utm_source=chatgpt.com","https://arxiv.org/abs/2211.17192?utm_source=chatgpt.com","https://arxiv.org/abs/2309.06180?utm_source=chatgpt.com","https://arxiv.org/abs/2312.00752?utm_source=chatgpt.com","https://arxiv.org/abs/2407.08608?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2407.08608?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"FlashAttention-3: Fast and Accurate Attention with Asynchrony and Low-precision","url":"https://arxiv.org/abs/2407.08608?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[{"title":"Efficient Memory Management for Large Language Model ...","url":"https://arxiv.org/abs/2309.06180?utm_source=chatgpt.com","pub_date":null,"snippet":"by W Kwon \u00b7 2023 \u00b7 Cited by 3693 \u2014 We propose PagedAttention, an attention algorithm inspired by the classical virtual memory and paging techniques in operating systems.","attribution":"arXiv"},{"title":"Fast Inference from Transformers via Speculative Decoding","url":"https://arxiv.org/abs/2211.17192?utm_source=chatgpt.com","pub_date":null,"snippet":"by Y Leviathan \u00b7 2022 \u00b7 Cited by 963 \u2014 In this work we introduce speculative decoding - an algorithm to sample from autoregressive models faster without any changes to the outputs.","attribution":"arXiv"},{"title":"STaR: Bootstrapping Reasoning With Reasoning","url":"https://arxiv.org/abs/2203.14465?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution":"arXiv"},{"title":"Mamba: Linear-Time Sequence Modeling with Selective State Spaces","url":"https://arxiv.org/abs/2312.00752?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution":"arXiv"}],"refs":[{"turn_index":22,"ref_type":"search","ref_index":2},{"turn_index":22,"ref_type":"search","ref_index":1},{"turn_index":24,"ref_type":"search","ref_index":2},{"turn_index":6,"ref_type":"search","ref_index":1},{"turn_index":11,"ref_type":"search","ref_index":0}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn23search0\ue201","start_idx":2030,"end_idx":2050,"safe_urls":["https://arxiv.org/abs/2203.15556?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2203.15556?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Training Compute-Optimal Large Language Models","url":"https://arxiv.org/abs/2203.15556?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":23,"ref_type":"search","ref_index":0}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn22search0\ue202turn22search3\ue201","start_idx":2421,"end_idx":2455,"safe_urls":["https://arxiv.org/abs/2305.18290?utm_source=chatgpt.com","https://arxiv.org/pdf/2305.18290?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2305.18290?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Direct Preference Optimization: Your Language Model is Secretly a Reward Model","url":"https://arxiv.org/abs/2305.18290?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[{"title":"Direct Preference Optimization: Your Language Model is ...","url":"https://arxiv.org/pdf/2305.18290?utm_source=chatgpt.com","pub_date":null,"snippet":"by R Rafailov \u00b7 2023 \u00b7 Cited by 5990 \u2014 In this paper, we show how to directly optimize a language model to adhere to human preferences, without explicit reward modeling or ...","attribution":"arXiv"}],"refs":[{"turn_index":22,"ref_type":"search","ref_index":0},{"turn_index":22,"ref_type":"search","ref_index":3}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn14search1\ue202turn14search5\ue201","start_idx":2655,"end_idx":2689,"safe_urls":["https://arxiv.org/abs/2403.07691?utm_source=chatgpt.com","https://arxiv.org/pdf/2403.07691?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2403.07691?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"ORPO: Monolithic Preference Optimization without Reference Model","url":"https://arxiv.org/abs/2403.07691?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[{"title":"arXiv:2403.07691v2 [cs.CL] 14 Mar 2024","url":"https://arxiv.org/pdf/2403.07691?utm_source=chatgpt.com","pub_date":null,"snippet":"by J Hong \u00b7 2024 \u00b7 Cited by 378 \u2014 We introduce a novel preference alignment algo- rithm, Odds Ratio Preference Optimization (ORPO), which incorporates an odds ratio-based penalty.","attribution":"arXiv"}],"refs":[{"turn_index":14,"ref_type":"search","ref_index":1},{"turn_index":14,"ref_type":"search","ref_index":5}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn16search1\ue202turn16search5\ue201","start_idx":3170,"end_idx":3204,"safe_urls":["https://arxiv.org/abs/2212.08073?utm_source=chatgpt.com","https://www-cdn.anthropic.com/7512771452629584566b6303311496c262da1006/Anthropic_ConstitutionalAI_v2.pdf?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2212.08073?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Constitutional AI: Harmlessness from AI Feedback","url":"https://arxiv.org/abs/2212.08073?utm_source=chatgpt.com","pub_date":null,"snippet":"by Y Bai \u00b7 2022 \u00b7 Cited by 2272 \u2014 We experiment with methods for training a harmless AI assistant through self-improvement, without any human labels identifying harmful outputs.","attribution_segments":null,"supporting_websites":[{"title":"Constitutional AI: Harmlessness from AI Feedback","url":"https://www-cdn.anthropic.com/7512771452629584566b6303311496c262da1006/Anthropic_ConstitutionalAI_v2.pdf?utm_source=chatgpt.com","pub_date":null,"snippet":"The approach is called Constitutional AI ... The model's self-critique and -revision approach can be framed as reinforcement learning from AI feedback (RLAIF).","attribution":"www-cdn.anthropic.com"}],"refs":[{"turn_index":16,"ref_type":"search","ref_index":1},{"turn_index":16,"ref_type":"search","ref_index":5}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn16search0\ue201","start_idx":3463,"end_idx":3483,"safe_urls":["https://arxiv.org/abs/2401.10020?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2401.10020?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Self-Rewarding Language Models","url":"https://arxiv.org/abs/2401.10020?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":16,"ref_type":"search","ref_index":0}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn17search1\ue201","start_idx":3765,"end_idx":3785,"safe_urls":["https://arxiv.org/abs/2312.09390?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2312.09390?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Eliciting Strong Capabilities With Weak Supervision","url":"https://arxiv.org/abs/2312.09390?utm_source=chatgpt.com","pub_date":null,"snippet":"by C Burns \u00b7 2023 \u00b7 Cited by 364 \u2014 We find that simple methods can often significantly improve weak-to-strong generalization: for example, when finetuning GPT-4 with a GPT-2-level ...","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":17,"ref_type":"search","ref_index":1}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn7search1\ue202turn9search0\ue201","start_idx":4153,"end_idx":4185,"safe_urls":["https://arxiv.org/abs/2211.12588?utm_source=chatgpt.com","https://arxiv.org/abs/2402.03300?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2402.03300?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"DeepSeekMath: Pushing the Limits of Mathematical ...","url":"https://arxiv.org/abs/2402.03300?utm_source=chatgpt.com","pub_date":null,"snippet":"by Z Shao \u00b7 2024 \u00b7 Cited by 2460 \u2014 Second, we introduce Group Relative Policy Optimization (GRPO), a variant of Proximal Policy Optimization (PPO), that enhances mathematical ...","attribution_segments":null,"supporting_websites":[{"title":"Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks","url":"https://arxiv.org/abs/2211.12588?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution":"arXiv"}],"refs":[{"turn_index":7,"ref_type":"search","ref_index":1},{"turn_index":9,"ref_type":"search","ref_index":0}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn19view0\ue201","start_idx":4486,"end_idx":4504,"safe_urls":["https://arxiv.org/pdf/2501.12948"],"refs":[],"alt":"([arXiv](https://arxiv.org/pdf/2501.12948))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"","url":"https://arxiv.org/pdf/2501.12948","pub_date":null,"snippet":null,"attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":19,"ref_type":"view","ref_index":0}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn21search1\ue202turn21search17\ue201","start_idx":4879,"end_idx":4914,"safe_urls":["https://cdn.openai.com/o1-system-card-20241205.pdf?utm_source=chatgpt.com","https://openai.com/index/learning-to-reason-with-llms/?utm_source=chatgpt.com"],"refs":[],"alt":"([OpenAI](https://cdn.openai.com/o1-system-card-20241205.pdf?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"OpenAI o1 System Card","url":"https://cdn.openai.com/o1-system-card-20241205.pdf?utm_source=chatgpt.com","pub_date":1739576680,"snippet":"Dec 5, 2024 \u2014 Through training, the models learn to refine their thinking process, try different strategies, and recognize their mistakes. Reasoning allows o1 ...","attribution_segments":null,"supporting_websites":[{"title":"Learning to reason with LLMs","url":"https://openai.com/index/learning-to-reason-with-llms/?utm_source=chatgpt.com","pub_date":null,"snippet":"Sep 12, 2024 \u2014 We are introducing OpenAI o1, a new large language model trained with reinforcement learning to perform complex reasoning. o1 thinks before ...","attribution":"OpenAI"}],"refs":[{"turn_index":21,"ref_type":"search","ref_index":1},{"turn_index":21,"ref_type":"search","ref_index":17}],"hue":null,"attributions":null,"attribution":"OpenAI"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn19view0\ue201","start_idx":5159,"end_idx":5177,"safe_urls":["https://arxiv.org/pdf/2501.12948"],"refs":[],"alt":"([arXiv](https://arxiv.org/pdf/2501.12948))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"","url":"https://arxiv.org/pdf/2501.12948","pub_date":null,"snippet":null,"attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":19,"ref_type":"view","ref_index":0}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn24search2\ue202turn24search3\ue201","start_idx":5820,"end_idx":5854,"safe_urls":["https://arxiv.org/abs/2211.17192?utm_source=chatgpt.com","https://arxiv.org/html/2403.18647v1?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2211.17192?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Fast Inference from Transformers via Speculative Decoding","url":"https://arxiv.org/abs/2211.17192?utm_source=chatgpt.com","pub_date":null,"snippet":"by Y Leviathan \u00b7 2022 \u00b7 Cited by 963 \u2014 In this work we introduce speculative decoding - an algorithm to sample from autoregressive models faster without any changes to the outputs.","attribution_segments":null,"supporting_websites":[{"title":"Accelerating LLM Inference through Speculative Decoding ...","url":"https://arxiv.org/html/2403.18647v1?utm_source=chatgpt.com","pub_date":null,"snippet":"Leviathan et al. (2023) introduced the speculative sampling method and proved that the distribution of the generated text remains unchanged for both the greedy ...","attribution":"arXiv"}],"refs":[{"turn_index":24,"ref_type":"search","ref_index":2},{"turn_index":24,"ref_type":"search","ref_index":3}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn15search0\ue202turn15search4\ue201","start_idx":6063,"end_idx":6097,"safe_urls":["https://aclanthology.org/2025.emnlp-main.376.pdf?utm_source=chatgpt.com","https://arxiv.org/abs/2306.14050?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2306.14050?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Symbolic Chain-of-Thought Distillation: Small Models Can Also \"Think\" Step-by-Step","url":"https://arxiv.org/abs/2306.14050?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[{"title":"Teach Small Models to Reason by Curriculum Distillation","url":"https://aclanthology.org/2025.emnlp-main.376.pdf?utm_source=chatgpt.com","pub_date":null,"snippet":"by W Jiang \u00b7 2025 \u2014 We distill reasoning capabilities from two teacher models, an LLM Qwen2.5-32B-Instruct, and an LRM DeepSeek-R1-Distill-Qwen-32B, into smaller ...","attribution":"ACL Anthology"}],"refs":[{"turn_index":15,"ref_type":"search","ref_index":0},{"turn_index":15,"ref_type":"search","ref_index":4}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn10search0\ue202turn10search2\ue202turn10search13\ue201","start_idx":6469,"end_idx":6518,"safe_urls":["https://arxiv.org/abs/2302.04761?utm_source=chatgpt.com","https://arxiv.org/pdf/2302.04761?utm_source=chatgpt.com","https://proceedings.neurips.cc/paper_files/paper/2024/file/e4c61f578ff07830f5c37378dd3ecb0d-Paper-Conference.pdf?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2302.04761?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Toolformer: Language Models Can Teach Themselves to Use Tools","url":"https://arxiv.org/abs/2302.04761?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[{"title":"arXiv:2302.04761v1 [cs.CL] 9 Feb 2023","url":"https://arxiv.org/pdf/2302.04761?utm_source=chatgpt.com","pub_date":null,"snippet":"by T Schick \u00b7 2023 \u00b7 Cited by 2563 \u2014 In contrast, the self-supervised nature of Toolformer enables it to learn how and when to use tools without requiring a specific prompt that.","attribution":"arXiv"},{"title":"Gorilla: Large Language Model Connected with Massive ...","url":"https://proceedings.neurips.cc/paper_files/paper/2024/file/e4c61f578ff07830f5c37378dd3ecb0d-Paper-Conference.pdf?utm_source=chatgpt.com","pub_date":null,"snippet":"by SG Patil \u00b7 2024 \u00b7 Cited by 775 \u2014 We introduce Gorilla, the first system to enable large-scale API integration with LLMs, demonstrating state-of-the-art performance in generating accurate API ...","attribution":"NeurIPS Proceedings"}],"refs":[{"turn_index":10,"ref_type":"search","ref_index":0},{"turn_index":10,"ref_type":"search","ref_index":2},{"turn_index":10,"ref_type":"search","ref_index":13}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn8search1\ue202turn8search0\ue201","start_idx":6744,"end_idx":6776,"safe_urls":["https://arxiv.org/abs/2310.11511?utm_source=chatgpt.com","https://arxiv.org/abs/2404.16130?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2404.16130?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"A Graph RAG Approach to Query-Focused Summarization","url":"https://arxiv.org/abs/2404.16130?utm_source=chatgpt.com","pub_date":null,"snippet":"by D Edge \u00b7 2024 \u00b7 Cited by 1021 \u2014 We propose GraphRAG, a graph-based approach to question answering over private text corpora that scales with both the generality of user questions and the ...","attribution_segments":null,"supporting_websites":[{"title":"Self-RAG: Learning to Retrieve, Generate, and Critique ...","url":"https://arxiv.org/abs/2310.11511?utm_source=chatgpt.com","pub_date":null,"snippet":"by A Asai \u00b7 2023 \u00b7 Cited by 1266 \u2014 We introduce a new framework called Self-Reflective Retrieval-Augmented Generation (Self-RAG) that enhances an LM's quality and factuality through retrieval ...","attribution":"arXiv"}],"refs":[{"turn_index":8,"ref_type":"search","ref_index":1},{"turn_index":8,"ref_type":"search","ref_index":0}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn6search1\ue201","start_idx":7107,"end_idx":7126,"safe_urls":["https://arxiv.org/abs/2203.14465?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2203.14465?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"STaR: Bootstrapping Reasoning With Reasoning","url":"https://arxiv.org/abs/2203.14465?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":6,"ref_type":"search","ref_index":1}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn11search0\ue202turn11search3\ue201","start_idx":7346,"end_idx":7380,"safe_urls":["https://arxiv.org/abs/2302.10866?utm_source=chatgpt.com","https://arxiv.org/abs/2312.00752?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2312.00752?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Mamba: Linear-Time Sequence Modeling with Selective State Spaces","url":"https://arxiv.org/abs/2312.00752?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[{"title":"Hyena Hierarchy: Towards Larger Convolutional Language Models","url":"https://arxiv.org/abs/2302.10866?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution":"arXiv"}],"refs":[{"turn_index":11,"ref_type":"search","ref_index":0},{"turn_index":11,"ref_type":"search","ref_index":3}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn22search2\ue202turn22search1\ue201","start_idx":7577,"end_idx":7611,"safe_urls":["https://arxiv.org/abs/2309.06180?utm_source=chatgpt.com","https://arxiv.org/abs/2407.08608?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2407.08608?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"FlashAttention-3: Fast and Accurate Attention with Asynchrony and Low-precision","url":"https://arxiv.org/abs/2407.08608?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[{"title":"Efficient Memory Management for Large Language Model ...","url":"https://arxiv.org/abs/2309.06180?utm_source=chatgpt.com","pub_date":null,"snippet":"by W Kwon \u00b7 2023 \u00b7 Cited by 3693 \u2014 We propose PagedAttention, an attention algorithm inspired by the classical virtual memory and paging techniques in operating systems.","attribution":"arXiv"}],"refs":[{"turn_index":22,"ref_type":"search","ref_index":2},{"turn_index":22,"ref_type":"search","ref_index":1}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn12search0\ue202turn12search4\ue201","start_idx":7824,"end_idx":7858,"safe_urls":["https://cloud.google.com/blog/products/ai-machine-learning/introducing-cloud-tpu-v5p-and-ai-hypercomputer?utm_source=chatgpt.com","https://www.nvidia.com/en-us/data-center/technologies/blackwell-architecture/?utm_source=chatgpt.com"],"refs":[],"alt":"([NVIDIA](https://www.nvidia.com/en-us/data-center/technologies/blackwell-architecture/?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"NVIDIA Blackwell Architecture","url":"https://www.nvidia.com/en-us/data-center/technologies/blackwell-architecture/?utm_source=chatgpt.com","pub_date":null,"snippet":"NVIDIA Blackwell Ultra Tensor Cores are supercharged with 2X the attention-layer acceleration and 1.5X more AI compute FLOPS compared to NVIDIA Blackwell GPUs.","attribution_segments":null,"supporting_websites":[{"title":"Introducing Cloud TPU v5p and AI Hypercomputer","url":"https://cloud.google.com/blog/products/ai-machine-learning/introducing-cloud-tpu-v5p-and-ai-hypercomputer?utm_source=chatgpt.com","pub_date":null,"snippet":"Dec 6, 2023 \u2014 Earlier this year, we announced the general availability of Cloud TPU v5e. With 2.3X price performance improvements over the previous generation ...","attribution":"Google Cloud"}],"refs":[{"turn_index":12,"ref_type":"search","ref_index":0},{"turn_index":12,"ref_type":"search","ref_index":4}],"hue":null,"attributions":null,"attribution":"NVIDIA"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn23search0\ue201","start_idx":8152,"end_idx":8172,"safe_urls":["https://arxiv.org/abs/2203.15556?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2203.15556?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Training Compute-Optimal Large Language Models","url":"https://arxiv.org/abs/2203.15556?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":23,"ref_type":"search","ref_index":0}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn22search0\ue202turn14search1\ue201","start_idx":8755,"end_idx":8789,"safe_urls":["https://arxiv.org/abs/2305.18290?utm_source=chatgpt.com","https://arxiv.org/abs/2403.07691?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2305.18290?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Direct Preference Optimization: Your Language Model is Secretly a Reward Model","url":"https://arxiv.org/abs/2305.18290?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[{"title":"ORPO: Monolithic Preference Optimization without Reference Model","url":"https://arxiv.org/abs/2403.07691?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution":"arXiv"}],"refs":[{"turn_index":22,"ref_type":"search","ref_index":0},{"turn_index":14,"ref_type":"search","ref_index":1}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn16search1\ue202turn16search0\ue201","start_idx":8917,"end_idx":8951,"safe_urls":["https://arxiv.org/abs/2212.08073?utm_source=chatgpt.com","https://arxiv.org/abs/2401.10020?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2212.08073?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Constitutional AI: Harmlessness from AI Feedback","url":"https://arxiv.org/abs/2212.08073?utm_source=chatgpt.com","pub_date":null,"snippet":"by Y Bai \u00b7 2022 \u00b7 Cited by 2272 \u2014 We experiment with methods for training a harmless AI assistant through self-improvement, without any human labels identifying harmful outputs.","attribution_segments":null,"supporting_websites":[{"title":"Self-Rewarding Language Models","url":"https://arxiv.org/abs/2401.10020?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution":"arXiv"}],"refs":[{"turn_index":16,"ref_type":"search","ref_index":1},{"turn_index":16,"ref_type":"search","ref_index":0}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn7search1\ue201","start_idx":9094,"end_idx":9113,"safe_urls":["https://arxiv.org/abs/2402.03300?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2402.03300?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"DeepSeekMath: Pushing the Limits of Mathematical ...","url":"https://arxiv.org/abs/2402.03300?utm_source=chatgpt.com","pub_date":null,"snippet":"by Z Shao \u00b7 2024 \u00b7 Cited by 2460 \u2014 Second, we introduce Group Relative Policy Optimization (GRPO), a variant of Proximal Policy Optimization (PPO), that enhances mathematical ...","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":7,"ref_type":"search","ref_index":1}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn19view0\ue201","start_idx":9271,"end_idx":9289,"safe_urls":["https://arxiv.org/pdf/2501.12948"],"refs":[],"alt":"([arXiv](https://arxiv.org/pdf/2501.12948))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"","url":"https://arxiv.org/pdf/2501.12948","pub_date":null,"snippet":null,"attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":19,"ref_type":"view","ref_index":0}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn21search1\ue202turn19view0\ue201","start_idx":9449,"end_idx":9481,"safe_urls":["https://arxiv.org/pdf/2501.12948","https://cdn.openai.com/o1-system-card-20241205.pdf?utm_source=chatgpt.com"],"refs":[],"alt":"([OpenAI](https://cdn.openai.com/o1-system-card-20241205.pdf?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"OpenAI o1 System Card","url":"https://cdn.openai.com/o1-system-card-20241205.pdf?utm_source=chatgpt.com","pub_date":1739576680,"snippet":"Dec 5, 2024 \u2014 Through training, the models learn to refine their thinking process, try different strategies, and recognize their mistakes. Reasoning allows o1 ...","attribution_segments":null,"supporting_websites":[{"title":"","url":"https://arxiv.org/pdf/2501.12948","pub_date":null,"snippet":null,"attribution":"arXiv"}],"refs":[{"turn_index":21,"ref_type":"search","ref_index":1},{"turn_index":19,"ref_type":"view","ref_index":0}],"hue":null,"attributions":null,"attribution":"OpenAI"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn24search2\ue201","start_idx":9706,"end_idx":9726,"safe_urls":["https://arxiv.org/abs/2211.17192?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2211.17192?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Fast Inference from Transformers via Speculative Decoding","url":"https://arxiv.org/abs/2211.17192?utm_source=chatgpt.com","pub_date":null,"snippet":"by Y Leviathan \u00b7 2022 \u00b7 Cited by 963 \u2014 In this work we introduce speculative decoding - an algorithm to sample from autoregressive models faster without any changes to the outputs.","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":24,"ref_type":"search","ref_index":2}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn6search1\ue201","start_idx":9862,"end_idx":9881,"safe_urls":["https://arxiv.org/abs/2203.14465?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2203.14465?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"STaR: Bootstrapping Reasoning With Reasoning","url":"https://arxiv.org/abs/2203.14465?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":6,"ref_type":"search","ref_index":1}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn11search0\ue202turn11search3\ue201","start_idx":9972,"end_idx":10006,"safe_urls":["https://arxiv.org/abs/2302.10866?utm_source=chatgpt.com","https://arxiv.org/abs/2312.00752?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2312.00752?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Mamba: Linear-Time Sequence Modeling with Selective State Spaces","url":"https://arxiv.org/abs/2312.00752?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[{"title":"Hyena Hierarchy: Towards Larger Convolutional Language Models","url":"https://arxiv.org/abs/2302.10866?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution":"arXiv"}],"refs":[{"turn_index":11,"ref_type":"search","ref_index":0},{"turn_index":11,"ref_type":"search","ref_index":3}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn22search2\ue202turn22search1\ue201","start_idx":10114,"end_idx":10148,"safe_urls":["https://arxiv.org/abs/2309.06180?utm_source=chatgpt.com","https://arxiv.org/abs/2407.08608?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2407.08608?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"FlashAttention-3: Fast and Accurate Attention with Asynchrony and Low-precision","url":"https://arxiv.org/abs/2407.08608?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[{"title":"Efficient Memory Management for Large Language Model ...","url":"https://arxiv.org/abs/2309.06180?utm_source=chatgpt.com","pub_date":null,"snippet":"by W Kwon \u00b7 2023 \u00b7 Cited by 3693 \u2014 We propose PagedAttention, an attention algorithm inspired by the classical virtual memory and paging techniques in operating systems.","attribution":"arXiv"}],"refs":[{"turn_index":22,"ref_type":"search","ref_index":2},{"turn_index":22,"ref_type":"search","ref_index":1}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn7search1\ue201","start_idx":10564,"end_idx":10583,"safe_urls":["https://arxiv.org/abs/2402.03300?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2402.03300?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"DeepSeekMath: Pushing the Limits of Mathematical ...","url":"https://arxiv.org/abs/2402.03300?utm_source=chatgpt.com","pub_date":null,"snippet":"by Z Shao \u00b7 2024 \u00b7 Cited by 2460 \u2014 Second, we introduce Group Relative Policy Optimization (GRPO), a variant of Proximal Policy Optimization (PPO), that enhances mathematical ...","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":7,"ref_type":"search","ref_index":1}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn21search1\ue202turn19view0\ue202turn24search2\ue201","start_idx":10774,"end_idx":10820,"safe_urls":["https://arxiv.org/abs/2211.17192?utm_source=chatgpt.com","https://arxiv.org/pdf/2501.12948","https://cdn.openai.com/o1-system-card-20241205.pdf?utm_source=chatgpt.com"],"refs":[],"alt":"([OpenAI](https://cdn.openai.com/o1-system-card-20241205.pdf?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"OpenAI o1 System Card","url":"https://cdn.openai.com/o1-system-card-20241205.pdf?utm_source=chatgpt.com","pub_date":1739576680,"snippet":"Dec 5, 2024 \u2014 Through training, the models learn to refine their thinking process, try different strategies, and recognize their mistakes. Reasoning allows o1 ...","attribution_segments":null,"supporting_websites":[{"title":"","url":"https://arxiv.org/pdf/2501.12948","pub_date":null,"snippet":null,"attribution":"arXiv"},{"title":"Fast Inference from Transformers via Speculative Decoding","url":"https://arxiv.org/abs/2211.17192?utm_source=chatgpt.com","pub_date":null,"snippet":"by Y Leviathan \u00b7 2022 \u00b7 Cited by 963 \u2014 In this work we introduce speculative decoding - an algorithm to sample from autoregressive models faster without any changes to the outputs.","attribution":"arXiv"}],"refs":[{"turn_index":21,"ref_type":"search","ref_index":1},{"turn_index":19,"ref_type":"view","ref_index":0},{"turn_index":24,"ref_type":"search","ref_index":2}],"hue":null,"attributions":null,"attribution":"OpenAI"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn23search0\ue201","start_idx":11065,"end_idx":11085,"safe_urls":["https://arxiv.org/abs/2203.15556?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2203.15556?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Training Compute-Optimal Large Language Models","url":"https://arxiv.org/abs/2203.15556?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":23,"ref_type":"search","ref_index":0}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn22search0\ue202turn14search1\ue201","start_idx":11198,"end_idx":11232,"safe_urls":["https://arxiv.org/abs/2305.18290?utm_source=chatgpt.com","https://arxiv.org/abs/2403.07691?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2305.18290?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Direct Preference Optimization: Your Language Model is Secretly a Reward Model","url":"https://arxiv.org/abs/2305.18290?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[{"title":"ORPO: Monolithic Preference Optimization without Reference Model","url":"https://arxiv.org/abs/2403.07691?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution":"arXiv"}],"refs":[{"turn_index":22,"ref_type":"search","ref_index":0},{"turn_index":14,"ref_type":"search","ref_index":1}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn10search0\ue202turn10search13\ue201","start_idx":11374,"end_idx":11409,"safe_urls":["https://arxiv.org/abs/2302.04761?utm_source=chatgpt.com","https://proceedings.neurips.cc/paper_files/paper/2024/file/e4c61f578ff07830f5c37378dd3ecb0d-Paper-Conference.pdf?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2302.04761?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Toolformer: Language Models Can Teach Themselves to Use Tools","url":"https://arxiv.org/abs/2302.04761?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[{"title":"Gorilla: Large Language Model Connected with Massive ...","url":"https://proceedings.neurips.cc/paper_files/paper/2024/file/e4c61f578ff07830f5c37378dd3ecb0d-Paper-Conference.pdf?utm_source=chatgpt.com","pub_date":null,"snippet":"by SG Patil \u00b7 2024 \u00b7 Cited by 775 \u2014 We introduce Gorilla, the first system to enable large-scale API integration with LLMs, demonstrating state-of-the-art performance in generating accurate API ...","attribution":"NeurIPS Proceedings"}],"refs":[{"turn_index":10,"ref_type":"search","ref_index":0},{"turn_index":10,"ref_type":"search","ref_index":13}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn7search1\ue201","start_idx":11556,"end_idx":11575,"safe_urls":["https://arxiv.org/abs/2402.03300?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2402.03300?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"DeepSeekMath: Pushing the Limits of Mathematical ...","url":"https://arxiv.org/abs/2402.03300?utm_source=chatgpt.com","pub_date":null,"snippet":"by Z Shao \u00b7 2024 \u00b7 Cited by 2460 \u2014 Second, we introduce Group Relative Policy Optimization (GRPO), a variant of Proximal Policy Optimization (PPO), that enhances mathematical ...","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":7,"ref_type":"search","ref_index":1}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn22search1\ue202turn22search2\ue202turn24search2\ue201","start_idx":11692,"end_idx":11740,"safe_urls":["https://arxiv.org/abs/2211.17192?utm_source=chatgpt.com","https://arxiv.org/abs/2309.06180?utm_source=chatgpt.com","https://arxiv.org/abs/2407.08608?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2309.06180?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Efficient Memory Management for Large Language Model ...","url":"https://arxiv.org/abs/2309.06180?utm_source=chatgpt.com","pub_date":null,"snippet":"by W Kwon \u00b7 2023 \u00b7 Cited by 3693 \u2014 We propose PagedAttention, an attention algorithm inspired by the classical virtual memory and paging techniques in operating systems.","attribution_segments":null,"supporting_websites":[{"title":"FlashAttention-3: Fast and Accurate Attention with Asynchrony and Low-precision","url":"https://arxiv.org/abs/2407.08608?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution":"arXiv"},{"title":"Fast Inference from Transformers via Speculative Decoding","url":"https://arxiv.org/abs/2211.17192?utm_source=chatgpt.com","pub_date":null,"snippet":"by Y Leviathan \u00b7 2022 \u00b7 Cited by 963 \u2014 In this work we introduce speculative decoding - an algorithm to sample from autoregressive models faster without any changes to the outputs.","attribution":"arXiv"}],"refs":[{"turn_index":22,"ref_type":"search","ref_index":1},{"turn_index":22,"ref_type":"search","ref_index":2},{"turn_index":24,"ref_type":"search","ref_index":2}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn15search0\ue201","start_idx":11880,"end_idx":11900,"safe_urls":["https://arxiv.org/abs/2306.14050?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2306.14050?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Symbolic Chain-of-Thought Distillation: Small Models Can Also \"Think\" Step-by-Step","url":"https://arxiv.org/abs/2306.14050?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":15,"ref_type":"search","ref_index":0}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn19view0\ue201","start_idx":12178,"end_idx":12196,"safe_urls":["https://arxiv.org/pdf/2501.12948"],"refs":[],"alt":"([arXiv](https://arxiv.org/pdf/2501.12948))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"","url":"https://arxiv.org/pdf/2501.12948","pub_date":null,"snippet":null,"attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":19,"ref_type":"view","ref_index":0}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn6search1\ue202turn11search0\ue201","start_idx":12347,"end_idx":12380,"safe_urls":["https://arxiv.org/abs/2203.14465?utm_source=chatgpt.com","https://arxiv.org/abs/2312.00752?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2203.14465?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"STaR: Bootstrapping Reasoning With Reasoning","url":"https://arxiv.org/abs/2203.14465?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[{"title":"Mamba: Linear-Time Sequence Modeling with Selective State Spaces","url":"https://arxiv.org/abs/2312.00752?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution":"arXiv"}],"refs":[{"turn_index":6,"ref_type":"search","ref_index":1},{"turn_index":11,"ref_type":"search","ref_index":0}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn21search1\ue201","start_idx":12629,"end_idx":12649,"safe_urls":["https://cdn.openai.com/o1-system-card-20241205.pdf?utm_source=chatgpt.com"],"refs":[],"alt":"([OpenAI](https://cdn.openai.com/o1-system-card-20241205.pdf?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"OpenAI o1 System Card","url":"https://cdn.openai.com/o1-system-card-20241205.pdf?utm_source=chatgpt.com","pub_date":1739576680,"snippet":"Dec 5, 2024 \u2014 Through training, the models learn to refine their thinking process, try different strategies, and recognize their mistakes. Reasoning allows o1 ...","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":21,"ref_type":"search","ref_index":1}],"hue":null,"attributions":null,"attribution":"OpenAI"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn22search2\ue202turn22search1\ue202turn24search2\ue201","start_idx":13084,"end_idx":13132,"safe_urls":["https://arxiv.org/abs/2211.17192?utm_source=chatgpt.com","https://arxiv.org/abs/2309.06180?utm_source=chatgpt.com","https://arxiv.org/abs/2407.08608?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2407.08608?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"FlashAttention-3: Fast and Accurate Attention with Asynchrony and Low-precision","url":"https://arxiv.org/abs/2407.08608?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[{"title":"Efficient Memory Management for Large Language Model ...","url":"https://arxiv.org/abs/2309.06180?utm_source=chatgpt.com","pub_date":null,"snippet":"by W Kwon \u00b7 2023 \u00b7 Cited by 3693 \u2014 We propose PagedAttention, an attention algorithm inspired by the classical virtual memory and paging techniques in operating systems.","attribution":"arXiv"},{"title":"Fast Inference from Transformers via Speculative Decoding","url":"https://arxiv.org/abs/2211.17192?utm_source=chatgpt.com","pub_date":null,"snippet":"by Y Leviathan \u00b7 2022 \u00b7 Cited by 963 \u2014 In this work we introduce speculative decoding - an algorithm to sample from autoregressive models faster without any changes to the outputs.","attribution":"arXiv"}],"refs":[{"turn_index":22,"ref_type":"search","ref_index":2},{"turn_index":22,"ref_type":"search","ref_index":1},{"turn_index":24,"ref_type":"search","ref_index":2}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn23search0\ue201","start_idx":13987,"end_idx":14007,"safe_urls":["https://arxiv.org/abs/2203.15556?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2203.15556?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Training Compute-Optimal Large Language Models","url":"https://arxiv.org/abs/2203.15556?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":23,"ref_type":"search","ref_index":0}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn22search0\ue202turn14search1\ue201","start_idx":14060,"end_idx":14094,"safe_urls":["https://arxiv.org/abs/2305.18290?utm_source=chatgpt.com","https://arxiv.org/abs/2403.07691?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2305.18290?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Direct Preference Optimization: Your Language Model is Secretly a Reward Model","url":"https://arxiv.org/abs/2305.18290?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[{"title":"ORPO: Monolithic Preference Optimization without Reference Model","url":"https://arxiv.org/abs/2403.07691?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution":"arXiv"}],"refs":[{"turn_index":22,"ref_type":"search","ref_index":0},{"turn_index":14,"ref_type":"search","ref_index":1}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn16search1\ue202turn16search0\ue201","start_idx":14168,"end_idx":14202,"safe_urls":["https://arxiv.org/abs/2212.08073?utm_source=chatgpt.com","https://arxiv.org/abs/2401.10020?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2212.08073?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Constitutional AI: Harmlessness from AI Feedback","url":"https://arxiv.org/abs/2212.08073?utm_source=chatgpt.com","pub_date":null,"snippet":"by Y Bai \u00b7 2022 \u00b7 Cited by 2272 \u2014 We experiment with methods for training a harmless AI assistant through self-improvement, without any human labels identifying harmful outputs.","attribution_segments":null,"supporting_websites":[{"title":"Self-Rewarding Language Models","url":"https://arxiv.org/abs/2401.10020?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution":"arXiv"}],"refs":[{"turn_index":16,"ref_type":"search","ref_index":1},{"turn_index":16,"ref_type":"search","ref_index":0}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn7search1\ue202turn9search0\ue201","start_idx":14288,"end_idx":14320,"safe_urls":["https://arxiv.org/abs/2211.12588?utm_source=chatgpt.com","https://arxiv.org/abs/2402.03300?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2402.03300?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"DeepSeekMath: Pushing the Limits of Mathematical ...","url":"https://arxiv.org/abs/2402.03300?utm_source=chatgpt.com","pub_date":null,"snippet":"by Z Shao \u00b7 2024 \u00b7 Cited by 2460 \u2014 Second, we introduce Group Relative Policy Optimization (GRPO), a variant of Proximal Policy Optimization (PPO), that enhances mathematical ...","attribution_segments":null,"supporting_websites":[{"title":"Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks","url":"https://arxiv.org/abs/2211.12588?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution":"arXiv"}],"refs":[{"turn_index":7,"ref_type":"search","ref_index":1},{"turn_index":9,"ref_type":"search","ref_index":0}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn21search1\ue202turn21search17\ue202turn19view0\ue201","start_idx":14410,"end_idx":14457,"safe_urls":["https://arxiv.org/pdf/2501.12948","https://cdn.openai.com/o1-system-card-20241205.pdf?utm_source=chatgpt.com","https://openai.com/index/learning-to-reason-with-llms/?utm_source=chatgpt.com"],"refs":[],"alt":"([OpenAI](https://cdn.openai.com/o1-system-card-20241205.pdf?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"OpenAI o1 System Card","url":"https://cdn.openai.com/o1-system-card-20241205.pdf?utm_source=chatgpt.com","pub_date":1739576680,"snippet":"Dec 5, 2024 \u2014 Through training, the models learn to refine their thinking process, try different strategies, and recognize their mistakes. Reasoning allows o1 ...","attribution_segments":null,"supporting_websites":[{"title":"Learning to reason with LLMs","url":"https://openai.com/index/learning-to-reason-with-llms/?utm_source=chatgpt.com","pub_date":null,"snippet":"Sep 12, 2024 \u2014 We are introducing OpenAI o1, a new large language model trained with reinforcement learning to perform complex reasoning. o1 thinks before ...","attribution":"OpenAI"},{"title":"","url":"https://arxiv.org/pdf/2501.12948","pub_date":null,"snippet":null,"attribution":"arXiv"}],"refs":[{"turn_index":21,"ref_type":"search","ref_index":1},{"turn_index":21,"ref_type":"search","ref_index":17},{"turn_index":19,"ref_type":"view","ref_index":0}],"hue":null,"attributions":null,"attribution":"OpenAI"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn10search0\ue202turn10search13\ue201","start_idx":14517,"end_idx":14552,"safe_urls":["https://arxiv.org/abs/2302.04761?utm_source=chatgpt.com","https://proceedings.neurips.cc/paper_files/paper/2024/file/e4c61f578ff07830f5c37378dd3ecb0d-Paper-Conference.pdf?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2302.04761?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Toolformer: Language Models Can Teach Themselves to Use Tools","url":"https://arxiv.org/abs/2302.04761?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[{"title":"Gorilla: Large Language Model Connected with Massive ...","url":"https://proceedings.neurips.cc/paper_files/paper/2024/file/e4c61f578ff07830f5c37378dd3ecb0d-Paper-Conference.pdf?utm_source=chatgpt.com","pub_date":null,"snippet":"by SG Patil \u00b7 2024 \u00b7 Cited by 775 \u2014 We introduce Gorilla, the first system to enable large-scale API integration with LLMs, demonstrating state-of-the-art performance in generating accurate API ...","attribution":"NeurIPS Proceedings"}],"refs":[{"turn_index":10,"ref_type":"search","ref_index":0},{"turn_index":10,"ref_type":"search","ref_index":13}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn22search2\ue202turn22search1\ue202turn24search2\ue201","start_idx":14640,"end_idx":14688,"safe_urls":["https://arxiv.org/abs/2211.17192?utm_source=chatgpt.com","https://arxiv.org/abs/2309.06180?utm_source=chatgpt.com","https://arxiv.org/abs/2407.08608?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2407.08608?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"FlashAttention-3: Fast and Accurate Attention with Asynchrony and Low-precision","url":"https://arxiv.org/abs/2407.08608?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[{"title":"Efficient Memory Management for Large Language Model ...","url":"https://arxiv.org/abs/2309.06180?utm_source=chatgpt.com","pub_date":null,"snippet":"by W Kwon \u00b7 2023 \u00b7 Cited by 3693 \u2014 We propose PagedAttention, an attention algorithm inspired by the classical virtual memory and paging techniques in operating systems.","attribution":"arXiv"},{"title":"Fast Inference from Transformers via Speculative Decoding","url":"https://arxiv.org/abs/2211.17192?utm_source=chatgpt.com","pub_date":null,"snippet":"by Y Leviathan \u00b7 2022 \u00b7 Cited by 963 \u2014 In this work we introduce speculative decoding - an algorithm to sample from autoregressive models faster without any changes to the outputs.","attribution":"arXiv"}],"refs":[{"turn_index":22,"ref_type":"search","ref_index":2},{"turn_index":22,"ref_type":"search","ref_index":1},{"turn_index":24,"ref_type":"search","ref_index":2}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn6search1\ue202turn11search0\ue202turn11search3\ue201","start_idx":14744,"end_idx":14791,"safe_urls":["https://arxiv.org/abs/2203.14465?utm_source=chatgpt.com","https://arxiv.org/abs/2302.10866?utm_source=chatgpt.com","https://arxiv.org/abs/2312.00752?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2203.14465?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"STaR: Bootstrapping Reasoning With Reasoning","url":"https://arxiv.org/abs/2203.14465?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[{"title":"Mamba: Linear-Time Sequence Modeling with Selective State Spaces","url":"https://arxiv.org/abs/2312.00752?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution":"arXiv"},{"title":"Hyena Hierarchy: Towards Larger Convolutional Language Models","url":"https://arxiv.org/abs/2302.10866?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution":"arXiv"}],"refs":[{"turn_index":6,"ref_type":"search","ref_index":1},{"turn_index":11,"ref_type":"search","ref_index":0},{"turn_index":11,"ref_type":"search","ref_index":3}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":" ","start_idx":15010,"end_idx":15010,"safe_urls":[],"refs":[],"alt":"","prompt_text":null,"type":"sources_footnote","sources":[{"title":"OpenAI o1 System Card","url":"https://cdn.openai.com/o1-system-card-20241205.pdf?utm_source=chatgpt.com","attribution":"OpenAI"},{"title":"Direct Preference Optimization: Your Language Model is Secretly a Reward Model","url":"https://arxiv.org/abs/2305.18290?utm_source=chatgpt.com","attribution":"arXiv"},{"title":"NVIDIA Blackwell Architecture","url":"https://www.nvidia.com/en-us/data-center/technologies/blackwell-architecture/?utm_source=chatgpt.com","attribution":"NVIDIA"}],"has_images":false}],"safe_urls":["https://arxiv.org/pdf/2501.12948","https://cdn.openai.com/o1-system-card-20241205.pdf?utm_source=chatgpt.com","https://openai.com/index/learning-to-reason-with-llms/?utm_source=chatgpt.com","https://arxiv.org/abs/2305.18290?utm_source=chatgpt.com","https://arxiv.org/abs/2403.07691?utm_source=chatgpt.com","https://arxiv.org/pdf/2305.18290?utm_source=chatgpt.com","https://arxiv.org/abs/2212.08073?utm_source=chatgpt.com","https://arxiv.org/abs/2401.10020?utm_source=chatgpt.com","https://www-cdn.anthropic.com/7512771452629584566b6303311496c262da1006/Anthropic_ConstitutionalAI_v2.pdf?utm_source=chatgpt.com","https://arxiv.org/abs/2211.12588?utm_source=chatgpt.com","https://arxiv.org/abs/2402.03300?utm_source=chatgpt.com","https://arxiv.org/abs/2203.14465?utm_source=chatgpt.com","https://arxiv.org/abs/2211.17192?utm_source=chatgpt.com","https://arxiv.org/abs/2309.06180?utm_source=chatgpt.com","https://arxiv.org/abs/2312.00752?utm_source=chatgpt.com","https://arxiv.org/abs/2407.08608?utm_source=chatgpt.com","https://arxiv.org/abs/2203.15556?utm_source=chatgpt.com","https://arxiv.org/abs/2305.18290?utm_source=chatgpt.com","https://arxiv.org/pdf/2305.18290?utm_source=chatgpt.com","https://arxiv.org/abs/2403.07691?utm_source=chatgpt.com","https://arxiv.org/pdf/2403.07691?utm_source=chatgpt.com","https://arxiv.org/abs/2212.08073?utm_source=chatgpt.com","https://www-cdn.anthropic.com/7512771452629584566b6303311496c262da1006/Anthropic_ConstitutionalAI_v2.pdf?utm_source=chatgpt.com","https://arxiv.org/abs/2401.10020?utm_source=chatgpt.com","https://arxiv.org/abs/2312.09390?utm_source=chatgpt.com","https://arxiv.org/abs/2211.12588?utm_source=chatgpt.com","https://arxiv.org/abs/2402.03300?utm_source=chatgpt.com","https://arxiv.org/pdf/2501.12948","https://cdn.openai.com/o1-system-card-20241205.pdf?utm_source=chatgpt.com","https://openai.com/index/learning-to-reason-with-llms/?utm_source=chatgpt.com","https://arxiv.org/pdf/2501.12948","https://arxiv.org/abs/2211.17192?utm_source=chatgpt.com","https://arxiv.org/html/2403.18647v1?utm_source=chatgpt.com","https://aclanthology.org/2025.emnlp-main.376.pdf?utm_source=chatgpt.com","https://arxiv.org/abs/2306.14050?utm_source=chatgpt.com","https://arxiv.org/abs/2302.04761?utm_source=chatgpt.com","https://arxiv.org/pdf/2302.04761?utm_source=chatgpt.com","https://proceedings.neurips.cc/paper_files/paper/2024/file/e4c61f578ff07830f5c37378dd3ecb0d-Paper-Conference.pdf?utm_source=chatgpt.com","https://arxiv.org/abs/2310.11511?utm_source=chatgpt.com","https://arxiv.org/abs/2404.16130?utm_source=chatgpt.com","https://arxiv.org/abs/2203.14465?utm_source=chatgpt.com","https://arxiv.org/abs/2302.10866?utm_source=chatgpt.com","https://arxiv.org/abs/2312.00752?utm_source=chatgpt.com","https://arxiv.org/abs/2309.06180?utm_source=chatgpt.com","https://arxiv.org/abs/2407.08608?utm_source=chatgpt.com","https://cloud.google.com/blog/products/ai-machine-learning/introducing-cloud-tpu-v5p-and-ai-hypercomputer?utm_source=chatgpt.com","https://www.nvidia.com/en-us/data-center/technologies/blackwell-architecture/?utm_source=chatgpt.com","https://arxiv.org/abs/2203.15556?utm_source=chatgpt.com","https://arxiv.org/abs/2305.18290?utm_source=chatgpt.com","https://arxiv.org/abs/2403.07691?utm_source=chatgpt.com","https://arxiv.org/abs/2212.08073?utm_source=chatgpt.com","https://arxiv.org/abs/2401.10020?utm_source=chatgpt.com","https://arxiv.org/abs/2402.03300?utm_source=chatgpt.com","https://arxiv.org/pdf/2501.12948","https://arxiv.org/pdf/2501.12948","https://cdn.openai.com/o1-system-card-20241205.pdf?utm_source=chatgpt.com","https://arxiv.org/abs/2211.17192?utm_source=chatgpt.com","https://arxiv.org/abs/2203.14465?utm_source=chatgpt.com","https://arxiv.org/abs/2302.10866?utm_source=chatgpt.com","https://arxiv.org/abs/2312.00752?utm_source=chatgpt.com","https://arxiv.org/abs/2309.06180?utm_source=chatgpt.com","https://arxiv.org/abs/2407.08608?utm_source=chatgpt.com","https://arxiv.org/abs/2402.03300?utm_source=chatgpt.com","https://arxiv.org/abs/2211.17192?utm_source=chatgpt.com","https://arxiv.org/pdf/2501.12948","https://cdn.openai.com/o1-system-card-20241205.pdf?utm_source=chatgpt.com","https://arxiv.org/abs/2203.15556?utm_source=chatgpt.com","https://arxiv.org/abs/2305.18290?utm_source=chatgpt.com","https://arxiv.org/abs/2403.07691?utm_source=chatgpt.com","https://arxiv.org/abs/2302.04761?utm_source=chatgpt.com","https://proceedings.neurips.cc/paper_files/paper/2024/file/e4c61f578ff07830f5c37378dd3ecb0d-Paper-Conference.pdf?utm_source=chatgpt.com","https://arxiv.org/abs/2402.03300?utm_source=chatgpt.com","https://arxiv.org/abs/2211.17192?utm_source=chatgpt.com","https://arxiv.org/abs/2309.06180?utm_source=chatgpt.com","https://arxiv.org/abs/2407.08608?utm_source=chatgpt.com","https://arxiv.org/abs/2306.14050?utm_source=chatgpt.com","https://arxiv.org/pdf/2501.12948","https://arxiv.org/abs/2203.14465?utm_source=chatgpt.com","https://arxiv.org/abs/2312.00752?utm_source=chatgpt.com","https://cdn.openai.com/o1-system-card-20241205.pdf?utm_source=chatgpt.com","https://arxiv.org/abs/2211.17192?utm_source=chatgpt.com","https://arxiv.org/abs/2309.06180?utm_source=chatgpt.com","https://arxiv.org/abs/2407.08608?utm_source=chatgpt.com","https://arxiv.org/abs/2203.15556?utm_source=chatgpt.com","https://arxiv.org/abs/2305.18290?utm_source=chatgpt.com","https://arxiv.org/abs/2403.07691?utm_source=chatgpt.com","https://arxiv.org/abs/2212.08073?utm_source=chatgpt.com","https://arxiv.org/abs/2401.10020?utm_source=chatgpt.com","https://arxiv.org/abs/2211.12588?utm_source=chatgpt.com","https://arxiv.org/abs/2402.03300?utm_source=chatgpt.com","https://arxiv.org/pdf/2501.12948","https://cdn.openai.com/o1-system-card-20241205.pdf?utm_source=chatgpt.com","https://openai.com/index/learning-to-reason-with-llms/?utm_source=chatgpt.com","https://arxiv.org/abs/2302.04761?utm_source=chatgpt.com","https://proceedings.neurips.cc/paper_files/paper/2024/file/e4c61f578ff07830f5c37378dd3ecb0d-Paper-Conference.pdf?utm_source=chatgpt.com","https://arxiv.org/abs/2211.17192?utm_source=chatgpt.com","https://arxiv.org/abs/2309.06180?utm_source=chatgpt.com","https://arxiv.org/abs/2407.08608?utm_source=chatgpt.com","https://arxiv.org/abs/2203.14465?utm_source=chatgpt.com","https://arxiv.org/abs/2302.10866?utm_source=chatgpt.com","https://arxiv.org/abs/2312.00752?utm_source=chatgpt.com"],"search_result_groups":[{"type":"search_result_group","domain":"arxiv.org","entries":[{"type":"search_result","url":"https://arxiv.org/abs/2309.00267?utm_source=chatgpt.com","title":"RLAIF vs. RLHF: Scaling Reinforcement Learning from ...","snippet":"by H Lee \u00b7 2023 \u00b7 Cited by 283 \u2014 Our results suggest that RLAIF can achieve performance on-par with using human feedback, offering a potential solution to the scalability limitations of RLHF.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2305.18290?utm_source=chatgpt.com","title":"Direct Preference Optimization: Your Language Model is ...","snippet":"by R Rafailov \u00b7 2023 \u00b7 Cited by 5990 \u2014 In this paper, we show how to directly optimize a language model to adhere to human preferences, without explicit reward modeling or ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2501.07301?utm_source=chatgpt.com","title":"The Lessons of Developing Process Reward Models in ...","snippet":"by Z Zhang \u00b7 2025 \u00b7 Cited by 183 \u2014 Process Reward Models (PRMs) emerge as a promising approach for process supervision in mathematical reasoning of Large Language Models ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2401.10020?utm_source=chatgpt.com","title":"Self-Rewarding Language Models","snippet":"Mar 28, 2025 \u2014 We posit that to achieve superhuman agents, future models require super- human feedback in order to provide an adequate training signal.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2305.18290v2?utm_source=chatgpt.com","title":"Direct Preference Optimization: Your Language Model is ...","snippet":"In this paper, we show how to directly optimize a language model to adhere to human preferences, without explicit reward modeling or reinforcement learning. We ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2305.20050?utm_source=chatgpt.com","title":"arXiv:2305.20050v1 [cs.LG] 31 May 2023","snippet":"May 31, 2023 \u2014 1. We show that process supervision can train much more reliable reward models than outcome supervision. We use our state-of-the-art PRM to.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2502.08922v1?utm_source=chatgpt.com","title":"Self-Consistency of the Internal Reward Models Improves ...","snippet":"Feb 13, 2025 \u2014 By employing self-consistent internal rewards, our method significantly improves the alignment performance and reward modeling capability of ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2508.19652v1?utm_source=chatgpt.com","title":"Self-Rewarding Vision-Language Model via Reasoning ...","snippet":"Aug 27, 2025 \u2014 These works show that internal visual signals can provide rich reward feedback for VLM alignment without costly supervision, yet the reward is ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":23},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2401.10020v1/?utm_source=chatgpt.com","title":"Self-Rewarding Language Models","snippet":"Jan 18, 2024 \u2014 RRHF: Rank responses to align language models with human feedback. In Thirty-seventh Conference on Neural Information Processing Systems, 2023.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":27},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2305.10601?utm_source=chatgpt.com","title":"Deliberate Problem Solving with Large Language Models","snippet":"by S Yao \u00b7 2023 \u00b7 Cited by 4450 \u2014 Tree of Thoughts (ToT) is a framework for language models that enables exploration over text units, allowing deliberate decision making and ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2203.11171?utm_source=chatgpt.com","title":"Self-Consistency Improves Chain of Thought Reasoning in ...","snippet":"by X Wang \u00b7 2022 \u00b7 Cited by 3135 \u2014 In this paper, we propose a new decoding strategy, self-consistency, to replace the naive greedy decoding used in chain-of-thought prompting.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2305.10601?utm_source=chatgpt.com","title":"Tree of Thoughts: Deliberate Problem Solving with Large ...","snippet":"Dec 3, 2023 \u2014 Tree of Thoughts (ToT) is a framework for language models that enables exploration of 'thoughts' as intermediate steps, allowing for deliberate ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2203.11171?utm_source=chatgpt.com","title":"Self-Consistency Improves Chain of Thought Reasoning in ...","snippet":"by X Wang \u00b7 2022 \u00b7 Cited by 3138 \u2014 In this paper, we introduce a novel decoding strategy called self-consistency to replace the greedy decoding strategy used in chain-of-thought ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2201.11903?utm_source=chatgpt.com","title":"Chain-of-Thought Prompting Elicits Reasoning in Large ...","snippet":"by J Wei \u00b7 2022 \u00b7 Cited by 21524 \u2014 We explore how generating a chain of thought -- a series of intermediate reasoning steps -- significantly improves the ability of large language models to ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2503.14521v1?utm_source=chatgpt.com","title":"Policy Frameworks for Transparent Chain-of-Thought ...","snippet":"Mar 14, 2025 \u2014 Through APIs of OpenAI's flagship reasoning models including o1, o3, and o3-mini, the reasoning trajectory is entirely invisible to users ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":21},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2305.08291?utm_source=chatgpt.com","title":"Large Language Model Guided Tree-of-Thought","snippet":"by J Long \u00b7 2023 \u00b7 Cited by 293 \u2014 In this paper, we introduce the Tree-of-Thought (ToT) framework, a novel ap- proach aimed at improving the problem-solving capabilities of ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":26},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2210.11610?utm_source=chatgpt.com","title":"Large language models can self-improve","snippet":"by J Huang \u00b7 2022 \u00b7 Cited by 740 \u2014 Self-consistency (Wang et al., 2022b) brings large improvements on reasoning tasks (e.g., 56.5% \u2192. 74.4% on GSM8K test set), and the gap between ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":31},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2412.14135v1?utm_source=chatgpt.com","title":"A Roadmap to Reproduce o1 from Reinforcement Learning ...","snippet":"Dec 18, 2024 \u2014 This paper analyzes the roadmap to achieving o1 from the perspective of reinforcement learning, focusing on four key components: policy initialization, reward ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":32},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2502.12893v1?utm_source=chatgpt.com","title":"H-CoT: Hijacking the Chain-of-Thought Safety Reasoning ...","snippet":"Feb 18, 2025 \u2014 We propose Hijacking Chain-of-Thought (H-CoT), a universal and transferable attack method that leverages the model's own displayed intermediate reasoning to ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":36},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2101.03961?utm_source=chatgpt.com","title":"Switch Transformers: Scaling to Trillion Parameter Models ...","snippet":"by W Fedus \u00b7 2021 \u00b7 Cited by 3244 \u2014 Mixture of Experts (MoE) defies this and instead selects different parameters for each incoming example. The result is a sparsely-activated ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":0},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2412.19437?utm_source=chatgpt.com","title":"[2412.19437] DeepSeek-V3 Technical Report","snippet":"by A Liu \u00b7 2024 \u00b7 Cited by 2372 \u2014 We present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with 671B total parameters with 37B activated for each token.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2407.06204?utm_source=chatgpt.com","title":"A Survey on Mixture of Experts in Large Language Models","snippet":"by W Cai \u00b7 2024 \u00b7 Cited by 123 \u2014 Mixture of Experts (MoE) scales model capacity by having different parts (experts) specialize in different tasks, engaging only relevant ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2412.19437v1?utm_source=chatgpt.com","title":"DeepSeek-V3 Technical Report","snippet":"We present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with 671B total parameters with 37B activated for each token.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2407.06204v2?utm_source=chatgpt.com","title":"A Survey on Mixture of Experts","snippet":"Aug 8, 2024 \u2014 While sparse activation of experts, as a trade-off, may yield computational efficiency gains at the expense of some performance loss when ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2506.12119v1?utm_source=chatgpt.com","title":"Can Mixture-of-Experts Surpass Dense LLMs Under Strictly ...","snippet":"Jun 13, 2025 \u2014 As an early attempt, Switch Transformer (Fedus et al., 2022) proposed top-1 gating to simplify MoE architecture and alleviate communication ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2505.09343v1?utm_source=chatgpt.com","title":"Insights into DeepSeek-V3: Scaling Challenges and ...","snippet":"May 14, 2025 \u2014 This paper presents an in-depth analysis of the DeepSeek-V3/R1 model architecture and its AI infrastructure, highlighting key innovations.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":25},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2411.19477?utm_source=chatgpt.com","title":"Simple and Provable Scaling Laws for the Test-Time ...","snippet":"by Y Chen \u00b7 2024 \u00b7 Cited by 14 \u2014 We propose two simple, principled and practical algorithms that enjoy provable scaling laws for the test-time compute of large language models (LLMs).","ref_id":{"turn_index":3,"ref_type":"search","ref_index":0},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2408.03314?utm_source=chatgpt.com","title":"Scaling LLM Test-Time Compute Optimally can be More ...","snippet":"by C Snell \u00b7 2024 \u00b7 Cited by 936 \u2014 Optimally scaling test-time compute in LLMs can be more effective than scaling model parameters, even outperforming a 14x larger model in some ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2302.01318?utm_source=chatgpt.com","title":"Accelerating Large Language Model Decoding with ...","snippet":"by C Chen \u00b7 2023 \u00b7 Cited by 487 \u2014 We present speculative sampling, an algorithm for accelerating transformer decoding by enabling the generation of multiple tokens from each ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2407.08608?utm_source=chatgpt.com","title":"FlashAttention-3","snippet":"by J Shah \u00b7 2024 \u00b7 Cited by 240 \u2014 We develop three main techniques to speed up attention on Hopper GPUs: exploiting asynchrony of the Tensor Cores and TMA to (1) overlap overall ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2309.06180?utm_source=chatgpt.com","title":"Efficient Memory Management for Large Language Model ...","snippet":"by W Kwon \u00b7 2023 \u00b7 Cited by 3688 \u2014 This paper proposes PagedAttention, a new attention algo- rithm that allows attention keys and values to be stored in non-contiguous paged ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2407.08608v1?utm_source=chatgpt.com","title":"FlashAttention-3: Fast and Accurate Attention with ...","snippet":"Jul 11, 2024 \u2014 We develop three main techniques to speed up attention on Hopper GPUs: exploiting asynchrony of the Tensor Cores and TMA to (1) overlap overall computation and ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2211.17192?utm_source=chatgpt.com","title":"arXiv:2211.17192v2 [cs.LG] 18 May 2023","snippet":"by Y Leviathan \u00b7 2022 \u00b7 Cited by 960 \u2014 In this work we in- troduce speculative decoding - an algorithm to sample from autoregressive models faster without any changes to the outputs, ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2510.19705v2?utm_source=chatgpt.com","title":"Introduction","snippet":"Oct 23, 2025 \u2014 We build on the speculative decoding method (Chen et al., 2023; Leviathan et al., 2023) for accelerating transformers. In this framework, an ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2212.10560?utm_source=chatgpt.com","title":"Aligning Language Models with Self-Generated Instructions","snippet":"by Y Wang \u00b7 2022 \u00b7 Cited by 2768 \u2014 View a PDF of the paper titled Self-Instruct: Aligning Language Models with Self-Generated Instructions, by Yizhong Wang and 6 other authors.","ref_id":{"turn_index":5,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2304.12244?utm_source=chatgpt.com","title":"[2304.12244] WizardLM: Empowering large pre-trained ...","snippet":"by C Xu \u00b7 2023 \u00b7 Cited by 1023 \u2014 Starting with an initial set of instructions, we use our proposed Evol-Instruct to rewrite them step by step into more complex instructions.","ref_id":{"turn_index":5,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2406.17557?utm_source=chatgpt.com","title":"Decanting the Web for the Finest Text Data at Scale","snippet":"by G Penedo \u00b7 2024 \u00b7 Cited by 260 \u2014 We introduce FineWeb, a 15-trillion token dataset derived from 96 Common Crawl snapshots that produces better-performing LLMs than other open pretraining ...","ref_id":{"turn_index":5,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2304.12244?utm_source=chatgpt.com","title":"WizardLM: EMPOWERING LARGE PRE-TRAINED LAN","snippet":"by C Xu \u00b7 2023 \u00b7 Cited by 1022 \u2014 This paper presented Evol-Instruct, an evolutionary algorithm that generates diverse and complex instruction data for LLM. Comprehensive ...","ref_id":{"turn_index":5,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2203.15556?utm_source=chatgpt.com","title":"Training Compute-Optimal Large Language Models","snippet":"by J Hoffmann \u00b7 2022 \u00b7 Cited by 3029 \u2014 We introduce Chinchilla, a substantially smaller model, trained for much longer than 300B tokens. Model. Size (# Parameters) Training Tokens.","ref_id":{"turn_index":5,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2212.10560?utm_source=chatgpt.com","title":"arXiv:2212.10560v2 [cs.CL] 25 May 2023","snippet":"by Y Wang \u00b7 2022 \u00b7 Cited by 2766 \u2014 We evaluate GPT3SELF-INST in comparison to various other models on both typical NLP tasks in- cluded in SUPERNI (Wang et al., 2022), and a set ...","ref_id":{"turn_index":5,"ref_type":"search","ref_index":23},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2406.17557v1?utm_source=chatgpt.com","title":"Decanting the Web for the Finest Text Data at Scale","snippet":"Jun 25, 2024 \u2014 With FineWeb, we aim to provide the open source community with a clean and large-scale dataset for pretraining performant large language models.","ref_id":{"turn_index":5,"ref_type":"search","ref_index":26},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2402.00159?utm_source=chatgpt.com","title":"Dolma: an Open Corpus of Three Trillion Tokens for ...","snippet":"by L Soldaini \u00b7 2024 \u00b7 Cited by 276 \u2014 To facilitate scientific research on language model pretraining, we curate and release Dolma, a three-trillion-token English corpus, built from ...","ref_id":{"turn_index":5,"ref_type":"search","ref_index":37},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2403.09629?utm_source=chatgpt.com","title":"Quiet-STaR: Language Models Can Teach Themselves to ...","snippet":"by E Zelikman \u00b7 2024 \u00b7 Cited by 191 \u2014 We present Quiet-STaR, a generalization of STaR in which LMs learn to generate rationales at each token to explain future text, improving their predictions.Jump t...","ref_id":{"turn_index":6,"ref_type":"search","ref_index":0},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2308.08998?utm_source=chatgpt.com","title":"Reinforced Self-Training (ReST) for Language Modeling","snippet":"by C Gulcehre \u00b7 2023 \u00b7 Cited by 349 \u2014 We propose a simple algorithm for aligning LLMs with human preferences inspired by growing batch reinforcement learning (RL), which we call Reinforced Self- ...","ref_id":{"turn_index":6,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2308.08998?utm_source=chatgpt.com","title":"Reinforced Self-Training (ReST) for Language Modeling","snippet":"by C Gulcehre \u00b7 2023 \u00b7 Cited by 349 \u2014 Typically, human feedback is used to learn a reward model, which is then used to fine-tune LLM with a reinforcement learning (RL) objective.","ref_id":{"turn_index":6,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2403.09629v1?utm_source=chatgpt.com","title":"Quiet-STaR: Language Models Can Teach Themselves to ...","snippet":"Mar 14, 2024 \u2014 We present Quiet-STaR, a generalization of STaR in which LMs learn to generate rationales at each token to explain future text, improving their predictions.Jump to","ref_id":{"turn_index":6,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://ar5iv.labs.arxiv.org/html/2203.14465?utm_source=chatgpt.com","title":"[2203.14465] STaR: Self-Taught Reasoner Bootstrapping ...","snippet":"This technique, the \"Self-Taught Reasoner\" (STaR), relies on a simple loop: generate rationales to answer many questions, prompted with a few rationale ...","ref_id":{"turn_index":6,"ref_type":"search","ref_index":21},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2502.13550v1?utm_source=chatgpt.com","title":"STaR-SQL: Self-Taught Reasoner for Text-to-SQL","snippet":"Feb 19, 2025 \u2014 In this paper, we introduce Self-Taught Reasoner for text-to-SQL (STaR-SQL), a novel approach that reframes SQL query generation as a reasoning-driven process.","ref_id":{"turn_index":6,"ref_type":"search","ref_index":27},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2501.12948?utm_source=chatgpt.com","title":"DeepSeek-R1: Incentivizing Reasoning Capability in LLMs ...","snippet":"by D Guo \u00b7 2025 \u00b7 Cited by 4839 \u2014 Abstract page for arXiv paper 2501.12948: DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning.","ref_id":{"turn_index":7,"ref_type":"search","ref_index":0},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2501.12948?utm_source=chatgpt.com","title":"DeepSeek-R1: Incentivizing Reasoning Capability in LLMs ...","snippet":"by D Guo \u00b7 2025 \u00b7 Cited by 4839 \u2014 In this paper, we take the first step toward improving language model reasoning capabilities using pure reinforcement learning (RL). Our ...","ref_id":{"turn_index":7,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2402.03300?utm_source=chatgpt.com","title":"DeepSeekMath","snippet":"by Z Shao \u00b7 2024 \u00b7 Cited by 2460 \u2014 Second, we introduce Group Relative Policy Optimization. (GRPO), a variant of Proximal Policy Optimization (PPO), that enhances mathematical ...","ref_id":{"turn_index":7,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2501.12948v1?utm_source=chatgpt.com","title":"DeepSeek-R1: Incentivizing Reasoning Capability in LLMs ...","snippet":"In this paper, we take the first step toward improving language model reasoning capabilities using pure reinforcement learning (RL).","ref_id":{"turn_index":7,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2502.02523?utm_source=chatgpt.com","title":"Brief analysis of DeepSeek R1 and its implications for ...","snippet":"by S Mercer \u00b7 2025 \u00b7 Cited by 20 \u2014 In late January 2025, DeepSeek released their new reasoning model (DeepSeek R1); which was developed at a fraction of the cost yet remains ...","ref_id":{"turn_index":7,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2310.11511?utm_source=chatgpt.com","title":"Self-RAG: Learning to Retrieve, Generate, and Critique ...","snippet":"by A Asai \u00b7 2023 \u00b7 Cited by 1266 \u2014 We introduce a new framework called Self-Reflective Retrieval-Augmented Generation (Self-RAG) that enhances an LM's quality and factuality through retrieval ...","ref_id":{"turn_index":8,"ref_type":"search","ref_index":0},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2405.07437?utm_source=chatgpt.com","title":"Evaluation of Retrieval-Augmented Generation: A Survey","snippet":"by H Yu \u00b7 2024 \u00b7 Cited by 245 \u2014 We examine and compare several quantifiable metrics of the Retrieval and Generation components, such as relevance, accuracy, and faithfulness, within the ...","ref_id":{"turn_index":8,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2410.12837?utm_source=chatgpt.com","title":"[2410.12837] A Comprehensive Survey of Retrieval ...","snippet":"by S Gupta \u00b7 2024 \u00b7 Cited by 137 \u2014 This paper presents a comprehensive study of Retrieval-Augmented Generation (RAG), tracing its evolution from foundational concepts to the current state of the ...","ref_id":{"turn_index":8,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2405.06211?utm_source=chatgpt.com","title":"A Survey on RAG Meeting LLMs: Towards Retrieval ...","snippet":"by W Fan \u00b7 2024 \u00b7 Cited by 878 \u2014 In this survey, we comprehensively review existing research studies in RA-LLMs, covering three primary technical perspectives: architectures, training ...","ref_id":{"turn_index":8,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2402.19473?utm_source=chatgpt.com","title":"[2402.19473] Retrieval-Augmented Generation for AI- ...","snippet":"by P Zhao \u00b7 2024 \u00b7 Cited by 543 \u2014 RAG introduces the information retrieval process, which enhances the generation process by retrieving relevant objects from available data stores.","ref_id":{"turn_index":8,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2503.10677v2?utm_source=chatgpt.com","title":"A Survey on Knowledge-Oriented Retrieval-Augmented ...","snippet":"This survey aims to provide a comprehensive overview of RAG by examining its fundamental components, including retrieval mechanisms, generation processes, and ...","ref_id":{"turn_index":8,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2501.09136?utm_source=chatgpt.com","title":"[2501.09136] Agentic Retrieval-Augmented Generation","snippet":"by A Singh \u00b7 2025 \u00b7 Cited by 139 \u2014 This survey provides a comprehensive exploration of Agentic RAG, beginning with its foundational principles and the evolution of RAG paradigms.","ref_id":{"turn_index":8,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2404.16130v1?utm_source=chatgpt.com","title":"A Graph RAG Approach to Query-Focused Summarization","snippet":"We propose a Graph RAG approach to question answering over private text corpora that scales with both the generality of user questions and the quantity of ...","ref_id":{"turn_index":8,"ref_type":"search","ref_index":22},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2211.12588?utm_source=chatgpt.com","title":"[2211.12588] Program of Thoughts Prompting","snippet":"by W Chen \u00b7 2022 \u00b7 Cited by 1023 \u2014 To disentangle computation from reasoning, we propose `Program of Thoughts' (PoT), which uses language models (mainly Codex) to express the reasoning process ...","ref_id":{"turn_index":9,"ref_type":"search","ref_index":0},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2211.10435?utm_source=chatgpt.com","title":"[2211.10435] PAL: Program-aided Language Models","snippet":"by L Gao \u00b7 2022 \u00b7 Cited by 1164 \u2014 In this paper, we present Program-Aided Language models (PAL): a novel approach that uses the LLM to read natural language problems and generate programs.","ref_id":{"turn_index":9,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2305.20050?utm_source=chatgpt.com","title":"[2305.20050] Let's Verify Step by Step","snippet":"by H Lightman \u00b7 2023 \u00b7 Cited by 1868 \u2014 We conduct our own investigation, finding that process supervision significantly outperforms outcome supervision for training models to solve problems.","ref_id":{"turn_index":9,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2211.10435?utm_source=chatgpt.com","title":"PAL: Program-aided Language Models","snippet":"by L Gao \u00b7 2022 \u00b7 Cited by 1164 \u2014 In this paper, we present Program-. Aided Language models (PAL): a novel approach that uses the LLM to read natural language prob- lems and generate programs as ...","ref_id":{"turn_index":9,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2305.11461v7?utm_source=chatgpt.com","title":"Hint of Thought prompting: an explainable and zero-shot ...","snippet":"This paper proposes a novel hint of thought (HoT) prompting with explain-ability and zero-shot logicalbility. It is decomposed into three steps.","ref_id":{"turn_index":9,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2308.15452?utm_source=chatgpt.com","title":"When Do Program-of-Thoughts Work for Reasoning?","snippet":"by Z Bi \u00b7 2023 \u00b7 Cited by 40 \u2014 Although there are effective methods like program-of-thought prompting for LLMs which uses programming language to tackle complex reasoning ...","ref_id":{"turn_index":9,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2510.12829?utm_source=chatgpt.com","title":"Mathematics with large language models as provers and ...","snippet":"by HL Duc \u00b7 2025 \u2014 In this paper we report a theorem proving feat achieved by ChatGPT by using a protocol involving different prover and verifier instances of the ...","ref_id":{"turn_index":9,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2510.12829?utm_source=chatgpt.com","title":"Mathematics with large language models as provers and ...","snippet":"by HL Duc \u00b7 2025 \u2014 In this paper we report a theorem proving feat achieved by ChatGPT by using a protocol involving different prover and verifier instances of the ...","ref_id":{"turn_index":9,"ref_type":"search","ref_index":24},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2305.11461?utm_source=chatgpt.com","title":"Zero-Shot Step by Step Pseudo Code Reasoning Prompting","snippet":"by I Lei \u00b7 2023 \u00b7 Cited by 2 \u2014 The Program of Thought (PoT) aims to generate text and programming language solutions for multi-step reasoning problems. In zero-shot CoT ...","ref_id":{"turn_index":9,"ref_type":"search","ref_index":25},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2305.15334?utm_source=chatgpt.com","title":"Gorilla: Large Language Model Connected with Massive ...","snippet":"by SG Patil \u00b7 2023 \u00b7 Cited by 775 \u2014 We release Gorilla, a finetuned LLaMA-based model that surpasses the performance of GPT-4 on writing API calls.","ref_id":{"turn_index":10,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2302.04761?utm_source=chatgpt.com","title":"arXiv:2302.04761v1 [cs.CL] 9 Feb 2023","snippet":"by T Schick \u00b7 2023 \u00b7 Cited by 2563 \u2014 In contrast, the self-supervised nature of Toolformer enables it to learn how and when to use tools without requiring a specific prompt that.","ref_id":{"turn_index":10,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2407.19832?utm_source=chatgpt.com","title":"ML-Mamba: Efficient Multi-Modal Large Language Model ...","snippet":"by W Huang \u00b7 2024 \u00b7 Cited by 15 \u2014 We introduce ML-Mamba, a multimodal language model, which utilizes the latest and efficient Mamba-2 model for inference.","ref_id":{"turn_index":11,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2302.10866?utm_source=chatgpt.com","title":"Hyena Hierarchy: Towards Larger Convolutional ...","snippet":"by M Poli \u00b7 2023 \u00b7 Cited by 473 \u2014 Hyena is a subquadratic attention replacement using convolutions and gating, improving accuracy and reducing training compute, reaching Transformer quality.","ref_id":{"turn_index":11,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2312.00752?utm_source=chatgpt.com","title":"Mamba: Linear-Time Sequence Modeling with Selective ...","snippet":"May 31, 2024 \u2014 Mamba is a neural network architecture using selective state space models, integrated without attention or MLP blocks, to model sequences.","ref_id":{"turn_index":11,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2405.21060?utm_source=chatgpt.com","title":"Transformers are SSMs: Generalized Models and Efficient ...","snippet":"by T Dao \u00b7 2024 \u00b7 Cited by 1036 \u2014 State-space models (SSMs) such as Mamba have recently been shown to match or outperform Transformers at small to medium scale.","ref_id":{"turn_index":11,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2404.05892?utm_source=chatgpt.com","title":"Eagle and Finch: RWKV with Matrix-Valued States","snippet":"by B Peng \u00b7 2024 \u00b7 Cited by 100 \u2014 Abstract:We present Eagle (RWKV-5) and Finch (RWKV-6), sequence models improving upon the RWKV (RWKV-4) architecture.","ref_id":{"turn_index":11,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2302.10866?utm_source=chatgpt.com","title":"Hyena Hierarchy","snippet":"by M Poli \u00b7 2023 \u00b7 Cited by 469 \u2014 Abstract. Recent advances in deep learning have relied heavily on the use of large Transformers due to their ability to learn at scale.","ref_id":{"turn_index":11,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2406.07887?utm_source=chatgpt.com","title":"An Empirical Study of Mamba-based Language Models","snippet":"by R Waleffe \u00b7 2024 \u00b7 Cited by 163 \u2014 We present a direct comparison between 8B-parameter Mamba, Mamba-2, and Transformer models trained on the same datasets of up to 3.5T tokens.","ref_id":{"turn_index":11,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2312.00752v2?utm_source=chatgpt.com","title":"Linear-Time Sequence Modeling with Selective State Spaces","snippet":"We propose a new class of selective state space models, that improves on prior work on several axes to achieve the modeling power of Transformers while scaling ...","ref_id":{"turn_index":11,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2412.14847?utm_source=chatgpt.com","title":"A Survey of RWKV","snippet":"by Z Li \u00b7 2024 \u00b7 Cited by 12 \u2014 This paper seeks to fill this gap as the first comprehensive review of the RWKV architecture, its core principles, and its varied applications, ...","ref_id":{"turn_index":11,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2412.14847v2?utm_source=chatgpt.com","title":"A Survey of RWKV","snippet":"This paper seeks to fill this gap as the first comprehensive review of the RWKV architecture, its core principles, and its varied applications.","ref_id":{"turn_index":11,"ref_type":"search","ref_index":20},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2406.07887?utm_source=chatgpt.com","title":"An Empirical Study of Mamba-based Language Models","snippet":"by R Waleffe \u00b7 2024 \u00b7 Cited by 163 \u2014 Mamba requires two all-reduces per layer while Mamba-2 requires only one. More details can be found in Dao and Gu 2024. extending hybrid SSM- ...","ref_id":{"turn_index":11,"ref_type":"search","ref_index":30},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2404.05892?utm_source=chatgpt.com","title":"arXiv:2404.05892v4 [cs.CL] 26 Sep 2024","snippet":"by B Peng \u00b7 2024 \u00b7 Cited by 96 \u2014 In this paper, we introduce two new architectures: Eagle (RWKV-5) and Finch (RWKV-6). First,. Eagle improves upon the architecture and ...","ref_id":{"turn_index":11,"ref_type":"search","ref_index":35},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2510.22500v1?utm_source=chatgpt.com","title":"Scalable Oversight via Partitioned Human Supervision","snippet":"Oct 26, 2025 \u2014 Our main contributions are as follows: 1) We introduce scalable oversight via partitioned human supervision, a protocol that exploits real-world ...","ref_id":{"turn_index":13,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2504.18530v3?utm_source=chatgpt.com","title":"Scaling Laws For Scalable Oversight","snippet":"A key idea is that scalable oversight can be bootstrapped: weaker systems oversee stronger ones, which then oversee even stronger models in the next stage\u2014 ...","ref_id":{"turn_index":13,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2502.16182?utm_source=chatgpt.com","title":"Your Language Model is Secretly a Preference Classifier","snippet":"by S Garg \u00b7 2025 \u00b7 Cited by 5 \u2014 In this work, we propose Implicit Preference Optimization (IPO), an alternative approach that leverages generative LLMs as preference classifiers.","ref_id":{"turn_index":14,"ref_type":"search","ref_index":0},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2403.07691v1?utm_source=chatgpt.com","title":"Reference-free Monolithic Preference Optimization with ...","snippet":"We introduce a novel preference alignment algorithm, Odds Ratio Preference Optimization (ORPO), which incorporates an odds ratio-based ...","ref_id":{"turn_index":14,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2506.07492?utm_source=chatgpt.com","title":"Explicit Preference Optimization: No Need for an Implicit ...","snippet":"by X Hu \u00b7 2025 \u2014 Explicit Preference Optimization (EXPO) is a framework that optimizes human preferences without needing implicit rewards or reparameterization, ...","ref_id":{"turn_index":14,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2403.07691?utm_source=chatgpt.com","title":"arXiv:2403.07691v2 [cs.CL] 14 Mar 2024","snippet":"by J Hong \u00b7 2024 \u00b7 Cited by 378 \u2014 We introduce a novel preference alignment algo- rithm, Odds Ratio Preference Optimization (ORPO), which incorporates an odds ratio-based penalty.","ref_id":{"turn_index":14,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2405.20830?utm_source=chatgpt.com","title":"Self-Augmented Preference Optimization","snippet":"by Y Yin \u00b7 2024 \u00b7 Cited by 3 \u2014 Odds Ratio Preference Optimization (ORPO) Hong et al. [2024]. For ORPO, we adhered to the default settings used on the Distilabel-Capybara ...","ref_id":{"turn_index":14,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2404.00530v2?utm_source=chatgpt.com","title":"Aligning Large Language Models via Joint Preference ...","snippet":"Jan 7, 2025 \u2014 In this work, we propose a framework that elicits preferences jointly over instruction-response pairs. Further, we find that the joint ...","ref_id":{"turn_index":14,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://www.arxiv.org/pdf/2510.03988?utm_source=chatgpt.com","title":"Distilling Reasoning into Student LLMs","snippet":"by HA Just \u00b7 2025 \u2014 Distilling long reasoning traces (10K+ tokens) from stronger teacher models into smaller student LLMs via supervised fine-tuning (SFT) has ...","ref_id":{"turn_index":15,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2504.08120?utm_source=chatgpt.com","title":"DeepSeek-R1 vs. o3-mini: How Well can Reasoning LLMs ...","snippet":"by D Larionov \u00b7 2025 \u00b7 Cited by 5 \u2014 This study systematically compares reasoning LLMs with non-reasoning counterparts across machine translation and text summarization evaluation tasks.","ref_id":{"turn_index":15,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2505.24850?utm_source=chatgpt.com","title":"Reinforcement Distillation from Teacher Data for LLM ...","snippet":"by S Xu \u00b7 2025 \u00b7 Cited by 1 \u2014 An alternative, more cost-effective strategy for smaller, efficient student models is distillation, where reasoning traces (e.g., Chain-of- ...","ref_id":{"turn_index":15,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2502.18001v1?utm_source=chatgpt.com","title":"Unveiling the Key Factors for Distilling Chain-of-Thought ...","snippet":"Feb 25, 2025 \u2014 These findings emphasize the need to tailor CoT strategies to specific student model, offering actionable insights for optimizing CoT ...","ref_id":{"turn_index":15,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2212.08073?utm_source=chatgpt.com","title":"Constitutional AI: Harmlessness from AI Feedback","snippet":"Dec 15, 2022 \u2014 Past experiments [Bai et al., 2022] showed that. RLHF significantly improves the models' ability to follow instructions, and the HH model is ...","ref_id":{"turn_index":16,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/1805.00899?utm_source=chatgpt.com","title":"[1805.00899] AI safety via debate","snippet":"by G Irving \u00b7 2018 \u00b7 Cited by 329 \u2014 Authors:Geoffrey Irving, Paul Christiano, Dario Amodei. View a PDF of the paper titled AI safety via debate, by Geoffrey Irving and 2 other ...","ref_id":{"turn_index":17,"ref_type":"search","ref_index":0},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2501.13124v1?utm_source=chatgpt.com","title":"Debate Helps Weak-to-Strong Generalization","snippet":"Jan 21, 2025 \u2014 In this paper, we empirically test it by finetuning a small weak model on ground truth labels with the additional help of knowledge from a ...","ref_id":{"turn_index":17,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://ar5iv.labs.arxiv.org/html/1805.00899?utm_source=chatgpt.com","title":"[1805.00899] AI safety via debate - ar5iv - arXiv","snippet":"[2018] Paul Christiano, Buck Shlegeris, and Dario Amodei. Supervising strong learners by amplifying weak experts. arXiv preprint arXiv:1810.08575, 2018.","ref_id":{"turn_index":17,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2412.16720v1?utm_source=chatgpt.com","title":"OpenAI o1 System Card","snippet":"The o1 model series is trained with large-scale reinforcement learning to reason using chain of thought. These advanced reasoning capabilities provide new ...","ref_id":{"turn_index":21,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2412.16720?utm_source=chatgpt.com","title":"[2412.16720] OpenAI o1 System Card","snippet":"by A Jaech \u00b7 2024 \u00b7 Cited by 1236 \u2014 The o1 model series is trained with large-scale reinforcement learning to reason using chain of thought. These advanced reasoning capabilities ...","ref_id":{"turn_index":21,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2502.05202v1?utm_source=chatgpt.com","title":"Accelerating LLM Inference with Lossless Speculative ...","snippet":"Speculative decoding (SD; Leviathan et al., 2023; Chen et al., 2023 ) is an effective method for accelerating LLM inference and increasing its throughput.","ref_id":{"turn_index":24,"ref_type":"search","ref_index":0},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2505.02865v1?utm_source=chatgpt.com","title":"Accelerating Large Language Model Reasoning via ...","snippet":"May 3, 2025 \u2014 We propose a novel Speculative Search (SpecSearch) framework that significantly accelerates LLM reasoning by optimizing thought generation.","ref_id":{"turn_index":24,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2403.18647v1?utm_source=chatgpt.com","title":"Accelerating LLM Inference through Speculative Decoding ...","snippet":"Leviathan et al. (2023) introduced the speculative sampling method and proved that the distribution of the generated text remains unchanged for both the greedy ...","ref_id":{"turn_index":24,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"arxiv.org"}]},{"type":"search_result_group","domain":"bluedot.org","entries":[{"type":"search_result","url":"https://bluedot.org/blog/scalable-oversight-intro?utm_source=chatgpt.com","title":"Can we scale human feedback for complex AI tasks? An ...","snippet":"Mar 18, 2024 \u2014 Why might scalable oversight not work? Uncertain assumptions that might not pan out. For example, task decomposition approaches were abandoned ...","ref_id":{"turn_index":13,"ref_type":"search","ref_index":0},"pub_date":null,"attribution":"bluedot.org"},{"type":"search_result","url":"https://bluedot.org/courses/alignment/4?utm_source=chatgpt.com","title":"AI Alignment: Unit 4 | Resources: Scalable oversight","snippet":"This paper introduced iterated amplification, a task decomposition approach. The paper explains the method more precisely, how it relates to other similar ...","ref_id":{"turn_index":13,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"bluedot.org"}]},{"type":"search_result_group","domain":"openai.com","entries":[{"type":"search_result","url":"https://openai.com/index/improving-mathematical-reasoning-with-process-supervision/?utm_source=chatgpt.com","title":"Improving mathematical reasoning with process supervision","snippet":"May 31, 2023 \u2014 We've trained a model to achieve a new state-of-the-art in mathematical problem solving by rewarding each correct step of reasoning (\u201cprocess supervision\u201d)","ref_id":{"turn_index":0,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"openai.com"},{"type":"search_result","url":"https://cdn.openai.com/papers/weak-to-strong-generalization.pdf?utm_source=chatgpt.com","title":"WEAK-TO-STRONG GENERALIZATION: ELICITING ...","snippet":"by C Burns \u00b7 Cited by 364 \u2014 For NLP and chess we supervise GPT-4 using GPT-2-level supervision, while for reward modeling we supervise a 3.5-level model using GPT-2-level ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"openai.com"},{"type":"search_result","url":"https://openai.com/index/learning-to-reason-with-llms/?utm_source=chatgpt.com","title":"Learning to reason with LLMs","snippet":"Sep 12, 2024 \u2014 Our large-scale reinforcement learning algorithm teaches the model how to think productively using its chain of thought in a highly data-efficient training ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":21},"pub_date":null,"attribution":"openai.com"},{"type":"search_result","url":"https://openai.com/index/introducing-o3-and-o4-mini/?utm_source=chatgpt.com","title":"Introducing OpenAI o3 and o4-mini","snippet":"Apr 16, 2025 \u2014 OpenAI o3 is our most powerful reasoning model that pushes the frontier across coding, math, science, visual perception, and more. It sets a new ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"openai.com"},{"type":"search_result","url":"https://openai.com/index/o3-mini-system-card/?utm_source=chatgpt.com","title":"OpenAI o3-mini System Card","snippet":"Jan 31, 2025 \u2014 The OpenAI o model series is trained with large-scale reinforcement learning to reason using chain of thought. These advanced reasoning ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"openai.com"},{"type":"search_result","url":"https://cdn.openai.com/pdf/2221c875-02dc-4789-800b-e7758f3722c1/o3-and-o4-mini-system-card.pdf?utm_source=chatgpt.com","title":"OpenAI o3 and o4-mini System Card","snippet":"Apr 16, 2025 \u2014 The OpenAI o-series models are trained with large-scale reinforcement learning on chains of thought. These advanced reasoning capabilities ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"openai.com"},{"type":"search_result","url":"https://openai.com/index/deliberative-alignment/?utm_source=chatgpt.com","title":"Deliberative alignment: reasoning enables safer language ...","snippet":"Dec 20, 2024 \u2014 We introduce deliberative alignment, a training paradigm that directly teaches reasoning LLMs the text of human-written and interpretable safety specifications.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"openai.com"},{"type":"search_result","url":"https://openai.com/index/o3-o4-mini-system-card/?utm_source=chatgpt.com","title":"OpenAI o3 and o4-mini System Card","snippet":"Apr 16, 2025 \u2014 The OpenAI o-series models are trained with large-scale reinforcement learning on chains of thought. These advanced reasoning capabilities ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"openai.com"},{"type":"search_result","url":"https://community.openai.com/t/tree-of-thoughts-prompting-method-that-outperforms-other-methods/226512?utm_source=chatgpt.com","title":"Tree of Thoughts \u2014 prompting method that outperforms ...","snippet":"May 24, 2023 \u2014 Tree of Thoughts (ToT) is a framework for complex problem solving using a 'System 2' tree search, enhancing LLMs, and achieving 74% success in ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":30},"pub_date":null,"attribution":"openai.com"},{"type":"search_result","url":"https://cdn.openai.com/pdf/34f2ada6-870f-4c26-9790-fd8def56387f/CoT_Monitoring.pdf?utm_source=chatgpt.com","title":"Monitoring Reasoning Models for Misbehavior and the ...","snippet":"by B Baker \u00b7 Cited by 114 \u2014 We show that we can monitor a frontier reasoning model, such as OpenAI o3-mini, for reward hacking in agentic coding environments by using ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":33},"pub_date":null,"attribution":"openai.com"},{"type":"search_result","url":"https://community.openai.com/t/papers-quiet-star-language-models-can-teach-themselves-to-think-before-speaking/686158?utm_source=chatgpt.com","title":"[PAPERS] Quiet-STaR: Language Models Can Teach ...","snippet":"Mar 16, 2024 \u2014 Quiet-STaR is a method that helps language models (LMs) to improve their predictions by teaching them to generate rationales, or internal thoughts, for each ...Jump to","ref_id":{"turn_index":6,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"openai.com"},{"type":"search_result","url":"https://cdn.openai.com/improving-mathematical-reasoning-with-process-supervision/Lets_Verify_Step_by_Step.pdf?utm_source=chatgpt.com","title":"Let's Verify Step by Step 1 Introduction","snippet":"We use our state-of-the-art PRM to solve 78.2% of problems from a representative subset of the MATH test set. 2. We show that a large reward model can reliably ...","ref_id":{"turn_index":9,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"openai.com"},{"type":"search_result","url":"https://cdn.openai.com/prover-verifier-games-improve-legibility-of-llm-outputs/legibility.pdf?utm_source=chatgpt.com","title":"PROVER-VERIFIER GAMES IMPROVE LEGIBILITY OF ...","snippet":"by JH Kirchner \u00b7 Cited by 46 \u2014 One way to increase confidence in the outputs of Large Language Models (LLMs) is to support them with reasoning that is clear and easy to check \u2014 a property.","ref_id":{"turn_index":9,"ref_type":"search","ref_index":36},"pub_date":null,"attribution":"openai.com"},{"type":"search_result","url":"https://openai.com/index/introducing-superalignment/?utm_source=chatgpt.com","title":"Introducing Superalignment","snippet":"Jul 5, 2023 \u2014 Our goal is to build a roughly human-level automated alignment researcher\u2060. We can then use vast amounts of compute to scale our efforts ...","ref_id":{"turn_index":13,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"openai.com"},{"type":"search_result","url":"https://openai.com/index/weak-to-strong-generalization/?utm_source=chatgpt.com","title":"Weak-to-strong generalization","snippet":"Dec 14, 2023 \u2014 Today, we are releasing the team's first paper, which introduces a new research direction for empirically aligning superhuman models. ... weak-to- ...","ref_id":{"turn_index":17,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"openai.com"},{"type":"search_result","url":"https://openai.com/index/debate/?utm_source=chatgpt.com","title":"AI safety via debate","snippet":"May 3, 2018 \u2014 We're proposing an AI safety technique which trains agents to debate topics with one another, using a human to judge who wins.","ref_id":{"turn_index":17,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"openai.com"},{"type":"search_result","url":"https://openai.com/index/openai-o1-system-card/?utm_source=chatgpt.com","title":"OpenAI o1 System Card","snippet":"The o1 model series is trained with large-scale reinforcement learning to reason using chain-of-thought. These advanced reasoning capabilities provide new ...","ref_id":{"turn_index":21,"ref_type":"search","ref_index":0},"pub_date":null,"attribution":"openai.com"},{"type":"search_result","url":"https://openai.com/index/introducing-openai-o1-preview/?utm_source=chatgpt.com","title":"Introducing OpenAI o1-preview","snippet":"Sep 12, 2024 \u2014 A new series of AI models designed to spend more time thinking before they respond. They can reason through complex tasks and solve harder problems than ...","ref_id":{"turn_index":21,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"openai.com"},{"type":"search_result","url":"https://platform.openai.com/docs/guides/reasoning?utm_source=chatgpt.com","title":"Reasoning models - OpenAI API","snippet":"Explore the capabilities of OpenAI's o1 series for complex reasoning and problem-solving. Learn about their features and how they compare to GPT-4o models.","ref_id":{"turn_index":21,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"openai.com"}]},{"type":"search_result_group","domain":"huggingface.co","entries":[{"type":"search_result","url":"https://huggingface.co/papers?q=Process+Reward+Models+%28PRMs%29&utm_source=chatgpt.com","title":"Daily Papers","snippet":"We introduce our first reflective generative model MetaStone-S1, which obtains OpenAI o3's performance via the self-supervised process reward model (SPRM).","ref_id":{"turn_index":0,"ref_type":"search","ref_index":25},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/papers/2305.10601?utm_source=chatgpt.com","title":"Tree of Thoughts: Deliberate Problem Solving with Large ...","snippet":"May 17, 2023 \u2014 Tree of Thoughts (ToT) enhances language models' problem-solving by exploring multiple reasoning paths and enabling deliberate decision-making.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":22},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/papers/2412.19437?utm_source=chatgpt.com","title":"Paper page - DeepSeek-V3 Technical Report","snippet":"Dec 26, 2024 \u2014 We present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with 671B total parameters with 37B activated for each token.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/google/switch-base-16?utm_source=chatgpt.com","title":"google/switch-base-16","snippet":"Switch Transformers is a Mixture of Experts (MoE) model trained on Masked Language Modeling (MLM) task. The model architecture is similar to the classic T5.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":27},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/spaces/HuggingFaceH4/blogpost-scaling-test-time-compute?utm_source=chatgpt.com","title":"Scaling test-time compute","snippet":"Dec 16, 2024 \u2014 This application implements test-time compute scaling to improve the performance of open language models on math problems.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/datasets/HuggingFaceFW/fineweb?utm_source=chatgpt.com","title":"HuggingFaceFW/fineweb \u00b7 Datasets at ...","snippet":"With FineWeb we aim to provide the open source community with a very large clean pretraining dataset that can be used to push the envelope on truly open ...","ref_id":{"turn_index":5,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/datasets/allenai/dolma?utm_source=chatgpt.com","title":"allenai/dolma \u00b7 Datasets at Hugging Face","snippet":"Dolma is a dataset of 3 trillion tokens from a diverse mix of web content, academic publications, code, books, and encyclopedic materials.","ref_id":{"turn_index":5,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/spaces/HuggingFaceFW/blogpost-fineweb-v1?utm_source=chatgpt.com","title":"FineWeb: decanting the web for the finest text data at scale","snippet":"May 31, 2024 \u2014 FineWeb creates a large-scale, high-quality text dataset for training large language models by processing and deduplicating web data.","ref_id":{"turn_index":5,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/datasets/allenai/dolma/discussions/37?utm_source=chatgpt.com","title":"allenai/dolma \u00b7 Common Crawl Dataset Partitioning method?","snippet":"Jun 3, 2024 \u2014 In the paper \"Dolma:an Open Corpus of Three Trillion Tokens for Language Model Pretraining Research\", the author give a figure to show the ...","ref_id":{"turn_index":5,"ref_type":"search","ref_index":22},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/datasets/WizardLMTeam/WizardLM_evol_instruct_70k?utm_source=chatgpt.com","title":"WizardLMTeam/WizardLM_evol_instruct_70k \u00b7 Datasets at ...","snippet":"Paper cutting: Materials: - Paper - Scissors Instructions: - Fold the paper in half horizontally. - Fold the paper in half vertically. - Cut along the ...","ref_id":{"turn_index":5,"ref_type":"search","ref_index":24},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/datasets/yizhongw/self_instruct?utm_source=chatgpt.com","title":"yizhongw/self_instruct \u00b7 Datasets at Hugging Face","snippet":"Self-Instruct is a framework that helps language models improve their ability to follow natural language instructions. It does this by using the model's own ...","ref_id":{"turn_index":5,"ref_type":"search","ref_index":33},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/papers/2304.12244?utm_source=chatgpt.com","title":"Empowering Large Language Models to Follow Complex ...","snippet":"Apr 24, 2023 \u2014 In this paper, we show an avenue for creating large amounts of instruction data with varying levels of complexity using LLM instead of humans.","ref_id":{"turn_index":5,"ref_type":"search","ref_index":39},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/allenai/open-instruct-self-instruct-13b?utm_source=chatgpt.com","title":"allenai/open-instruct-self-instruct-13b","snippet":"Mar 7, 2023 \u2014 Exploring the State of Instruction Tuning on Open Resources}, author={Yizhong Wang ... arXiv preprint arXiv:2212.10560}, year={2022} }.","ref_id":{"turn_index":5,"ref_type":"search","ref_index":48},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/deepseek-ai/DeepSeek-R1?utm_source=chatgpt.com","title":"deepseek-ai/DeepSeek-R1","snippet":"May 29, 2025 \u2014 We introduce DeepSeek-R1, which incorporates cold-start data before RL. DeepSeek-R1 achieves performance comparable to OpenAI-o1 across math, code, and ...","ref_id":{"turn_index":7,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/docs/course/chapter12/3?utm_source=chatgpt.com","title":"Understanding the DeepSeek R1 Paper","snippet":"The paper introduces a new reinforcement learning algorithm called Group Relative Policy Optimization (GRPO). DeepSeek R1 Overview. In the next chapter, we will ...","ref_id":{"turn_index":7,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/papers/2302.04761?utm_source=chatgpt.com","title":"Language Models Can Teach Themselves to Use Tools","snippet":"Feb 9, 2023 \u2014 Toolformer, a language model, self-supervisedly learns to use external tools via APIs, enhancing its zero-shot performance on various tasks.","ref_id":{"turn_index":10,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/papers/2305.15334?utm_source=chatgpt.com","title":"Large Language Model Connected with Massive APIs","snippet":"May 24, 2023 \u2014 Gorilla, a finetuned LLaMA model, excels in writing API calls with more accuracy and flexibility than GPT-4, using a document retriever to ...","ref_id":{"turn_index":10,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/papers/2302.10866?utm_source=chatgpt.com","title":"Towards Larger Convolutional Language Models","snippet":"Feb 21, 2023 \u2014 We propose Hyena, a subquadratic drop-in replacement for attention constructed by interleaving implicitly parametrized long convolutions and data-controlled ...","ref_id":{"turn_index":11,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/nvidia/mamba2-8b-3t-4k?utm_source=chatgpt.com","title":"nvidia/mamba2-8b-3t-4k","snippet":"Oct 21, 2025 \u2014 We release the 8B-parameter Mamba-2 and Mamba-2-Hybrid model (made of Mamba-2, attention, and MLP layers) trained for the paper An Empirical Study of Mamba- ...","ref_id":{"turn_index":11,"ref_type":"search","ref_index":23},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/papers/2403.07691?utm_source=chatgpt.com","title":"Monolithic Preference Optimization without Reference Model","snippet":"Mar 12, 2024 \u2014 We introduce a straightforward and innovative reference model-free monolithic odds ratio preference optimization algorithm, ORPO, eliminating the necessity for ...","ref_id":{"turn_index":14,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/papers/2401.10020?utm_source=chatgpt.com","title":"Paper page - Self-Rewarding Language Models","snippet":"Jan 18, 2024 \u2014 In this work, we study Self-Rewarding Language Models, where the language model itself is used via LLM-as-a-Judge prompting to provide its own ...","ref_id":{"turn_index":16,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"huggingface.co"}]},{"type":"search_result_group","domain":"google.com","entries":[{"type":"search_result","url":"https://scholar.google.com/citations?hl=en&user=TwABcRgAAAAJ&utm_source=chatgpt.com","title":"Rafael Mitkov Rafailov","snippet":"Direct preference optimization: Your language model is secretly a reward model. R Rafailov, A Sharma, E Mitchell, CD Manning, S Ermon, C Finn. Advances in ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":36},"pub_date":null,"attribution":"google.com"},{"type":"search_result","url":"https://scholar.google.com/citations?hl=en&user=V5B8dSUAAAAJ&utm_source=chatgpt.com","title":"Eric Zelikman","snippet":"STaR: Bootstrapping reasoning with reasoning. E Zelikman, Y Wu, J Mu, ND Goodman. NeurIPS 2022, 2022. 1146*, 2022 ; Quiet-STaR: Language models can teach ...","ref_id":{"turn_index":6,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"google.com"},{"type":"search_result","url":"https://cloud.google.com/tpu/pricing?utm_source=chatgpt.com","title":"Cloud TPU pricing","snippet":"Estimate your cost. Estimate the cost of using Cloud TPU with the Compute Engine pricing calculator, choose \u201cCloud TPU\u201d on the top bar. Free access via TRC.","ref_id":{"turn_index":12,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"google.com"},{"type":"search_result","url":"https://cloud.google.com/blog/products/ai-machine-learning/introducing-cloud-tpu-v5p-and-ai-hypercomputer?utm_source=chatgpt.com","title":"Introducing Cloud TPU v5p and AI Hypercomputer","snippet":"Dec 6, 2023 \u2014 Earlier this year, we announced the general availability of Cloud TPU v5e. With 2.3X price performance improvements over the previous generation ...","ref_id":{"turn_index":12,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"google.com"},{"type":"search_result","url":"https://cloud.google.com/blog/products/compute/performance-per-dollar-of-gpus-and-tpus-for-ai-inference?utm_source=chatgpt.com","title":"Performance per dollar of GPUs and TPUs for AI inference","snippet":"Sep 12, 2023 \u2014 The new Cloud TPU v5e, announced at Google Cloud Next, enables high-performance and cost-effective inference for a broad range AI workloads, ...","ref_id":{"turn_index":12,"ref_type":"search","ref_index":28},"pub_date":null,"attribution":"google.com"},{"type":"search_result","url":"https://scholar.google.com/citations?hl=en&user=NQRw0bQAAAAJ&utm_source=chatgpt.com","title":"Tri Dao","snippet":"FlashAttention: Fast and memory-efficient exact attention with IO-awareness. T Dao, D Fu, S Ermon, A Rudra, C R\u00e9. Advances in neural information processing ...","ref_id":{"turn_index":22,"ref_type":"search","ref_index":20},"pub_date":null,"attribution":"google.com"}]},{"type":"search_result_group","domain":"openreview.net","entries":[{"type":"search_result","url":"https://openreview.net/forum?id=AAxIs3D2ZZ&utm_source=chatgpt.com","title":"RLAIF: Scaling Reinforcement Learning from Human ...","snippet":"by H Lee \u00b7 Cited by 676 \u2014 Abstract: Reinforcement learning from human feedback (RLHF) is an effective technique for aligning large language models (LLMs) to human ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/pdf?id=HPuSIXJaa9&utm_source=chatgpt.com","title":"Direct Preference Optimization: Your Language Model is ...","snippet":"by R Rafailov \u00b7 Cited by 5990 \u2014 In this paper, we show how to directly optimize a language model to adhere to human preferences, without explicit reward modeling or reinforcement learning. We ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/pdf?id=0NphYCmgua&utm_source=chatgpt.com","title":"Self-Rewarding Language Models","snippet":"by W Yuan \u00b7 Cited by 549 \u2014 Abstract. We posit that to achieve superhuman agents, fu- ture models require superhuman feedback in order to provide an adequate training signal.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":35},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/forum?id=5Xc1ecxO1h&utm_source=chatgpt.com","title":"Tree of Thoughts: Deliberate Problem Solving with Large ...","snippet":"by S Yao \u00b7 Cited by 4450 \u2014 Tree of Thoughts (ToT) is a framework for language models that enables exploration of 'thoughts' as intermediate steps for problem solving, ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/forum?id=1PL1NIMMrw&utm_source=chatgpt.com","title":"Self-Consistency Improves Chain of Thought Reasoning in ...","snippet":"by X Wang \u00b7 Cited by 3138 \u2014 In this paper, we propose a new decoding strategy, self-consistency, to replace the naive greedy decoding used in chain-of-thought prompting. It ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/forum?id=4FWAwZtd2n&utm_source=chatgpt.com","title":"Scaling LLM Test-Time Compute Optimally Can be More ...","snippet":"by CV Snell \u00b7 Cited by 125 \u2014 Optimally scaling test-time compute can outperform much larger models in a FLOPs-matched evaluation, and can improve efficiency by more than 4x.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/forum?id=tVConYid20&referrer=%5Bthe+profile+of+Tri+Dao%5D%28%2Fprofile%3Fid%3D~Tri_Dao1%29&utm_source=chatgpt.com","title":"FlashAttention-3: Fast and Accurate Attention with ...","snippet":"There has already been a paper from Colfax (arXiv 2312.11918) available online more than half a year ago describing how to implement efficient FlashAttention on ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/forum?id=CfXh93NDgH&utm_source=chatgpt.com","title":"WizardLM: Empowering Large Pre-Trained Language ...","snippet":"by C Xu \u00b7 Cited by 323 \u2014 In this paper, we show an avenue for creating large amounts of instruction data with varying levels of complexity using LLM instead of humans.","ref_id":{"turn_index":5,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/forum?id=jnRBe6zatP&utm_source=chatgpt.com","title":"FineWeb2: One Pipeline to Scale Them All \u2014 Adapting Pre ...","snippet":"by G Penedo \u00b7 Cited by 15 \u2014 In this work, we introduce a new pre-training dataset curation pipeline based on FineWeb that can be automatically adapted to support any language. We ...","ref_id":{"turn_index":5,"ref_type":"search","ref_index":36},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/pdf?id=_3ELRdg2sgI&utm_source=chatgpt.com","title":"STaR: Self-Taught Reasoner","snippet":"by E Zelikman \u00b7 2022 \u00b7 Cited by 1054 \u2014 STaR is a technique that iteratively generates rationales, refines the model, and fine-tunes on correct answers, using a loop to improve itself.","ref_id":{"turn_index":6,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/forum?id=8rcFOqEud5&utm_source=chatgpt.com","title":"LLM Self-Training via Process Reward Guided Tree Search","snippet":"by D Zhang \u00b7 Cited by 297 \u2014 In this paper, we develop a reinforced self-training approach, called ReST-MCTS*, based on integrating process reward guidance with tree search MCTS* for ...","ref_id":{"turn_index":6,"ref_type":"search","ref_index":19},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/pdf/bae0b8ad9a6997d28df14db90f717c0beae4d571.pdf?utm_source=chatgpt.com","title":"Reflection-Reinforced Self-Training for Language Agents","snippet":"Figure 2: An overview of our Re-ReST method. Our approach incorporates self-training in language agent tasks by sampling multiple outputs from an agent and ...","ref_id":{"turn_index":6,"ref_type":"search","ref_index":25},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/pdf?id=hSyW5go0v8&utm_source=chatgpt.com","title":"SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND ...","snippet":"by A Asai \u00b7 Cited by 1264 \u2014 In particular, SELF-RAG outperforms retrieval-augmented ChatGPT on four tasks, Llama2-chat (Touvron et al., 2023) and Alpaca (Dubois et al., 2023) on all tasks.","ref_id":{"turn_index":8,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/forum?id=0er6aOyXUD&utm_source=chatgpt.com","title":"Evaluating Robustness of Reward Models for Mathematical ...","snippet":"by S Kim \u00b7 Cited by 9 \u2014 The paper introduces RewardMATH, a new benchmark for evaluating reward models in mathematical reasoning tasks, designed to address limitations in the existing ...","ref_id":{"turn_index":9,"ref_type":"search","ref_index":27},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/forum?id=YfZ4ZPt8zd&utm_source=chatgpt.com","title":"Program of Thoughts Prompting: Disentangling ...","snippet":"by W Chen \u00b7 Cited by 1023 \u2014 Here we propose `Program of Thoughts' (PoT), which uses language models (mainly Codex) to generate text and programming language statements, and ...","ref_id":{"turn_index":9,"ref_type":"search","ref_index":29},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/pdf?id=Yacmpz84TH&utm_source=chatgpt.com","title":"Toolformer: Language Models Can Teach Themselves to ...","snippet":"by T Schick \u00b7 Cited by 2563 \u2014 We have introduced Toolformer, a LM that learns in a self-supervised way how to use different tools such as search engines, calculators, and translation systems ...","ref_id":{"turn_index":10,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/pdf/8b1adabdb46c50f4f229110fd2a095c9c2f3520f.pdf?utm_source=chatgpt.com","title":"Quantizing the RWKV Family with Proxy Guided Hybrid of ...","snippet":"It contains several blocks and each block has two key modules: Time Mixing and Channel Mixing. language understanding tasks, RWKV-v6 (Peng et al., 2024) has ...","ref_id":{"turn_index":11,"ref_type":"search","ref_index":27},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/forum?id=l5Wrcgyobp&utm_source=chatgpt.com","title":"Scalable Oversight in Multi-Agent Systems: Provable ...","snippet":"by M Bronikowski \u2014 This paper presents Hierarchical Delegated Oversight (HDO), a framework for scalable oversight in multi-agent systems that uses structured ...","ref_id":{"turn_index":13,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/pdf?id=a3PmRgAB5T&utm_source=chatgpt.com","title":"SELF-PLAY PREFERENCE OPTIMIZATION FOR LAN","snippet":"by Y Wu \u00b7 Cited by 183 \u2014 Self-Play Preference Optimization (SPPO) is a self-play-based method for language model alignment, treating it as a two-player game to identify the Nash ...","ref_id":{"turn_index":14,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/forum?id=N1vYivuSKq&utm_source=chatgpt.com","title":"Weak to Strong Generalization for Large Language Models ...","snippet":"by Y Zhou \u00b7 Cited by 93 \u2014 This paper first conducts a series of analyses to explore the factors influencing the spectrum from weak to strong generalization in large language models (LLMs) ...","ref_id":{"turn_index":17,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"openreview.net"}]},{"type":"search_result_group","domain":"rwkv.com","entries":[{"type":"search_result","url":"https://blog.rwkv.com/archive?utm_source=chatgpt.com","title":"Archive - RWKV Open Source Development Blog","snippet":"RWKV v6 Finch 14B is here! From 14B, 7B, 3B, 1.6B here are the various RWKV v6 models. Sep 2, 2024 \u2022 ...","ref_id":{"turn_index":11,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"rwkv.com"},{"type":"search_result","url":"https://wiki.rwkv.com/basic/architecture.html?utm_source=chatgpt.com","title":"RWKV Architecture History","snippet":"Aug 12, 2025 \u2014 The version code of RWKV-V6 is \"Finch\". This version was developed in October 2023 and is the currently (November 2024) stable architecture.","ref_id":{"turn_index":11,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"rwkv.com"}]},{"type":"search_result_group","domain":"microsoft.com","entries":[{"type":"search_result","url":"https://www.microsoft.com/en-us/research/project/graphrag/?utm_source=chatgpt.com","title":"Project GraphRAG - Microsoft Research","snippet":"GraphRAG (Graphs + Retrieval Augmented Generation) is a technique for richly understanding text datasets by combining text extraction, network analysis, and ...","ref_id":{"turn_index":8,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"microsoft.com"},{"type":"search_result","url":"https://www.microsoft.com/en-us/research/project/graphrag/publications/?utm_source=chatgpt.com","title":"Project GraphRAG - Microsoft Research: Publications","snippet":"Publications. View by: Year, Research Area, Publication Type. Expand all | Collapse all. 2024. From Local to Global: A Graph RAG Approach to Query-Focused ...","ref_id":{"turn_index":8,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"microsoft.com"},{"type":"search_result","url":"https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/?utm_source=chatgpt.com","title":"GraphRAG: Unlocking LLM discovery on narrative private ...","snippet":"Feb 13, 2024 \u2014 Microsoft Research's new approach, GraphRAG, uses the LLM to create a knowledge graph based on the private dataset. This graph is then used ...","ref_id":{"turn_index":8,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"microsoft.com"},{"type":"search_result","url":"https://www.microsoft.com/en-us/research/wp-content/uploads/2024/07/The-Stack-GraphRAG-article.pdf?utm_source=chatgpt.com","title":"The-Stack-GraphRAG-article.pdf","snippet":"Jul 26, 2024 \u2014 We spoke to Microsoft to understand more about GraphRAG and how it improves upon existing RAG methodologies. Jonathan Larson, Senior Principal ...","ref_id":{"turn_index":8,"ref_type":"search","ref_index":25},"pub_date":null,"attribution":"microsoft.com"},{"type":"search_result","url":"https://techcommunity.microsoft.com/blog/azureinfrastructureblog/inside-maia-100-revolutionizing-ai-workloads-with-microsofts-custom-ai-accelerat/4229118?utm_source=chatgpt.com","title":"Inside Maia 100: Revolutionizing AI Workloads with ...","snippet":"Aug 27, 2024 \u2014 Microsoft's first-generation custom AI accelerator designed specifically for large-scale AI workloads deployed in Azure.","ref_id":{"turn_index":12,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"microsoft.com"},{"type":"search_result","url":"https://azure.microsoft.com/en-us/blog/azure-maia-for-the-era-of-ai-from-silicon-to-software-to-systems/?utm_source=chatgpt.com","title":"Azure Maia for the era of AI: From silicon to software ...","snippet":"Apr 3, 2024 \u2014 Azure Maia 100 is a unique innovation combining state-of-the-art silicon packaging techniques, ultra-high-bandwidth networking design, modern cooling and power ...","ref_id":{"turn_index":12,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"microsoft.com"}]},{"type":"search_result_group","domain":"sebastianraschka.com","entries":[{"type":"search_result","url":"https://magazine.sebastianraschka.com/p/ai-research-papers-2024-part-1?utm_source=chatgpt.com","title":"Noteworthy AI Research Papers of 2024 (Part One) - Ahead of AI","snippet":"Dec 31, 2024 \u2014 In DoRA: Weight-Decomposed Low-Rank Adaptation (February 2024), Liu and colleagues.extend LoRA by first decomposing a pretrained weight matrix ...","ref_id":{"turn_index":13,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"sebastianraschka.com"}]},{"type":"search_result_group","domain":"aclanthology.org","entries":[{"type":"search_result","url":"https://aclanthology.org/2025.findings-acl.930.pdf?utm_source=chatgpt.com","title":"Process-based Self-Rewarding Language Models","snippet":"by S Zhang \u00b7 2025 \u00b7 Cited by 16 \u2014 2023. Rrhf: Rank responses to align language models with human feedback without tears. arXiv preprint. arXiv:2304.05302. Shimao Zhang, Yu Bao ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":31},"pub_date":null,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2025.acl-long.212.pdf?utm_source=chatgpt.com","title":"Dynamic and Generalizable Process Reward Modeling","snippet":"by Z Yin \u00b7 2025 \u00b7 Cited by 4 \u2014 Process Reward Models (PRMs) are crucial for guiding Large Language Models (LLMs) in complex scenarios by providing dense re- ward signals.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":37},"pub_date":null,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2025.findings-naacl.107.pdf?utm_source=chatgpt.com","title":"SimSMoE: Toward Efficient Training Mixture of Experts via ...","snippet":"by G Do \u00b7 2025 \u00b7 Cited by 1 \u2014 This study illustrates representation collapse lev- els in sparse mixture-of-experts (SMoE) models by employing a similarity learning metric.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2025.acl-long.232.pdf?utm_source=chatgpt.com","title":"Revisiting the Test-Time Scaling of o1-like Models","snippet":"by Z Zeng \u00b7 2025 \u00b7 Cited by 37 \u2014 The test-time scaling have two dimensions, sequential and parallel (Zeng et al., 2024). Sequential scaling increase test-time compute by scaling ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2024.lrec-main.725.pdf?utm_source=chatgpt.com","title":"How Speculative Can Speculative Decoding Be?","snippet":"by Z Liu \u00b7 2024 \u00b7 Cited by 1 \u2014 Noteworthy implementations include Google's speculative de- coding (Leviathan et al., 2023), DeepMind's specu-.","ref_id":{"turn_index":4,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2023.acl-long.754/?utm_source=chatgpt.com","title":"Aligning Language Models with Self-Generated Instructions","snippet":"by Y Wang \u00b7 2023 \u00b7 Cited by 2768 \u2014 Self-Instruct provides an almost annotation-free method for aligning pre-trained language models with instructions.","ref_id":{"turn_index":5,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2024.acl-long.840.pdf?utm_source=chatgpt.com","title":"Dolma : an Open Corpus of Three Trillion Tokens for ...","snippet":"by L Soldaini \u00b7 2024 \u00b7 Cited by 276 \u2014 We release the Dolma Corpus, a diverse, multi- source collection of 3T tokens1 across over 4B doc- uments acquired from 6 different data sources ...","ref_id":{"turn_index":5,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2024.emnlp-main.861.pdf?utm_source=chatgpt.com","title":"Reflection-Reinforced Self-Training for Language Agents","snippet":"by ZY Dou \u00b7 2024 \u00b7 Cited by 15 \u2014 The self-training process typically involves refining the model by generating samples, assessing their quality through rewards, and updating the ...","ref_id":{"turn_index":6,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2025.acl-long.1187.pdf?utm_source=chatgpt.com","title":"STaR-SQL: Self-Taught Reasoner for Text-to-SQL","snippet":"by M He \u00b7 2025 \u00b7 Cited by 8 \u2014 STaR-SQL is a self-taught reasoner that frames SQL query generation as a reasoning-driven process, using step-by-step rationales to handle ...","ref_id":{"turn_index":6,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2025.findings-emnlp.1020.pdf?utm_source=chatgpt.com","title":"Fast Quiet-STaR: Thinking Without Thought Tokens","snippet":"Quiet-STaR (Zelikman et al., 2024) is a method for enabling language models to autonomously learn to generate internal rationales\u2014referred to as. \u201cthoughts\u201d\u2014in ...Jump to","ref_id":{"turn_index":6,"ref_type":"search","ref_index":20},"pub_date":null,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2024.acl-long.510.pdf?utm_source=chatgpt.com","title":"Math-Shepherd: Verify and Reinforce LLMs Step-by- ...","snippet":"by P Wang \u00b7 2024 \u00b7 Cited by 546 \u2014 There are two primary types of verifiers: the Outcome Reward Model (ORM) and the Process Reward Model (PRM). The ORM allocates a score to the ...","ref_id":{"turn_index":9,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2024.findings-acl.924.pdf?utm_source=chatgpt.com","title":"Small Language Models Need Strong Verifiers to Self- ...","snippet":"by Y Zhang \u00b7 2024 \u00b7 Cited by 60 \u2014 We introduce SCORE, a novel pipeline to generate self-correction data from a small LM, and subsequently fine-tune the model to be a self- ...","ref_id":{"turn_index":9,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2025.emnlp-main.679.pdf?utm_source=chatgpt.com","title":"R-PRM: Reasoning-Driven Process Reward Modeling","snippet":"by S She \u00b7 2025 \u00b7 Cited by 19 \u2014 Process Reward Models (PRMs) have emerged as a promising solution to address the reason- ing mistakes of large language models (LLMs).","ref_id":{"turn_index":9,"ref_type":"search","ref_index":31},"pub_date":null,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2025.acl-long.384.pdf?utm_source=chatgpt.com","title":"Aligning Large Language Models with Implicit Preferences ...","snippet":"by Z Tan \u00b7 2025 \u00b7 Cited by 1 \u2014 Learning from preference feedback is essential for aligning large language models (LLMs) with human values and improving the quality of generated responses.","ref_id":{"turn_index":14,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2023.acl-long.150/?utm_source=chatgpt.com","title":"Symbolic Chain-of-Thought Distillation: Small Models Can ...","snippet":"by LH Li \u00b7 2023 \u00b7 Cited by 176 \u2014 We introduce Symbolic Chain-of-Thought Distillation (SCoTD), a method to train a smaller student model on rationalizations sampled from a significantly larger ...","ref_id":{"turn_index":15,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2025.emnlp-main.376.pdf?utm_source=chatgpt.com","title":"Teach Small Models to Reason by Curriculum Distillation","snippet":"by W Jiang \u00b7 2025 \u2014 We distill reasoning capabilities from two teacher models, an LLM Qwen2.5-32B-Instruct, and an LRM DeepSeek-R1-Distill-Qwen-32B, into smaller ...","ref_id":{"turn_index":15,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2024.lrec-main.1140.pdf?utm_source=chatgpt.com","title":"Distilling Probing and Reasoning Capabilities into Smaller ...","snippet":"by Y Zhao \u00b7 2024 \u00b7 Cited by 10 \u2014 A key focus of these efforts has been the transfer of specialized abilities like the Chain- of-Thought (CoT) paradigm from LLMs to SLMs, thereby ...","ref_id":{"turn_index":15,"ref_type":"search","ref_index":24},"pub_date":null,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2024.emnlp-main.602.pdf?utm_source=chatgpt.com","title":"Speculative Decoding and Specialized Drafters","snippet":"by E Yi \u00b7 2024 \u00b7 Cited by 4 \u2014 2023. Accelerating large language model decoding with speculative sampling. arXiv preprint. arXiv:2302.01318. Wei-Lin Chiang, Zhuohan Li, Zi ...","ref_id":{"turn_index":24,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"aclanthology.org"}]},{"type":"search_result_group","domain":"jordan.im","entries":[{"type":"search_result","url":"https://r.jordan.im/download/technology/zelikman2022.pdf?utm_source=chatgpt.com","title":"arXiv:2203.14465v2 [cs.LG] 20 May 2022","snippet":"by E Zelikman \u00b7 2022 \u00b7 Cited by 1054 \u2014 We present the Self-Taught Reasoner (STaR), which iteratively improves a model's ability to generate rationales to solve problems. We few-shot prompt a model to...","ref_id":{"turn_index":6,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"jordan.im"},{"type":"search_result","url":"https://r.jordan.im/download/technology/irving2018.pdf?utm_source=chatgpt.com","title":"arXiv:1805.00899v2 [stat.ML] 22 Oct 2018","snippet":"by G Irving \u00b7 2018 \u00b7 Cited by 329 \u2014 The goal of this paper is to lay out theoretical and practical properties of debate as an approach to. AI alignment. We also lay out plans for experiments to ...","ref_id":{"turn_index":17,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"jordan.im"}]},{"type":"search_result_group","domain":"portkey.ai","entries":[{"type":"search_result","url":"https://portkey.ai/blog/openai-o1-model-card-analysis/?utm_source=chatgpt.com","title":"Deep Dive: OpenAI's o1 - The Dawn of Deliberate AI","snippet":"Dec 8, 2024 \u2014 The o1 model engages in explicit reasoning before generating responses. This isn't just a feature; it's a complete reimagining of AI architecture.","ref_id":{"turn_index":21,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"portkey.ai"}]},{"type":"search_result_group","domain":"jmlr.org","entries":[{"type":"search_result","url":"https://jmlr.org/papers/volume23/21-0998/21-0998.pdf?utm_source=chatgpt.com","title":"Switch Transformers: Scaling to Trillion Parameter Models ...","snippet":"by W Fedus \u00b7 2022 \u00b7 Cited by 3244 \u2014 The Switch Transformer architecture, which simplifies and improves over Mixture of. Experts. \u2022 Scaling properties and a benchmark against the strongly tuned T5 ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"jmlr.org"}]},{"type":"search_result_group","domain":"akashbajwa.co","entries":[{"type":"search_result","url":"https://www.akashbajwa.co/p/inference-time-scaling-laws?utm_source=chatgpt.com","title":"Inference Time Scaling Laws - by Akash Bajwa","snippet":"Oct 6, 2024 \u2014 Pre-training scaling laws may soon hit a data wall, but OpenAI's o1 model has revealed an entirely new scaling law: inference time scaling.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"akashbajwa.co"}]},{"type":"search_result_group","domain":"shishirpatil.github.io","entries":[{"type":"search_result","url":"https://shishirpatil.github.io/publications/gorilla-2023.pdf?utm_source=chatgpt.com","title":"Gorilla: Large Language Model Connected with Massive APIs","snippet":"by SG Patil \u00b7 2023 \u00b7 Cited by 775 \u2014 In this paper, we propose Gorilla, a new novel pipeline for finetuning LLMs to call APIs. The finetuned model's performance surpasses prompting ...","ref_id":{"turn_index":10,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"shishirpatil.github.io"}]},{"type":"search_result_group","domain":"nvidia.com","entries":[{"type":"search_result","url":"https://blogs.nvidia.com/blog/ai-scaling-laws/?utm_source=chatgpt.com","title":"How Scaling Laws Drive Smarter, More Powerful AI","snippet":"Feb 12, 2025 \u2014 Scaling laws describe how the performance of AI systems improves as the size of the training data, model parameters or computational resources increases.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"nvidia.com"},{"type":"search_result","url":"https://nvidianews.nvidia.com/news/nvidia-blackwell-platform-arrives-to-power-a-new-era-of-computing?utm_source=chatgpt.com","title":"NVIDIA Blackwell Platform Arrives to Power a New Era of ...","snippet":"Mar 18, 2024 \u2014 The Blackwell GPU architecture features six transformative technologies for accelerated computing, which will help unlock breakthroughs in data ...","ref_id":{"turn_index":12,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"nvidia.com"},{"type":"search_result","url":"https://developer.nvidia.com/blog/nvidia-blackwell-delivers-world-record-deepseek-r1-inference-performance/?utm_source=chatgpt.com","title":"NVIDIA Blackwell Delivers World-Record DeepSeek-R1 ...","snippet":"Mar 18, 2025 \u2014 NVIDIA Blackwell architecture incorporates many breakthrough capabilities that help accelerate generative AI inference, including second- ...","ref_id":{"turn_index":12,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"nvidia.com"}]},{"type":"search_result_group","domain":"lesswrong.com","entries":[{"type":"search_result","url":"https://www.lesswrong.com/posts/byNYzsfFmb2TpYFPW/o1-a-technical-primer?utm_source=chatgpt.com","title":"o1: A Technical Primer","snippet":"Dec 9, 2024 \u2014 In September 2024, OpenAI released o1, its first reasoning model. This model exhibits remarkable test-time scaling laws, which complete a missing piece of the ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"lesswrong.com"},{"type":"search_result","url":"https://www.lesswrong.com/posts/midXmMb2Xg37F2Kgn/new-scaling-laws-for-large-language-models?utm_source=chatgpt.com","title":"New Scaling Laws for Large Language Models","snippet":"Apr 1, 2022 \u2014 This paper is exciting! Machine learning researchers thought they knew laws about how to scale compute optimally, and the laws turned out to be wrong!","ref_id":{"turn_index":5,"ref_type":"search","ref_index":35},"pub_date":null,"attribution":"lesswrong.com"},{"type":"search_result","url":"https://www.lesswrong.com/posts/FFz6H35Gy6BArHxkc/ais-101-task-decomposition-for-scalable-oversight?utm_source=chatgpt.com","title":"AIS 101: Task decomposition for scalable oversight","snippet":"Jul 25, 2023 \u2014 ... decomposing tasks in order, for example, to provide a better reward. A complementary way to engage with the task decomposition and the papers ...","ref_id":{"turn_index":13,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"lesswrong.com"},{"type":"search_result","url":"https://www.lesswrong.com/posts/aLhLGns2BSun3EzXB/paper-constitutional-ai-harmlessness-from-ai-feedback?utm_source=chatgpt.com","title":"Paper: Constitutional AI: Harmlessness from AI Feedback","snippet":"The authors propose a method for training a harmless AI assistant that can supervise other AIs, using only a list of rules (a \"constitution\") as human ...","ref_id":{"turn_index":16,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"lesswrong.com"},{"type":"search_result","url":"https://www.lesswrong.com/posts/HfigEyXddxkSGunKr/the-o1-system-card-is-not-about-o1?utm_source=chatgpt.com","title":"The o1 System Card Is Not About o1","snippet":"Dec 13, 2024 \u2014 The o1 model is quite good at programming. In my use, it has been remarkably better than the o1 preview. You should just try it and mostly ignore evaluations.","ref_id":{"turn_index":21,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"lesswrong.com"}]},{"type":"search_result_group","domain":"researchgate.net","entries":[{"type":"search_result","url":"https://www.researchgate.net/publication/388963207_Self-Consistency_of_the_Internal_Reward_Models_Improves_Self-Rewarding_Language_Models?utm_source=chatgpt.com","title":"Self-Consistency of the Internal Reward Models Improves ...","snippet":"Aligning Large Language Models (LLMs) with human preferences is crucial for their deployment in real-world applications.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":38},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/359390115_Self-Consistency_Improves_Chain_of_Thought_Reasoning_in_Language_Models?utm_source=chatgpt.com","title":"Self-Consistency Improves Chain of Thought Reasoning in ...","snippet":"We explore a simple ensemble strategy, self-consistency, that significantly improves the reasoning accuracy of large language models.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":27},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/387512415_DeepSeek-V3_Technical_Report?utm_source=chatgpt.com","title":"DeepSeek-V3 Technical Report","snippet":"Sep 12, 2025 \u2014 We present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with 671B total parameters with 37B activated for each token.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/382916607_THE_EVOLUTION_OF_MIXTURE_OF_EXPERTS_A_SURVEY_FROM_BASICS_TO_BREAKTHROUGHS?utm_source=chatgpt.com","title":"the evolution of mixture of experts: a survey from basics ...","snippet":"We discuss techniques for efficiently distributing computational resources among experts, ensuring optimal model performance while managing hardware constraints ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":20},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/368159584_Accelerating_Large_Language_Model_Decoding_with_Speculative_Sampling?utm_source=chatgpt.com","title":"(PDF) Accelerating Large Language Model Decoding with ...","snippet":"Feb 3, 2023 \u2014 We present speculative sampling, an algorithm for accelerating transformer decoding by enabling the generation of multiple tokens from each ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":19},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/374920067_Efficient_Memory_Management_for_Large_Language_Model_Serving_with_PagedAttention?utm_source=chatgpt.com","title":"Efficient Memory Management for Large Language Model ...","snippet":"In this paper, we focus on exploring PLMs as a stand-alone model for VL reasoning tasks. Inspired by the recently popular","ref_id":{"turn_index":4,"ref_type":"search","ref_index":26},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/382178162_FlashAttention-3_Fast_and_Accurate_Attention_with_Asynchrony_and_Low-precision?utm_source=chatgpt.com","title":"(PDF) FlashAttention-3: Fast and Accurate Attention with ...","snippet":"Jul 12, 2024 \u2014 FlashAttention-3: Fast and Accurate Attention with Asynchrony and Low-precision. July 2024. DOI:10.48550/arXiv.2407.08608. License; CC BY 4.0.","ref_id":{"turn_index":4,"ref_type":"search","ref_index":27},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/366462719_Self-Instruct_Aligning_Language_Model_with_Self_Generated_Instructions?utm_source=chatgpt.com","title":"(PDF) Self-Instruct: Aligning Language Model with ...","snippet":"Dec 20, 2022 \u2014 Large \"instruction-tuned\" language models (finetuned to respond to instructions) have demonstrated a remarkable ability to generalize ...","ref_id":{"turn_index":5,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/370227313_WizardLM_Empowering_Large_Language_Models_to_Follow_Complex_Instructions?utm_source=chatgpt.com","title":"(PDF) WizardLM: Empowering Large Language Models to ...","snippet":"Apr 24, 2023 \u2014 WizardLM: Empowering Large Language Models to Follow Complex Instructions. April 2023 ... construction method using Evol-Instruct. Evol-Instruct ...","ref_id":{"turn_index":5,"ref_type":"search","ref_index":34},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/384207944_Dolma_an_Open_Corpus_of_Three_Trillion_Tokens_for_Language_Model_Pretraining_Research?utm_source=chatgpt.com","title":"Dolma: an Open Corpus of Three Trillion Tokens for ...","snippet":"Aug 26, 2025 \u2014 We employ AI Hub 6 data and Dolma (Soldaini et al., 2024) for monolingual corpora in Korean and English, respectively, randomly filtering ...","ref_id":{"turn_index":5,"ref_type":"search","ref_index":42},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/381152763_Reflection-Reinforced_Self-Training_for_Language_Agents?utm_source=chatgpt.com","title":"Reflection-Reinforced Self-Training for Language Agents","snippet":"Jun 3, 2024 \u2014 Self-training can potentially improve the performance of language agents without relying on demonstrations from humans or stronger models.","ref_id":{"turn_index":6,"ref_type":"search","ref_index":22},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/359518050_STaR_Bootstrapping_Reasoning_With_Reasoning?utm_source=chatgpt.com","title":"STaR: Bootstrapping Reasoning With Reasoning","snippet":"Generating step-by-step \"chain-of-thought\" rationales improves language model performance on complex reasoning tasks like mathematics or commonsense ...","ref_id":{"turn_index":6,"ref_type":"search","ref_index":24},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/365614638_PAL_Program-aided_Language_Models?utm_source=chatgpt.com","title":"(PDF) PAL: Program-aided Language Models","snippet":"We present Program-Aided Language models (PaL): a new method that uses the LLM to understand natural language problems and generate programs as ...","ref_id":{"turn_index":9,"ref_type":"search","ref_index":22},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/368392996_Toolformer_Language_Models_Can_Teach_Themselves_to_Use_Tools?utm_source=chatgpt.com","title":"Language Models Can Teach Themselves to Use Tools","snippet":"\"Toolformer\" (Schick et al., 2023) introduces information retrieval (IR) as an external tool. Autonomous interaction is actualized between LLM and IR through ...","ref_id":{"turn_index":10,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/368688016_Hyena_Hierarchy_Towards_Larger_Convolutional_Language_Models?utm_source=chatgpt.com","title":"Towards Larger Convolutional Language Models","snippet":"Hyena Hierarchy: Towards Larger Convolutional Language Models. February 2023. DOI:10.48550/arXiv.2302.10866. Authors:.","ref_id":{"turn_index":11,"ref_type":"search","ref_index":32},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/396967853_Scalable_Oversight_via_Partitioned_Human_Supervision?utm_source=chatgpt.com","title":"(PDF) Scalable Oversight via Partitioned Human Supervision","snippet":"5 days ago \u2014 In this section, we explain our problem setup and notations and explain our proposed method. Setup and Notations We consider a multiple-choice ...","ref_id":{"turn_index":13,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/372918028_Distilling_Reasoning_Capabilities_into_Smaller_Language_Models?utm_source=chatgpt.com","title":"Distilling Reasoning Capabilities into Smaller Language ...","snippet":"A viable solution is to distill these reasoning capabilities into smaller models either by distilling individual strategies (Magister et al., 2023; Shridhar et ...","ref_id":{"turn_index":15,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/324908324_AI_safety_via_debate?utm_source=chatgpt.com","title":"AI safety via debate","snippet":"This approach gets two AI instances to make arguments and critique each other's reasoning, with a human judge making the final decision (Irving, Christiano, and ...","ref_id":{"turn_index":17,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/388633903_Relating_Misfit_to_Gain_in_Weak-to-Strong_Generalization_Beyond_the_Squared_Loss?utm_source=chatgpt.com","title":"(PDF) Relating Misfit to Gain in Weak-to-Strong ...","snippet":"Jan 31, 2025 \u2014 The premise in weak-to-strong generalization (. 9. ) is that increasingly strong AI models will learn to outperform. their weak supervisors ...","ref_id":{"turn_index":17,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/373016581_Accelerating_LLM_Inference_with_Staged_Speculative_Decoding?utm_source=chatgpt.com","title":"(PDF) Accelerating LLM Inference with Staged Speculative ...","snippet":"Recent advances with large language models (LLM) illustrate their diverse capabilities. We propose a novel algorithm, staged speculative ...","ref_id":{"turn_index":24,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"researchgate.net"}]},{"type":"search_result_group","domain":"github.com","entries":[{"type":"search_result","url":"https://github.com/eric-mitchell/direct-preference-optimization?utm_source=chatgpt.com","title":"eric-mitchell/direct-preference-optimization - DPO","snippet":"This repo includes a reference implementation of the DPO algorithm for training language models from preference data, as described in the paper Direct ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":20},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/princeton-nlp/tree-of-thought-llm?utm_source=chatgpt.com","title":"princeton-nlp/tree-of-thought-llm","snippet":"Official implementation for paper Tree of Thoughts: Deliberate Problem Solving with Large Language Models with code, prompts, model outputs.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/deepseek-ai/DeepSeek-V3?utm_source=chatgpt.com","title":"deepseek-ai/DeepSeek-V3","snippet":"We present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with 671B total parameters with 37B activated for each token.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/hughbzhang/o1_inference_scaling_laws?utm_source=chatgpt.com","title":"Replicating O1 inference-time scaling laws","snippet":"A graph showing scaling laws for inference time compute. Using only the public o1-mini API, I tried to reconstruct the graph as closely as possible.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/vllm-project/vllm?utm_source=chatgpt.com","title":"vllm-project/vllm: A high-throughput and memory-efficient ...","snippet":"Efficient management of attention key and value memory with PagedAttention; Continuous batching of incoming requests; Fast model execution with CUDA/HIP graph ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/togethercomputer/flash-attention-3?utm_source=chatgpt.com","title":"togethercomputer/flash-attention-3: Fast and memory ...","snippet":"This repository provides the official implementation of FlashAttention and FlashAttention-2 from the following papers. ... Paper: https://arxiv.org/abs/2205.14135","ref_id":{"turn_index":4,"ref_type":"search","ref_index":24},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/yizhongw/self-instruct?utm_source=chatgpt.com","title":"Self-Instruct: Aligning LM with Self Generated Instructions","snippet":"This repository contains code and data for the Self-Instruct paper, a method for aligning pretrained language models with instructions.","ref_id":{"turn_index":5,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/nlpxucan/WizardLM?utm_source=chatgpt.com","title":"nlpxucan/WizardLM: LLMs build upon Evol Insturct","snippet":"Evol-Instruct is a novel method using LLMs instead of humans to automatically mass-produce open-domain instructions of various difficulty levels and skills ...","ref_id":{"turn_index":5,"ref_type":"search","ref_index":19},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/allenai/dolma?utm_source=chatgpt.com","title":"allenai/dolma: Data and tools for generating and inspecting ...","snippet":"It was created as a training corpus for OLMo, a language model from the Allen Institute for AI (AI2). Dolma is available for download on the HuggingFace ...","ref_id":{"turn_index":5,"ref_type":"search","ref_index":27},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/epfml/fineweb2-hq?utm_source=chatgpt.com","title":"Enhancing Multilingual LLM Pretraining with Model-Based ...","snippet":"This is the codebase for our paper Enhancing Multilingual LLM Pretraining with Model-Based Data Selection. Abstract: Dataset curation has become a basis for ...","ref_id":{"turn_index":5,"ref_type":"search","ref_index":31},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/kyo-takano/chinchilla?utm_source=chatgpt.com","title":"kyo-takano/chinchilla: A toolkit for scaling law research","snippet":"chinchilla is a research toolkit designed to estimate scaling laws & train compute-optimal models for various deep learning tasks.","ref_id":{"turn_index":5,"ref_type":"search","ref_index":45},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/AkariAsai/self-rag?utm_source=chatgpt.com","title":"AkariAsai/self-rag: This includes the original ...","snippet":"A new framework to train an arbitrary LM to learn to retrieve, generate, and critique to enhance the factuality and quality of generations.","ref_id":{"turn_index":8,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/microsoft/graphrag?utm_source=chatgpt.com","title":"microsoft/graphrag: A modular graph-based Retrieval ...","snippet":"The GraphRAG project is a data pipeline and transformation suite that is designed to extract meaningful, structured data from unstructured text using the power ...","ref_id":{"turn_index":8,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/reasoning-machines/pal?utm_source=chatgpt.com","title":"reasoning-machines/pal - Program-Aided Language Models","snippet":"In PaL, Large Language Model solves reasoning problems that involve complex arithmetic and procedural tasks by generating reasoning chains of text and code.","ref_id":{"turn_index":9,"ref_type":"search","ref_index":26},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/ShishirPatil/gorilla?utm_source=chatgpt.com","title":"ShishirPatil/gorilla: Gorilla: Training and Evaluating LLMs ...","snippet":"With Gorilla, we are the first to demonstrate how to use LLMs to invoke 1,600+ (and growing) API calls accurately while reducing hallucination. This repository ...","ref_id":{"turn_index":10,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/conceptofmind/toolformer?utm_source=chatgpt.com","title":"conceptofmind/toolformer","snippet":"Jun 21, 2024 \u2014 We introduce Toolformer, a model trained to decide which APIs to call, when to call them, what arguments to pass, and how to best incorporate the results into ...","ref_id":{"turn_index":10,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/state-spaces/mamba?utm_source=chatgpt.com","title":"state-spaces/mamba: Mamba SSM architecture","snippet":"Mamba is a new state space model architecture showing promising performance on information-dense data such as language modeling.","ref_id":{"turn_index":11,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/MLGroupJLU/RWKV-Survey?utm_source=chatgpt.com","title":"MLGroupJLU/RWKV-Survey: The official ...","snippet":"[5/1/2024] The second version of the paper has been released on arXiv, with the addition of the \"Audio and Music Tasks\" chapter. [19/12/2024] ...","ref_id":{"turn_index":11,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/HazyResearch/safari?utm_source=chatgpt.com","title":"HazyResearch/safari: Convolutions for Sequence Modeling","snippet":"Hyena. Hyena Hierarchy: Towards Larger Convolutional Language models Michael Poli*, Stefano Massaroli*, Eric Nguyen*, Daniel Y.","ref_id":{"turn_index":11,"ref_type":"search","ref_index":28},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/zchuz/CoT-Reasoning-Survey?utm_source=chatgpt.com","title":"zchuz/CoT-Reasoning-Survey: [ACL 2024] A ...","snippet":"This repository contains the resources for ACL 2024 paper Navigate through Enigmatic Labyrinth, A Survey of Chain of Thought Reasoning: Advances, Frontiers and ...","ref_id":{"turn_index":15,"ref_type":"search","ref_index":21},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/Dao-AILab/flash-attention?utm_source=chatgpt.com","title":"Dao-AILab/flash-attention: Fast and memory-efficient exact ...","snippet":"This repository provides the official implementation of FlashAttention and FlashAttention-2 from the following papers.","ref_id":{"turn_index":22,"ref_type":"search","ref_index":26},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/romsto/Speculative-Decoding?utm_source=chatgpt.com","title":"romsto/Speculative-Decoding: Implementation of the paper ...","snippet":"This repository is a pytorch implementation of Speculative Decoding / Speculative Sampling (Leviathan et al., 2023; Chen et al., 2023).","ref_id":{"turn_index":24,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"github.com"}]},{"type":"search_result_group","domain":"neurips.cc","entries":[{"type":"search_result","url":"https://proceedings.neurips.cc/paper_files/paper/2024/file/7ede97c3e082c6df10a8d6103a2eebd2-Paper-Conference.pdf?utm_source=chatgpt.com","title":"FlashAttention-3: Fast and Accurate Attention with ...","snippet":"by J Shah \u00b7 2024 \u00b7 Cited by 240 \u2014 Is flash attention stable? arXiv preprint. arXiv:2405.02803, 2024. [22] Albert Gu and Tri Dao. Mamba: Linear-time sequence modeling with selective ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"neurips.cc"},{"type":"search_result","url":"https://proceedings.neurips.cc/paper_files/paper/2022/file/c1e2faff6f588870935f114ebe04a3e5-Paper-Conference.pdf?utm_source=chatgpt.com","title":"Training Compute-Optimal Large Language Models","snippet":"by J Hoffmann \u00b7 2022 \u00b7 Cited by 222 \u2014 We test this hypothesis by training a predicted compute-optimal model, Chinchilla, that uses the same compute budget as Gopher but with 70B parameters and 4\u00d7 ...","ref_id":{"turn_index":5,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"neurips.cc"},{"type":"search_result","url":"https://neurips.cc/virtual/2024/events/datasets-benchmarks-2024?utm_source=chatgpt.com","title":"Datasets Benchmarks 2024","snippet":"We introduce DrivingDojo, the first dataset tailor-made for training interactive world models with complex driving dynamics.","ref_id":{"turn_index":5,"ref_type":"search","ref_index":41},"pub_date":null,"attribution":"neurips.cc"},{"type":"search_result","url":"https://proceedings.neurips.cc/paper_files/paper/2024/file/e4c61f578ff07830f5c37378dd3ecb0d-Paper-Conference.pdf?utm_source=chatgpt.com","title":"Gorilla: Large Language Model Connected with Massive ...","snippet":"by SG Patil \u00b7 2024 \u00b7 Cited by 775 \u2014 We introduce Gorilla, the first system to enable large-scale API integration with LLMs, demonstrating state-of-the-art performance in generating accurate API ...","ref_id":{"turn_index":10,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"neurips.cc"},{"type":"search_result","url":"https://proceedings.neurips.cc/paper_files/paper/2024/file/5b6346a05a537d4cdb2f50323452a9fe-Paper-Conference.pdf?utm_source=chatgpt.com","title":"Easy-to-Hard Generalization: Scalable Alignment Beyond ...","snippet":"by Z Sun \u00b7 2024 \u00b7 Cited by 86 \u2014 Based on this insight, we propose a novel approach to scalable alignment, which firstly trains the (process-supervised) reward models on easy problems (e.g. ...","ref_id":{"turn_index":13,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"neurips.cc"},{"type":"search_result","url":"https://proceedings.neurips.cc/paper_files/paper/2024/hash/e4a0d8aef3567f742b0794844d9b5847-Abstract-Conference.html?utm_source=chatgpt.com","title":"Quantifying the Gain in Weak-to-Strong Generalization","snippet":"by M Charikar \u00b7 2024 \u00b7 Cited by 27 \u2014 Our theory reveals several curious algorithmic insights. For instance, we can predict the amount by which the strong model will improve over the weak model, and .....","ref_id":{"turn_index":17,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"neurips.cc"}]},{"type":"search_result_group","domain":"medium.com","entries":[{"type":"search_result","url":"https://davidmack.medium.com/how-does-openai-o1-work-1d4eb38b1e26?utm_source=chatgpt.com","title":"How does OpenAI o1 work? - David Mack - Medium","snippet":"OpenAI's o1 \u201cstrawberry\u201d provides meaningful progress towards an agent capable model (it may even count as one in some's definitions).","ref_id":{"turn_index":1,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://medium.com/%40adnanmasood/state-of-reasoning-llms-the-new-era-of-thinking-machines-f241b1a3096d?utm_source=chatgpt.com","title":"State of Reasoning LLMs: The New Era of \u201cThinking ...","snippet":"Chain-of-Thought Redaction: During training, reasoning models may be optimized to produce a hidden reasoning trace that isn't meant for end ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":25},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://medium.com/%40aiml_58187/beyond-bigger-models-the-evolution-of-language-model-scaling-laws-d4bc974d3876?utm_source=chatgpt.com","title":"Language Model Scaling Laws: Beyond Bigger AI ...","snippet":"Inference scaling (OpenAI's o1 model, 2024) emerged as a new direction, focusing on optimising inference-time compute for improved reasoning.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://medium.com/%40zaiinn440/training-at-scale-chinchilla-scaling-laws-for-compute-optimal-training-of-llms-eca49f58c358?utm_source=chatgpt.com","title":"Training at Scale: Chinchilla Scaling Laws for Compute ...","snippet":"The main goal of this paper was to find the relationship between three factors. These factors are model size, number of tokens, and compute ...","ref_id":{"turn_index":5,"ref_type":"search","ref_index":40},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://ritvik19.medium.com/papers-explained-174-fineweb-280bbc08068b?utm_source=chatgpt.com","title":"Papers Explained 174: FineWeb - Ritvik Rastogi - Medium","snippet":"FineWeb is a large-scale dataset for pretraining LLMs, consisting of 15T tokens and 44TB of disk space. It was created by combining 96 CommonCrawl snapshots.","ref_id":{"turn_index":5,"ref_type":"search","ref_index":46},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://medium.com/ai-insights-cobet/quiet-star-empowering-language-models-with-internal-monologue-for-enhanced-reasoning-c0637d885f7a?utm_source=chatgpt.com","title":"Quiet Star: Empowering Language Models with Internal ...","snippet":"Quiet Star aims to mimic this human cognitive process in language models. By incorporating an internal reasoning phase, the model can evaluate ...Jump to","ref_id":{"turn_index":6,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://medium.com/%40sahin.samia/the-math-behind-deepseek-a-deep-dive-into-group-relative-policy-optimization-grpo-8a75007491ba?utm_source=chatgpt.com","title":"A Deep Dive into Group Relative Policy Optimization (GRPO)","snippet":"This blog dives into the math behind Group Relative Policy Optimization (GRPO), the core reinforcement learning algorithm that drives DeepSeek's exceptional ...","ref_id":{"turn_index":7,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://medium.com/%40zilliz_learn/graphrag-explained-enhancing-rag-with-knowledge-graphs-3312065f99e1?utm_source=chatgpt.com","title":"GraphRAG Explained: Enhancing RAG with Knowledge ...","snippet":"Retrieval Augmented Generation (RAG) is a technique that connects external data sources to enhance the output of large language models ...","ref_id":{"turn_index":8,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://medium.com/%40yu-joshua/2024-the-year-of-rag-part-1-bdf8a05f818d?utm_source=chatgpt.com","title":"2024: The Year of RAG (Part 1)","snippet":"\u201cEvaluation of Retrieval-Augmented Generation: A Survey.\u201d arXiv preprint arXiv:2405.07437v2 (2024). 6. Challenges & Future Directions for RAG.","ref_id":{"turn_index":8,"ref_type":"search","ref_index":23},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://medium.com/%40sahin.samia/self-rag-self-reflective-retrieval-augmented-generation-the-game-changer-in-factual-ai-dd32e59e3ff9?utm_source=chatgpt.com","title":"SELF-RAG (Self-Reflective Retrieval-Augmented Generation)","snippet":"SELF-RAG is a framework that integrates three key components \u2014 retrieval, generation, and self-reflection \u2014 to create a smarter and more ...","ref_id":{"turn_index":8,"ref_type":"search","ref_index":24},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://medium.com/%40yananchen1116/lets-verify-step-by-step-orm-vs-prm-613ecffb59ab?utm_source=chatgpt.com","title":"Let's Verify Step by Step, ORM vs PRM | by Yanan Chen","snippet":"In this work, the authors compare two ways of training verifier: ORM(Outcome-supervised reward models) vs PRM(process-supervised reward models).","ref_id":{"turn_index":9,"ref_type":"search","ref_index":19},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://medium.com/%40ohusiev_6834/gorilla-the-architectural-shift-you-probably-missed-0b9f9d8d93e5?utm_source=chatgpt.com","title":"Gorilla: The Architectural Shift You Probably Missed","snippet":"This was Gorilla, a project by Microsoft Research (2023), which proposed a model-centric approach to generating executable API calls by ...","ref_id":{"turn_index":10,"ref_type":"search","ref_index":19},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://medium.com/%4023subhasmukherjee/hyena-hierarchies-the-future-beyond-transformers-e1f31d42dd67?utm_source=chatgpt.com","title":"Hyena Hierarchies : The future beyond transformers ?","snippet":"Hyena Hierarchies were introduced in the year 2023 in the paper \u2014 \u201cHyena Hierarchy: Towards Larger Convolutional Language Models\u201d. It ...","ref_id":{"turn_index":11,"ref_type":"search","ref_index":21},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://bytebridge.medium.com/gpu-and-tpu-comparative-analysis-report-a5268e4f0d2a?utm_source=chatgpt.com","title":"GPU and TPU Comparative Analysis Report | by ByteBridge","snippet":"The TPU v5p is projected to deliver up to 460 petaFLOPS per pod when up to 8,960 chips are connected, offering up to 4 times higher performance ...","ref_id":{"turn_index":12,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://medium.com/%40adnanmasood/an-operational-taxonomy-of-ai-alignment-approaches-59b43c5d6596?utm_source=chatgpt.com","title":"An Operational Taxonomy of AI Alignment Approaches","snippet":"Third, we scale supervision with process\u2011based oversight (judge the steps, not just outcomes), AI\u2011assisted review (critics, verifiers, test ...","ref_id":{"turn_index":13,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://medium.com/%40sanderink.ursina/process-based-supervision-in-ai-guiding-learning-step-by-step-ddad77b17cfc?utm_source=chatgpt.com","title":"Process-Based Supervision in AI: Guiding Learning Step- ...","snippet":"Process-based supervision (also known as process supervision or step-wise supervision) is an approach to training AI models where feedback ...","ref_id":{"turn_index":13,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://medium.com/%40bhavinjawade/orpo-preference-optimization-without-reference-model-dc4745867214?utm_source=chatgpt.com","title":"ORPO \u2014 Preference Optimization without Reference Model","snippet":"ORPO introduces a method to directly contrast favored (chosen) and disfavored (rejected) responses by calculating the odds ratio.","ref_id":{"turn_index":14,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://medium.com/%40tubelwj/how-does-deepseek-r1-transfer-its-reasoning-capability-to-qwen-through-knowledge-distillation-5a7701d8926a?utm_source=chatgpt.com","title":"How does DeepSeek-R1 transfer its reasoning capability to ...","snippet":"Through knowledge distillation, the reasoning capabilities of DeepSeek-R1 are efficiently transferred to the Qwen series of smaller models.","ref_id":{"turn_index":15,"ref_type":"search","ref_index":22},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://medium.com/%40EleventhHourEnthusiast/direct-preference-optimization-your-language-model-is-secretly-a-reward-model-5b8f44cb9b9b?utm_source=chatgpt.com","title":"Direct Preference Optimization: Your Language Model is ...","snippet":"Rafailov et al. (2023) propose Direct Preference Optimization (DPO) as an alternative, directly optimizing language models to align with human ...","ref_id":{"turn_index":22,"ref_type":"search","ref_index":21},"pub_date":null,"attribution":"medium.com"}]},{"type":"search_result_group","domain":"berkeley.edu","entries":[{"type":"search_result","url":"https://www2.eecs.berkeley.edu/Pubs/TechRpts/2025/EECS-2025-121.pdf?utm_source=chatgpt.com","title":"Benchmarking LLMs on Advanced Mathematical Reasoning","snippet":"by J Yue \u00b7 2025 \u2014 MATH-Minos is a system that aims to improve mathematical verifiers (critics) by training them with stepwise natural language feedback (Gao et al ...","ref_id":{"turn_index":9,"ref_type":"search","ref_index":28},"pub_date":null,"attribution":"berkeley.edu"},{"type":"search_result","url":"https://gorilla.cs.berkeley.edu/?utm_source=chatgpt.com","title":"Gorilla LLM","snippet":"Gorilla Execution Engine (GoEX) is a runtime for LLM-generated actions like code, API calls, and more. Featuring post-facto validation for assessing LLM ...","ref_id":{"turn_index":10,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"berkeley.edu"}]},{"type":"search_result_group","domain":"datacenterdynamics.com","entries":[{"type":"search_result","url":"https://www.datacenterdynamics.com/en/news/microsoft-delays-production-of-maia-100-ai-chip-to-2026-report/?utm_source=chatgpt.com","title":"Microsoft delays production of Maia 200 AI chip to 2026","snippet":"Jun 30, 2025 \u2014 According to a report from The Information, the tech giant has pushed mass production of the new AI chips, codenamed Braga, back by at least six months.","ref_id":{"turn_index":12,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"datacenterdynamics.com"}]},{"type":"search_result_group","domain":"interconnects.ai","entries":[{"type":"search_result","url":"https://www.interconnects.ai/p/openais-o1-using-search-was-a-psyop?utm_source=chatgpt.com","title":"OpenAI's o1 using \"search\" was a PSYOP","snippet":"Dec 4, 2024 \u2014 How to understand OpenAI's o1 models as really just one wacky, wonderful, long chain of thought.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":35},"pub_date":null,"attribution":"interconnects.ai"},{"type":"search_result","url":"https://www.interconnects.ai/p/rl-backlog-openais-many-rls-clarifying?utm_source=chatgpt.com","title":"RL backlog: OpenAI's many RLs, clarifying distillation, and ...","snippet":"Apr 5, 2025 \u2014 A fun speculation that OpenAI is really invested in RL and post-training is that their new o3-mini model has the same date cutoff, October 2023, ...","ref_id":{"turn_index":15,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"interconnects.ai"}]},{"type":"search_result_group","domain":"anthropic.com","entries":[{"type":"search_result","url":"https://www-cdn.anthropic.com/7512771452629584566b6303311496c262da1006/Anthropic_ConstitutionalAI_v2.pdf?utm_source=chatgpt.com","title":"Constitutional AI: Harmlessness from AI Feedback","snippet":"The approach is called Constitutional AI ... The model's self-critique and -revision approach can be framed as reinforcement learning from AI feedback (RLAIF).","ref_id":{"turn_index":16,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"anthropic.com"}]},{"type":"search_result_group","domain":"reddit.com","entries":[{"type":"search_result","url":"https://www.reddit.com/r/singularity/comments/19aqc0s/metas_new_paper_selfrewarding_language_models/?utm_source=chatgpt.com","title":"META's new paper - \"Self-Rewarding Language Models\"","snippet":"In this work, we study Self-Rewarding Language Models, where the language model itself is used via LLM-as-a-Judge prompting to provide its own rewards during ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/MachineLearning/comments/13wwzq9/r_new_openai_article_improving_mathematical/?utm_source=chatgpt.com","title":"Improving Mathematical Reasoning with Process Supervision","snippet":"The Process Reward Model (\"PRM\") is able to pick solutions for the difficult \"MATH\" benchmark much better than the Outcome Reward Model (\"ORM\").","ref_id":{"turn_index":0,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/LocalLLaMA/comments/1ikh3vz/openai_is_hiding_the_actual_thinking_tokens_in/?utm_source=chatgpt.com","title":"OpenAI is hiding the actual thinking tokens in o3-mini","snippet":"Thinking tokens are just intermediate tokens which increase the probability of a right answer. As \"reasoning\" models progress the thinking ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/MachineLearning/comments/kvlk1j/r_switch_transformers_scaling_to_trillion/?utm_source=chatgpt.com","title":"[R] Switch Transformers: Scaling to Trillion Parameter ...","snippet":"Mixture of Experts (MoE) defies this and instead selects different parameters for each incoming example. The result is a sparsely-activated ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":24},"pub_date":null,"attribution":"reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/MachineLearning/comments/1h6pmvd/d_daily_paper_discussions_flashattention_3/?utm_source=chatgpt.com","title":"[D] Daily Paper Discussions - FlashAttention 3","snippet":"As a part of daily paper discussions on the Yannic Kilcher discord server, I will be volunteering to lead the analysis of FlashAttention-3 ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":21},"pub_date":null,"attribution":"reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/mlscaling/comments/trwkck/training_computeoptimal_large_language_models/?utm_source=chatgpt.com","title":"\"Training Compute-Optimal Large Language Models ...","snippet":"We verify this by training a more compute-optimal 70B model, called Chinchilla, on 1.4 trillion tokens.","ref_id":{"turn_index":5,"ref_type":"search","ref_index":20},"pub_date":null,"attribution":"reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/machinelearningnews/comments/1d76uz2/huggingface_releases_fineweb_a_new_largescale/?utm_source=chatgpt.com","title":"A New Large-Scale (15-Trillion Tokens, 44TB Disk Space) ...","snippet":"Hugging Face has introduced FineWeb, a comprehensive dataset designed to enhance the training of large language models (LLMs).","ref_id":{"turn_index":5,"ref_type":"search","ref_index":21},"pub_date":null,"attribution":"reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/singularity/comments/12ygpgu/wizardlm_empowering_large_language_models_to/?utm_source=chatgpt.com","title":"WizardLM: Empowering Large Language Models to Follow ...","snippet":"The authors use their proposed Evol-Instruct algorithm to rewrite an initial set of instructions step by step into more complex instructions.","ref_id":{"turn_index":5,"ref_type":"search","ref_index":44},"pub_date":null,"attribution":"reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/LocalLLaMA/comments/1bfifi2/quietstar_language_models_can_teach_themselves_to/?utm_source=chatgpt.com","title":"Quiet-STaR: Language Models Can Teach Themselves to ...","snippet":"Figure 2 of their paper - Showing the improvement in benchmarks with different number of thoughts, ahead tokens and training steps.Jump to","ref_id":{"turn_index":6,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/datascience/comments/1arnavt/how_does_selfrag_work_new_on_llamaindex/?utm_source=chatgpt.com","title":"How does self-RAG work (new on llamaindex)!","snippet":"Paper: SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION https://arxiv.org/pdf/2310.11511v1.pdf. \ud83d\udcfd\ufe0fSee ...","ref_id":{"turn_index":8,"ref_type":"search","ref_index":27},"pub_date":null,"attribution":"reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/PromptEngineering/comments/1en989j/programofthought_prompting_outperforms/?utm_source=chatgpt.com","title":"Program-of-Thought Prompting Outperforms Chain- ...","snippet":"In the experiments run, on average, PoT + self-consistency (SC) outperformed CoT + SC by 10%, and PoT outperformed CoT by 8-15% on various ...","ref_id":{"turn_index":9,"ref_type":"search","ref_index":33},"pub_date":null,"attribution":"reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/LocalLLaMA/comments/13lznoc/hyena_hierarchy_towards_larger_convolutional/?utm_source=chatgpt.com","title":"Towards Larger Convolutional Language Models : r ...","snippet":"Those of you following everything closely has anyone come across open source projects attempting to leverage the recent Hyena development.","ref_id":{"turn_index":11,"ref_type":"search","ref_index":25},"pub_date":null,"attribution":"reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/LocalLLaMA/comments/1am5clf/rwkv_v6_the_finch_series_15b_model_sota_multilang/?utm_source=chatgpt.com","title":"RWKV v6 Finch Series: 1.5B SOTA Multilang & English","snippet":"The Finch series is version 6 of rwkv, bascially like v5, but with its own selectivity mechanism like mamba.","ref_id":{"turn_index":11,"ref_type":"search","ref_index":31},"pub_date":null,"attribution":"reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/singularity/comments/1d76q2f/mamba_2_transformers_are_ssms_generalized_models/?utm_source=chatgpt.com","title":"[Mamba 2] Transformers are SSMs: Generalized Models ...","snippet":"[Mamba 2] Transformers are SSMs: Generalized Models and Efficient Algorithms Through Structured State Space Duality. AI.","ref_id":{"turn_index":11,"ref_type":"search","ref_index":34},"pub_date":null,"attribution":"reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/singularity/comments/1ac0ax9/googles_latest_ai_chip_is_up_to_28_times_faster/?utm_source=chatgpt.com","title":"Google's latest AI chip is up to 2.8 times faster at training ...","snippet":"Google's v5p TPUs are up to 2.8 times faster at training large language models than TPU v4, and offer 2.1-times value-for-money. Although the ...","ref_id":{"turn_index":12,"ref_type":"search","ref_index":19},"pub_date":null,"attribution":"reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/hardware/comments/1o9nnrg/intel_foundry_reportedly_secures_18a_order_from/?utm_source=chatgpt.com","title":"Intel Foundry Reportedly Secures 18A Order from Microsoft ...","snippet":"Intel Foundry Reportedly Secures 18A Order from Microsoft for Maia 2 Accelerator ... Intel's own AI accelerator (Falcon Shores) was to use ...","ref_id":{"turn_index":12,"ref_type":"search","ref_index":23},"pub_date":null,"attribution":"reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/LocalLLaMA/comments/1d3y51o/peter_from_lightblue_here_id_like_to_share_our/?utm_source=chatgpt.com","title":"Peter from Lightblue here. I'd like to share our ORPO ...","snippet":"ORPO (Odds Ratio Preference Optimization) is a novel preference alignment algorithm for language models that incorporates an odds ratio-based ...","ref_id":{"turn_index":14,"ref_type":"search","ref_index":19},"pub_date":null,"attribution":"reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/MachineLearning/comments/1icfbll/d_deepseek_distillation_and_training_costs/?utm_source=chatgpt.com","title":"[D] DeepSeek distillation and training costs","snippet":"Next, they use R1 to create Reasoning examples, which they use to fine-tune V3-Base via SFT(?) to create V3 (or R1-distill-V3-Base, which would ...","ref_id":{"turn_index":15,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/singularity/comments/1hlniif/according_to_two_recent_articles_from_the/?utm_source=chatgpt.com","title":"According to two recent articles from The Information, ...","snippet":"I think o3-mini benefits from more compute in the RL post-training phase as well as distillation from o3. ... OpenAI to release new o3 reasoning ...","ref_id":{"turn_index":15,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/LocalLLaMA/comments/1ffsn12/i_dont_understand_the_hype_about_chatgpts_o1/?utm_source=chatgpt.com","title":"I don't understand the hype about ChatGPT's o1 series","snippet":"Also, the reasoning tokens give them a window into how the model \"thinks\". OpenAI explains it best, in the o1 System Card: One of the key ...","ref_id":{"turn_index":21,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/OpenAI/comments/1fjpk4l/how_openai_o1_works_in_a_simple_way_and_why_it/?utm_source=chatgpt.com","title":"How OpenAI o1 works in a simple way and why it matters ...","snippet":"This model doesn't just predict\u2014it thinks, using advanced reasoning techniques like Chain of Thought (CoT) to solve complex problems step by ...","ref_id":{"turn_index":21,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"reddit.com"}]},{"type":"search_result_group","domain":"alastairreid.github.io","entries":[{"type":"search_result","url":"https://alastairreid.github.io/RelatedWork/papers/fedus%3Aarxiv%3A2021/?utm_source=chatgpt.com","title":"Switch transformers: Scaling to trillion parameter models with ...","snippet":"Observes that the [mixture of experts] approach suffers from problems in complexity, communication costs and training instabilities.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"alastairreid.github.io"}]},{"type":"search_result_group","domain":"semanticscholar.org","entries":[{"type":"search_result","url":"https://www.semanticscholar.org/paper/Self-Rewarding-Language-Models-Yuan-Pang/04d64be16fb402f28348faffef484bd419c8bd8f?utm_source=chatgpt.com","title":"[PDF] Self-Rewarding Language Models","snippet":"Jan 18, 2024 \u2014 Self-Consistency of the Internal Reward Models Improves Self-Rewarding Language Models ... Language Models with Human Feedback without ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":19},"pub_date":null,"attribution":"semanticscholar.org"},{"type":"search_result","url":"https://www.semanticscholar.org/paper/Tree-of-Thoughts%3A-Deliberate-Problem-Solving-with-Yao-Yu/2f3822eb380b5e753a6d579f31dfc3ec4c4a0820?utm_source=chatgpt.com","title":"Tree of Thoughts: Deliberate Problem Solving with Large ...","snippet":"A new framework for language model inference, Tree of Thoughts (ToT), which generalizes over the popular Chain of Thought approach to prompting language ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"semanticscholar.org"},{"type":"search_result","url":"https://www.semanticscholar.org/paper/Self-Consistency-Improves-Chain-of-Thought-in-Wang-Wei/5f19ae1135a9500940978104ec15a5b8751bc7d2?utm_source=chatgpt.com","title":"Self-Consistency Improves Chain of Thought Reasoning in ...","snippet":"This paper proposes a new decoding strategy, self-consistency, to replace the naive greedy decoding used in chain-of-thought prompting that first samples a ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":19},"pub_date":null,"attribution":"semanticscholar.org"},{"type":"search_result","url":"https://www.semanticscholar.org/paper/Switch-Transformers%3A-Scaling-to-Trillion-Parameter-Fedus-Zoph/fdacf2a732f55befdc410ea927091cad3b791f13?utm_source=chatgpt.com","title":"Switch Transformers: Scaling to Trillion Parameter Models ...","snippet":"Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity \u00b7 W. Fedus, Barret Zoph, Noam M. Shazeer \u00b7 Published in Journal of ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"semanticscholar.org"},{"type":"search_result","url":"https://www.semanticscholar.org/paper/DeepSeek-V3-Technical-Report-DeepSeek-AI-Liu/e07a7e57745b69c0f08601fbdd19cfdcafbe1152?utm_source=chatgpt.com","title":"[PDF] DeepSeek-V3 Technical Report","snippet":"Dec 27, 2024 \u2014 We present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with 671B total parameters with 37B activated for each token. To ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":19},"pub_date":null,"attribution":"semanticscholar.org"},{"type":"search_result","url":"https://www.semanticscholar.org/paper/FlashAttention-3%3A-Fast-and-Accurate-Attention-with-Shah-Bikshandi/5d1ca53a0b41f4f5c960cd9997556d7180d6b88d?utm_source=chatgpt.com","title":"[PDF] FlashAttention-3: Fast and Accurate Attention with ...","snippet":"This work develops three main techniques to speed up attention on Hopper GPUs: exploiting asynchrony of the Tensor Cores and TMA to overlap overall ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"semanticscholar.org"},{"type":"search_result","url":"https://www.semanticscholar.org/paper/e65b346d442e9962a4276dc1c1af2956d9d5f1eb?utm_source=chatgpt.com","title":"Aligning Language Models with Self-Generated Instructions","snippet":"Self-Instruct is introduced, a framework for improving the instruction-following capabilities of pretrained language models by bootstrapping off their own ...","ref_id":{"turn_index":5,"ref_type":"search","ref_index":43},"pub_date":null,"attribution":"semanticscholar.org"},{"type":"search_result","url":"https://www.semanticscholar.org/paper/Quiet-STaR%3A-Language-Models-Can-Teach-Themselves-to-Zelikman-Harik/b5bffe41155052a43010ec7197f832e81c546268?utm_source=chatgpt.com","title":"Quiet-STaR: Language Models Can Teach Themselves to ...","snippet":"Quiet-STaR is presented, a generalization of STaR in which LMs learn to generate rationales at each token to explain future text, improving their ...","ref_id":{"turn_index":6,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"semanticscholar.org"},{"type":"search_result","url":"https://www.semanticscholar.org/paper/Reinforced-Self-Training-%28ReST%29-for-Language-Gulcehre-Paine/182c7b40ff7560a5545764814338f55a2098e441?utm_source=chatgpt.com","title":"Reinforced Self-Training (ReST) for Language Modeling","snippet":"The results show that ReST can substantially improve translation quality, as measured by automated metrics and human evaluation on machine translation ...","ref_id":{"turn_index":6,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"semanticscholar.org"},{"type":"search_result","url":"https://www.semanticscholar.org/paper/Self-RAG%3A-Learning-to-Retrieve%2C-Generate%2C-and-Asai-Wu/ddbd8fe782ac98e9c64dd98710687a962195dd9b?utm_source=chatgpt.com","title":"[PDF] Self-RAG: Learning to Retrieve, Generate, and ...","snippet":"A new framework called Self-Reflective Retrieval-Augmented Generation (Self-RAG) is introduced that enhances an LM's quality and factuality through ...","ref_id":{"turn_index":8,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"semanticscholar.org"},{"type":"search_result","url":"https://www.semanticscholar.org/paper/6c1e1cc1e0e1f8fd026fe517607b2d4535565fa7?utm_source=chatgpt.com","title":"[PDF] PAL: Program-aided Language Models","snippet":"This paper presents Program-Aided Language models (PAL): a novel approach that uses the LLM to read natural language problems and generate programs as the ...","ref_id":{"turn_index":9,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"semanticscholar.org"},{"type":"search_result","url":"https://www.semanticscholar.org/paper/998ac3e945857cf2676ee7efdbaf443a0c6f820a?utm_source=chatgpt.com","title":"[PDF] Hyena Hierarchy: Towards Larger Convolutional ...","snippet":"Feb 21, 2023 \u2014 This work proposes Hyena, a subquadratic drop-in replacement for attention constructed by interleaving implicitly parametrized long ...","ref_id":{"turn_index":11,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"semanticscholar.org"},{"type":"search_result","url":"https://www.semanticscholar.org/paper/Mamba%3A-Linear-Time-Sequence-Modeling-with-Selective-Gu-Dao/7bbc7595196a0606a07506c4fb1473e5e87f6082?utm_source=chatgpt.com","title":"Linear-Time Sequence Modeling with Selective State Spaces","snippet":"Mamba: Linear-Time Sequence Modeling with Selective State Spaces ... Albert Gu, Tri Dao; Published in arXiv.org 1 December 2023; Computer ...","ref_id":{"turn_index":11,"ref_type":"search","ref_index":22},"pub_date":null,"attribution":"semanticscholar.org"},{"type":"search_result","url":"https://www.semanticscholar.org/paper/IPO%3A-Your-Language-Model-is-Secretly-a-Preference-Garg-Singh/0b9fae1ac6b080d65e79970da2d452c64f3352a8?utm_source=chatgpt.com","title":"Your Language Model is Secretly a Preference Classifier","snippet":"Feb 22, 2025 \u2014 This work proposes Implicit Preference Optimization (IPO), an alternative approach that leverages generative LLMs as preference classifiers, ...","ref_id":{"turn_index":14,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"semanticscholar.org"},{"type":"search_result","url":"https://www.semanticscholar.org/paper/ORPO%3A-Monolithic-Preference-Optimization-without-Hong-Lee/973814cd535facbf4f27c3de477b05bf19366030?utm_source=chatgpt.com","title":"Monolithic Preference Optimization without Reference Model","snippet":"This paper revisits SFT in the context of preference alignment, and demonstrates, both empirically and theoretically, that the odds ratio is a sensible ...","ref_id":{"turn_index":14,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"semanticscholar.org"},{"type":"search_result","url":"https://www.semanticscholar.org/paper/Symbolic-Chain-of-Thought-Distillation%3A-Small-Can-Li-Hessel/7a6a298efb965ce9a351a3212f6f536e94dbbb03?utm_source=chatgpt.com","title":"Symbolic Chain-of-Thought Distillation: Small Models Can ...","snippet":"2023. TLDR. This paper uses very large models as reasoning teachers to enable complex reasoning in smaller models and reduce model size requirements by ...","ref_id":{"turn_index":15,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"semanticscholar.org"},{"type":"search_result","url":"https://www.semanticscholar.org/paper/Constitutional-AI%3A-Harmlessness-from-AI-Feedback-Bai-Kadavath/3936fd3c6187f606c6e4e2e20b196dbc41cc4654?utm_source=chatgpt.com","title":"Constitutional AI: Harmlessness from AI Feedback","snippet":"This work experiments with methods for training a harmless AI assistant through self-improvement, without any human labels identifying harmful outputs, ...","ref_id":{"turn_index":16,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"semanticscholar.org"},{"type":"search_result","url":"https://www.semanticscholar.org/paper/AI-safety-via-debate-Irving-Christiano/5a5a1d666e4b7b933bc5aafbbadf179bc447ee67?utm_source=chatgpt.com","title":"[PDF] AI safety via debate","snippet":"This work proposes training agents via self play on a zero sum debate game, focusing on potential weaknesses as the model scales up, and proposes future ...","ref_id":{"turn_index":17,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"semanticscholar.org"},{"type":"search_result","url":"https://www.semanticscholar.org/paper/43e624ddeed82df944a6cae0dedec3372438e243?utm_source=chatgpt.com","title":"[PDF] Accelerating LLM Inference with Staged Speculative ...","snippet":"This work addresses the low arithmetic intensity of small-batch inference by improving upon previous work in speculative decoding, and restructure the ...","ref_id":{"turn_index":24,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"semanticscholar.org"}]},{"type":"search_result_group","domain":"nature.com","entries":[{"type":"search_result","url":"https://www.nature.com/articles/s41586-025-09422-z?utm_source=chatgpt.com","title":"DeepSeek-R1 incentivizes reasoning in LLMs through ...","snippet":"by D Guo \u00b7 2025 \u00b7 Cited by 107 \u2014 Here we show that the reasoning abilities of LLMs can be incentivized through pure reinforcement learning (RL), obviating the need for human- ...","ref_id":{"turn_index":7,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"nature.com"}]},{"type":"search_result_group","domain":"selfrag.github.io","entries":[{"type":"search_result","url":"https://selfrag.github.io/?utm_source=chatgpt.com","title":"Self-RAG: Learning to Retrieve, Generate and Critique ...","snippet":"Self-RAG learns to retrieve, generate and critique to enhance LM's output quality and factuality, outperforming ChatGPT and retrieval-augmented LLama2 Chat ...","ref_id":{"turn_index":8,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"selfrag.github.io"}]},{"type":"search_result_group","domain":"acm.org","entries":[{"type":"search_result","url":"https://dl.acm.org/doi/10.5555/3666122.3668460?utm_source=chatgpt.com","title":"Direct preference optimization: your language model is ...","snippet":"by R Rafailov \u00b7 2023 \u00b7 Cited by 5990 \u2014 Direct Preference Optimization (DPO) is a method to fine-tune language models to align with human preferences, solving a classification problem ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":28},"pub_date":null,"attribution":"acm.org"},{"type":"search_result","url":"https://dl.acm.org/doi/abs/10.5555/3586589.3586709?utm_source=chatgpt.com","title":"Switch transformers: scaling to trillion parameter models ...","snippet":"by W Fedus \u00b7 2022 \u00b7 Cited by 3244 \u2014 Switch transformers: scaling to trillion parameter models with simple and efficient sparsity. AUTHORs: William Fedus.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"acm.org"},{"type":"search_result","url":"https://dl.acm.org/doi/10.1145/3600006.3613165?utm_source=chatgpt.com","title":"Efficient Memory Management for Large Language Model ...","snippet":"by W Kwon \u00b7 2023 \u00b7 Cited by 3688 \u2014 We propose PagedAttention, an attention algorithm inspired by the classical virtual memory and paging techniques in operating systems.","ref_id":{"turn_index":4,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"acm.org"},{"type":"search_result","url":"https://dl.acm.org/doi/10.5555/3600270.3602446?utm_source=chatgpt.com","title":"Training compute-optimal large language models","snippet":"by J Hoffmann \u00b7 2022 \u00b7 Cited by 3027 \u2014 As a highlight, Chinchilla reaches a state-of-the-art average accuracy of 67.5% on the MMLU benchmark, greater than a 7% improvement over Gopher. Supplementary ....","ref_id":{"turn_index":5,"ref_type":"search","ref_index":30},"pub_date":null,"attribution":"acm.org"},{"type":"search_result","url":"https://dl.acm.org/doi/10.5555/3600270.3601396?utm_source=chatgpt.com","title":"STaR: self-taught reasoner bootstrapping reasoning with ...","snippet":"by E Zelikman \u00b7 2022 \u00b7 Cited by 1058 \u2014 This technique, the \"Self-Taught Reasoner\" (STaR), relies on a simple loop: generate rationales to answer many questions, prompted with a few rationale ...","ref_id":{"turn_index":6,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"acm.org"},{"type":"search_result","url":"https://dl.acm.org/doi/10.1145/3637528.3671470?utm_source=chatgpt.com","title":"A Survey on RAG Meeting LLMs: Towards Retrieval ...","snippet":"by W Fan \u00b7 2024 \u00b7 Cited by 876 \u2014 In this survey, we comprehensively review existing research studies in RA-LLMs, covering three primary technical perspectives.","ref_id":{"turn_index":8,"ref_type":"search","ref_index":26},"pub_date":null,"attribution":"acm.org"},{"type":"search_result","url":"https://dl.acm.org/doi/10.5555/3618408.3618843?utm_source=chatgpt.com","title":"PAL: program-aided language models","snippet":"by L Gao \u00b7 2023 \u00b7 Cited by 1164 \u2014 In this paper, we present Program-Aided Language models (PAL): a novel approach that uses the LLM to read natural language problems and generate programs.","ref_id":{"turn_index":9,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"acm.org"},{"type":"search_result","url":"https://dl.acm.org/doi/10.5555/3666122.3669119?utm_source=chatgpt.com","title":"Toolformer: language models can teach themselves to use ...","snippet":"by T Schick \u00b7 2023 \u00b7 Cited by 2561 \u2014 In this paper, we show that LMs can teach themselves to use external tools via simple APIs and achieve the best of both worlds. We introduce Toolformer, a model .....","ref_id":{"turn_index":10,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"acm.org"},{"type":"search_result","url":"https://dl.acm.org/doi/10.5555/3618408.3619572?utm_source=chatgpt.com","title":"Hyena hierarchy: towards larger convolutional language ...","snippet":"by M Poli \u00b7 2023 \u00b7 Cited by 473 \u2014 Hyena is a subquadratic attention replacement using long convolutions and data-controlled gating, improving accuracy and reducing training compute.","ref_id":{"turn_index":11,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"acm.org"},{"type":"search_result","url":"https://dl.acm.org/doi/10.5555/3692070.3692281?utm_source=chatgpt.com","title":"Human alignment of large language models through online ...","snippet":"by D Calandriello \u00b7 2024 \u00b7 Cited by 53 \u2014 In this paper, our contribution is two-fold. First, we show the equivalence between two recent alignment methods, namely Identity Preference Optimisation (IPO)...","ref_id":{"turn_index":14,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"acm.org"},{"type":"search_result","url":"https://dl.acm.org/doi/10.5555/3692070.3694459?utm_source=chatgpt.com","title":"Self-rewarding language models | ICML","snippet":"by W Yuan \u00b7 2024 \u00b7 Cited by 558 \u2014 In this work, we study Self-Rewarding Language Models, where the language model itself is used via LLM-as-a-Judge prompting to provide its own rewards during ...","ref_id":{"turn_index":16,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"acm.org"},{"type":"search_result","url":"https://dl.acm.org/doi/10.1145/3669940.3707256?utm_source=chatgpt.com","title":"Dynamic Memory Management for Serving LLMs without ...","snippet":"PagedAttention is a popular approach for dynamic memory allocation in LLM serving systems. It enables on-demand allocation of GPU memory to mitigate KV ...","ref_id":{"turn_index":22,"ref_type":"search","ref_index":25},"pub_date":null,"attribution":"acm.org"},{"type":"search_result","url":"https://dl.acm.org/doi/10.5555/3737916.3740109?utm_source=chatgpt.com","title":"FlashAttention-3: fast and accurate attention with ...","snippet":"Jun 5, 2025 \u2014 We develop three main techniques to speed up attention on Hopper GPUs: exploiting asynchrony of the Tensor Cores and TMA to (1) overlap overall ...","ref_id":{"turn_index":22,"ref_type":"search","ref_index":29},"pub_date":null,"attribution":"acm.org"},{"type":"search_result","url":"https://dl.acm.org/doi/10.5555/3618408.3619203?utm_source=chatgpt.com","title":"Fast inference from transformers via speculative decoding","snippet":"by Y Leviathan \u00b7 2023 \u00b7 Cited by 960 \u2014 In this work we introduce speculative decoding - an algorithm to sample from autoregressive models faster without any changes to the outputs.","ref_id":{"turn_index":24,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"acm.org"}]},{"type":"search_result_group","domain":"eetimes.com","entries":[{"type":"search_result","url":"https://www.eetimes.com/nvidias-blackwell-gpu-offers-fp4-transformer-engine-sharp/?utm_source=chatgpt.com","title":"Nvidia's Blackwell Offers FP4, Second-Gen Transformer ...","snippet":"Mar 27, 2024 \u2014 With B200 boosting performance 2.5\u00d7 over H100, where do Nvidia's 25\u00d7-30\u00d7 performance claims come from? The key is in communication for large ...","ref_id":{"turn_index":12,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"eetimes.com"}]},{"type":"search_result_group","domain":"delftaisafety.org","entries":[{"type":"search_result","url":"https://www.delftaisafety.org/week-4-scalable-oversight-and-model-evaluations?utm_source=chatgpt.com","title":"Week 4 - Scalable Oversight and Model Evaluations \u2014 DAISI","snippet":"Iterated amplification involves repeatedly using task decomposition to train increasingly powerful agents. We then discuss another potential solution to the ...","ref_id":{"turn_index":13,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"delftaisafety.org"}]},{"type":"search_result_group","domain":"promptlayer.com","entries":[{"type":"search_result","url":"https://blog.promptlayer.com/openai-o3-vs-deepseek-r1-an-analysis-of-reasoning-models/?utm_source=chatgpt.com","title":"OpenAI o3 vs DeepSeek r1: Which Reasoning Model is ...","snippet":"Jan 28, 2025 \u2014 O3 excels in coding, while R1 is strong in math and reasoning, and is more cost-effective and open-source. O3 has a higher cost.","ref_id":{"turn_index":15,"ref_type":"search","ref_index":29},"pub_date":null,"attribution":"promptlayer.com"},{"type":"search_result","url":"https://blog.promptlayer.com/how-openais-o1-model-works-behind-the-scenes-what-we-can-learn-from-it/?utm_source=chatgpt.com","title":"How OpenAI's o1 model works behind-the-scenes & what ...","snippet":"Jan 2, 2025 \u2014 Understanding o1's Reasoning Process. OpenAI o1 chain-of-thought has 6 steps as detailed below. 1. Problem Analysis. The model begins by ...","ref_id":{"turn_index":21,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"promptlayer.com"}]},{"type":"search_result_group","domain":"pcdn.co","entries":[{"type":"search_result","url":"https://s10251.pcdn.co/pdf/2022-hoffman-chinchilla.pdf?utm_source=chatgpt.com","title":"Training Compute-Optimal Large Language Models","snippet":"Mar 29, 2022 \u2014 We investigate the optimal model size and number of tokens for training a transformer language model under a given compute budget.","ref_id":{"turn_index":23,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"pcdn.co"}]},{"type":"search_result_group","domain":"harvard.edu","entries":[{"type":"search_result","url":"https://ui.adsabs.harvard.edu/abs/2024arXiv241219437D/abstract?utm_source=chatgpt.com","title":"DeepSeek-V3 Technical Report","snippet":"by A Liu \u00b7 2024 \u00b7 Cited by 2372 \u2014 Abstract. We present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with 671B total parameters with 37B activated for each token.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"harvard.edu"},{"type":"search_result","url":"https://ui.adsabs.harvard.edu/abs/2022arXiv221210560W/abstract?utm_source=chatgpt.com","title":"Aligning Language Model with Self Generated Instructions","snippet":"by Y Wang \u00b7 2022 \u00b7 Cited by 2766 \u2014 We introduce Self-Instruct, a framework for improving the instruction-following capabilities of pretrained language models by bootstrapping off its own ...","ref_id":{"turn_index":5,"ref_type":"search","ref_index":28},"pub_date":null,"attribution":"harvard.edu"},{"type":"search_result","url":"https://ui.adsabs.harvard.edu/abs/arXiv%3A2501.12948?utm_source=chatgpt.com","title":"DeepSeek-R1: Incentivizing Reasoning Capability in LLMs ...","snippet":"DeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) ... arXiv e-prints. Pub Date: January 2025; DOI: 10.48550/arXiv.2501.12948.","ref_id":{"turn_index":7,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"harvard.edu"}]},{"type":"search_result_group","domain":"allenai.org","entries":[{"type":"search_result","url":"https://allenai.org/blog/dolma-3-trillion-tokens-open-llm-corpus-9a0ff4b8da64?utm_source=chatgpt.com","title":"3 trillion token open corpus for language model pretraining","snippet":"Aug 18, 2023 \u2014 A dataset of 3 trillion tokens from a diverse mix of web content, academic publications, code, books, and encyclopedic materials.","ref_id":{"turn_index":5,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"allenai.org"},{"type":"search_result","url":"https://allenai.org/dolma?utm_source=chatgpt.com","title":"Dolma","snippet":"Dolma is an open dataset of 3 trillion tokens from a diverse mix of web content, academic publications, code, books, and encyclopedic materials.","ref_id":{"turn_index":5,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"allenai.org"},{"type":"search_result","url":"https://allenai.org/blog/olmo2?utm_source=chatgpt.com","title":"OLMo 2: The best fully open language model to date","snippet":"Nov 26, 2024 \u2014 We find that OLMo 2 7B and 13B are the best fully-open models to-date, often outperforming open weight models of equivalent size.","ref_id":{"turn_index":5,"ref_type":"search","ref_index":47},"pub_date":null,"attribution":"allenai.org"}]},{"type":"search_result_group","domain":"semianalysis.com","entries":[{"type":"search_result","url":"https://newsletter.semianalysis.com/p/scaling-laws-o1-pro-architecture-reasoning-training-infrastructure-orion-and-claude-3-5-opus-failures?utm_source=chatgpt.com","title":"Scaling Laws - O1 Pro Architecture, Reasoning Training ...","snippet":"Dec 10, 2024 \u2014 In this report we will outline the old pre-training scaling trend as well as the new scaling trends for post-training and inference time. This ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"semianalysis.com"},{"type":"search_result","url":"https://newsletter.semianalysis.com/p/tpuv5e-the-new-benchmark-in-cost?utm_source=chatgpt.com","title":"TPUv5e: The New Benchmark in Cost-Efficient Inference ...","snippet":"Sep 1, 2023 \u2014 Today we want to detail this game changing chip by demonstrating its performance/TCO advantage with data for cost of training GPT-3 and cost of ...","ref_id":{"turn_index":12,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"semianalysis.com"},{"type":"search_result","url":"https://newsletter.semianalysis.com/p/microsoft-infrastructure-ai-and-cpu?utm_source=chatgpt.com","title":"AI & CPU Custom Silicon Maia 100, Athena, Cobalt 100","snippet":"Nov 15, 2023 \u2014 Outside of accelerators there are also significant requirements for 800G PAM4 optics, coherent optics, cabling, cooling, CPUs, storage, DRAM, ...","ref_id":{"turn_index":12,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"semianalysis.com"}]},{"type":"search_result_group","domain":"datacamp.com","entries":[{"type":"search_result","url":"https://www.datacamp.com/blog/rlaif-reinforcement-learning-from-ai-feedback?utm_source=chatgpt.com","title":"RLAIF: What is Reinforcement Learning From AI Feedback?","snippet":"May 28, 2024 \u2014 RLAIF is a machine learning technique in which AI models provide feedback to other AI models during the reinforcement learning process.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":30},"pub_date":null,"attribution":"datacamp.com"},{"type":"search_result","url":"https://www.datacamp.com/blog/deepseek-r1?utm_source=chatgpt.com","title":"DeepSeek-R1: Features, o1 Comparison, Distilled Models ...","snippet":"Learn about DeepSeek-R1's key features, development process, distilled models, how to access it, pricing, and how it compares to OpenAI o1.","ref_id":{"turn_index":15,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"datacamp.com"},{"type":"search_result","url":"https://www.datacamp.com/blog/open-ai-o1?utm_source=chatgpt.com","title":"OpenAI o1 Guide: How It Works, Use Cases, API & More","snippet":"OpenAI o1 is a new series of models from OpenAI excelling in complex reasoning tasks, using chain-of-thought reasoning to outperform GPT-4o in areas like math, ...","ref_id":{"turn_index":21,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"datacamp.com"}]},{"type":"search_result_group","domain":"rlhfbook.com","entries":[{"type":"search_result","url":"https://rlhfbook.com/c/13-cai?utm_source=chatgpt.com","title":"Constitutional AI & AI Feedback","snippet":"RL from AI Feedback (RLAIF) is a larger set of techniques for using AI to augment or generate feedback data, including pairwise preferences [1] [2] [3]. There ...","ref_id":{"turn_index":16,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"rlhfbook.com"}]},{"type":"search_result_group","domain":"aaai.org","entries":[{"type":"search_result","url":"https://ojs.aaai.org/index.php/AAAI/article/view/29821/31426?utm_source=chatgpt.com","title":"Distilling Complex Reasoning Capabilities from LLMs by ...","snippet":"by Y Li \u00b7 2024 \u00b7 Cited by 35 \u2014 The conventional process of model specialization can be summarized as three steps (Zhu et al. 2023): The first step is chain-of-thought distillation, training ...","ref_id":{"turn_index":15,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"aaai.org"},{"type":"search_result","url":"https://ojs.aaai.org/index.php/AAAI/article/view/34952/37107?utm_source=chatgpt.com","title":"Debate Helps Weak-to-Strong Generalization","snippet":"by H Lang \u00b7 2025 \u00b7 Cited by 8 \u2014 We investigate ways of improving human supervision with a strong pretrained model and then supervise the strong model with enhanced weak human supervision. To ...","ref_id":{"turn_index":17,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"aaai.org"}]},{"type":"search_result_group","domain":"leehanchung.github.io","entries":[{"type":"search_result","url":"https://leehanchung.github.io/blogs/2024/10/08/reasoning-understanding-o1/?utm_source=chatgpt.com","title":"Reasoning Series, Part 1: Understanding OpenAI o1 - Han Lee","snippet":"Oct 8, 2024 \u2014 OpenAI's o1-preview, released in September 2024, introduces \"reasoning tokens\" to enhance complex problem-solving capabilities.","ref_id":{"turn_index":21,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"leehanchung.github.io"}]},{"type":"search_result_group","domain":"analyticsvidhya.com","entries":[{"type":"search_result","url":"https://www.analyticsvidhya.com/blog/2024/09/chinchilla-scaling-law/?utm_source=chatgpt.com","title":"What is the Chinchilla Scaling Law?","snippet":"Sep 19, 2024 \u2014 How the Chinchilla Scaling Law redefines NLP by optimizing large language models, balancing model size, data, and computational efficiency?","ref_id":{"turn_index":23,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"analyticsvidhya.com"}]},{"type":"search_result_group","domain":"substack.com","entries":[{"type":"search_result","url":"https://cameronrwolfe.substack.com/p/rlaif-reinforcement-learning-from?utm_source=chatgpt.com","title":"RLAIF: Reinforcement Learning from AI Feedback","snippet":"We will explore recent research that aims to automate the collection of human preferences for RLHF using AI, forming a new technique known as reinforcement ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":22},"pub_date":null,"attribution":"substack.com"},{"type":"search_result","url":"https://cameronrwolfe.substack.com/p/direct-preference-optimization?utm_source=chatgpt.com","title":"Direct Preference Optimization (DPO) - Deep (Learning) Focus","snippet":"[1] Rafailov, Rafael, et al. \"Direct preference optimization: Your language model is secretly a reward model.\" Advances in neural information ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":24},"pub_date":null,"attribution":"substack.com"},{"type":"search_result","url":"https://cameronrwolfe.substack.com/p/conditional-computation-the-birth?utm_source=chatgpt.com","title":"Mixture-of-Experts (MoE): The Birth and Rise of Conditional ...","snippet":"[5] Fedus, William, Barret Zoph, and Noam Shazeer. \"Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":21},"pub_date":null,"attribution":"substack.com"},{"type":"search_result","url":"https://gonzoml.substack.com/p/deepseek-v3-technical-details?utm_source=chatgpt.com","title":"DeepSeek-V3: Technical Details - Gonzo ML","snippet":"DeepSeek-V3 contains 671B total parameters, of which 37B are active for each token. It has 61 transformer layers with the hidden dimension, d_h=7168.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":28},"pub_date":null,"attribution":"substack.com"},{"type":"search_result","url":"https://cameronrwolfe.substack.com/p/moe-llms?utm_source=chatgpt.com","title":"Mixture-of-Experts (MoE) LLMs - by Cameron R. Wolfe, Ph.D.","snippet":"They enable exploration of larger scales without drastic increases in compute, reduce training costs, and can be efficiently hosted.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":29},"pub_date":null,"attribution":"substack.com"},{"type":"search_result","url":"https://garymarcus.substack.com/p/a-new-ai-scaling-law-shell-game?utm_source=chatgpt.com","title":"The new AI scaling law shell game - by Gary Marcus - Substack","snippet":"The new version is that there is not one scaling law, but three: scaling with how long you train a model (which isn't really holding anymore), scaling with how ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"substack.com"},{"type":"search_result","url":"https://cameronrwolfe.substack.com/p/llm-scaling-laws?utm_source=chatgpt.com","title":"Scaling Laws for LLMs: From GPT-3 to o3","snippet":"Scaling laws help us to predict the results of larger and more expensive training runs, giving us the necessary confidence to continue investing in scale.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"substack.com"},{"type":"search_result","url":"https://cameronrwolfe.substack.com/p/program-aided-language-models?utm_source=chatgpt.com","title":"Program-Aided Language Models - by Cameron R. Wolfe, Ph.D.","snippet":"Recent research has explored a programatic approach that encourages the LLM to generate chains of thought with both natural language and code components.","ref_id":{"turn_index":9,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"substack.com"},{"type":"search_result","url":"https://gonzoml.substack.com/p/mamba-linear-time-sequence-modeling?utm_source=chatgpt.com","title":"Mamba: Linear-Time Sequence Modeling with Selective ...","snippet":"The current work introduces a new class, selective state space models, bridging this gap by achieving transformer-level quality with linear input size scaling.","ref_id":{"turn_index":11,"ref_type":"search","ref_index":33},"pub_date":null,"attribution":"substack.com"},{"type":"search_result","url":"https://businessanalytics.substack.com/p/from-tpu-v5e-to-trillion-dollar-trends?utm_source=chatgpt.com","title":"From TPU v5e to Trillion-Dollar Trends: AI's New Cost Curve","snippet":"Aug 28, 2025 \u2014 Google Cloud Cuts AI Training Costs by 40% with TPU v5e. Plus: Nvidia ... After Optimization: $0.30 per GPU-equivalent hour (40% improvement).","ref_id":{"turn_index":12,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"substack.com"},{"type":"search_result","url":"https://offthegridxp.substack.com/p/what-is-microsofts-maia-100-artificial?utm_source=chatgpt.com","title":"What is Microsoft's Maia 100 artificial intelligence chip?","snippet":"A custom-built rack for the Maia 100 AI Accelerator and its cooling \u201csidekick\u201d system inside a thermal chamber at a Microsoft lab in Redmond.","ref_id":{"turn_index":12,"ref_type":"search","ref_index":20},"pub_date":null,"attribution":"substack.com"},{"type":"search_result","url":"https://cameronrwolfe.substack.com/p/demystifying-reasoning-models?utm_source=chatgpt.com","title":"Demystifying Reasoning Models - by Cameron R. Wolfe, Ph.D.","snippet":"Compared to other reasoning models from OpenAI, o3-mini is more cost effective and production-ready. For example, this model supports features ...","ref_id":{"turn_index":15,"ref_type":"search","ref_index":20},"pub_date":null,"attribution":"substack.com"}]},{"type":"search_result_group","domain":"vllm.ai","entries":[{"type":"search_result","url":"https://blog.vllm.ai/2023/06/20/vllm.html?utm_source=chatgpt.com","title":"vLLM: Easy, Fast, and Cheap LLM Serving with PagedAttention","snippet":"Jun 20, 2023 \u2014 vLLM equipped with PagedAttention redefines the new state of the art in LLM serving: it delivers up to 24x higher throughput than HuggingFace Transformers.","ref_id":{"turn_index":4,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"vllm.ai"},{"type":"search_result","url":"https://docs.vllm.ai/en/latest/design/paged_attention.html?utm_source=chatgpt.com","title":"Paged Attention - vLLM","snippet":"Paged Attention\u00b6. Warning. This is a historical document based on the original paper for vLLM. It no longer describes the code used in vLLM today. Currently ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":29},"pub_date":null,"attribution":"vllm.ai"}]},{"type":"search_result_group","domain":"sino-huang.github.io","entries":[{"type":"search_result","url":"https://sino-huang.github.io/posts/timo_schick-toolformer-language-models-can-teach-themselves-to-use-tools-2023/?utm_source=chatgpt.com","title":"Timo_schick Toolformer Language Models Can Teach ...","snippet":"Mar 1, 2023 \u2014 Title: Toolformer: Language Models Can Teach Themselves to Use Tools 2023 \u00b7 Author: Timo Schick et. al. META AI research \u00b7 Publish Year: 9 Feb ...","ref_id":{"turn_index":10,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"sino-huang.github.io"}]},{"type":"search_result_group","domain":"tomshardware.com","entries":[{"type":"search_result","url":"https://www.tomshardware.com/tech-industry/semiconductors/intel-foundry-secures-contract-to-build-microsofts-maia-2-next-gen-ai-processor-on-18a-18a-p-node-claims-report-could-be-first-step-in-ongoing-partnership?utm_source=chatgpt.com","title":"Intel Foundry secures contract to build Microsoft's Maia 2 ...","snippet":"Oct 17, 2025 \u2014 Intel Foundry secures contract to build Microsoft's Maia 2 next-gen AI processor on 18A/18A-P node, claims report \u2014 could be first step in ...","ref_id":{"turn_index":12,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"tomshardware.com"},{"type":"search_result","url":"https://www.tomshardware.com/pc-components/gpus/nvidias-next-gen-ai-gpu-revealed-blackwell-b200-gpu-delivers-up-to-20-petaflops-of-compute-and-massive-improvements-over-hopper-h100?utm_source=chatgpt.com","title":"Nvidia's next-gen AI GPU is 4X faster than Hopper","snippet":"Mar 18, 2024 \u2014 The dual-die B200 GPU has 4X the AI training performance and 30X the inference performance of its predecessor.","ref_id":{"turn_index":12,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"tomshardware.com"}]},{"type":"search_result_group","domain":"summarizepaper.com","entries":[{"type":"search_result","url":"https://www.summarizepaper.com/en/arxiv-id/2312.00752v2/?utm_source=chatgpt.com","title":"Linear-Time Sequence Modeling with Selective State Spaces","snippet":"Oct 23, 2024 \u2014 In their paper titled \"Mamba: Linear-Time Sequence Modeling with Selective State Spaces,\" authors Albert Gu and Tri Dao introduce a novel ...","ref_id":{"turn_index":11,"ref_type":"search","ref_index":29},"pub_date":null,"attribution":"summarizepaper.com"},{"type":"search_result","url":"https://www.summarizepaper.com/en/arxiv-id/2502.16182v1/?utm_source=chatgpt.com","title":"Your Language Model is Secretly a Preference Classifier","snippet":"Mar 1, 2025 \u2014 Implicit Preference Optimization (IPO) is a novel approach in reinforcement learning from human feedback (RLHF); IPO aims to reduce reliance ...","ref_id":{"turn_index":14,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"summarizepaper.com"}]},{"type":"search_result_group","domain":"emergentmind.com","entries":[{"type":"search_result","url":"https://www.emergentmind.com/topics/test-time-scaling-law?utm_source=chatgpt.com","title":"Test-Time Scaling Law","snippet":"Jul 1, 2025 \u2014 Test-time scaling law describes how model performance evolves as computational resources are increased specifically at inference or testing\u2014 ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"emergentmind.com"},{"type":"search_result","url":"https://www.emergentmind.com/papers/2403.09629?utm_source=chatgpt.com","title":"Quiet-STaR: Self-Reasoning in Language Models","snippet":"Mar 14, 2024 \u2014 The paper introduces Quiet-STaR, a method that lets language models self-generate internal rationales to enhance next-token predictions. It ...Jump to","ref_id":{"turn_index":6,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"emergentmind.com"},{"type":"search_result","url":"https://www.emergentmind.com/topics/o3-mini-reasoning-model?utm_source=chatgpt.com","title":"O3-mini Reasoning Model Overview","snippet":"Jul 12, 2025 \u2014 O3-mini is a chain-of-thought large language model engineered to perform multi-step reasoning on complex, multimodal tasks.","ref_id":{"turn_index":15,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"emergentmind.com"},{"type":"search_result","url":"https://www.emergentmind.com/topics/chinchilla-optimal-datasets?utm_source=chatgpt.com","title":"Chinchilla-Optimal Datasets","snippet":"Oct 9, 2025 \u2014 Chinchilla-Optimal Datasets enable compute-efficient training by balancing model parameters with token count to boost performance and ...","ref_id":{"turn_index":23,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"emergentmind.com"}]},{"type":"search_result_group","domain":"tridao.me","entries":[{"type":"search_result","url":"https://tridao.me/blog/2024/flash3/?utm_source=chatgpt.com","title":"FlashAttention-3: Fast and Accurate Attention with ...","snippet":"Jul 11, 2024 \u2014 In this blogpost, we describe three main techniques to speed up attention on Hopper GPUs: exploiting asynchrony of the Tensor Cores and TMA.","ref_id":{"turn_index":4,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"tridao.me"},{"type":"search_result","url":"https://tridao.me/blog/2024/mamba2-part1-model/?utm_source=chatgpt.com","title":"State Space Duality (Mamba-2) Part I - The Model","snippet":"May 31, 2024 \u2014 State Space Duality (SSD) refers to a specific layer in Mamba-2, a standalone model that can be incorporated into deep neural networks. The SSD ...","ref_id":{"turn_index":11,"ref_type":"search","ref_index":19},"pub_date":null,"attribution":"tridao.me"},{"type":"search_result","url":"https://tridao.me/tridao.github.io/?utm_source=chatgpt.com","title":"Tri Dao","snippet":"Jul 11, 2024, FlashAttention-3: Fast and Accurate Attention with Asynchrony and Low-precision ... Outstanding Paper runner-up arXiv Code. Outstanding Paper ...","ref_id":{"turn_index":22,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"tridao.me"}]},{"type":"search_result_group","domain":"decibel.vc","entries":[{"type":"search_result","url":"https://www.decibel.vc/articles/gorilla-enabling-large-language-models-to-use-tools-by-invoking-apis?utm_source=chatgpt.com","title":"Gorilla: Enabling Large Language Models to Use Tools by ...","snippet":"Gorilla finds the semantically and syntactically correct API to invoke, demonstrating how to use LLMs to invoke 1600+ (and growing) API calls accurately while ...","ref_id":{"turn_index":10,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"decibel.vc"}]},{"type":"search_result_group","domain":"wandb.ai","entries":[{"type":"search_result","url":"https://wandb.ai/onlineinference/genai-research/reports/NVIDIA-Blackwell-GPU-architecture-Unleashing-next-gen-AI-performance--VmlldzoxMjgwODI4Mw?utm_source=chatgpt.com","title":"NVIDIA Blackwell GPU architecture: Unleashing next\u2011gen ...","snippet":"May 16, 2025 \u2014 Blackwell GPU: NVIDIA's next-gen architecture with multi-die design, FP4 precision, NVLink-5, and GB200 Superchip powering unparalleled AI ...","ref_id":{"turn_index":12,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"wandb.ai"}]},{"type":"search_result_group","domain":"sciencedirect.com","entries":[{"type":"search_result","url":"https://www.sciencedirect.com/science/article/pii/S1877050924021860?utm_source=chatgpt.com","title":"A Survey on RAG with LLMs","snippet":"by M Arslan \u00b7 2024 \u00b7 Cited by 109 \u2014 This paper seeks to address this gap by providing a thorough review of RAG applications, encompassing both task-specific and discipline-specific studies.","ref_id":{"turn_index":8,"ref_type":"search","ref_index":20},"pub_date":null,"attribution":"sciencedirect.com"},{"type":"search_result","url":"https://www.sciencedirect.com/science/article/pii/S2666389925002181?utm_source=chatgpt.com","title":"Toward large reasoning models: A survey of reinforced ...","snippet":"by F Xu \u00b7 2025 \u00b7 Cited by 75 \u2014 The rise of large language models (LLMs) has led to research on their application in complex reasoning tasks. Researchers are exploring the ...","ref_id":{"turn_index":9,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"sciencedirect.com"},{"type":"search_result","url":"https://www.sciencedirect.com/science/article/abs/pii/S0893608024005185?utm_source=chatgpt.com","title":"Distilling mathematical reasoning capabilities into Small ...","snippet":"by X Zhu \u00b7 2024 \u00b7 Cited by 24 \u2014 This involves creating a reasoning dataset with multiple thought processes, including Chain-of-Thought (CoT), Program-of-Thought (PoT), and Equation-of-Thought ...","ref_id":{"turn_index":15,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"sciencedirect.com"}]},{"type":"search_result_group","domain":"digi-con.org","entries":[{"type":"search_result","url":"https://digi-con.org/on-constitutional-ai/?utm_source=chatgpt.com","title":"On 'Constitutional' AI - The Digital Constitutionalist","snippet":"May 22, 2025 \u2014 Anthropic seeks to train AI systems with a Constitution to ensure they remain 'helpful, honest, and harmless'.","ref_id":{"turn_index":16,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"digi-con.org"}]},{"type":"search_result_group","domain":"aarnphm.xyz","entries":[{"type":"search_result","url":"https://aarnphm.xyz/thoughts/Speculative-decoding?utm_source=chatgpt.com","title":"Speculative decoding","snippet":"May 21, 2025 \u2014 arXiv (Chen et al., 2023). von Neumann ... This work from DeepMind was performed concurrently and independently from Leviathan et al.","ref_id":{"turn_index":4,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"aarnphm.xyz"}]},{"type":"search_result_group","domain":"ssrn.com","entries":[{"type":"search_result","url":"https://papers.ssrn.com/sol3/Delivery.cfm/5107732.pdf?abstractid=5107732&mirid=1&utm_source=chatgpt.com","title":"The Mathematics of DeepSeek-R1","snippet":"Jan 22, 2025 \u2014 In the Group Relative Policy Optimization (GRPO) framework, the ob- jective incorporates group-based sampling to improve training efficiency and.","ref_id":{"turn_index":7,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"ssrn.com"}]},{"type":"search_result_group","domain":"reasonwithpal.com","entries":[{"type":"search_result","url":"https://reasonwithpal.com/?utm_source=chatgpt.com","title":"PAL: Program-aided Language Models","snippet":"We present Program-Aided Language models (PAL): a new method that uses the LLM to read natural language problems and generate programs as the intermediate ...","ref_id":{"turn_index":9,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"reasonwithpal.com"}]},{"type":"search_result_group","domain":"iclr.cc","entries":[{"type":"search_result","url":"https://proceedings.iclr.cc/paper_files/paper/2024/file/79fea214543ba263952ac3f4e5452b14-Paper-Conference.pdf?utm_source=chatgpt.com","title":"FROM SPARSE TO SOFT MIXTURES OF EXPERTS","snippet":"by J Puigcerver \u00b7 Cited by 206 \u2014 We study performance at different training budgets and show that Soft MoE dominates other models in terms of performance at a given training cost or time.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"iclr.cc"},{"type":"search_result","url":"https://proceedings.iclr.cc/paper_files/paper/2025/file/4eef032250ac525903063cd760cb0480-Paper-Conference.pdf?utm_source=chatgpt.com","title":"ITERATIVE NASH POLICY OPTIMIZATION: ALIGNING ...","snippet":"by Y Zhang \u00b7 Cited by 36 \u2014 In this paper, we study how to learn a policy \u03c0 that has a high probability of generating a preferred response over any other policy given the prompt x. We ...","ref_id":{"turn_index":14,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"iclr.cc"}]},{"type":"search_result_group","domain":"nb-data.com","entries":[{"type":"search_result","url":"https://www.nb-data.com/p/utilizing-gorilla-llm-to-boost-prompt?utm_source=chatgpt.com","title":"Utilizing Gorilla LLM to Boost Prompt Results for Greater ...","snippet":"Jul 31, 2023 \u2014 In the paper, Gorilla showed better API call results; as shown in the image above, GPT-4 and Claude suffer from Hallucinations and wrong facts.","ref_id":{"turn_index":10,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"nb-data.com"}]},{"type":"search_result_group","domain":"alignmentforum.org","entries":[{"type":"search_result","url":"https://www.alignmentforum.org/posts/Hna4aoMwr6Qx9rHBs/linkpost-introducing-superalignment?utm_source=chatgpt.com","title":"[Linkpost] Introducing Superalignment","snippet":"Jul 5, 2023 \u2014 To align the first automated alignment researcher, we will need to 1) develop a scalable training method, 2) validate the resulting model, and 3 ...","ref_id":{"turn_index":13,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"alignmentforum.org"},{"type":"search_result","url":"https://www.alignmentforum.org/posts/aLhLGns2BSun3EzXB/paper-constitutional-ai-harmlessness-from-ai-feedback?utm_source=chatgpt.com","title":"Paper: Constitutional AI: Harmlessness from AI Feedback ...","snippet":"Dec 16, 2022 \u2014 The authors propose a method for training a harmless AI assistant that can supervise other AIs, using only a list of rules (a \"constitution\") as human ...","ref_id":{"turn_index":16,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"alignmentforum.org"},{"type":"search_result","url":"https://www.alignmentforum.org/posts/5Kv2qNfRyXXihNrx2/ai-safety-debate-and-its-applications?utm_source=chatgpt.com","title":"AI Safety Debate and Its Applications","snippet":"Jul 23, 2019 \u2014 [1] Irving, Geoffrey, Paul Christiano, and Dario Amodei. \"AI safety via debate.\" arXiv preprint arXiv:1805.00899 (2018). Since the AIs are ...","ref_id":{"turn_index":17,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"alignmentforum.org"}]},{"type":"search_result_group","domain":"geekwire.com","entries":[{"type":"search_result","url":"https://www.geekwire.com/2024/buyer-beware-openais-o1-large-language-model-is-an-entirely-different-beast/?utm_source=chatgpt.com","title":"Buyer beware: OpenAI's o1 reasoning model is an entirely ...","snippet":"Dec 26, 2024 \u2014 OpenAI's new o1 model marks a significant leap in AI reasoning capabilities but introduces critical risks.","ref_id":{"turn_index":21,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"geekwire.com"}]},{"type":"search_result_group","domain":"aiengineering.academy","entries":[{"type":"search_result","url":"https://aiengineering.academy/LLM/TheoryBehindFinetuning/GRPO/?utm_source=chatgpt.com","title":"Theory Behind GRPO","snippet":"GRPO is a reinforcement learning algorithm designed to train large language models (LLMs) for complex tasks like solving math problems or writing code.","ref_id":{"turn_index":7,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"aiengineering.academy"},{"type":"search_result","url":"https://aiengineering.academy/LLM/TheoryBehindFinetuning/ORPO/?utm_source=chatgpt.com","title":"ORPO(Odds Ratio Preference Optimization)","snippet":"ORPO, or Odds Ratio Preference Optimization, is a method to fine-tune large language models (LLMs) like GPT-3 or Llama-2, making them generate responses humans ...","ref_id":{"turn_index":14,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"aiengineering.academy"}]},{"type":"search_result_group","domain":"psu.edu","entries":[{"type":"search_result","url":"https://faculty.ist.psu.edu/vhonavar/Papers/Neurips24.pdf?utm_source=chatgpt.com","title":"Cal-DPO: Calibrated Direct Preference Optimization for ...","snippet":"by T Xiao \u00b7 Cited by 41 \u2014 We study the problem of aligning large language models (LLMs) with human preference data. Contrastive preference optimization has shown promising results.","ref_id":{"turn_index":14,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"psu.edu"}]},{"type":"search_result_group","domain":"youtube.com","entries":[{"type":"search_result","url":"https://www.youtube.com/watch?v=V4dO2pyYGgs&utm_source=chatgpt.com","title":"Reinforced Self-Training (ReST) for Language Modeling ...","snippet":"This is a paper called reinforced self training or short rest for language modeling.","ref_id":{"turn_index":6,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"youtube.com"},{"type":"search_result","url":"https://www.youtube.com/watch?v=0rfgyQ-wAQM&utm_source=chatgpt.com","title":"Mathematical Reasoning in Language Models by OpenAI","snippet":"In recent years, large language models have greatly improved in their ability to perform complex multi-step reasoning.","ref_id":{"turn_index":9,"ref_type":"search","ref_index":35},"pub_date":null,"attribution":"youtube.com"}]},{"type":"search_result_group","domain":"scispace.com","entries":[{"type":"search_result","url":"https://scispace.com/papers/self-consistency-improves-chain-of-thought-reasoning-in-11cskg6j?utm_source=chatgpt.com","title":"Self-Consistency Improves Chain of Thought Reasoning in ...","snippet":"In this paper, we propose a new decoding strategy, self-consistency, to replace the naive greedy decoding used in chain-of-thought prompting.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":23},"pub_date":null,"attribution":"scispace.com"},{"type":"search_result","url":"https://scispace.com/papers/reinforced-self-training-rest-for-language-modeling-4yzqyitd91?utm_source=chatgpt.com","title":"Reinforced Self-Training (ReST) for Language Modeling","snippet":"Our results show that ReST can substantially improve translation quality, as measured by automated metrics and human evaluation on machine translation ...","ref_id":{"turn_index":6,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"scispace.com"},{"type":"search_result","url":"https://scispace.com/papers/program-of-thoughts-prompting-disentangling-computation-from-2vdo1u1x?utm_source=chatgpt.com","title":"Disentangling Computation from Reasoning for Numerical ...","snippet":"To disentangle computation from reasoning, we propose `Program of Thoughts' (PoT), which uses language models (mainly Codex) to express the reasoning process as ...","ref_id":{"turn_index":9,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"scispace.com"},{"type":"search_result","url":"https://scispace.com/papers/pal-program-aided-language-models-8fdiwko7?utm_source=chatgpt.com","title":"PAL: Program-aided Language Models (2022) | Luyu Gao","snippet":"In this paper, we present Program-Aided Language models (PAL): a novel approach that uses the LLM to read natural language problems and generate programs as the ...","ref_id":{"turn_index":9,"ref_type":"search","ref_index":30},"pub_date":null,"attribution":"scispace.com"},{"type":"search_result","url":"https://scispace.com/papers/self-rewarding-language-models-59h9rbvq8i?utm_source=chatgpt.com","title":"Self-Rewarding Language Models - Weizhe Yuan","snippet":"In this work, we study Self-Rewarding Language Models, where the language model itself is used via LLM-as-a-Judge prompting to provide its own rewards during ...","ref_id":{"turn_index":16,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"scispace.com"}]},{"type":"search_result_group","domain":"fireworks.ai","entries":[{"type":"search_result","url":"https://fireworks.ai/blog/deepseek-r1-distillation-reasoning?utm_source=chatgpt.com","title":"Distillation with Reasoning: Can DeepSeek R1 Teach ...","snippet":"Jan 31, 2025 \u2014 Distillation is a method for transferring knowledge from a large, more powerful teacher model to a smaller, more cost-effective student model.","ref_id":{"turn_index":15,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"fireworks.ai"}]},{"type":"search_result_group","domain":"assemblyai.com","entries":[{"type":"search_result","url":"https://assemblyai.com/blog/how-reinforcement-learning-from-ai-feedback-works?utm_source=chatgpt.com","title":"How Reinforcement Learning from AI Feedback works","snippet":"Aug 1, 2023 \u2014 Reinforcement Learning from AI Feedback (RLAIF) is a method devised by Anthropic that is designed to overcome many of the shortcomings of RLHF.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"assemblyai.com"}]},{"type":"search_result_group","domain":"rohan-paul.com","entries":[{"type":"search_result","url":"https://www.rohan-paul.com/p/mixture-of-experts-moe-architectures?utm_source=chatgpt.com","title":"Mixture-of-Experts (MoE) Architectures: 2024\u20132025 ...","snippet":"Jun 16, 2025 \u2014 By sparsely activating experts, MoE LLMs can attain superior performance on a range of tasks without the prohibitive costs of dense super-models ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"rohan-paul.com"}]},{"type":"search_result_group","domain":"innovationendeavors.com","entries":[{"type":"search_result","url":"https://www.innovationendeavors.com/insights/mechanisms-for-test-time-compute?utm_source=chatgpt.com","title":"Mechanisms for test-time compute","snippet":"In this blog I aim to outline the major ways test-time compute scaling can be achieved, based on both reviewing a lot of the recent literature in this space.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"innovationendeavors.com"}]},{"type":"search_result_group","domain":"bibsonomy.org","entries":[{"type":"search_result","url":"https://www.bibsonomy.org/bibtex/2c75ab44b188ee0f499f807ee49f94d9d/tomvoelker?utm_source=chatgpt.com","title":"Language Models Can Teach Themselves to Use Tools","snippet":"Introduces Toolformer, an approach enabling language models to self-learn the use of external tools. Demonstrates its effectiveness on tasks like web search, ...","ref_id":{"turn_index":10,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"bibsonomy.org"}]},{"type":"search_result_group","domain":"hotchips.org","entries":[{"type":"search_result","url":"https://hc2024.hotchips.org/assets/program/conference/day2/81_HC2024.Microsoft.Xu.Ramakrishnan.final.v2.pdf?utm_source=chatgpt.com","title":"Inside Maia 100","snippet":"by S Xu \u00b7 Cited by 3 \u2014 Maia 100 Introduction. Microsoft's 1st-gen custom AI Accelerator.. Targets large-scale AI workloads.. Designed specifically for Azure to run production ...","ref_id":{"turn_index":12,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"hotchips.org"}]},{"type":"search_result_group","domain":"slator.com","entries":[{"type":"search_result","url":"https://slator.com/how-well-can-openai-o3-mini-deepseek-r1-evaluate-ai-translation/?utm_source=chatgpt.com","title":"How Well Can OpenAI's o3-mini and DeepSeek-R1 ...","snippet":"May 2, 2025 \u2014 \u201cEffective distillation of evaluation relevant reasoning requires sufficient model capacity, with smaller distilled models potentially ...","ref_id":{"turn_index":15,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"slator.com"}]},{"type":"search_result_group","domain":"lifearchitect.ai","entries":[{"type":"search_result","url":"https://lifearchitect.ai/chinchilla/?utm_source=chatgpt.com","title":"Chinchilla data-optimal scaling laws: In plain English","snippet":"Aug 15, 2025 \u2014 For a fixed compute budget, Chinchilla showed that we need to be using 11\u00d7 more data during training than that used for GPT-3 and similar models.","ref_id":{"turn_index":5,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"lifearchitect.ai"}]},{"type":"search_result_group","domain":"semiengineering.com","entries":[{"type":"search_result","url":"https://semiengineering.com/deepseek-improving-language-model-reasoning-capabilities-using-pure-reinforcement-learning/?utm_source=chatgpt.com","title":"DeepSeek: Improving Language Model Reasoning ...","snippet":"Jan 27, 2025 \u2014 A new technical paper titled \u201cDeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning\u201d was published by DeepSeek.","ref_id":{"turn_index":7,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"semiengineering.com"}]},{"type":"search_result_group","domain":"projectpro.io","entries":[{"type":"search_result","url":"https://www.projectpro.io/article/self-rag/1176?utm_source=chatgpt.com","title":"The Self-RAG Shortcut Every AI Expert Wishes They Knew","snippet":"Oct 15, 2025 \u2014 The paper, Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection, by Asai et al., introduces a novel framework for self ...","ref_id":{"turn_index":8,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"projectpro.io"}]},{"type":"search_result_group","domain":"oxen.ai","entries":[{"type":"search_result","url":"https://ghost.oxen.ai/mamba-linear-time-sequence-modeling-with-selective-state-spaces-arxiv-dives/?utm_source=chatgpt.com","title":"Mamba: Linear-Time Sequence Modeling with Selective ...","snippet":"Dec 15, 2023 \u2014 Mamba is a recurrent neural network, a selective structured state space model, that outperforms Transformers with faster inference and scales ...","ref_id":{"turn_index":11,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"oxen.ai"}]},{"type":"search_result_group","domain":"intelligencestrategy.org","entries":[{"type":"search_result","url":"https://www.intelligencestrategy.org/blog-posts/superalignment-40-techniques-for-aligning-superintelligent-ai?utm_source=chatgpt.com","title":"Superalignment: 40+ Techniques for Aligning Superintelligent AI","snippet":"Jul 4, 2024 \u2014 Superalignment ensures superintelligent AI aligns with human values and ethics, using methods like RLHF, scalable oversight, and adversarial ...","ref_id":{"turn_index":13,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"intelligencestrategy.org"}]},{"type":"search_result_group","domain":"alphaxiv.org","entries":[{"type":"search_result","url":"https://www.alphaxiv.org/overview/2412.19437v2?utm_source=chatgpt.com","title":"DeepSeek-V3 Technical Report","snippet":"DeepSeek-V3 represents a significant advancement in open-source large language models, built upon a sophisticated Mixture-of-Experts (MoE) architecture with 671 ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":22},"pub_date":null,"attribution":"alphaxiv.org"},{"type":"search_result","url":"https://www.alphaxiv.org/overview/2510.13744v1?utm_source=chatgpt.com","title":"Hard2Verify: A Step-Level Verification Benchmark for Open ...","snippet":"Salesforce AI Research introduces Hard2Verify, a human-annotated benchmark for step-level verification of open-ended, frontier-level mathematical proofs, ...","ref_id":{"turn_index":9,"ref_type":"search","ref_index":32},"pub_date":null,"attribution":"alphaxiv.org"},{"type":"search_result","url":"https://www.alphaxiv.org/resources/2403.07691v1?utm_source=chatgpt.com","title":"Reference-free Monolithic Preference Optimization with ...","snippet":"Reference-free Monolithic Preference Optimization with Odds Ratio ... Get an engaging lecture and Q&A format to quickly understand the paper in minutes, perfect ...","ref_id":{"turn_index":14,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"alphaxiv.org"},{"type":"search_result","url":"https://www.alphaxiv.org/fr/overview/2212.08073v1?utm_source=chatgpt.com","title":"Constitutional AI: Harmlessness from AI Feedback","snippet":"Anthropic's Constitutional AI introduces a two-stage approach using AI-generated feedback based on natural language principles to train AI assistants.","ref_id":{"turn_index":16,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"alphaxiv.org"}]},{"type":"search_result_group","domain":"nips.cc","entries":[{"type":"search_result","url":"https://papers.nips.cc/paper_files/paper/2023/hash/a85b405ed65c6477a4fe8302b5e06ce7-Abstract-Conference.html?utm_source=chatgpt.com","title":"Direct Preference Optimization: Your Language Model is ...","snippet":"by R Rafailov \u00b7 2023 \u00b7 Cited by 5990 \u2014 Direct Preference Optimization (DPO) is a method that optimizes a language model to align with human preferences by solving a classification problem, ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"nips.cc"}]},{"type":"search_result_group","domain":"liner.com","entries":[{"type":"search_result","url":"https://liner.com/review/the-fineweb-datasets-decanting-the-web-for-the-finest-text?utm_source=chatgpt.com","title":"Decanting the Web for the Finest Text Data at Scale - Liner","snippet":"This paper introduces FineWeb, a large-scale dataset for LLM pretraining, detailing its construction and analyzing its textual properties and word ...","ref_id":{"turn_index":5,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"liner.com"}]},{"type":"search_result_group","domain":"goombalab.github.io","entries":[{"type":"search_result","url":"https://goombalab.github.io/blog/2024/mamba2-part1-model/?utm_source=chatgpt.com","title":"State Space Duality (Mamba-2) Part I - The Model | Goomba Lab","snippet":"May 31, 2024 \u2014 The main point of the Mamba-2 paper is what we call structured state space duality (SSD), which refers to several things.","ref_id":{"turn_index":11,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"goombalab.github.io"}]},{"type":"search_result_group","domain":"techcrunch.com","entries":[{"type":"search_result","url":"https://techcrunch.com/2023/12/06/google-announces-the-cloud-tpu-v5p-its-most-powerful-ai-accelerator-yet/?utm_source=chatgpt.com","title":"Google announces the Cloud TPU v5p, its most powerful AI ...","snippet":"Dec 6, 2023 \u2014 Google says all of this means the TPU v5p can train a large language model like GPT3-175B 2.8 times faster than the TPU v4 \u2014 and do so more cost ...","ref_id":{"turn_index":12,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"techcrunch.com"}]},{"type":"search_result_group","domain":"distill.pub","entries":[{"type":"search_result","url":"https://distill.pub/2019/safety-needs-social-scientists?utm_source=chatgpt.com","title":"AI Safety Needs Social Scientists","snippet":"by G Irving \u00b7 2019 \u00b7 Cited by 97 \u2014 This paper is a call for social scientists in AI safety. We ... AI safety via debate [PDF] Irving, G., Christiano, P. and Amodei, D., 2018.","ref_id":{"turn_index":17,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"distill.pub"}]},{"type":"search_result_group","domain":"techrxiv.org","entries":[{"type":"search_result","url":"https://www.techrxiv.org/users/885930/articles/1264015/master/file/data/A_Survey_on_Mixture_of_Experts__Advancements__Challenges__and_Future_Directions%20%281%29/A_Survey_on_Mixture_of_Experts__Advancements__Challenges__and_Future_Directions%20%281%29.pdf?utm_source=chatgpt.com","title":"A Survey on Mixture of Experts: Advancements, ...","snippet":"Abstract\u2014Mixture of Experts (MoE) is an advanced machine learning paradigm that enhances model scalability, efficiency, and specialization by dynamically ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"techrxiv.org"}]},{"type":"search_result_group","domain":"continuumlabs.ai","entries":[{"type":"search_result","url":"https://training.continuumlabs.ai/inference/why-is-inference-important/paged-attention-and-vllm?utm_source=chatgpt.com","title":"Paged Attention and vLLM","snippet":"May 26, 2024 \u2014 This November 2023 paper addresses the challenge of efficiently serving large language models (LLMs) in high-throughput scenarios.","ref_id":{"turn_index":4,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"continuumlabs.ai"}]},{"type":"search_result_group","domain":"aimind.so","entries":[{"type":"search_result","url":"https://pub.aimind.so/critical-review-of-gorilla-paper-%EF%B8%8Fan-api-store-for-llms-af327f2fddb?utm_source=chatgpt.com","title":"Critical Review of \ud83e\udd8dGORILLA Paper: \ud83d\udee0\ufe0fAn API store for ...","snippet":"Aug 7, 2023 \u2014 GORILLA addresses this issue by training LLMs to accurately invoke over 1,600 API calls, thereby reducing hallucination and improving the ...","ref_id":{"turn_index":10,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"aimind.so"}]},{"type":"search_result_group","domain":"amazon.com","entries":[{"type":"search_result","url":"https://aws.amazon.com/blogs/machine-learning/fine-tune-large-language-models-with-reinforcement-learning-from-human-or-ai-feedback/?utm_source=chatgpt.com","title":"Fine-tune large language models with reinforcement ...","snippet":"Apr 4, 2025 \u2014 The following diagram illustrates reinforcement learning from human feedback (RLHF) compared to reinforcement learning from AI feedback (RLAIF).","ref_id":{"turn_index":0,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"amazon.com"}]},{"type":"search_result_group","domain":"ibm.com","entries":[{"type":"search_result","url":"https://www.ibm.com/think/topics/tree-of-thoughts?utm_source=chatgpt.com","title":"What is Tree Of Thoughts Prompting?","snippet":"[4] Shunyu Yao, D. Y. (2023). Tree of Thoughts: Deliberate Problem Solving with Large Language Models. ArXiv, abs/2305.10601. https://arxiv.org/abs/2305.10601.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":34},"pub_date":null,"attribution":"ibm.com"},{"type":"search_result","url":"https://www.ibm.com/think/topics/mixture-of-experts?utm_source=chatgpt.com","title":"What is mixture of experts?","snippet":"In their influential 2021 paper, \u201cSwitch Transformers: Scaling to Trillion Parameter Models with Simple and Efficiency Sparsity,\u201d Fedus et al. took top-k ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"ibm.com"}]},{"type":"search_result_group","domain":"nsf.gov","entries":[{"type":"search_result","url":"https://par.nsf.gov/biblio/10539591?utm_source=chatgpt.com","title":"SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND ...","snippet":"by A Asai \u00b7 2024 \u00b7 Cited by 1264 \u2014 We developed an app called Self-E, which guides users through the experiment. We conducted a 2-week diary study with 16 participants from the local population.","ref_id":{"turn_index":8,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"nsf.gov"}]},{"type":"search_result_group","domain":"meta.com","entries":[{"type":"search_result","url":"https://ai.meta.com/research/publications/toolformer-language-models-can-teach-themselves-to-use-tools/?utm_source=chatgpt.com","title":"Toolformer: Language Models Can Teach Themselves to ...","snippet":"Feb 22, 2024 \u2014 We introduce Toolformer, a model trained to decide which APIs to call, when to call them, what arguments to pass, and how to best incorporate ...","ref_id":{"turn_index":10,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"meta.com"}]},{"type":"search_result_group","domain":"theverge.com","entries":[{"type":"search_result","url":"https://www.theverge.com/2024/3/18/24105157/nvidia-blackwell-gpu-b200-ai?utm_source=chatgpt.com","title":"Nvidia reveals Blackwell B200 GPU, the 'world's most ...","snippet":"Mar 18, 2024 \u2014 Nvidia says the new B200 GPU offers up to 20 petaflops of FP4 horsepower from its 208 billion transistors. Also, it says, a GB200 that combines ...","ref_id":{"turn_index":12,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"theverge.com"}]},{"type":"search_result_group","domain":"towardsai.net","entries":[{"type":"search_result","url":"https://pub.towardsai.net/how-microsofts-graphrag-works-step-by-step-b15cada5c209?utm_source=chatgpt.com","title":"How GraphRAG Works Step-By-Step","snippet":"May 6, 2025 \u2014 Explore how Microsoft's GraphRAG works step-by-step from Graph Creation to Local and Global Search using real examples and code insights.","ref_id":{"turn_index":8,"ref_type":"search","ref_index":19},"pub_date":null,"attribution":"towardsai.net"}]},{"type":"search_result_group","domain":"snorkel.ai","entries":[{"type":"search_result","url":"https://snorkel.ai/blog/research-spotlight-is-long-chain-of-thought-structure-all-that-matters-when-it-comes-to-llm-reasoning-distillation/?utm_source=chatgpt.com","title":"Research spotlight: reasoning distillation and long CoT ...","snippet":"Mar 19, 2025 \u2014 An overview of published research into how the structure of long chain-of-thoughts impacts reasoning distillation from models like DeepSeek.","ref_id":{"turn_index":15,"ref_type":"search","ref_index":19},"pub_date":null,"attribution":"snorkel.ai"}]},{"type":"search_result_group","domain":"stanford.edu","entries":[{"type":"search_result","url":"https://cs224r.stanford.edu/projects/pdfs/CS224R_Final_Report__5_.pdf?utm_source=chatgpt.com","title":"Precise RLAIF: Improving Instruction Following with Sentence ...","snippet":"by M Pe\u00f1a \u2014 Canonical Reinforcement Learning from AI Feedback In 2022, Bai et al. at Anthropic introduced. RL from AI Feedback in the paper \"Constitutional AI.\" RLAIF is ...","ref_id":{"turn_index":16,"ref_type":"search","ref_index":19},"pub_date":null,"attribution":"stanford.edu"}]},{"type":"search_result_group","domain":"zilliz.com","entries":[{"type":"search_result","url":"https://zilliz.com/learn/efficient-memory-management-for-llm-serving-pagedattention?utm_source=chatgpt.com","title":"Efficient Memory Management for Large Language Model ...","snippet":"Oct 5, 2024 \u2014 PagedAttention and vLLM solve important challenges in serving LLMs, particularly the high costs and inefficiencies in GPU memory usage when using it for ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":20},"pub_date":null,"attribution":"zilliz.com"}]},{"type":"search_result_group","domain":"tobysimonds.com","entries":[{"type":"search_result","url":"https://tobysimonds.com/research/2025/09/29/Proofs.html?utm_source=chatgpt.com","title":"How to Train an LLM to do proofs: Beyond Verifiable ...","snippet":"Sep 29, 2025 \u2014 Demonstrated that LLMs can be trained using RL to improve at writing proofs by leveraging LLM judges with rubric-based evaluation.","ref_id":{"turn_index":9,"ref_type":"search","ref_index":20},"pub_date":null,"attribution":"tobysimonds.com"}]},{"type":"search_result_group","domain":"learnprompting.org","entries":[{"type":"search_result","url":"https://learnprompting.org/docs/retrieval_augmented_generation/self-rag?srsltid=AfmBOoqeZnZ1Pv3YFBdqlMJOGx545z9EctPxYaGmH0mG5ALSwfOgOzqy&utm_source=chatgpt.com","title":"Self-RAG","snippet":"Mar 2, 2025 \u2014 Discover how Self-RAG enhances LLMs by making them smarter about when to retrieve external knowledge and how to self-assess their responses.","ref_id":{"turn_index":8,"ref_type":"search","ref_index":21},"pub_date":null,"attribution":"learnprompting.org"}]},{"type":"search_result_group","domain":"xpu.pub","entries":[{"type":"search_result","url":"https://xpu.pub/2024/03/28/nvidia-blackwell/?utm_source=chatgpt.com","title":"Nvidia Blackwell GPU Promises 30\u00d7 Speedup, but Expect 3","snippet":"Mar 28, 2024 \u2014 Nvidia has disclosed the first Blackwell (B100/B200) details, promising performance gains from 3\u00d7 to 30\u00d7 over Hopper (H100/H200).","ref_id":{"turn_index":12,"ref_type":"search","ref_index":21},"pub_date":null,"attribution":"xpu.pub"}]},{"type":"search_result_group","domain":"aussieai.com","entries":[{"type":"search_result","url":"https://www.aussieai.com/research/speculative-decoding?utm_source=chatgpt.com","title":"Speculative Decoding: Types and Optimizations","snippet":"Speculative decoding is a multi-model ensemble architecture where a small model generates some possible output tokens (\"speculating\" on the correct answer)","ref_id":{"turn_index":4,"ref_type":"search","ref_index":22},"pub_date":null,"attribution":"aussieai.com"}]},{"type":"search_result_group","domain":"skymod.tech","entries":[{"type":"search_result","url":"https://skymod.tech/inside-googles-tpu-and-gpu-comparisons/?utm_source=chatgpt.com","title":"Inside Google's TPU: Architecture and GPU Comparisons","snippet":"Aug 13, 2025 \u2014 Recent TPU generations from Google (v5e, v5p, v6e) deliver massive compute power for AI training and inference, especially in cloud environments ...","ref_id":{"turn_index":12,"ref_type":"search","ref_index":22},"pub_date":null,"attribution":"skymod.tech"}]},{"type":"search_result_group","domain":"preprints.org","entries":[{"type":"search_result","url":"https://www.preprints.org/manuscript/202408.0583/v2/download?utm_source=chatgpt.com","title":"The Evolution of Mixture of Experts: A Survey from Basics ...","snippet":"by A Vats \u00b7 2024 \u00b7 Cited by 16 \u2014 Mixture of Experts (MoE) divides input data into sub-tasks, training specialized experts for each, to improve deep learning performance.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":23},"pub_date":null,"attribution":"preprints.org"}]},{"type":"search_result_group","domain":"runpod.io","entries":[{"type":"search_result","url":"https://www.runpod.io/blog/introduction-to-vllm-and-pagedattention?utm_source=chatgpt.com","title":"Introduction to vLLM and PagedAttention","snippet":"May 31, 2024 \u2014 Learn how vLLM achieves up to 24x higher throughput than Hugging Face Transformers by using PagedAttention to eliminate memory waste, ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":23},"pub_date":null,"attribution":"runpod.io"}]},{"type":"search_result_group","domain":"paperwithoutcode.com","entries":[{"type":"search_result","url":"https://paperwithoutcode.com/quiet-star-language-models-can-teach-themselves-to-think-before-speaking-code-of-improved-recursive-cot-like-in-openai-o1/?utm_source=chatgpt.com","title":"Quiet-STaR: Language Models Can Teach Themselves to ...","snippet":"Sep 20, 2024 \u2014 Unlike STaR, which was confined to specific question-answering datasets, Quiet-STaR generalizes reasoning to unstructured text, enabling ...Jump to","ref_id":{"turn_index":6,"ref_type":"search","ref_index":23},"pub_date":null,"attribution":"paperwithoutcode.com"}]},{"type":"search_result_group","domain":"ultralytics.com","entries":[{"type":"search_result","url":"https://www.ultralytics.com/blog/openai-o1-a-new-series-of-openai-models-for-ai-reasoning?utm_source=chatgpt.com","title":"OpenAI o1: New AI Reasoning Models - Inside Look","snippet":"September 13, 2024. Find out about the newly launched OpenAI o1 models and what makes them special. We'll also take a look at how they work and their impact ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":24},"pub_date":null,"attribution":"ultralytics.com"}]},{"type":"search_result_group","domain":"icml.cc","entries":[{"type":"search_result","url":"https://icml.cc/media/icml-2024/Slides/35222_1r94S59.pdf?utm_source=chatgpt.com","title":"Mixture-of-Experts in the Era of LLMs A New Odyssey","snippet":"Jul 22, 2024 \u2014 Can we achieve next generation model quality on current generation of hardware? \u2022 From a computation perspective sparse Mixture-of-Experts.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":26},"pub_date":null,"attribution":"icml.cc"},{"type":"search_result","url":"https://icml.cc/virtual/2025/poster/45120?utm_source=chatgpt.com","title":"Quantizing the RWKV Family with Proxy Guided Hybrid of ...","snippet":"This paper investigates and identifies two key constraints inherent in the properties of RWKV ... arXiv preprint arXiv:2404.00456, 2024. Bisk, Y., Zellers, R., ...","ref_id":{"turn_index":11,"ref_type":"search","ref_index":24},"pub_date":null,"attribution":"icml.cc"}]},{"type":"search_result_group","domain":"networkworld.com","entries":[{"type":"search_result","url":"https://www.networkworld.com/article/2066534/nvidia-launches-blackwell-gpu-architecture.html?utm_source=chatgpt.com","title":"Nvidia launches Blackwell GPU architecture","snippet":"Mar 18, 2024 \u2014 The next-gen Blackwell architecture will offer a 4x performance boost over the current Hopper lineup, Nvidia claims.","ref_id":{"turn_index":12,"ref_type":"search","ref_index":24},"pub_date":null,"attribution":"networkworld.com"}]},{"type":"search_result_group","domain":"research.google","entries":[{"type":"search_result","url":"https://research.google/blog/looking-back-at-speculative-decoding/?utm_source=chatgpt.com","title":"Looking back at speculative decoding","snippet":"Speculative decoding has proven to be an effective technique for faster and cheaper inference from LLMs without compromising quality.","ref_id":{"turn_index":4,"ref_type":"search","ref_index":25},"pub_date":null,"attribution":"research.google"},{"type":"search_result","url":"https://research.google/blog/distilling-step-by-step-outperforming-larger-language-models-with-less-training-data-and-smaller-model-sizes/?utm_source=chatgpt.com","title":"Distilling step-by-step: Outperforming larger language ...","snippet":"Sep 21, 2023 \u2014 We introduce distilling step-by-step, a new simple mechanism that allows us to train smaller task-specific models with much less training data.","ref_id":{"turn_index":15,"ref_type":"search","ref_index":27},"pub_date":null,"attribution":"research.google"}]},{"type":"search_result_group","domain":"mbrenndoerfer.com","entries":[{"type":"search_result","url":"https://mbrenndoerfer.com/writing/chinchilla-scaling-laws-compute-optimal-training-resource-allocation?utm_source=chatgpt.com","title":"Chinchilla Scaling Laws: Compute-Optimal Training and ...","snippet":"2 days ago \u2014 A comprehensive guide to the Chinchilla scaling laws introduced in 2022. Learn how compute-optimal training balances model size and training ...","ref_id":{"turn_index":5,"ref_type":"search","ref_index":25},"pub_date":null,"attribution":"mbrenndoerfer.com"}]},{"type":"search_result_group","domain":"encord.com","entries":[{"type":"search_result","url":"https://encord.com/blog/reinforecement-learning-from-ai-feedback-what-is-rlaif/?utm_source=chatgpt.com","title":"What is RLAIF - Reinforcement Learning from AI Feedback?","snippet":"Dec 20, 2023 \u2014 Reinforcement Learning (RLAIF) Stage\u200b\u200b In the RL stage, the process mimics RLHF. It replaces human preferences with AI-generated feedback.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":26},"pub_date":null,"attribution":"encord.com"}]},{"type":"search_result_group","domain":"x.com","entries":[{"type":"search_result","url":"https://x.com/omarsar0/status/1768681638009975088?utm_source=chatgpt.com","title":"LMs Can Teach Themselves to Think Before Speaking","snippet":"Quiet-STaR enables LMs to generate rationales at each token to explain future text. It proposes a token-wise parallel sampling algorithm that ...Jump to","ref_id":{"turn_index":6,"ref_type":"search","ref_index":26},"pub_date":null,"attribution":"x.com"}]},{"type":"search_result_group","domain":"maartengrootendorst.com","entries":[{"type":"search_result","url":"https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-mamba-and-state?utm_source=chatgpt.com","title":"A Visual Guide to Mamba and State Space Models","snippet":"Gu, Albert, and Tri Dao. \"Mamba: Linear-time sequence modeling with selective state spaces.\" arXiv preprint arXiv:2312.00752 (2023). 2. Gu, Albert, et al.","ref_id":{"turn_index":11,"ref_type":"search","ref_index":26},"pub_date":null,"attribution":"maartengrootendorst.com"}]},{"type":"search_result_group","domain":"windowsforum.com","entries":[{"type":"search_result","url":"https://windowsforum.com/threads/microsoft-bets-on-in-house-ai-chips-with-maia-100-and-cobalt-100.383077/?utm_source=chatgpt.com","title":"Microsoft Bets on In-House AI Chips With Maia 100 and ...","snippet":"Oct 3, 2025 \u2014 Microsoft announced Cobalt\u2011powered VM families with claims of improved price\u2011performance over prior Arm instances and broad region availability.","ref_id":{"turn_index":12,"ref_type":"search","ref_index":26},"pub_date":null,"attribution":"windowsforum.com"}]},{"type":"search_result_group","domain":"genesiscloud.com","entries":[{"type":"search_result","url":"https://www.genesiscloud.com/blog/blackwell-gpus-gb200-b200?utm_source=chatgpt.com","title":"Nvidia Blackwell GPUs: Unlocking AI Potential with B200s ...","snippet":"Oct 10, 2024 \u2014 This difference in speedup largely comes from the transition to the FP4 precision format, which doubles the operations per second compared to ...","ref_id":{"turn_index":12,"ref_type":"search","ref_index":27},"pub_date":null,"attribution":"genesiscloud.com"}]},{"type":"search_result_group","domain":"alexirpan.com","entries":[{"type":"search_result","url":"https://www.alexirpan.com/2024/12/04/late-o1-thoughts.html?utm_source=chatgpt.com","title":"Late Takes on OpenAI o1","snippet":"Dec 4, 2024 \u2014 OpenAI o1 is a model release widely believed (but not confirmed) to be a post-trained version of GPT-4o. It is directly trained to spend more time generating.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":28},"pub_date":null,"attribution":"alexirpan.com"}]},{"type":"search_result_group","domain":"yanivle.github.io","entries":[{"type":"search_result","url":"https://yanivle.github.io/ai/2023/07/25/speculative-decoding-icml.html?utm_source=chatgpt.com","title":"Speculative Decoding @ ICML - Yaniv Leviathan","snippet":"Jul 25, 2023 \u2014 Speculative decoding enables inferring from LLMs faster, without a trade-off - i.e. we decode faster while guaranteeing exactly the same output ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":28},"pub_date":null,"attribution":"yanivle.github.io"}]},{"type":"search_result_group","domain":"neo4j.com","entries":[{"type":"search_result","url":"https://neo4j.com/blog/genai/graphrag-manifesto/?utm_source=chatgpt.com","title":"The GraphRAG Manifesto: Adding Knowledge to GenAI","snippet":"Jul 11, 2024 \u2014 This post is intended to be a comprehensive and easy-to-read treatment of GraphRAG. It turns out that building a knowledge graph of your data and using it in ...","ref_id":{"turn_index":8,"ref_type":"search","ref_index":28},"pub_date":null,"attribution":"neo4j.com"}]},{"type":"search_result_group","domain":"bespokelabs.ai","entries":[{"type":"search_result","url":"https://www.bespokelabs.ai/blog/bespoke-stratos-the-unreasonable-effectiveness-of-reasoning-distillation?utm_source=chatgpt.com","title":"The unreasonable effectiveness of reasoning distillation","snippet":"Jan 22, 2025 \u2014 We trained Bespoke-Stratos-32B, our reasoning model distilled from DeepSeek-R1 using Berkeley NovaSky's Sky-T1 data pipeline.","ref_id":{"turn_index":15,"ref_type":"search","ref_index":28},"pub_date":null,"attribution":"bespokelabs.ai"}]},{"type":"search_result_group","domain":"iese.edu","entries":[{"type":"search_result","url":"https://blog.iese.edu/artificial-intelligence-management/2024/chain-of-thought-reasoning-the-new-llm-breakthrough/?utm_source=chatgpt.com","title":"Chain of Thought Reasoning, the New LLM Breakthrough","snippet":"Oct 22, 2024 \u2014 Furthermore, in July 2024, OpenAI published a blog post describing how they developed CriticGPT, a model based on GPT-4, to evaluate the output ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":29},"pub_date":null,"attribution":"iese.edu"}]},{"type":"search_result_group","domain":"wikipedia.org","entries":[{"type":"search_result","url":"https://en.wikipedia.org/wiki/OpenAI_o3?utm_source=chatgpt.com","title":"OpenAI o3","snippet":"OpenAI o3 is a reflective generative pre-trained transformer (GPT) model developed by OpenAI as a successor to OpenAI o1 for ChatGPT.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":29},"pub_date":null,"attribution":"wikipedia.org"}]},{"type":"search_result_group","domain":"wizardlm.github.io","entries":[{"type":"search_result","url":"https://wizardlm.github.io/WizardMath/?utm_source=chatgpt.com","title":"WizardMath - WizardLM","snippet":"In this paper, we present WizardMath, which enhances the mathematical reasoning abilities of Llama-2, by applying our proposed Reinforcement Learning from Evol ...","ref_id":{"turn_index":5,"ref_type":"search","ref_index":29},"pub_date":null,"attribution":"wizardlm.github.io"},{"type":"search_result","url":"https://wizardlm.github.io/WizardCoder/?utm_source=chatgpt.com","title":"WizardCoder - WizardLM","snippet":"In this paper, we present Code Evol-Instruct, a novel approach that adapts the Evol-Instruct method to the realm of code, enhancing Code LLMs to create ...","ref_id":{"turn_index":5,"ref_type":"search","ref_index":49},"pub_date":null,"attribution":"wizardlm.github.io"}]},{"type":"search_result_group","domain":"springer.com","entries":[{"type":"search_result","url":"https://link.springer.com/article/10.1007/s00521-025-11666-9?utm_source=chatgpt.com","title":"A survey on retrieval-augmentation generation (RAG) ...","snippet":"by M Abo El-Enen \u00b7 2025 \u00b7 Cited by 1 \u2014 This paper provides a comprehensive examination of RAG models in healthcare, analyzing their architectural variations, performance ...","ref_id":{"turn_index":8,"ref_type":"search","ref_index":29},"pub_date":null,"attribution":"springer.com"}]},{"type":"search_result_group","domain":"toronto.edu","entries":[{"type":"search_result","url":"https://www.cs.toronto.edu/~cmaddis/courses/csc2541_w25/presentations/mu_cao_dpo.pdf?utm_source=chatgpt.com","title":"Direct Preference Optimization(DPO)","snippet":"Feb 14, 2025 \u2014 DPO optimizes for human preferences while avoiding reinforcement learning, aiming to find the optimal policy and remove the reward model.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":32},"pub_date":null,"attribution":"toronto.edu"}]},{"type":"search_result_group","domain":"allenai.github.io","entries":[{"type":"search_result","url":"https://allenai.github.io/dolma/docs/assets/dolma-v0_1-20230819.pdf?utm_source=chatgpt.com","title":"Dolma: An Open Corpus of 3 Trillion Tokens for Language ...","snippet":"Common Crawl. The Common Crawl data is available on Amazon S3 as part of the Amazon Web. Services' Open Data Sponsorship program and can be freely downloaded 2.","ref_id":{"turn_index":5,"ref_type":"search","ref_index":32},"pub_date":null,"attribution":"allenai.github.io"}]},{"type":"search_result_group","domain":"amatria.in","entries":[{"type":"search_result","url":"https://amatria.in/blog/postpretraining-revisted?utm_source=chatgpt.com","title":"The post-training journey of modern LLMs revisited","snippet":"Sep 6, 2025 \u2014 This idea was formalized into a technique known as Process Supervision, where a reward is provided for each correct step in a model's reasoning ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":33},"pub_date":null,"attribution":"amatria.in"}]},{"type":"search_result_group","domain":"raw.githubusercontent.com","entries":[{"type":"search_result","url":"https://raw.githubusercontent.com/mlresearch/v235/main/assets/lee24t/lee24t.pdf?utm_source=chatgpt.com","title":"RLAIF vs. RLHF: Scaling Reinforcement Learning from ...","snippet":"by H Lee \u00b7 Cited by 282 \u2014 Abstract. Reinforcement learning from human feedback. (RLHF) has proven effective in aligning large lan- guage models (LLMs) with human preferences,.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":34},"pub_date":null,"attribution":"raw.githubusercontent.com"}]},{"type":"search_result_group","domain":"athina.ai","entries":[{"type":"search_result","url":"https://blog.athina.ai/pal-program-aided-language-models?utm_source=chatgpt.com","title":"PAL: Program-aided Language Models","snippet":"Jan 27, 2023 \u2014 A novel approach that uses the LLM to read natural language problems and generate programs as the intermediate reasoning steps.","ref_id":{"turn_index":9,"ref_type":"search","ref_index":34},"pub_date":null,"attribution":"athina.ai"}]},{"type":"search_result_group","domain":"mdpi.com","entries":[{"type":"search_result","url":"https://www.mdpi.com/2076-3417/15/12/6420?utm_source=chatgpt.com","title":"Advanced Hyena Hierarchy Architectures for Predictive ...","snippet":"by T Song \u00b7 2025 \u2014 This study addresses these challenges by proposing a novel integrated deep learning framework based on Hyena Hierarchy architectures.","ref_id":{"turn_index":11,"ref_type":"search","ref_index":36},"pub_date":null,"attribution":"mdpi.com"}]},{"type":"search_result_group","domain":"scribd.com","entries":[{"type":"search_result","url":"https://www.scribd.com/document/689324832/Tree-of-Thoughts-Deliberate-Problem-Solving-with-Large-Language-Models?utm_source=chatgpt.com","title":"Tree of Thoughts: Deliberate Problem Solving With Large ...","snippet":"May 17, 2023 \u2014 Tree of Thoughts: Deliberate Problem Solving with Large Language Models - Free download as PDF File (.pdf), Text File (.txt) or read online ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":37},"pub_date":null,"attribution":"scribd.com"}]},{"type":"search_result_group","domain":"nih.gov","entries":[{"type":"search_result","url":"https://pmc.ncbi.nlm.nih.gov/articles/PMC12334620/?utm_source=chatgpt.com","title":"MathOdyssey: Benchmarking Mathematical Problem ...","snippet":"by M Fang \u00b7 2025 \u00b7 Cited by 43 \u2014 MathOdyssey: Benchmarking Mathematical Problem-Solving Skills in Large Language Models Using Odyssey Math Data ... Training verifiers to solve math word problems.","ref_id":{"turn_index":9,"ref_type":"search","ref_index":37},"pub_date":null,"attribution":"nih.gov"}]},{"type":"search_result_group","domain":"marekbiernacki.com","entries":[{"type":"search_result","url":"https://www.marekbiernacki.com/paper-reviews/self-instruct?utm_source=chatgpt.com","title":"Self Instruct: Aligning Language Models with Self-Generated ...","snippet":"Aug 22, 2025 \u2014 This paper introduces the SELF-INSTRUCT framework for improving instruction-following capabilities of pre-trained language models by ...","ref_id":{"turn_index":5,"ref_type":"search","ref_index":38},"pub_date":null,"attribution":"marekbiernacki.com"}]}],"citations":[],"request_id":"wfr_019a51cd5d3b7123a6fe080708343a30","message_type":"next","model_slug":"gpt-5-pro","default_model_slug":"gpt-5-pro","parent_id":"f7073b06-3cc0-4258-bb19-391b6c6582cc","timestamp_":"absolute","can_save":true},"recipient":"all","channel":"final"},"parent":"f7073b06-3cc0-4258-bb19-391b6c6582cc","children":[]}}}