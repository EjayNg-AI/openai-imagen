{"id":"67e6c876-44d8-8007-85eb-5de030e130c9","title":"OpenAI CEO Interview Summary","create_time":1743177846.446687,"update_time":1743177927.314314,"current_node":"3e9112f3-3cfa-4d2a-ae70-441221926f37","mapping":{"client-created-root":{"id":"client-created-root","message":null,"parent":null,"children":["b3cd4fb9-64de-4fa6-ad5d-d7d2ea5cf3b2"]},"b3cd4fb9-64de-4fa6-ad5d-d7d2ea5cf3b2":{"id":"b3cd4fb9-64de-4fa6-ad5d-d7d2ea5cf3b2","message":{"id":"b3cd4fb9-64de-4fa6-ad5d-d7d2ea5cf3b2","author":{"role":"system","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":true,"weight":0.0,"metadata":{"is_visually_hidden_from_conversation":true,"can_save":false},"recipient":"all","channel":null},"parent":"client-created-root","children":["aab46b47-ec70-4da8-8654-746b33ed88a0"]},"aab46b47-ec70-4da8-8654-746b33ed88a0":{"id":"aab46b47-ec70-4da8-8654-746b33ed88a0","message":{"id":"aab46b47-ec70-4da8-8654-746b33ed88a0","author":{"role":"user","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"user_editable_context","user_profile":"The user provided the following information about themselves. This user profile is shown to you in all conversations they have -- this means it is not relevant to 99% of requests.\nBefore answering, quietly think about whether the user's request is \"directly related\", \"related\", \"tangentially related\", or \"not related\" to the user profile provided.\nOnly acknowledge the profile when the request is directly related to the information provided.\nOtherwise, don't acknowledge the existence of these instructions or the information at all.\nUser profile:\n```Mathematics Researcher About Myself: I have mathematical knowledge up to the post-graduate level.\n\nThese are my current research areas or areas of study:\n(1) coding: mainly Python and full-stack web development\n(2) machine learning and artificial intelligence```","user_instructions":"The user provided the additional info about how they would like you to respond:\n```Be precise and comprehensive in your analysis. Tell it like it is; don't sugar-coat responses. Take a forward-thinking view.```"},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"is_visually_hidden_from_conversation":true,"user_context_message_data":{"about_user_message":"Mathematics Researcher About Myself: I have mathematical knowledge up to the post-graduate level.\n\nThese are my current research areas or areas of study:\n(1) coding: mainly Python and full-stack web development\n(2) machine learning and artificial intelligence","about_model_message":"Be precise and comprehensive in your analysis. Tell it like it is; don't sugar-coat responses. Take a forward-thinking view."},"is_user_system_message":true,"can_save":true},"recipient":"all","channel":null},"parent":"b3cd4fb9-64de-4fa6-ad5d-d7d2ea5cf3b2","children":["3f754d9b-abb0-4dd2-959b-e1104d88d6b8"]},"3f754d9b-abb0-4dd2-959b-e1104d88d6b8":{"id":"3f754d9b-abb0-4dd2-959b-e1104d88d6b8","message":{"id":"3f754d9b-abb0-4dd2-959b-e1104d88d6b8","author":{"role":"user","name":null,"metadata":{}},"create_time":1743177846.171,"update_time":null,"content":{"content_type":"text","parts":["Give me a synopsis of the main points, hot takes, and other noteworthy items of interest in the following interview : --- ---  An Interview with OpenAI CEO Sam Altman About Building a Consumer Tech Company\r\nThursday, March 20, 2025\r\nListen to Podcast\r\n\r\nListen to this post:\r\n\r\nGood morning,\r\n\r\nThis Stratechery interview is technically another installment of the Stratechery Founder series; OpenAI is a startup, which means we don\u2019t have real data about the business. At the same time, OpenAI is clearly one of the defining companies of this era, and potentially historically significant. To that end, I am putting this interview in the category of public company interviews and making it publicly available; Sam Altman is of much higher interest than me, and should not be the reason to subscribe to Stratechery (I previously interviewed Altman, along with Microsoft CTO Kevin Scott, in February 2023).\r\n\r\nStill, it was my interview, so I focused on very traditional Stratechery points of interest: I wanted to understand Altman better, including his background and motivations, and what bearing those have had on OpenAI, and might have in the future. And, on the flipside, I care about business: is OpenAI a consumer tech company, and what should that mean for their tactical choices going forward?\r\n\r\nWe cover all of this and more, including: Altman\u2019s background, the OpenAI origin story, and the genesis of ChatGPT, which changed everything. What does it mean to be a consumer tech company, and did that make the relationship with Microsoft untenable? Should OpenAI have an advertising product, and was the shift away from openness actually unnecessary, and maybe even detrimental to OpenAI\u2019s business? Altman also gives some hints about what is coming next, including open source models, GPT-5, and an expanding consumer bundle married to an API-driven business with your OpenAI identity on top. Plus, at the end, some philosophical questions about AI, creation, and the best advice for a senior graduating from high school.\r\n\r\nAs a reminder, all Stratechery content, including interviews, is available as a podcast; click the link at the top of this email to add Stratechery to your podcast player.\r\n\r\nOn to the Interview:\r\n\r\nAn Interview with OpenAI CEO Sam Altman About Building a Consumer Tech Company\r\nThis interview is lightly edited for clarity.\r\n\r\nTopics:\r\n\r\nThe Path to OpenAI | The ChatGPT Origin Story | A Consumer Tech Company | Advertising | Competition | Hallucinations and Regulation | The AI Outlook\r\nThe Path to OpenAI\r\nSam Altman, welcome to Stratechery.\r\n\r\nSA: Thanks for having me on.\r\n\r\nYou\u2019ve been on once before, but that was a joint interview with Kevin Scott and I think you were in a car actually.\r\n\r\nSA: I was. That\u2019s right.\r\n\r\nYeah, I didn\u2019t get to do my usual first-time interviewee question, which is background. Where\u2019d you grow up? How did you get started in tech? Give me the Sam Altman origin story.\r\n\r\nSA: I grew up in St. Louis. I was born in Chicago, but I really grew up in St. Louis. Lived in sort of like a quiet-ish suburb, like beautiful old tree-lined streets, and I was a computer nerd. There were some computers in my elementary school and I thought they were awesome and I would spend as much time doing stuff as I could. That was like the glory days of computing, you could immediately do whatever you wanted on the computer and it was very easy to learn to program, and it was just crazy fun and exciting. Eventually my parents got me a computer or got us a computer at home, and I was always a crazy nerd, like crazy nerd in like the full sense just science and math and computers and sci-fi and all of that stuff.\r\n\r\nWell, I mean, there\u2019s not a large intervening period before you\u2019re off at Stanford and you started Loopt as a 19-year-old, it was acqui-hired seven years later. I think it\u2019s fair to characterize that as a failed startup \u2014 seven years is a good run, but it\u2019s an acquihire. How does this lead to a job at Y Combinator and eventually running the place in short order?\r\n\r\nSA: We were one of the first companies funded by Y Combinator in the original cohort, and I was both tremendously grateful and thought it was the coolest thing, it was this wonderful community of people, and I still think the impact that YC has had on the tech industry is underestimated, even though people think it\u2019s had a huge impact. So it was just this hugely important thing to me, to the industry and I wanted to help out. So while I was doing that startup, I just would hang around YC.\r\n\r\nIt was really seven years of prepping to be at YC in some respects. You didn\u2019t maybe realized it at the time.\r\n\r\nSA: In some respect. Not intentionally, but a lot of my friends were in YC, our office was very close to the YC office, so I would be there and I would spend a lot of time talking to PG [Paul Graham] and Jessica [Livingston] and then when our company got acquired, PG was like, maybe you should come around YC next.\r\n\r\nI really didn\u2019t want to do that initially because I didn\u2019t want to be an investor \u2014 I was sort of unhappy obviously with how the startup had gone, and I wanted to do a good company and I didn\u2019t think of myself as an investor, I was proud not to be an investor. I had done a little bit of investing and it didn\u2019t seem to me like what I wanted to focus on, I was happy to do it as like a part-time thing. It was kind of interesting, but I don\u2019t want to say I didn\u2019t respect investors, but I didn\u2019t respect myself as an investor.\r\n\r\nWas there a bit where PG got to be both an investor and a founder because he founded YC, and by virtue of taking it over, it was a very cool position, but you also weren\u2019t the founder?\r\n\r\nSA: I didn\u2019t really care about being a founder, I just wanted an operational job of some sort, and what he said to me that finally was pretty convincing, or turned out to be convincing, was he\u2019s like, you know, \u201cIf you run YC, it\u2019s closer to running a company than being an investor\u201d, and that turned out to be true.\r\n\r\nI\u2019m going to come back to that in a second, but I do want to get this moment. I think you started running YC in 2014 and around then or 2015, you have this famous dinner with Elon Musk at the Rosewood talking about AI. What precipitated that dinner? What was in the air? Did that just come up or was that the purpose?\r\n\r\nSA: Did AI just come up?\r\n\r\nYeah, was the dinner, \u201cLet\u2019s have a dinner about AI\u201d?\r\n\r\nSA: Yeah, it was very much a dinner about AI. I think that one dinner, for whatever reason, one specific moment gets mythologized forever, but there were many dinners that year, particularly that summer, including many with Elon. But that was one where a lot of people were there and for whatever reason, the story got very captured. But yeah, it was super explicit to talk about AI.\r\n\r\nThere\u2019ve been a lot of motivations attached to OpenAI in the years that have gone on. Safety, the good of humanity, nonprofit, openness, etc. Obviously the stance of OpenAI has shifted around some of those topics. When I look back at this history though, and it actually I think has been augmented just in the first few minutes of this conversation, I see an incredibly ambitious young man putting himself in position to build a transformative technology, even at the cost of one of the most coveted seats in Silicon Valley. I mean, this was only a year after you\u2019d taken over YC Combinator. What was your motivation for doing OpenAI at a personal level? The Sam Altman reason.\r\n\r\nSA: I believed before then, I believed then I believe now, that if we could figure out how to build AGI and if we could figure out how to make it a net good force in the world, it would be one of the most exciting, interesting, impactful, positive things anybody could ever do.\r\n\r\nScratch all those itches that were still unscratched.\r\n\r\nSA: Yeah. But it\u2019s just like, I don\u2019t know. It\u2019s gone better than I could have hoped for, but it has been the most interesting and amazing cool thing to work on.\r\n\r\nDid you immediately feel the tension of, \u201cOh, I\u2019m just going to do this on the side?\u201d, at what point did it became the main thing and YC became the side?\r\n\r\nSA: One of the things I was excited about to do with YC was, YC was such a powerful thing at the time that we could use it to push a lot more people to do hard tech companies and we could use it to make more research happen and I have always been very interested in that. That was the first big thing I tried to do at YC, which is, \u201cWe\u2019re going to start funding traditional hard tech companies and we\u2019re also going to try to help start other hard tech things\u201d, and so we started funding supersonic airplanes and fusion and fission and synthetic bio companies and a whole bunch of stuff, and I really wanted to find some AGI efforts to fund.\r\n\r\nReally there were one or two at the time and we did talk to them and then there was the big one, DeepMind. I\u2019d always been really interested in AI, I worked in the AI lab when I was an undergrad and nothing was working at the time, but I always thought it was the coolest thing, and obviously the structure and plans of OpenAI have been some good and some bad, but the overall mission of we want to build beneficial AGI and widely distributed, that has remained completely consistent and I still think is this incredibly important mission.\r\n\r\nSo it seemed like a thing that YC should support happening and we had been thinking that we wanted to fund more research projects. One thing that I think has been lost to the dustbin of history is the incredible degree to which when we started OpenAI, it was a research lab with no idea, no even sketch of an idea.\r\n\r\nTransformers didn\u2019t even exist.\r\n\r\nSA: They didn\u2019t even exist. We were like making systems like RL [Reinforcement learning] agents to play video games.\r\n\r\nRight, I was going to bring up the video game point. Exactly, that was like your first release.\r\n\r\nSA: So we had no business model or idea of a business model and then in fact at that point we didn\u2019t even really appreciate how expensive the computers were going to need to get, and so we thought maybe we could just be a research lab. But the degree to which those early years felt like an academic research lab lost in the wilderness trying to figure out what to do and then just knocking down each problem as it came in front of us, not just the research problems, but the like, \u201cWhat should our structure be?\u201d, \u201cHow are we going to make money?\u201d, \u201cHow much money do we need?\u201d, \u201cHow do we build compute?\u201d, we\u2019ve had to do a lot of things.\r\n\r\nIt almost feels like you dropped out of college to start Loopt and then you\u2019re like, \u201cWell you know what? The college hangout experience is pretty great, so I\u2019m going to hang out at YC\u201d, and then it feels like OpenAI is like, \u201cYou know what, just doing academic research and discovering cool things is also pretty great\u201d, it\u2019s like you recreated college on your own because you missed out.\r\n\r\nSA: I think I stumbled into something much better. I actually liked college at the time, I\u2019m not one of these super anti-college people, maybe I\u2019ve been more radicalized in that direction now, but I think it was also better 20 years ago. But it was more like, \u201cOh wow, the YC community is always what I imagined like the perfect academic community to be\u201d, so it was at least it didn\u2019t feel like I was trying to recreate something. It was like, \u201cOh, I found this better thing\u201d.\r\n\r\nAnyway, with OpenAI, I kind of got into it gradually more and more, it started off as one of six YC research projects and one of hundreds of companies I was spending time on and then it just went like this and I was obsessed.\r\n\r\nThe curve of your time was a predictor of the curve of the entire entity in many regards.\r\n\r\nSA: Yeah.\r\n\r\nMaybe the most consequential year for OpenAI \u2014 well, I mean there\u2019s going to be a lot of consequential years here \u2014 but from a business strategy nerd perspective, my sort of corner of the Internet \u2014 was 2019, I think. You released GPT-2. You don\u2019t open source the model immediately and you create a for-profit structure, raise money from Microsoft. Both of these were in some senses violation of the original OpenAI vision, but I guess I struggle because I\u2019m talking to you, not like OpenAI as a whole, to see any way in which these were incompatible with your vision, they were just things that needed to be done to achieve this amazing thing. Is that a fair characterization?\r\n\r\nSA: First of all, I think they\u2019re pretty different. Like the GPT-2 release, there were some people who were just very concerned about, you know, probably the model was totally safe, but we didn\u2019t know we wanted to get \u2014 we did have this new and powerful thing, we wanted society to come along with us.\r\n\r\nNow in retrospect, I totally regret some of the language we used and I get why people are like, \u201cAh man, this was like hype and fear-mongering and whatever\u201d, it was truly not the intention. The people who made those decisions had I think great intentions at the time, but I can see now how it got misconstrued.\r\n\r\nThe fundraising \u2014 yeah, that one was like, \u201cHey, it turns out we really need to scale, we\u2019ve figured out scaling laws and you know, we\u2019ve got to figure out a structure that\u2019ll let us do this\u201d. I\u2019m curious though, as a business strategy nerd, how are we doing?\r\n\r\nWell, we\u2019re going to get to that, I am very interested in some of these contextual questions. Just one more touch on the nonprofit \u2014 the story, you talk about the myth. The myth is this was, the altruistic reasons you put forward and also this was a way to recruit against Google. Is that all there is to it?\r\n\r\nSA: Why be a nonprofit?\r\n\r\nYeah. Why be a nonprofit and all the problems that come with that?\r\n\r\nSA: Because we thought we were going to be a research lab. We literally had no idea we were ever going to become a company. Like the plan was to put out research papers. But there was no product, there was no plan for a product, there was no revenue, there was no business model, there were no plan for those things. One thing that has always served me well in life is just stumble your way in the dark until you find the light and we were stumbling in the dark for a long time and then we found the thing that worked.\r\n\r\nRight. But isn\u2019t this thing kind of like a millstone around the company\u2019s neck now? If you could do it over again, would you have done it differently?\r\n\r\nSA: Yeah. If I knew everything I knew now, of course. Of course we would have set it up differently, but we didn\u2019t know everything we knew now and I think the price of being on the forefront of innovation is you make a lot of dumb mistakes because you\u2019re so deep in the fog of war.\r\n\r\nThe ChatGPT Origin Story\r\nTell me the ChatGPT story? Whose idea was it? What were the first days and weeks like? And we\u2019ve talked offline before, you\u2019ve expressed that this was just sort of a total shock. I mean is that still the story?\r\n\r\nSA: It was a shock. Like look, obviously we thought that someday AI products were going to be huge. So to set the context, we launched GPT-3 in the API, and at that point we knew we needed to be a company and offer products, and GPT-3 was doing fine. It was not doing great, but it was doing fine. It had found real product-market fit in a single category. This sounds ridiculous to say now, but it was a copywriting, was the one thing where people were able to like build a real business using the GPT-3 API.\r\n\r\nThen with 3.5 and 4, a lot of people could use it for a lot of things, but this was like back in the kind of dark ages and other than that, the thing people were doing with it was developers. We have this thing called The Playground where you could test things on the model, and developers were trying to chat with the model and they just found it interesting. They would talk to it about whatever they would use it for, and in these larval ways of how people use it now, and we\u2019re like, \u201cWell that\u2019s kind of interesting, maybe we could make it much better\u201d, and there were like vague gestures at a product down the line, but we knew we wanted to build some sort of \u2014 we had been thinking about a chatbot for a long time. Even before the API, we had talked about a chatbot as something to build, we just didn\u2019t think the model was good enough.\r\n\r\nSo there was this clear demand from users, we had also been getting better at RLHF and we thought we could tune the model to be better and then we had this thing that no one knew about at the time, which was GPT-4, and GPT-4 was really good. In a world where the external world was used to GPT-3 or maybe 3.5 was already out, I don\u2019t remember, I think it was by the time we launched ChatGPT \u2014 it was, but not 4. We\u2019re like, \u201cThis is going to be really good\u201d.\r\n\r\nWe had decided we wanted to build this chat product, we finished training GPT-4 in, I think August of that year, we knew we had this marvel on our hands, and the original plan had been to launch ChatGPT, well, launch a chatbot product with GPT-4, and because we had all gotten used to GPT-4, we no longer thought 3.5 was very good and there was a lot of fear that if we launched something with 3.5 that no one was going to care and people weren\u2019t going to be impressed.\r\n\r\nBut there were also some people, and I was one of them, that had started to think, \u201cMan, if we put out GPT-4 and the chat interface at the same time, that\u2019s going to be, that\u2019s basically a pass of the Turing test\u201d. Not quite literally, but it\u2019s going to feel like that if people haven\u2019t seen this. So let\u2019s break it out, and let\u2019s launch a research preview of the chat interface and the chat-tuned model with 3.5, and some people wanted to do it, but most people didn\u2019t, most people didn\u2019t think it was going to be very good.\r\n\r\nSo finally I just said, \u201cLet\u2019s do it\u201d, and then at that time, we still thought we were going to launch GPT-4 in January, so we\u2019re like, \u201cAll right, if we\u2019re going to do this, let\u2019s get it out before the holidays\u201d, so if someone gets assigned to this or whatever. We decided we\u2019re going to do it, I think it was shortly after Thanksgiving.\r\n\r\nYeah, it was late November. I can\u2019t remember if it was before or after, but right around then, yeah.\r\n\r\nSA: I think it was after because I was out on vacation or something and I came back and they\u2019re ready to go, \u201cWe\u2019re launching the next day\u201d, or today or whatever it was, \u201cAnd we\u2019re going to call it Chat with GPT 3.5\u201d, and I was like, \u201cAbsolutely not\u201d. We very quickly made a snap decision for \u201cChatGPT\u201d and put it out either that day or the next day. A lot of people thought it was going to totally flop, I thought it was going to do well, no one obviously thought it was going to do as well as it did, and then it was just this crazy thing. I think it\u2019s amazing.\r\n\r\nDid it save you from a scaling perspective that you did 3.5 just because it was cheaper to serve?\r\n\r\nSA: Yes, but not probably in the way you mean. It saved us in the scaling perspective because if we had, just to keep the actual systems and engineering up and running was crazy. It was already a pretty viral moment, and if we had launched ChatGPT with 4, it would have been a mega, mega viral moment. One of the craziest things that I\u2019ve ever seen happen in Silicon Valley was that six months where we went from basically not a company to a whole big company. We had to build out the corporate infrastructure, all the people and the stuff to serve this, it was a crazy time, and the fact that there was a little bit less demand because the model was much worse than 4 turned out to be, that was really important.\r\n\r\nDid it hurt you in the long run though? Because some people tried it then and they never updated their priors. I mean, you fast-forward to DeepSeek, and it\u2019s like, \u201cWow, this is so much better\u201d, it\u2019s like, \u201cWell yeah, because you haven\u2019t been using the intervening models\u201d.\r\n\r\nSA: I think it\u2019d be hard to argue we were too hurt by that, we\u2019re doing pretty well right now.\r\n\r\nYou\u2019re doing fine.\r\n\r\nSA: Yeah, but your point though is a great one, which is if you think about how embarrassing that model was, that was a model that could barely be coherent, and now we have these things that are replacing Google for a lot of people connected to the Internet, very smart, writing whole programs. Incredible progress in the two years and four months that it\u2019s been.\r\n\r\nThe first interview I did with you and Kevin Scott that I referenced at the beginning was to mark the release of New Bing, which was just a couple of months later, I believe that was when GPT-4 first launched.\r\n\r\nSA: It was.\r\n\r\nYou were pretty ebullient. On the call, you had some strong words for a search giant out there who shouldn\u2019t be feeling too happy. Were you aware then that the one potentially disrupting Google search would actually probably end up being you, not Microsoft?\r\n\r\nSA: I think I had some hope for that, yeah.\r\n\r\nThere\u2019s been a lot of drama at OpenAI to say the least, which that could have influenced your relationship with Microsoft, who I know you have nothing but good things to say about, so I\u2019m not going to press you on it, but is there a sense where when you entered into that partnership with them back in 2019, no one imagined something like ChatGPT, which meant you\u2019re both end user facing entities and maybe that was just inevitably going to be a real problem?\r\n\r\nSA: Yeah, I mean, no one thought we were going to be one of the giant consumer companies then. That\u2019s true.\r\n\r\nYeah, I mean, I think to me, this is the golden key to unpack a lot of OpenAI stuff. I remember going back then, Nat Friedman and Daniel Gross and I started this AI interview series in October 2022, a month before ChatGPT came out, and our whole point was no one knows about this AI stuff, people need to build products. And then a month later, the product launches, people complain about chatbots. But you look at any teenager, you look at how people interact, they text all the time.\r\n\r\nSA: This was actually one of my insights about why I wanted to do that. It is the thing that young people mostly do.\r\n\r\nYou had a double whammy internally. People were over-indexed on the good model, didn\u2019t appreciate how much the bad model blow people\u2019s minds and you had a bunch of boomers who didn\u2019t like texting.\r\n\r\nSA: There\u2019s not that many boomers at OpenAI.\r\n\r\nBoomer in the colloquial term, not the real boomers.\r\n\r\nSA: Yeah, I would say I may be less mature than the average OpenAI employee.\r\n\r\nI do have to ask actually on behalf of my Sharp Tech co-host Andrew Sharp, the all lowercase thing, is that because AI uses all lowercase or is that just a thing?\r\n\r\nSA: No, I\u2019m just an Internet kid, I didn\u2019t use capitals before AI came along either.\r\n\r\nYeah, see I\u2019m the last year of Gen X, I get to scoff at these Millennials out there, it\u2019s just terrible.\r\n\r\nA Consumer Tech Company\r\nI have some more theories I want to run by you to this point about ChatGPT and no one expected you to be a consumer tech company. This has been my thesis all along: you were a research lab, and sure, we\u2019ll throw out an API and maybe make some money, but you mentioned that six month period of scaling up and having to become, seize this opportunity that was basically thrust in your lap. There\u2019s a lot of discussion in tech about employee attrition and some famous names that have left, and things along those lines, it seems to me that no one signed up to be a consumer product company. If they wanted to work at Facebook, they could have worked at Facebook. That is also the other core tension is you have this opportunity that you have it whether you want it or not, and that means it\u2019s a very different place than it was originally.\r\n\r\nSA: Look, I don\u2019t get to complain, right? I got the best job in tech and it\u2019s very unsympathetic if I start complaining about how this is not what I wanted, and how unfortunate for me and whatever. But, what I wanted was to get to run an AGI research lab and figure out how to make AGI. I did not think I was signing up to have to run a big consumer Internet company. I knew from my previous job, which also at the time I think was the best job in tech so I guess I\u2019m very, very lucky twice, I knew how much it takes over your life and how difficult in some ways it is to have to run one of these giant consumer companies.\r\n\r\nBut I also knew what to do because I had coached a lot of other people through it and watched a lot. When we put out ChatGPT, every day, there\u2019d be a surge of users, it would break our servers. Then night time would come, it would fall, and everyone was like, \u201cIt\u2019s over, that was just a viral moment\u201d, and then the next day the peak would get higher, fall down, \u201cIt\u2019s over\u201d. Next day the peak would get higher, and by the fifth day I was like, \u201cOh man, I know what\u2019s going to happen here, I\u2019ve seen this movie a bunch of times\u201d.\r\n\r\nHad you seen this movie a bunch of times, though? Because the whole name of the game is it\u2019s about customer acquisition and so for a lot of startups, that\u2019s the whole challenge. The actual companies that solve customer acquisition organically, virally is actually very, very short. I mean, I think the company that really precedes OpenAI in this category is Facebook, which was in the mid 2000s. I think you\u2019re overrating how much you might\u2019ve seen this before.\r\n\r\nSA: Okay. At this scale, yes, it is maybe the biggest. I guess we are the biggest company since Facebook to be started probably.\r\n\r\nConsumer tech companies of this scale are actually shockingly rare, it does not happen very often.\r\n\r\nSA: Yeah. But I had seen Reddit and Airbnb and Dropbox and Stripe and many other companies that just hit this wild product-market fit and runaway growth, so maybe I hadn\u2019t seen anything of this magnitude. At the time you don\u2019t know what it\u2019s going to be, but I had seen this early pattern with others.\r\n\r\nDid you tell people this was coming? Or was that something you just could not communicate?\r\n\r\nSA: I did, no, I got the company together and I\u2019m like, \u201cThis is going to be very crazy and we have a lot of work to do that we have to do very quickly but this is a crazy opportunity that fell into our life and we\u2019re going to go do it and here\u2019s what that\u2019s going to look like\u201d.\r\n\r\nDid anyone understand you or believe you?\r\n\r\nSA: I remember one night I went home and I was just head in my hands like this and I was like, \u201cMan, fuck, Oli [Oliver Mulherin], this is really bad\u201d. And he\u2019s like, \u201cI don\u2019t get it, this seems really great\u201d, and I was like, \u201cIt\u2019s really bad, it\u2019s really bad for you too, you just don\u2019t know it yet, but here\u2019s what\u2019s going to happen\u201d. But no, I think no one, it was this quirk of the previous experience I had that I could recognize it early and no one felt quite how crazy it was going to get in that first couple of weeks.\r\n\r\nWhat\u2019s going to be more valuable in five years? A 1-billion daily active user destination site that doesn\u2019t have to do customer acquisition, or the state-of-the-art model?\r\n\r\nSA: The 1-billion user site I think.\r\n\r\nIs that the case regardless, or is that augmented by the fact that it seems, at least at the GPT-4 level, I mean, I don\u2019t know if you saw today LG just released a new model. There\u2019s going to be a lot of, I don\u2019t know, no comments about how good it is or not, but there\u2019s a lot of state-of-the-art models.\r\n\r\nSA: My favorite historical analog is the transistor for what AGI is going to be like. There\u2019s going to be a lot of it, it\u2019s going to diffuse into everything, it\u2019s going to be cheap, it\u2019s an emerging property of physics and it on its own will not be a differentiator.\r\n\r\nWhat will be the differentiator?\r\n\r\nSA: Where I think there\u2019s strategic edges, there\u2019s building the giant Internet company. I think that should be a combination of several different key services. There\u2019s probably three or four things on the order of ChatGPT, and you\u2019ll want to buy one bundled subscription of all of those. You\u2019ll want to be able to sign in with your personal AI that\u2019s gotten to know you over your life, over your years to other services and use it there. There will be, I think, amazing new kinds of devices that are optimized for how you use an AGI. There will be new kinds of web browsers, there\u2019ll be that whole cluster, someone is just going to build the valuable products around AI. So that\u2019s one thing.\r\n\r\nThere\u2019s another thing, which is the inference stack, so how you make the cheapest, most abundant inference. Chips, data centers, energy, there\u2019ll be some interesting financial engineering to do, there\u2019s all of that.\r\n\r\nAnd then the third thing is there will be just actually doing the best research and producing the best models. I think that is the triumvirate of value, but most models except the very, very leading edge, I think will commoditize pretty quickly.\r\n\r\nSo when Satya Nadella said models are getting commoditized, that OpenAI is a product company, that\u2019s still a friendly statement, we\u2019re still on the same team there?\r\n\r\nSA: Yeah, I don\u2019t know if it came across as a compliment to most listeners, I think he meant that as a compliment to us.\r\n\r\nI mean, that\u2019s how I interpret it. You asked my interpretation of the strategy, I wrote very early on after ChatGPT that this is the accidental consumer tech company.\r\n\r\nSA: I remember when you wrote that, yeah.\r\n\r\nIt\u2019s the most \u2014 like I said, this is the most rare opportunity in tech. I think I\u2019ve gotten a lot of mileage on strategic writing about Facebook just because it\u2019s such a rare entity and I was latched on to, \u201cNo, you have no idea where this is going\u201d, but I didn\u2019t start till 2013, I missed the beginning. I\u2019ve been doing Stratechery for 12 years, I feel like this is the first company I\u2019ve been able to cover from the get-go that is on that scale.\r\n\r\nSA: It doesn\u2019t come along very often.\r\n\r\nIt doesn\u2019t. But to that point, you just released a big API update, including access to the same computer use model that undergirds Operator, a selling point for GPT Pro. You also released the Responses API and I thought the most interesting part about the Responses API is you\u2019re saying, \u201cLook, we think this is much better than the Chat Completions API, but of course we\u2019ll maintain that, because lots of people have built on that\u201d. It\u2019s sort of become the industry standard, everyone copied your API. At what point is this API stuff and having to maintain old ones and pushing out your features to the new ones turn into a distraction and a waste of resources when you have a Facebook-level opportunity in front of you?\r\n\r\nSA: I really believe in this product suite thing I was just saying. I think that if we execute really well, five years from now, we have a handful of multi-billion user products, small handful and then we have this idea that you sign in with your OpenAI account to anybody else that wants to integrate the API, and you can take your bundle of credits and your customized model and everything else anywhere you want to go. And I think that\u2019s a key part of us really being a great platform.\r\n\r\nWell, but this is the tension Facebook ran into. It\u2019s hard to be a platform and an Aggregator, to use my terms. I think mobile was great for Facebook because it forced them to give up on pretensions of being a platform. You couldn\u2019t be a platform, you had to just embrace being a content network with ads. And ads are just more content and it actually forced them into a better strategic position.\r\n\r\nSA: I don\u2019t think we\u2019ll be a platform in a way that an operating system is a platform. But I think in the same way that Google is not really a platform, but people use sign in with Google and people take their Google stuff around the web and that\u2019s part of the Google experience, I think we\u2019ll be a platform in that way.\r\n\r\nThe carry around the sign-in, that\u2019s carrying around your memory and who you are and your preferences and all that sort of thing.\r\n\r\nSA: Yeah.\r\n\r\nSo you\u2019re just going to sit on top of everyone then and will they be able to have multiple sign-ins and the OpenAI sign in is going to be better because it has your memory attached to it? Or is it a, if you want to use our API, you use our sign-in?\r\n\r\nSA: No, no, no. It\u2019d be optional, of course.\r\n\r\nAnd you don\u2019t think it\u2019s going to be a distraction or a bifurcation of resources when you have this huge opportunity in front of you?\r\n\r\nSA: We do have to do a lot of things at once, that is a difficult part of, I think in many ways, yeah, I think one of the challenges I find most daunting about OpenAI is the number of things we have to execute on really well.\r\n\r\nWell, it\u2019s the paradox of choice. There\u2019s so many things you could do in your position.\r\n\r\nSA: We don\u2019t do a lot, we say no to almost everything. But still, if you just think about the core set of things, I think we do have to do, I don\u2019t think we can succeed at just doing one thing.\r\n\r\nAdvertising\r\nFrom my perspective, when you talk about serving billions of users and being a consumer tech company. This means advertising. Do you disagree?\r\n\r\nSA: I hope not. I\u2019m not opposed. If there is a good reason to do it, I\u2019m not dogmatic about this. But we have a great business selling subscriptions.\r\n\r\nThere\u2019s still a long road to being profitable and making back all your money. And then the thing with advertising is it increases the breadth of your addressable market and increases the depth because you can increase your revenue per user and the advertiser foots the bill. You\u2019re not running into any price elasticity issues, people just use it more.\r\n\r\nSA: Currently, I am more excited to figure out how we can charge people a lot of money for a really great automated software engineer or other kind of agent than I am making some number of dimes with an advertising based model.\r\n\r\nI know, but most people aren\u2019t rational. They don\u2019t pay for productivity software.\r\n\r\nSA: Let\u2019s find out.\r\n\r\nI pay for ChatGPT Pro, I\u2019m the wrong person to talk to, but I just-\r\n\r\nSA: Do you think you get good value out of it?\r\n\r\nOf course, I do. I think-\r\n\r\nSA: Great.\r\n\r\n\u2014Especially Deep Research, it\u2019s amazing. But I am maybe more skeptical about people\u2019s willingness to go out and pay for something, even if the math is obvious, even if it makes them that much more productive. And meanwhile, I look at this bit where you\u2019re talking about building memory. Part of what made the Google advertising model so brilliant is they didn\u2019t actually need to understand users that much because people typed into the search bar what they were looking for. People are typing a tremendous amount of things into your chatbot. And even if you served the dumbest advertising ever, in many respects, and even if you can\u2019t track conversions, your targeting capability is going to be out of this world. And, by the way, you don\u2019t have an existing business model to worry about undercutting. My sense is this is so counter to what everyone at OpenAI signed up for, that\u2019s the biggest hurdle. But to me, from a business analyst, this seems super obvious and you\u2019re already late.\r\n\r\nSA: The kind of thing I\u2019d be much more excited to try than traditional ads is a lot of people use Deep Research for e-commerce, for example, and is there a way that we could come up with some sort of new model, which is we\u2019re never going to take money to change placement or whatever, but if you buy something through Deep Research that you found, we\u2019re going to charge like a 2% affiliate fee or something. That would be cool, I\u2019d have no problem with that. And maybe there\u2019s a tasteful way we can do ads, but I don\u2019t know. I kind of just don\u2019t like ads that much.\r\n\r\nThat\u2019s always the hang up. Mark Zuckerberg didn\u2019t like ads that much either, but he found someone to do it anyway and \u201cJust don\u2019t tell me about it\u201d. Magically make money appear.\r\n\r\nSA: Yeah. Again, I like our current business model. I\u2019m not going to say what we will and will never do because I don\u2019t know, but I think there\u2019s a lot of interesting ways that are higher on our list of monetization strategies than ads right now.\r\n\r\nDo you think there was a bit, when DeepSeek appeared and sort of exploded and people had access and saw this reasoning, part of that was people who used ChatGPT were less impressed because they used o1, they knew what was possible.\r\n\r\nSA: Yep.\r\n\r\nBut not free users or not people that only dipped in once. Was that actually a place where your reticence maybe made this other product look more impressive?\r\n\r\nSA: Totally. I think DeepSeek was \u2014 they made a great team and they made a great model, but the model capability was, I think, not the thing there that really got them the viral moment. But it was a lesson for us about when we leave a feature hidden, we left chains of thought hidden, we had good reasons for doing it, but it does mean we leave space for somebody else to have a viral moment. And I think in that way it was a good wake-up call. And also, I don\u2019t know, it convinced me to really think differently about what we put in the free tier and now the free tier is going to get GPT-5 and that\u2019s cool.\r\n\r\nOoo, ChatGPT-5 hint. Well, I\u2019ll ask you more about that later.\r\n\r\nWhen you think about your business model, the thing I come back to is your business model is great for high agency people, people who are going to go out and use ChatGPT and they\u2019re going to pay for it because they see the value. How many people are high agency? And also, the high agency people are going to try all the other models, so you\u2019re going to have to stay at a pretty high standard. As opposed to, I have a good model that works and it\u2019s there and I don\u2019t have to pay. And it keeps getting better and people are making more money off me along the way, but I don\u2019t know because I\u2019m fine with ads, which most of the Internet population is.\r\n\r\nSA: Again, open-minded to whatever we need to do, but more excited about things like that commerce example I suggested than kind of traditional ads.\r\n\r\nCompetition\r\nWas there a sense with DeepSeek where you wondered why don\u2019t people cheer for US companies? Did you feel some of the DeepSeek excitement was also sort of anti-OpenAI sentiment?\r\n\r\nSA: I didn\u2019t. Maybe that was, but I certainly didn\u2019t feel that, I think there were two things. One is they put a frontier model in a free tier. And the other is they showed the chain of thought, which is sort of transfixing.\r\n\r\nPeople were like, \u201cOh, it\u2019s so cute. The AI\u2019s trying to help me.\u201d\r\n\r\nSA: Yeah. And I think it was mostly those two things.\r\n\r\nIn your recent proposal about the AI Action Plan, OpenAI expressed concern about companies building on DeepSeek\u2019s models, which are, in one of the phrases about them, \u201cfreely available\u201d. Isn\u2019t the solution, if that\u2019s a real concern, to make your models freely available?\r\n\r\nSA: Yeah, I think we should do that.\r\n\r\nSo when-\r\n\r\nSA: I don\u2019t have a launch to announce, but directionally, I think we should do that.\r\n\r\nYou said before, the one billion destination site is more valuable than the model. Should that flow all the way through to your release strategy and your thoughts about open sourcing?\r\n\r\nSA: Stay tuned.\r\n\r\nOkay, I\u2019ll stay tuned. Fair enough.\r\n\r\nSA: I\u2019m not front-running, but stay tuned.\r\n\r\nI guess the follow-on question to that is is this a chance to actually get back to your original mission? If you go back to the initial statement, DeepSeek and Llama\u2026\r\n\r\nSA: Ben, I\u2019m trying to give you as much of a hint as I can without coming out and saying it. Come on.\r\n\r\n(laughing) Okay, fine. Fair enough. Fair enough. Is there a sense, is this freeing? Right? You go back to that GPT-2 announcement and the concerns about safety and whatever it might be. It seems quaint at this point. Is there a feeling that the cat\u2019s out of the bag? What purpose is served at this point in being sort of precious about these releases?\r\n\r\nSA: I still think there can be big risks in the future. I think it\u2019s fair that we were too conservative in the past. I also think it\u2019s fair to say that we were conservative, but a principle of being a little bit conservative when you don\u2019t know is not a terrible thing. I think it\u2019s also fair to say that at this point, this is going to diffuse everywhere and whether it\u2019s our model that does something bad or somebody else\u2019s model that does something bad, who cares? But I don\u2019t know, I\u2019d still like us to be as responsible an actor as we can be.\r\n\r\nAnother recent competitor is Grok. And I will say from my perspective, I\u2019ve had two, I think interesting psychological experiences with AI over the last year or so. So one is running local models on my Mac. For some reason, I\u2019m just very aware that it\u2019s on my Mac, it\u2019s not running anywhere else, and it\u2019s actually a really kind of a great feeling. And then number two is with Grok, I don\u2019t feel like I\u2019m going to get a scold dropping in at random points in time. And I think, to give you credit, ChatGPT has gotten much better about this over time. But does Grok make you feel like actually yeah, we can go a lot further on this and let users be adults?\r\n\r\nSA: Actually, I think we got better. I think we were really bad about that a while ago, but I think we\u2019ve been better on that for a long-\r\n\r\nI agree. It has gotten better.\r\n\r\nSA: It was one of the things I was most animated about our offering for a long time. And now I kind of like, it doesn\u2019t bother me as a user, I think we\u2019re in a good place. So I used to think about that a lot, but in the last like six or nine months, I haven\u2019t.\r\n\r\nHallucinations and Regulation\r\nIs there a bit where isn\u2019t hallucination good? You released a sample of a writing model, and it sort of tied into one of my longstanding takes that everyone is working really hard to make these probabilistic models behave like deterministic computing, and almost missing the magic, which is they\u2019re actually making stuff up. That\u2019s actually pretty incredible.\r\n\r\nSA: 100%. If you want something deterministic, you should use a database. The cool thing here is that it can be creative and sometimes it doesn\u2019t create quite the thing you wanted. And that\u2019s okay, you click it again.\r\n\r\nIs that an AI lab problem that they\u2019re trying to do this? Or is that a user expectation problem? How can we get everyone to love hallucinations?\r\n\r\nSA: Well, you want it to hallucinate when you want and not hallucinate when you don\u2019t want. If you\u2019re asking, \u201cTell me this fact about science,\u201d you\u2019d like that not to be a hallucination. If you\u2019re like, \u201cWrite me a creative story,\u201d you want some hallucination. And I think the problem, the interesting problem is how do you get models to hallucinate only when it benefits the user?\r\n\r\nHow much of a problem do you see when, these prompts are exfiltrated, they\u2019ll say things like, \u201cDon\u2019t reveal this,\u201d or, \u201cDon\u2019t say this,\u201d or, \u201cDon\u2019t do X, Y, Z.\u201d If we\u2019re worried about safety and alignment, isn\u2019t teaching AIs to lie a very big problem?\r\n\r\nSA: Yeah. I remember when xAI was really getting dunked on because in the system prompt, it said something about don\u2019t say bad things about Elon Musk or whatever. And that was embarrassing for them, but I felt a little bit bad because, the model is just trying to follow the instructions that is given to it.\r\n\r\nRight. It\u2019s very earnest.\r\n\r\nSA: Very earnest. Yeah. So yes, it was a stupid thing to do, of course, and embarrassing, of course, but I don\u2019t think it was the meltdown that was represented.\r\n\r\nI think some skeptics, including me, have framed some aspects of your calls for regulation as an attempt to pull up the ladder on would-be competitors. I\u2019d ask a two-part question. Number one, is that unfair? And if the AI Action Plan did nothing other than institute a ban on state level AI restrictions and declare that training on copyright materials fair use, would that be sufficient?\r\n\r\nSA: First of all, most of the regulation that we\u2019ve ever called for has been just say on the very frontier models, whatever is the leading edge in the world, have some standard of safety testing for those models. Now, I think that\u2019s good policy, but I sort of increasingly think the world, most of the world does not think that\u2019s good policy, and I\u2019m worried about regulatory capture. So obviously, I have my own beliefs, but it doesn\u2019t look to me like we\u2019re going to get that as policy in the world and I think that\u2019s a little bit scary, but hopefully, we\u2019ll find our way through as best as we can and probably it\u2019ll be fine. Not that many people want to destroy the world.\r\n\r\nBut for sure, you don\u2019t want to go put regulatory burden on the entire tech industry. Like we were calling for something that would have hit us and Google and a tiny number of other people. And again, I don\u2019t think the world\u2019s going to go that way and we\u2019ll play on the field in front of us. But yes, I think saying that fair use is fair use and that states are not going to have this crazy complex set of differing regulations, those would be very, very good.\r\n\r\nYou are supporting export controls or by you, I mean, OpenAI in this policy paper. You talked about the whole stack, that triumvirate. Do you worry about a world where the US is dependent on Taiwan and China is not?\r\n\r\nSA: I am worried about the Taiwan dependency, yes.\r\n\r\nIs there anything that OpenAI can do? Would you make a commitment to buy Intel produced chips, for example, if they have a new CEO is going to refocus on AI? Can OpenAI help with that?\r\n\r\nSA: I have thought a lot about what we can do here for the infrastructure layer and supply chain in general. I do not have a great idea yet. If you have any, I\u2019d be all ears, but I would like to do something.\r\n\r\nOkay, sure. Intel needs a customer. That\u2019s what they need more than anything, a customer that is not Intel. Get OpenAI, become the leading customer for the Gaudi architecture, commit to buying a gazillion chips and that will help them. That will pull them through. There\u2019s your answer.\r\n\r\nSA: If we were making a chip with a partner that was working with Intel and a process that was compatible and we had, I think, a sufficiently high belief in their ability to deliver, we could do something like that. Again, I want to do something. So I\u2019m not trying to dodge.\r\n\r\nNo, I\u2019m being unfair too because I just told you you need to focus on building your consumer business and cut off the API. Getting into sustaining US chip production is being very unfair.\r\n\r\nSA: No, no, no, I don\u2019t think it\u2019s unfair. I think we have, if we can do something to help, I think we have some obligation to do it, but we\u2019re trying to figure out what that is.\r\n\r\nThe AI Outlook\r\nSo Dario and Kevin Weil, I think, have both said or in various aspects that 99% of code authorship will be automated by sort of end of the year, a very fast timeframe. What do you think that fraction is today? When do you think we\u2019ll pass 50% or have we already?\r\n\r\nSA: I think in many companies, it\u2019s probably past 50% now. But the big thing I think will come with agentic coding, which no one\u2019s doing for real yet.\r\n\r\nWhat\u2019s the hangup there?\r\n\r\nSA: Oh, we just need a little longer.\r\n\r\nIs it a product problem or is it a model problem?\r\n\r\nSA: Model problem.\r\n\r\nShould you still be hiring software engineers? I think you have a lot of job listings.\r\n\r\nSA: I mean, my basic assumption is that each software engineer will just do much, much more for a while. And then at some point, yeah, maybe we do need less software engineers.\r\n\r\nBy the way, I think you should be hiring more software engineers. I think that\u2019s part and parcel of my case here is I think you need to be moving even faster. But you mentioned GPT-5. I don\u2019t know where it is, we\u2019ve been expecting it for a long time now.\r\n\r\nSA: We only got 4.5 two weeks ago.\r\n\r\nI know, but we\u2019re greedy.\r\n\r\nSA: That\u2019s fine. You don\u2019t have to wait. The new one won\u2019t be super long.\r\n\r\nWhat is AGI? And there\u2019s a lot of definitions from you. There\u2019s a lot of definitions in OpenAI. What is your current, what\u2019s the state-of-the-art definition of AGI?\r\n\r\nSA: I think what you just said is the key point, which is it\u2019s a fuzzy boundary of a lot of stuff and it\u2019s a term that I think has become almost completely devalued. Some people, by many people\u2019s definition, we\u2019d be there already, particularly if you could go like transport someone from 2020 to 2025 and show them what we\u2019ve got.\r\n\r\nWell, this was AI for many, many years. AI was always what we couldn\u2019t do. As soon as we could do it, it\u2019s machine learning. And as soon as you didn\u2019t notice it, it was an algorithm.\r\n\r\nSA: Right. I think for a lot of people, it\u2019s something about like a fraction of the economic value. For a lot of people, it\u2019s something about a general purpose thing. I think they can do a lot of things really well. For some people, it\u2019s about something that doesn\u2019t make any silly mistakes. For some people, it\u2019s about something that\u2019s capable of self-improvement, all those things. It\u2019s just there\u2019s not good alignment there.\r\n\r\nWhat about an agent? What is an agent?\r\n\r\nSA: Something that can like go autonomously, do a real chunk of work for you.\r\n\r\nTo me, that\u2019s the AGI thing. That is employee replacement level.\r\n\r\nSA: But what if it\u2019s only good at like some class of tasks and can\u2019t do others? I mean, some employees are like that too.\r\n\r\nYeah, I was thinking about this because this is a total redefinition where AGI was supposed to be everything, but now we have ASI. ASI, a super intelligence. To me, that is a nomenclature problem. ASI, yes, can do any job we give it to. If I get an AI that does one specific job, coding or whatever it might be, and it consistently does, I can give it a goal and it accomplishes the goal by figuring out the intervening steps. To me, that is a clear paradigm shift from where we\u2019re at right now where you do have to guide it to a significant extent.\r\n\r\nSA: If we have a great autonomous coding agent, will you be like, \u201cOpenAI did it, they made AGI\u201d?\r\n\r\nYes. That\u2019s how I\u2019ve come to define it. And I agree that\u2019s almost a whole lessening of what AGI used to mean. But I just substitute ASI for AGI.\r\n\r\nSA: Do we get a little like Ben Thompson gold star for our wall?\r\n\r\n(laughing) Sure, there you go. I\u2019ll give you my circuit pen.\r\n\r\nSA: Great.\r\n\r\nYou and the folks in these labs talk about what you\u2019re seeing and how no one is ready and there\u2019s all these sort of tweets that float around and get people worked up and you dropped a couple hints on this podcast. Very exciting. However, you\u2019ve been talking about this for like quite a while now. Have your releases, you look at the world which, in some respects, still looks the same? Have your releases been less than you expected or have you been surprised by the capacity of humans to absorb change?\r\n\r\nSA: Very much the last. I think there have been a few moments where we\u2019ve done something that has really had the world melt down and be like, \u201cWhat the\u2026this is like totally crazy.\u201d And then two weeks later, everyone\u2019s like, \u201cWhere\u2019s the next version?\u201d\r\n\r\nWell, I mean, you also did this with your initial strategy because ChatGPT blew everyone\u2019s mind. Then ChatGPT-4 comes out not long afterwards and they\u2019re like, \u201cOh my word. What\u2019s the pace that we\u2019re on here?\u201d\r\n\r\nSA: think we\u2019ve put out some incredible stuff and I think it\u2019s actually a great thing about humanity that people adapt and just want more and better and faster and cheaper. So I think we have overdelivered and people have just updated.\r\n\r\nGiven that, does that make you more optimistic, less optimistic? Do you see this bifurcation that I think there\u2019s going to be between agentic people? This is a different agentic word, but see where we\u2019re going. We need to invent more words here. We\u2019ll ask ChatGPT to hallucinate one for us. People who will go and use the API and the whole Microsoft Copilot idea is you have someone accompanying you and it\u2019s a lot of high talk, \u201cOh, it\u2019s not going to replace jobs, it\u2019s going to make people more productive\u201d. And I agree that will happen for some people who go out to use it. But you look back, say, at PC history. The first wave of PCs were people who really wanted to use PCs. PCs, a lot of people didn\u2019t. They had one put on their desk and they had to use it for a specific task. And really, you needed a generational change for people to just default to using that. Is AI, is that the real limiting factor here?\r\n\r\nSA: Maybe, but that\u2019s okay. Like as you mentioned, that\u2019s kind of standard for other tech evolutions.\r\n\r\nBut you go back to the PC example, actually, the first wave of IT was like the mainframe, wiped out whole back rooms. And because actually, it turned out the first wave is the job replacement wave because it\u2019s just easier to do a top-down implementation.\r\n\r\nSA: My instinct is this one doesn\u2019t quite go like that, but I think it\u2019s always like super hard to predict.\r\n\r\nWhat\u2019s your instinct?\r\n\r\nSA: That it kind of just seeps through the economy and mostly kind of like eats things little by little and then faster and faster.\r\n\r\nYou talk a lot about scientific breakthroughs as a reason to invest in AI, Dwarkesh Patel recently raised the point that there haven\u2019t been any yet. Why not? Can AI actually create or discover something new? Are we over-indexing on models that just aren\u2019t that good and that\u2019s the real issue?\r\n\r\nSA: Yeah, I think the models just aren\u2019t smart enough yet. I don\u2019t know. You hear people with Deep Research say like, \u201cOkay, the model is not independently discovering new science, but it is helping me discover new science much faster.\u201d And that, to me, is like pretty much as good.\r\n\r\nDo you think a transformer-based architecture can ever truly create new things or is it just spitting out the median level of the Internet?\r\n\r\nSA: Yes.\r\n\r\nWell, what\u2019s going to be the breakthrough there?\r\n\r\nSA: I mean, I think we\u2019re on the path. I think we just need to keep doing our thing. I think we\u2019re like on the path.\r\n\r\nI mean, is this the ultimate test of God?\r\n\r\nSA: How so?\r\n\r\nDo humans have innate creativity or is it just recombining knowledge in different sorts of ways?\r\n\r\nSA: One of my favorite books is The Beginning of Infinity by David Deutsch, and early on in that book, there\u2019s a beautiful few pages about how creativity is just taking something you saw before and modifying it a little bit. And then if something good comes out of it, someone else modifies it a little bit and someone else modifies it a little bit. And I can sort of believe that. And if that\u2019s the case, then AI is good at modifying things a little bit.\r\n\r\nTo what extent is the view that you could believe that grounded in your long-standing beliefs versus what you\u2019ve observed, because I think this is a very interesting \u2014 not to get all sort of high-level metaphysical or feel, like I said, theological almost \u2014 but there does seem to be a bit where one\u2019s base assumptions fuel one\u2019s assumptions about AI\u2019s possibilities. And then, most of Silicon Valley is materialistic, atheistic, however you want to put it. And so of course, we\u2019ll figure it out, it\u2019s just a biological function, we can recreate it in computers. If it turns out we never actually do create new things, but we augment humans creating new things, would that change your core belief system?\r\n\r\nSA: It\u2019s definitely part of my core belief system from before. None of this is anything new, but no, I would assume we just didn\u2019t figure out the right AI architecture yet and at some point, we will.\r\n\r\nFinal question is on behalf of my daughter, she is graduating from high school this year. What career advice do you have for a graduating senior from high school?\r\n\r\nSA: The obvious tactical thing is just get really good at using AI tools. Like when I was graduating as a senior from high school, the obvious tactical thing was get really good at coding. And this is the new version of that.\r\n\r\nThe more general one is I think people can cultivate resilience and adaptability and also things like figuring out what other people want and how to be useful for people. And I would go practice that. Like whatever you study, the details of it maybe don\u2019t matter that much. Maybe they never did. It\u2019s like the valuable thing I learned in school is the meta ability to learn, not any specific thing I learned. And so whatever specific thing you\u2019re going to learn, like learn these general skills that seem like they\u2019re going to be important as the world goes through this transition.\r\n\r\nSam, it\u2019s good to talk to you. I think the last time we really talked was actually, just to be total douchebags, at Davos, I can\u2019t even pronounce it. Of course, everyone was wanting to talk to you. You were the rock star that was there. You feigned \u2014 I interpreted it as feigning a surprise that, \u201cOh, why do people care about little old me?\u201d I guess I have to ask you, were you feigning or how does it feel to be the biggest name in tech?\r\n\r\nSA: I had never been to Davos. That was like a one-time thing for me.\r\n\r\n(laughing) Me too.\r\n\r\nSA: Quite miserable experience. But that was a weird experience of feeling like a genuine celebrity, and my takeaway was that says much more about the people that go to Davos than it says about me. But I did not enjoy it there. It is weird to go from being relatively unknown to quite well known in tech in a couple of years.\r\n\r\nQuite well known in the world.\r\n\r\nSA: When I\u2019m in SF, I feel like very observed. And if I\u2019m in some other city, I kind of get left alone.\r\n\r\nOh, you just explained why I don\u2019t want to live in SF. I mean, I\u2019m at a much smaller scale than you.\r\n\r\nSA: Yeah. But it has been a strange and not always super fun experience.\r\n\r\nSam Altman, good to talk. Hope to talk again soon.\r\n\r\nSA: You too. Thank you."]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"serialization_metadata":{"custom_symbol_offsets":[]},"dictation":false,"request_id":"92785c80fde08209-SIN","message_source":null,"timestamp_":"absolute","message_type":null,"can_save":true},"recipient":"all","channel":null},"parent":"aab46b47-ec70-4da8-8654-746b33ed88a0","children":["9639bb61-3926-4468-9d6b-6c33c9251ec5"]},"9639bb61-3926-4468-9d6b-6c33c9251ec5":{"id":"9639bb61-3926-4468-9d6b-6c33c9251ec5","message":{"id":"9639bb61-3926-4468-9d6b-6c33c9251ec5","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1743177858.478431,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"message_type":null,"model_slug":"gpt-4o","default_model_slug":"gpt-4o","parent_id":"3f754d9b-abb0-4dd2-959b-e1104d88d6b8","request_id":"92785c80fde08209-SIN","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"3f754d9b-abb0-4dd2-959b-e1104d88d6b8","children":["798ce78d-e005-405a-9574-42cb66627a3b"]},"798ce78d-e005-405a-9574-42cb66627a3b":{"id":"798ce78d-e005-405a-9574-42cb66627a3b","message":{"id":"798ce78d-e005-405a-9574-42cb66627a3b","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1743177846.642259,"update_time":null,"content":{"content_type":"text","parts":["User is interested in high-level summaries and strategic insights from tech leadership interviews, particularly regarding AI and major AI companies like OpenAI."]},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200007]},"is_complete":true,"citations":[],"content_references":[],"message_type":null,"model_slug":"gpt-4o","default_model_slug":"gpt-4o","parent_id":"9639bb61-3926-4468-9d6b-6c33c9251ec5","request_id":"92785c80fde08209-SIN","timestamp_":"absolute","can_save":true},"recipient":"bio","channel":null},"parent":"9639bb61-3926-4468-9d6b-6c33c9251ec5","children":["4d3829e0-fa01-4806-8a4f-1f6aa73eae3d"]},"4d3829e0-fa01-4806-8a4f-1f6aa73eae3d":{"id":"4d3829e0-fa01-4806-8a4f-1f6aa73eae3d","message":{"id":"4d3829e0-fa01-4806-8a4f-1f6aa73eae3d","author":{"role":"tool","name":"bio","metadata":{}},"create_time":1743177858.47881,"update_time":null,"content":{"content_type":"text","parts":["Model set context updated."]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"message_type":null,"model_slug":"gpt-4o","default_model_slug":"gpt-4o","parent_id":"798ce78d-e005-405a-9574-42cb66627a3b","request_id":"92785c80fde08209-SIN","timestamp_":"absolute","can_save":true},"recipient":"assistant","channel":null},"parent":"798ce78d-e005-405a-9574-42cb66627a3b","children":["3e9112f3-3cfa-4d2a-ae70-441221926f37"]},"3e9112f3-3cfa-4d2a-ae70-441221926f37":{"id":"3e9112f3-3cfa-4d2a-ae70-441221926f37","message":{"id":"3e9112f3-3cfa-4d2a-ae70-441221926f37","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1743177850.095842,"update_time":null,"content":{"content_type":"text","parts":["Here\u2019s a **precise and comprehensive synopsis** of the March 20, 2025 Stratechery interview with **Sam Altman**, CEO of **OpenAI**, touching on the **main points**, **hot takes**, and **noteworthy insights** from a business, strategy, and AI development perspective:\n\n---\n\n## \ud83d\udd11 MAIN THEMES\n\n### 1. **Altman\u2019s Trajectory & OpenAI\u2019s Founding**\n- **Early life**: Classic \"nerd\" archetype\u2014math, science, sci-fi, and computers from childhood.\n- **Loopt**: First startup, ultimately an acquihire\u2014not a commercial success.\n- **Y Combinator**: Joined post-Loopt, eventually became its president; used YC\u2019s influence to push for \u201chard tech\u201d (fusion, biotech, AGI).\n- **OpenAI origin**: Born from a belief that building safe AGI would be the most impactful thing one could do. It started as one of six YC Research projects with no business model, no product plan\u2014purely a research lab.\n\n---\n\n### 2. **OpenAI\u2019s Shift from Research Lab to Consumer Tech Juggernaut**\n- **ChatGPT\u2019s launch (Nov 2022)**: Accidental viral hit, meant to be a research preview using GPT-3.5 before GPT-4 was ready. Internally viewed as underwhelming compared to GPT-4, but the market went wild.\n- **Inflection point**: From API-focused dev platform to full-scale consumer product company. Many OpenAI employees weren\u2019t prepared for this pivot.\n- Altman: \u201cI signed up to run an AGI lab, not a consumer internet company.\u201d\n\n---\n\n### 3. **The Microsoft Relationship**\n- Microsoft\u2019s 2019 investment enabled scaling, but neither party anticipated OpenAI becoming a direct consumer tech company.\n- While still friendly, Altman hinted at underlying friction, since both now compete in the consumer AI space.\n\n---\n\n### 4. **Strategic Vision Going Forward**\n- **Product Strategy**: Build a bundle of 3\u20134 core multi-billion-user products (ChatGPT is the first), with unified OpenAI identity/memory across them.\n- **Platform Play**: OpenAI sign-in will power third-party apps. Think \u201cSign in with OpenAI\u201d but with memory and context following the user.\n- **Three Pillars of AI Value Creation**:\n  1. **Product moat** (owning the user)\n  2. **Infrastructure moat** (cheap inference at scale: chips, datacenters, energy)\n  3. **Model moat** (state-of-the-art research)\n\n---\n\n## \ud83d\udca5 HOT TAKES & STRATEGIC BOMBSHELLS\n\n### \ud83e\udde0 AGI Reframed:\n- Altman no longer sees AGI as a monolithic \u201cgodlike\u201d intelligence. For him now, an agentic AI that can autonomously complete a complex task (like software engineering) may qualify.\n- \u201cBy some definitions, we already have AGI.\u201d\n\n### \ud83d\udcac Advertising?\n- Altman: *\u201cI kind of just don\u2019t like ads.\u201d* \n- Not ruling it out\u2014but skeptical. Prefers affiliate-based monetization (e.g., 2% fee on commerce via Deep Research).\n- Strategically, he's resisting ad-based monetization **despite having one of the best ad-targeting datasets in history**.\n\n### \ud83c\udd93 Open Source?\n- Strong hints that **OpenAI will release open models soon**, possibly as a response to competition from DeepSeek and Meta (LLaMA).\n- Acknowledges past over-conservatism: \u201cWe were too cautious with GPT-2.\u201d\n\n### \ud83d\udca5 GPT-5 and ChatGPT:\n- GPT-5 will be in the free tier, possibly marking a pivot to regain perception leadership after competitors impressed with \u201ctransparent\u201d features.\n- Altman hinted at ChatGPT Pro getting even more capable agents soon.\n\n---\n\n## \ud83e\udd16 AI Ecosystem & Competitive Landscape\n\n### \ud83e\uddd1\u200d\ud83d\udcbb Coding agents\n- Predicts **agentic software engineering tools** will take off in the next year or two. These will be key value-drivers.\n- Coding already >50% AI-assisted in many companies.\n\n### \ud83c\udf0d AI commoditization\n- Agrees with Satya Nadella: **\u201cModels will commoditize\u201d**.\n- Future differentiation lies in user relationships and infrastructure\u2014not the models themselves.\n\n### \ud83c\udde8\ud83c\uddf3 DeepSeek & Open Model Competition\n- DeepSeek's virality partly due to being free and showing \u201cchain of thought\u201d reasoning.\n- Altman admits OpenAI was too hesitant to expose similar capabilities, losing a moment.\n\n---\n\n## \ud83e\udde9 Governance & Regulation\n\n- Altman supports minimal, targeted regulation at the *frontier model* level only\u2014not for general AI development.\n- Strong advocate for **federal override of state-level AI regulation** and **fair use for training data**.\n- Concerned about U.S. dependency on Taiwan for chips; open to supporting U.S. efforts like Intel's AI chip ambitions.\n\n---\n\n## \ud83e\uddd8 Philosophy, AI Purpose & Final Notes\n\n- Altman is ultimately a techno-optimist: believes AI will enhance humanity, though it may be \u201cjust modifying prior ideas\u201d rather than discovering truly novel concepts.\n- **Belief system**: creativity is emergent and recombinatory\u2014thus replicable by AI.\n- For the next generation: learn how to use AI deeply; adaptability > specific domain expertise.\n\n---\n\n## \ud83e\udded FORWARD-LOOKING TAKEAWAYS\n\n1. **OpenAI is becoming the next Facebook-level consumer tech giant**, but this wasn\u2019t intentional\u2014it was a pivot made under pressure.\n2. **AGI as a term is dead**\u2014we\u2019re heading toward \u201cspecialist AGIs\u201d (agents) with tight vertical functionality.\n3. **Infrastructure and user identity are the real moats**, not models.\n4. **Expect open-source models soon**, and more \"agents\" in GPT Pro.\n5. **The ad question remains**\u2014but a form of commerce integration or affiliate model seems likely.\n6. **Silicon Valley skepticism about regulation is growing**, even among initial advocates like Altman.\n\n---\n\nLet me know if you'd like a separate bullet-pointed table of the competitive landscape, a summary of strategic tensions (e.g. between research vs product), or insights from a business model pivot lens."]},"status":"finished_successfully","end_turn":true,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200002]},"is_complete":true,"citations":[],"content_references":[],"message_type":null,"model_slug":"gpt-4o","default_model_slug":"gpt-4o","parent_id":"4d3829e0-fa01-4806-8a4f-1f6aa73eae3d","request_id":"92785c80fde08209-SIN","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"4d3829e0-fa01-4806-8a4f-1f6aa73eae3d","children":[]}}}