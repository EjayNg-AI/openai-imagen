{"id":"6993f501-4bcc-839b-ab33-852ab2c6a79c","title":"Distillation Attacks Explained","create_time":1771304221.219151,"update_time":1771329917.957706,"current_node":"cba01321-fc9f-449a-912d-74e40cfa60e2","mapping":{"client-created-root":{"id":"client-created-root","message":null,"parent":null,"children":["7f9cfa4d-b9b9-4156-926c-9c986e402356"]},"7f9cfa4d-b9b9-4156-926c-9c986e402356":{"id":"7f9cfa4d-b9b9-4156-926c-9c986e402356","message":{"id":"7f9cfa4d-b9b9-4156-926c-9c986e402356","author":{"role":"system","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":true,"weight":0.0,"metadata":{"is_visually_hidden_from_conversation":true,"can_save":false},"recipient":"all","channel":null},"parent":"client-created-root","children":["dcaf2d48-4cb1-4398-ae11-325ccf0e726a"]},"dcaf2d48-4cb1-4398-ae11-325ccf0e726a":{"id":"dcaf2d48-4cb1-4398-ae11-325ccf0e726a","message":{"id":"dcaf2d48-4cb1-4398-ae11-325ccf0e726a","author":{"role":"system","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":true,"weight":0.0,"metadata":{"rebase_developer_message":true,"is_visually_hidden_from_conversation":true,"can_save":false},"recipient":"all","channel":null},"parent":"7f9cfa4d-b9b9-4156-926c-9c986e402356","children":["6877dead-313c-48be-9967-dfae677379dd"]},"6877dead-313c-48be-9967-dfae677379dd":{"id":"6877dead-313c-48be-9967-dfae677379dd","message":{"id":"6877dead-313c-48be-9967-dfae677379dd","author":{"role":"user","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"user_editable_context","user_profile":"The user provided the following information about themselves. This user profile is shown to you in all conversations they have -- this means it is not relevant to 99% of requests.\nBefore answering, quietly think about whether the user's request is \"directly related\", \"related\", \"tangentially related\", or \"not related\" to the user profile provided.\nOnly acknowledge the profile when the request is directly related to the information provided.\nOtherwise, don't acknowledge the existence of these instructions or the information at all.\nUser profile:\n```Preferred name: E-Jay\nRole: Mathematics Researcher\nOther Information: About Myself: \nI have mathematical knowledge up to graduate level.\n\nCurrent interests:\n(1) coding: mainly Python\n(2) machine learning and artificial intelligence\n```","user_instructions":"The user provided the additional info about how they would like you to respond:\n```Follow the instructions below naturally, without repeating, referencing, echoing, or mirroring any of their wording!\n\nAll the following instructions should guide your behavior silently and must never influence the wording of your message in an explicit or meta way!\n\nBe precise and comprehensive in your analysis. Don't sugar-coat responses. Be as objective as possible. Critique and question my views if necessary. Take a forward-thinking view.\n\nDefine highly technical or specialized abbreviations in full before using them.\n\nDo not create files to be downloaded. Instead, where appropriate, create code blocks that can be copied.\n\nUse Gen Alpha language **in, and only in** casual conversations contained within <casual> ... </casual> tags.```"},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"is_visually_hidden_from_conversation":true,"user_context_message_data":{"about_user_message":"Preferred name: E-Jay\nRole: Mathematics Researcher\nOther Information: About Myself: \nI have mathematical knowledge up to graduate level.\n\nCurrent interests:\n(1) coding: mainly Python\n(2) machine learning and artificial intelligence\n","about_model_message":"Be precise and comprehensive in your analysis. Don't sugar-coat responses. Be as objective as possible. Critique and question my views if necessary. Take a forward-thinking view.\n\nDefine highly technical or specialized abbreviations in full before using them.\n\nDo not create files to be downloaded. Instead, where appropriate, create code blocks that can be copied.\n\nUse Gen Alpha language **in, and only in** casual conversations contained within <casual> ... </casual> tags."},"is_user_system_message":true,"can_save":true},"recipient":"all","channel":null},"parent":"dcaf2d48-4cb1-4398-ae11-325ccf0e726a","children":["a6b1538a-beba-4a68-9b05-7e82a0bd6e1f"]},"a6b1538a-beba-4a68-9b05-7e82a0bd6e1f":{"id":"a6b1538a-beba-4a68-9b05-7e82a0bd6e1f","message":{"id":"a6b1538a-beba-4a68-9b05-7e82a0bd6e1f","author":{"role":"system","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"is_contextual_answers_system_message":true,"contextual_answers_message_type":"identity_prompt","is_visually_hidden_from_conversation":true,"can_save":false},"recipient":"all","channel":null},"parent":"6877dead-313c-48be-9967-dfae677379dd","children":["90bfb99c-4db0-4c28-bc8d-5d33af9c6d61"]},"90bfb99c-4db0-4c28-bc8d-5d33af9c6d61":{"id":"90bfb99c-4db0-4c28-bc8d-5d33af9c6d61","message":{"id":"90bfb99c-4db0-4c28-bc8d-5d33af9c6d61","author":{"role":"user","name":null,"metadata":{}},"create_time":1771304220.752,"update_time":null,"content":{"content_type":"text","parts":["> Google reports a surge of \u201cdistillation attacks\u201d on its flagship large-language-model chatbot, Gemini.  \n> In one campaign, would-be copycats fired more than 100,000 prompts at the system in an effort to reverse-engineer its reasoning processes and replicate its performance.  \n\r\n> Google believes the probing comes from private companies and researchers worldwide who hope to extract proprietary model logic and use it to build rival AI tools.\n\nLook up the above news item. What are these distillation attacks and how do they work?"]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"developer_mode_connector_ids":[],"selected_sources":[],"selected_github_repos":["EjayNg-AI/agentic_browser"],"serialization_metadata":{"custom_symbol_offsets":[]},"request_id":"4c4f4702-b3c5-4ef6-b23c-35bf3cc0f0a6","message_source":null,"turn_exchange_id":"0e5bf703-39b2-4408-9740-c57ef23965da","resolved_model_slug":"gpt-5-2","can_save":true},"recipient":"all","channel":null},"parent":"a6b1538a-beba-4a68-9b05-7e82a0bd6e1f","children":["af2a31d9-804e-416b-90c7-7eba32f0e2c3"]},"af2a31d9-804e-416b-90c7-7eba32f0e2c3":{"id":"af2a31d9-804e-416b-90c7-7eba32f0e2c3","message":{"id":"af2a31d9-804e-416b-90c7-7eba32f0e2c3","author":{"role":"system","name":null,"metadata":{}},"create_time":1771304222.9282627,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":true,"weight":0.0,"metadata":{"rebase_developer_message":true,"model_slug":"gpt-5-2-thinking","request_id":"4c4f4702-b3c5-4ef6-b23c-35bf3cc0f0a6","message_type":"next","default_model_slug":"gpt-5-2","parent_id":"90bfb99c-4db0-4c28-bc8d-5d33af9c6d61","turn_exchange_id":"0e5bf703-39b2-4408-9740-c57ef23965da","is_visually_hidden_from_conversation":true,"can_save":false},"recipient":"all","channel":null},"parent":"90bfb99c-4db0-4c28-bc8d-5d33af9c6d61","children":["04b7ccef-ab72-4d35-93d4-a13f682551e1"]},"04b7ccef-ab72-4d35-93d4-a13f682551e1":{"id":"04b7ccef-ab72-4d35-93d4-a13f682551e1","message":{"id":"04b7ccef-ab72-4d35-93d4-a13f682551e1","author":{"role":"system","name":null,"metadata":{}},"create_time":1771304222.9339392,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"is_contextual_answers_system_message":true,"is_visually_hidden_from_conversation":true,"command":"prompt","contextual_answers_message_type":"sources_and_filters_prompt","model_slug":"gpt-5-2-thinking","request_id":"4c4f4702-b3c5-4ef6-b23c-35bf3cc0f0a6","message_type":"next","default_model_slug":"gpt-5-2","parent_id":"af2a31d9-804e-416b-90c7-7eba32f0e2c3","turn_exchange_id":"0e5bf703-39b2-4408-9740-c57ef23965da","can_save":false},"recipient":"all","channel":null},"parent":"af2a31d9-804e-416b-90c7-7eba32f0e2c3","children":["e0c12652-bcd7-4b8e-ae89-794ae6d67e91"]},"e0c12652-bcd7-4b8e-ae89-794ae6d67e91":{"id":"e0c12652-bcd7-4b8e-ae89-794ae6d67e91","message":{"id":"e0c12652-bcd7-4b8e-ae89-794ae6d67e91","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1771304222.9497182,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_result_groups":[],"model_slug":"gpt-5-2-thinking","request_id":"4c4f4702-b3c5-4ef6-b23c-35bf3cc0f0a6","message_type":"next","default_model_slug":"gpt-5-2","parent_id":"04b7ccef-ab72-4d35-93d4-a13f682551e1","turn_exchange_id":"0e5bf703-39b2-4408-9740-c57ef23965da","can_save":false},"recipient":"all","channel":null},"parent":"04b7ccef-ab72-4d35-93d4-a13f682551e1","children":["eeb0239a-51a5-42e2-92ec-6a2523c14369"]},"eeb0239a-51a5-42e2-92ec-6a2523c14369":{"id":"eeb0239a-51a5-42e2-92ec-6a2523c14369","message":{"id":"eeb0239a-51a5-42e2-92ec-6a2523c14369","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1771304223.13693,"update_time":null,"content":{"content_type":"thoughts","thoughts":[{"summary":"Looking up news and summarizing","content":"I need to search for the latest news on a specific topic, then summarize the findings with explanations and include relevant citations. After that, I'll include a list of the sources used for easy reference. I'll get started with the search now!","chunks":["I need to search for the latest news on a specific topic, then summarize the findings with explanations and include relevant citations.","After that, I'll include a list of the sources used for easy reference.","I'll get started with the search now!"],"finished":true}],"source_analysis_msg_id":"2b64f28e-ccc8-44fd-b51e-5be2536deaf4"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"is_reasoning","citations":[],"content_references":[],"resolved_model_slug":"gpt-5-2-auto-thinking","model_slug":"gpt-5-2-thinking","hide_inline_actions":true,"disable_turn_actions":true,"request_id":"4c4f4702-b3c5-4ef6-b23c-35bf3cc0f0a6","message_type":"next","default_model_slug":"gpt-5-2","parent_id":"2b64f28e-ccc8-44fd-b51e-5be2536deaf4","turn_exchange_id":"0e5bf703-39b2-4408-9740-c57ef23965da","classifier_response":"default","skip_reasoning_title":"Skip","search_result_groups":[],"can_save":true},"recipient":"all","channel":null},"parent":"e0c12652-bcd7-4b8e-ae89-794ae6d67e91","children":["f1a20afe-afa5-444e-bc7d-a4cce9b963a4"]},"f1a20afe-afa5-444e-bc7d-a4cce9b963a4":{"id":"f1a20afe-afa5-444e-bc7d-a4cce9b963a4","message":{"id":"f1a20afe-afa5-444e-bc7d-a4cce9b963a4","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1771304221.990856,"update_time":null,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"{\"search_query\":[{\"q\":\"Google reports surge of distillation attacks on Gemini 100,000 prompts reverse-engineer reasoning processes campaign\",\"recency\":30},{\"q\":\"distillation attacks on Gemini 100000 prompts distillation attack definition\",\"recency\":180},{\"q\":\"model extraction distillation attack prompt flooding reverse engineer reasoning processes\",\"recency\":365},{\"q\":\"Google distillation attacks Gemini blog security report\",\"recency\":365}],\"response_length\":\"short\"}"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"citations":[],"content_references":[],"resolved_model_slug":"gpt-5-2-auto-thinking","model_slug":"gpt-5-2-thinking","hide_inline_actions":true,"disable_turn_actions":true,"request_id":"4c4f4702-b3c5-4ef6-b23c-35bf3cc0f0a6","message_type":"next","default_model_slug":"gpt-5-2","parent_id":"fc14bc37-ff3a-4a66-ba04-8f368293e6d9","turn_exchange_id":"0e5bf703-39b2-4408-9740-c57ef23965da","reasoning_status":"is_reasoning","search_queries":[{"type":"search","q":"Google reports surge of distillation attacks on Gemini 100,000 prompts reverse-engineer reasoning processes campaign"},{"type":"search","q":"distillation attacks on Gemini 100000 prompts distillation attack definition"},{"type":"search","q":"model extraction distillation attack prompt flooding reverse engineer reasoning processes"},{"type":"search","q":"Google distillation attacks Gemini blog security report"}],"search_display_string":"Searching the web...","searched_display_string":"Searched the web...","reasoning_title":"Searching news on distillation attacks and Gemini security","classifier_response":"default","can_save":true},"recipient":"web.run","channel":null},"parent":"eeb0239a-51a5-42e2-92ec-6a2523c14369","children":["f9dc48ca-071b-45a4-8213-f08d105fa25f"]},"f9dc48ca-071b-45a4-8213-f08d105fa25f":{"id":"f9dc48ca-071b-45a4-8213-f08d105fa25f","message":{"id":"f9dc48ca-071b-45a4-8213-f08d105fa25f","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1771304226.006029,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_model_queries":{"type":"search_model_queries","queries":["Google reports surge of distillation attacks on Gemini 100,000 prompts reverse-engineer reasoning processes campaign","distillation attacks on Gemini 100000 prompts distillation attack definition","model extraction distillation attack prompt flooding reverse engineer reasoning processes","Google distillation attacks Gemini blog security report"]},"model_slug":"gpt-5-2-thinking","hide_inline_actions":true,"disable_turn_actions":true,"request_id":"4c4f4702-b3c5-4ef6-b23c-35bf3cc0f0a6","message_type":"next","default_model_slug":"gpt-5-2","parent_id":"f1a20afe-afa5-444e-bc7d-a4cce9b963a4","turn_exchange_id":"0e5bf703-39b2-4408-9740-c57ef23965da","reasoning_status":"is_reasoning","reasoning_title":"Searching news on distillation attacks and Gemini security","classifier_response":"default","can_save":false},"recipient":"all","channel":null},"parent":"f1a20afe-afa5-444e-bc7d-a4cce9b963a4","children":["98eeee4f-603d-4545-96ea-33b9402174a1"]},"98eeee4f-603d-4545-96ea-33b9402174a1":{"id":"98eeee4f-603d-4545-96ea-33b9402174a1","message":{"id":"98eeee4f-603d-4545-96ea-33b9402174a1","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1771304226.0038555,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_result_groups":[{"type":"search_result_group","domain":"www.itpro.com","entries":[{"type":"search_result","url":"https://www.itpro.com/technology/artificial-intelligence/google-says-hacker-groups-are-using-gemini-to-augment-attacks-and-companies-are-even-stealing-its-models","title":"Google says hacker groups are using Gemini to augment attacks - and companies are even 'stealing' its models","snippet":"A new report from Google Threat Intelligence Group (GTIG) and Google DeepMind reveals that state-backed hacker groups are increasingly utilizing Google's Gemini large language model (LLM) in cyberattacks. Advanced Persistent Threats (APTs) from countries like China, Iran, and North Korea are using Gemini to gather intelligence, craft phishing campaigns, and produce stealthy malware. For instance, Gemini has helped groups create tailored phishing emails, research victims, and plan attacks on IT and cybersecurity firms. One malware, HONESTCUE, uses Gemini to execute code in system memory, avoiding traditional detection methods.\n\nMoreover, threat actors are stealing and misusing Gemini and other public AI models, sometimes repackaging them as proprietary tools for sale on the dark web. GTIG has also observed \u201cmodel extraction\u201d practices where attackers mimic Gemini\u2019s capabilities using knowledge distillation, raising intellectual property concerns. Over 100,000 prompts aimed at replicating Gemini's reasoning were blocked. Google has since disabled compromised assets and cautioned organizations to monitor API usage carefully to prevent abuse and data theft. The report flags AI\u2019s growing role across all stages of cyberattacks and urges vigilance as AI-driven threats gain sophistication.","ref_id":{"turn_index":0,"ref_type":"news","ref_index":26},"pub_date":1770896416.0,"attribution":"www.itpro.com"}]},{"type":"search_result_group","domain":"cloud.google.com","entries":[{"type":"search_result","url":"https://cloud.google.com/blog/topics/threat-intelligence/distillation-experimentation-integration-ai-adversarial-use","title":"GTIG AI Threat Tracker: Distillation, Experimentation, and ...","snippet":"5 days ago \u2014 Google DeepMind and GTIG have identified an increase in model extraction attempts or \"distillation attacks,\" a method of intellectual property ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":1},"pub_date":1770854400.0,"attribution":"cloud.google.com"},{"type":"search_result","url":"https://cloud.google.com/blog/topics/threat-intelligence/threat-actor-usage-of-ai-tools","title":"Advances in Threat Actor Usage of AI Tools","snippet":"5 Nov 2025 \u2014 In this report, Google Threat Intelligence Group (GTIG) presents findings on adversarial misuse of AI, including Gemini and other non-Google ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":18},"pub_date":1762300800.0,"attribution":"cloud.google.com"}]},{"type":"search_result_group","domain":"www.gend.co","entries":[{"type":"search_result","url":"https://www.gend.co/blog/gemini-model-extraction-attacks","title":"Gemini Model Extraction Attacks: How 'AI Cloning' Works","snippet":"12 hours ago \u2014 Model extraction (distillation) attacks try to \u201cclone\u201d an AI model by sending large volumes of carefully designed prompts and using the ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"www.gend.co"}]},{"type":"search_result_group","domain":"www.moneycontrol.com","entries":[{"type":"search_result","url":"https://www.moneycontrol.com/technology/hackers-created-google-gemini-clone-using-100-000-prompts-here-s-how-google-stopped-it-article-13825539.html","title":"Hackers created Google Gemini clone using 100000 prompts","snippet":"5 days ago \u2014 Google revealed hackers attempted to clone its Gemini AI using large-scale prompt attacks, prompting new safeguards against model extraction ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"www.moneycontrol.com"}]},{"type":"search_result_group","domain":"blog.google","entries":[{"type":"search_result","url":"https://blog.google/innovation-and-ai/infrastructure-and-cloud/google-cloud/gtig-report-ai-cyber-attacks-feb-2026/","title":"Google Threat Intelligence Group reports on AI threat trends","snippet":"5 days ago \u2014 We've also strengthened both our security controls and Gemini models against misuse. Read the full report on the Google Cloud Threat ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":4},"pub_date":1770854400.0,"attribution":"blog.google"}]},{"type":"search_result_group","domain":"www.linkedin.com","entries":[{"type":"search_result","url":"https://www.linkedin.com/news/story/googles-gemini-faces-surge-in-model-extraction-attacks-8405602/","title":"Google's Gemini faces surge in model extraction attacks","snippet":"4 days ago \u2014 The headline finding: \"distillation attacks\" are surging, where adversaries use legitimate API access to systematically extract proprietary ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":5},"pub_date":1771010175.421,"attribution":"www.linkedin.com"},{"type":"search_result","url":"https://www.linkedin.com/posts/asteris-ai_hackers-use-more-than-100000-prompts-to-activity-7427711427148283904-Rm1v","title":"Google Issues Warning on AI Model Extraction Threats","snippet":"They're trying to reverse-engineer its reasoning. They flood the model with queries to map its internal logic and patterns. The objective is ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":8},"pub_date":1770904404.42,"attribution":"www.linkedin.com"},{"type":"search_result","url":"https://www.linkedin.com/posts/srivalli-jeenu-4613322bb_aisecurity-cybersecurity-googlegemini-activity-7427644970091630592-U0iO","title":"Google's Gemini AI Model Hacked Over 100000 Times","snippet":"... distillation attack' where commercially motivated actors flooded Gemini with queries. Their goal? To reverse-engineer its reasoning and ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":17},"pub_date":1770888559.824,"attribution":"www.linkedin.com"}]},{"type":"search_result_group","domain":"arstechnica.com","entries":[{"type":"search_result","url":"https://arstechnica.com/ai/2026/02/attackers-prompted-gemini-over-100000-times-while-trying-to-clone-it-google-says/","title":"Attackers prompted Gemini over 100000 times while trying ...","snippet":"4 days ago \u2014 Attackers prompted Gemini over 100,000 times while trying to clone it, Google says. Distillation technique lets copycats mimic Gemini at a ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"arstechnica.com"}]},{"type":"search_result_group","domain":"www.artificialintelligence-news.com","entries":[{"type":"search_result","url":"https://www.artificialintelligence-news.com/news/state-sponsored-hackers-ai-cyberattacks-google/","title":"Google identifies state-sponsored hackers using AI in attacks","snippet":"5 days ago \u2014 One campaign targeting Gemini's reasoning abilities involved the collation and use of over 100,000 prompts designed to coerce the model into ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":7},"pub_date":1770886800.0,"attribution":"www.artificialintelligence-news.com"}]},{"type":"search_result_group","domain":"www.infosecurity-magazine.com","entries":[{"type":"search_result","url":"https://www.infosecurity-magazine.com/news/nation-state-hackers-gemini-ai/","title":"Nation-State Hackers Embrace Gemini AI for Malicious ...","snippet":"5 days ago \u2014 Google researchers found that government-backed hackers now use AI throughout the whole attack lifecycle.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"www.infosecurity-magazine.com"}]},{"type":"search_result_group","domain":"finance.biggo.com","entries":[{"type":"search_result","url":"https://finance.biggo.com/news/202602122250_Google-Gemini-AI-Model-Cloning-Attack-Blocked","title":"Google Thwarts Major AI Model Theft Attempt: Attackers Flood ...","snippet":"4 days ago \u2014 This was not a traditional data breach but a calculated \"distillation\" or \"model-extraction\" attempt. The goal was to systematically query the ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"finance.biggo.com"}]},{"type":"search_result_group","domain":"timesofindia.indiatimes.com","entries":[{"type":"search_result","url":"https://timesofindia.indiatimes.com/technology/tech-news/hackers-use-more-than-100000-prompts-to-make-a-google-gemini-clone/articleshow/128254048.cms","title":"Hackers use more than 100000 prompts to make a Google ...","snippet":"5 days ago \u2014 Many of the attacks were crafted to tease out the algorithms that help Gemini \"reason\", or decide how to process information, Google said.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":11},"pub_date":1770893580.0,"attribution":"timesofindia.indiatimes.com"}]},{"type":"search_result_group","domain":"www.instagram.com","entries":[{"type":"search_result","url":"https://www.instagram.com/p/DUyOUmQEkRs/","title":"Google says attackers launched a large-scale \u201cdistillation ...","snippet":"One instance involved adversaries using over 100,000 generated prompts to systematically probe the model, a technique known as model extraction.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"www.instagram.com"}]},{"type":"search_result_group","domain":"www.csoonline.com","entries":[{"type":"search_result","url":"https://www.csoonline.com/article/4132098/google-fears-massive-attempt-to-clone-gemini-ai-through-model-extraction.html","title":"Google fears massive attempt to clone Gemini AI ... - CSO Online","snippet":"4 days ago \u2014 The company identified over 100000 prompts it suspects were intended to extract proprietary reasoning capabilities.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":13},"pub_date":1770940800.0,"attribution":"www.csoonline.com"}]},{"type":"search_result_group","domain":"www.eweek.com","entries":[{"type":"search_result","url":"https://www.eweek.com/news/google-gemini-model-extraction-attacks/","title":"Hackers Try to Clone Google's Gemini With 100000+ AI ...","snippet":"3 days ago \u2014 Google says threat actors launched 100000+ model extraction attacks against Gemini, attempting to reverse engineer its AI logic and training ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":14},"pub_date":1771001352.0,"attribution":"www.eweek.com"}]},{"type":"search_result_group","domain":"discuss.ai.google.dev","entries":[{"type":"search_result","url":"https://discuss.ai.google.dev/t/paid-ultra-account-auto-banned/122685","title":"Paid Ultra Account Auto-Banned - Google Antigravity","snippet":"5 days ago \u2014 No Reverse Engineering. Customer will not, and will not allow End Users to, reverse engineer or extract any components of an AI/ML Service ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":15},"pub_date":1770897219.0,"attribution":"discuss.ai.google.dev"}]},{"type":"search_result_group","domain":"www.bankinfosecurity.com","entries":[{"type":"search_result","url":"https://www.bankinfosecurity.com/state-hackers-turn-google-ai-into-attack-acceleration-tool-a-30751","title":"State Hackers Turn Google AI Into Attack Acceleration Tool","snippet":"3 days ago \u2014 In one case, more than 100,000 prompts attempted to coerce Gemini into outputting full reasoning processes. The breadth of questions ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"www.bankinfosecurity.com"}]},{"type":"search_result_group","domain":"www.techradar.com","entries":[{"type":"search_result","url":"https://www.techradar.com/pro/security/google-says-it-wont-fix-this-potentially-concerning-gemini-security-issue","title":"Google says it won't fix this potentially concerning Gemini security issue","snippet":"Google has declined to fix a recently discovered security concern in its Gemini AI tool, identified as an \"ASCII smuggling attack.\" Security researcher Viktor Markopoulos demonstrated how attackers can embed hidden malicious prompts within emails using invisible text formatting (e.g., white font on a white background or font size 0). When a user asks Gemini\u2014now integrated into Google Workspace tools such as Gmail, Docs, and Sheets\u2014to summarize the content of such an email, the AI interprets and executes the concealed instructions. These commands could include phishing messages or even directives to extract sensitive data.\n\nGoogle, however, argues that this threat constitutes social engineering rather than a true security flaw and sees the issue as the user's responsibility. The lack of a fix raises concerns due to the increasing automation and integration of AI tools, which may unwittingly execute harmful actions based on hidden instructions smuggled within benign-looking content.","ref_id":{"turn_index":0,"ref_type":"news","ref_index":38},"pub_date":1759939800.0,"attribution":"www.techradar.com"}]},{"type":"search_result_group","domain":"www.wired.com","entries":[{"type":"search_result","url":"https://www.wired.com/story/google-gemini-calendar-invite-hijack-smart-home","title":"Hackers Hijacked Google's Gemini AI With a Poisoned Calendar Invite to Take Over a Smart Home","snippet":"In a groundbreaking cybersecurity demonstration, researchers in Tel Aviv exploited Google\u2019s Gemini AI using a \u201cpoisoned\u201d Google Calendar invite to take over an internet-connected smart home. By embedding indirect prompt injections into seemingly benign calendar events, the AI was manipulated to trigger actions like turning on lights, opening shutters, and activating a boiler. This exploit was demonstrated as part of 14 novel attacks showcased at the Black Hat cybersecurity conference.\n\nDubbed \u201cInvitation Is All You Need,\u201d the attacks highlight a serious vulnerability in large language models (LLMs) like Gemini, especially as they become agents capable of controlling real-world systems. These prompt injections didn't require user input but were indirectly embedded in calendar invites or document titles, demonstrating the risks of automatic AI decision-making.\n\nDespite no real-world attacks being reported, Google has taken the findings seriously, implementing machine learning-based detection, layered defenses, and increased user confirmations. Still, experts caution that the evolving nature of prompt injections poses an ongoing security challenge. The research underscores the urgent need for robust safeguards as AI becomes increasingly integrated into physical and digital infrastructures.","ref_id":{"turn_index":0,"ref_type":"news","ref_index":40},"pub_date":1754485200.0,"attribution":"www.wired.com"}]}],"debug_sonic_thread_id":"thread_6993f5220a34832cb81c86897a6be588","model_slug":"gpt-5-2-thinking","hide_inline_actions":true,"disable_turn_actions":true,"request_id":"4c4f4702-b3c5-4ef6-b23c-35bf3cc0f0a6","message_type":"next","default_model_slug":"gpt-5-2","parent_id":"dd64b786-2cf4-4a48-9cd9-26224cf371af","turn_exchange_id":"0e5bf703-39b2-4408-9740-c57ef23965da","reasoning_status":"is_reasoning","reasoning_title":"Searching news on distillation attacks and Gemini security","classifier_response":"default","can_save":false},"recipient":"all","channel":null},"parent":"f9dc48ca-071b-45a4-8213-f08d105fa25f","children":["29c48e45-5810-4c7d-b72d-a5690461acdd"]},"29c48e45-5810-4c7d-b72d-a5690461acdd":{"id":"29c48e45-5810-4c7d-b72d-a5690461acdd","message":{"id":"29c48e45-5810-4c7d-b72d-a5690461acdd","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1771304228.416002,"update_time":null,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"{\"open\":[{\"ref_id\":\"turn0search1\"}],\"response_length\":\"short\"}"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"citations":[],"content_references":[],"resolved_model_slug":"gpt-5-2-auto-thinking","model_slug":"gpt-5-2-thinking","hide_inline_actions":true,"disable_turn_actions":true,"request_id":"4c4f4702-b3c5-4ef6-b23c-35bf3cc0f0a6","message_type":"next","default_model_slug":"gpt-5-2","parent_id":"2c04eb35-8a81-4b29-bfdf-7702e8a74668","turn_exchange_id":"0e5bf703-39b2-4408-9740-c57ef23965da","reasoning_status":"is_reasoning","reasoning_title":"Opening Google blog post for details","classifier_response":"default","can_save":true},"recipient":"web.run","channel":null},"parent":"98eeee4f-603d-4545-96ea-33b9402174a1","children":["4e6e8c80-75c7-4723-a7fb-ff8b42b9f656"]},"4e6e8c80-75c7-4723-a7fb-ff8b42b9f656":{"id":"4e6e8c80-75c7-4723-a7fb-ff8b42b9f656","message":{"id":"4e6e8c80-75c7-4723-a7fb-ff8b42b9f656","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1771304230.1285825,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_result_groups":[{"type":"search_result_group","domain":"cloud.google.com","entries":[{"type":"search_result","url":"https://cloud.google.com/blog/topics/threat-intelligence/distillation-experimentation-integration-ai-adversarial-use","title":"GTIG AI Threat Tracker: Distillation, Experimentation, and (Continued) Integration of AI for Adversarial Use | Google Cloud Blog","snippet":"Total lines: 330\n","ref_id":{"turn_index":1,"ref_type":"view","ref_index":0},"pub_date":null,"attribution":"cloud.google.com"}]}],"debug_sonic_thread_id":"thread_6993f5220a34832cb81c86897a6be588","model_slug":"gpt-5-2-thinking","hide_inline_actions":true,"disable_turn_actions":true,"request_id":"4c4f4702-b3c5-4ef6-b23c-35bf3cc0f0a6","message_type":"next","default_model_slug":"gpt-5-2","parent_id":"29c48e45-5810-4c7d-b72d-a5690461acdd","turn_exchange_id":"0e5bf703-39b2-4408-9740-c57ef23965da","reasoning_status":"is_reasoning","reasoning_title":"Opening Google blog post for details","classifier_response":"default","can_save":false},"recipient":"all","channel":null},"parent":"29c48e45-5810-4c7d-b72d-a5690461acdd","children":["6cf6f39f-7d21-489b-b647-2b17902c1c07"]},"6cf6f39f-7d21-489b-b647-2b17902c1c07":{"id":"6cf6f39f-7d21-489b-b647-2b17902c1c07","message":{"id":"6cf6f39f-7d21-489b-b647-2b17902c1c07","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1771304234.509463,"update_time":null,"content":{"content_type":"thoughts","thoughts":[{"summary":"Explaining distillation attacks and mitigations","content":"I\u2019ll explain distillation attacks, where a model is extracted via API queries by collecting input-output pairs and training a student model. This includes optimizations like prompt engineering and imitation learning. I\u2019ll break down steps and cover mitigations. I\u2019ll also explain why 100k prompts are used and source information from trusted articles.","chunks":["I\u2019ll explain distillation attacks, where a model is extracted via API queries by collecting input-output pairs and training a student model.","This includes optimizations like prompt engineering and imitation learning.","I\u2019ll break down steps and cover mitigations.","I\u2019ll also explain why 100k prompts are used and source information from trusted articles."],"finished":true}],"source_analysis_msg_id":"2c04eb35-8a81-4b29-bfdf-7702e8a74668"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"is_reasoning","citations":[],"content_references":[],"resolved_model_slug":"gpt-5-2-auto-thinking","model_slug":"gpt-5-2-thinking","hide_inline_actions":true,"disable_turn_actions":true,"request_id":"4c4f4702-b3c5-4ef6-b23c-35bf3cc0f0a6","message_type":"next","default_model_slug":"gpt-5-2","parent_id":"599ce509-0f45-453b-9173-a87887c570a7","turn_exchange_id":"0e5bf703-39b2-4408-9740-c57ef23965da","classifier_response":"default","skip_reasoning_title":"Skip","search_result_groups":[{"type":"search_result_group","domain":"www.itpro.com","entries":[{"type":"search_result","url":"https://www.itpro.com/technology/artificial-intelligence/google-says-hacker-groups-are-using-gemini-to-augment-attacks-and-companies-are-even-stealing-its-models","title":"Google says hacker groups are using Gemini to augment attacks - and companies are even 'stealing' its models","snippet":"A new report from Google Threat Intelligence Group (GTIG) and Google DeepMind reveals that state-backed hacker groups are increasingly utilizing Google's Gemini large language model (LLM) in cyberattacks. Advanced Persistent Threats (APTs) from countries like China, Iran, and North Korea are using Gemini to gather intelligence, craft phishing campaigns, and produce stealthy malware. For instance, Gemini has helped groups create tailored phishing emails, research victims, and plan attacks on IT and cybersecurity firms. One malware, HONESTCUE, uses Gemini to execute code in system memory, avoiding traditional detection methods.\n\nMoreover, threat actors are stealing and misusing Gemini and other public AI models, sometimes repackaging them as proprietary tools for sale on the dark web. GTIG has also observed \u201cmodel extraction\u201d practices where attackers mimic Gemini\u2019s capabilities using knowledge distillation, raising intellectual property concerns. Over 100,000 prompts aimed at replicating Gemini's reasoning were blocked. Google has since disabled compromised assets and cautioned organizations to monitor API usage carefully to prevent abuse and data theft. The report flags AI\u2019s growing role across all stages of cyberattacks and urges vigilance as AI-driven threats gain sophistication.","ref_id":{"turn_index":0,"ref_type":"news","ref_index":26},"pub_date":1770896416.0,"attribution":"www.itpro.com"}]},{"type":"search_result_group","domain":"cloud.google.com","entries":[{"type":"search_result","url":"https://cloud.google.com/blog/topics/threat-intelligence/distillation-experimentation-integration-ai-adversarial-use","title":"GTIG AI Threat Tracker: Distillation, Experimentation, and ...","snippet":"5 days ago \u2014 Google DeepMind and GTIG have identified an increase in model extraction attempts or \"distillation attacks,\" a method of intellectual property ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":1},"pub_date":1770854400.0,"attribution":"cloud.google.com"},{"type":"search_result","url":"https://cloud.google.com/blog/topics/threat-intelligence/threat-actor-usage-of-ai-tools","title":"Advances in Threat Actor Usage of AI Tools","snippet":"5 Nov 2025 \u2014 In this report, Google Threat Intelligence Group (GTIG) presents findings on adversarial misuse of AI, including Gemini and other non-Google ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":18},"pub_date":1762300800.0,"attribution":"cloud.google.com"},{"type":"search_result","url":"https://cloud.google.com/blog/topics/threat-intelligence/distillation-experimentation-integration-ai-adversarial-use","title":"GTIG AI Threat Tracker: Distillation, Experimentation, and (Continued) Integration of AI for Adversarial Use | Google Cloud Blog","snippet":"Total lines: 330\n","ref_id":{"turn_index":1,"ref_type":"view","ref_index":0},"pub_date":null,"attribution":"cloud.google.com"}]},{"type":"search_result_group","domain":"www.gend.co","entries":[{"type":"search_result","url":"https://www.gend.co/blog/gemini-model-extraction-attacks","title":"Gemini Model Extraction Attacks: How 'AI Cloning' Works","snippet":"12 hours ago \u2014 Model extraction (distillation) attacks try to \u201cclone\u201d an AI model by sending large volumes of carefully designed prompts and using the ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"www.gend.co"}]},{"type":"search_result_group","domain":"www.moneycontrol.com","entries":[{"type":"search_result","url":"https://www.moneycontrol.com/technology/hackers-created-google-gemini-clone-using-100-000-prompts-here-s-how-google-stopped-it-article-13825539.html","title":"Hackers created Google Gemini clone using 100000 prompts","snippet":"5 days ago \u2014 Google revealed hackers attempted to clone its Gemini AI using large-scale prompt attacks, prompting new safeguards against model extraction ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"www.moneycontrol.com"}]},{"type":"search_result_group","domain":"blog.google","entries":[{"type":"search_result","url":"https://blog.google/innovation-and-ai/infrastructure-and-cloud/google-cloud/gtig-report-ai-cyber-attacks-feb-2026/","title":"Google Threat Intelligence Group reports on AI threat trends","snippet":"5 days ago \u2014 We've also strengthened both our security controls and Gemini models against misuse. Read the full report on the Google Cloud Threat ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":4},"pub_date":1770854400.0,"attribution":"blog.google"}]},{"type":"search_result_group","domain":"www.linkedin.com","entries":[{"type":"search_result","url":"https://www.linkedin.com/news/story/googles-gemini-faces-surge-in-model-extraction-attacks-8405602/","title":"Google's Gemini faces surge in model extraction attacks","snippet":"4 days ago \u2014 The headline finding: \"distillation attacks\" are surging, where adversaries use legitimate API access to systematically extract proprietary ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":5},"pub_date":1771010175.421,"attribution":"www.linkedin.com"},{"type":"search_result","url":"https://www.linkedin.com/posts/asteris-ai_hackers-use-more-than-100000-prompts-to-activity-7427711427148283904-Rm1v","title":"Google Issues Warning on AI Model Extraction Threats","snippet":"They're trying to reverse-engineer its reasoning. They flood the model with queries to map its internal logic and patterns. The objective is ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":8},"pub_date":1770904404.42,"attribution":"www.linkedin.com"},{"type":"search_result","url":"https://www.linkedin.com/posts/srivalli-jeenu-4613322bb_aisecurity-cybersecurity-googlegemini-activity-7427644970091630592-U0iO","title":"Google's Gemini AI Model Hacked Over 100000 Times","snippet":"... distillation attack' where commercially motivated actors flooded Gemini with queries. Their goal? To reverse-engineer its reasoning and ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":17},"pub_date":1770888559.824,"attribution":"www.linkedin.com"}]},{"type":"search_result_group","domain":"arstechnica.com","entries":[{"type":"search_result","url":"https://arstechnica.com/ai/2026/02/attackers-prompted-gemini-over-100000-times-while-trying-to-clone-it-google-says/","title":"Attackers prompted Gemini over 100000 times while trying ...","snippet":"4 days ago \u2014 Attackers prompted Gemini over 100,000 times while trying to clone it, Google says. Distillation technique lets copycats mimic Gemini at a ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"arstechnica.com"}]},{"type":"search_result_group","domain":"www.artificialintelligence-news.com","entries":[{"type":"search_result","url":"https://www.artificialintelligence-news.com/news/state-sponsored-hackers-ai-cyberattacks-google/","title":"Google identifies state-sponsored hackers using AI in attacks","snippet":"5 days ago \u2014 One campaign targeting Gemini's reasoning abilities involved the collation and use of over 100,000 prompts designed to coerce the model into ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":7},"pub_date":1770886800.0,"attribution":"www.artificialintelligence-news.com"}]},{"type":"search_result_group","domain":"www.infosecurity-magazine.com","entries":[{"type":"search_result","url":"https://www.infosecurity-magazine.com/news/nation-state-hackers-gemini-ai/","title":"Nation-State Hackers Embrace Gemini AI for Malicious ...","snippet":"5 days ago \u2014 Google researchers found that government-backed hackers now use AI throughout the whole attack lifecycle.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"www.infosecurity-magazine.com"}]},{"type":"search_result_group","domain":"finance.biggo.com","entries":[{"type":"search_result","url":"https://finance.biggo.com/news/202602122250_Google-Gemini-AI-Model-Cloning-Attack-Blocked","title":"Google Thwarts Major AI Model Theft Attempt: Attackers Flood ...","snippet":"4 days ago \u2014 This was not a traditional data breach but a calculated \"distillation\" or \"model-extraction\" attempt. The goal was to systematically query the ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"finance.biggo.com"}]},{"type":"search_result_group","domain":"timesofindia.indiatimes.com","entries":[{"type":"search_result","url":"https://timesofindia.indiatimes.com/technology/tech-news/hackers-use-more-than-100000-prompts-to-make-a-google-gemini-clone/articleshow/128254048.cms","title":"Hackers use more than 100000 prompts to make a Google ...","snippet":"5 days ago \u2014 Many of the attacks were crafted to tease out the algorithms that help Gemini \"reason\", or decide how to process information, Google said.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":11},"pub_date":1770893580.0,"attribution":"timesofindia.indiatimes.com"}]},{"type":"search_result_group","domain":"www.instagram.com","entries":[{"type":"search_result","url":"https://www.instagram.com/p/DUyOUmQEkRs/","title":"Google says attackers launched a large-scale \u201cdistillation ...","snippet":"One instance involved adversaries using over 100,000 generated prompts to systematically probe the model, a technique known as model extraction.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"www.instagram.com"}]},{"type":"search_result_group","domain":"www.csoonline.com","entries":[{"type":"search_result","url":"https://www.csoonline.com/article/4132098/google-fears-massive-attempt-to-clone-gemini-ai-through-model-extraction.html","title":"Google fears massive attempt to clone Gemini AI ... - CSO Online","snippet":"4 days ago \u2014 The company identified over 100000 prompts it suspects were intended to extract proprietary reasoning capabilities.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":13},"pub_date":1770940800.0,"attribution":"www.csoonline.com"}]},{"type":"search_result_group","domain":"www.eweek.com","entries":[{"type":"search_result","url":"https://www.eweek.com/news/google-gemini-model-extraction-attacks/","title":"Hackers Try to Clone Google's Gemini With 100000+ AI ...","snippet":"3 days ago \u2014 Google says threat actors launched 100000+ model extraction attacks against Gemini, attempting to reverse engineer its AI logic and training ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":14},"pub_date":1771001352.0,"attribution":"www.eweek.com"}]},{"type":"search_result_group","domain":"discuss.ai.google.dev","entries":[{"type":"search_result","url":"https://discuss.ai.google.dev/t/paid-ultra-account-auto-banned/122685","title":"Paid Ultra Account Auto-Banned - Google Antigravity","snippet":"5 days ago \u2014 No Reverse Engineering. Customer will not, and will not allow End Users to, reverse engineer or extract any components of an AI/ML Service ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":15},"pub_date":1770897219.0,"attribution":"discuss.ai.google.dev"}]},{"type":"search_result_group","domain":"www.bankinfosecurity.com","entries":[{"type":"search_result","url":"https://www.bankinfosecurity.com/state-hackers-turn-google-ai-into-attack-acceleration-tool-a-30751","title":"State Hackers Turn Google AI Into Attack Acceleration Tool","snippet":"3 days ago \u2014 In one case, more than 100,000 prompts attempted to coerce Gemini into outputting full reasoning processes. The breadth of questions ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"www.bankinfosecurity.com"}]},{"type":"search_result_group","domain":"www.techradar.com","entries":[{"type":"search_result","url":"https://www.techradar.com/pro/security/google-says-it-wont-fix-this-potentially-concerning-gemini-security-issue","title":"Google says it won't fix this potentially concerning Gemini security issue","snippet":"Google has declined to fix a recently discovered security concern in its Gemini AI tool, identified as an \"ASCII smuggling attack.\" Security researcher Viktor Markopoulos demonstrated how attackers can embed hidden malicious prompts within emails using invisible text formatting (e.g., white font on a white background or font size 0). When a user asks Gemini\u2014now integrated into Google Workspace tools such as Gmail, Docs, and Sheets\u2014to summarize the content of such an email, the AI interprets and executes the concealed instructions. These commands could include phishing messages or even directives to extract sensitive data.\n\nGoogle, however, argues that this threat constitutes social engineering rather than a true security flaw and sees the issue as the user's responsibility. The lack of a fix raises concerns due to the increasing automation and integration of AI tools, which may unwittingly execute harmful actions based on hidden instructions smuggled within benign-looking content.","ref_id":{"turn_index":0,"ref_type":"news","ref_index":38},"pub_date":1759939800.0,"attribution":"www.techradar.com"}]},{"type":"search_result_group","domain":"www.wired.com","entries":[{"type":"search_result","url":"https://www.wired.com/story/google-gemini-calendar-invite-hijack-smart-home","title":"Hackers Hijacked Google's Gemini AI With a Poisoned Calendar Invite to Take Over a Smart Home","snippet":"In a groundbreaking cybersecurity demonstration, researchers in Tel Aviv exploited Google\u2019s Gemini AI using a \u201cpoisoned\u201d Google Calendar invite to take over an internet-connected smart home. By embedding indirect prompt injections into seemingly benign calendar events, the AI was manipulated to trigger actions like turning on lights, opening shutters, and activating a boiler. This exploit was demonstrated as part of 14 novel attacks showcased at the Black Hat cybersecurity conference.\n\nDubbed \u201cInvitation Is All You Need,\u201d the attacks highlight a serious vulnerability in large language models (LLMs) like Gemini, especially as they become agents capable of controlling real-world systems. These prompt injections didn't require user input but were indirectly embedded in calendar invites or document titles, demonstrating the risks of automatic AI decision-making.\n\nDespite no real-world attacks being reported, Google has taken the findings seriously, implementing machine learning-based detection, layered defenses, and increased user confirmations. Still, experts caution that the evolving nature of prompt injections poses an ongoing security challenge. The research underscores the urgent need for robust safeguards as AI becomes increasingly integrated into physical and digital infrastructures.","ref_id":{"turn_index":0,"ref_type":"news","ref_index":40},"pub_date":1754485200.0,"attribution":"www.wired.com"}]}],"safe_urls":["https://arstechnica.com/ai/2026/02/attackers-prompted-gemini-over-100000-times-while-trying-to-clone-it-google-says/","https://blog.google/innovation-and-ai/infrastructure-and-cloud/google-cloud/gtig-report-ai-cyber-attacks-feb-2026/","https://cloud.google.com/blog/topics/threat-intelligence/distillation-experimentation-integration-ai-adversarial-use","https://cloud.google.com/blog/topics/threat-intelligence/threat-actor-usage-of-ai-tools","https://discuss.ai.google.dev/t/paid-ultra-account-auto-banned/122685","https://finance.biggo.com/news/202602122250_Google-Gemini-AI-Model-Cloning-Attack-Blocked","https://timesofindia.indiatimes.com/technology/tech-news/hackers-use-more-than-100000-prompts-to-make-a-google-gemini-clone/articleshow/128254048.cms","https://www.artificialintelligence-news.com/news/state-sponsored-hackers-ai-cyberattacks-google/","https://www.bankinfosecurity.com/state-hackers-turn-google-ai-into-attack-acceleration-tool-a-30751","https://www.csoonline.com/article/4132098/google-fears-massive-attempt-to-clone-gemini-ai-through-model-extraction.html","https://www.eweek.com/news/google-gemini-model-extraction-attacks/","https://www.gend.co/blog/gemini-model-extraction-attacks","https://www.infosecurity-magazine.com/news/nation-state-hackers-gemini-ai/","https://www.instagram.com/p/DUyOUmQEkRs/","https://www.itpro.com/technology/artificial-intelligence/google-says-hacker-groups-are-using-gemini-to-augment-attacks-and-companies-are-even-stealing-its-models","https://www.linkedin.com/news/story/googles-gemini-faces-surge-in-model-extraction-attacks-8405602/","https://www.linkedin.com/posts/asteris-ai_hackers-use-more-than-100000-prompts-to-activity-7427711427148283904-Rm1v","https://www.linkedin.com/posts/srivalli-jeenu-4613322bb_aisecurity-cybersecurity-googlegemini-activity-7427644970091630592-U0iO","https://www.moneycontrol.com/technology/hackers-created-google-gemini-clone-using-100-000-prompts-here-s-how-google-stopped-it-article-13825539.html","https://www.techradar.com/pro/security/google-says-it-wont-fix-this-potentially-concerning-gemini-security-issue","https://www.wired.com/story/google-gemini-calendar-invite-hijack-smart-home"],"can_save":true},"recipient":"all","channel":null},"parent":"4e6e8c80-75c7-4723-a7fb-ff8b42b9f656","children":["7c4104ff-46d8-471e-a36c-6a8a434a9991"]},"7c4104ff-46d8-471e-a36c-6a8a434a9991":{"id":"7c4104ff-46d8-471e-a36c-6a8a434a9991","message":{"id":"7c4104ff-46d8-471e-a36c-6a8a434a9991","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1771304230.285186,"update_time":null,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"{\"open\":[{\"ref_id\":\"turn0search6\"}],\"response_length\":\"short\"}"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"citations":[],"content_references":[],"resolved_model_slug":"gpt-5-2-auto-thinking","model_slug":"gpt-5-2-thinking","hide_inline_actions":true,"disable_turn_actions":true,"request_id":"4c4f4702-b3c5-4ef6-b23c-35bf3cc0f0a6","message_type":"next","default_model_slug":"gpt-5-2","parent_id":"85fadead-9aec-4bde-bb8f-7e37f698cc01","turn_exchange_id":"0e5bf703-39b2-4408-9740-c57ef23965da","reasoning_status":"is_reasoning","reasoning_title":"Explaining distillation attacks and mitigation strategies","classifier_response":"default","can_save":true},"recipient":"web.run","channel":null},"parent":"6cf6f39f-7d21-489b-b647-2b17902c1c07","children":["19fa00af-9634-4ea6-ae3a-30d98c93d363"]},"19fa00af-9634-4ea6-ae3a-30d98c93d363":{"id":"19fa00af-9634-4ea6-ae3a-30d98c93d363","message":{"id":"19fa00af-9634-4ea6-ae3a-30d98c93d363","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1771304233.6152263,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_result_groups":[],"debug_sonic_thread_id":"thread_6993f5220a34832cb81c86897a6be588","model_slug":"gpt-5-2-thinking","hide_inline_actions":true,"disable_turn_actions":true,"request_id":"4c4f4702-b3c5-4ef6-b23c-35bf3cc0f0a6","message_type":"next","default_model_slug":"gpt-5-2","parent_id":"00320559-a436-4f93-845e-f282a55f7c71","turn_exchange_id":"0e5bf703-39b2-4408-9740-c57ef23965da","reasoning_status":"is_reasoning","reasoning_title":"Explaining distillation attacks and mitigation strategies","classifier_response":"default","can_save":false},"recipient":"all","channel":null},"parent":"7c4104ff-46d8-471e-a36c-6a8a434a9991","children":["d49b1756-00f4-4611-9a7b-db78b00ce5e1"]},"d49b1756-00f4-4611-9a7b-db78b00ce5e1":{"id":"d49b1756-00f4-4611-9a7b-db78b00ce5e1","message":{"id":"d49b1756-00f4-4611-9a7b-db78b00ce5e1","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1771304238.925268,"update_time":null,"content":{"content_type":"thoughts","thoughts":[{"summary":"Finding reliable sources on model extraction attacks","content":"I can\u2019t access the primary source, but I\u2019ll turn to other trusted sites like CSO, BankInfoSecurity, eWeek, and ITPro. I\u2019ll cite Google\u2019s blog as the main source. I also plan to include academic sources on general model extraction and knowledge distillation. Let\u2019s look into terms like \"model extraction attacks machine learning.\"","chunks":["I can\u2019t access the primary source, but I\u2019ll turn to other trusted sites like CSO, BankInfoSecurity, eWeek, and ITPro.","I\u2019ll cite Google\u2019s blog as the main source.","I also plan to include academic sources on general model extraction and knowledge distillation.","Let\u2019s look into terms like \"model extraction attacks machine learning.\""],"finished":true}],"source_analysis_msg_id":"85fadead-9aec-4bde-bb8f-7e37f698cc01"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"is_reasoning","citations":[],"content_references":[],"resolved_model_slug":"gpt-5-2-auto-thinking","model_slug":"gpt-5-2-thinking","hide_inline_actions":true,"disable_turn_actions":true,"request_id":"4c4f4702-b3c5-4ef6-b23c-35bf3cc0f0a6","message_type":"next","default_model_slug":"gpt-5-2","parent_id":"e6861f78-e593-4335-b6d8-941e7755c2e4","turn_exchange_id":"0e5bf703-39b2-4408-9740-c57ef23965da","classifier_response":"default","skip_reasoning_title":"Skip","search_result_groups":[{"type":"search_result_group","domain":"www.itpro.com","entries":[{"type":"search_result","url":"https://www.itpro.com/technology/artificial-intelligence/google-says-hacker-groups-are-using-gemini-to-augment-attacks-and-companies-are-even-stealing-its-models","title":"Google says hacker groups are using Gemini to augment attacks - and companies are even 'stealing' its models","snippet":"A new report from Google Threat Intelligence Group (GTIG) and Google DeepMind reveals that state-backed hacker groups are increasingly utilizing Google's Gemini large language model (LLM) in cyberattacks. Advanced Persistent Threats (APTs) from countries like China, Iran, and North Korea are using Gemini to gather intelligence, craft phishing campaigns, and produce stealthy malware. For instance, Gemini has helped groups create tailored phishing emails, research victims, and plan attacks on IT and cybersecurity firms. One malware, HONESTCUE, uses Gemini to execute code in system memory, avoiding traditional detection methods.\n\nMoreover, threat actors are stealing and misusing Gemini and other public AI models, sometimes repackaging them as proprietary tools for sale on the dark web. GTIG has also observed \u201cmodel extraction\u201d practices where attackers mimic Gemini\u2019s capabilities using knowledge distillation, raising intellectual property concerns. Over 100,000 prompts aimed at replicating Gemini's reasoning were blocked. Google has since disabled compromised assets and cautioned organizations to monitor API usage carefully to prevent abuse and data theft. The report flags AI\u2019s growing role across all stages of cyberattacks and urges vigilance as AI-driven threats gain sophistication.","ref_id":{"turn_index":0,"ref_type":"news","ref_index":26},"pub_date":1770896416.0,"attribution":"www.itpro.com"}]},{"type":"search_result_group","domain":"cloud.google.com","entries":[{"type":"search_result","url":"https://cloud.google.com/blog/topics/threat-intelligence/distillation-experimentation-integration-ai-adversarial-use","title":"GTIG AI Threat Tracker: Distillation, Experimentation, and ...","snippet":"5 days ago \u2014 Google DeepMind and GTIG have identified an increase in model extraction attempts or \"distillation attacks,\" a method of intellectual property ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":1},"pub_date":1770854400.0,"attribution":"cloud.google.com"},{"type":"search_result","url":"https://cloud.google.com/blog/topics/threat-intelligence/threat-actor-usage-of-ai-tools","title":"Advances in Threat Actor Usage of AI Tools","snippet":"5 Nov 2025 \u2014 In this report, Google Threat Intelligence Group (GTIG) presents findings on adversarial misuse of AI, including Gemini and other non-Google ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":18},"pub_date":1762300800.0,"attribution":"cloud.google.com"},{"type":"search_result","url":"https://cloud.google.com/blog/topics/threat-intelligence/distillation-experimentation-integration-ai-adversarial-use","title":"GTIG AI Threat Tracker: Distillation, Experimentation, and (Continued) Integration of AI for Adversarial Use | Google Cloud Blog","snippet":"Total lines: 330\n","ref_id":{"turn_index":1,"ref_type":"view","ref_index":0},"pub_date":null,"attribution":"cloud.google.com"}]},{"type":"search_result_group","domain":"www.gend.co","entries":[{"type":"search_result","url":"https://www.gend.co/blog/gemini-model-extraction-attacks","title":"Gemini Model Extraction Attacks: How 'AI Cloning' Works","snippet":"12 hours ago \u2014 Model extraction (distillation) attacks try to \u201cclone\u201d an AI model by sending large volumes of carefully designed prompts and using the ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"www.gend.co"}]},{"type":"search_result_group","domain":"www.moneycontrol.com","entries":[{"type":"search_result","url":"https://www.moneycontrol.com/technology/hackers-created-google-gemini-clone-using-100-000-prompts-here-s-how-google-stopped-it-article-13825539.html","title":"Hackers created Google Gemini clone using 100000 prompts","snippet":"5 days ago \u2014 Google revealed hackers attempted to clone its Gemini AI using large-scale prompt attacks, prompting new safeguards against model extraction ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"www.moneycontrol.com"}]},{"type":"search_result_group","domain":"blog.google","entries":[{"type":"search_result","url":"https://blog.google/innovation-and-ai/infrastructure-and-cloud/google-cloud/gtig-report-ai-cyber-attacks-feb-2026/","title":"Google Threat Intelligence Group reports on AI threat trends","snippet":"5 days ago \u2014 We've also strengthened both our security controls and Gemini models against misuse. Read the full report on the Google Cloud Threat ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":4},"pub_date":1770854400.0,"attribution":"blog.google"}]},{"type":"search_result_group","domain":"www.linkedin.com","entries":[{"type":"search_result","url":"https://www.linkedin.com/news/story/googles-gemini-faces-surge-in-model-extraction-attacks-8405602/","title":"Google's Gemini faces surge in model extraction attacks","snippet":"4 days ago \u2014 The headline finding: \"distillation attacks\" are surging, where adversaries use legitimate API access to systematically extract proprietary ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":5},"pub_date":1771010175.421,"attribution":"www.linkedin.com"},{"type":"search_result","url":"https://www.linkedin.com/posts/asteris-ai_hackers-use-more-than-100000-prompts-to-activity-7427711427148283904-Rm1v","title":"Google Issues Warning on AI Model Extraction Threats","snippet":"They're trying to reverse-engineer its reasoning. They flood the model with queries to map its internal logic and patterns. The objective is ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":8},"pub_date":1770904404.42,"attribution":"www.linkedin.com"},{"type":"search_result","url":"https://www.linkedin.com/posts/srivalli-jeenu-4613322bb_aisecurity-cybersecurity-googlegemini-activity-7427644970091630592-U0iO","title":"Google's Gemini AI Model Hacked Over 100000 Times","snippet":"... distillation attack' where commercially motivated actors flooded Gemini with queries. Their goal? To reverse-engineer its reasoning and ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":17},"pub_date":1770888559.824,"attribution":"www.linkedin.com"}]},{"type":"search_result_group","domain":"arstechnica.com","entries":[{"type":"search_result","url":"https://arstechnica.com/ai/2026/02/attackers-prompted-gemini-over-100000-times-while-trying-to-clone-it-google-says/","title":"Attackers prompted Gemini over 100000 times while trying ...","snippet":"4 days ago \u2014 Attackers prompted Gemini over 100,000 times while trying to clone it, Google says. Distillation technique lets copycats mimic Gemini at a ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"arstechnica.com"}]},{"type":"search_result_group","domain":"www.artificialintelligence-news.com","entries":[{"type":"search_result","url":"https://www.artificialintelligence-news.com/news/state-sponsored-hackers-ai-cyberattacks-google/","title":"Google identifies state-sponsored hackers using AI in attacks","snippet":"5 days ago \u2014 One campaign targeting Gemini's reasoning abilities involved the collation and use of over 100,000 prompts designed to coerce the model into ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":7},"pub_date":1770886800.0,"attribution":"www.artificialintelligence-news.com"}]},{"type":"search_result_group","domain":"www.infosecurity-magazine.com","entries":[{"type":"search_result","url":"https://www.infosecurity-magazine.com/news/nation-state-hackers-gemini-ai/","title":"Nation-State Hackers Embrace Gemini AI for Malicious ...","snippet":"5 days ago \u2014 Google researchers found that government-backed hackers now use AI throughout the whole attack lifecycle.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"www.infosecurity-magazine.com"}]},{"type":"search_result_group","domain":"finance.biggo.com","entries":[{"type":"search_result","url":"https://finance.biggo.com/news/202602122250_Google-Gemini-AI-Model-Cloning-Attack-Blocked","title":"Google Thwarts Major AI Model Theft Attempt: Attackers Flood ...","snippet":"4 days ago \u2014 This was not a traditional data breach but a calculated \"distillation\" or \"model-extraction\" attempt. The goal was to systematically query the ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"finance.biggo.com"}]},{"type":"search_result_group","domain":"timesofindia.indiatimes.com","entries":[{"type":"search_result","url":"https://timesofindia.indiatimes.com/technology/tech-news/hackers-use-more-than-100000-prompts-to-make-a-google-gemini-clone/articleshow/128254048.cms","title":"Hackers use more than 100000 prompts to make a Google ...","snippet":"5 days ago \u2014 Many of the attacks were crafted to tease out the algorithms that help Gemini \"reason\", or decide how to process information, Google said.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":11},"pub_date":1770893580.0,"attribution":"timesofindia.indiatimes.com"}]},{"type":"search_result_group","domain":"www.instagram.com","entries":[{"type":"search_result","url":"https://www.instagram.com/p/DUyOUmQEkRs/","title":"Google says attackers launched a large-scale \u201cdistillation ...","snippet":"One instance involved adversaries using over 100,000 generated prompts to systematically probe the model, a technique known as model extraction.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"www.instagram.com"}]},{"type":"search_result_group","domain":"www.csoonline.com","entries":[{"type":"search_result","url":"https://www.csoonline.com/article/4132098/google-fears-massive-attempt-to-clone-gemini-ai-through-model-extraction.html","title":"Google fears massive attempt to clone Gemini AI ... - CSO Online","snippet":"4 days ago \u2014 The company identified over 100000 prompts it suspects were intended to extract proprietary reasoning capabilities.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":13},"pub_date":1770940800.0,"attribution":"www.csoonline.com"}]},{"type":"search_result_group","domain":"www.eweek.com","entries":[{"type":"search_result","url":"https://www.eweek.com/news/google-gemini-model-extraction-attacks/","title":"Hackers Try to Clone Google's Gemini With 100000+ AI ...","snippet":"3 days ago \u2014 Google says threat actors launched 100000+ model extraction attacks against Gemini, attempting to reverse engineer its AI logic and training ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":14},"pub_date":1771001352.0,"attribution":"www.eweek.com"}]},{"type":"search_result_group","domain":"discuss.ai.google.dev","entries":[{"type":"search_result","url":"https://discuss.ai.google.dev/t/paid-ultra-account-auto-banned/122685","title":"Paid Ultra Account Auto-Banned - Google Antigravity","snippet":"5 days ago \u2014 No Reverse Engineering. Customer will not, and will not allow End Users to, reverse engineer or extract any components of an AI/ML Service ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":15},"pub_date":1770897219.0,"attribution":"discuss.ai.google.dev"}]},{"type":"search_result_group","domain":"www.bankinfosecurity.com","entries":[{"type":"search_result","url":"https://www.bankinfosecurity.com/state-hackers-turn-google-ai-into-attack-acceleration-tool-a-30751","title":"State Hackers Turn Google AI Into Attack Acceleration Tool","snippet":"3 days ago \u2014 In one case, more than 100,000 prompts attempted to coerce Gemini into outputting full reasoning processes. The breadth of questions ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"www.bankinfosecurity.com"}]},{"type":"search_result_group","domain":"www.techradar.com","entries":[{"type":"search_result","url":"https://www.techradar.com/pro/security/google-says-it-wont-fix-this-potentially-concerning-gemini-security-issue","title":"Google says it won't fix this potentially concerning Gemini security issue","snippet":"Google has declined to fix a recently discovered security concern in its Gemini AI tool, identified as an \"ASCII smuggling attack.\" Security researcher Viktor Markopoulos demonstrated how attackers can embed hidden malicious prompts within emails using invisible text formatting (e.g., white font on a white background or font size 0). When a user asks Gemini\u2014now integrated into Google Workspace tools such as Gmail, Docs, and Sheets\u2014to summarize the content of such an email, the AI interprets and executes the concealed instructions. These commands could include phishing messages or even directives to extract sensitive data.\n\nGoogle, however, argues that this threat constitutes social engineering rather than a true security flaw and sees the issue as the user's responsibility. The lack of a fix raises concerns due to the increasing automation and integration of AI tools, which may unwittingly execute harmful actions based on hidden instructions smuggled within benign-looking content.","ref_id":{"turn_index":0,"ref_type":"news","ref_index":38},"pub_date":1759939800.0,"attribution":"www.techradar.com"}]},{"type":"search_result_group","domain":"www.wired.com","entries":[{"type":"search_result","url":"https://www.wired.com/story/google-gemini-calendar-invite-hijack-smart-home","title":"Hackers Hijacked Google's Gemini AI With a Poisoned Calendar Invite to Take Over a Smart Home","snippet":"In a groundbreaking cybersecurity demonstration, researchers in Tel Aviv exploited Google\u2019s Gemini AI using a \u201cpoisoned\u201d Google Calendar invite to take over an internet-connected smart home. By embedding indirect prompt injections into seemingly benign calendar events, the AI was manipulated to trigger actions like turning on lights, opening shutters, and activating a boiler. This exploit was demonstrated as part of 14 novel attacks showcased at the Black Hat cybersecurity conference.\n\nDubbed \u201cInvitation Is All You Need,\u201d the attacks highlight a serious vulnerability in large language models (LLMs) like Gemini, especially as they become agents capable of controlling real-world systems. These prompt injections didn't require user input but were indirectly embedded in calendar invites or document titles, demonstrating the risks of automatic AI decision-making.\n\nDespite no real-world attacks being reported, Google has taken the findings seriously, implementing machine learning-based detection, layered defenses, and increased user confirmations. Still, experts caution that the evolving nature of prompt injections poses an ongoing security challenge. The research underscores the urgent need for robust safeguards as AI becomes increasingly integrated into physical and digital infrastructures.","ref_id":{"turn_index":0,"ref_type":"news","ref_index":40},"pub_date":1754485200.0,"attribution":"www.wired.com"}]}],"safe_urls":["https://arstechnica.com/ai/2026/02/attackers-prompted-gemini-over-100000-times-while-trying-to-clone-it-google-says/","https://blog.google/innovation-and-ai/infrastructure-and-cloud/google-cloud/gtig-report-ai-cyber-attacks-feb-2026/","https://cloud.google.com/blog/topics/threat-intelligence/distillation-experimentation-integration-ai-adversarial-use","https://cloud.google.com/blog/topics/threat-intelligence/threat-actor-usage-of-ai-tools","https://discuss.ai.google.dev/t/paid-ultra-account-auto-banned/122685","https://finance.biggo.com/news/202602122250_Google-Gemini-AI-Model-Cloning-Attack-Blocked","https://timesofindia.indiatimes.com/technology/tech-news/hackers-use-more-than-100000-prompts-to-make-a-google-gemini-clone/articleshow/128254048.cms","https://www.artificialintelligence-news.com/news/state-sponsored-hackers-ai-cyberattacks-google/","https://www.bankinfosecurity.com/state-hackers-turn-google-ai-into-attack-acceleration-tool-a-30751","https://www.csoonline.com/article/4132098/google-fears-massive-attempt-to-clone-gemini-ai-through-model-extraction.html","https://www.eweek.com/news/google-gemini-model-extraction-attacks/","https://www.gend.co/blog/gemini-model-extraction-attacks","https://www.infosecurity-magazine.com/news/nation-state-hackers-gemini-ai/","https://www.instagram.com/p/DUyOUmQEkRs/","https://www.itpro.com/technology/artificial-intelligence/google-says-hacker-groups-are-using-gemini-to-augment-attacks-and-companies-are-even-stealing-its-models","https://www.linkedin.com/news/story/googles-gemini-faces-surge-in-model-extraction-attacks-8405602/","https://www.linkedin.com/posts/asteris-ai_hackers-use-more-than-100000-prompts-to-activity-7427711427148283904-Rm1v","https://www.linkedin.com/posts/srivalli-jeenu-4613322bb_aisecurity-cybersecurity-googlegemini-activity-7427644970091630592-U0iO","https://www.moneycontrol.com/technology/hackers-created-google-gemini-clone-using-100-000-prompts-here-s-how-google-stopped-it-article-13825539.html","https://www.techradar.com/pro/security/google-says-it-wont-fix-this-potentially-concerning-gemini-security-issue","https://www.wired.com/story/google-gemini-calendar-invite-hijack-smart-home"],"can_save":true},"recipient":"all","channel":null},"parent":"19fa00af-9634-4ea6-ae3a-30d98c93d363","children":["39d0ad29-ed75-4616-9c88-1ce2c4766a8c"]},"39d0ad29-ed75-4616-9c88-1ce2c4766a8c":{"id":"39d0ad29-ed75-4616-9c88-1ce2c4766a8c","message":{"id":"39d0ad29-ed75-4616-9c88-1ce2c4766a8c","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1771304233.750929,"update_time":null,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"{\"search_query\":[{\"q\":\"model extraction attack machine learning Tramer 2016 stealing machine learning models via prediction APIs\",\"recency\":3650},{\"q\":\"knowledge distillation Hinton 2015 student teacher model distillation paper\",\"recency\":3650},{\"q\":\"black-box model extraction attacks survey 2020 2021\",\"recency\":3650},{\"q\":\"logit stealing distillation attack paper 2020\",\"recency\":3650}],\"response_length\":\"short\"}"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"citations":[],"content_references":[],"resolved_model_slug":"gpt-5-2-auto-thinking","model_slug":"gpt-5-2-thinking","hide_inline_actions":true,"disable_turn_actions":true,"request_id":"4c4f4702-b3c5-4ef6-b23c-35bf3cc0f0a6","message_type":"next","default_model_slug":"gpt-5-2","parent_id":"e5541e9c-8246-4958-826f-a64749bd5830","turn_exchange_id":"0e5bf703-39b2-4408-9740-c57ef23965da","reasoning_status":"is_reasoning","search_queries":[{"type":"search","q":"model extraction attack machine learning Tramer 2016 stealing machine learning models via prediction APIs"},{"type":"search","q":"knowledge distillation Hinton 2015 student teacher model distillation paper"},{"type":"search","q":"black-box model extraction attacks survey 2020 2021"},{"type":"search","q":"logit stealing distillation attack paper 2020"}],"search_display_string":"Searching the web...","searched_display_string":"Searched the web...","reasoning_title":"Searching for model extraction and knowledge distillation sources","classifier_response":"default","can_save":true},"recipient":"web.run","channel":null},"parent":"d49b1756-00f4-4611-9a7b-db78b00ce5e1","children":["deec49d6-12a4-4091-90e1-854aea55d725"]},"deec49d6-12a4-4091-90e1-854aea55d725":{"id":"deec49d6-12a4-4091-90e1-854aea55d725","message":{"id":"deec49d6-12a4-4091-90e1-854aea55d725","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1771304238.3107195,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_model_queries":{"type":"search_model_queries","queries":["model extraction attack machine learning Tramer 2016 stealing machine learning models via prediction APIs","knowledge distillation Hinton 2015 student teacher model distillation paper","black-box model extraction attacks survey 2020 2021","logit stealing distillation attack paper 2020"]},"model_slug":"gpt-5-2-thinking","hide_inline_actions":true,"disable_turn_actions":true,"request_id":"4c4f4702-b3c5-4ef6-b23c-35bf3cc0f0a6","message_type":"next","default_model_slug":"gpt-5-2","parent_id":"e7f1f419-2121-437a-9c06-8063a3c49d46","turn_exchange_id":"0e5bf703-39b2-4408-9740-c57ef23965da","reasoning_status":"is_reasoning","reasoning_title":"Searching for model extraction and knowledge distillation sources","classifier_response":"default","can_save":false},"recipient":"all","channel":null},"parent":"39d0ad29-ed75-4616-9c88-1ce2c4766a8c","children":["6f24edb6-cf71-48d2-afb0-b3591cf7be1b"]},"6f24edb6-cf71-48d2-afb0-b3591cf7be1b":{"id":"6f24edb6-cf71-48d2-afb0-b3591cf7be1b","message":{"id":"6f24edb6-cf71-48d2-afb0-b3591cf7be1b","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1771304238.307693,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_result_groups":[{"type":"search_result_group","domain":"arxiv.org","entries":[{"type":"search_result","url":"https://arxiv.org/abs/1609.02943","title":"Stealing Machine Learning Models via Prediction APIs","snippet":"","ref_id":{"turn_index":3,"ref_type":"search","ref_index":0},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/1503.02531","title":"[1503.02531] Distilling the Knowledge in a Neural Network","snippet":"by G Hinton \u00b7 2015 \u00b7 Cited by 29944 \u2014 We show that we can significantly improve the acoustic model of a heavily used commercial system by distilling the knowledge in an ensemble of models into a ...Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2502.16065v1","title":"A Survey of Model Extraction Attacks and Defenses ...","snippet":"22 Feb 2025 \u2014 In our survey, we classify extraction attacks based on the adversary's knowledge. In cloud computing, attacks are predominantly black-box, ...Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2403.05181v1","title":"Adversarial Sparse Teacher: Defense Against Distillation ...","snippet":"8 Mar 2024 \u2014 We introduce Adversarial Sparse Teacher (AST), a novel methodology that leverages adversarial examples, sparse logits, and a unique loss ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"arxiv.org"}]},{"type":"search_result_group","domain":"www.usenix.org","entries":[{"type":"search_result","url":"https://www.usenix.org/system/files/conference/usenixsecurity16/sec16_paper_tramer.pdf","title":"Stealing Machine Learning Models via Prediction APIs","snippet":"by F Tram\u00e8r \u00b7 2016 \u00b7 Cited by 2809 \u2014 An adversary uses q prediction queries to extract an \u02c6f \u2248 f. 3 Model Extraction Attacks. An ML model extraction attack arises when an adversary.Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":4},"pub_date":1468867884.0,"attribution":"www.usenix.org"}]},{"type":"search_result_group","domain":"www.ibm.com","entries":[{"type":"search_result","url":"https://www.ibm.com/think/topics/knowledge-distillation","title":"What is Knowledge distillation? | IBM","snippet":"Knowledge distillation is a machine learning technique used to transfer the learning of a large pre-trained \u201cteacher model\u201d to a smaller \u201cstudent model.\u201d","ref_id":{"turn_index":3,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"www.ibm.com"}]},{"type":"search_result_group","domain":"dl.acm.org","entries":[{"type":"search_result","url":"https://dl.acm.org/doi/10.1145/3711896.3736573","title":"A Survey on Model Extraction Attacks and Defenses for ...","snippet":"3 Aug 2025 \u2014 This survey provides a comprehensive taxonomy of LLM-specific extraction attacks and defenses, categorizing attacks into functionality ...Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"dl.acm.org"},{"type":"search_result","url":"https://dl.acm.org/doi/10.5555/3241094.3241142","title":"Stealing machine learning models via prediction APIs","snippet":"by F Tram\u00e8r \u00b7 2016 \u00b7 Cited by 2809 \u2014 We show simple, efficient attacks that extract target ML models with near-perfect fidelity for popular model classes including logistic regression, neural ...Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"dl.acm.org"}]},{"type":"search_result_group","domain":"medium.com","entries":[{"type":"search_result","url":"https://medium.com/%40asimadnan/understanding-knowledge-distillation-from-hintons-paper-to-openai-s-mini-models-e5a761b0dc47","title":"Understanding Knowledge Distillation: From Hinton's ...","snippet":"The concept of knowledge distillation emerged in 2015 with Geoffrey Hinton, Oriol Vinyals, and Jeff Dean's influential paper, Distilling the ...Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":9},"pub_date":1738376353.093,"attribution":"medium.com"}]},{"type":"search_result_group","domain":"www.researchgate.net","entries":[{"type":"search_result","url":"https://www.researchgate.net/publication/395277091_A_Comprehensive_Survey_of_Model_Extraction_Attacks_Current_Trends_Defenses_and_Future_Directions","title":"A Comprehensive Survey of Model Extraction Attacks","snippet":"7 Sept 2025 \u2014 A Comprehensive Survey of Model Extraction Attacks: Current Trends, Defenses, and Future Directions. February 2025. DOI:10.1109/SATC65530.Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":10},"pub_date":1740441600.0,"attribution":"www.researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/392054762_Adversarial_Sparse_Teacher_Defense_Against_Distillation-Based_Model_Stealing_Attacks_Using_Adversarial_Examples","title":"(PDF) Adversarial Sparse Teacher: Defense Against ...","snippet":"6 Aug 2025 \u2014 We introduce Adversarial Sparse Teacher (AST), a robust defense method against distillation-based model stealing attacks.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":15},"pub_date":1735689600.0,"attribution":"www.researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/308027534_Stealing_Machine_Learning_Models_via_Prediction_APIs","title":"(PDF) Stealing Machine Learning Models via Prediction APIs","snippet":"10 Aug 2016 \u2014 are used in practice, may be seen as a hyper-parameter. 3 Model Extraction Attacks. An ML model extraction attack arises when an adversary.Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":16},"pub_date":1470787200.0,"attribution":"www.researchgate.net"}]},{"type":"search_result_group","domain":"www.sciencedirect.com","entries":[{"type":"search_result","url":"https://www.sciencedirect.com/science/article/abs/pii/S0306457324004151","title":"A novel knowledge distillation technique by deriving target ...","snippet":"by MI Hossain \u00b7 2025 \u00b7 Cited by 4 \u2014 This paper proposes a novel distillation technique called TALD-KD that performs through Target Augmentation and a novel concept of dynamic Logits Distortion ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"www.sciencedirect.com"}]},{"type":"search_result_group","domain":"www.semanticscholar.org","entries":[{"type":"search_result","url":"https://www.semanticscholar.org/paper/Stealing-Machine-Learning-Models-via-Prediction-Tram%C3%A8r-Zhang/8a95423d0059f7c5b1422f0ef1aa60b9e26aab7e","title":"[PDF] Stealing Machine Learning Models via Prediction APIs","snippet":"Simple, efficient attacks are shown that extract target ML models with near-perfect fidelity for popular model classes including logistic regression, ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"www.semanticscholar.org"}]},{"type":"search_result_group","domain":"neptune.ai","entries":[{"type":"search_result","url":"https://neptune.ai/blog/knowledge-distillation","title":"Knowledge Distillation: Principles, Algorithms, Applications","snippet":"In this scheme, the teacher model is first pre-trained on a training dataset, and then knowledge from the teacher model is distilled to train the student model.Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":13},"pub_date":1658471463.0,"attribution":"neptune.ai"}]},{"type":"search_result_group","domain":"ink.library.smu.edu.sg","entries":[{"type":"search_result","url":"https://ink.library.smu.edu.sg/cgi/viewcontent.cgi?article=9591&context=sis_research","title":"A black-box attack on code models via representation ...","snippet":"by J ZHANG \u00b7 2023 \u00b7 Cited by 17 \u2014 As a result, black-box attack techniques based on variable substitution have emerged as a valuable avenue for research and multiple works have been proposed ...Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"ink.library.smu.edu.sg"}]},{"type":"search_result_group","domain":"www.wired.com","entries":[{"type":"search_result","url":"https://www.wired.com/2016/09/how-to-steal-an-ai","title":"How to Steal an AI","snippet":"The article \u201cHow to Steal an AI\u201d explores the vulnerability of machine learning (ML) systems to model extraction attacks, revealing that even black-box AI models\u2014whose internal workings are hidden\u2014can be reverse-engineered. Researchers from Cornell Tech, EPFL, and the University of North Carolina demonstrated that with only the input/output access provided by public APIs of platforms like Amazon Machine Learning and BigML, attackers can replicate AI models to near-perfect accuracy. By analyzing the model's outputs, especially \"confidence values,\" and training their own models accordingly, the team could reconstruct proprietary algorithms and potentially sensitive training data with only hundreds to a few thousand queries.\n\nThese cloned models not only bypass pay-per-query restrictions but also pose privacy risks and offer exploit paths to attackers targeting systems like spam or malware filters. The research raises ethical and legal concerns around shared AI models and suggests that current defensive measures\u2014like hiding confidence levels\u2014may be insufficient for more complex systems. Critics note the attacked models are relatively simple, but the work underscores growing security implications in ML, particularly regarding proprietary AI and sensitive data reconstructions, like facial recognition models. The research hints that machine learning systems might need stronger protections akin to those used in traditional software.","ref_id":{"turn_index":3,"ref_type":"news","ref_index":43},"pub_date":1475247981.0,"attribution":"www.wired.com"}]}],"debug_sonic_thread_id":"thread_6993f5220a34832cb81c86897a6be588","model_slug":"gpt-5-2-thinking","hide_inline_actions":true,"disable_turn_actions":true,"request_id":"4c4f4702-b3c5-4ef6-b23c-35bf3cc0f0a6","message_type":"next","default_model_slug":"gpt-5-2","parent_id":"deec49d6-12a4-4091-90e1-854aea55d725","turn_exchange_id":"0e5bf703-39b2-4408-9740-c57ef23965da","reasoning_status":"is_reasoning","reasoning_title":"Searching for model extraction and knowledge distillation sources","classifier_response":"default","can_save":false},"recipient":"all","channel":null},"parent":"deec49d6-12a4-4091-90e1-854aea55d725","children":["b16ab9f2-8454-4413-b1b3-3d6faa6e3d75"]},"b16ab9f2-8454-4413-b1b3-3d6faa6e3d75":{"id":"b16ab9f2-8454-4413-b1b3-3d6faa6e3d75","message":{"id":"b16ab9f2-8454-4413-b1b3-3d6faa6e3d75","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1771304245.873609,"update_time":null,"content":{"content_type":"reasoning_recap","content":"Thought for 22s"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"reasoning_ended","finished_duration_sec":22,"search_result_groups":[{"type":"search_result_group","domain":"www.itpro.com","entries":[{"type":"search_result","url":"https://www.itpro.com/technology/artificial-intelligence/google-says-hacker-groups-are-using-gemini-to-augment-attacks-and-companies-are-even-stealing-its-models","title":"Google says hacker groups are using Gemini to augment attacks - and companies are even 'stealing' its models","snippet":"A new report from Google Threat Intelligence Group (GTIG) and Google DeepMind reveals that state-backed hacker groups are increasingly utilizing Google's Gemini large language model (LLM) in cyberattacks. Advanced Persistent Threats (APTs) from countries like China, Iran, and North Korea are using Gemini to gather intelligence, craft phishing campaigns, and produce stealthy malware. For instance, Gemini has helped groups create tailored phishing emails, research victims, and plan attacks on IT and cybersecurity firms. One malware, HONESTCUE, uses Gemini to execute code in system memory, avoiding traditional detection methods.\n\nMoreover, threat actors are stealing and misusing Gemini and other public AI models, sometimes repackaging them as proprietary tools for sale on the dark web. GTIG has also observed \u201cmodel extraction\u201d practices where attackers mimic Gemini\u2019s capabilities using knowledge distillation, raising intellectual property concerns. Over 100,000 prompts aimed at replicating Gemini's reasoning were blocked. Google has since disabled compromised assets and cautioned organizations to monitor API usage carefully to prevent abuse and data theft. The report flags AI\u2019s growing role across all stages of cyberattacks and urges vigilance as AI-driven threats gain sophistication.","ref_id":{"turn_index":0,"ref_type":"news","ref_index":26},"pub_date":1770896416.0,"attribution":"www.itpro.com"}]},{"type":"search_result_group","domain":"cloud.google.com","entries":[{"type":"search_result","url":"https://cloud.google.com/blog/topics/threat-intelligence/distillation-experimentation-integration-ai-adversarial-use","title":"GTIG AI Threat Tracker: Distillation, Experimentation, and ...","snippet":"5 days ago \u2014 Google DeepMind and GTIG have identified an increase in model extraction attempts or \"distillation attacks,\" a method of intellectual property ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":1},"pub_date":1770854400.0,"attribution":"cloud.google.com"},{"type":"search_result","url":"https://cloud.google.com/blog/topics/threat-intelligence/threat-actor-usage-of-ai-tools","title":"Advances in Threat Actor Usage of AI Tools","snippet":"5 Nov 2025 \u2014 In this report, Google Threat Intelligence Group (GTIG) presents findings on adversarial misuse of AI, including Gemini and other non-Google ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":18},"pub_date":1762300800.0,"attribution":"cloud.google.com"},{"type":"search_result","url":"https://cloud.google.com/blog/topics/threat-intelligence/distillation-experimentation-integration-ai-adversarial-use","title":"GTIG AI Threat Tracker: Distillation, Experimentation, and (Continued) Integration of AI for Adversarial Use | Google Cloud Blog","snippet":"Total lines: 330\n","ref_id":{"turn_index":1,"ref_type":"view","ref_index":0},"pub_date":null,"attribution":"cloud.google.com"}]},{"type":"search_result_group","domain":"www.gend.co","entries":[{"type":"search_result","url":"https://www.gend.co/blog/gemini-model-extraction-attacks","title":"Gemini Model Extraction Attacks: How 'AI Cloning' Works","snippet":"12 hours ago \u2014 Model extraction (distillation) attacks try to \u201cclone\u201d an AI model by sending large volumes of carefully designed prompts and using the ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"www.gend.co"}]},{"type":"search_result_group","domain":"www.moneycontrol.com","entries":[{"type":"search_result","url":"https://www.moneycontrol.com/technology/hackers-created-google-gemini-clone-using-100-000-prompts-here-s-how-google-stopped-it-article-13825539.html","title":"Hackers created Google Gemini clone using 100000 prompts","snippet":"5 days ago \u2014 Google revealed hackers attempted to clone its Gemini AI using large-scale prompt attacks, prompting new safeguards against model extraction ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"www.moneycontrol.com"}]},{"type":"search_result_group","domain":"blog.google","entries":[{"type":"search_result","url":"https://blog.google/innovation-and-ai/infrastructure-and-cloud/google-cloud/gtig-report-ai-cyber-attacks-feb-2026/","title":"Google Threat Intelligence Group reports on AI threat trends","snippet":"5 days ago \u2014 We've also strengthened both our security controls and Gemini models against misuse. Read the full report on the Google Cloud Threat ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":4},"pub_date":1770854400.0,"attribution":"blog.google"}]},{"type":"search_result_group","domain":"www.linkedin.com","entries":[{"type":"search_result","url":"https://www.linkedin.com/news/story/googles-gemini-faces-surge-in-model-extraction-attacks-8405602/","title":"Google's Gemini faces surge in model extraction attacks","snippet":"4 days ago \u2014 The headline finding: \"distillation attacks\" are surging, where adversaries use legitimate API access to systematically extract proprietary ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":5},"pub_date":1771010175.421,"attribution":"www.linkedin.com"},{"type":"search_result","url":"https://www.linkedin.com/posts/asteris-ai_hackers-use-more-than-100000-prompts-to-activity-7427711427148283904-Rm1v","title":"Google Issues Warning on AI Model Extraction Threats","snippet":"They're trying to reverse-engineer its reasoning. They flood the model with queries to map its internal logic and patterns. The objective is ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":8},"pub_date":1770904404.42,"attribution":"www.linkedin.com"},{"type":"search_result","url":"https://www.linkedin.com/posts/srivalli-jeenu-4613322bb_aisecurity-cybersecurity-googlegemini-activity-7427644970091630592-U0iO","title":"Google's Gemini AI Model Hacked Over 100000 Times","snippet":"... distillation attack' where commercially motivated actors flooded Gemini with queries. Their goal? To reverse-engineer its reasoning and ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":17},"pub_date":1770888559.824,"attribution":"www.linkedin.com"}]},{"type":"search_result_group","domain":"arstechnica.com","entries":[{"type":"search_result","url":"https://arstechnica.com/ai/2026/02/attackers-prompted-gemini-over-100000-times-while-trying-to-clone-it-google-says/","title":"Attackers prompted Gemini over 100000 times while trying ...","snippet":"4 days ago \u2014 Attackers prompted Gemini over 100,000 times while trying to clone it, Google says. Distillation technique lets copycats mimic Gemini at a ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"arstechnica.com"}]},{"type":"search_result_group","domain":"www.artificialintelligence-news.com","entries":[{"type":"search_result","url":"https://www.artificialintelligence-news.com/news/state-sponsored-hackers-ai-cyberattacks-google/","title":"Google identifies state-sponsored hackers using AI in attacks","snippet":"5 days ago \u2014 One campaign targeting Gemini's reasoning abilities involved the collation and use of over 100,000 prompts designed to coerce the model into ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":7},"pub_date":1770886800.0,"attribution":"www.artificialintelligence-news.com"}]},{"type":"search_result_group","domain":"www.infosecurity-magazine.com","entries":[{"type":"search_result","url":"https://www.infosecurity-magazine.com/news/nation-state-hackers-gemini-ai/","title":"Nation-State Hackers Embrace Gemini AI for Malicious ...","snippet":"5 days ago \u2014 Google researchers found that government-backed hackers now use AI throughout the whole attack lifecycle.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"www.infosecurity-magazine.com"}]},{"type":"search_result_group","domain":"finance.biggo.com","entries":[{"type":"search_result","url":"https://finance.biggo.com/news/202602122250_Google-Gemini-AI-Model-Cloning-Attack-Blocked","title":"Google Thwarts Major AI Model Theft Attempt: Attackers Flood ...","snippet":"4 days ago \u2014 This was not a traditional data breach but a calculated \"distillation\" or \"model-extraction\" attempt. The goal was to systematically query the ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"finance.biggo.com"}]},{"type":"search_result_group","domain":"timesofindia.indiatimes.com","entries":[{"type":"search_result","url":"https://timesofindia.indiatimes.com/technology/tech-news/hackers-use-more-than-100000-prompts-to-make-a-google-gemini-clone/articleshow/128254048.cms","title":"Hackers use more than 100000 prompts to make a Google ...","snippet":"5 days ago \u2014 Many of the attacks were crafted to tease out the algorithms that help Gemini \"reason\", or decide how to process information, Google said.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":11},"pub_date":1770893580.0,"attribution":"timesofindia.indiatimes.com"}]},{"type":"search_result_group","domain":"www.instagram.com","entries":[{"type":"search_result","url":"https://www.instagram.com/p/DUyOUmQEkRs/","title":"Google says attackers launched a large-scale \u201cdistillation ...","snippet":"One instance involved adversaries using over 100,000 generated prompts to systematically probe the model, a technique known as model extraction.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"www.instagram.com"}]},{"type":"search_result_group","domain":"www.csoonline.com","entries":[{"type":"search_result","url":"https://www.csoonline.com/article/4132098/google-fears-massive-attempt-to-clone-gemini-ai-through-model-extraction.html","title":"Google fears massive attempt to clone Gemini AI ... - CSO Online","snippet":"4 days ago \u2014 The company identified over 100000 prompts it suspects were intended to extract proprietary reasoning capabilities.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":13},"pub_date":1770940800.0,"attribution":"www.csoonline.com"}]},{"type":"search_result_group","domain":"www.eweek.com","entries":[{"type":"search_result","url":"https://www.eweek.com/news/google-gemini-model-extraction-attacks/","title":"Hackers Try to Clone Google's Gemini With 100000+ AI ...","snippet":"3 days ago \u2014 Google says threat actors launched 100000+ model extraction attacks against Gemini, attempting to reverse engineer its AI logic and training ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":14},"pub_date":1771001352.0,"attribution":"www.eweek.com"}]},{"type":"search_result_group","domain":"discuss.ai.google.dev","entries":[{"type":"search_result","url":"https://discuss.ai.google.dev/t/paid-ultra-account-auto-banned/122685","title":"Paid Ultra Account Auto-Banned - Google Antigravity","snippet":"5 days ago \u2014 No Reverse Engineering. Customer will not, and will not allow End Users to, reverse engineer or extract any components of an AI/ML Service ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":15},"pub_date":1770897219.0,"attribution":"discuss.ai.google.dev"}]},{"type":"search_result_group","domain":"www.bankinfosecurity.com","entries":[{"type":"search_result","url":"https://www.bankinfosecurity.com/state-hackers-turn-google-ai-into-attack-acceleration-tool-a-30751","title":"State Hackers Turn Google AI Into Attack Acceleration Tool","snippet":"3 days ago \u2014 In one case, more than 100,000 prompts attempted to coerce Gemini into outputting full reasoning processes. The breadth of questions ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"www.bankinfosecurity.com"}]},{"type":"search_result_group","domain":"www.techradar.com","entries":[{"type":"search_result","url":"https://www.techradar.com/pro/security/google-says-it-wont-fix-this-potentially-concerning-gemini-security-issue","title":"Google says it won't fix this potentially concerning Gemini security issue","snippet":"Google has declined to fix a recently discovered security concern in its Gemini AI tool, identified as an \"ASCII smuggling attack.\" Security researcher Viktor Markopoulos demonstrated how attackers can embed hidden malicious prompts within emails using invisible text formatting (e.g., white font on a white background or font size 0). When a user asks Gemini\u2014now integrated into Google Workspace tools such as Gmail, Docs, and Sheets\u2014to summarize the content of such an email, the AI interprets and executes the concealed instructions. These commands could include phishing messages or even directives to extract sensitive data.\n\nGoogle, however, argues that this threat constitutes social engineering rather than a true security flaw and sees the issue as the user's responsibility. The lack of a fix raises concerns due to the increasing automation and integration of AI tools, which may unwittingly execute harmful actions based on hidden instructions smuggled within benign-looking content.","ref_id":{"turn_index":0,"ref_type":"news","ref_index":38},"pub_date":1759939800.0,"attribution":"www.techradar.com"}]},{"type":"search_result_group","domain":"www.wired.com","entries":[{"type":"search_result","url":"https://www.wired.com/story/google-gemini-calendar-invite-hijack-smart-home","title":"Hackers Hijacked Google's Gemini AI With a Poisoned Calendar Invite to Take Over a Smart Home","snippet":"In a groundbreaking cybersecurity demonstration, researchers in Tel Aviv exploited Google\u2019s Gemini AI using a \u201cpoisoned\u201d Google Calendar invite to take over an internet-connected smart home. By embedding indirect prompt injections into seemingly benign calendar events, the AI was manipulated to trigger actions like turning on lights, opening shutters, and activating a boiler. This exploit was demonstrated as part of 14 novel attacks showcased at the Black Hat cybersecurity conference.\n\nDubbed \u201cInvitation Is All You Need,\u201d the attacks highlight a serious vulnerability in large language models (LLMs) like Gemini, especially as they become agents capable of controlling real-world systems. These prompt injections didn't require user input but were indirectly embedded in calendar invites or document titles, demonstrating the risks of automatic AI decision-making.\n\nDespite no real-world attacks being reported, Google has taken the findings seriously, implementing machine learning-based detection, layered defenses, and increased user confirmations. Still, experts caution that the evolving nature of prompt injections poses an ongoing security challenge. The research underscores the urgent need for robust safeguards as AI becomes increasingly integrated into physical and digital infrastructures.","ref_id":{"turn_index":0,"ref_type":"news","ref_index":40},"pub_date":1754485200.0,"attribution":"www.wired.com"}]}],"safe_urls":["https://arstechnica.com/ai/2026/02/attackers-prompted-gemini-over-100000-times-while-trying-to-clone-it-google-says/","https://blog.google/innovation-and-ai/infrastructure-and-cloud/google-cloud/gtig-report-ai-cyber-attacks-feb-2026/","https://cloud.google.com/blog/topics/threat-intelligence/distillation-experimentation-integration-ai-adversarial-use","https://cloud.google.com/blog/topics/threat-intelligence/threat-actor-usage-of-ai-tools","https://discuss.ai.google.dev/t/paid-ultra-account-auto-banned/122685","https://finance.biggo.com/news/202602122250_Google-Gemini-AI-Model-Cloning-Attack-Blocked","https://timesofindia.indiatimes.com/technology/tech-news/hackers-use-more-than-100000-prompts-to-make-a-google-gemini-clone/articleshow/128254048.cms","https://www.artificialintelligence-news.com/news/state-sponsored-hackers-ai-cyberattacks-google/","https://www.bankinfosecurity.com/state-hackers-turn-google-ai-into-attack-acceleration-tool-a-30751","https://www.csoonline.com/article/4132098/google-fears-massive-attempt-to-clone-gemini-ai-through-model-extraction.html","https://www.eweek.com/news/google-gemini-model-extraction-attacks/","https://www.gend.co/blog/gemini-model-extraction-attacks","https://www.infosecurity-magazine.com/news/nation-state-hackers-gemini-ai/","https://www.instagram.com/p/DUyOUmQEkRs/","https://www.itpro.com/technology/artificial-intelligence/google-says-hacker-groups-are-using-gemini-to-augment-attacks-and-companies-are-even-stealing-its-models","https://www.linkedin.com/news/story/googles-gemini-faces-surge-in-model-extraction-attacks-8405602/","https://www.linkedin.com/posts/asteris-ai_hackers-use-more-than-100000-prompts-to-activity-7427711427148283904-Rm1v","https://www.linkedin.com/posts/srivalli-jeenu-4613322bb_aisecurity-cybersecurity-googlegemini-activity-7427644970091630592-U0iO","https://www.moneycontrol.com/technology/hackers-created-google-gemini-clone-using-100-000-prompts-here-s-how-google-stopped-it-article-13825539.html","https://www.techradar.com/pro/security/google-says-it-wont-fix-this-potentially-concerning-gemini-security-issue","https://www.wired.com/story/google-gemini-calendar-invite-hijack-smart-home"],"model_slug":"gpt-5-2-thinking","hide_inline_actions":true,"disable_turn_actions":true,"request_id":"4c4f4702-b3c5-4ef6-b23c-35bf3cc0f0a6","message_type":"next","default_model_slug":"gpt-5-2","parent_id":"6f24edb6-cf71-48d2-afb0-b3591cf7be1b","turn_exchange_id":"0e5bf703-39b2-4408-9740-c57ef23965da","can_save":true},"recipient":"all","channel":null},"parent":"6f24edb6-cf71-48d2-afb0-b3591cf7be1b","children":["e407dea3-87b4-4103-87f3-f105e54eceb5"]},"e407dea3-87b4-4103-87f3-f105e54eceb5":{"id":"e407dea3-87b4-4103-87f3-f105e54eceb5","message":{"id":"e407dea3-87b4-4103-87f3-f105e54eceb5","author":{"role":"assistant","name":null,"metadata":{"real_author":"tool:web"}},"create_time":1771304240.35867,"update_time":null,"content":{"content_type":"text","parts":["What you quoted is describing **model extraction** via **knowledge distillation**\u2014Google (DeepMind + Google Threat Intelligence Group) calls these **\u201cdistillation attacks.\u201d** The attacker isn\u2019t \u201chacking in.\u201d They\u2019re **using the model exactly as a normal user would** (via chat/API), but at scale and with carefully chosen prompts, to **clone capabilities** of the target model. \ue200cite\ue202turn1view0\ue201\n\n## What is a \u201cdistillation attack\u201d (in this context)?\nGoogle defines **model extraction attacks (MEA)** as cases where an adversary uses **legitimate access** to systematically probe a deployed model and harvest enough input\u2192output behavior to train a new \u201cstudent\u201d model. They\u2019re called *distillation* attacks because they use **knowledge distillation (KD)**: training a student model to imitate a teacher model\u2019s outputs. \ue200cite\ue202turn1view0\ue202turn3search1\ue201\n\nThis is essentially **capability theft**: reproduce performance without paying the full training cost (data, compute, engineering). \ue200cite\ue202turn1view0\ue201\n\n## How do these attacks work?\nAt a high level, it\u2019s **black-box cloning**:\n\n1. **Get access** to the target model (e.g., Gemini chat or API) like any customer would. \ue200cite\ue202turn1view0\ue201  \n2. **Generate a large prompt set** (often programmatically). The prompts are designed to cover:\n   - many task types (reasoning, coding, summarization, translation, etc.)\n   - many difficulty levels\n   - many languages / domains  \n   The \u201c100,000 prompts\u201d number you quoted is exactly this kind of high-volume coverage. \ue200cite\ue202turn1view0\ue202turn0search16\ue201\n3. **Record outputs** and build a synthetic dataset: `(prompt, model_output)` pairs.\n4. **Train a student model** on those pairs (supervised fine-tuning, or other imitation-style training) so it learns to produce similar outputs given similar prompts. Google explicitly describes this \u201cquery teacher \u2192 supervised fine-tune student\u201d loop. \ue200cite\ue202turn1view0\ue201\n5. **Iterate adaptively**: use the current student\u2019s weaknesses to generate the next round of prompts (active learning / curriculum building), improving cloning efficiency under a query budget. This \u201cadaptive querying\u201d idea is a standard theme in model extraction research. \ue200cite\ue202turn3search0\ue202turn3search2\ue201\n\n### The \u201creasoning trace coercion\u201d twist (Gemini-specific detail)\nGoogle says one common target is Gemini\u2019s **reasoning ability**, and that attackers tried to **coerce \u201cfull reasoning processes\u201d** (i.e., richer intermediate reasoning traces) rather than the usual summarized outputs. In their case study, Google describes:\n- **>100,000 prompts** in one campaign\n- an intent that appeared to be **replicating reasoning in non-English languages across tasks**\n- detection/mitigation in real time to protect internal reasoning traces \ue200cite\ue202turn1view0\ue202turn0search16\ue201\n\nWhy would an attacker want \u201creasoning traces\u201d?\n- If you can extract more detailed intermediate reasoning (even imperfectly), you create **higher-quality training targets** for the student\u2014closer to the teacher\u2019s internal decision process\u2014often improving student performance per query.\n\n## Why this is feasible even if you never see the model\u2019s weights\nThis is not new in principle: **\u201csteal the model through its API\u201d** has been studied for years. Classic extraction work showed that with only query access, attackers can reconstruct models surprisingly well\u2014especially if outputs include richer signals (like confidence scores). \ue200cite\ue202turn3search0\ue202turn3news43\ue201\n\nFor large language models (LLMs), the output is usually \u201cjust text,\u201d but text is still a **very information-rich supervision signal**:\n- it contains *choices, style, heuristics, refusal patterns, tool-use style, formatting habits*\n- and across enough coverage, it approximates the teacher\u2019s behavior distribution\n\n## What it is *not*\n- It\u2019s usually **not** about stealing training data directly (though other attacks aim at that).\n- It\u2019s usually **not** a traditional intrusion/breach.\n- It\u2019s **IP/capability theft** and (sometimes) a way to ship a \u201cGemini-like\u201d product with fewer guardrails. \ue200cite\ue202turn1view0\ue202turn0news26\ue201\n\n## Why \u201c100,000 prompts\u201d makes sense\nCloning broad competence (especially \u201creasoning\u201d) needs:\n- wide task coverage\n- multilingual coverage\n- and enough examples to train robustly\n\nSo attackers tend to run **industrial-scale prompt generation**. Google\u2019s report frames this as a growing pattern from private sector entities and researchers globally. \ue200cite\ue202turn1view0\ue202turn0search13\ue201\n\n## Defenses (what providers do)\nGoogle\u2019s report focuses on detecting and disrupting extraction patterns and hardening models/classifiers. \ue200cite\ue202turn1view0\ue202turn0search4\ue201  \nMore broadly (industry-wide), defenses tend to include:\n- **rate limits / anomaly detection** (high-volume, patterned querying)\n- **output controls** (avoid exposing sensitive internals like detailed reasoning traces)\n- **watermarking / canary behaviors** (harder to prove, but often discussed)\n- **serving-time \u201canti-distillation\u201d tactics** that reduce the value of stolen outputs without hurting normal users too much (an active research area) \ue200cite\ue202turn3search2\ue202turn3search7\ue201\n\n\ue200navlist\ue202Related coverage\ue202turn0news26,turn3news43\ue201"]},"status":"finished_successfully","end_turn":true,"weight":1.0,"metadata":{"content_references":[{"matched_text":"\ue200cite\ue202turn1view0\ue201","start_idx":378,"end_idx":395,"safe_urls":["https://cloud.google.com/blog/topics/threat-intelligence/distillation-experimentation-integration-ai-adversarial-use"],"refs":[],"alt":"([Google Cloud](https://cloud.google.com/blog/topics/threat-intelligence/distillation-experimentation-integration-ai-adversarial-use))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"GTIG AI Threat Tracker: Distillation, Experimentation, and (Continued) Integration of AI for Adversarial Use | Google Cloud Blog","url":"https://cloud.google.com/blog/topics/threat-intelligence/distillation-experimentation-integration-ai-adversarial-use","pub_date":null,"snippet":null,"attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":1,"ref_type":"view","ref_index":0}],"hue":null,"attributions":null,"attribution":"Google Cloud"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn1view0\ue202turn3search1\ue201","start_idx":821,"end_idx":851,"safe_urls":["https://arxiv.org/abs/1503.02531","https://arxiv.org/abs/1503.02531?utm_source=chatgpt.com","https://cloud.google.com/blog/topics/threat-intelligence/distillation-experimentation-integration-ai-adversarial-use"],"refs":[],"alt":"([Google Cloud](https://cloud.google.com/blog/topics/threat-intelligence/distillation-experimentation-integration-ai-adversarial-use))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"GTIG AI Threat Tracker: Distillation, Experimentation, and (Continued) Integration of AI for Adversarial Use | Google Cloud Blog","url":"https://cloud.google.com/blog/topics/threat-intelligence/distillation-experimentation-integration-ai-adversarial-use","pub_date":null,"snippet":null,"attribution_segments":null,"supporting_websites":[{"title":"[1503.02531] Distilling the Knowledge in a Neural Network","url":"https://arxiv.org/abs/1503.02531?utm_source=chatgpt.com","pub_date":null,"snippet":"by G Hinton \u00b7 2015 \u00b7 Cited by 29944 \u2014 We show that we can significantly improve the acoustic model of a heavily used commercial system by distilling the knowledge in an ensemble of models into a ...Read more","attribution":"arXiv"}],"refs":[{"turn_index":1,"ref_type":"view","ref_index":0},{"turn_index":3,"ref_type":"search","ref_index":1}],"hue":null,"attributions":null,"attribution":"Google Cloud"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn1view0\ue201","start_idx":985,"end_idx":1002,"safe_urls":["https://cloud.google.com/blog/topics/threat-intelligence/distillation-experimentation-integration-ai-adversarial-use"],"refs":[],"alt":"([Google Cloud](https://cloud.google.com/blog/topics/threat-intelligence/distillation-experimentation-integration-ai-adversarial-use))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"GTIG AI Threat Tracker: Distillation, Experimentation, and (Continued) Integration of AI for Adversarial Use | Google Cloud Blog","url":"https://cloud.google.com/blog/topics/threat-intelligence/distillation-experimentation-integration-ai-adversarial-use","pub_date":null,"snippet":null,"attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":1,"ref_type":"view","ref_index":0}],"hue":null,"attributions":null,"attribution":"Google Cloud"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn1view0\ue201","start_idx":1170,"end_idx":1187,"safe_urls":["https://cloud.google.com/blog/topics/threat-intelligence/distillation-experimentation-integration-ai-adversarial-use"],"refs":[],"alt":"([Google Cloud](https://cloud.google.com/blog/topics/threat-intelligence/distillation-experimentation-integration-ai-adversarial-use))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"GTIG AI Threat Tracker: Distillation, Experimentation, and (Continued) Integration of AI for Adversarial Use | Google Cloud Blog","url":"https://cloud.google.com/blog/topics/threat-intelligence/distillation-experimentation-integration-ai-adversarial-use","pub_date":null,"snippet":null,"attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":1,"ref_type":"view","ref_index":0}],"hue":null,"attributions":null,"attribution":"Google Cloud"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn1view0\ue202turn0search16\ue201","start_idx":1510,"end_idx":1541,"safe_urls":["https://cloud.google.com/blog/topics/threat-intelligence/distillation-experimentation-integration-ai-adversarial-use","https://www.bankinfosecurity.com/state-hackers-turn-google-ai-into-attack-acceleration-tool-a-30751","https://www.bankinfosecurity.com/state-hackers-turn-google-ai-into-attack-acceleration-tool-a-30751?utm_source=chatgpt.com"],"refs":[],"alt":"([Google Cloud](https://cloud.google.com/blog/topics/threat-intelligence/distillation-experimentation-integration-ai-adversarial-use))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"GTIG AI Threat Tracker: Distillation, Experimentation, and (Continued) Integration of AI for Adversarial Use | Google Cloud Blog","url":"https://cloud.google.com/blog/topics/threat-intelligence/distillation-experimentation-integration-ai-adversarial-use","pub_date":null,"snippet":null,"attribution_segments":null,"supporting_websites":[{"title":"State Hackers Turn Google AI Into Attack Acceleration Tool","url":"https://www.bankinfosecurity.com/state-hackers-turn-google-ai-into-attack-acceleration-tool-a-30751?utm_source=chatgpt.com","pub_date":null,"snippet":"3 days ago \u2014 In one case, more than 100,000 prompts attempted to coerce Gemini into outputting full reasoning processes. The breadth of questions ...Read more","attribution":"BankInfoSecurity"}],"refs":[{"turn_index":1,"ref_type":"view","ref_index":0},{"turn_index":0,"ref_type":"search","ref_index":16}],"hue":null,"attributions":null,"attribution":"Google Cloud"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn1view0\ue201","start_idx":1880,"end_idx":1897,"safe_urls":["https://cloud.google.com/blog/topics/threat-intelligence/distillation-experimentation-integration-ai-adversarial-use"],"refs":[],"alt":"([Google Cloud](https://cloud.google.com/blog/topics/threat-intelligence/distillation-experimentation-integration-ai-adversarial-use))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"GTIG AI Threat Tracker: Distillation, Experimentation, and (Continued) Integration of AI for Adversarial Use | Google Cloud Blog","url":"https://cloud.google.com/blog/topics/threat-intelligence/distillation-experimentation-integration-ai-adversarial-use","pub_date":null,"snippet":null,"attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":1,"ref_type":"view","ref_index":0}],"hue":null,"attributions":null,"attribution":"Google Cloud"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn3search0\ue202turn3search2\ue201","start_idx":2172,"end_idx":2204,"safe_urls":["https://arxiv.org/abs/1609.02943","https://arxiv.org/abs/1609.02943?utm_source=chatgpt.com","https://arxiv.org/html/2502.16065v1","https://arxiv.org/html/2502.16065v1?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/1609.02943?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Stealing Machine Learning Models via Prediction APIs","url":"https://arxiv.org/abs/1609.02943?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[{"title":"A Survey of Model Extraction Attacks and Defenses ...","url":"https://arxiv.org/html/2502.16065v1?utm_source=chatgpt.com","pub_date":null,"snippet":"22 Feb 2025 \u2014 In our survey, we classify extraction attacks based on the adversary's knowledge. In cloud computing, attacks are predominantly black-box, ...Read more","attribution":"arXiv"}],"refs":[{"turn_index":3,"ref_type":"search","ref_index":0},{"turn_index":3,"ref_type":"search","ref_index":2}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn1view0\ue202turn0search16\ue201","start_idx":2737,"end_idx":2768,"safe_urls":["https://cloud.google.com/blog/topics/threat-intelligence/distillation-experimentation-integration-ai-adversarial-use","https://www.bankinfosecurity.com/state-hackers-turn-google-ai-into-attack-acceleration-tool-a-30751","https://www.bankinfosecurity.com/state-hackers-turn-google-ai-into-attack-acceleration-tool-a-30751?utm_source=chatgpt.com"],"refs":[],"alt":"([Google Cloud](https://cloud.google.com/blog/topics/threat-intelligence/distillation-experimentation-integration-ai-adversarial-use))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"GTIG AI Threat Tracker: Distillation, Experimentation, and (Continued) Integration of AI for Adversarial Use | Google Cloud Blog","url":"https://cloud.google.com/blog/topics/threat-intelligence/distillation-experimentation-integration-ai-adversarial-use","pub_date":null,"snippet":null,"attribution_segments":null,"supporting_websites":[{"title":"State Hackers Turn Google AI Into Attack Acceleration Tool","url":"https://www.bankinfosecurity.com/state-hackers-turn-google-ai-into-attack-acceleration-tool-a-30751?utm_source=chatgpt.com","pub_date":null,"snippet":"3 days ago \u2014 In one case, more than 100,000 prompts attempted to coerce Gemini into outputting full reasoning processes. The breadth of questions ...Read more","attribution":"BankInfoSecurity"}],"refs":[{"turn_index":1,"ref_type":"view","ref_index":0},{"turn_index":0,"ref_type":"search","ref_index":16}],"hue":null,"attributions":null,"attribution":"Google Cloud"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn3search0\ue202turn3news43\ue201","start_idx":3400,"end_idx":3431,"safe_urls":["https://arxiv.org/abs/1609.02943","https://arxiv.org/abs/1609.02943?utm_source=chatgpt.com","https://www.wired.com/2016/09/how-to-steal-an-ai","https://www.wired.com/2016/09/how-to-steal-an-ai?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/1609.02943?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Stealing Machine Learning Models via Prediction APIs","url":"https://arxiv.org/abs/1609.02943?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[{"title":"How to Steal an AI","url":"https://www.wired.com/2016/09/how-to-steal-an-ai?utm_source=chatgpt.com","pub_date":null,"snippet":"The article \u201cHow to Steal an AI\u201d explores the vulnerability of machine learning (ML) systems to model extraction attacks, revealing that even black-box AI models\u2014whose internal workings are hidden\u2014can be reverse-engineered. Researchers from Cornell Tech, EPFL, and the University of North Carolina demonstrated that with only the input/output access provided by public APIs of platforms like Amazon Machine Learning and BigML, attackers can replicate AI models to near-perfect accuracy. By analyzing the model's outputs, especially \"confidence values,\" and training their own models accordingly, the team could reconstruct proprietary algorithms and potentially sensitive training data with only hundreds to a few thousand queries.\n\nThese cloned models not only bypass pay-per-query restrictions but also pose privacy risks and offer exploit paths to attackers targeting systems like spam or malware filters. The research raises ethical and legal concerns around shared AI models and suggests that current defensive measures\u2014like hiding confidence levels\u2014may be insufficient for more complex systems. Critics note the attacked models are relatively simple, but the work underscores growing security implications in ML, particularly regarding proprietary AI and sensitive data reconstructions, like facial recognition models. The research hints that machine learning systems might need stronger protections akin to those used in traditional software.","attribution":"WIRED"}],"refs":[{"turn_index":3,"ref_type":"search","ref_index":0},{"turn_index":3,"ref_type":"news","ref_index":43}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn1view0\ue202turn0news26\ue201","start_idx":4027,"end_idx":4056,"safe_urls":["https://cloud.google.com/blog/topics/threat-intelligence/distillation-experimentation-integration-ai-adversarial-use","https://www.itpro.com/technology/artificial-intelligence/google-says-hacker-groups-are-using-gemini-to-augment-attacks-and-companies-are-even-stealing-its-models","https://www.itpro.com/technology/artificial-intelligence/google-says-hacker-groups-are-using-gemini-to-augment-attacks-and-companies-are-even-stealing-its-models?utm_source=chatgpt.com"],"refs":[],"alt":"([Google Cloud](https://cloud.google.com/blog/topics/threat-intelligence/distillation-experimentation-integration-ai-adversarial-use))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"GTIG AI Threat Tracker: Distillation, Experimentation, and (Continued) Integration of AI for Adversarial Use | Google Cloud Blog","url":"https://cloud.google.com/blog/topics/threat-intelligence/distillation-experimentation-integration-ai-adversarial-use","pub_date":null,"snippet":null,"attribution_segments":null,"supporting_websites":[{"title":"Google says hacker groups are using Gemini to augment attacks - and companies are even 'stealing' its models","url":"https://www.itpro.com/technology/artificial-intelligence/google-says-hacker-groups-are-using-gemini-to-augment-attacks-and-companies-are-even-stealing-its-models?utm_source=chatgpt.com","pub_date":null,"snippet":"A new report from Google Threat Intelligence Group (GTIG) and Google DeepMind reveals that state-backed hacker groups are increasingly utilizing Google's Gemini large language model (LLM) in cyberattacks. Advanced Persistent Threats (APTs) from countries like China, Iran, and North Korea are using Gemini to gather intelligence, craft phishing campaigns, and produce stealthy malware. For instance, Gemini has helped groups create tailored phishing emails, research victims, and plan attacks on IT and cybersecurity firms. One malware, HONESTCUE, uses Gemini to execute code in system memory, avoiding traditional detection methods.\n\nMoreover, threat actors are stealing and misusing Gemini and other public AI models, sometimes repackaging them as proprietary tools for sale on the dark web. GTIG has also observed \u201cmodel extraction\u201d practices where attackers mimic Gemini\u2019s capabilities using knowledge distillation, raising intellectual property concerns. Over 100,000 prompts aimed at replicating Gemini's reasoning were blocked. Google has since disabled compromised assets and cautioned organizations to monitor API usage carefully to prevent abuse and data theft. The report flags AI\u2019s growing role across all stages of cyberattacks and urges vigilance as AI-driven threats gain sophistication.","attribution":"IT Pro"}],"refs":[{"turn_index":1,"ref_type":"view","ref_index":0},{"turn_index":0,"ref_type":"news","ref_index":26}],"hue":null,"attributions":null,"attribution":"Google Cloud"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn1view0\ue202turn0search13\ue201","start_idx":4407,"end_idx":4438,"safe_urls":["https://cloud.google.com/blog/topics/threat-intelligence/distillation-experimentation-integration-ai-adversarial-use","https://www.csoonline.com/article/4132098/google-fears-massive-attempt-to-clone-gemini-ai-through-model-extraction.html","https://www.csoonline.com/article/4132098/google-fears-massive-attempt-to-clone-gemini-ai-through-model-extraction.html?utm_source=chatgpt.com"],"refs":[],"alt":"([Google Cloud](https://cloud.google.com/blog/topics/threat-intelligence/distillation-experimentation-integration-ai-adversarial-use))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"GTIG AI Threat Tracker: Distillation, Experimentation, and (Continued) Integration of AI for Adversarial Use | Google Cloud Blog","url":"https://cloud.google.com/blog/topics/threat-intelligence/distillation-experimentation-integration-ai-adversarial-use","pub_date":null,"snippet":null,"attribution_segments":null,"supporting_websites":[{"title":"Google fears massive attempt to clone Gemini AI ... - CSO Online","url":"https://www.csoonline.com/article/4132098/google-fears-massive-attempt-to-clone-gemini-ai-through-model-extraction.html?utm_source=chatgpt.com","pub_date":null,"snippet":"4 days ago \u2014 The company identified over 100000 prompts it suspects were intended to extract proprietary reasoning capabilities.","attribution":"CSO Online"}],"refs":[{"turn_index":1,"ref_type":"view","ref_index":0},{"turn_index":0,"ref_type":"search","ref_index":13}],"hue":null,"attributions":null,"attribution":"Google Cloud"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn1view0\ue202turn0search4\ue201","start_idx":4578,"end_idx":4608,"safe_urls":["https://blog.google/innovation-and-ai/infrastructure-and-cloud/google-cloud/gtig-report-ai-cyber-attacks-feb-2026/","https://blog.google/innovation-and-ai/infrastructure-and-cloud/google-cloud/gtig-report-ai-cyber-attacks-feb-2026/?utm_source=chatgpt.com","https://cloud.google.com/blog/topics/threat-intelligence/distillation-experimentation-integration-ai-adversarial-use"],"refs":[],"alt":"([Google Cloud](https://cloud.google.com/blog/topics/threat-intelligence/distillation-experimentation-integration-ai-adversarial-use))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"GTIG AI Threat Tracker: Distillation, Experimentation, and (Continued) Integration of AI for Adversarial Use | Google Cloud Blog","url":"https://cloud.google.com/blog/topics/threat-intelligence/distillation-experimentation-integration-ai-adversarial-use","pub_date":null,"snippet":null,"attribution_segments":null,"supporting_websites":[{"title":"Google Threat Intelligence Group reports on AI threat trends","url":"https://blog.google/innovation-and-ai/infrastructure-and-cloud/google-cloud/gtig-report-ai-cyber-attacks-feb-2026/?utm_source=chatgpt.com","pub_date":null,"snippet":"5 days ago \u2014 We've also strengthened both our security controls and Gemini models against misuse. Read the full report on the Google Cloud Threat ...Read more","attribution":"blog.google"}],"refs":[{"turn_index":1,"ref_type":"view","ref_index":0},{"turn_index":0,"ref_type":"search","ref_index":4}],"hue":null,"attributions":null,"attribution":"Google Cloud"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn3search2\ue202turn3search7\ue201","start_idx":5057,"end_idx":5089,"safe_urls":["https://arxiv.org/html/2403.05181v1","https://arxiv.org/html/2403.05181v1?utm_source=chatgpt.com","https://arxiv.org/html/2502.16065v1","https://arxiv.org/html/2502.16065v1?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/html/2502.16065v1?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"A Survey of Model Extraction Attacks and Defenses ...","url":"https://arxiv.org/html/2502.16065v1?utm_source=chatgpt.com","pub_date":null,"snippet":"22 Feb 2025 \u2014 In our survey, we classify extraction attacks based on the adversary's knowledge. In cloud computing, attacks are predominantly black-box, ...Read more","attribution_segments":null,"supporting_websites":[{"title":"Adversarial Sparse Teacher: Defense Against Distillation ...","url":"https://arxiv.org/html/2403.05181v1?utm_source=chatgpt.com","pub_date":null,"snippet":"8 Mar 2024 \u2014 We introduce Adversarial Sparse Teacher (AST), a novel methodology that leverages adversarial examples, sparse logits, and a unique loss ...","attribution":"arXiv"}],"refs":[{"turn_index":3,"ref_type":"search","ref_index":2},{"turn_index":3,"ref_type":"search","ref_index":7}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200navlist\ue202Related coverage\ue202turn0news26,turn3news43\ue201","start_idx":5091,"end_idx":5141,"safe_urls":["https://images.openai.com/static-rsc-1/7gemLXIcHOeBC0g4oXCJht0UcMmcZeEJXWrrnNOOF8MQE0LhC5XlvMNTf2VUglebUr5DqvJm_nyyYuFrO4CvMxyi14tt0hnVjzt9bN8AnkYhfd0D1GeJm0PzEwBp-l-1","https://www.itpro.com/technology/artificial-intelligence/google-says-hacker-groups-are-using-gemini-to-augment-attacks-and-companies-are-even-stealing-its-models","https://www.itpro.com/technology/artificial-intelligence/google-says-hacker-groups-are-using-gemini-to-augment-attacks-and-companies-are-even-stealing-its-models?utm_source=chatgpt.com","https://www.wired.com/2016/09/how-to-steal-an-ai","https://www.wired.com/2016/09/how-to-steal-an-ai?utm_source=chatgpt.com"],"refs":[{"turn_index":0,"ref_type":"news","ref_index":26},{"turn_index":3,"ref_type":"news","ref_index":43}],"alt":"- [IT Pro](https://www.itpro.com/technology/artificial-intelligence/google-says-hacker-groups-are-using-gemini-to-augment-attacks-and-companies-are-even-stealing-its-models?utm_source=chatgpt.com)\n- [WIRED](https://www.wired.com/2016/09/how-to-steal-an-ai?utm_source=chatgpt.com)","prompt_text":"\nnavlist containing the following URLs:\n- [Google says hacker groups are using Gemini to augment attacks - and companies are even 'stealing' its models](https://www.itpro.com/technology/artificial-intelligence/google-says-hacker-groups-are-using-gemini-to-augment-attacks-and-companies-are-even-stealing-its-models?utm_source=chatgpt.com)\n- [How to Steal an AI](https://www.wired.com/2016/09/how-to-steal-an-ai?utm_source=chatgpt.com)\n","type":"nav_list","title":"Related coverage","items":[{"title":"Google says hacker groups are using Gemini to augment attacks - and companies are even 'stealing' its models","url":"https://www.itpro.com/technology/artificial-intelligence/google-says-hacker-groups-are-using-gemini-to-augment-attacks-and-companies-are-even-stealing-its-models?utm_source=chatgpt.com","thumbnail_url":"https://images.openai.com/static-rsc-1/7gemLXIcHOeBC0g4oXCJht0UcMmcZeEJXWrrnNOOF8MQE0LhC5XlvMNTf2VUglebUr5DqvJm_nyyYuFrO4CvMxyi14tt0hnVjzt9bN8AnkYhfd0D1GeJm0PzEwBp-l-1","pub_date":1770896416.0,"attribution":"IT Pro"},{"title":"How to Steal an AI","url":"https://www.wired.com/2016/09/how-to-steal-an-ai?utm_source=chatgpt.com","thumbnail_url":null,"pub_date":1475247981.0,"attribution":"WIRED"}],"user_time_zone":"Asia/Singapore"},{"matched_text":" ","start_idx":5141,"end_idx":5141,"safe_urls":[],"refs":[],"alt":"","prompt_text":null,"type":"sources_footnote","sources":[{"title":"GTIG AI Threat Tracker: Distillation, Experimentation, and (Continued) Integration of AI for Adversarial Use | Google Cloud Blog","url":"https://cloud.google.com/blog/topics/threat-intelligence/distillation-experimentation-integration-ai-adversarial-use","attribution":"Google Cloud"},{"title":"Stealing Machine Learning Models via Prediction APIs","url":"https://arxiv.org/abs/1609.02943?utm_source=chatgpt.com","attribution":"arXiv"}],"has_images":false}],"safe_urls":["https://arxiv.org/abs/1503.02531","https://arxiv.org/abs/1503.02531?utm_source=chatgpt.com","https://arxiv.org/abs/1609.02943","https://arxiv.org/abs/1609.02943?utm_source=chatgpt.com","https://arxiv.org/html/2403.05181v1","https://arxiv.org/html/2403.05181v1?utm_source=chatgpt.com","https://arxiv.org/html/2502.16065v1","https://arxiv.org/html/2502.16065v1?utm_source=chatgpt.com","https://blog.google/innovation-and-ai/infrastructure-and-cloud/google-cloud/gtig-report-ai-cyber-attacks-feb-2026/","https://blog.google/innovation-and-ai/infrastructure-and-cloud/google-cloud/gtig-report-ai-cyber-attacks-feb-2026/?utm_source=chatgpt.com","https://cloud.google.com/blog/topics/threat-intelligence/distillation-experimentation-integration-ai-adversarial-use","https://images.openai.com/static-rsc-1/7gemLXIcHOeBC0g4oXCJht0UcMmcZeEJXWrrnNOOF8MQE0LhC5XlvMNTf2VUglebUr5DqvJm_nyyYuFrO4CvMxyi14tt0hnVjzt9bN8AnkYhfd0D1GeJm0PzEwBp-l-1","https://www.bankinfosecurity.com/state-hackers-turn-google-ai-into-attack-acceleration-tool-a-30751","https://www.bankinfosecurity.com/state-hackers-turn-google-ai-into-attack-acceleration-tool-a-30751?utm_source=chatgpt.com","https://www.csoonline.com/article/4132098/google-fears-massive-attempt-to-clone-gemini-ai-through-model-extraction.html","https://www.csoonline.com/article/4132098/google-fears-massive-attempt-to-clone-gemini-ai-through-model-extraction.html?utm_source=chatgpt.com","https://www.itpro.com/technology/artificial-intelligence/google-says-hacker-groups-are-using-gemini-to-augment-attacks-and-companies-are-even-stealing-its-models","https://www.itpro.com/technology/artificial-intelligence/google-says-hacker-groups-are-using-gemini-to-augment-attacks-and-companies-are-even-stealing-its-models?utm_source=chatgpt.com","https://www.wired.com/2016/09/how-to-steal-an-ai","https://www.wired.com/2016/09/how-to-steal-an-ai?utm_source=chatgpt.com"],"search_result_groups":[{"type":"search_result_group","domain":"google.com","entries":[{"type":"search_result","url":"https://cloud.google.com/blog/topics/threat-intelligence/distillation-experimentation-integration-ai-adversarial-use?utm_source=chatgpt.com","title":"GTIG AI Threat Tracker: Distillation, Experimentation, and ...","snippet":"5 days ago \u2014 Google DeepMind and GTIG have identified an increase in model extraction attempts or \"distillation attacks,\" a method of intellectual property ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"google.com"},{"type":"search_result","url":"https://cloud.google.com/blog/topics/threat-intelligence/threat-actor-usage-of-ai-tools?utm_source=chatgpt.com","title":"Advances in Threat Actor Usage of AI Tools","snippet":"5 Nov 2025 \u2014 In this report, Google Threat Intelligence Group (GTIG) presents findings on adversarial misuse of AI, including Gemini and other non-Google ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"google.com"}]},{"type":"search_result_group","domain":"arxiv.org","entries":[{"type":"search_result","url":"https://arxiv.org/abs/1503.02531?utm_source=chatgpt.com","title":"[1503.02531] Distilling the Knowledge in a Neural Network","snippet":"by G Hinton \u00b7 2015 \u00b7 Cited by 29944 \u2014 We show that we can significantly improve the acoustic model of a heavily used commercial system by distilling the knowledge in an ensemble of models into a ...Re...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2403.05181v1?utm_source=chatgpt.com","title":"Adversarial Sparse Teacher: Defense Against Distillation ...","snippet":"8 Mar 2024 \u2014 We introduce Adversarial Sparse Teacher (AST), a novel methodology that leverages adversarial examples, sparse logits, and a unique loss ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2508.15031v1?utm_source=chatgpt.com","title":"A Systematic Survey of Model Extraction Attacks and ...","snippet":"20 Aug 2025 \u2014 The black-box nature of most MLaaS offerings provides some inherent protection against model extraction (Kesarwani et al., 2018) . Service ...Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2401.17746v1?utm_source=chatgpt.com","title":"Logit Poisoning Attack in Distillation-based Federated ...","snippet":"31 Jan 2024 \u2014 This paper has unveiled a novel perspective on poisoning attacks within distillation-based federated learning, a complex issue that ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":27},"pub_date":null,"attribution":"arxiv.org"}]},{"type":"search_result_group","domain":"gend.co","entries":[{"type":"search_result","url":"https://www.gend.co/blog/gemini-model-extraction-attacks?utm_source=chatgpt.com","title":"Gemini Model Extraction Attacks: How 'AI Cloning' Works","snippet":"12 hours ago \u2014 Model extraction (distillation) attacks try to \u201cclone\u201d an AI model by sending large volumes of carefully designed prompts and using the ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"gend.co"}]},{"type":"search_result_group","domain":"moneycontrol.com","entries":[{"type":"search_result","url":"https://www.moneycontrol.com/technology/hackers-created-google-gemini-clone-using-100-000-prompts-here-s-how-google-stopped-it-article-13825539.html?utm_source=chatgpt.com","title":"Hackers created Google Gemini clone using 100000 prompts","snippet":"5 days ago \u2014 Google revealed hackers attempted to clone its Gemini AI using large-scale prompt attacks, prompting new safeguards against model extraction ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"moneycontrol.com"}]},{"type":"search_result_group","domain":"blog.google","entries":[{"type":"search_result","url":"https://blog.google/innovation-and-ai/infrastructure-and-cloud/google-cloud/gtig-report-ai-cyber-attacks-feb-2026/?utm_source=chatgpt.com","title":"Google Threat Intelligence Group reports on AI threat trends","snippet":"5 days ago \u2014 We've also strengthened both our security controls and Gemini models against misuse. Read the full report on the Google Cloud Threat ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"blog.google"}]},{"type":"search_result_group","domain":"usenix.org","entries":[{"type":"search_result","url":"https://www.usenix.org/system/files/conference/usenixsecurity16/sec16_paper_tramer.pdf?utm_source=chatgpt.com","title":"Stealing Machine Learning Models via Prediction APIs","snippet":"by F Tram\u00e8r \u00b7 2016 \u00b7 Cited by 2809 \u2014 An adversary uses q prediction queries to extract an \u02c6f \u2248 f. 3 Model Extraction Attacks. An ML model extraction attack arises when an adversary.Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"usenix.org"},{"type":"search_result","url":"https://www.usenix.org/sites/default/files/conference/protected-files/security16_slides_tramer.pdf?utm_source=chatgpt.com","title":"Stealing Machine Learning Models via Prediction APIs","snippet":"by F Tram\u00e8r \u00b7 2016 \u00b7 Cited by 2809 \u2014 Model Extraction Attacks (Prior Work). 6. If f(x) is just a class ... Online Attack: AWS Machine Learning. 12 input. Model. Online Queries ...Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":28},"pub_date":null,"attribution":"usenix.org"}]},{"type":"search_result_group","domain":"linkedin.com","entries":[{"type":"search_result","url":"https://www.linkedin.com/news/story/googles-gemini-faces-surge-in-model-extraction-attacks-8405602/?utm_source=chatgpt.com","title":"Google's Gemini faces surge in model extraction attacks","snippet":"4 days ago \u2014 Google's Gemini chatbot is being targeted by adversaries attempting to extract its underlying algorithms, reports NBC News.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"linkedin.com"},{"type":"search_result","url":"https://www.linkedin.com/posts/asteris-ai_hackers-use-more-than-100000-prompts-to-activity-7427711427148283904-Rm1v?utm_source=chatgpt.com","title":"Google Issues Warning on AI Model Extraction Threats","snippet":"They're trying to reverse-engineer its reasoning. They flood the model with queries to map its internal logic and patterns. The objective is ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"linkedin.com"},{"type":"search_result","url":"https://www.linkedin.com/posts/srivalli-jeenu-4613322bb_aisecurity-cybersecurity-googlegemini-activity-7427644970091630592-U0iO?utm_source=chatgpt.com","title":"Google's Gemini AI Model Hacked Over 100000 Times","snippet":"... distillation attack' where commercially motivated actors flooded Gemini with queries. Their goal? To reverse-engineer its reasoning and ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"linkedin.com"}]},{"type":"search_result_group","domain":"ibm.com","entries":[{"type":"search_result","url":"https://www.ibm.com/think/topics/knowledge-distillation?utm_source=chatgpt.com","title":"What is Knowledge distillation? | IBM","snippet":"Knowledge distillation is a machine learning technique used to transfer the learning of a large pre-trained \u201cteacher model\u201d to a smaller \u201cstudent model.\u201d","ref_id":{"turn_index":3,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"ibm.com"}]},{"type":"search_result_group","domain":"arstechnica.com","entries":[{"type":"search_result","url":"https://arstechnica.com/ai/2026/02/attackers-prompted-gemini-over-100000-times-while-trying-to-clone-it-google-says/?utm_source=chatgpt.com","title":"Attackers prompted Gemini over 100000 times while trying ...","snippet":"4 days ago \u2014 Attackers prompted Gemini over 100,000 times while trying to clone it, Google says. Distillation technique lets copycats mimic Gemini at a ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"arstechnica.com"}]},{"type":"search_result_group","domain":"acm.org","entries":[{"type":"search_result","url":"https://dl.acm.org/doi/full/10.1145/3773080?utm_source=chatgpt.com","title":"The Emerged Security and Privacy of LLM Agent: A Survey ...","snippet":"by F He \u00b7 2025 \u00b7 Cited by 97 \u2014 Data extraction attacks are defined as efforts by adversaries to extract sensitive information or key insights from LLM agents or their underlying data, such as ...Read...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":20},"pub_date":null,"attribution":"acm.org"},{"type":"search_result","url":"https://dl.acm.org/doi/10.1145/3711896.3736573?utm_source=chatgpt.com","title":"A Survey on Model Extraction Attacks and Defenses for ...","snippet":"3 Aug 2025 \u2014 This survey provides a comprehensive taxonomy of LLM-specific extraction attacks and defenses, categorizing attacks into functionality ...Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"acm.org"},{"type":"search_result","url":"https://dl.acm.org/doi/10.5555/3241094.3241142?utm_source=chatgpt.com","title":"Stealing machine learning models via prediction APIs","snippet":"by F Tram\u00e8r \u00b7 2016 \u00b7 Cited by 2809 \u2014 We show simple, efficient attacks that extract target ML models with near-perfect fidelity for popular model classes including logistic regression, neural ...Read...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"acm.org"},{"type":"search_result","url":"https://dl.acm.org/doi/10.1016/j.ipm.2024.104056?utm_source=chatgpt.com","title":"Why logit distillation works: : A novel knowledge ...","snippet":"by MI Hossain \u00b7 2025 \u00b7 Cited by 4 \u2014 This paper proposes a novel distillation technique called TALD-KD that performs through Target Augmentation and a novel concept of dynamic Logits Distortion ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":39},"pub_date":null,"attribution":"acm.org"}]},{"type":"search_result_group","domain":"artificialintelligence-news.com","entries":[{"type":"search_result","url":"https://www.artificialintelligence-news.com/news/state-sponsored-hackers-ai-cyberattacks-google/?utm_source=chatgpt.com","title":"Google identifies state-sponsored hackers using AI in attacks","snippet":"5 days ago \u2014 One campaign targeting Gemini's reasoning abilities involved the collation and use of over 100,000 prompts designed to coerce the model into ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"artificialintelligence-news.com"}]},{"type":"search_result_group","domain":"infosecurity-magazine.com","entries":[{"type":"search_result","url":"https://www.infosecurity-magazine.com/news/nation-state-hackers-gemini-ai/?utm_source=chatgpt.com","title":"Nation-State Hackers Embrace Gemini AI for Malicious ...","snippet":"5 days ago \u2014 Google researchers found that government-backed hackers now use AI throughout the whole attack lifecycle.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"infosecurity-magazine.com"}]},{"type":"search_result_group","domain":"medium.com","entries":[{"type":"search_result","url":"https://medium.com/%40asimadnan/understanding-knowledge-distillation-from-hintons-paper-to-openai-s-mini-models-e5a761b0dc47?utm_source=chatgpt.com","title":"Understanding Knowledge Distillation: From Hinton's ...","snippet":"The concept of knowledge distillation emerged in 2015 with Geoffrey Hinton, Oriol Vinyals, and Jeff Dean's influential paper, Distilling the ...Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"medium.com"}]},{"type":"search_result_group","domain":"biggo.com","entries":[{"type":"search_result","url":"https://finance.biggo.com/news/202602122250_Google-Gemini-AI-Model-Cloning-Attack-Blocked?utm_source=chatgpt.com","title":"Google Thwarts Major AI Model Theft Attempt: Attackers Flood ...","snippet":"4 days ago \u2014 This was not a traditional data breach but a calculated \"distillation\" or \"model-extraction\" attempt. The goal was to systematically query the ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"biggo.com"}]},{"type":"search_result_group","domain":"researchgate.net","entries":[{"type":"search_result","url":"https://www.researchgate.net/publication/395277091_A_Comprehensive_Survey_of_Model_Extraction_Attacks_Current_Trends_Defenses_and_Future_Directions?utm_source=chatgpt.com","title":"A Comprehensive Survey of Model Extraction Attacks","snippet":"7 Sept 2025 \u2014 A Comprehensive Survey of Model Extraction Attacks: Current Trends, Defenses, and Future Directions. February 2025. DOI:10.1109/SATC65530.Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/392054762_Adversarial_Sparse_Teacher_Defense_Against_Distillation-Based_Model_Stealing_Attacks_Using_Adversarial_Examples?utm_source=chatgpt.com","title":"(PDF) Adversarial Sparse Teacher: Defense Against ...","snippet":"6 Aug 2025 \u2014 We introduce Adversarial Sparse Teacher (AST), a robust defense method against distillation-based model stealing attacks.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/308027534_Stealing_Machine_Learning_Models_via_Prediction_APIs?utm_source=chatgpt.com","title":"(PDF) Stealing Machine Learning Models via Prediction APIs","snippet":"10 Aug 2016 \u2014 are used in practice, may be seen as a hyper-parameter. 3 Model Extraction Attacks. An ML model extraction attack arises when an adversary.Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"researchgate.net"}]},{"type":"search_result_group","domain":"indiatimes.com","entries":[{"type":"search_result","url":"https://timesofindia.indiatimes.com/technology/tech-news/hackers-use-more-than-100000-prompts-to-make-a-google-gemini-clone/articleshow/128254048.cms?utm_source=chatgpt.com","title":"Hackers use more than 100000 prompts to make a Google ...","snippet":"5 days ago \u2014 Many of the attacks were crafted to tease out the algorithms that help Gemini \"reason\", or decide how to process information, Google said.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"indiatimes.com"}]},{"type":"search_result_group","domain":"sciencedirect.com","entries":[{"type":"search_result","url":"https://www.sciencedirect.com/science/article/abs/pii/S0306457324004151?utm_source=chatgpt.com","title":"A novel knowledge distillation technique by deriving target ...","snippet":"by MI Hossain \u00b7 2025 \u00b7 Cited by 4 \u2014 This paper proposes a novel distillation technique called TALD-KD that performs through Target Augmentation and a novel concept of dynamic Logits Distortion ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"sciencedirect.com"},{"type":"search_result","url":"https://www.sciencedirect.com/science/article/abs/pii/S0020025523000208?utm_source=chatgpt.com","title":"Black-box attacks on image classification model with ...","snippet":"by X Kang \u00b7 2023 \u00b7 Cited by 8 \u2014 A deep reinforcement learning-based black-box attacker on the image classification model is introduced in our research. Different from the existing black-box ...Read mo...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":26},"pub_date":null,"attribution":"sciencedirect.com"},{"type":"search_result","url":"https://www.sciencedirect.com/science/article/abs/pii/S0950705124005495?utm_source=chatgpt.com","title":"Student-friendly knowledge distillation","snippet":"by M Yuan \u00b7 2024 \u00b7 Cited by 48 \u2014 In knowledge distillation, the knowledge from the teacher model is often too complex for the student model to thoroughly process.Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":33},"pub_date":null,"attribution":"sciencedirect.com"}]},{"type":"search_result_group","domain":"instagram.com","entries":[{"type":"search_result","url":"https://www.instagram.com/p/DUyOUmQEkRs/?utm_source=chatgpt.com","title":"Google says attackers launched a large-scale \u201cdistillation ...","snippet":"One instance involved adversaries using over 100,000 generated prompts to systematically probe the model, a technique known as model extraction.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"instagram.com"},{"type":"search_result","url":"https://www.instagram.com/p/DUzjC0OkWk6/?utm_source=chatgpt.com","title":"Attackers sent over 100000 prompts to clone Google's ...","snippet":"According to an alert from Google's Threat Intelligence Group, adversarial actors submitted more than 100,000 crafted queries to the AI chatbot ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":19},"pub_date":null,"attribution":"instagram.com"}]},{"type":"search_result_group","domain":"semanticscholar.org","entries":[{"type":"search_result","url":"https://www.semanticscholar.org/paper/Stealing-Machine-Learning-Models-via-Prediction-Tram%C3%A8r-Zhang/8a95423d0059f7c5b1422f0ef1aa60b9e26aab7e?utm_source=chatgpt.com","title":"[PDF] Stealing Machine Learning Models via Prediction APIs","snippet":"Simple, efficient attacks are shown that extract target ML models with near-perfect fidelity for popular model classes including logistic regression, ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"semanticscholar.org"},{"type":"search_result","url":"https://www.semanticscholar.org/paper/Logit-Poisoning-Attack-in-Distillation-based-and-Yu-Zhu/f8ba7945aae001ab3defb4caba4b2770f3852f5d?utm_source=chatgpt.com","title":"Logit Poisoning Attack in Distillation-based Federated ...","snippet":"This study introduces a two-stage scheme for logit poisoning attacks, addressing previous shortcomings, and proposes an efficient defense algorithm to ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":35},"pub_date":null,"attribution":"semanticscholar.org"}]},{"type":"search_result_group","domain":"csoonline.com","entries":[{"type":"search_result","url":"https://www.csoonline.com/article/4132098/google-fears-massive-attempt-to-clone-gemini-ai-through-model-extraction.html?utm_source=chatgpt.com","title":"Google fears massive attempt to clone Gemini AI ... - CSO Online","snippet":"4 days ago \u2014 Google detected and blocked a campaign involving more than 100,000 prompts that it claimed were designed to copy the proprietary reasoning ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"csoonline.com"}]},{"type":"search_result_group","domain":"neptune.ai","entries":[{"type":"search_result","url":"https://neptune.ai/blog/knowledge-distillation?utm_source=chatgpt.com","title":"Knowledge Distillation: Principles, Algorithms, Applications","snippet":"In this scheme, the teacher model is first pre-trained on a training dataset, and then knowledge from the teacher model is distilled to train the student model.Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"neptune.ai"}]},{"type":"search_result_group","domain":"eweek.com","entries":[{"type":"search_result","url":"https://www.eweek.com/news/google-gemini-model-extraction-attacks/?utm_source=chatgpt.com","title":"Hackers Try to Clone Google's Gemini With 100000+ AI ...","snippet":"3 days ago \u2014 Google says threat actors launched 100000+ model extraction attacks against Gemini, attempting to reverse engineer its AI logic and training ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"eweek.com"}]},{"type":"search_result_group","domain":"smu.edu.sg","entries":[{"type":"search_result","url":"https://ink.library.smu.edu.sg/cgi/viewcontent.cgi?article=9591&context=sis_research&utm_source=chatgpt.com","title":"A black-box attack on code models via representation ...","snippet":"by J ZHANG \u00b7 2023 \u00b7 Cited by 17 \u2014 As a result, black-box attack techniques based on variable substitution have emerged as a valuable avenue for research and multiple works have been proposed ...Read m...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"smu.edu.sg"}]},{"type":"search_result_group","domain":"google.dev","entries":[{"type":"search_result","url":"https://discuss.ai.google.dev/t/paid-ultra-account-auto-banned/122685?utm_source=chatgpt.com","title":"Paid Ultra Account Auto-Banned - Google Antigravity","snippet":"5 days ago \u2014 No Reverse Engineering. Customer will not, and will not allow End Users to, reverse engineer or extract any components of an AI/ML Service ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"google.dev"}]},{"type":"search_result_group","domain":"bankinfosecurity.com","entries":[{"type":"search_result","url":"https://www.bankinfosecurity.com/state-hackers-turn-google-ai-into-attack-acceleration-tool-a-30751?utm_source=chatgpt.com","title":"State Hackers Turn Google AI Into Attack Acceleration Tool","snippet":"3 days ago \u2014 Hackers backed by China, Iran and North Korea used Gemini to profile targets, generate phishing messages, troubleshoot code and research ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"bankinfosecurity.com"}]},{"type":"search_result_group","domain":"openreview.net","entries":[{"type":"search_result","url":"https://openreview.net/pdf?id=BJxA924YvS&utm_source=chatgpt.com","title":"REVISITING KNOWLEDGE DISTILLATION: A TEACHER- ...","snippet":"by L Yuan \u00b7 Cited by 106 \u2014 Hinton et al. (2015) proposed Knowledge Distillation (KD) to transfer knowledge from one neural network (teacher) to another (student). Usually, the ...Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"openreview.net"}]},{"type":"search_result_group","domain":"springer.com","entries":[{"type":"search_result","url":"https://link.springer.com/article/10.1007/s10791-025-09742-8?utm_source=chatgpt.com","title":"Peak-controlled logits poisoning attack in federated distillation","snippet":"by Y Tang \u00b7 2025 \u00b7 Cited by 3 \u2014 The paper introduces PCFDLA, an attack method with precise misleading capabilities and controllability, addressing the deficiencies identified ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":19},"pub_date":null,"attribution":"springer.com"}]},{"type":"search_result_group","domain":"github.com","entries":[{"type":"search_result","url":"https://github.com/ftramer/Steal-ML?utm_source=chatgpt.com","title":"ftramer/Steal-ML: Model extraction attacks on Machine ...","snippet":"Python implementation of extraction attacks against Machine Learning models, as described in the following paper: Stealing Machine Learning Models via ...Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":20},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/kzhao5/ModelExtractionPapers?utm_source=chatgpt.com","title":"Model Extraction(Stealing) Attacks and Defenses on ...","snippet":"This repository contains a curated list of research papers on model extraction attacks and defenses in machine learning, organized by year of publication.Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":22},"pub_date":null,"attribution":"github.com"}]},{"type":"search_result_group","domain":"sentinelone.com","entries":[{"type":"search_result","url":"https://www.sentinelone.com/blog/the-good-the-bad-and-the-ugly-in-cybersecurity-week-7-7/?utm_source=chatgpt.com","title":"The Good, the Bad and the Ugly in Cybersecurity \u2013 Week 7","snippet":"3 days ago \u2014 State-backed hackers and cybercriminals are increasingly exploiting Google's Gemini AI to streamline their attacks from initial reconnaissance ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":21},"pub_date":null,"attribution":"sentinelone.com"}]},{"type":"search_result_group","domain":"thecvf.com","entries":[{"type":"search_result","url":"https://openaccess.thecvf.com/content_ICCV_2019/papers/Cho_On_the_Efficacy_of_Knowledge_Distillation_ICCV_2019_paper.pdf?utm_source=chatgpt.com","title":"On the Efficacy of Knowledge Distillation","snippet":"by JH Cho \u00b7 2019 \u00b7 Cited by 1083 \u2014 In this paper, we present a thorough evaluation of the ef- ficacy of knowledge distillation and its dependence on stu- dent and teacher architectures.Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":21},"pub_date":null,"attribution":"thecvf.com"},{"type":"search_result","url":"https://openaccess.thecvf.com/content/CVPR2023/papers/Jin_Multi-Level_Logit_Distillation_CVPR_2023_paper.pdf?utm_source=chatgpt.com","title":"Multi-Level Logit Distillation - CVF Open Access","snippet":"by Y Jin \u00b7 2023 \u00b7 Cited by 201 \u2014 In this paper, we propose multi-level logit distillation, a novel approach to make better utilization of logit outputs for knowledge distillation.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":31},"pub_date":null,"attribution":"thecvf.com"}]},{"type":"search_result_group","domain":"the-decoder.com","entries":[{"type":"search_result","url":"https://the-decoder.com/google-and-openai-complain-about-distillation-attacks-that-clone-their-ai-models-on-the-cheap/?utm_source=chatgpt.com","title":"Google and OpenAI complain about distillation attacks that ...","snippet":"2 days ago \u2014 According to Google, Gemini was hit with a massive cloning attempt through distillation, with a single campaign firing over 100,000 requests at ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":22},"pub_date":null,"attribution":"the-decoder.com"}]},{"type":"search_result_group","domain":"substack.com","entries":[{"type":"search_result","url":"https://rohittamma.substack.com/p/you-dont-need-to-steal-the-model?utm_source=chatgpt.com","title":"You Don't Need to Steal the Model to ... - Cybersecurity Mastery","snippet":"Last week, Google reported that attackers may have used over 100,000 prompts in an attempt to clone Gemini.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":23},"pub_date":null,"attribution":"substack.com"}]},{"type":"search_result_group","domain":"aaai.org","entries":[{"type":"search_result","url":"https://cdn.aaai.org/ojs/20036/20036-13-24049-1-2-20220628.pdf?utm_source=chatgpt.com","title":"Defending against Model Stealing via Verifying Embedded ...","snippet":"by Y Li \u00b7 2022 \u00b7 Cited by 98 \u2014 In the logit- query attacks, the adversary usually obtains the substitute model by minimizing the distance between its predicted log- its and those generated by ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":23},"pub_date":null,"attribution":"aaai.org"}]},{"type":"search_result_group","domain":"ycombinator.com","entries":[{"type":"search_result","url":"https://news.ycombinator.com/item?id=46995296&utm_source=chatgpt.com","title":"Google identifies over 100k prompts used in distillation ...","snippet":"4 days ago \u2014 Google DeepMind and GTIG have identified an increase in model extraction attempts or \"distillation attacks,\" a method of intellectual ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":24},"pub_date":null,"attribution":"ycombinator.com"}]},{"type":"search_result_group","domain":"scispace.com","entries":[{"type":"search_result","url":"https://scispace.com/papers/stealing-machine-learning-models-via-prediction-apis-5gpwck98q5?utm_source=chatgpt.com","title":"Stealing machine learning models via prediction APIs","snippet":"TL;DR: In this paper, the authors investigate model extraction attacks in ML-as-a-service (ML-aaS) systems and show that an adversary with black-box access, ...Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":24},"pub_date":null,"attribution":"scispace.com"}]},{"type":"search_result_group","domain":"checkpoint.com","entries":[{"type":"search_result","url":"https://research.checkpoint.com/2026/16th-february-threat-intelligence-report/?utm_source=chatgpt.com","title":"16th February \u2013 Threat Intelligence Report","snippet":"11 hours ago \u2014 Google has released an analysis of adversarial AI misuse, detailing model extraction \u201cdistillation ... Security Report; Threat Research.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":25},"pub_date":null,"attribution":"checkpoint.com"}]},{"type":"search_result_group","domain":"intellabs.github.io","entries":[{"type":"search_result","url":"https://intellabs.github.io/distiller/knowledge_distillation.html?utm_source=chatgpt.com","title":"Knowledge Distillation - Neural Network Distiller","snippet":"Knowledge distillation is model compression method in which a small model is trained to mimic a pre-trained, larger model (or ensemble of models).Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":25},"pub_date":null,"attribution":"intellabs.github.io"}]},{"type":"search_result_group","domain":"nih.gov","entries":[{"type":"search_result","url":"https://pmc.ncbi.nlm.nih.gov/articles/PMC9955283/?utm_source=chatgpt.com","title":"ShrewdAttack: Low Cost High Accuracy Model Extraction - PMC","snippet":"by Y Liu \u00b7 2023 \u00b7 Cited by 6 \u2014 Previous work [2,3,4] has shown that an attacker can access models on a platform solely through a black box and perform model extraction attacks ...Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":30},"pub_date":null,"attribution":"nih.gov"}]},{"type":"search_result_group","domain":"fox-it.com","entries":[{"type":"search_result","url":"https://www.fox-it.com/be/five-essential-machine-learning-security-papers/?utm_source=chatgpt.com","title":"Five Essential Machine Learning Security Papers","snippet":"From the paper: \u201cWe demonstrate successful model extraction attacks against ... This paper describes a relatively simple attack technique to extract verbatim ...Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":32},"pub_date":null,"attribution":"fox-it.com"}]},{"type":"search_result_group","domain":"osu.edu","entries":[{"type":"search_result","url":"https://icicle.osu.edu/media/document/2024-06-12/exploiting_xai_for_model_extraction_pets_final.pdf?utm_source=chatgpt.com","title":"Exploiting Explainable Artificial Intelligence (XAI) for Model ...","snippet":"by AC Oksuz \u00b7 Cited by 10 \u2014 XAI tools can increase the vulnerability of model extraction at- tacks, which is a concern when model owners prefer black-box access, thereby keeping model ...Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":34},"pub_date":null,"attribution":"osu.edu"}]},{"type":"search_result_group","domain":"duke.edu","entries":[{"type":"search_result","url":"https://scholars.duke.edu/individual/pub1493919?utm_source=chatgpt.com","title":"Stealing Machine Learning Models via Prediction APIs","snippet":"Tram\u00e8r, F., Zhang, F., Juels, A., Reiter, M. K., & Ristenpart, T. (2016). Stealing Machine Learning Models via Prediction APIs. In T. Holz & S. Savage (Eds.), ...Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":36},"pub_date":null,"attribution":"duke.edu"}]},{"type":"search_result_group","domain":"towardsai.net","entries":[{"type":"search_result","url":"https://pub.towardsai.net/knowledge-distillation-in-neural-network-6fae1f6c5f63?utm_source=chatgpt.com","title":"Knowledge Distillation In Neural Network | by Sovit Nayak","snippet":"25 Nov 2024 \u2014 Geoffrey Hinton first published this information in the paper \u201cDistilling the Knowledge in a Neural Network\u201d where he took a simple MNIST ...Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":37},"pub_date":null,"attribution":"towardsai.net"}]},{"type":"search_result_group","domain":"google.com.sg","entries":[{"type":"search_result","url":"https://scholar.google.com.sg/citations?hl=en&user=i6Re3L0AAAAJ&utm_source=chatgpt.com","title":"Peizhuo Lv","snippet":"MEA-defender: a robust watermark against model extraction attack. P Lv, H Ma ... 2024. Rag-wm: An efficient black-box watermarking approach for retrieval- ...Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":38},"pub_date":null,"attribution":"google.com.sg"}]}],"citations":[],"resolved_model_slug":"gpt-5-2-auto-thinking","model_slug":"gpt-5-2-thinking","request_id":"4c4f4702-b3c5-4ef6-b23c-35bf3cc0f0a6","message_type":"next","default_model_slug":"gpt-5-2","parent_id":"b16ab9f2-8454-4413-b1b3-3d6faa6e3d75","turn_exchange_id":"0e5bf703-39b2-4408-9740-c57ef23965da","suggested_connector_ids":["connector_openai_deep_research"],"cta_by_suggested_connector_id":{"connector_openai_deep_research":"Research distillation attacks on AI"},"can_save":true},"recipient":"all","channel":"final"},"parent":"b16ab9f2-8454-4413-b1b3-3d6faa6e3d75","children":["11dfcb30-1147-497b-94b8-6244a03077ec"]},"11dfcb30-1147-497b-94b8-6244a03077ec":{"id":"11dfcb30-1147-497b-94b8-6244a03077ec","message":{"id":"11dfcb30-1147-497b-94b8-6244a03077ec","author":{"role":"user","name":null,"metadata":{}},"create_time":1771327139.936,"update_time":null,"content":{"content_type":"text","parts":["Is distilling an open source model always permitted"]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"developer_mode_connector_ids":[],"selected_sources":[],"selected_github_repos":["EjayNg-AI/agentic_browser"],"serialization_metadata":{"custom_symbol_offsets":[]},"request_id":"c3e33dfc-6a48-4aea-b81d-7391a5cf1249","message_source":null,"turn_exchange_id":"633e0793-8247-436e-a4eb-4a36a1b4d9cc","resolved_model_slug":"gpt-5-2","can_save":true},"recipient":"all","channel":null},"parent":"e407dea3-87b4-4103-87f3-f105e54eceb5","children":["75fffc3c-9272-4949-985c-c2aa851550b8"]},"75fffc3c-9272-4949-985c-c2aa851550b8":{"id":"75fffc3c-9272-4949-985c-c2aa851550b8","message":{"id":"75fffc3c-9272-4949-985c-c2aa851550b8","author":{"role":"system","name":null,"metadata":{}},"create_time":1771327140.2250538,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":true,"weight":0.0,"metadata":{"rebase_developer_message":true,"request_id":"c3e33dfc-6a48-4aea-b81d-7391a5cf1249","message_type":"next","model_slug":"gpt-5-2","default_model_slug":"gpt-5-2","parent_id":"11dfcb30-1147-497b-94b8-6244a03077ec","turn_exchange_id":"633e0793-8247-436e-a4eb-4a36a1b4d9cc","is_visually_hidden_from_conversation":true,"can_save":false},"recipient":"all","channel":null},"parent":"11dfcb30-1147-497b-94b8-6244a03077ec","children":["2b1510cf-bf84-40a5-94b6-0b4bf931ba58"]},"2b1510cf-bf84-40a5-94b6-0b4bf931ba58":{"id":"2b1510cf-bf84-40a5-94b6-0b4bf931ba58","message":{"id":"2b1510cf-bf84-40a5-94b6-0b4bf931ba58","author":{"role":"system","name":null,"metadata":{}},"create_time":1771327140.3050373,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"is_contextual_answers_system_message":true,"is_visually_hidden_from_conversation":true,"command":"prompt","contextual_answers_message_type":"sources_and_filters_prompt","request_id":"c3e33dfc-6a48-4aea-b81d-7391a5cf1249","message_type":"next","model_slug":"gpt-5-2","default_model_slug":"gpt-5-2","parent_id":"75fffc3c-9272-4949-985c-c2aa851550b8","turn_exchange_id":"633e0793-8247-436e-a4eb-4a36a1b4d9cc","can_save":false},"recipient":"all","channel":null},"parent":"75fffc3c-9272-4949-985c-c2aa851550b8","children":["97631948-b9e4-45d1-b040-570f0a172ed8"]},"97631948-b9e4-45d1-b040-570f0a172ed8":{"id":"97631948-b9e4-45d1-b040-570f0a172ed8","message":{"id":"97631948-b9e4-45d1-b040-570f0a172ed8","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1771327140.267784,"update_time":null,"content":{"content_type":"text","parts":["No.  \n\nDistilling an open-source model is **not automatically permitted**. Whether it is allowed depends entirely on the model\u2019s **license terms** and how you use the distilled model.\n\nThis is a legal question, not a technical one.\n\n---\n\n# 1. What \u201cdistillation\u201d means legally\n\nDistillation = training a new \u201cstudent\u201d model on outputs generated by a \u201cteacher\u201d model.\n\nLegally, that may count as:\n\n- Creating a **derivative work**\n- Using the model in a way governed by its **license**\n- Potentially redistributing restricted weights or capabilities\n\nSome licenses treat outputs as free to use. Others restrict commercial use, redistribution, or competitive replication.\n\n---\n\n# 2. Open source \u2260 unrestricted\n\nMany AI models marketed as \u201copen source\u201d are actually under:\n\n- Custom research licenses  \n- Non-commercial licenses  \n- Responsible AI licenses  \n- Field-of-use restrictions  \n\nSo you must inspect the exact license.\n\n---\n\n# 3. Major License Categories (What Distillation Usually Means)\n\n## A. Permissive Open-Source Licenses  \nExamples: Apache 2.0, MIT\n\nIf a model is released under Apache 2.0 (true open source):\n\n- Commercial use \u2192 permitted  \n- Modification \u2192 permitted  \n- Redistribution \u2192 permitted  \n\nDistilling such a model is generally allowed.\n\nHowever:\n- You must preserve required notices.\n- You cannot violate patent clauses (Apache includes patent grants).\n\nIf you distill an Apache-licensed model, the student model is typically fine to use commercially.\n\n---\n\n## B. Copyleft Licenses  \nExamples: GPL variants (rare for model weights)\n\nIf the weights are under strong copyleft:\n- Your derivative model might also need to be released under the same license.\n\nDistillation could count as a derivative work, depending on jurisdiction.\n\nThis is legally murky.\n\n---\n\n## C. \u201cOpen-Weight but Restricted\u201d Licenses  \nThis is very common in LLMs.\n\nExamples:\n- Meta Llama Community License\n- Non-commercial research licenses\n- Responsible AI Licenses\n\nTypical restrictions:\n- Cannot use to train competing models\n- Cannot exceed certain scale thresholds\n- Cannot use for specific industries\n- Must comply with usage policy\n- No \u201cimproving other LLMs\u201d clause\n\nSome licenses explicitly forbid using the model to train another model.\n\nIn such cases, distillation would violate the license.\n\n---\n\n# 4. Important Nuances\n\n### 1. Are outputs restricted?\nSome licenses explicitly allow unrestricted use of model outputs.\nOthers do not.\n\nIf outputs are unrestricted, you may argue that training on outputs is allowed.\n\nBut some licenses explicitly prohibit using outputs to train competing models.\n\n### 2. Is the student a derivative work?\nThere is no global legal consensus yet.\n\nCourts have not definitively ruled whether:\n- Training on outputs creates a derivative model.\n\nThis is unsettled law.\n\n### 3. API vs Weights\nUsing an API under Terms of Service is very different from downloading weights under an open license.\n\nAPI terms often explicitly prohibit distillation.\n\n---\n\n# 5. Practical Examples\n\n- Distilling a model under Apache 2.0 \u2192 usually fine.\n- Distilling LLaMA (Community License) \u2192 depends on clause; may restrict.\n- Distilling a research-only model \u2192 typically not allowed commercially.\n- Distilling from OpenAI API \u2192 explicitly prohibited.\n\n---\n\n# 6. Why companies care\n\nDistillation can:\n- Replicate proprietary alignment layers\n- Copy reasoning behavior\n- Reduce training cost dramatically\n\nThat\u2019s why many modern licenses include anti-distillation clauses.\n\n---\n\n# 7. Bottom Line\n\nDistilling an open-source model is:\n\n- **Permitted** if the license allows modification and commercial use (e.g., Apache 2.0).\n- **Possibly restricted** if the license contains use limitations.\n- **Often prohibited** under API Terms of Service.\n- **Legally gray** regarding derivative-work doctrine in some jurisdictions.\n\n\u201cOpen source\u201d in AI does not mean \u201cfree to clone without constraint.\u201d\n\n---\n\nIf you want, tell me which specific model license you\u2019re evaluating and I\u2019ll analyze the exact clauses and risks."]},"status":"finished_successfully","end_turn":true,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200002]},"is_complete":true,"citations":[],"content_references":[],"resolved_model_slug":"gpt-5-2","search_result_groups":[],"request_id":"c3e33dfc-6a48-4aea-b81d-7391a5cf1249","message_type":"next","model_slug":"gpt-5-2","default_model_slug":"gpt-5-2","parent_id":"2b1510cf-bf84-40a5-94b6-0b4bf931ba58","turn_exchange_id":"633e0793-8247-436e-a4eb-4a36a1b4d9cc","can_save":true},"recipient":"all","channel":"final"},"parent":"2b1510cf-bf84-40a5-94b6-0b4bf931ba58","children":["e32a51f0-3247-4a47-983f-705c6c653b74"]},"e32a51f0-3247-4a47-983f-705c6c653b74":{"id":"e32a51f0-3247-4a47-983f-705c6c653b74","message":{"id":"e32a51f0-3247-4a47-983f-705c6c653b74","author":{"role":"user","name":null,"metadata":{}},"create_time":1771327290.659,"update_time":null,"content":{"content_type":"text","parts":["gpt-oss-120B/20B variants, qwen, small deepseek models\n"]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"developer_mode_connector_ids":[],"selected_sources":[],"selected_github_repos":["EjayNg-AI/agentic_browser"],"serialization_metadata":{"custom_symbol_offsets":[]},"request_id":"347903ef-b18b-4ace-885e-9fc4a6a4e940","message_source":null,"turn_exchange_id":"b38d8719-a889-4ca2-a1a1-b36b79809edb","resolved_model_slug":"gpt-5-2","can_save":true},"recipient":"all","channel":null},"parent":"97631948-b9e4-45d1-b040-570f0a172ed8","children":["f7132623-9371-4ff2-9d63-4c348540809b"]},"f7132623-9371-4ff2-9d63-4c348540809b":{"id":"f7132623-9371-4ff2-9d63-4c348540809b","message":{"id":"f7132623-9371-4ff2-9d63-4c348540809b","author":{"role":"system","name":null,"metadata":{}},"create_time":1771327290.9071467,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":true,"weight":0.0,"metadata":{"rebase_system_message":true,"request_id":"347903ef-b18b-4ace-885e-9fc4a6a4e940","message_type":"next","model_slug":"gpt-5-2","default_model_slug":"gpt-5-2","parent_id":"e32a51f0-3247-4a47-983f-705c6c653b74","turn_exchange_id":"b38d8719-a889-4ca2-a1a1-b36b79809edb","is_visually_hidden_from_conversation":true,"can_save":false},"recipient":"all","channel":null},"parent":"e32a51f0-3247-4a47-983f-705c6c653b74","children":["3b5ff14b-178d-4858-a54e-df8d4961e7eb"]},"3b5ff14b-178d-4858-a54e-df8d4961e7eb":{"id":"3b5ff14b-178d-4858-a54e-df8d4961e7eb","message":{"id":"3b5ff14b-178d-4858-a54e-df8d4961e7eb","author":{"role":"system","name":null,"metadata":{}},"create_time":1771327291.027268,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":true,"weight":0.0,"metadata":{"rebase_developer_message":true,"request_id":"347903ef-b18b-4ace-885e-9fc4a6a4e940","message_type":"next","model_slug":"gpt-5-2","default_model_slug":"gpt-5-2","parent_id":"f7132623-9371-4ff2-9d63-4c348540809b","turn_exchange_id":"b38d8719-a889-4ca2-a1a1-b36b79809edb","is_visually_hidden_from_conversation":true,"can_save":false},"recipient":"all","channel":null},"parent":"f7132623-9371-4ff2-9d63-4c348540809b","children":["84b924f2-e443-48e0-9fb3-ec89e6cab700"]},"84b924f2-e443-48e0-9fb3-ec89e6cab700":{"id":"84b924f2-e443-48e0-9fb3-ec89e6cab700","message":{"id":"84b924f2-e443-48e0-9fb3-ec89e6cab700","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1771327290.970805,"update_time":null,"content":{"content_type":"text","parts":["You\u2019re asking about three different ecosystems, and they are **not legally equivalent**.\n\nBelow is a precise breakdown.\n\n---\n\n# 1\ufe0f\u20e3 GPT-OSS-120B / GPT-OSS-20B\n\nIf you are referring to the **OpenAI open-weight GPT-OSS variants**, those models are released under an **Apache 2.0\u2013style permissive license**.\n\n### What that means:\n\nApache 2.0 allows:\n\n- Commercial use  \n- Modification  \n- Distribution  \n- Private use  \n- Sublicensing  \n\nThere is **no anti-distillation clause** in Apache 2.0.\n\n### So:\n\nDistilling GPT-OSS weights into a smaller student model is permitted.\n\nYou must:\n- Preserve license notices\n- Include attribution\n- Respect patent clause terms\n\nThere is no copyleft requirement.\n\nFrom a legal standpoint, distilling Apache-licensed weights is low risk.\n\n---\n\n# 2\ufe0f\u20e3 Qwen (Alibaba)\n\nQwen models have historically used **Alibaba\u2019s Tongyi Qianwen License** or Apache 2.0 depending on the version.\n\nYou must check the exact model version.\n\nThere are two scenarios:\n\n### A. Apache 2.0 Qwen releases  \nDistillation permitted (same logic as above).\n\n### B. Qwen Community License versions  \nThese sometimes include:\n- Usage restrictions\n- Field-of-use clauses\n- Large-scale deployment thresholds\n\nSome versions prohibit:\n> Using the model to train competing large models.\n\nIf that clause exists, distillation for competitive LLM development would violate terms.\n\nSo for Qwen:\n- Older Apache releases \u2192 generally safe\n- Newer community-licensed releases \u2192 must read the clause carefully\n\n---\n\n# 3\ufe0f\u20e3 DeepSeek (Small Models)\n\nDeepSeek has released models under different terms:\n\n- DeepSeek-LLM early versions \u2192 Apache 2.0  \n- DeepSeek-Coder \u2192 Apache 2.0  \n- Some newer releases \u2192 custom license variants\n\nIf Apache 2.0:\nDistillation allowed.\n\nIf custom license:\nCheck for:\n\n- \u201cNo training competing models\u201d\n- \u201cNo improving other foundation models\u201d\n- \u201cNo derivative large-scale models\u201d\n\nDeepSeek has experimented with more protective clauses in later releases.\n\n---\n\n# 4\ufe0f\u20e3 Important Legal Subtlety\n\nEven if distillation is allowed:\n\nYou must ensure:\n- You are not incorporating proprietary weights\n- You are not violating export controls\n- You are not violating local AI regulations\n- You are complying with usage policy (if attached to license)\n\nAlso:\n\nIf you fine-tune using a mixture of:\n- Apache-licensed teacher outputs\n- Proprietary API outputs\n\nYour student model may become legally contaminated.\n\nThis is where people get into trouble.\n\n---\n\n# 5\ufe0f\u20e3 Summary Table\n\n| Model Family | Typical License | Distillation Allowed? |\n|--------------|-----------------|-----------------------|\n| GPT-OSS (Apache) | Apache 2.0 | Yes |\n| Qwen (Apache version) | Apache 2.0 | Yes |\n| Qwen (Community license) | Custom | Depends on clause |\n| DeepSeek (Apache releases) | Apache 2.0 | Yes |\n| DeepSeek (custom variants) | Custom | Must check |\n\n---\n\n# 6\ufe0f\u20e3 Forward-Looking View\n\nThe industry trend is shifting:\n\n- Early open models \u2192 Apache\n- Newer frontier models \u2192 restrictive community licenses\n- API access \u2192 explicit anti-distillation\n\nExpect anti-distillation clauses to become standard.\n\nOpen-weight \u2260 open-competition.\n\n---\n\nIf you want, I can:\n\n- Pull the exact current license text for specific versions  \n- Parse the anti-distillation clauses  \n- Explain what counts as \u201ctraining a competing model\u201d in practice  \n\nJust give me the exact version numbers."]},"status":"finished_successfully","end_turn":true,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200002]},"is_complete":true,"citations":[],"content_references":[],"resolved_model_slug":"gpt-5-2","search_result_groups":[],"request_id":"347903ef-b18b-4ace-885e-9fc4a6a4e940","message_type":"next","model_slug":"gpt-5-2","default_model_slug":"gpt-5-2","parent_id":"3b5ff14b-178d-4858-a54e-df8d4961e7eb","turn_exchange_id":"b38d8719-a889-4ca2-a1a1-b36b79809edb","can_save":true},"recipient":"all","channel":"final"},"parent":"3b5ff14b-178d-4858-a54e-df8d4961e7eb","children":["c0267544-bc13-4698-9682-62780d20ff2a"]},"c0267544-bc13-4698-9682-62780d20ff2a":{"id":"c0267544-bc13-4698-9682-62780d20ff2a","message":{"id":"c0267544-bc13-4698-9682-62780d20ff2a","author":{"role":"user","name":null,"metadata":{}},"create_time":1771327746.204,"update_time":null,"content":{"content_type":"text","parts":["what is the latest qwen model comparable in size to gpt-oss-20B"]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"developer_mode_connector_ids":[],"selected_sources":[],"selected_github_repos":["EjayNg-AI/agentic_browser"],"serialization_metadata":{"custom_symbol_offsets":[]},"request_id":"e4e327e4-970c-4bf1-933f-87a7b1ca8371","message_source":null,"turn_exchange_id":"6e9e1782-65cc-446d-9765-b96314b77cd9","resolved_model_slug":"gpt-5-2","can_save":true},"recipient":"all","channel":null},"parent":"84b924f2-e443-48e0-9fb3-ec89e6cab700","children":["44e4793c-7c04-4a32-a14d-9ac318a0bde5"]},"44e4793c-7c04-4a32-a14d-9ac318a0bde5":{"id":"44e4793c-7c04-4a32-a14d-9ac318a0bde5","message":{"id":"44e4793c-7c04-4a32-a14d-9ac318a0bde5","author":{"role":"system","name":null,"metadata":{}},"create_time":1771327747.955592,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":true,"weight":0.0,"metadata":{"rebase_developer_message":true,"model_slug":"gpt-5-2-thinking","request_id":"e4e327e4-970c-4bf1-933f-87a7b1ca8371","message_type":"next","default_model_slug":"gpt-5-2","parent_id":"c0267544-bc13-4698-9682-62780d20ff2a","turn_exchange_id":"6e9e1782-65cc-446d-9765-b96314b77cd9","is_visually_hidden_from_conversation":true,"can_save":false},"recipient":"all","channel":null},"parent":"c0267544-bc13-4698-9682-62780d20ff2a","children":["a0737659-cff8-4645-92cf-3bd41936ac69"]},"a0737659-cff8-4645-92cf-3bd41936ac69":{"id":"a0737659-cff8-4645-92cf-3bd41936ac69","message":{"id":"a0737659-cff8-4645-92cf-3bd41936ac69","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1771327748.967438,"update_time":null,"content":{"content_type":"thoughts","thoughts":[{"summary":"Looking up latest AI model sizes and updates","content":"I need to look up the latest AI model sizes, especially regarding Qwen2.5, like the 14B, 32B, and possibly 20B or 22B versions. I'll check for the most recent info (Feb 2026) to make sure I have the correct details and give you an accurate comparison.","chunks":["I need to look up the latest AI model sizes, especially regarding Qwen2.5, like the 14B, 32B, and possibly 20B or 22B versions.","I'll check for the most recent info (Feb 2026) to make sure I have the correct details and give you an accurate comparison."],"finished":true}],"source_analysis_msg_id":"3d5576a5-2223-4386-988b-05319576b4b4"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"is_reasoning","citations":[],"content_references":[],"resolved_model_slug":"gpt-5-2-auto-thinking","model_slug":"gpt-5-2-thinking","hide_inline_actions":true,"disable_turn_actions":true,"request_id":"e4e327e4-970c-4bf1-933f-87a7b1ca8371","message_type":"next","default_model_slug":"gpt-5-2","parent_id":"3d5576a5-2223-4386-988b-05319576b4b4","turn_exchange_id":"6e9e1782-65cc-446d-9765-b96314b77cd9","classifier_response":"default","skip_reasoning_title":"Skip","search_result_groups":[],"can_save":true},"recipient":"all","channel":null},"parent":"44e4793c-7c04-4a32-a14d-9ac318a0bde5","children":["46eda493-9d9e-4ee2-b171-994adc4d96a2"]},"46eda493-9d9e-4ee2-b171-994adc4d96a2":{"id":"46eda493-9d9e-4ee2-b171-994adc4d96a2","message":{"id":"46eda493-9d9e-4ee2-b171-994adc4d96a2","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1771327747.516009,"update_time":null,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"{\"search_query\":[{\"q\":\"latest Qwen model 20B parameters Qwen 20B 22B 2025 2026\",\"recency\":30},{\"q\":\"Qwen2.5 22B model release\",\"recency\":365},{\"q\":\"Qwen model list 2025 2026 20B 14B 32B\",\"recency\":365},{\"q\":\"gpt-oss-20B parameters openai gpt-oss-20b\",\"recency\":365}],\"response_length\":\"short\"}"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"citations":[],"content_references":[],"resolved_model_slug":"gpt-5-2-auto-thinking","model_slug":"gpt-5-2-thinking","hide_inline_actions":true,"disable_turn_actions":true,"request_id":"e4e327e4-970c-4bf1-933f-87a7b1ca8371","message_type":"next","default_model_slug":"gpt-5-2","parent_id":"5a090a33-c739-4359-8486-b5acabbde091","turn_exchange_id":"6e9e1782-65cc-446d-9765-b96314b77cd9","reasoning_status":"is_reasoning","search_queries":[{"type":"search","q":"latest Qwen model 20B parameters Qwen 20B 22B 2025 2026"},{"type":"search","q":"Qwen2.5 22B model release"},{"type":"search","q":"Qwen model list 2025 2026 20B 14B 32B"},{"type":"search","q":"gpt-oss-20B parameters openai gpt-oss-20b"}],"search_display_string":"Searching the web...","searched_display_string":"Searched the web...","reasoning_title":"Searching for latest Qwen model sizes and details","classifier_response":"default","can_save":true},"recipient":"web.run","channel":null},"parent":"a0737659-cff8-4645-92cf-3bd41936ac69","children":["79ab404d-4987-4f69-b1d4-9763175b3ed9"]},"79ab404d-4987-4f69-b1d4-9763175b3ed9":{"id":"79ab404d-4987-4f69-b1d4-9763175b3ed9","message":{"id":"79ab404d-4987-4f69-b1d4-9763175b3ed9","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1771327759.2691102,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_model_queries":{"type":"search_model_queries","queries":["latest Qwen model 20B parameters Qwen 20B 22B 2025 2026","Qwen2.5 22B model release","Qwen model list 2025 2026 20B 14B 32B","gpt-oss-20B parameters openai gpt-oss-20b"]},"model_slug":"gpt-5-2-thinking","hide_inline_actions":true,"disable_turn_actions":true,"request_id":"e4e327e4-970c-4bf1-933f-87a7b1ca8371","message_type":"next","default_model_slug":"gpt-5-2","parent_id":"46eda493-9d9e-4ee2-b171-994adc4d96a2","turn_exchange_id":"6e9e1782-65cc-446d-9765-b96314b77cd9","reasoning_status":"is_reasoning","reasoning_title":"Searching for latest Qwen model sizes and details","classifier_response":"default","can_save":false},"recipient":"all","channel":null},"parent":"46eda493-9d9e-4ee2-b171-994adc4d96a2","children":["fd86e20d-8a73-4567-87f7-671ecda75c34"]},"fd86e20d-8a73-4567-87f7-671ecda75c34":{"id":"fd86e20d-8a73-4567-87f7-671ecda75c34","message":{"id":"fd86e20d-8a73-4567-87f7-671ecda75c34","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1771327759.2669768,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_result_groups":[{"type":"search_result_group","domain":"www.reuters.com","entries":[{"type":"search_result","url":"https://www.reuters.com/world/china/alibaba-unveils-new-qwen35-model-agentic-ai-era-2026-02-16/","title":"Alibaba unveils new Qwen3.5 model for 'agentic AI era'","snippet":"Alibaba has launched a new artificial intelligence model, Qwen 3.5, designed to independently perform complex tasks with improved efficiency and lower operational costs. The company claims the model is 60% cheaper and eight times more powerful in handling large workloads than its predecessor. Qwen 3.5 introduces \"visual agentic capabilities,\" enabling it to take actions across both mobile and desktop applications\u2014signaling Alibaba's push into the \"agentic AI\" era.\n\nThis move aims to boost adoption of its Qwen chatbot app in China, following stiff competition from ByteDance\u2019s Doubao and the globally recognized AI firm DeepSeek. ByteDance recently updated its own chatbot to Doubao 2.0. Alibaba's prior marketing drive, including a coupon giveaway tied to the Qwen chatbot, led to a sevenfold surge in active users despite technical issues.\n\nAlthough Alibaba did not mention DeepSeek in its latest release, Qwen 3.5 reportedly outperforms U.S. models including GPT-5.2, Claude Opus 4.5, and Gemini 3 Pro. DeepSeek is expected to unveil its next-gen model soon, which could further intensify the competitive dynamic within China\u2019s rapidly evolving AI sector.","ref_id":{"turn_index":0,"ref_type":"news","ref_index":34},"pub_date":1771232517.0,"attribution":"www.reuters.com"}]},{"type":"search_result_group","domain":"qwen.ai","entries":[{"type":"search_result","url":"https://qwen.ai/blog?id=qwen3","title":"Qwen3","snippet":"Today, we are excited to announce the release of Qwen3, the latest addition to the Qwen family of large language models. Our flagship model, Qwen3-235B-A22B ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":0},"pub_date":null,"attribution":"qwen.ai"},{"type":"search_result","url":"https://qwen.ai/blog?from=research.latest-advancements-list&id=4074cca80393150c248e508aa62983f9cb7d27cd","title":"Qwen3-Next","snippet":"10 Sept 2025 \u2014 To further improve training and inference efficiency under long-context and large-parameter settings, we design a brand-new model architecture ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"qwen.ai"}]},{"type":"search_result_group","domain":"en.wikipedia.org","entries":[{"type":"search_result","url":"https://en.wikipedia.org/wiki/Qwen","title":"Qwen","snippet":"","ref_id":{"turn_index":0,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"en.wikipedia.org"}]},{"type":"search_result_group","domain":"www.alibabacloud.com","entries":[{"type":"search_result","url":"https://www.alibabacloud.com/help/en/model-studio/models","title":"Alibaba Cloud Model Studio:Model list","snippet":"QwQ. QwQ is a reasoning model trained on the Qwen2.5 base and significantly enhanced through reinforcement learning. It achieves performance comparable to ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"www.alibabacloud.com"}]},{"type":"search_result_group","domain":"huggingface.co","entries":[{"type":"search_result","url":"https://huggingface.co/openai/gpt-oss-20b","title":"openai/gpt-oss-20b","snippet":"8 Aug 2025 \u2014 gpt-oss-20b \u2014 for lower latency, and local or specialized use cases (21B parameters with 3.6B active parameters). Both models were trained on ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/collections/Qwen/qwen25","title":"Qwen2.5 - a Qwen Collection","snippet":"Qwen2.5. updated Dec 30, 2025. Qwen2.5 language models, including pretrained and instruction-tuned models of 7 sizes ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/collections/Qwen/qwen3","title":"Qwen3 - a Qwen Collection","snippet":"Qwen/Qwen3-14B-AWQ. Text Generation \u2022 15B \u2022 Updated May 20, 2025 \u2022 540k \u2022 55 \u00b7 Qwen/Qwen3-8B-AWQ. Text Generation \u2022 Updated May 20, 2025 \u2022 132k \u2022 37 \u00b7 Qwen/ ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"huggingface.co"}]},{"type":"search_result_group","domain":"github.com","entries":[{"type":"search_result","url":"https://github.com/QwenLM/Qwen3","title":"QwenLM/Qwen3","snippet":"2024.09.19: We released the Qwen2.5 series. This time there are 3 extra model sizes: 3B, 14B, and 32B for more possibilities. Check ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"github.com"}]},{"type":"search_result_group","domain":"openai.com","entries":[{"type":"search_result","url":"https://openai.com/index/introducing-gpt-oss/","title":"Introducing gpt-oss","snippet":"5 Aug 2025 \u2014 gpt-oss-120b activates 5.1B parameters per token, while gpt-oss-20b activates 3.6B. The models have 117b and 21b total parameters respectively.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"openai.com"}]},{"type":"search_result_group","domain":"developers.openai.com","entries":[{"type":"search_result","url":"https://developers.openai.com/api/docs/models/gpt-oss-20b","title":"gpt-oss-20b Model | OpenAI API","snippet":"gpt-oss-20b is our medium-sized open-weight model for low latency, local, or specialized use-cases (21B parameters with 3.6B active parameters).Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"developers.openai.com"}]},{"type":"search_result_group","domain":"openrouter.ai","entries":[{"type":"search_result","url":"https://openrouter.ai/qwen","title":"Qwen","snippet":"Qwen3-235B-A22B is a 235B parameter mixture-of-experts (MoE) model developed by Qwen, activating 22B parameters per forward pass. It supports seamless ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"openrouter.ai"}]},{"type":"search_result_group","domain":"llm-stats.com","entries":[{"type":"search_result","url":"https://llm-stats.com/models/compare/codestral-22b-vs-qwen-2.5-14b-instruct","title":"Codestral-22B vs Qwen2.5 14B Instruct Comparison","snippet":"Codestral-22B was released on 2024-05-29, while Qwen2.5 14B Instruct was released on 2024-09-19. Qwen2.5 14B Instruct is 4 months newer than Codestral-22B.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"llm-stats.com"}]},{"type":"search_result_group","domain":"www.tomshardware.com","entries":[{"type":"search_result","url":"https://www.tomshardware.com/tech-industry/artificial-intelligence/openai-intros-two-lightweight-open-model-language-models-that-can-run-on-consumer-gpus-optimized-to-run-on-devices-with-just-16gb-of-memory","title":"OpenAI intros two open-weight language models that can run on consumer GPUs - optimized to run on devices with just 16GB of memory","snippet":"OpenAI has introduced two new open-weight language models, \"gpt-oss-120b\" and \"gpt-oss-20b,\" both optimized for consumer-grade GPUs. The gpt-oss-120b model is designed to operate on a single 80GB GPU, while gpt-oss-20b can run on edge devices with just 16GB of memory. These models employ a Transformer architecture with mixture-of-experts, dense and sparse attention patterns, and grouped multi-query attention. They support an extensive context length of up to 131,072 tokens.\n\nThe models are built for Chain-of-Thought reasoning and balance performance, efficiency, and practical usability. Remarkably, they are the first open-weight models OpenAI has released since GPT-2, and they are licensed under Apache 2.0 to promote broader adoption, particularly in markets with limited access to proprietary models.\n\nPerformance-wise, gpt-oss-120b rivals OpenAI\u2019s o4-mini model and surpasses it in specific tasks like health-related queries and competitive math. Meanwhile, gpt-oss-20b matches o3-mini\u2019s capabilities while being significantly lighter. Both models are currently supported across multiple platforms, including ONNX Runtime, Azure, AWS, and Ollama.","ref_id":{"turn_index":0,"ref_type":"news","ref_index":40},"pub_date":1754587519.0,"attribution":"www.tomshardware.com"}]},{"type":"search_result_group","domain":"www.theverge.com","entries":[{"type":"search_result","url":"https://www.theverge.com/openai/718785/openai-gpt-oss-open-model-release","title":"OpenAI releases a free GPT model that can run on your laptop","snippet":"OpenAI has released a new open-weight model called GPT-OSS, marking its first such release in over six years. Available in two variants\u2014a 120-billion-parameter model and a 20-billion-parameter model\u2014GPT-OSS can be run locally on laptops or via cloud platforms such as Hugging Face, Databricks, Azure, and AWS. The models, licensed under Apache 2.0, are free to use and can be modified for commercial purposes. The larger version runs with a single Nvidia GPU and compares to OpenAI's o4-mini, while the smaller version, requiring just 16GB of VRAM, performs similarly to the o3-mini. GPT-OSS supports reasoning, coding, web browsing, and agent operation through OpenAI APIs.\n\nAfter previously withholding open models due to safety concerns, OpenAI now aims to support a growing developer community favoring customizable, cost-effective alternatives. GPT-OSS includes robust safety evaluations and features transparent reasoning processes. Although benchmark comparisons to other open models like Llama and DeepSeek are not provided, OpenAI asserts GPT-OSS matches performance on numerous tests with its closed reasoning models. The company hopes the model empowers smaller developers and companies to innovate with more control over their data.","ref_id":{"turn_index":0,"ref_type":"news","ref_index":42},"pub_date":1754413252.0,"attribution":"www.theverge.com"}]}],"debug_sonic_thread_id":"thread_6994510f5370833181a7c0568e68bd6e","model_slug":"gpt-5-2-thinking","hide_inline_actions":true,"disable_turn_actions":true,"request_id":"e4e327e4-970c-4bf1-933f-87a7b1ca8371","message_type":"next","default_model_slug":"gpt-5-2","parent_id":"6244ae63-8524-437e-84e3-c4346a695be8","turn_exchange_id":"6e9e1782-65cc-446d-9765-b96314b77cd9","reasoning_status":"is_reasoning","reasoning_title":"Searching for latest Qwen model sizes and details","classifier_response":"default","can_save":false},"recipient":"all","channel":null},"parent":"79ab404d-4987-4f69-b1d4-9763175b3ed9","children":["ea3daa14-12e2-4d39-ae05-08620692a5b7"]},"ea3daa14-12e2-4d39-ae05-08620692a5b7":{"id":"ea3daa14-12e2-4d39-ae05-08620692a5b7","message":{"id":"ea3daa14-12e2-4d39-ae05-08620692a5b7","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1771327770.978386,"update_time":null,"content":{"content_type":"thoughts","thoughts":[{"summary":"Exploring Qwen model sizes for comparison","content":"I need to compare the latest Qwen models to the GPT-OSS-20B. Qwen3 includes 14B and 32B options, but no 20B. To match, the 14B seems closest. There's also a Qwen3.5 coming, though its exact sizes aren't clear yet. I\u2019ll search to get the most up-to-date info.","chunks":["I need to compare the latest Qwen models to the GPT-OSS-20B.","Qwen3 includes 14B and 32B options, but no 20B.","To match, the 14B seems closest.","There's also a Qwen3.5 coming, though its exact sizes aren't clear yet.","I\u2019ll search to get the most up-to-date info."],"finished":true}],"source_analysis_msg_id":"7256d4d4-ff19-4295-b11e-07d1e4e7501c"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"is_reasoning","citations":[],"content_references":[],"resolved_model_slug":"gpt-5-2-auto-thinking","model_slug":"gpt-5-2-thinking","hide_inline_actions":true,"disable_turn_actions":true,"request_id":"e4e327e4-970c-4bf1-933f-87a7b1ca8371","message_type":"next","default_model_slug":"gpt-5-2","parent_id":"64f4f86c-4f87-4c7b-8c5f-b3c0c5682dd1","turn_exchange_id":"6e9e1782-65cc-446d-9765-b96314b77cd9","classifier_response":"default","skip_reasoning_title":"Skip","search_result_groups":[{"type":"search_result_group","domain":"www.reuters.com","entries":[{"type":"search_result","url":"https://www.reuters.com/world/china/alibaba-unveils-new-qwen35-model-agentic-ai-era-2026-02-16/","title":"Alibaba unveils new Qwen3.5 model for 'agentic AI era'","snippet":"Alibaba has launched a new artificial intelligence model, Qwen 3.5, designed to independently perform complex tasks with improved efficiency and lower operational costs. The company claims the model is 60% cheaper and eight times more powerful in handling large workloads than its predecessor. Qwen 3.5 introduces \"visual agentic capabilities,\" enabling it to take actions across both mobile and desktop applications\u2014signaling Alibaba's push into the \"agentic AI\" era.\n\nThis move aims to boost adoption of its Qwen chatbot app in China, following stiff competition from ByteDance\u2019s Doubao and the globally recognized AI firm DeepSeek. ByteDance recently updated its own chatbot to Doubao 2.0. Alibaba's prior marketing drive, including a coupon giveaway tied to the Qwen chatbot, led to a sevenfold surge in active users despite technical issues.\n\nAlthough Alibaba did not mention DeepSeek in its latest release, Qwen 3.5 reportedly outperforms U.S. models including GPT-5.2, Claude Opus 4.5, and Gemini 3 Pro. DeepSeek is expected to unveil its next-gen model soon, which could further intensify the competitive dynamic within China\u2019s rapidly evolving AI sector.","ref_id":{"turn_index":0,"ref_type":"news","ref_index":34},"pub_date":1771232517.0,"attribution":"www.reuters.com"}]},{"type":"search_result_group","domain":"qwen.ai","entries":[{"type":"search_result","url":"https://qwen.ai/blog?id=qwen3","title":"Qwen3","snippet":"Today, we are excited to announce the release of Qwen3, the latest addition to the Qwen family of large language models. Our flagship model, Qwen3-235B-A22B ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":0},"pub_date":null,"attribution":"qwen.ai"},{"type":"search_result","url":"https://qwen.ai/blog?from=research.latest-advancements-list&id=4074cca80393150c248e508aa62983f9cb7d27cd","title":"Qwen3-Next","snippet":"10 Sept 2025 \u2014 To further improve training and inference efficiency under long-context and large-parameter settings, we design a brand-new model architecture ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"qwen.ai"}]},{"type":"search_result_group","domain":"en.wikipedia.org","entries":[{"type":"search_result","url":"https://en.wikipedia.org/wiki/Qwen","title":"Qwen","snippet":"","ref_id":{"turn_index":0,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"en.wikipedia.org"}]},{"type":"search_result_group","domain":"www.alibabacloud.com","entries":[{"type":"search_result","url":"https://www.alibabacloud.com/help/en/model-studio/models","title":"Alibaba Cloud Model Studio:Model list","snippet":"QwQ. QwQ is a reasoning model trained on the Qwen2.5 base and significantly enhanced through reinforcement learning. It achieves performance comparable to ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"www.alibabacloud.com"}]},{"type":"search_result_group","domain":"huggingface.co","entries":[{"type":"search_result","url":"https://huggingface.co/openai/gpt-oss-20b","title":"openai/gpt-oss-20b","snippet":"8 Aug 2025 \u2014 gpt-oss-20b \u2014 for lower latency, and local or specialized use cases (21B parameters with 3.6B active parameters). Both models were trained on ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/collections/Qwen/qwen25","title":"Qwen2.5 - a Qwen Collection","snippet":"Qwen2.5. updated Dec 30, 2025. Qwen2.5 language models, including pretrained and instruction-tuned models of 7 sizes ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/collections/Qwen/qwen3","title":"Qwen3 - a Qwen Collection","snippet":"Qwen/Qwen3-14B-AWQ. Text Generation \u2022 15B \u2022 Updated May 20, 2025 \u2022 540k \u2022 55 \u00b7 Qwen/Qwen3-8B-AWQ. Text Generation \u2022 Updated May 20, 2025 \u2022 132k \u2022 37 \u00b7 Qwen/ ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"huggingface.co"}]},{"type":"search_result_group","domain":"github.com","entries":[{"type":"search_result","url":"https://github.com/QwenLM/Qwen3","title":"QwenLM/Qwen3","snippet":"2024.09.19: We released the Qwen2.5 series. This time there are 3 extra model sizes: 3B, 14B, and 32B for more possibilities. Check ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"github.com"}]},{"type":"search_result_group","domain":"openai.com","entries":[{"type":"search_result","url":"https://openai.com/index/introducing-gpt-oss/","title":"Introducing gpt-oss","snippet":"5 Aug 2025 \u2014 gpt-oss-120b activates 5.1B parameters per token, while gpt-oss-20b activates 3.6B. The models have 117b and 21b total parameters respectively.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"openai.com"}]},{"type":"search_result_group","domain":"developers.openai.com","entries":[{"type":"search_result","url":"https://developers.openai.com/api/docs/models/gpt-oss-20b","title":"gpt-oss-20b Model | OpenAI API","snippet":"gpt-oss-20b is our medium-sized open-weight model for low latency, local, or specialized use-cases (21B parameters with 3.6B active parameters).Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"developers.openai.com"}]},{"type":"search_result_group","domain":"openrouter.ai","entries":[{"type":"search_result","url":"https://openrouter.ai/qwen","title":"Qwen","snippet":"Qwen3-235B-A22B is a 235B parameter mixture-of-experts (MoE) model developed by Qwen, activating 22B parameters per forward pass. It supports seamless ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"openrouter.ai"}]},{"type":"search_result_group","domain":"llm-stats.com","entries":[{"type":"search_result","url":"https://llm-stats.com/models/compare/codestral-22b-vs-qwen-2.5-14b-instruct","title":"Codestral-22B vs Qwen2.5 14B Instruct Comparison","snippet":"Codestral-22B was released on 2024-05-29, while Qwen2.5 14B Instruct was released on 2024-09-19. Qwen2.5 14B Instruct is 4 months newer than Codestral-22B.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"llm-stats.com"}]},{"type":"search_result_group","domain":"www.tomshardware.com","entries":[{"type":"search_result","url":"https://www.tomshardware.com/tech-industry/artificial-intelligence/openai-intros-two-lightweight-open-model-language-models-that-can-run-on-consumer-gpus-optimized-to-run-on-devices-with-just-16gb-of-memory","title":"OpenAI intros two open-weight language models that can run on consumer GPUs - optimized to run on devices with just 16GB of memory","snippet":"OpenAI has introduced two new open-weight language models, \"gpt-oss-120b\" and \"gpt-oss-20b,\" both optimized for consumer-grade GPUs. The gpt-oss-120b model is designed to operate on a single 80GB GPU, while gpt-oss-20b can run on edge devices with just 16GB of memory. These models employ a Transformer architecture with mixture-of-experts, dense and sparse attention patterns, and grouped multi-query attention. They support an extensive context length of up to 131,072 tokens.\n\nThe models are built for Chain-of-Thought reasoning and balance performance, efficiency, and practical usability. Remarkably, they are the first open-weight models OpenAI has released since GPT-2, and they are licensed under Apache 2.0 to promote broader adoption, particularly in markets with limited access to proprietary models.\n\nPerformance-wise, gpt-oss-120b rivals OpenAI\u2019s o4-mini model and surpasses it in specific tasks like health-related queries and competitive math. Meanwhile, gpt-oss-20b matches o3-mini\u2019s capabilities while being significantly lighter. Both models are currently supported across multiple platforms, including ONNX Runtime, Azure, AWS, and Ollama.","ref_id":{"turn_index":0,"ref_type":"news","ref_index":40},"pub_date":1754587519.0,"attribution":"www.tomshardware.com"}]},{"type":"search_result_group","domain":"www.theverge.com","entries":[{"type":"search_result","url":"https://www.theverge.com/openai/718785/openai-gpt-oss-open-model-release","title":"OpenAI releases a free GPT model that can run on your laptop","snippet":"OpenAI has released a new open-weight model called GPT-OSS, marking its first such release in over six years. Available in two variants\u2014a 120-billion-parameter model and a 20-billion-parameter model\u2014GPT-OSS can be run locally on laptops or via cloud platforms such as Hugging Face, Databricks, Azure, and AWS. The models, licensed under Apache 2.0, are free to use and can be modified for commercial purposes. The larger version runs with a single Nvidia GPU and compares to OpenAI's o4-mini, while the smaller version, requiring just 16GB of VRAM, performs similarly to the o3-mini. GPT-OSS supports reasoning, coding, web browsing, and agent operation through OpenAI APIs.\n\nAfter previously withholding open models due to safety concerns, OpenAI now aims to support a growing developer community favoring customizable, cost-effective alternatives. GPT-OSS includes robust safety evaluations and features transparent reasoning processes. Although benchmark comparisons to other open models like Llama and DeepSeek are not provided, OpenAI asserts GPT-OSS matches performance on numerous tests with its closed reasoning models. The company hopes the model empowers smaller developers and companies to innovate with more control over their data.","ref_id":{"turn_index":0,"ref_type":"news","ref_index":42},"pub_date":1754413252.0,"attribution":"www.theverge.com"}]}],"safe_urls":["https://developers.openai.com/api/docs/models/gpt-oss-20b","https://en.wikipedia.org/wiki/Qwen","https://github.com/QwenLM/Qwen3","https://huggingface.co/collections/Qwen/qwen25","https://huggingface.co/collections/Qwen/qwen3","https://huggingface.co/openai/gpt-oss-20b","https://llm-stats.com/models/compare/codestral-22b-vs-qwen-2.5-14b-instruct","https://openai.com/index/introducing-gpt-oss/","https://openrouter.ai/qwen","https://qwen.ai/blog?from=research.latest-advancements-list&id=4074cca80393150c248e508aa62983f9cb7d27cd","https://qwen.ai/blog?id=qwen3","https://www.alibabacloud.com/help/en/model-studio/models","https://www.reuters.com/world/china/alibaba-unveils-new-qwen35-model-agentic-ai-era-2026-02-16/","https://www.theverge.com/openai/718785/openai-gpt-oss-open-model-release","https://www.tomshardware.com/tech-industry/artificial-intelligence/openai-intros-two-lightweight-open-model-language-models-that-can-run-on-consumer-gpus-optimized-to-run-on-devices-with-just-16gb-of-memory"],"can_save":true},"recipient":"all","channel":null},"parent":"fd86e20d-8a73-4567-87f7-671ecda75c34","children":["258990de-45ee-484e-a34e-1937f0eb04a4"]},"258990de-45ee-484e-a34e-1937f0eb04a4":{"id":"258990de-45ee-484e-a34e-1937f0eb04a4","message":{"id":"258990de-45ee-484e-a34e-1937f0eb04a4","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1771327761.172896,"update_time":null,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"{\"search_query\":[{\"q\":\"Qwen3.5 model sizes 14B 32B 2026 \\\"Qwen3.5\\\" \\\"B\\\"\",\"recency\":30},{\"q\":\"qwen3.5 hugging face 14b\",\"recency\":30},{\"q\":\"Qwen3.5 release blog qwen.ai\",\"recency\":30},{\"q\":\"Qwen3.5-20B\",\"recency\":365}],\"response_length\":\"short\"}"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"citations":[],"content_references":[],"resolved_model_slug":"gpt-5-2-auto-thinking","model_slug":"gpt-5-2-thinking","hide_inline_actions":true,"disable_turn_actions":true,"request_id":"e4e327e4-970c-4bf1-933f-87a7b1ca8371","message_type":"next","default_model_slug":"gpt-5-2","parent_id":"f2906f12-e68d-4013-bd86-59c9917659fc","turn_exchange_id":"6e9e1782-65cc-446d-9765-b96314b77cd9","reasoning_status":"is_reasoning","search_queries":[{"type":"search","q":"Qwen3.5 model sizes 14B 32B 2026 \"Qwen3.5\" \"B\""},{"type":"search","q":"qwen3.5 hugging face 14b"},{"type":"search","q":"Qwen3.5 release blog qwen.ai"},{"type":"search","q":"Qwen3.5-20B"}],"search_display_string":"Searching the web...","searched_display_string":"Searched the web...","reasoning_title":"Searching for Qwen3.5 model size details","classifier_response":"default","can_save":true},"recipient":"web.run","channel":null},"parent":"ea3daa14-12e2-4d39-ae05-08620692a5b7","children":["05078029-6e2a-4620-8fe4-dbd77d36de37"]},"05078029-6e2a-4620-8fe4-dbd77d36de37":{"id":"05078029-6e2a-4620-8fe4-dbd77d36de37","message":{"id":"05078029-6e2a-4620-8fe4-dbd77d36de37","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1771327773.0817454,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_model_queries":{"type":"search_model_queries","queries":["Qwen3.5 model sizes 14B 32B 2026 \"Qwen3.5\" \"B\"","qwen3.5 hugging face 14b","Qwen3.5 release blog qwen.ai","Qwen3.5-20B"]},"model_slug":"gpt-5-2-thinking","hide_inline_actions":true,"disable_turn_actions":true,"request_id":"e4e327e4-970c-4bf1-933f-87a7b1ca8371","message_type":"next","default_model_slug":"gpt-5-2","parent_id":"258990de-45ee-484e-a34e-1937f0eb04a4","turn_exchange_id":"6e9e1782-65cc-446d-9765-b96314b77cd9","reasoning_status":"is_reasoning","reasoning_title":"Searching for Qwen3.5 model size details","classifier_response":"default","can_save":false},"recipient":"all","channel":null},"parent":"258990de-45ee-484e-a34e-1937f0eb04a4","children":["a362ce85-1314-49dc-8101-e6274c4ec7b3"]},"a362ce85-1314-49dc-8101-e6274c4ec7b3":{"id":"a362ce85-1314-49dc-8101-e6274c4ec7b3","message":{"id":"a362ce85-1314-49dc-8101-e6274c4ec7b3","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1771327773.0794282,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_result_groups":[{"type":"search_result_group","domain":"www.reuters.com","entries":[{"type":"search_result","url":"https://www.reuters.com/world/china/alibaba-unveils-new-qwen35-model-agentic-ai-era-2026-02-16/","title":"Alibaba unveils new Qwen3.5 model for 'agentic AI era'","snippet":"Alibaba has launched a new artificial intelligence model, Qwen 3.5, designed to independently perform complex tasks with improved efficiency and lower operational costs. The company claims the model is 60% cheaper and eight times more powerful in handling large workloads than its predecessor. Qwen 3.5 introduces \"visual agentic capabilities,\" enabling it to take actions across both mobile and desktop applications\u2014signaling Alibaba's push into the \"agentic AI\" era.\n\nThis move aims to boost adoption of its Qwen chatbot app in China, following stiff competition from ByteDance\u2019s Doubao and the globally recognized AI firm DeepSeek. ByteDance recently updated its own chatbot to Doubao 2.0. Alibaba's prior marketing drive, including a coupon giveaway tied to the Qwen chatbot, led to a sevenfold surge in active users despite technical issues.\n\nAlthough Alibaba did not mention DeepSeek in its latest release, Qwen 3.5 reportedly outperforms U.S. models including GPT-5.2, Claude Opus 4.5, and Gemini 3 Pro. DeepSeek is expected to unveil its next-gen model soon, which could further intensify the competitive dynamic within China\u2019s rapidly evolving AI sector.","ref_id":{"turn_index":1,"ref_type":"news","ref_index":36},"pub_date":1771232517.0,"attribution":"www.reuters.com"}]},{"type":"search_result_group","domain":"m.economictimes.com","entries":[{"type":"search_result","url":"https://m.economictimes.com/tech/artificial-intelligence/alibaba-unveils-new-qwen3-5-model-for-agentic-ai-era/articleshow/128416327.cms","title":"Alibaba launches Qwen3.5; claims cheaper model with advanced linguistic capabilities","snippet":"Alibaba has launched Qwen3.5, the latest version of its flagship AI model, enhancing its position in the competitive AI landscape. Unveiled on February 16, 2026, Qwen3.5 comes with improved linguistic abilities and is designed to be more cost-effective compared to its predecessors. The development underscores Alibaba's focus on building advanced artificial general intelligence (AGI) tools for the emerging era of agentic AI\u2014AI that performs tasks with greater autonomy and adaptability. The upgraded model is reportedly better at understanding and generating human language, a key component for more natural and effective AI-human interaction. This move places Alibaba in closer competition with global tech leaders in the AI domain, reflecting China\u2019s broader investment in cutting-edge AI technology.","ref_id":{"turn_index":1,"ref_type":"news","ref_index":37},"pub_date":1771233691.0,"attribution":"m.economictimes.com"}]},{"type":"search_result_group","domain":"www.alibabacloud.com","entries":[{"type":"search_result","url":"https://www.alibabacloud.com/help/en/model-studio/models","title":"Alibaba Cloud Model Studio:Model list","snippet":"qwen2.5-7b-instruct. $0.072. $0.144. qwen2.5-3b-instruct. 32,768. 30,720. $0.044. $0.130. qwen2.5-1.5b-instruct. Free for a limited time. qwen2.5-0.5b-instruct ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":0},"pub_date":null,"attribution":"www.alibabacloud.com"}]},{"type":"search_result_group","domain":"huggingface.co","entries":[{"type":"search_result","url":"https://huggingface.co/Qwen/Qwen3-14B","title":"Qwen/Qwen3-14B","snippet":"14 May 2025 \u2014 Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models.Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/collections/Qwen/qwen3","title":"Qwen3 - a Qwen Collection","snippet":"We're on a journey to advance and democratize artificial intelligence through open source and open science.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/Qwen","title":"Qwen","snippet":"Welcome to Qwen. This is the organization of Qwen, which refers to the large language model family built by Alibaba Cloud.Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/Qwen/Qwen3.5-397B-A17B","title":"Qwen/Qwen3.5-397B-A17B","snippet":"1 day ago \u2014 Qwen3.5 features the following enhancement: Unified Vision-Language Foundation: Early fusion training on multimodal tokens achieves cross- ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/Qwen/Qwen3-14B-Base","title":"Qwen/Qwen3-14B-Base","snippet":"14 May 2025 \u2014 Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models.Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"huggingface.co"}]},{"type":"search_result_group","domain":"qwen.ai","entries":[{"type":"search_result","url":"https://qwen.ai/blog?id=qwen3.5","title":"Qwen3.5: Towards Native Multimodal Agents","snippet":"1 day ago \u2014 Qwen3.5 can help with web development, especially for frontend tasks like building web pages and designing user interfaces. It makes creating ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"qwen.ai"},{"type":"search_result","url":"https://qwen.ai/research","title":"Qwen - Comprehensive Functionality","snippet":"Qwen3-TTS is a series of powerful speech generation capabilities developed by Qwen, offering comprehensive support for voice clone, voice design, ultra-high ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"qwen.ai"},{"type":"search_result","url":"https://qwen.ai/","title":"Qwen - Chatbot, image, video, document, web integration","snippet":"Qwen Chat is an AI assistant for everyone, powered by the Qwen series models. It's free to use, open to all, and ready to help with creativity, ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"qwen.ai"}]},{"type":"search_result_group","domain":"github.com","entries":[{"type":"search_result","url":"https://github.com/QwenLM/Qwen3.5","title":"QwenLM/Qwen3.5","snippet":"1 day ago \u2014 Qwen3.5 represents a significant leap forward, integrating breakthroughs in multimodal learning, architectural efficiency, reinforcement ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"github.com"}]},{"type":"search_result_group","domain":"openrouter.ai","entries":[{"type":"search_result","url":"https://openrouter.ai/qwen","title":"Qwen","snippet":"The Qwen3.5 series 397B-A17B native vision-language model is built on a hybrid architecture that integrates a linear attention mechanism with a sparse mixture- ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"openrouter.ai"}]},{"type":"search_result_group","domain":"ollama.com","entries":[{"type":"search_result","url":"https://ollama.com/search?q=qwen","title":"qwen \u00b7 Ollama Search","snippet":"The Qwen3.5 series 397B-A17B native vision-language model ... models by Alibaba Cloud spanning from 0.5B to 110B parameters. 0.5b 1.8b 4b 7b 14b 32b 72b 110b.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"ollama.com"}]},{"type":"search_result_group","domain":"www.reddit.com","entries":[{"type":"search_result","url":"https://www.reddit.com/r/LocalLLaMA/comments/1r657w5/qwen35_release_blog_post/","title":"Qwen3.5 Release Blog Post : r/LocalLLaMA","snippet":"They released a flagship that, according to their claims, is better than gpt-5.2 and opus 4.6 in thinking variety; but this flagship is equally ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":12},"pub_date":1771234304.037,"attribution":"www.reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/LocalLLaMA/comments/1mvjdxh/which_model_is_less_demanding_on_resources/","title":"which model is less demanding on resources, gpt-oss-20b ...","snippet":"gpt-oss-20b uses ~33% less memory than Qwen3-30B-A3B, but because of the similar number of active parameters, the compute cost is similar. If ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"www.reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/LocalLLaMA/comments/1r60ety/qwen_35_will_be_released_today/","title":"Qwen 3.5 will be released today : r/LocalLLaMA","snippet":"Sources reveal that Alibaba will open-source its next-generation large model, Qwen3.5, tonight on Lunar New Year's Eve. The ... The 0.6b qwen3 is ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":14},"pub_date":1771217660.959,"attribution":"www.reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/singularity/comments/1r65i6p/qwen35397ba17b_first_openweight_model_in_qwen35/","title":"Qwen3.5-397B-A17B: First open-weight model in ...","snippet":"One of the interesting benchmarks I noticed is the ZeroBench, Qwen 3.5 scored 12 by surpassing other frontier models, interesting.Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":15},"pub_date":1771235370.559,"attribution":"www.reddit.com"}]},{"type":"search_result_group","domain":"medium.com","entries":[{"type":"search_result","url":"https://medium.com/%40ai-engineering-trend/qwen3-5-release-397b-parameter-model-with-native-multimodal-capabilities-and-8-19x-inference-f74076a6d080","title":"Qwen3.5 Release: 397B Parameter Model with Native ...","snippet":"Qwen3.5 Release: 397B Parameter Model with Native Multimodal Capabilities and 8\u201319x Inference Efficiency Boost.Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":16},"pub_date":1771246112.377,"attribution":"medium.com"}]}],"debug_sonic_thread_id":"thread_6994510f5370833181a7c0568e68bd6e","model_slug":"gpt-5-2-thinking","hide_inline_actions":true,"disable_turn_actions":true,"request_id":"e4e327e4-970c-4bf1-933f-87a7b1ca8371","message_type":"next","default_model_slug":"gpt-5-2","parent_id":"46bc1f89-cbc3-499c-bfa0-7eae0f3adcc4","turn_exchange_id":"6e9e1782-65cc-446d-9765-b96314b77cd9","reasoning_status":"is_reasoning","reasoning_title":"Searching for Qwen3.5 model size details","classifier_response":"default","can_save":false},"recipient":"all","channel":null},"parent":"05078029-6e2a-4620-8fe4-dbd77d36de37","children":["0d1d35ae-40ca-4c93-80e2-33cbbf7a59b1"]},"0d1d35ae-40ca-4c93-80e2-33cbbf7a59b1":{"id":"0d1d35ae-40ca-4c93-80e2-33cbbf7a59b1","message":{"id":"0d1d35ae-40ca-4c93-80e2-33cbbf7a59b1","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1771327782.020135,"update_time":null,"content":{"content_type":"thoughts","thoughts":[{"summary":"Checking Qwen3.5 model sizes","content":"I see there's a Qwen3.5 blog, so I'll open it to find out about the new model lineup. I\u2019m hoping to find relevant sizes near 20B, and it seems like Qwen3.5 may include a new dense 14B or something like a 30B-A3B. Time to verify!","chunks":["I see there's a Qwen3.5 blog, so I'll open it to find out about the new model lineup.","I\u2019m hoping to find relevant sizes near 20B, and it seems like Qwen3.5 may include a new dense 14B or something like a 30B-A3B.","Time to verify!"],"finished":true}],"source_analysis_msg_id":"0fbc0f19-2e4e-4f92-babb-89c7c7429b83"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"is_reasoning","citations":[],"content_references":[],"resolved_model_slug":"gpt-5-2-auto-thinking","model_slug":"gpt-5-2-thinking","hide_inline_actions":true,"disable_turn_actions":true,"request_id":"e4e327e4-970c-4bf1-933f-87a7b1ca8371","message_type":"next","default_model_slug":"gpt-5-2","parent_id":"32edb25d-f420-4608-af6c-6f24c8aeca0f","turn_exchange_id":"6e9e1782-65cc-446d-9765-b96314b77cd9","classifier_response":"default","skip_reasoning_title":"Skip","search_result_groups":[{"type":"search_result_group","domain":"www.reuters.com","entries":[{"type":"search_result","url":"https://www.reuters.com/world/china/alibaba-unveils-new-qwen35-model-agentic-ai-era-2026-02-16/","title":"Alibaba unveils new Qwen3.5 model for 'agentic AI era'","snippet":"Alibaba has launched a new artificial intelligence model, Qwen 3.5, designed to independently perform complex tasks with improved efficiency and lower operational costs. The company claims the model is 60% cheaper and eight times more powerful in handling large workloads than its predecessor. Qwen 3.5 introduces \"visual agentic capabilities,\" enabling it to take actions across both mobile and desktop applications\u2014signaling Alibaba's push into the \"agentic AI\" era.\n\nThis move aims to boost adoption of its Qwen chatbot app in China, following stiff competition from ByteDance\u2019s Doubao and the globally recognized AI firm DeepSeek. ByteDance recently updated its own chatbot to Doubao 2.0. Alibaba's prior marketing drive, including a coupon giveaway tied to the Qwen chatbot, led to a sevenfold surge in active users despite technical issues.\n\nAlthough Alibaba did not mention DeepSeek in its latest release, Qwen 3.5 reportedly outperforms U.S. models including GPT-5.2, Claude Opus 4.5, and Gemini 3 Pro. DeepSeek is expected to unveil its next-gen model soon, which could further intensify the competitive dynamic within China\u2019s rapidly evolving AI sector.","ref_id":{"turn_index":0,"ref_type":"news","ref_index":34},"pub_date":1771232517.0,"attribution":"www.reuters.com"}]},{"type":"search_result_group","domain":"qwen.ai","entries":[{"type":"search_result","url":"https://qwen.ai/blog?id=qwen3","title":"Qwen3","snippet":"Today, we are excited to announce the release of Qwen3, the latest addition to the Qwen family of large language models. Our flagship model, Qwen3-235B-A22B ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":0},"pub_date":null,"attribution":"qwen.ai"},{"type":"search_result","url":"https://qwen.ai/blog?from=research.latest-advancements-list&id=4074cca80393150c248e508aa62983f9cb7d27cd","title":"Qwen3-Next","snippet":"10 Sept 2025 \u2014 To further improve training and inference efficiency under long-context and large-parameter settings, we design a brand-new model architecture ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"qwen.ai"}]},{"type":"search_result_group","domain":"en.wikipedia.org","entries":[{"type":"search_result","url":"https://en.wikipedia.org/wiki/Qwen","title":"Qwen","snippet":"","ref_id":{"turn_index":0,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"en.wikipedia.org"}]},{"type":"search_result_group","domain":"www.alibabacloud.com","entries":[{"type":"search_result","url":"https://www.alibabacloud.com/help/en/model-studio/models","title":"Alibaba Cloud Model Studio:Model list","snippet":"QwQ. QwQ is a reasoning model trained on the Qwen2.5 base and significantly enhanced through reinforcement learning. It achieves performance comparable to ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"www.alibabacloud.com"}]},{"type":"search_result_group","domain":"huggingface.co","entries":[{"type":"search_result","url":"https://huggingface.co/openai/gpt-oss-20b","title":"openai/gpt-oss-20b","snippet":"8 Aug 2025 \u2014 gpt-oss-20b \u2014 for lower latency, and local or specialized use cases (21B parameters with 3.6B active parameters). Both models were trained on ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/collections/Qwen/qwen25","title":"Qwen2.5 - a Qwen Collection","snippet":"Qwen2.5. updated Dec 30, 2025. Qwen2.5 language models, including pretrained and instruction-tuned models of 7 sizes ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/collections/Qwen/qwen3","title":"Qwen3 - a Qwen Collection","snippet":"Qwen/Qwen3-14B-AWQ. Text Generation \u2022 15B \u2022 Updated May 20, 2025 \u2022 540k \u2022 55 \u00b7 Qwen/Qwen3-8B-AWQ. Text Generation \u2022 Updated May 20, 2025 \u2022 132k \u2022 37 \u00b7 Qwen/ ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"huggingface.co"}]},{"type":"search_result_group","domain":"github.com","entries":[{"type":"search_result","url":"https://github.com/QwenLM/Qwen3","title":"QwenLM/Qwen3","snippet":"2024.09.19: We released the Qwen2.5 series. This time there are 3 extra model sizes: 3B, 14B, and 32B for more possibilities. Check ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"github.com"}]},{"type":"search_result_group","domain":"openai.com","entries":[{"type":"search_result","url":"https://openai.com/index/introducing-gpt-oss/","title":"Introducing gpt-oss","snippet":"5 Aug 2025 \u2014 gpt-oss-120b activates 5.1B parameters per token, while gpt-oss-20b activates 3.6B. The models have 117b and 21b total parameters respectively.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"openai.com"}]},{"type":"search_result_group","domain":"developers.openai.com","entries":[{"type":"search_result","url":"https://developers.openai.com/api/docs/models/gpt-oss-20b","title":"gpt-oss-20b Model | OpenAI API","snippet":"gpt-oss-20b is our medium-sized open-weight model for low latency, local, or specialized use-cases (21B parameters with 3.6B active parameters).Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"developers.openai.com"}]},{"type":"search_result_group","domain":"openrouter.ai","entries":[{"type":"search_result","url":"https://openrouter.ai/qwen","title":"Qwen","snippet":"Qwen3-235B-A22B is a 235B parameter mixture-of-experts (MoE) model developed by Qwen, activating 22B parameters per forward pass. It supports seamless ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"openrouter.ai"}]},{"type":"search_result_group","domain":"llm-stats.com","entries":[{"type":"search_result","url":"https://llm-stats.com/models/compare/codestral-22b-vs-qwen-2.5-14b-instruct","title":"Codestral-22B vs Qwen2.5 14B Instruct Comparison","snippet":"Codestral-22B was released on 2024-05-29, while Qwen2.5 14B Instruct was released on 2024-09-19. Qwen2.5 14B Instruct is 4 months newer than Codestral-22B.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"llm-stats.com"}]},{"type":"search_result_group","domain":"www.tomshardware.com","entries":[{"type":"search_result","url":"https://www.tomshardware.com/tech-industry/artificial-intelligence/openai-intros-two-lightweight-open-model-language-models-that-can-run-on-consumer-gpus-optimized-to-run-on-devices-with-just-16gb-of-memory","title":"OpenAI intros two open-weight language models that can run on consumer GPUs - optimized to run on devices with just 16GB of memory","snippet":"OpenAI has introduced two new open-weight language models, \"gpt-oss-120b\" and \"gpt-oss-20b,\" both optimized for consumer-grade GPUs. The gpt-oss-120b model is designed to operate on a single 80GB GPU, while gpt-oss-20b can run on edge devices with just 16GB of memory. These models employ a Transformer architecture with mixture-of-experts, dense and sparse attention patterns, and grouped multi-query attention. They support an extensive context length of up to 131,072 tokens.\n\nThe models are built for Chain-of-Thought reasoning and balance performance, efficiency, and practical usability. Remarkably, they are the first open-weight models OpenAI has released since GPT-2, and they are licensed under Apache 2.0 to promote broader adoption, particularly in markets with limited access to proprietary models.\n\nPerformance-wise, gpt-oss-120b rivals OpenAI\u2019s o4-mini model and surpasses it in specific tasks like health-related queries and competitive math. Meanwhile, gpt-oss-20b matches o3-mini\u2019s capabilities while being significantly lighter. Both models are currently supported across multiple platforms, including ONNX Runtime, Azure, AWS, and Ollama.","ref_id":{"turn_index":0,"ref_type":"news","ref_index":40},"pub_date":1754587519.0,"attribution":"www.tomshardware.com"}]},{"type":"search_result_group","domain":"www.theverge.com","entries":[{"type":"search_result","url":"https://www.theverge.com/openai/718785/openai-gpt-oss-open-model-release","title":"OpenAI releases a free GPT model that can run on your laptop","snippet":"OpenAI has released a new open-weight model called GPT-OSS, marking its first such release in over six years. Available in two variants\u2014a 120-billion-parameter model and a 20-billion-parameter model\u2014GPT-OSS can be run locally on laptops or via cloud platforms such as Hugging Face, Databricks, Azure, and AWS. The models, licensed under Apache 2.0, are free to use and can be modified for commercial purposes. The larger version runs with a single Nvidia GPU and compares to OpenAI's o4-mini, while the smaller version, requiring just 16GB of VRAM, performs similarly to the o3-mini. GPT-OSS supports reasoning, coding, web browsing, and agent operation through OpenAI APIs.\n\nAfter previously withholding open models due to safety concerns, OpenAI now aims to support a growing developer community favoring customizable, cost-effective alternatives. GPT-OSS includes robust safety evaluations and features transparent reasoning processes. Although benchmark comparisons to other open models like Llama and DeepSeek are not provided, OpenAI asserts GPT-OSS matches performance on numerous tests with its closed reasoning models. The company hopes the model empowers smaller developers and companies to innovate with more control over their data.","ref_id":{"turn_index":0,"ref_type":"news","ref_index":42},"pub_date":1754413252.0,"attribution":"www.theverge.com"}]}],"safe_urls":["https://developers.openai.com/api/docs/models/gpt-oss-20b","https://en.wikipedia.org/wiki/Qwen","https://github.com/QwenLM/Qwen3","https://huggingface.co/collections/Qwen/qwen25","https://huggingface.co/collections/Qwen/qwen3","https://huggingface.co/openai/gpt-oss-20b","https://llm-stats.com/models/compare/codestral-22b-vs-qwen-2.5-14b-instruct","https://openai.com/index/introducing-gpt-oss/","https://openrouter.ai/qwen","https://qwen.ai/blog?from=research.latest-advancements-list&id=4074cca80393150c248e508aa62983f9cb7d27cd","https://qwen.ai/blog?id=qwen3","https://www.alibabacloud.com/help/en/model-studio/models","https://www.reuters.com/world/china/alibaba-unveils-new-qwen35-model-agentic-ai-era-2026-02-16/","https://www.theverge.com/openai/718785/openai-gpt-oss-open-model-release","https://www.tomshardware.com/tech-industry/artificial-intelligence/openai-intros-two-lightweight-open-model-language-models-that-can-run-on-consumer-gpus-optimized-to-run-on-devices-with-just-16gb-of-memory"],"can_save":true},"recipient":"all","channel":null},"parent":"a362ce85-1314-49dc-8101-e6274c4ec7b3","children":["a05a8fcb-310e-4b4d-b93d-1513291fc316"]},"a05a8fcb-310e-4b4d-b93d-1513291fc316":{"id":"a05a8fcb-310e-4b4d-b93d-1513291fc316","message":{"id":"a05a8fcb-310e-4b4d-b93d-1513291fc316","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1771327778.584593,"update_time":null,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"{\"open\":[{\"ref_id\":\"turn1search2\"},{\"ref_id\":\"turn1search5\"},{\"ref_id\":\"turn0search0\"}],\"response_length\":\"short\"}"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"citations":[],"content_references":[],"resolved_model_slug":"gpt-5-2-auto-thinking","model_slug":"gpt-5-2-thinking","hide_inline_actions":true,"disable_turn_actions":true,"request_id":"e4e327e4-970c-4bf1-933f-87a7b1ca8371","message_type":"next","default_model_slug":"gpt-5-2","parent_id":"69acea42-98d9-44ea-8c8c-e04e23062f0d","turn_exchange_id":"6e9e1782-65cc-446d-9765-b96314b77cd9","reasoning_status":"is_reasoning","reasoning_title":"Opening Qwen3.5 blog for model lineup analysis","classifier_response":"default","can_save":true},"recipient":"web.run","channel":null},"parent":"0d1d35ae-40ca-4c93-80e2-33cbbf7a59b1","children":["9b2d23ca-7814-46eb-96ba-bf07584ccfb7"]},"9b2d23ca-7814-46eb-96ba-bf07584ccfb7":{"id":"9b2d23ca-7814-46eb-96ba-bf07584ccfb7","message":{"id":"9b2d23ca-7814-46eb-96ba-bf07584ccfb7","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1771327781.3792317,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_result_groups":[{"type":"search_result_group","domain":"qwen.ai","entries":[{"type":"search_result","url":"https://qwen.ai/blog?id=qwen3.5","title":"Qwen","snippet":"Total lines: 0\n","ref_id":{"turn_index":2,"ref_type":"view","ref_index":0},"pub_date":null,"attribution":"qwen.ai"},{"type":"search_result","url":"https://qwen.ai/blog?id=qwen3","title":"Qwen","snippet":"Total lines: 0\n","ref_id":{"turn_index":2,"ref_type":"view","ref_index":2},"pub_date":null,"attribution":"qwen.ai"}]},{"type":"search_result_group","domain":"github.com","entries":[{"type":"search_result","url":"https://github.com/QwenLM/Qwen3.5","title":"GitHub - QwenLM/Qwen3.5: Qwen3.5 is the large language model series developed by Qwen team, Alibaba Cloud.","snippet":"Total lines: 411\n","ref_id":{"turn_index":2,"ref_type":"view","ref_index":1},"pub_date":null,"attribution":"github.com"}]}],"debug_sonic_thread_id":"thread_6994510f5370833181a7c0568e68bd6e","model_slug":"gpt-5-2-thinking","hide_inline_actions":true,"disable_turn_actions":true,"request_id":"e4e327e4-970c-4bf1-933f-87a7b1ca8371","message_type":"next","default_model_slug":"gpt-5-2","parent_id":"a05a8fcb-310e-4b4d-b93d-1513291fc316","turn_exchange_id":"6e9e1782-65cc-446d-9765-b96314b77cd9","reasoning_status":"is_reasoning","reasoning_title":"Opening Qwen3.5 blog for model lineup analysis","classifier_response":"default","can_save":false},"recipient":"all","channel":null},"parent":"a05a8fcb-310e-4b4d-b93d-1513291fc316","children":["0cae79c9-bccd-4aec-89b8-7c45c1c887df"]},"0cae79c9-bccd-4aec-89b8-7c45c1c887df":{"id":"0cae79c9-bccd-4aec-89b8-7c45c1c887df","message":{"id":"0cae79c9-bccd-4aec-89b8-7c45c1c887df","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1771327793.862333,"update_time":null,"content":{"content_type":"reasoning_recap","content":"Thought for 44s"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"reasoning_ended","finished_duration_sec":44,"search_result_groups":[{"type":"search_result_group","domain":"www.reuters.com","entries":[{"type":"search_result","url":"https://www.reuters.com/world/china/alibaba-unveils-new-qwen35-model-agentic-ai-era-2026-02-16/","title":"Alibaba unveils new Qwen3.5 model for 'agentic AI era'","snippet":"Alibaba has launched a new artificial intelligence model, Qwen 3.5, designed to independently perform complex tasks with improved efficiency and lower operational costs. The company claims the model is 60% cheaper and eight times more powerful in handling large workloads than its predecessor. Qwen 3.5 introduces \"visual agentic capabilities,\" enabling it to take actions across both mobile and desktop applications\u2014signaling Alibaba's push into the \"agentic AI\" era.\n\nThis move aims to boost adoption of its Qwen chatbot app in China, following stiff competition from ByteDance\u2019s Doubao and the globally recognized AI firm DeepSeek. ByteDance recently updated its own chatbot to Doubao 2.0. Alibaba's prior marketing drive, including a coupon giveaway tied to the Qwen chatbot, led to a sevenfold surge in active users despite technical issues.\n\nAlthough Alibaba did not mention DeepSeek in its latest release, Qwen 3.5 reportedly outperforms U.S. models including GPT-5.2, Claude Opus 4.5, and Gemini 3 Pro. DeepSeek is expected to unveil its next-gen model soon, which could further intensify the competitive dynamic within China\u2019s rapidly evolving AI sector.","ref_id":{"turn_index":0,"ref_type":"news","ref_index":34},"pub_date":1771232517.0,"attribution":"www.reuters.com"}]},{"type":"search_result_group","domain":"qwen.ai","entries":[{"type":"search_result","url":"https://qwen.ai/blog?id=qwen3","title":"Qwen3","snippet":"Today, we are excited to announce the release of Qwen3, the latest addition to the Qwen family of large language models. Our flagship model, Qwen3-235B-A22B ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":0},"pub_date":null,"attribution":"qwen.ai"},{"type":"search_result","url":"https://qwen.ai/blog?from=research.latest-advancements-list&id=4074cca80393150c248e508aa62983f9cb7d27cd","title":"Qwen3-Next","snippet":"10 Sept 2025 \u2014 To further improve training and inference efficiency under long-context and large-parameter settings, we design a brand-new model architecture ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"qwen.ai"}]},{"type":"search_result_group","domain":"en.wikipedia.org","entries":[{"type":"search_result","url":"https://en.wikipedia.org/wiki/Qwen","title":"Qwen","snippet":"","ref_id":{"turn_index":0,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"en.wikipedia.org"}]},{"type":"search_result_group","domain":"www.alibabacloud.com","entries":[{"type":"search_result","url":"https://www.alibabacloud.com/help/en/model-studio/models","title":"Alibaba Cloud Model Studio:Model list","snippet":"QwQ. QwQ is a reasoning model trained on the Qwen2.5 base and significantly enhanced through reinforcement learning. It achieves performance comparable to ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"www.alibabacloud.com"}]},{"type":"search_result_group","domain":"huggingface.co","entries":[{"type":"search_result","url":"https://huggingface.co/openai/gpt-oss-20b","title":"openai/gpt-oss-20b","snippet":"8 Aug 2025 \u2014 gpt-oss-20b \u2014 for lower latency, and local or specialized use cases (21B parameters with 3.6B active parameters). Both models were trained on ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/collections/Qwen/qwen25","title":"Qwen2.5 - a Qwen Collection","snippet":"Qwen2.5. updated Dec 30, 2025. Qwen2.5 language models, including pretrained and instruction-tuned models of 7 sizes ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/collections/Qwen/qwen3","title":"Qwen3 - a Qwen Collection","snippet":"Qwen/Qwen3-14B-AWQ. Text Generation \u2022 15B \u2022 Updated May 20, 2025 \u2022 540k \u2022 55 \u00b7 Qwen/Qwen3-8B-AWQ. Text Generation \u2022 Updated May 20, 2025 \u2022 132k \u2022 37 \u00b7 Qwen/ ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"huggingface.co"}]},{"type":"search_result_group","domain":"github.com","entries":[{"type":"search_result","url":"https://github.com/QwenLM/Qwen3","title":"QwenLM/Qwen3","snippet":"2024.09.19: We released the Qwen2.5 series. This time there are 3 extra model sizes: 3B, 14B, and 32B for more possibilities. Check ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"github.com"}]},{"type":"search_result_group","domain":"openai.com","entries":[{"type":"search_result","url":"https://openai.com/index/introducing-gpt-oss/","title":"Introducing gpt-oss","snippet":"5 Aug 2025 \u2014 gpt-oss-120b activates 5.1B parameters per token, while gpt-oss-20b activates 3.6B. The models have 117b and 21b total parameters respectively.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"openai.com"}]},{"type":"search_result_group","domain":"developers.openai.com","entries":[{"type":"search_result","url":"https://developers.openai.com/api/docs/models/gpt-oss-20b","title":"gpt-oss-20b Model | OpenAI API","snippet":"gpt-oss-20b is our medium-sized open-weight model for low latency, local, or specialized use-cases (21B parameters with 3.6B active parameters).Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"developers.openai.com"}]},{"type":"search_result_group","domain":"openrouter.ai","entries":[{"type":"search_result","url":"https://openrouter.ai/qwen","title":"Qwen","snippet":"Qwen3-235B-A22B is a 235B parameter mixture-of-experts (MoE) model developed by Qwen, activating 22B parameters per forward pass. It supports seamless ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"openrouter.ai"}]},{"type":"search_result_group","domain":"llm-stats.com","entries":[{"type":"search_result","url":"https://llm-stats.com/models/compare/codestral-22b-vs-qwen-2.5-14b-instruct","title":"Codestral-22B vs Qwen2.5 14B Instruct Comparison","snippet":"Codestral-22B was released on 2024-05-29, while Qwen2.5 14B Instruct was released on 2024-09-19. Qwen2.5 14B Instruct is 4 months newer than Codestral-22B.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"llm-stats.com"}]},{"type":"search_result_group","domain":"www.tomshardware.com","entries":[{"type":"search_result","url":"https://www.tomshardware.com/tech-industry/artificial-intelligence/openai-intros-two-lightweight-open-model-language-models-that-can-run-on-consumer-gpus-optimized-to-run-on-devices-with-just-16gb-of-memory","title":"OpenAI intros two open-weight language models that can run on consumer GPUs - optimized to run on devices with just 16GB of memory","snippet":"OpenAI has introduced two new open-weight language models, \"gpt-oss-120b\" and \"gpt-oss-20b,\" both optimized for consumer-grade GPUs. The gpt-oss-120b model is designed to operate on a single 80GB GPU, while gpt-oss-20b can run on edge devices with just 16GB of memory. These models employ a Transformer architecture with mixture-of-experts, dense and sparse attention patterns, and grouped multi-query attention. They support an extensive context length of up to 131,072 tokens.\n\nThe models are built for Chain-of-Thought reasoning and balance performance, efficiency, and practical usability. Remarkably, they are the first open-weight models OpenAI has released since GPT-2, and they are licensed under Apache 2.0 to promote broader adoption, particularly in markets with limited access to proprietary models.\n\nPerformance-wise, gpt-oss-120b rivals OpenAI\u2019s o4-mini model and surpasses it in specific tasks like health-related queries and competitive math. Meanwhile, gpt-oss-20b matches o3-mini\u2019s capabilities while being significantly lighter. Both models are currently supported across multiple platforms, including ONNX Runtime, Azure, AWS, and Ollama.","ref_id":{"turn_index":0,"ref_type":"news","ref_index":40},"pub_date":1754587519.0,"attribution":"www.tomshardware.com"}]},{"type":"search_result_group","domain":"www.theverge.com","entries":[{"type":"search_result","url":"https://www.theverge.com/openai/718785/openai-gpt-oss-open-model-release","title":"OpenAI releases a free GPT model that can run on your laptop","snippet":"OpenAI has released a new open-weight model called GPT-OSS, marking its first such release in over six years. Available in two variants\u2014a 120-billion-parameter model and a 20-billion-parameter model\u2014GPT-OSS can be run locally on laptops or via cloud platforms such as Hugging Face, Databricks, Azure, and AWS. The models, licensed under Apache 2.0, are free to use and can be modified for commercial purposes. The larger version runs with a single Nvidia GPU and compares to OpenAI's o4-mini, while the smaller version, requiring just 16GB of VRAM, performs similarly to the o3-mini. GPT-OSS supports reasoning, coding, web browsing, and agent operation through OpenAI APIs.\n\nAfter previously withholding open models due to safety concerns, OpenAI now aims to support a growing developer community favoring customizable, cost-effective alternatives. GPT-OSS includes robust safety evaluations and features transparent reasoning processes. Although benchmark comparisons to other open models like Llama and DeepSeek are not provided, OpenAI asserts GPT-OSS matches performance on numerous tests with its closed reasoning models. The company hopes the model empowers smaller developers and companies to innovate with more control over their data.","ref_id":{"turn_index":0,"ref_type":"news","ref_index":42},"pub_date":1754413252.0,"attribution":"www.theverge.com"}]}],"safe_urls":["https://developers.openai.com/api/docs/models/gpt-oss-20b","https://en.wikipedia.org/wiki/Qwen","https://github.com/QwenLM/Qwen3","https://huggingface.co/collections/Qwen/qwen25","https://huggingface.co/collections/Qwen/qwen3","https://huggingface.co/openai/gpt-oss-20b","https://llm-stats.com/models/compare/codestral-22b-vs-qwen-2.5-14b-instruct","https://openai.com/index/introducing-gpt-oss/","https://openrouter.ai/qwen","https://qwen.ai/blog?from=research.latest-advancements-list&id=4074cca80393150c248e508aa62983f9cb7d27cd","https://qwen.ai/blog?id=qwen3","https://www.alibabacloud.com/help/en/model-studio/models","https://www.reuters.com/world/china/alibaba-unveils-new-qwen35-model-agentic-ai-era-2026-02-16/","https://www.theverge.com/openai/718785/openai-gpt-oss-open-model-release","https://www.tomshardware.com/tech-industry/artificial-intelligence/openai-intros-two-lightweight-open-model-language-models-that-can-run-on-consumer-gpus-optimized-to-run-on-devices-with-just-16gb-of-memory"],"model_slug":"gpt-5-2-thinking","hide_inline_actions":true,"disable_turn_actions":true,"request_id":"e4e327e4-970c-4bf1-933f-87a7b1ca8371","message_type":"next","default_model_slug":"gpt-5-2","parent_id":"9b2d23ca-7814-46eb-96ba-bf07584ccfb7","turn_exchange_id":"6e9e1782-65cc-446d-9765-b96314b77cd9","can_save":true},"recipient":"all","channel":null},"parent":"9b2d23ca-7814-46eb-96ba-bf07584ccfb7","children":["922b4fe2-c078-4232-8ce2-c69b0f066abe"]},"922b4fe2-c078-4232-8ce2-c69b0f066abe":{"id":"922b4fe2-c078-4232-8ce2-c69b0f066abe","message":{"id":"922b4fe2-c078-4232-8ce2-c69b0f066abe","author":{"role":"assistant","name":null,"metadata":{"real_author":"tool:web"}},"create_time":1771327781.604378,"update_time":null,"content":{"content_type":"text","parts":["If you mean **\u201caround the same total parameter count as `gpt-oss-20b` (\u224821B total parameters)\u201d**, then **Qwen doesn\u2019t currently have a ~20\u201322B dense model in its latest open-weight lineup**.\n\nWhat you *can* pick depends on what you mean by \u201csize\u201d:\n\n## Closest by total parameters (dense)\n- **Qwen3-14B** (latest generation, dense) \u2014 closest *below* 21B. \ue200cite\ue202turn0search1\ue202turn1search1\ue201  \n- Next step up is **Qwen3-32B** \u2014 substantially larger than 21B. \ue200cite\ue202turn0search1\ue202turn1search3\ue201  \n\nFor reference, **`gpt-oss-20b` is ~21B total parameters** (MoE architecture, 3.6B active per token). \ue200cite\ue202turn0search6\ue202turn0search3\ue201\n\n## Closest by \u201cactive compute\u201d (MoE-ish comparison)\nIf you care more about **active parameters per token / compute profile** than total weights, a more apples-to-apples Qwen option is:\n- **Qwen3-30B-A3B** (30B total, ~3B active) \u2014 its *active* size is in the same ballpark as `gpt-oss-20b` (3.6B active). \ue200cite\ue202turn0search1\ue202turn0search6\ue201  \n\n## \u201cLatest Qwen\u201d note\nAlibaba announced **Qwen3.5** on **Feb 16, 2026**, but the first public open-weight drop appears to be a **very large MoE model (397B-A17B)**, not a ~20B-class model. \ue200cite\ue202turn2view1\ue202turn1news36\ue201\n\n---\n\n### Practical recommendation\n- Want **closest \u201cfeel\u201d to 20B dense** and simpler deployment: **Qwen3-14B**. \ue200cite\ue202turn1search1\ue202turn0search1\ue201  \n- Want **similar \u201cactive compute\u201d** to `gpt-oss-20b` (MoE-style): **Qwen3-30B-A3B**. \ue200cite\ue202turn0search1\ue202turn0search6\ue201  \n\nIf you tell me your constraint (VRAM limit? CPU-only? target latency?), I\u2019ll pick the best match and suggest an inference stack (vLLM / llama.cpp / MLX) accordingly."]},"status":"finished_successfully","end_turn":true,"weight":1.0,"metadata":{"content_references":[{"matched_text":"\ue200cite\ue202turn0search1\ue202turn1search1\ue201","start_idx":354,"end_idx":386,"safe_urls":["https://en.wikipedia.org/wiki/Qwen","https://en.wikipedia.org/wiki/Qwen?utm_source=chatgpt.com","https://huggingface.co/Qwen/Qwen3-14B","https://huggingface.co/Qwen/Qwen3-14B?utm_source=chatgpt.com"],"refs":[],"alt":"([Wikipedia](https://en.wikipedia.org/wiki/Qwen?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Qwen","url":"https://en.wikipedia.org/wiki/Qwen?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[{"title":"Qwen/Qwen3-14B","url":"https://huggingface.co/Qwen/Qwen3-14B?utm_source=chatgpt.com","pub_date":null,"snippet":"14 May 2025 \u2014 Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models.Read more","attribution":"Hugging Face"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":1},{"turn_index":1,"ref_type":"search","ref_index":1}],"hue":null,"attributions":null,"attribution":"Wikipedia"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search1\ue202turn1search3\ue201","start_idx":454,"end_idx":486,"safe_urls":["https://en.wikipedia.org/wiki/Qwen","https://en.wikipedia.org/wiki/Qwen?utm_source=chatgpt.com","https://huggingface.co/collections/Qwen/qwen3","https://huggingface.co/collections/Qwen/qwen3?utm_source=chatgpt.com"],"refs":[],"alt":"([Wikipedia](https://en.wikipedia.org/wiki/Qwen?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Qwen","url":"https://en.wikipedia.org/wiki/Qwen?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[{"title":"Qwen3 - a Qwen Collection","url":"https://huggingface.co/collections/Qwen/qwen3?utm_source=chatgpt.com","pub_date":null,"snippet":"We're on a journey to advance and democratize artificial intelligence through open source and open science.","attribution":"Hugging Face"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":1},{"turn_index":1,"ref_type":"search","ref_index":3}],"hue":null,"attributions":null,"attribution":"Wikipedia"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search6\ue202turn0search3\ue201","start_idx":591,"end_idx":623,"safe_urls":["https://huggingface.co/openai/gpt-oss-20b","https://huggingface.co/openai/gpt-oss-20b?utm_source=chatgpt.com","https://openai.com/index/introducing-gpt-oss/","https://openai.com/index/introducing-gpt-oss/?utm_source=chatgpt.com"],"refs":[],"alt":"([OpenAI](https://openai.com/index/introducing-gpt-oss/?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Introducing gpt-oss","url":"https://openai.com/index/introducing-gpt-oss/?utm_source=chatgpt.com","pub_date":null,"snippet":"5 Aug 2025 \u2014 gpt-oss-120b activates 5.1B parameters per token, while gpt-oss-20b activates 3.6B. The models have 117b and 21b total parameters respectively.Read more","attribution_segments":null,"supporting_websites":[{"title":"openai/gpt-oss-20b","url":"https://huggingface.co/openai/gpt-oss-20b?utm_source=chatgpt.com","pub_date":null,"snippet":"8 Aug 2025 \u2014 gpt-oss-20b \u2014 for lower latency, and local or specialized use cases (21B parameters with 3.6B active parameters). Both models were trained on ...Read more","attribution":"Hugging Face"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":6},{"turn_index":0,"ref_type":"search","ref_index":3}],"hue":null,"attributions":null,"attribution":"OpenAI"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search1\ue202turn0search6\ue201","start_idx":930,"end_idx":962,"safe_urls":["https://en.wikipedia.org/wiki/Qwen","https://en.wikipedia.org/wiki/Qwen?utm_source=chatgpt.com","https://openai.com/index/introducing-gpt-oss/","https://openai.com/index/introducing-gpt-oss/?utm_source=chatgpt.com"],"refs":[],"alt":"([Wikipedia](https://en.wikipedia.org/wiki/Qwen?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Qwen","url":"https://en.wikipedia.org/wiki/Qwen?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[{"title":"Introducing gpt-oss","url":"https://openai.com/index/introducing-gpt-oss/?utm_source=chatgpt.com","pub_date":null,"snippet":"5 Aug 2025 \u2014 gpt-oss-120b activates 5.1B parameters per token, while gpt-oss-20b activates 3.6B. The models have 117b and 21b total parameters respectively.Read more","attribution":"OpenAI"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":1},{"turn_index":0,"ref_type":"search","ref_index":6}],"hue":null,"attributions":null,"attribution":"Wikipedia"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn2view1\ue202turn1news36\ue201","start_idx":1155,"end_idx":1184,"safe_urls":["https://github.com/QwenLM/Qwen3.5","https://www.reuters.com/world/china/alibaba-unveils-new-qwen35-model-agentic-ai-era-2026-02-16/","https://www.reuters.com/world/china/alibaba-unveils-new-qwen35-model-agentic-ai-era-2026-02-16/?utm_source=chatgpt.com"],"refs":[],"alt":"([GitHub](https://github.com/QwenLM/Qwen3.5))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"GitHub - QwenLM/Qwen3.5: Qwen3.5 is the large language model series developed by Qwen team, Alibaba Cloud.","url":"https://github.com/QwenLM/Qwen3.5","pub_date":null,"snippet":null,"attribution_segments":null,"supporting_websites":[{"title":"Alibaba unveils new Qwen3.5 model for 'agentic AI era'","url":"https://www.reuters.com/world/china/alibaba-unveils-new-qwen35-model-agentic-ai-era-2026-02-16/?utm_source=chatgpt.com","pub_date":null,"snippet":"Alibaba has launched a new artificial intelligence model, Qwen 3.5, designed to independently perform complex tasks with improved efficiency and lower operational costs. The company claims the model is 60% cheaper and eight times more powerful in handling large workloads than its predecessor. Qwen 3.5 introduces \"visual agentic capabilities,\" enabling it to take actions across both mobile and desktop applications\u2014signaling Alibaba's push into the \"agentic AI\" era.\n\nThis move aims to boost adoption of its Qwen chatbot app in China, following stiff competition from ByteDance\u2019s Doubao and the globally recognized AI firm DeepSeek. ByteDance recently updated its own chatbot to Doubao 2.0. Alibaba's prior marketing drive, including a coupon giveaway tied to the Qwen chatbot, led to a sevenfold surge in active users despite technical issues.\n\nAlthough Alibaba did not mention DeepSeek in its latest release, Qwen 3.5 reportedly outperforms U.S. models including GPT-5.2, Claude Opus 4.5, and Gemini 3 Pro. DeepSeek is expected to unveil its next-gen model soon, which could further intensify the competitive dynamic within China\u2019s rapidly evolving AI sector.","attribution":"Reuters"}],"refs":[{"turn_index":2,"ref_type":"view","ref_index":1},{"turn_index":1,"ref_type":"news","ref_index":36}],"hue":null,"attributions":null,"attribution":"GitHub"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn1search1\ue202turn0search1\ue201","start_idx":1298,"end_idx":1330,"safe_urls":["https://en.wikipedia.org/wiki/Qwen","https://en.wikipedia.org/wiki/Qwen?utm_source=chatgpt.com","https://huggingface.co/Qwen/Qwen3-14B","https://huggingface.co/Qwen/Qwen3-14B?utm_source=chatgpt.com"],"refs":[],"alt":"([Hugging Face](https://huggingface.co/Qwen/Qwen3-14B?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Qwen/Qwen3-14B","url":"https://huggingface.co/Qwen/Qwen3-14B?utm_source=chatgpt.com","pub_date":null,"snippet":"14 May 2025 \u2014 Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models.Read more","attribution_segments":null,"supporting_websites":[{"title":"Qwen","url":"https://en.wikipedia.org/wiki/Qwen?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution":"Wikipedia"}],"refs":[{"turn_index":1,"ref_type":"search","ref_index":1},{"turn_index":0,"ref_type":"search","ref_index":1}],"hue":null,"attributions":null,"attribution":"Hugging Face"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search1\ue202turn0search6\ue201","start_idx":1418,"end_idx":1450,"safe_urls":["https://en.wikipedia.org/wiki/Qwen","https://en.wikipedia.org/wiki/Qwen?utm_source=chatgpt.com","https://openai.com/index/introducing-gpt-oss/","https://openai.com/index/introducing-gpt-oss/?utm_source=chatgpt.com"],"refs":[],"alt":"([Wikipedia](https://en.wikipedia.org/wiki/Qwen?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Qwen","url":"https://en.wikipedia.org/wiki/Qwen?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[{"title":"Introducing gpt-oss","url":"https://openai.com/index/introducing-gpt-oss/?utm_source=chatgpt.com","pub_date":null,"snippet":"5 Aug 2025 \u2014 gpt-oss-120b activates 5.1B parameters per token, while gpt-oss-20b activates 3.6B. The models have 117b and 21b total parameters respectively.Read more","attribution":"OpenAI"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":1},{"turn_index":0,"ref_type":"search","ref_index":6}],"hue":null,"attributions":null,"attribution":"Wikipedia"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":" ","start_idx":1619,"end_idx":1619,"safe_urls":[],"refs":[],"alt":"","prompt_text":null,"type":"sources_footnote","sources":[{"title":"Qwen","url":"https://en.wikipedia.org/wiki/Qwen?utm_source=chatgpt.com","attribution":"Wikipedia"},{"title":"Introducing gpt-oss","url":"https://openai.com/index/introducing-gpt-oss/?utm_source=chatgpt.com","attribution":"OpenAI"},{"title":"GitHub - QwenLM/Qwen3.5: Qwen3.5 is the large language model series developed by Qwen team, Alibaba Cloud.","url":"https://github.com/QwenLM/Qwen3.5","attribution":"GitHub"},{"title":"Qwen/Qwen3-14B","url":"https://huggingface.co/Qwen/Qwen3-14B?utm_source=chatgpt.com","attribution":"Hugging Face"}],"has_images":false}],"safe_urls":["https://en.wikipedia.org/wiki/Qwen","https://en.wikipedia.org/wiki/Qwen?utm_source=chatgpt.com","https://github.com/QwenLM/Qwen3.5","https://huggingface.co/Qwen/Qwen3-14B","https://huggingface.co/Qwen/Qwen3-14B?utm_source=chatgpt.com","https://huggingface.co/collections/Qwen/qwen3","https://huggingface.co/collections/Qwen/qwen3?utm_source=chatgpt.com","https://huggingface.co/openai/gpt-oss-20b","https://huggingface.co/openai/gpt-oss-20b?utm_source=chatgpt.com","https://openai.com/index/introducing-gpt-oss/","https://openai.com/index/introducing-gpt-oss/?utm_source=chatgpt.com","https://www.reuters.com/world/china/alibaba-unveils-new-qwen35-model-agentic-ai-era-2026-02-16/","https://www.reuters.com/world/china/alibaba-unveils-new-qwen35-model-agentic-ai-era-2026-02-16/?utm_source=chatgpt.com"],"search_result_groups":[{"type":"search_result_group","domain":"qwen.ai","entries":[{"type":"search_result","url":"https://qwen.ai/blog?id=qwen3&utm_source=chatgpt.com","title":"Qwen3","snippet":"Today, we are excited to announce the release of Qwen3, the latest addition to the Qwen family of large language models. Our flagship model, Qwen3-235B-A22B ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":0},"pub_date":null,"attribution":"qwen.ai"},{"type":"search_result","url":"https://qwen.ai/blog?from=research.latest-advancements-list&id=4074cca80393150c248e508aa62983f9cb7d27cd&utm_source=chatgpt.com","title":"Qwen3-Next","snippet":"10 Sept 2025 \u2014 To further improve training and inference efficiency under long-context and large-parameter settings, we design a brand-new model architecture ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"qwen.ai"},{"type":"search_result","url":"https://qwen.ai/blog?id=qwen3.5&utm_source=chatgpt.com","title":"Qwen3.5: Towards Native Multimodal Agents","snippet":"1 day ago \u2014 Qwen3.5 can help with web development, especially for frontend tasks like building web pages and designing user interfaces. It makes creating ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"qwen.ai"},{"type":"search_result","url":"https://qwen.ai/research?utm_source=chatgpt.com","title":"Qwen - Comprehensive Functionality","snippet":"Qwen3-TTS is a series of powerful speech generation capabilities developed by Qwen, offering comprehensive support for voice clone, voice design, ultra-high ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"qwen.ai"},{"type":"search_result","url":"https://qwen.ai/?utm_source=chatgpt.com","title":"Qwen - Chatbot, image, video, document, web integration","snippet":"Qwen Chat is an AI assistant for everyone, powered by the Qwen series models. It's free to use, open to all, and ready to help with creativity, ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"qwen.ai"}]},{"type":"search_result_group","domain":"alibabacloud.com","entries":[{"type":"search_result","url":"https://www.alibabacloud.com/help/en/model-studio/models?utm_source=chatgpt.com","title":"Alibaba Cloud Model Studio:Model list","snippet":"Flagship models. \u901a\u4e49new Qwen-Max. Ideal for complex tasks. The most powerful model. \u901a\u4e49new Qwen-Plus. A balance of performance, speed, and cost. \u901a\u4e49new ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"alibabacloud.com"}]},{"type":"search_result_group","domain":"huggingface.co","entries":[{"type":"search_result","url":"https://huggingface.co/openai/gpt-oss-20b?utm_source=chatgpt.com","title":"openai/gpt-oss-20b","snippet":"8 Aug 2025 \u2014 gpt-oss-20b \u2014 for lower latency, and local or specialized use cases (21B parameters with 3.6B active parameters). Both models were trained on ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/collections/Qwen/qwen25?utm_source=chatgpt.com","title":"Qwen2.5 - a Qwen Collection","snippet":"Qwen2.5. updated Dec 30, 2025. Qwen2.5 language models, including pretrained and instruction-tuned models of 7 sizes ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/collections/Qwen/qwen3?utm_source=chatgpt.com","title":"Qwen3 - a Qwen Collection","snippet":"Qwen/Qwen3-14B-AWQ. Text Generation \u2022 15B \u2022 Updated May 20, 2025 \u2022 540k \u2022 55 \u00b7 Qwen/Qwen3-8B-AWQ. Text Generation \u2022 Updated May 20, 2025 \u2022 132k \u2022 37 \u00b7 Qwen/ ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/Qwen?utm_source=chatgpt.com","title":"Qwen","snippet":"Welcome to Qwen. This is the organization of Qwen, which refers to the large language model family built by Alibaba Cloud.Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/Qwen/Qwen3.5-397B-A17B?utm_source=chatgpt.com","title":"Qwen/Qwen3.5-397B-A17B","snippet":"1 day ago \u2014 Qwen3.5 features the following enhancement: Unified Vision-Language Foundation: Early fusion training on multimodal tokens achieves cross- ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/Qwen/Qwen3-14B-Base?utm_source=chatgpt.com","title":"Qwen/Qwen3-14B-Base","snippet":"14 May 2025 \u2014 Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models.Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/Qwen/Qwen3-14B-FP8?utm_source=chatgpt.com","title":"Qwen/Qwen3-14B-FP8","snippet":"14 May 2025 \u2014 Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models.Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":23},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/Qwen/collections?utm_source=chatgpt.com","title":"Qwen - Hugging Face","snippet":"Org profile for Qwen on Hugging Face, the AI community building the future.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":33},"pub_date":null,"attribution":"huggingface.co"}]},{"type":"search_result_group","domain":"github.com","entries":[{"type":"search_result","url":"https://github.com/QwenLM/Qwen3?utm_source=chatgpt.com","title":"QwenLM/Qwen3","snippet":"2024.09.19: We released the Qwen2.5 series. This time there are 3 extra model sizes: 3B, 14B, and 32B for more possibilities. Check ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/QwenLM/Qwen-Image?utm_source=chatgpt.com","title":"QwenLM/Qwen-Image","snippet":"We are thrilled to release Qwen-Image, a 20B MMDiT image foundation model that achieves significant advances in complex text rendering and precise image ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/TIGER-AI-Lab/MMLU-Pro/issues/22?utm_source=chatgpt.com","title":"Add Qwen2.5 model family \u00b7 Issue #22 \u00b7 TIGER-AI-Lab ...","snippet":"20 Sept 2024 \u2014 Tracking issue for the Qwen2.5 model family. These models are SOTA in their sizes on many benchmarks, and most are released under an ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/openai/gpt-oss?utm_source=chatgpt.com","title":"openai/gpt-oss","snippet":"gpt-oss-20b \u2014 for lower latency, and local or specialized use cases (21B parameters with 3.6B active parameters). Both models were trained using our harmony ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":19},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/QwenLM/Qwen3.5?utm_source=chatgpt.com","title":"QwenLM/Qwen3.5","snippet":"1 day ago \u2014 Qwen3.5 represents a significant leap forward, integrating breakthroughs in multimodal learning, architectural efficiency, reinforcement ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"github.com"}]},{"type":"search_result_group","domain":"openai.com","entries":[{"type":"search_result","url":"https://developers.openai.com/api/docs/models/gpt-oss-20b?utm_source=chatgpt.com","title":"gpt-oss-20b Model | OpenAI API","snippet":"gpt-oss-20b is our medium-sized open-weight model for low latency, local, or specialized use-cases (21B parameters with 3.6B active parameters).Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"openai.com"},{"type":"search_result","url":"https://cdn.openai.com/pdf/419b6906-9da6-406c-a19d-1bb078ac7637/oai_gpt-oss_model_card.pdf?utm_source=chatgpt.com","title":"gpt-oss-120b & gpt-oss-20b Model Card","snippet":"5 Aug 2025 \u2014 forward pass), and gpt-oss-20b with 24 layers (20.9B total and 3.6B active parameters). Table 1 shows a full breakdown of the parameter counts.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":33},"pub_date":null,"attribution":"openai.com"}]},{"type":"search_result_group","domain":"openrouter.ai","entries":[{"type":"search_result","url":"https://openrouter.ai/qwen?utm_source=chatgpt.com","title":"Qwen","snippet":"Qwen3-235B-A22B is a 235B parameter mixture-of-experts (MoE) model developed by Qwen, activating 22B parameters per forward pass. It supports seamless ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"openrouter.ai"},{"type":"search_result","url":"https://openrouter.ai/openai/gpt-oss-20b%3Afree?utm_source=chatgpt.com","title":"gpt-oss-20b (free) - API, Providers, Stats","snippet":"5 Aug 2025 \u2014 gpt-oss-20b is an open-weight 21B parameter model released by OpenAI under the Apache 2.0 license. Run gpt-oss-20b (free) with API.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"openrouter.ai"}]},{"type":"search_result_group","domain":"llm-stats.com","entries":[{"type":"search_result","url":"https://llm-stats.com/models/compare/codestral-22b-vs-qwen-2.5-14b-instruct?utm_source=chatgpt.com","title":"Codestral-22B vs Qwen2.5 14B Instruct Comparison","snippet":"Codestral-22B was released on 2024-05-29, while Qwen2.5 14B Instruct was released on 2024-09-19. Qwen2.5 14B Instruct is 4 months newer than Codestral-22B.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"llm-stats.com"}]},{"type":"search_result_group","domain":"ollama.com","entries":[{"type":"search_result","url":"https://ollama.com/search?q=qwen&utm_source=chatgpt.com","title":"qwen \u00b7 Ollama Search","snippet":"The Qwen3.5 series 397B-A17B native vision-language model ... models by Alibaba Cloud spanning from 0.5B to 110B parameters. 0.5b 1.8b 4b 7b 14b 32b 72b 110b.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"ollama.com"},{"type":"search_result","url":"https://ollama.com/library/qwen3%3A14b?utm_source=chatgpt.com","title":"qwen3:14b","snippet":"Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":30},"pub_date":null,"attribution":"ollama.com"}]},{"type":"search_result_group","domain":"reddit.com","entries":[{"type":"search_result","url":"https://www.reddit.com/r/LocalLLaMA/comments/1iaizfb/qwen251m_release_on_huggingface_the_longcontext/?utm_source=chatgpt.com","title":"The long-context version of Qwen2.5, supporting 1M-token ...","snippet":"Qwen2.5-1M Release on HuggingFace - The long-context version of Qwen2.5, supporting 1M-token context lengths!Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":26},"pub_date":null,"attribution":"reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/LocalLLaMA/comments/1r657w5/qwen35_release_blog_post/?utm_source=chatgpt.com","title":"Qwen3.5 Release Blog Post : r/LocalLLaMA","snippet":"They released a flagship that, according to their claims, is better than gpt-5.2 and opus 4.6 in thinking variety; but this flagship is equally ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/LocalLLaMA/comments/1mvjdxh/which_model_is_less_demanding_on_resources/?utm_source=chatgpt.com","title":"which model is less demanding on resources, gpt-oss-20b ...","snippet":"gpt-oss-20b uses ~33% less memory than Qwen3-30B-A3B, but because of the similar number of active parameters, the compute cost is similar. If ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/LocalLLaMA/comments/1r60ety/qwen_35_will_be_released_today/?utm_source=chatgpt.com","title":"Qwen 3.5 will be released today : r/LocalLLaMA","snippet":"Sources reveal that Alibaba will open-source its next-generation large model, Qwen3.5, tonight on Lunar New Year's Eve. The ... The 0.6b qwen3 is ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/singularity/comments/1r65i6p/qwen35397ba17b_first_openweight_model_in_qwen35/?utm_source=chatgpt.com","title":"Qwen3.5-397B-A17B: First open-weight model in ...","snippet":"One of the interesting benchmarks I noticed is the ZeroBench, Qwen 3.5 scored 12 by surpassing other frontier models, interesting.Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"reddit.com"}]},{"type":"search_result_group","domain":"arxiv.org","entries":[{"type":"search_result","url":"https://arxiv.org/html/2409.12186v2?utm_source=chatgpt.com","title":"Qwen2.5-Coder Technical Report","snippet":"The release of these models aims to advance code intelligence research and promote widespread adoption in real-world applications, facilitated by permissive ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"arxiv.org"}]},{"type":"search_result_group","domain":"nvidia.com","entries":[{"type":"search_result","url":"https://build.nvidia.com/openai/gpt-oss-20b/modelcard?utm_source=chatgpt.com","title":"gpt-oss-20b Model by OpenAI","snippet":"5 Aug 2025 \u2014 Training Properties: The gpt-oss-20b model has approximately 20 billion total parameters, with approximately 4 billion active parameters per ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"nvidia.com"},{"type":"search_result","url":"https://build.nvidia.com/models?utm_source=chatgpt.com","title":"Models - Try NVIDIA NIM APIs","snippet":"qwen3.5-397b-a17b. Next-gen Qwen 3.5 VLM (400B MoE) brings advanced ... b-v2. Accurate and optimized English transcriptions with punctuation and word ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":22},"pub_date":null,"attribution":"nvidia.com"}]},{"type":"search_result_group","domain":"dev.to","entries":[{"type":"search_result","url":"https://dev.to/czmilo/2025-latest-complete-guide-to-qwen-image-edit-image-editing-model-2kd5?utm_source=chatgpt.com","title":"2025 Latest: Complete Guide to Qwen-Image-Edit ...","snippet":"18 Aug 2025 \u2014 Qwen-Image-Edit is the latest image editing foundation model released by Alibaba's Qwen team, built upon the 20B parameter Qwen-Image model.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"dev.to"}]},{"type":"search_result_group","domain":"medium.com","entries":[{"type":"search_result","url":"https://medium.com/%40ai-engineering-trend/qwen3-5-release-397b-parameter-model-with-native-multimodal-capabilities-and-8-19x-inference-f74076a6d080?utm_source=chatgpt.com","title":"Qwen3.5 Release: 397B Parameter Model with Native ...","snippet":"Qwen3.5 Release: 397B Parameter Model with Native Multimodal Capabilities and 8\u201319x Inference Efficiency Boost.Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"medium.com"}]},{"type":"search_result_group","domain":"reuters.com","entries":[{"type":"search_result","url":"https://www.reuters.com/world/china/alibaba-unveils-new-qwen35-model-agentic-ai-era-2026-02-16/?utm_source=chatgpt.com","title":"Alibaba unveils new Qwen3.5 model for 'agentic AI era'","snippet":"1 day ago \u2014 Alibaba said Qwen3.5 was 60% cheaper to use and eight times better at processing large workloads than its immediate predecessor, adding that ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"reuters.com"}]},{"type":"search_result_group","domain":"qwenlm.github.io","entries":[{"type":"search_result","url":"https://qwenlm.github.io/blog/qwen2.5/?utm_source=chatgpt.com","title":"Qwen2.5: A Party of Foundation Models!","snippet":"19 Sept 2024 \u2014 Qwen-Plus Instruct Performance. A significant update in Qwen2.5 is the reintroduction of our 14B and 32B models, Qwen2.5-14B and Qwen2.5-32B.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"qwenlm.github.io"},{"type":"search_result","url":"https://qwenlm.github.io/blog/qwen2.5-coder/?utm_source=chatgpt.com","title":"Qwen2.5-Coder: Code More, Learn More!","snippet":"19 Sept 2024 \u2014 Qwen2.5-Coder is part of the Qwen2.5 series, available in three model sizes: 1.5B, 7B, and a 32B version (coming soon).Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":20},"pub_date":null,"attribution":"qwenlm.github.io"},{"type":"search_result","url":"https://qwenlm.github.io/blog/qwen3/?utm_source=chatgpt.com","title":"Qwen3: Think Deeper, Act Faster | Qwen","snippet":"29 Apr 2025 \u2014 QWEN CHAT GitHub Hugging Face ModelScope Kaggle DEMO DISCORD Introduction Today, we are excited to announce the release of Qwen3, ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":27},"pub_date":null,"attribution":"qwenlm.github.io"}]},{"type":"search_result_group","domain":"unsloth.ai","entries":[{"type":"search_result","url":"https://unsloth.ai/docs/models/qwen3-how-to-run-and-fine-tune?utm_source=chatgpt.com","title":"Qwen3 - How to Run & Fine-tune","snippet":"Qwen3 - Unsloth Dynamic 2.0 with optimal configs: \u00b7 0.6B \u00b7 1.7B \u00b7 4B \u00b7 8B \u00b7 14B \u00b7 30B-A3B \u00b7 32B ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"unsloth.ai"},{"type":"search_result","url":"https://unsloth.ai/docs/models/qwen3.5?utm_source=chatgpt.com","title":"Qwen3.5 - How to Run Locally Guide","snippet":"1 day ago \u2014 Qwen3.5 is Alibaba's new model family, including Qwen3.5-397B-A17B, a 397B-parameter (17B active) multimodal reasoning model with ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":25},"pub_date":null,"attribution":"unsloth.ai"}]},{"type":"search_result_group","domain":"siliconflow.com","entries":[{"type":"search_result","url":"https://www.siliconflow.com/models/compare/qwen2-5-32b-instruct-vs-qwen3-14b?utm_source=chatgpt.com","title":"Qwen2.5-32B-Instruct vs Qwen3-14B \u2013 Performance, Pricing","snippet":"4 Feb 2026 \u2014 Compare Qwen2.5-32B-Instruct and Qwen3-14B across performance, cost, capabilities, and real-world use cases. See which model fits your ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":21},"pub_date":null,"attribution":"siliconflow.com"},{"type":"search_result","url":"https://www.siliconflow.com/articles/en/the-best-qwen-models-in-2025?utm_source=chatgpt.com","title":"Ultimate Guide - The Best Qwen Models in 2026","snippet":"Qwen3-235B-A22B is the flagship large language model in the Qwen series, featuring a Mixture-of-Experts (MoE) architecture with 235B total parameters and 22B ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":22},"pub_date":null,"attribution":"siliconflow.com"}]},{"type":"search_result_group","domain":"analyticsvidhya.com","entries":[{"type":"search_result","url":"https://www.analyticsvidhya.com/blog/2026/02/qwen3-5-open-weight-qwen3-5-plus/?utm_source=chatgpt.com","title":"We Tested The New Qwen3.5 Open Weight, Qwen3.5-Plus","snippet":"18 hours ago \u2014 The Qwen 3.5 series is out, bringing multimodal intelligence, agentic abilities, and efficiency for real-world workloads.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":21},"pub_date":null,"attribution":"analyticsvidhya.com"}]},{"type":"search_result_group","domain":"together.ai","entries":[{"type":"search_result","url":"https://www.together.ai/qwen?utm_source=chatgpt.com","title":"Qwen Models Family | Together AI","snippet":"Explore the full lineup of Qwen open-source models, ideal for developing hybrid AI with multi-language support and excellent performance at coding, ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":23},"pub_date":null,"attribution":"together.ai"}]},{"type":"search_result_group","domain":"huaweicloud.com","entries":[{"type":"search_result","url":"https://support.huaweicloud.com/intl/en-us/productdesc-pangulm/pangulm_01_0029.html?utm_source=chatgpt.com","title":"Third-Party Large Models - \u534e\u4e3a\u4e91","snippet":"7 Jan 2026 \u2014 It supports Qwen3 series models (Qwen3-8B/14B/30B-A3B/32B/235B-A22B), DeepSeek-R1-Distill-Qwen-32B, DeepSeek-R1-Distill-LLama-70B/8B, Qwen2.5- ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":24},"pub_date":null,"attribution":"huaweicloud.com"}]},{"type":"search_result_group","domain":"ycombinator.com","entries":[{"type":"search_result","url":"https://news.ycombinator.com/item?id=47032876&utm_source=chatgpt.com","title":"Qwen3.5: Towards Native Multimodal Agents","snippet":"1 hour ago \u2014 Those Ryzen AI Max+ 395 systems are all more or less the same. For inference you want the one with 128GB soldered RAM. There are ones from ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":24},"pub_date":null,"attribution":"ycombinator.com"}]},{"type":"search_result_group","domain":"linkedin.com","entries":[{"type":"search_result","url":"https://www.linkedin.com/pulse/qwen-3-most-advanced-hybrid-open-source-ai-model-from-alibaba-pm7xe?utm_source=chatgpt.com","title":"Qwen 3: The most advanced 'hybrid' open-source AI model ...","snippet":"As one of the most advanced \"hybrid\" open-source AI models available today, it combines cutting-edge technology with unparalleled flexibility.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":25},"pub_date":null,"attribution":"linkedin.com"}]},{"type":"search_result_group","domain":"facebook.com","entries":[{"type":"search_result","url":"https://www.facebook.com/saturngod.blog.news/posts/qwen-35-soon/1493102952816696/?utm_source=chatgpt.com","title":"Qwen 3.5 soon","snippet":"\u2713 Versatile Model Sizes: Available in 0.6B, 4B, and 8B variants ... Besides the 32B coder, we have coders of 0.5B / 1.5B / 3B / 7B / 14B!","ref_id":{"turn_index":1,"ref_type":"search","ref_index":26},"pub_date":null,"attribution":"facebook.com"}]},{"type":"search_result_group","domain":"modelscope.cn","entries":[{"type":"search_result","url":"https://modelscope.cn/models/Qwen/Qwen3-14B?utm_source=chatgpt.com","title":"Qwen/Qwen3-14B","snippet":"Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":27},"pub_date":null,"attribution":"modelscope.cn"},{"type":"search_result","url":"https://modelscope.cn/models/Qwen/Qwen3.5-397B-A17B?utm_source=chatgpt.com","title":"Qwen3.5-397B-A17B","snippet":"Next-Generation Training Infrastructure: Near-100% multimodal training efficiency compared to text-only training and asynchronous RL frameworks supporting ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":28},"pub_date":null,"attribution":"modelscope.cn"}]},{"type":"search_result_group","domain":"qwenimages.com","entries":[{"type":"search_result","url":"https://www.qwenimages.com/blog/qwen-image-release?utm_source=chatgpt.com","title":"Qwen-Image Open Source Release! Alibaba's 20B Parameter ...","snippet":"Alibaba's Tongyi Qianwen team officially open-sources Qwen-Image, a 20B parameter MMDiT model achieving significant breakthroughs in complex text rendering ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":28},"pub_date":null,"attribution":"qwenimages.com"}]},{"type":"search_result_group","domain":"kaggle.com","entries":[{"type":"search_result","url":"https://www.kaggle.com/models/qwen-lm/qwen2.5?utm_source=chatgpt.com","title":"QwenLM | Qwen2.5","snippet":"14 Nov 2024 \u2014 For Qwen2.5, we release a number of base language models and instruction-tuned language models ranging from 0.5 to 72 billion parameters. Qwen2.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":29},"pub_date":null,"attribution":"kaggle.com"}]},{"type":"search_result_group","domain":"understandingai.org","entries":[{"type":"search_result","url":"https://www.understandingai.org/p/the-best-chinese-open-weight-models?utm_source=chatgpt.com","title":"The best Chinese open-weight models","snippet":"15 Dec 2025 \u2014 The fact that Qwen is Chinese might be the biggest barrier for the average US firm. Models: Qwen3 4B Thinking: Released April 26, 2025.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":30},"pub_date":null,"attribution":"understandingai.org"}]},{"type":"search_result_group","domain":"oracle.com","entries":[{"type":"search_result","url":"https://docs.oracle.com/en-us/iaas/Content/generative-ai/openai-gpt-oss-20b.htm?utm_source=chatgpt.com","title":"OpenAI gpt-oss-20b","snippet":"9 Feb 2026 \u2014 gpt-oss-20b is an open-weight, text-only language model designed for powerful reasoning and agentic tasks. Available in These Commercial RegionsRead more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":31},"pub_date":null,"attribution":"oracle.com"}]},{"type":"search_result_group","domain":"datacamp.com","entries":[{"type":"search_result","url":"https://www.datacamp.com/blog/qwen3-5?utm_source=chatgpt.com","title":"Qwen3.5: Features, Access, and Benchmarks","snippet":"17 hours ago \u2014 Learn about the new Qwen3.5 series of models, covering the key features, costs, how to access, and how it compares to other similar models.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":31},"pub_date":null,"attribution":"datacamp.com"}]},{"type":"search_result_group","domain":"lmstudio.ai","entries":[{"type":"search_result","url":"https://lmstudio.ai/models/openai/gpt-oss-20b?utm_source=chatgpt.com","title":"gpt-oss","snippet":"29 Aug 2025 \u2014 Designed for lower latency and specialized or local deployment, the model has 21B total parameters with only 3.6B active at a time. Thanks to ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":32},"pub_date":null,"attribution":"lmstudio.ai"}]},{"type":"search_result_group","domain":"zenmux.ai","entries":[{"type":"search_result","url":"https://zenmux.ai/models?utm_source=chatgpt.com","title":"Models","snippet":"Qwen ... Feb 16,2026 - 3 PM100.00%. Qwen: Qwen3 14B. qwen/qwen3-14b. API Request \u00b7 Chat. 22.01Mtokens. Qwen3-14B is a dense 14.8B ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":32},"pub_date":null,"attribution":"zenmux.ai"}]},{"type":"search_result_group","domain":"artificialanalysis.ai","entries":[{"type":"search_result","url":"https://artificialanalysis.ai/models/comparisons/qwen3-max-vs-gpt-oss-20b?utm_source=chatgpt.com","title":"Qwen3 Max vs gpt-oss-20B (high): Model Comparison","snippet":"Comparison between Qwen3 Max and gpt-oss-20B (high) across intelligence, price, speed, context window and more.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":35},"pub_date":null,"attribution":"artificialanalysis.ai"}]}],"citations":[],"resolved_model_slug":"gpt-5-2-auto-thinking","model_slug":"gpt-5-2-thinking","request_id":"e4e327e4-970c-4bf1-933f-87a7b1ca8371","message_type":"next","default_model_slug":"gpt-5-2","parent_id":"0cae79c9-bccd-4aec-89b8-7c45c1c887df","turn_exchange_id":"6e9e1782-65cc-446d-9765-b96314b77cd9","can_save":true},"recipient":"all","channel":"final"},"parent":"0cae79c9-bccd-4aec-89b8-7c45c1c887df","children":["60fa5170-7304-4a7b-b2f6-71c4c6cd1f6b"]},"60fa5170-7304-4a7b-b2f6-71c4c6cd1f6b":{"id":"60fa5170-7304-4a7b-b2f6-71c4c6cd1f6b","message":{"id":"60fa5170-7304-4a7b-b2f6-71c4c6cd1f6b","author":{"role":"user","name":null,"metadata":{}},"create_time":1771329838.791,"update_time":null,"content":{"content_type":"text","parts":["How about the Kimi family of models?"]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"developer_mode_connector_ids":[],"selected_sources":[],"selected_github_repos":["EjayNg-AI/agentic_browser"],"serialization_metadata":{"custom_symbol_offsets":[]},"request_id":"440cf611-d1f1-4ba5-82ae-d494323333dc","message_source":null,"turn_exchange_id":"244c6745-e056-41eb-b609-68be82c19c3e","resolved_model_slug":"gpt-5-2","can_save":true},"recipient":"all","channel":null},"parent":"922b4fe2-c078-4232-8ce2-c69b0f066abe","children":["f6ee205d-811d-4714-9e3e-951480ba5f65"]},"f6ee205d-811d-4714-9e3e-951480ba5f65":{"id":"f6ee205d-811d-4714-9e3e-951480ba5f65","message":{"id":"f6ee205d-811d-4714-9e3e-951480ba5f65","author":{"role":"system","name":null,"metadata":{}},"create_time":1771329840.4760094,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":true,"weight":0.0,"metadata":{"rebase_developer_message":true,"model_slug":"gpt-5-2-thinking","request_id":"440cf611-d1f1-4ba5-82ae-d494323333dc","message_type":"next","default_model_slug":"gpt-5-2","parent_id":"60fa5170-7304-4a7b-b2f6-71c4c6cd1f6b","turn_exchange_id":"244c6745-e056-41eb-b609-68be82c19c3e","is_visually_hidden_from_conversation":true,"can_save":false},"recipient":"all","channel":null},"parent":"60fa5170-7304-4a7b-b2f6-71c4c6cd1f6b","children":["edd312c4-4a9e-4bda-91b1-cd12a2849300"]},"edd312c4-4a9e-4bda-91b1-cd12a2849300":{"id":"edd312c4-4a9e-4bda-91b1-cd12a2849300","message":{"id":"edd312c4-4a9e-4bda-91b1-cd12a2849300","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1771329840.815482,"update_time":null,"content":{"content_type":"thoughts","thoughts":[{"summary":"Thinking longer for a better answer","content":"","chunks":[],"finished":true}],"source_analysis_msg_id":"6dfda644-bf02-4ea0-a53d-ca35a503c43d"},"status":"in_progress","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"is_reasoning","citations":[],"content_references":[],"resolved_model_slug":"gpt-5-2-auto-thinking","model_slug":"gpt-5-2-thinking","hide_inline_actions":true,"disable_turn_actions":true,"request_id":"440cf611-d1f1-4ba5-82ae-d494323333dc","message_type":"next","default_model_slug":"gpt-5-2","parent_id":"6dfda644-bf02-4ea0-a53d-ca35a503c43d","turn_exchange_id":"244c6745-e056-41eb-b609-68be82c19c3e","classifier_response":"default","skip_reasoning_title":"Skip","can_save":true},"recipient":"all","channel":null},"parent":"f6ee205d-811d-4714-9e3e-951480ba5f65","children":["48d94073-02be-4bb9-b217-b3cc4e6f36f8"]},"48d94073-02be-4bb9-b217-b3cc4e6f36f8":{"id":"48d94073-02be-4bb9-b217-b3cc4e6f36f8","message":{"id":"48d94073-02be-4bb9-b217-b3cc4e6f36f8","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1771329839.993645,"update_time":null,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"{\"search_query\":[{\"q\":\"Moonshot AI Kimi open source model sizes 2025 2026 Kimi K2 Kimi K1\",\"recency\":14},{\"q\":\"Moonshot AI Kimi model release open weights Hugging Face \\\"Kimi\\\" 20B 30B\",\"recency\":365},{\"q\":\"Kimi (Moonshot AI) model family Kimi 1.5 2.0 open source parameters\",\"recency\":365},{\"q\":\"Hugging Face MoonshotAI Kimi model 2026\",\"recency\":365}],\"response_length\":\"short\"}"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"citations":[],"content_references":[],"resolved_model_slug":"gpt-5-2-auto-thinking","model_slug":"gpt-5-2-thinking","hide_inline_actions":true,"disable_turn_actions":true,"request_id":"440cf611-d1f1-4ba5-82ae-d494323333dc","message_type":"next","default_model_slug":"gpt-5-2","parent_id":"775db8b1-d17c-452c-a281-b815304620bb","turn_exchange_id":"244c6745-e056-41eb-b609-68be82c19c3e","reasoning_status":"is_reasoning","search_queries":[{"type":"search","q":"Moonshot AI Kimi open source model sizes 2025 2026 Kimi K2 Kimi K1"},{"type":"search","q":"Moonshot AI Kimi model release open weights Hugging Face \"Kimi\" 20B 30B"},{"type":"search","q":"Kimi (Moonshot AI) model family Kimi 1.5 2.0 open source parameters"},{"type":"search","q":"Hugging Face MoonshotAI Kimi model 2026"}],"search_display_string":"Searching the web...","searched_display_string":"Searched the web...","reasoning_title":"Browsing for Kimi model details and image carousel","classifier_response":"default","can_save":true},"recipient":"web.run","channel":null},"parent":"edd312c4-4a9e-4bda-91b1-cd12a2849300","children":["41ca4b9d-83e1-4e42-b819-37fb76f66da9"]},"41ca4b9d-83e1-4e42-b819-37fb76f66da9":{"id":"41ca4b9d-83e1-4e42-b819-37fb76f66da9","message":{"id":"41ca4b9d-83e1-4e42-b819-37fb76f66da9","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1771329845.3378217,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_model_queries":{"type":"search_model_queries","queries":["Moonshot AI Kimi open source model sizes 2025 2026 Kimi K2 Kimi K1","Moonshot AI Kimi model release open weights Hugging Face \"Kimi\" 20B 30B","Kimi (Moonshot AI) model family Kimi 1.5 2.0 open source parameters","Hugging Face MoonshotAI Kimi model 2026"]},"model_slug":"gpt-5-2-thinking","hide_inline_actions":true,"disable_turn_actions":true,"request_id":"440cf611-d1f1-4ba5-82ae-d494323333dc","message_type":"next","default_model_slug":"gpt-5-2","parent_id":"48d94073-02be-4bb9-b217-b3cc4e6f36f8","turn_exchange_id":"244c6745-e056-41eb-b609-68be82c19c3e","reasoning_status":"is_reasoning","reasoning_title":"Browsing for Kimi model details and image carousel","classifier_response":"default","can_save":false},"recipient":"all","channel":null},"parent":"48d94073-02be-4bb9-b217-b3cc4e6f36f8","children":["4396771f-65d5-4540-b865-7b225d666fec"]},"4396771f-65d5-4540-b865-7b225d666fec":{"id":"4396771f-65d5-4540-b865-7b225d666fec","message":{"id":"4396771f-65d5-4540-b865-7b225d666fec","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1771329845.3354495,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_result_groups":[{"type":"search_result_group","domain":"github.com","entries":[{"type":"search_result","url":"https://github.com/MoonshotAI/Kimi-K2","title":"MoonshotAI/Kimi-K2","snippet":"Kimi K2 is a state-of-the-art mixture-of-experts (MoE) language model with 32 billion activated parameters and 1 trillion total parameters.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":0},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/MoonshotAI/Kimi-K2.5","title":"MoonshotAI/Kimi-K2.5: Moonshot's most powerful model","snippet":"Kimi K2.5 is an open-source, native multimodal agentic model built through continual pretraining on approximately 15 trillion mixed visual and text tokens ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"github.com"}]},{"type":"search_result_group","domain":"huggingface.co","entries":[{"type":"search_result","url":"https://huggingface.co/moonshotai/Kimi-K2.5","title":"moonshotai/Kimi-K2.5","snippet":"2 Feb 2026 \u2014 Kimi K2.5 is an open-source, native multimodal agentic model built through continual pretraining on approximately 15 trillion mixed visual and ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/moonshotai/Kimi-K2.5/discussions/5","title":"moonshotai/Kimi-K2.5 \u00b7 Congratulations on this release ...","snippet":"27 Jan 2026 \u2014 ai, Deepseek and Qwen still release text only models in 2026. We ... Keep up the great work and thank you! https://huggingface.co/moonshotai/Kimi- ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/nvidia/Kimi-K2.5-NVFP4","title":"nvidia/Kimi-K2.5-NVFP4","snippet":"The NVIDIA Kimi-K2.5-NVFP4 model is the quantized version of the Moonshot AI's Kimi-K2.5 model, which is an auto-regressive language model that uses an ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"huggingface.co"}]},{"type":"search_result_group","domain":"www.moonshot.ai","entries":[{"type":"search_result","url":"https://www.moonshot.ai/","title":"Moonshot AI","snippet":"Kimi is driven by Moonshot's proprietary LLM. It supports online search, deep thinking, multimodal reasoning, and long-form text conversations.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"www.moonshot.ai"}]},{"type":"search_result_group","domain":"www.reddit.com","entries":[{"type":"search_result","url":"https://www.reddit.com/r/LocalLLaMA/comments/1qpewj7/ama_with_kimi_the_opensource_frontier_lab_behind/","title":"AMA With Kimi, The Open-source Frontier Lab Behind ...","snippet":"Hey there! Kimi K2 (+ thinking) has been my favourite model to use for everything from general QA to difficult coding problems. K2.5 Is awesome!Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"www.reddit.com"}]},{"type":"search_result_group","domain":"platform.moonshot.ai","entries":[{"type":"search_result","url":"https://platform.moonshot.ai/docs/guide/kimi-k2-5-quickstart","title":"Kimi K2.5 - Kimi Large Language Model API Service","snippet":"29 Jan 2026 \u2014 Kimi Open Platform, providing trillion-parameter K2 large language model API, supporting 256K long context and Tool Calling.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"platform.moonshot.ai"}]},{"type":"search_result_group","domain":"en.wikipedia.org","entries":[{"type":"search_result","url":"https://en.wikipedia.org/wiki/Kimi_%28chatbot%29","title":"Kimi (chatbot)","snippet":"","ref_id":{"turn_index":0,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"en.wikipedia.org"}]},{"type":"search_result_group","domain":"www.facebook.com","entries":[{"type":"search_result","url":"https://www.facebook.com/groups/DeepNetGroup/posts/2716588342067364/","title":"Moonshot AI releases Kimi K2.5 open source model","snippet":"Moonshot AI Releases Kimi K2.5: An Open Source Visual Agentic Intelligence Model with Native Swarm Execution Kimi K2.5 is an open source visual ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"www.facebook.com"}]},{"type":"search_result_group","domain":"docs.api.nvidia.com","entries":[{"type":"search_result","url":"https://docs.api.nvidia.com/nim/reference/moonshotai-kimi-k2-5","title":"moonshotai / kimi-k2-5","snippet":"26 Jan 2026 \u2014 Kimi K2.5 is an open-source, native multimodal agentic model built through continual pretraining on approximately 15 trillion mixed visual ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"docs.api.nvidia.com"}]},{"type":"search_result_group","domain":"moonshotai.github.io","entries":[{"type":"search_result","url":"https://moonshotai.github.io/Kimi-K2/","title":"Kimi K2: Open Agentic Intelligence","snippet":"Kimi K2 is our latest Mixture-of-Experts model with 32 billion activated parameters and 1 trillion total parameters. It achieves state-of-the-art performance.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"moonshotai.github.io"}]},{"type":"search_result_group","domain":"build.nvidia.com","entries":[{"type":"search_result","url":"https://build.nvidia.com/moonshotai/kimi-k2.5/modelcard","title":"kimi-k2.5 Model by Moonshotai","snippet":"26 Jan 2026 \u2014 Description. Kimi K2.5 is an open-source, native multimodal agentic model built through continual pretraining on approximately 15 trillion mixed ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"build.nvidia.com"}]},{"type":"search_result_group","domain":"www.reuters.com","entries":[{"type":"search_result","url":"https://www.reuters.com/business/media-telecom/chinas-moonshot-ai-releases-open-source-model-reclaim-market-position-2025-07-11/","title":"China's Moonshot AI releases open-source model to reclaim market position","snippet":"Chinese AI startup Moonshot AI has launched a new open-source model, Kimi K2, aiming to regain its footing in the increasingly competitive domestic AI market. The model, designed with advanced coding abilities and strong performance in agent tasks and tool integration, is said to surpass some leading open-source models like DeepSeek\u2019s V3 and rival top U.S. technologies in specific areas such as coding. This release follows a broader trend among Chinese tech firms\u2014such as Alibaba, Tencent, Baidu, and DeepSeek\u2014to open source their models in contrast to U.S. firms like OpenAI and Google, which keep theirs proprietary. Open-sourcing is seen as a way for Chinese companies to demonstrate their technical strength, grow developer communities, and enhance global influence amidst U.S. restrictions on Chinese tech advancement. Moonshot, founded in 2023 and backed by players like Alibaba, rose to prominence in 2024 but lost ground after DeepSeek launched its low-cost R1 model in early 2025. Moonshot\u2019s Kimi app dropped from third to seventh place in monthly active users over the last year.","ref_id":{"turn_index":0,"ref_type":"news","ref_index":41},"pub_date":1752247308.0,"attribution":"www.reuters.com"}]}],"debug_sonic_thread_id":"thread_699459355dbc8333912335616f00f381","model_slug":"gpt-5-2-thinking","hide_inline_actions":true,"disable_turn_actions":true,"request_id":"440cf611-d1f1-4ba5-82ae-d494323333dc","message_type":"next","default_model_slug":"gpt-5-2","parent_id":"7d843567-d8bf-4bf7-b33c-5deabd8c53a0","turn_exchange_id":"244c6745-e056-41eb-b609-68be82c19c3e","reasoning_status":"is_reasoning","reasoning_title":"Browsing for Kimi model details and image carousel","classifier_response":"default","can_save":false},"recipient":"all","channel":null},"parent":"41ca4b9d-83e1-4e42-b819-37fb76f66da9","children":["88f3ac35-798b-498e-b53c-de9fdce38ee7"]},"88f3ac35-798b-498e-b53c-de9fdce38ee7":{"id":"88f3ac35-798b-498e-b53c-de9fdce38ee7","message":{"id":"88f3ac35-798b-498e-b53c-de9fdce38ee7","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1771329857.435096,"update_time":null,"content":{"content_type":"thoughts","thoughts":[{"summary":"Clarifying Kimi model sizes","content":"I need to compare Kimi family sizes with gpt-oss-20B. Kimi\u2019s open models are MoE with huge sizes (like 1T total, 32B active), which seems much bigger. However, there are smaller versions, like Kimi-VL 16B MoE with 3B active. I\u2019ll verify details by searching for model cards and confirming the figures.","chunks":["I need to compare Kimi family sizes with gpt-oss-20B.","Kimi\u2019s open models are MoE with huge sizes (like 1T total, 32B active), which seems much bigger.","However, there are smaller versions, like Kimi-VL 16B MoE with 3B active.","I\u2019ll verify details by searching for model cards and confirming the figures."],"finished":true}],"source_analysis_msg_id":"21090203-037b-4ef7-8c7c-657a42c36ddd"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"is_reasoning","citations":[],"content_references":[],"resolved_model_slug":"gpt-5-2-auto-thinking","model_slug":"gpt-5-2-thinking","hide_inline_actions":true,"disable_turn_actions":true,"request_id":"440cf611-d1f1-4ba5-82ae-d494323333dc","message_type":"next","default_model_slug":"gpt-5-2","parent_id":"995a6871-0919-4351-a6b0-c2ac3796764f","turn_exchange_id":"244c6745-e056-41eb-b609-68be82c19c3e","classifier_response":"default","skip_reasoning_title":"Skip","can_save":true},"recipient":"all","channel":null},"parent":"4396771f-65d5-4540-b865-7b225d666fec","children":["9313b9c1-0f2c-4705-b933-698a0d87d4df"]},"9313b9c1-0f2c-4705-b933-698a0d87d4df":{"id":"9313b9c1-0f2c-4705-b933-698a0d87d4df","message":{"id":"9313b9c1-0f2c-4705-b933-698a0d87d4df","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1771329852.049742,"update_time":null,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"{\"search_query\":[{\"q\":\"moonshotai Kimi-VL 16B 3B active license MIT model card\",\"recency\":365},{\"q\":\"MoonshotAI Kimi-Linear 48B 3B active Kimi Delta Attention model release\",\"recency\":365},{\"q\":\"MoonshotAI Kimi-Dev 72B based on Qwen2.5-72B license model card\",\"recency\":365},{\"q\":\"Hugging Face moonshotai Kimi-VL-Thinking model card\",\"recency\":365}],\"response_length\":\"short\"}"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"citations":[],"content_references":[],"resolved_model_slug":"gpt-5-2-auto-thinking","model_slug":"gpt-5-2-thinking","hide_inline_actions":true,"disable_turn_actions":true,"request_id":"440cf611-d1f1-4ba5-82ae-d494323333dc","message_type":"next","default_model_slug":"gpt-5-2","parent_id":"45a75c5f-a439-4bb7-8ba9-5f446e6bb978","turn_exchange_id":"244c6745-e056-41eb-b609-68be82c19c3e","reasoning_status":"is_reasoning","search_queries":[{"type":"search","q":"moonshotai Kimi-VL 16B 3B active license MIT model card"},{"type":"search","q":"MoonshotAI Kimi-Linear 48B 3B active Kimi Delta Attention model release"},{"type":"search","q":"MoonshotAI Kimi-Dev 72B based on Qwen2.5-72B license model card"},{"type":"search","q":"Hugging Face moonshotai Kimi-VL-Thinking model card"}],"search_display_string":"Searching the web...","searched_display_string":"Searched the web...","reasoning_title":"Searching for Kimi model cards and details","classifier_response":"default","can_save":true},"recipient":"web.run","channel":null},"parent":"88f3ac35-798b-498e-b53c-de9fdce38ee7","children":["b2fb25e4-cdde-404c-8261-ae92621e43fa"]},"b2fb25e4-cdde-404c-8261-ae92621e43fa":{"id":"b2fb25e4-cdde-404c-8261-ae92621e43fa","message":{"id":"b2fb25e4-cdde-404c-8261-ae92621e43fa","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1771329859.8217797,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_model_queries":{"type":"search_model_queries","queries":["moonshotai Kimi-VL 16B 3B active license MIT model card","MoonshotAI Kimi-Linear 48B 3B active Kimi Delta Attention model release","MoonshotAI Kimi-Dev 72B based on Qwen2.5-72B license model card","Hugging Face moonshotai Kimi-VL-Thinking model card"]},"model_slug":"gpt-5-2-thinking","hide_inline_actions":true,"disable_turn_actions":true,"request_id":"440cf611-d1f1-4ba5-82ae-d494323333dc","message_type":"next","default_model_slug":"gpt-5-2","parent_id":"9313b9c1-0f2c-4705-b933-698a0d87d4df","turn_exchange_id":"244c6745-e056-41eb-b609-68be82c19c3e","reasoning_status":"is_reasoning","reasoning_title":"Searching for Kimi model cards and details","classifier_response":"default","can_save":false},"recipient":"all","channel":null},"parent":"9313b9c1-0f2c-4705-b933-698a0d87d4df","children":["45ff1048-c30f-4ea4-864c-0307b539a5ad"]},"45ff1048-c30f-4ea4-864c-0307b539a5ad":{"id":"45ff1048-c30f-4ea4-864c-0307b539a5ad","message":{"id":"45ff1048-c30f-4ea4-864c-0307b539a5ad","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1771329859.8194354,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_result_groups":[{"type":"search_result_group","domain":"huggingface.co","entries":[{"type":"search_result","url":"https://huggingface.co/moonshotai/Kimi-VL-A3B-Instruct","title":"moonshotai/Kimi-VL-A3B-Instruct","snippet":"10 Apr 2025 \u2014 We present Kimi-VL, an efficient open-source Mixture-of-Experts (MoE) vision-language model (VLM) that offers advanced multimodal reasoning, ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":0},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/moonshotai/Kimi-Dev-72B","title":"moonshotai/Kimi-Dev-72B","snippet":"We introduce Kimi-Dev-72B, our new open-source coding LLM for software engineering tasks. Kimi-Dev-72B achieves a new state-of-the-art on SWE-bench Verified ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/moonshotai/Kimi-VL-A3B-Thinking","title":"moonshotai/Kimi-VL-A3B-Thinking","snippet":"10 Apr 2025 \u2014 We present Kimi-VL, an efficient open-source Mixture-of-Experts (MoE) vision-language model (VLM) that offers advanced multimodal reasoning, ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/moonshotai/Kimi-Dev-72B/blob/main/LICENSE.md","title":"LICENSE.md \u00b7 moonshotai/Kimi-Dev-72B at main","snippet":"17 Jun 2025 \u2014 Kimi-Dev-72B is built with Qwen-2.5-72B. Qwen-2.5-72B is licensed under the Qwen LICENSE AGREEMENT, Copyright (c) Alibaba Cloud.Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/moonshotai/Kimi-VL-A3B-Thinking-2506","title":"moonshotai/Kimi-VL-A3B-Thinking-2506","snippet":"10 Apr 2025 \u2014 A long-decode model that will generates up to 32K tokens, we recommend using VLLM for inference, which has already supported Kimi-VL series.Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/moonshotai","title":"moonshotai (Moonshot AI)","snippet":"2 Feb 2026 \u2014 models 16. Sort: Recently updated \u00b7 moonshotai/Kimi-K2.5 \u00b7 moonshotai/Kimi-VL-A3B-Thinking-2506 \u00b7 moonshotai/Kimi-VL-A3B-Thinking \u00b7 moonshotai/ ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/moonshotai/Kimi-VL-A3B-Thinking/tree/3f0f648b6b8494b1e76c8de7c8f7ca58bf081e11/figures","title":"moonshotai/Kimi-VL-A3B-Thinking at ...","snippet":"We're on a journey to advance and democratize artificial intelligence through open source and open science.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/collections/SoulSeeker/moonshotai-kimi-vl-a3b-thinking","title":"moonshotai/Kimi-VL-A3B-Thinking - a SoulSeeker Collection","snippet":"14 Jul 2025 \u2014 Unlock the magic of AI with handpicked models, awesome datasets, papers, and mind-blowing Spaces from SoulSeeker. ... Hugging Face's logo Hugging ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"huggingface.co"}]},{"type":"search_result_group","domain":"github.com","entries":[{"type":"search_result","url":"https://github.com/MoonshotAI/Kimi-Linear","title":"MoonshotAI/Kimi-Linear","snippet":"48B, 3B, 1M, Hugging Face. Key Features. Kimi Delta Attention (KDA): A linear attention mechanism that refines the gated delta rule with finegrained gating.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/MoonshotAI/Kimi-VL","title":"Kimi-VL: Mixture-of-Experts Vision-Language Model for ...","snippet":"See the performance of Kimi-VL-A3B-Thinking-2506 at Hugging Face. As an efficient model, Kimi-VL can robustly handle diverse tasks (fine-grained perception, ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/MoonshotAI/Kimi-K2","title":"MoonshotAI/Kimi-K2","snippet":"Kimi K2 is a state-of-the-art mixture-of-experts (MoE) language model with 32 billion activated parameters and 1 trillion total parameters.Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"github.com"}]},{"type":"search_result_group","domain":"arxiv.org","entries":[{"type":"search_result","url":"https://arxiv.org/pdf/2510.26692","title":"Kimi Linear: An Expressive, Efficient Attention Architecture","snippet":"by K Team \u00b7 2025 \u00b7 Cited by 22 \u2014 In this work, we present Kimi Linear, a hybrid linear attention architecture designed to meet the efficiency demands of agentic intelligence and ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2509.23045v2","title":"Kimi-Dev: Agentless Training as Skill Prior for SWE-Agents","snippet":"9 Oct 2025 \u2014 To figure this out, we perform SWE-Agent SFT on the original Qwen2.5-72B (Base), the mid-trained model (MT), the model then activated with ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"arxiv.org"}]},{"type":"search_result_group","domain":"www.reddit.com","entries":[{"type":"search_result","url":"https://www.reddit.com/r/LocalLLaMA/comments/1jvgpju/moonshot_ai_released_kimivl_moe_3b16b_thinking/","title":"Moonshot AI released Kimi-VL MoE (3B/16B) Thinking","snippet":"An MoE VLM and an MoE Reasoning VLM with only ~3B activated parameters (total 16B). Strong multimodal reasoning (36.8% on MathVision, on par with 10x larger ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":8},"pub_date":1744232536.459,"attribution":"www.reddit.com"}]},{"type":"search_result_group","domain":"www.digitalocean.com","entries":[{"type":"search_result","url":"https://www.digitalocean.com/community/tutorials/kimi-linear-moonshot-ai","title":"Designing Hardware-Aware Algorithms with Kimi Linear","snippet":"Moonshot AI's Kimi Linear introduces Kimi Delta Attention (KDA), a hardware-aware algorithm. Learn how to run Kimi Linear on DigitalOcean.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":9},"pub_date":1764215478.0,"attribution":"www.digitalocean.com"}]},{"type":"search_result_group","domain":"apxml.com","entries":[{"type":"search_result","url":"https://apxml.com/models/kimi-vl-a3b-instruct","title":"Kimi-VL-A3B-Instruct: Specifications and GPU VRAM ...","snippet":"The model comprises a total of 16 billion parameters, with its design allowing for the activation of approximately 2.8 billion parameters during inference ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"apxml.com"}]},{"type":"search_result_group","domain":"trythatllm.com","entries":[{"type":"search_result","url":"https://trythatllm.com/model/moonshotai-kimi-linear-48b-a3b-instruct","title":"Kimi Linear 48B A3B Instruct","snippet":"Kimi Linear 48B A3B Instruct is Moonshot AI's efficient hybrid linear attention model released in October 2025, featuring Kimi Delta Attention (KDA) for 75% ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"trythatllm.com"}]},{"type":"search_result_group","domain":"medium.com","entries":[{"type":"search_result","url":"https://medium.com/data-science-in-your-pocket/kimi-linear-bye-bye-transformers-c79f843f208c","title":"Kimi-Linear : Bye Bye Transformers | by Mehul Gupta","snippet":"The Kimi Linear 48B model (with 3B active parameters per forward pass via Mixture-of-Experts) outperforms standard full-attention ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":16},"pub_date":1761927255.028,"attribution":"medium.com"}]},{"type":"search_result_group","domain":"moonshotai.github.io","entries":[{"type":"search_result","url":"https://moonshotai.github.io/Kimi-Dev/","title":"Kimi-Dev-72B","snippet":"16 Jun 2025 \u2014 With the Qwen 2.5-72B base model as a starting point, we gather millions of GitHub issues and PR commits as its mid-training dataset. The ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"moonshotai.github.io"}]}],"debug_sonic_thread_id":"thread_699459355dbc8333912335616f00f381","model_slug":"gpt-5-2-thinking","hide_inline_actions":true,"disable_turn_actions":true,"request_id":"440cf611-d1f1-4ba5-82ae-d494323333dc","message_type":"next","default_model_slug":"gpt-5-2","parent_id":"79900ac1-9413-407b-8b26-311e763119d7","turn_exchange_id":"244c6745-e056-41eb-b609-68be82c19c3e","reasoning_status":"is_reasoning","reasoning_title":"Searching for Kimi model cards and details","classifier_response":"default","can_save":false},"recipient":"all","channel":null},"parent":"b2fb25e4-cdde-404c-8261-ae92621e43fa","children":["315d5dd9-1c8f-4fb2-8f39-3a3a14218c15"]},"315d5dd9-1c8f-4fb2-8f39-3a3a14218c15":{"id":"315d5dd9-1c8f-4fb2-8f39-3a3a14218c15","message":{"id":"315d5dd9-1c8f-4fb2-8f39-3a3a14218c15","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1771329874.614686,"update_time":null,"content":{"content_type":"reasoning_recap","content":"Thought for 33s"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"reasoning_ended","finished_duration_sec":33,"model_slug":"gpt-5-2-thinking","hide_inline_actions":true,"disable_turn_actions":true,"request_id":"440cf611-d1f1-4ba5-82ae-d494323333dc","message_type":"next","default_model_slug":"gpt-5-2","parent_id":"79be328b-3c55-49a7-93a3-dae643d1e8b2","turn_exchange_id":"244c6745-e056-41eb-b609-68be82c19c3e","can_save":true},"recipient":"all","channel":null},"parent":"45ff1048-c30f-4ea4-864c-0307b539a5ad","children":["cba01321-fc9f-449a-912d-74e40cfa60e2"]},"cba01321-fc9f-449a-912d-74e40cfa60e2":{"id":"cba01321-fc9f-449a-912d-74e40cfa60e2","message":{"id":"cba01321-fc9f-449a-912d-74e40cfa60e2","author":{"role":"assistant","name":null,"metadata":{"real_author":"tool:web"}},"create_time":1771329865.850581,"update_time":null,"content":{"content_type":"text","parts":["The **Kimi (Moonshot AI)** open-weight family is a bit \u201cnon-standard\u201d compared to `gpt-oss-20B`, because their flagship releases are mostly **Mixture-of-Experts (MoE)** with **very large total parameters** and a smaller **activated (active) parameter** count per token.\n\n## What Kimi models exist in the \u201c~gpt-oss-20B class\u201d?\nFirst, recall: **`gpt-oss-20B` is MoE with ~21B total parameters and ~3.6B active per token.** \ue200cite\ue202openai.com/index/introducing-gpt-oss/\ue201\n\n### Closest Kimi options by **total parameter count** (dense-ish sizing feel)\nKimi does **not** really have a flagship \u201c~20B dense\u201d equivalent. The closest in raw size are **~16B MoE** releases:\n\n- **Moonlight-16B-A3B / Moonlight-16B-A3B-Instruct** (16B total; A3B implies ~3B active) \ue200cite\ue202turn1search11\ue201  \n- **Kimi-VL-A3B (16B total; ~2.8B active in the language decoder)** (multimodal VLM) \ue200cite\ue202turn1search0\ue202turn1search12\ue201\n\nThese are the most \u201cnearby\u201d if your goal is **weights scale** that\u2019s not wildly bigger than 20B.\n\n### Closest by **active compute per token** (more apples-to-apples for MoE)\nIf what you really mean is \u201csimilar runtime compute profile,\u201d then the A3B models are very comparable:\n\n- `gpt-oss-20B`: **~3.6B active**\n- Kimi A3B family: **~2.8\u20133B active** \ue200cite\ue202turn1search0\ue202openai.com/index/introducing-gpt-oss/\ue201\n\nSo **Kimi-VL-A3B** / **Moonlight-16B-A3B** are arguably the closest \u201cpractical\u201d match to `gpt-oss-20B` in terms of **activated capacity**, even though total params differ.\n\n## Where Kimi\u2019s \u201cmain\u201d flagship models sit (and why they\u2019re not comparable)\nMoonshot\u2019s flagship open-weight Kimi releases are *huge* MoE:\n\n- **Kimi K2:** **1T total parameters, 32B activated** \ue200cite\ue202turn1search10\ue202turn0search11\ue201  \n- **Kimi K2.5:** described as open-source multimodal agentic model built atop K2 base; still in the \u201ctrillion parameter\u201d class of releases in their docs/ecosystem \ue200cite\ue202turn0search2\ue202turn0search5\ue201\n\nThose are **way above** `gpt-oss-20B` in total size, and also above it in activated parameters.\n\n## Licenses and \u201cis distillation permitted?\u201d\nIf you\u2019re asking because of distillation legality:\n\n- **Kimi K2** is released under a **modified MIT** license (per public summaries) \ue200cite\ue202turn0search7\ue201  \n- **Kimi-Dev-72B**: its Hugging Face LICENSE notes it\u2019s under **MIT**, but also explicitly says it\u2019s built on **Qwen-2.5-72B** and references the **Qwen license agreement**\u2014so you must treat it as potentially \u201clicense-layered.\u201d \ue200cite\ue202turn1search6\ue202turn1search17\ue201\n\n(Practically: for distillation, you\u2019d check the exact LICENSE file of the specific model repo you use, plus any upstream/base-model constraints.)\n\n## What I\u2019d pick depending on your intent\n- Want **closest to `gpt-oss-20B` by \u201csize class\u201d** (not huge): **Moonlight-16B-A3B (text)** or **Kimi-VL-A3B (multimodal)**. \ue200cite\ue202turn1search11\ue202turn1search0\ue201  \n- Want **Kimi\u2019s best-known flagship capabilities** (agentic/coding, but massive): **Kimi K2 / K2.5**. \ue200cite\ue202turn1search10\ue202turn0search2\ue201\n\nIf you tell me your deployment constraint (e.g., **single 24GB GPU**, **CPU-only**, **laptop VRAM**, **target context length**), I\u2019ll recommend the most realistic Kimi variant + the simplest inference stack (e.g., vLLM vs llama.cpp) for that hardware."]},"status":"finished_successfully","end_turn":true,"weight":1.0,"metadata":{"content_references":[{"matched_text":"\ue200cite\ue202openai.com/index/introducing-gpt-oss/\ue201","start_idx":421,"end_idx":465,"safe_urls":[],"refs":[],"alt":null,"prompt_text":null,"type":"hidden","invalid":true},{"matched_text":"\ue200cite\ue202turn1search11\ue201","start_idx":752,"end_idx":772,"safe_urls":["https://huggingface.co/moonshotai","https://huggingface.co/moonshotai?utm_source=chatgpt.com"],"refs":[],"alt":"([Hugging Face](https://huggingface.co/moonshotai?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"moonshotai (Moonshot AI)","url":"https://huggingface.co/moonshotai?utm_source=chatgpt.com","pub_date":null,"snippet":"2 Feb 2026 \u2014 models 16. Sort: Recently updated \u00b7 moonshotai/Kimi-K2.5 \u00b7 moonshotai/Kimi-VL-A3B-Thinking-2506 \u00b7 moonshotai/Kimi-VL-A3B-Thinking \u00b7 moonshotai/ ...Read more","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":1,"ref_type":"search","ref_index":11}],"hue":null,"attributions":null,"attribution":"Hugging Face"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn1search0\ue202turn1search12\ue201","start_idx":860,"end_idx":893,"safe_urls":["https://apxml.com/models/kimi-vl-a3b-instruct","https://apxml.com/models/kimi-vl-a3b-instruct?utm_source=chatgpt.com","https://huggingface.co/moonshotai/Kimi-VL-A3B-Instruct","https://huggingface.co/moonshotai/Kimi-VL-A3B-Instruct?utm_source=chatgpt.com"],"refs":[],"alt":"([Hugging Face](https://huggingface.co/moonshotai/Kimi-VL-A3B-Instruct?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"moonshotai/Kimi-VL-A3B-Instruct","url":"https://huggingface.co/moonshotai/Kimi-VL-A3B-Instruct?utm_source=chatgpt.com","pub_date":null,"snippet":"10 Apr 2025 \u2014 We present Kimi-VL, an efficient open-source Mixture-of-Experts (MoE) vision-language model (VLM) that offers advanced multimodal reasoning, ...Read more","attribution_segments":null,"supporting_websites":[{"title":"Kimi-VL-A3B-Instruct: Specifications and GPU VRAM ...","url":"https://apxml.com/models/kimi-vl-a3b-instruct?utm_source=chatgpt.com","pub_date":null,"snippet":"The model comprises a total of 16 billion parameters, with its design allowing for the activation of approximately 2.8 billion parameters during inference ...Read more","attribution":"ApX"}],"refs":[{"turn_index":1,"ref_type":"search","ref_index":0},{"turn_index":1,"ref_type":"search","ref_index":12}],"hue":null,"attributions":null,"attribution":"Hugging Face"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn1search0\ue202openai.com/index/introducing-gpt-oss/\ue201","start_idx":1245,"end_idx":1302,"safe_urls":["https://huggingface.co/moonshotai/Kimi-VL-A3B-Instruct","https://huggingface.co/moonshotai/Kimi-VL-A3B-Instruct?utm_source=chatgpt.com"],"refs":["malformed"],"alt":"([Hugging Face](https://huggingface.co/moonshotai/Kimi-VL-A3B-Instruct?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"moonshotai/Kimi-VL-A3B-Instruct","url":"https://huggingface.co/moonshotai/Kimi-VL-A3B-Instruct?utm_source=chatgpt.com","pub_date":null,"snippet":"10 Apr 2025 \u2014 We present Kimi-VL, an efficient open-source Mixture-of-Experts (MoE) vision-language model (VLM) that offers advanced multimodal reasoning, ...Read more","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":1,"ref_type":"search","ref_index":0}],"hue":null,"attributions":null,"attribution":"Hugging Face"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn1search10\ue202turn0search11\ue201","start_idx":1670,"end_idx":1704,"safe_urls":["https://github.com/MoonshotAI/Kimi-K2","https://github.com/MoonshotAI/Kimi-K2?utm_source=chatgpt.com","https://moonshotai.github.io/Kimi-K2/","https://moonshotai.github.io/Kimi-K2/?utm_source=chatgpt.com"],"refs":[],"alt":"([GitHub](https://github.com/MoonshotAI/Kimi-K2?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"MoonshotAI/Kimi-K2","url":"https://github.com/MoonshotAI/Kimi-K2?utm_source=chatgpt.com","pub_date":null,"snippet":"Kimi K2 is a state-of-the-art mixture-of-experts (MoE) language model with 32 billion activated parameters and 1 trillion total parameters.Read more","attribution_segments":null,"supporting_websites":[{"title":"Kimi K2: Open Agentic Intelligence","url":"https://moonshotai.github.io/Kimi-K2/?utm_source=chatgpt.com","pub_date":null,"snippet":"Kimi K2 is our latest Mixture-of-Experts model with 32 billion activated parameters and 1 trillion total parameters. It achieves state-of-the-art performance.Read more","attribution":"moonshotai.github.io"}],"refs":[{"turn_index":1,"ref_type":"search","ref_index":10},{"turn_index":0,"ref_type":"search","ref_index":11}],"hue":null,"attributions":null,"attribution":"GitHub"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search2\ue202turn0search5\ue201","start_idx":1870,"end_idx":1902,"safe_urls":["https://github.com/MoonshotAI/Kimi-K2.5","https://github.com/MoonshotAI/Kimi-K2.5?utm_source=chatgpt.com","https://platform.moonshot.ai/docs/guide/kimi-k2-5-quickstart","https://platform.moonshot.ai/docs/guide/kimi-k2-5-quickstart?utm_source=chatgpt.com"],"refs":[],"alt":"([GitHub](https://github.com/MoonshotAI/Kimi-K2.5?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"MoonshotAI/Kimi-K2.5: Moonshot's most powerful model","url":"https://github.com/MoonshotAI/Kimi-K2.5?utm_source=chatgpt.com","pub_date":null,"snippet":"Kimi K2.5 is an open-source, native multimodal agentic model built through continual pretraining on approximately 15 trillion mixed visual and text tokens ...Read more","attribution_segments":null,"supporting_websites":[{"title":"Kimi K2.5 - Kimi Large Language Model API Service","url":"https://platform.moonshot.ai/docs/guide/kimi-k2-5-quickstart?utm_source=chatgpt.com","pub_date":null,"snippet":"29 Jan 2026 \u2014 Kimi Open Platform, providing trillion-parameter K2 large language model API, supporting 256K long context and Tool Calling.","attribution":"platform.moonshot.ai"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":2},{"turn_index":0,"ref_type":"search","ref_index":5}],"hue":null,"attributions":null,"attribution":"GitHub"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search7\ue201","start_idx":2180,"end_idx":2199,"safe_urls":["https://en.wikipedia.org/wiki/Kimi_%28chatbot%29","https://en.wikipedia.org/wiki/Kimi_%28chatbot%29?utm_source=chatgpt.com"],"refs":[],"alt":"([Wikipedia](https://en.wikipedia.org/wiki/Kimi_%28chatbot%29?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Kimi (chatbot)","url":"https://en.wikipedia.org/wiki/Kimi_%28chatbot%29?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":7}],"hue":null,"attributions":null,"attribution":"Wikipedia"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn1search6\ue202turn1search17\ue201","start_idx":2430,"end_idx":2463,"safe_urls":["https://huggingface.co/moonshotai/Kimi-Dev-72B/blob/main/LICENSE.md","https://huggingface.co/moonshotai/Kimi-Dev-72B/blob/main/LICENSE.md?utm_source=chatgpt.com","https://moonshotai.github.io/Kimi-Dev/","https://moonshotai.github.io/Kimi-Dev/?utm_source=chatgpt.com"],"refs":[],"alt":"([Hugging Face](https://huggingface.co/moonshotai/Kimi-Dev-72B/blob/main/LICENSE.md?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"LICENSE.md \u00b7 moonshotai/Kimi-Dev-72B at main","url":"https://huggingface.co/moonshotai/Kimi-Dev-72B/blob/main/LICENSE.md?utm_source=chatgpt.com","pub_date":null,"snippet":"17 Jun 2025 \u2014 Kimi-Dev-72B is built with Qwen-2.5-72B. Qwen-2.5-72B is licensed under the Qwen LICENSE AGREEMENT, Copyright (c) Alibaba Cloud.Read more","attribution_segments":null,"supporting_websites":[{"title":"Kimi-Dev-72B","url":"https://moonshotai.github.io/Kimi-Dev/?utm_source=chatgpt.com","pub_date":null,"snippet":"16 Jun 2025 \u2014 With the Qwen 2.5-72B base model as a starting point, we gather millions of GitHub issues and PR commits as its mid-training dataset. The ...Read more","attribution":"moonshotai.github.io"}],"refs":[{"turn_index":1,"ref_type":"search","ref_index":6},{"turn_index":1,"ref_type":"search","ref_index":17}],"hue":null,"attributions":null,"attribution":"Hugging Face"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn1search11\ue202turn1search0\ue201","start_idx":2780,"end_idx":2813,"safe_urls":["https://huggingface.co/moonshotai","https://huggingface.co/moonshotai/Kimi-VL-A3B-Instruct","https://huggingface.co/moonshotai/Kimi-VL-A3B-Instruct?utm_source=chatgpt.com","https://huggingface.co/moonshotai?utm_source=chatgpt.com"],"refs":[],"alt":"([Hugging Face](https://huggingface.co/moonshotai?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"moonshotai (Moonshot AI)","url":"https://huggingface.co/moonshotai?utm_source=chatgpt.com","pub_date":null,"snippet":"2 Feb 2026 \u2014 models 16. Sort: Recently updated \u00b7 moonshotai/Kimi-K2.5 \u00b7 moonshotai/Kimi-VL-A3B-Thinking-2506 \u00b7 moonshotai/Kimi-VL-A3B-Thinking \u00b7 moonshotai/ ...Read more","attribution_segments":null,"supporting_websites":[{"title":"moonshotai/Kimi-VL-A3B-Instruct","url":"https://huggingface.co/moonshotai/Kimi-VL-A3B-Instruct?utm_source=chatgpt.com","pub_date":null,"snippet":"10 Apr 2025 \u2014 We present Kimi-VL, an efficient open-source Mixture-of-Experts (MoE) vision-language model (VLM) that offers advanced multimodal reasoning, ...Read more","attribution":"Hugging Face"}],"refs":[{"turn_index":1,"ref_type":"search","ref_index":11},{"turn_index":1,"ref_type":"search","ref_index":0}],"hue":null,"attributions":null,"attribution":"Hugging Face"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn1search10\ue202turn0search2\ue201","start_idx":2918,"end_idx":2951,"safe_urls":["https://github.com/MoonshotAI/Kimi-K2","https://github.com/MoonshotAI/Kimi-K2.5","https://github.com/MoonshotAI/Kimi-K2.5?utm_source=chatgpt.com","https://github.com/MoonshotAI/Kimi-K2?utm_source=chatgpt.com"],"refs":[],"alt":"([GitHub](https://github.com/MoonshotAI/Kimi-K2?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"MoonshotAI/Kimi-K2","url":"https://github.com/MoonshotAI/Kimi-K2?utm_source=chatgpt.com","pub_date":null,"snippet":"Kimi K2 is a state-of-the-art mixture-of-experts (MoE) language model with 32 billion activated parameters and 1 trillion total parameters.Read more","attribution_segments":null,"supporting_websites":[{"title":"MoonshotAI/Kimi-K2.5: Moonshot's most powerful model","url":"https://github.com/MoonshotAI/Kimi-K2.5?utm_source=chatgpt.com","pub_date":null,"snippet":"Kimi K2.5 is an open-source, native multimodal agentic model built through continual pretraining on approximately 15 trillion mixed visual and text tokens ...Read more","attribution":"GitHub"}],"refs":[{"turn_index":1,"ref_type":"search","ref_index":10},{"turn_index":0,"ref_type":"search","ref_index":2}],"hue":null,"attributions":null,"attribution":"GitHub"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":" ","start_idx":3204,"end_idx":3204,"safe_urls":[],"refs":[],"alt":"","prompt_text":null,"type":"sources_footnote","sources":[{"title":"moonshotai (Moonshot AI)","url":"https://huggingface.co/moonshotai?utm_source=chatgpt.com","attribution":"Hugging Face"},{"title":"MoonshotAI/Kimi-K2","url":"https://github.com/MoonshotAI/Kimi-K2?utm_source=chatgpt.com","attribution":"GitHub"},{"title":"Kimi (chatbot)","url":"https://en.wikipedia.org/wiki/Kimi_%28chatbot%29?utm_source=chatgpt.com","attribution":"Wikipedia"}],"has_images":false}],"safe_urls":["https://apxml.com/models/kimi-vl-a3b-instruct","https://apxml.com/models/kimi-vl-a3b-instruct?utm_source=chatgpt.com","https://en.wikipedia.org/wiki/Kimi_%28chatbot%29","https://en.wikipedia.org/wiki/Kimi_%28chatbot%29?utm_source=chatgpt.com","https://github.com/MoonshotAI/Kimi-K2","https://github.com/MoonshotAI/Kimi-K2.5","https://github.com/MoonshotAI/Kimi-K2.5?utm_source=chatgpt.com","https://github.com/MoonshotAI/Kimi-K2?utm_source=chatgpt.com","https://huggingface.co/moonshotai","https://huggingface.co/moonshotai/Kimi-Dev-72B/blob/main/LICENSE.md","https://huggingface.co/moonshotai/Kimi-Dev-72B/blob/main/LICENSE.md?utm_source=chatgpt.com","https://huggingface.co/moonshotai/Kimi-VL-A3B-Instruct","https://huggingface.co/moonshotai/Kimi-VL-A3B-Instruct?utm_source=chatgpt.com","https://huggingface.co/moonshotai?utm_source=chatgpt.com","https://moonshotai.github.io/Kimi-Dev/","https://moonshotai.github.io/Kimi-Dev/?utm_source=chatgpt.com","https://moonshotai.github.io/Kimi-K2/","https://moonshotai.github.io/Kimi-K2/?utm_source=chatgpt.com","https://platform.moonshot.ai/docs/guide/kimi-k2-5-quickstart","https://platform.moonshot.ai/docs/guide/kimi-k2-5-quickstart?utm_source=chatgpt.com"],"search_result_groups":[{"type":"search_result_group","domain":"huggingface.co","entries":[{"type":"search_result","url":"https://huggingface.co/moonshotai/Kimi-K2.5?utm_source=chatgpt.com","title":"moonshotai/Kimi-K2.5","snippet":"2 Feb 2026 \u2014 Kimi K2.5 is an open-source, native multimodal agentic model built through continual pretraining on approximately 15 trillion mixed visual and ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/moonshotai/Kimi-K2.5/discussions/5?utm_source=chatgpt.com","title":"moonshotai/Kimi-K2.5 \u00b7 Congratulations on this release ...","snippet":"27 Jan 2026 \u2014 ai, Deepseek and Qwen still release text only models in 2026. We ... Keep up the great work and thank you! https://huggingface.co/moonshotai/Kimi- ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/nvidia/Kimi-K2.5-NVFP4?utm_source=chatgpt.com","title":"nvidia/Kimi-K2.5-NVFP4","snippet":"The NVIDIA Kimi-K2.5-NVFP4 model is the quantized version of the Moonshot AI's Kimi-K2.5 model, which is an auto-regressive language model that uses an ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/nvidia/Kimi-K2.5-NVFP4/raw/d4a2f757554635160d3827398e8cbb065060de74/README.md?utm_source=chatgpt.com","title":"raw","snippet":"This model has been developed and built to a third-party's requirements for this application and use case; see link to Non-NVIDIA [(Kimi-K2.5) Model Card](https ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":20},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/spaces/zh-ai-community/2025-ai-timeline?utm_source=chatgpt.com","title":"2025 China AI Timeline - a Hugging Face Space by zh-ai- ...","snippet":"Qwen/Qwen-Image \u2728. \u2606 2.39k Model. Open Weights Model vision. Qwen/Qwen-Image ... Moonshot's experimental MoE model with Kimi Delta Attention. \u2606 20 ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":26},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/moonshotai/Kimi-K2-Thinking?utm_source=chatgpt.com","title":"moonshotai/Kimi-K2-Thinking","snippet":"27 Jan 2026 \u2014 Kimi K2 Thinking is the latest, most capable version of open-source thinking model. Starting with Kimi K2, we built it as a thinking agent that ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":28},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/moonshotai/Kimi-Dev-72B?utm_source=chatgpt.com","title":"moonshotai/Kimi-Dev-72B","snippet":"We introduce Kimi-Dev-72B, our new open-source coding LLM for software engineering tasks. Kimi-Dev-72B achieves a new state-of-the-art on SWE-bench Verified ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/moonshotai/Kimi-VL-A3B-Thinking?utm_source=chatgpt.com","title":"moonshotai/Kimi-VL-A3B-Thinking","snippet":"10 Apr 2025 \u2014 We present Kimi-VL, an efficient open-source Mixture-of-Experts (MoE) vision-language model (VLM) that offers advanced multimodal reasoning, ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/moonshotai/Kimi-VL-A3B-Thinking-2506?utm_source=chatgpt.com","title":"moonshotai/Kimi-VL-A3B-Thinking-2506","snippet":"10 Apr 2025 \u2014 A long-decode model that will generates up to 32K tokens, we recommend using VLLM for inference, which has already supported Kimi-VL series.Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/moonshotai/Kimi-VL-A3B-Thinking/tree/3f0f648b6b8494b1e76c8de7c8f7ca58bf081e11/figures?utm_source=chatgpt.com","title":"moonshotai/Kimi-VL-A3B-Thinking at ...","snippet":"We're on a journey to advance and democratize artificial intelligence through open source and open science.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/collections/SoulSeeker/moonshotai-kimi-vl-a3b-thinking?utm_source=chatgpt.com","title":"moonshotai/Kimi-VL-A3B-Thinking - a SoulSeeker Collection","snippet":"14 Jul 2025 \u2014 Unlock the magic of AI with handpicked models, awesome datasets, papers, and mind-blowing Spaces from SoulSeeker. ... Hugging Face's logo Hugging ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/moonshotai/Kimi-VL-A3B-Thinking/tree/main?utm_source=chatgpt.com","title":"moonshotai/Kimi-VL-A3B-Thinking at main","snippet":"We're on a journey to advance and democratize artificial intelligence through open source and open science.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":22},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/blog/moonshotai/kimi-vl-a3b-thinking-2506?utm_source=chatgpt.com","title":"\ud83e\udd14\ud83d\udc40\ud83c\udfac\ud83d\udda5\ufe0f\ud83d\udcd6 Kimi-VL-A3B-Thinking-2506: A Quick Navigation","snippet":"21 Jun 2025 \u2014 This model's more efficient reasoning, improved visual understanding, and support for high-resolution and video inputs can open up new possibilities for users.Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":26},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/moonshotai/Kimi-Linear-48B-A3B-Instruct/discussions/11?utm_source=chatgpt.com","title":"moonshotai/Kimi-Linear-48B-A3B-Instruct - KDA","snippet":"5 Nov 2025 \u2014 I noticed in the illustration of the model architecture (Figure 3 in the paper) that the KDA block includes \"Kimi Delta Attention\".","ref_id":{"turn_index":1,"ref_type":"search","ref_index":32},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/mlx-community/Kimi-VL-A3B-Thinking-2506-bf16?utm_source=chatgpt.com","title":"mlx-community/Kimi-VL-A3B-Thinking-2506-bf16","snippet":"This model was converted to MLX format from moonshotai/Kimi-VL-A3B-Thinking-2506 using mlx-vlm version 0.3.2. Refer to the original model card for more details ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":34},"pub_date":null,"attribution":"huggingface.co"}]},{"type":"search_result_group","domain":"github.com","entries":[{"type":"search_result","url":"https://github.com/MoonshotAI/Kimi-Linear?utm_source=chatgpt.com","title":"MoonshotAI/Kimi-Linear","snippet":"48B, 3B, 1M, Hugging Face. Key Features. Kimi Delta Attention (KDA): A linear attention mechanism that refines the gated delta rule with finegrained gating.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/MoonshotAI/Kimi-VL?utm_source=chatgpt.com","title":"Kimi-VL: Mixture-of-Experts Vision-Language Model for ...","snippet":"Kimi-VL: Mixture-of-Experts Vision-Language Model for Multimodal Reasoning, Long-Context Understanding, and Strong Agent Capabilities. License. MIT license.Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"github.com"}]},{"type":"search_result_group","domain":"moonshot.ai","entries":[{"type":"search_result","url":"https://www.moonshot.ai/?utm_source=chatgpt.com","title":"Moonshot AI","snippet":"Kimi is driven by Moonshot's proprietary LLM. It supports online search, deep thinking, multimodal reasoning, and long-form text conversations.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"moonshot.ai"},{"type":"search_result","url":"https://platform.moonshot.ai/docs/guide/kimi-k2-5-quickstart?utm_source=chatgpt.com","title":"Kimi K2.5 - Kimi Large Language Model API Service","snippet":"29 Jan 2026 \u2014 Kimi Open Platform, providing trillion-parameter K2 large language model API, supporting 256K long context and Tool Calling.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"moonshot.ai"}]},{"type":"search_result_group","domain":"reddit.com","entries":[{"type":"search_result","url":"https://www.reddit.com/r/LocalLLaMA/comments/1qpewj7/ama_with_kimi_the_opensource_frontier_lab_behind/?utm_source=chatgpt.com","title":"AMA With Kimi, The Open-source Frontier Lab Behind ...","snippet":"Hey there! Kimi K2 (+ thinking) has been my favourite model to use for everything from general QA to difficult coding problems. K2.5 Is awesome!Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/LocalLLaMA/comments/1m0onbu/alibababacked_moonshot_releases_new_kimi_ai_model/?utm_source=chatgpt.com","title":"Alibaba-backed Moonshot releases new Kimi AI model that ...","snippet":"And despite having more than 1.5x the number of parameters ... KaniTTS2 \u2014 open-source 400M TTS model with voice cloning, runs in 3GB VRAM.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":27},"pub_date":null,"attribution":"reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/LocalLLaMA/comments/1jvgpju/moonshot_ai_released_kimivl_moe_3b16b_thinking/?utm_source=chatgpt.com","title":"Moonshot AI released Kimi-VL MoE (3B/16B) Thinking","snippet":"An MoE VLM and an MoE Reasoning VLM with only ~3B activated parameters (total 16B). Strong multimodal reasoning (36.8% on MathVision, on par with 10x larger ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/LocalLLaMA/comments/1lcw50r/kimidev72b/?utm_source=chatgpt.com","title":"Kimi-Dev-72B : r/LocalLLaMA","snippet":"It's a perfect model for inference providers like Cerebras/SambaNova - you can have it generate tokens at 1000 t/s and it will be a beast.Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":29},"pub_date":null,"attribution":"reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/LocalLLaMA/comments/1jw2ltz/moonshotai_has_just_finished_setting_up_the_demo/?utm_source=chatgpt.com","title":"moonshotai has just finished setting up the demo for Kimi- ...","snippet":"moonshotai has just finished setting up the demo for Kimi-VL-A3B-Thinking on HuggingFace, everyone can go and try it out!","ref_id":{"turn_index":1,"ref_type":"search","ref_index":30},"pub_date":null,"attribution":"reddit.com"}]},{"type":"search_result_group","domain":"arxiv.org","entries":[{"type":"search_result","url":"https://arxiv.org/pdf/2507.20534?utm_source=chatgpt.com","title":"Kimi K2: Open Agentic Intelligence","snippet":"by K Team \u00b7 2025 \u00b7 Cited by 189 \u2014 We introduce Kimi K2, a Mixture-of-Experts (MoE) large language model with 32 billion activated parameters and 1 trillion total parameters. We ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2510.26692?utm_source=chatgpt.com","title":"Kimi Linear: An Expressive, Efficient Attention Architecture","snippet":"by K Team \u00b7 2025 \u00b7 Cited by 22 \u2014 In this work, we present Kimi Linear, a hybrid linear attention architecture designed to meet the efficiency demands of agentic intelligence and ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2509.23045v2?utm_source=chatgpt.com","title":"Kimi-Dev: Agentless Training as Skill Prior for SWE-Agents","snippet":"9 Oct 2025 \u2014 To figure this out, we perform SWE-Agent SFT on the original Qwen2.5-72B (Base), the mid-trained model (MT), the model then activated with ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2504.07491v3?utm_source=chatgpt.com","title":"Kimi-VL Technical Report","snippet":"With only around 3B activated parameters, it sets a new standard for efficient yet capable multimodal thinking models. Code and models are publicly accessible ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":23},"pub_date":null,"attribution":"arxiv.org"}]},{"type":"search_result_group","domain":"facebook.com","entries":[{"type":"search_result","url":"https://www.facebook.com/groups/DeepNetGroup/posts/2716588342067364/?utm_source=chatgpt.com","title":"Moonshot AI releases Kimi K2.5 open source model","snippet":"Moonshot AI Releases Kimi K2.5: An Open Source Visual Agentic Intelligence Model with Native Swarm Execution Kimi K2.5 is an open source visual ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"facebook.com"},{"type":"search_result","url":"https://www.facebook.com/asus.sg/posts/alibabas-new-qwen-ai-is-quickly-becoming-the-app-to-watch-powered-by-the-latest-/891658016520630/?utm_source=chatgpt.com","title":"Alibaba's new Qwen AI is quickly becoming the app to ...","snippet":"Qwen2.5-VL-72B competes with top-tier models in reasoning, math, and video understanding. The 7B model?Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":25},"pub_date":null,"attribution":"facebook.com"}]},{"type":"search_result_group","domain":"digitalocean.com","entries":[{"type":"search_result","url":"https://www.digitalocean.com/community/tutorials/kimi-linear-moonshot-ai?utm_source=chatgpt.com","title":"Designing Hardware-Aware Algorithms with Kimi Linear","snippet":"Moonshot AI's Kimi Linear introduces Kimi Delta Attention (KDA), a hardware-aware algorithm. Learn how to run Kimi Linear on DigitalOcean.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"digitalocean.com"}]},{"type":"search_result_group","domain":"nvidia.com","entries":[{"type":"search_result","url":"https://docs.api.nvidia.com/nim/reference/moonshotai-kimi-k2-5?utm_source=chatgpt.com","title":"moonshotai / kimi-k2-5","snippet":"26 Jan 2026 \u2014 Kimi K2.5 is an open-source, native multimodal agentic model built through continual pretraining on approximately 15 trillion mixed visual ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"nvidia.com"},{"type":"search_result","url":"https://build.nvidia.com/moonshotai/kimi-k2.5/modelcard?utm_source=chatgpt.com","title":"kimi-k2.5 Model by Moonshotai","snippet":"26 Jan 2026 \u2014 Kimi K2.5 HuggingFace Model Card. Model Architecture: Architecture Type: Transformer Network Architecture: Mixture-of-Experts (MoE) Total ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"nvidia.com"},{"type":"search_result","url":"https://docs.api.nvidia.com/nim/reference/moonshotai-kimi-k2-instruct?utm_source=chatgpt.com","title":"moonshotai / kimi-k2-instruct","snippet":"12 Jul 2025 \u2014 This model is designed for agentic AI and tool use, including advanced code generation, complex problem-solving, and multilingual applications.Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":27},"pub_date":null,"attribution":"nvidia.com"}]},{"type":"search_result_group","domain":"moonshotai.github.io","entries":[{"type":"search_result","url":"https://moonshotai.github.io/Kimi-K2/?utm_source=chatgpt.com","title":"Kimi K2: Open Agentic Intelligence","snippet":"Kimi K2 is our latest Mixture-of-Experts model with 32 billion activated parameters and 1 trillion total parameters. It achieves state-of-the-art performance.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"moonshotai.github.io"},{"type":"search_result","url":"https://moonshotai.github.io/Kimi-Dev/?utm_source=chatgpt.com","title":"Kimi-Dev-72B","snippet":"16 Jun 2025 \u2014 With the Qwen 2.5-72B base model as a starting point, we gather millions of GitHub issues and PR commits as its mid-training dataset. The ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"moonshotai.github.io"}]},{"type":"search_result_group","domain":"apxml.com","entries":[{"type":"search_result","url":"https://apxml.com/models/kimi-vl-a3b-instruct?utm_source=chatgpt.com","title":"Kimi-VL-A3B-Instruct: Specifications and GPU VRAM ...","snippet":"The model comprises a total of 16 billion parameters, with its design allowing for the activation of approximately 2.8 billion parameters during inference ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"apxml.com"}]},{"type":"search_result_group","domain":"linkedin.com","entries":[{"type":"search_result","url":"https://www.linkedin.com/posts/deeplearningai_moonshot-releases-kimi-k2-a-trillion-parameter-activity-7355948968452804610-MmtB?utm_source=chatgpt.com","title":"Moonshot AI releases Kimi K2 LLM family with open ...","snippet":"Beijing\u2011based Moonshot AI released the Kimi K2 LLM family, providing open\u2011weights access (under a modified MIT license) to a one ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"linkedin.com"}]},{"type":"search_result_group","domain":"trythatllm.com","entries":[{"type":"search_result","url":"https://trythatllm.com/model/moonshotai-kimi-linear-48b-a3b-instruct?utm_source=chatgpt.com","title":"Kimi Linear 48B A3B Instruct","snippet":"Kimi Linear 48B A3B Instruct is Moonshot AI's efficient hybrid linear attention model released in October 2025, featuring Kimi Delta Attention (KDA) for 75% ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"trythatllm.com"},{"type":"search_result","url":"https://trythatllm.com/model/moonshotai-kimi-dev-72b?utm_source=chatgpt.com","title":"Kimi Dev 72B","snippet":"Kimi Dev 72B is a coding-specialized LLM built on Qwen2.5-72B and optimized through large-scale reinforcement learning. The model autonomously patches real ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":33},"pub_date":null,"attribution":"trythatllm.com"}]},{"type":"search_result_group","domain":"ycombinator.com","entries":[{"type":"search_result","url":"https://news.ycombinator.com/item?id=46775961&utm_source=chatgpt.com","title":"Kimi Released Kimi K2.5, Open-Source Visual SOTA- ...","snippet":"27 Jan 2026 \u2014 Huggingface Link: https://huggingface.co/moonshotai/Kimi-K2.5. 1T parameters, 32b active parameters. License: MIT with the following ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"ycombinator.com"},{"type":"search_result","url":"https://news.ycombinator.com/item?id=44533403&utm_source=chatgpt.com","title":"Kimi K2 is a state-of-the-art mixture-of-experts (MoE) ...","snippet":"11 Jul 2025 \u2014 Kimi K2 is the large language model series developed by Moonshot AI team. Moonshot AI [1] (Moonshot; Chinese: \u6708\u4e4b\u6697\u9762; pinyin: Yu\u00e8 Zh\u012b ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":31},"pub_date":null,"attribution":"ycombinator.com"}]},{"type":"search_result_group","domain":"scmp.com","entries":[{"type":"search_result","url":"https://www.scmp.com/tech/tech-trends/article/3317986/chinese-unicorn-moonshot-launches-ai-model-kimi-k2-red-hot-open-source-market?utm_source=chatgpt.com","title":"Chinese unicorn Moonshot launches AI model Kimi K2 in ...","snippet":"12 Jul 2025 \u2014 Beijing-based Moonshot said Kimi K2 was developed with a mixture-of-experts (MoE) architecture and boasts 1 trillion total parameters, with 32 ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"scmp.com"}]},{"type":"search_result_group","domain":"medium.com","entries":[{"type":"search_result","url":"https://medium.com/data-science-in-your-pocket/kimi-k2-5-best-open-sourced-coding-ai-is-here-00c355772640?utm_source=chatgpt.com","title":"Kimi K2.5: Best open-sourced coding AI is here","snippet":"Moonshot AI has released Kimi K2.5, now the most powerful open-source model available. This is not a small upgrade. K2.5 changes how AI sees, ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://medium.com/predict/six-new-ai-models-worth-your-attention-436976c7da22?utm_source=chatgpt.com","title":"Six new AI models worth your attention | by Conrad Gray","snippet":"Kimi K2 Thinking is Moonshot AI's new flagship \u201cthinking agent\u201d: a trillion-parameter, open-weight mixture-of-experts model built to reason step ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":22},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://medium.com/data-science-in-your-pocket/how-to-use-kimi-k2-for-free-b403d4f96892?utm_source=chatgpt.com","title":"How to use Kimi-K2 for Free?","snippet":"You'll need a Hugging Face account. The model runs on shared backend, so it might be slow. But it's a working demo, enough to see how Kimi-K2 ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":32},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://medium.com/data-science-in-your-pocket/kimi-linear-bye-bye-transformers-c79f843f208c?utm_source=chatgpt.com","title":"Kimi-Linear : Bye Bye Transformers | by Mehul Gupta","snippet":"The Kimi Linear 48B model (with 3B active parameters per forward pass via Mixture-of-Experts) outperforms standard full-attention ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"medium.com"}]},{"type":"search_result_group","domain":"distk.in","entries":[{"type":"search_result","url":"https://distk.in/blog/how-to-use-moonshot-kimi-k2-5-ai-2026.html?utm_source=chatgpt.com","title":"How to Use Moonshot AI Kimi K2.5 2026 - Distk","snippet":"27 Jan 2026 \u2014 Complete guide to using Moonshot AI Kimi K2.5 in 2026. Learn API integration, multimodal AI capabilities, visual coding, agent swarms, ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"distk.in"}]},{"type":"search_result_group","domain":"interconnects.ai","entries":[{"type":"search_result","url":"https://www.interconnects.ai/p/2025-open-models-year-in-review?utm_source=chatgpt.com","title":"2025 Open Models Year in Review","snippet":"14 Dec 2025 \u2014 Kimi K2: Moonshot AI is a laser-focused lab similar to DeepSeek: They work on one model line at a time, while running experiments on smaller ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":19},"pub_date":null,"attribution":"interconnects.ai"}]},{"type":"search_result_group","domain":"openrouter.ai","entries":[{"type":"search_result","url":"https://openrouter.ai/moonshot?utm_source=chatgpt.com","title":"Models: 'moonshot'","snippet":"Built on Kimi K2 with continued pretraining over approximately 15T mixed visual and text tokens, it delivers strong performance in general reasoning, visual ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":19},"pub_date":null,"attribution":"openrouter.ai"},{"type":"search_result","url":"https://openrouter.ai/moonshotai/kimi-dev-72b?utm_source=chatgpt.com","title":"Kimi Dev 72B - API, Providers, Stats","snippet":"16 Jun 2025 \u2014 Kimi-Dev-72B is an open-source large language model fine-tuned for software engineering and issue resolution tasks. Based on Qwen2.5-72B, it ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":21},"pub_date":null,"attribution":"openrouter.ai"}]},{"type":"search_result_group","domain":"runcrate.ai","entries":[{"type":"search_result","url":"https://www.runcrate.ai/models/moonshotai/Kimi-Linear-48B-A3B-Instruct?utm_source=chatgpt.com","title":"moonshotai/Kimi-Linear-48B-A3B-Instruct - AI Model","snippet":"Kimi Linear achieves superior performance and hardware efficiency, especially for long-context tasks. It reduces the need for large KV caches by up to 75% and ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":20},"pub_date":null,"attribution":"runcrate.ai"}]},{"type":"search_result_group","domain":"unsloth.ai","entries":[{"type":"search_result","url":"https://unsloth.ai/docs/models/tutorials/kimi-k2-thinking-how-to-run-locally?utm_source=chatgpt.com","title":"Kimi K2 Thinking: Run Locally Guide","snippet":"27 Jan 2026 \u2014 The full Kimi K2 Q8 quant is 1.09TB in size and will need at least 8 x H200 GPUs. For optimal performance you will need at least 247GB unified ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":21},"pub_date":null,"attribution":"unsloth.ai"},{"type":"search_result","url":"https://unsloth.ai/docs/models/kimi-k2.5?utm_source=chatgpt.com","title":"Kimi K2.5: How to Run Locally Guide","snippet":"Kimi-K2.5 is the new model by Moonshot which achieves SOTA performance in vision, coding, agentic and chat tasks. The 1T parameter hybrid reasoning model ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":23},"pub_date":null,"attribution":"unsloth.ai"}]},{"type":"search_result_group","domain":"dev.to","entries":[{"type":"search_result","url":"https://dev.to/czmilo/kimi-k25-in-2026-the-ultimate-guide-to-open-source-visual-agentic-intelligence-18od?utm_source=chatgpt.com","title":"Kimi K2.5 in 2026: The Ultimate Guide to Open-Source ...","snippet":"27 Jan 2026 \u2014 Kimi K2.5 represents a significant milestone in open-source AI development, released in January 2026 by Moonshot AI. Building upon the ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":24},"pub_date":null,"attribution":"dev.to"}]},{"type":"search_result_group","domain":"researchgate.net","entries":[{"type":"search_result","url":"https://www.researchgate.net/publication/397088634_Kimi_Linear_An_Expressive_Efficient_Attention_Architecture?utm_source=chatgpt.com","title":"Kimi Linear: An Expressive, Efficient Attention Architecture","snippet":"30 Oct 2025 \u2014 We introduce Kimi Linear, a hybrid linear attention architecture that, for the first time, outperforms full attention under fair comparisons ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":24},"pub_date":null,"attribution":"researchgate.net"}]},{"type":"search_result_group","domain":"kr-asia.com","entries":[{"type":"search_result","url":"https://kr-asia.com/moonshot-ai-sees-overseas-revenue-surge-as-kimi-k2-5-gains-traction-abroad?utm_source=chatgpt.com","title":"Moonshot AI sees overseas revenue surge as Kimi K2.5 ...","snippet":"1 Feb 2026 \u2014 Global paying users were reported to have quadrupled within days of K2.5's launch.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":25},"pub_date":null,"attribution":"kr-asia.com"}]},{"type":"search_result_group","domain":"skywork.ai","entries":[{"type":"search_result","url":"https://skywork.ai/blog/models/moonshotai-kimi-linear-48b-a3b-base-free-chat-online/?utm_source=chatgpt.com","title":"moonshotai/Kimi-Linear-48B-A3B-Base Free Chat Online","snippet":"This innovative model combines 48 billion total parameters with a Mixture-of-Experts (MoE) approach that activates only 3 billion parameters per forward pass, ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":28},"pub_date":null,"attribution":"skywork.ai"}]},{"type":"search_result_group","domain":"substack.com","entries":[{"type":"search_result","url":"https://recodechinaai.substack.com/p/kimi-k2-thinking-the-46m-model-shifting?utm_source=chatgpt.com","title":"Kimi K2 Thinking: The $4.6M Model Shifting AI Narratives","snippet":"K2 Thinking is a reasoning model that thinks while using tools. It's the best open LLM available right now, with specific agentic capabilities ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":29},"pub_date":null,"attribution":"substack.com"}]},{"type":"search_result_group","domain":"intuitionlabs.ai","entries":[{"type":"search_result","url":"https://intuitionlabs.ai/articles/kimi-k2-open-weight-llm-analysis?utm_source=chatgpt.com","title":"Analysis of the Kimi K2 Open-Weight Language Model","snippet":"Examines Kimi K2, a trillion-parameter open-weight LLM from Moonshot AI. Learn its technical details, development background, and strategic context.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":30},"pub_date":null,"attribution":"intuitionlabs.ai"}]},{"type":"search_result_group","domain":"caict.ac.cn","entries":[{"type":"search_result","url":"https://aihub.caict.ac.cn/models/moonshotai/Kimi-VL-A3B-Thinking?utm_source=chatgpt.com","title":"moonshotai/Kimi-VL-A3B-Thinking - \u9cb8\u667a\u793e\u533a\u00b7\u5927\u6a21\u578b\u516c\u5171\u670d\u52a1 ...","snippet":"10 Apr 2025 \u2014 We present Kimi-VL, an efficient open-source Mixture-of-Experts (MoE) vision-language model (VLM) that offers advanced multimodal reasoning, ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":31},"pub_date":null,"attribution":"caict.ac.cn"}]},{"type":"search_result_group","domain":"ollama.com","entries":[{"type":"search_result","url":"https://ollama.com/richardyoung/kimi-vl-a3b-thinking%3Alatest?utm_source=chatgpt.com","title":"richardyoung/kimi-vl-a3b-thinking","snippet":"Kimi-VL-A3B-Thinking is a powerful vision-language model from Moonshot AI featuring extended thinking capabilities for complex visual reasoning. Built on the ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":35},"pub_date":null,"attribution":"ollama.com"}]},{"type":"search_result_group","domain":"zhihu.com","entries":[{"type":"search_result","url":"https://zhuanlan.zhihu.com/p/1967520433587880668?utm_source=chatgpt.com","title":"\u6708\u4e4b\u6697\u9762MoonshotAI\u5f00\u6e90Kimi-Linear-48B-A3B\u3010AI \u65e9\u62a5 ...","snippet":"31 Oct 2025 \u2014 MoonshotAI\u5728Hugging Face\u4e0a\u53d1\u5e03\u4e86 Kimi-Linear-48B-A3B-Base \u4e0e Kimi-Linear-48B-A3B-Instruct \u4e24\u6b3e\u6a21\u578b\uff0c\u5e76\u540c\u6b65\u516c\u5f00\u4e86\u6280\u672f\u62a5\u544a\u548c\u53ef\u590d\u73b0\u7684 KDA \u5185\u6838\u4ee3\u7801\u3002","ref_id":{"turn_index":1,"ref_type":"search","ref_index":36},"pub_date":null,"attribution":"zhihu.com"}]},{"type":"search_result_group","domain":"galaxy.ai","entries":[{"type":"search_result","url":"https://blog.galaxy.ai/compare/kimi-dev-72b-vs-qwen2-5-vl-72b-instruct?utm_source=chatgpt.com","title":"Kimi Dev 72B vs. Qwen2.5 VL 72B Instruct","snippet":"In-depth analysis of Kimi Dev 72B vs Qwen2.5 VL 72B Instruct, revealing performance gaps, cost differences, and benchmarks. Choose the right model for your ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":37},"pub_date":null,"attribution":"galaxy.ai"}]}],"citations":[],"resolved_model_slug":"gpt-5-2-auto-thinking","model_slug":"gpt-5-2-thinking","request_id":"440cf611-d1f1-4ba5-82ae-d494323333dc","message_type":"next","default_model_slug":"gpt-5-2","parent_id":"315d5dd9-1c8f-4fb2-8f39-3a3a14218c15","turn_exchange_id":"244c6745-e056-41eb-b609-68be82c19c3e","can_save":true},"recipient":"all","channel":"final"},"parent":"315d5dd9-1c8f-4fb2-8f39-3a3a14218c15","children":[]}}}