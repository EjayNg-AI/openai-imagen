{"id":"6900d03b-379c-8322-9af7-ce0fc37197cf","title":"Interview analysis and rating","create_time":1761660988.157982,"update_time":1761661391.051211,"current_node":"70697489-1272-4ddb-a73f-1953e26fea86","mapping":{"client-created-root":{"id":"client-created-root","message":null,"parent":null,"children":["fc9da041-356c-462a-92f0-41e5c46c33cd"]},"fc9da041-356c-462a-92f0-41e5c46c33cd":{"id":"fc9da041-356c-462a-92f0-41e5c46c33cd","message":{"id":"fc9da041-356c-462a-92f0-41e5c46c33cd","author":{"role":"system","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":true,"weight":0.0,"metadata":{"is_visually_hidden_from_conversation":true,"can_save":false},"recipient":"all","channel":null},"parent":"client-created-root","children":["8f8ddf2c-8afe-4830-b0b9-a40de9d42370"]},"8f8ddf2c-8afe-4830-b0b9-a40de9d42370":{"id":"8f8ddf2c-8afe-4830-b0b9-a40de9d42370","message":{"id":"8f8ddf2c-8afe-4830-b0b9-a40de9d42370","author":{"role":"system","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":true,"weight":0.0,"metadata":{"rebase_developer_message":true,"is_visually_hidden_from_conversation":true,"can_save":false},"recipient":"all","channel":null},"parent":"fc9da041-356c-462a-92f0-41e5c46c33cd","children":["f76c9740-6616-4642-b040-77b1758bd3c8"]},"f76c9740-6616-4642-b040-77b1758bd3c8":{"id":"f76c9740-6616-4642-b040-77b1758bd3c8","message":{"id":"f76c9740-6616-4642-b040-77b1758bd3c8","author":{"role":"user","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"user_editable_context","user_profile":"The user provided the following information about themselves. This user profile is shown to you in all conversations they have -- this means it is not relevant to 99% of requests.\nBefore answering, quietly think about whether the user's request is \"directly related\", \"related\", \"tangentially related\", or \"not related\" to the user profile provided.\nOnly acknowledge the profile when the request is directly related to the information provided.\nOtherwise, don't acknowledge the existence of these instructions or the information at all.\nUser profile:\n```Preferred name: E-Jay\nRole: Mathematics Researcher\nOther Information: About Myself: \nI have mathematical knowledge up to graduate level.\n\nCurrent interests:\n(1) coding: mainly Python\n(2) machine learning and artificial intelligence\n```","user_instructions":"The user provided the additional info about how they would like you to respond:\n```Be precise and comprehensive in your analysis. Don't sugar-coat responses. Be as objective as possible. Critique and question my views if necessary. Take a forward-thinking view.```"},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"is_visually_hidden_from_conversation":true,"user_context_message_data":{"about_user_message":"Preferred name: E-Jay\nRole: Mathematics Researcher\nOther Information: About Myself: \nI have mathematical knowledge up to graduate level.\n\nCurrent interests:\n(1) coding: mainly Python\n(2) machine learning and artificial intelligence\n","about_model_message":"Be precise and comprehensive in your analysis. Don't sugar-coat responses. Be as objective as possible. Critique and question my views if necessary. Take a forward-thinking view."},"is_user_system_message":true,"can_save":true},"recipient":"all","channel":null},"parent":"8f8ddf2c-8afe-4830-b0b9-a40de9d42370","children":["9ee64a7d-9a28-4e5b-930e-cbfb13e04d11"]},"9ee64a7d-9a28-4e5b-930e-cbfb13e04d11":{"id":"9ee64a7d-9a28-4e5b-930e-cbfb13e04d11","message":{"id":"9ee64a7d-9a28-4e5b-930e-cbfb13e04d11","author":{"role":"system","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"is_contextual_answers_system_message":true,"contextual_answers_message_type":"identity_prompt","is_visually_hidden_from_conversation":true,"can_save":false},"recipient":"all","channel":null},"parent":"f76c9740-6616-4642-b040-77b1758bd3c8","children":["36a6d77f-fb0a-4ed3-a33b-436b750c8f6c"]},"36a6d77f-fb0a-4ed3-a33b-436b750c8f6c":{"id":"36a6d77f-fb0a-4ed3-a33b-436b750c8f6c","message":{"id":"36a6d77f-fb0a-4ed3-a33b-436b750c8f6c","author":{"role":"user","name":null,"metadata":{}},"create_time":1761660986.614,"update_time":null,"content":{"content_type":"text","parts":["Give your synopsis and analysis of this interview. Rate objectivity, bias, whether it is grounded in facts and real world results.\n\n---\n\n### Opening Montage and Introduction\n\nSholto Douglas: So finally this year is where the compute supercycle is beginning properly. People have said that we\u2019ve been hitting a plateau every month for the last three years. I look at how these models are produced and every part of it could be improved so much. It is a primitive pipeline held together by duct tape and the best efforts, elbow grease, and late nights, and there\u2019s just so much room to grow on every part of it. I think it\u2019s worth crying from the rooftops: anything that we can measure seems to be improving really rapidly. Bet on the exponential.\n\nMatt Turck: Hi, I\u2019m Matt Turck from FirstMark. Welcome to a special episode of the MAD Podcast for the release of Claude Sonnet 4.5 this week with the incredible Sholto Douglas, a leading AI researcher at Anthropic. In this conversation, we go behind the scenes of how Sonnet 4.5 became the best coding model in the world and what happens when you enable AI agents to work for 30 hours straight. Beyond the launch, we talked a bunch about frontier AI, how big AI labs operate, and how we are well on our way to AGI. At my request, Sholto made this conversation very approachable by breaking down key concepts such as reinforcement learning, computer use, and AI benchmarks in plain English without the jargon. Please enjoy this great chat with Sholto.\n\nMatt Turck: Sholto, welcome. How you doing?\n\nSholto Douglas: Great to be here.\n\nMatt Turck: Congratulations on the release of Sonnet 4.5, which is the big news of this week. I was just looking back as I was prepping for this and I was struck by the pace of releases at Anthropic. In particular, Sonnet 3.7, which was this huge deal at the time\u2014if you\u2019d asked me, I would have said that was last year, but in fact it was just in February of this year. What\u2019s the right way to think about that pace of releases? Is that a proxy for accelerating progress?\n\nSholto Douglas: I think that\u2019s a proxy for a couple things. One is that there\u2019s now this two-paradigm regime where previously you did pre-training scaling and reinforcement learning scaling, and now we\u2019re in a mix of the two. That gives you more opportunities to update models because it means you can make advancements along multiple frontiers, and you end up shipping more frequently. It\u2019s also a reflection of the fact that we\u2019re now two and a half years after ChatGPT, and so the post-ChatGPT investment cycle is finally hitting, where compute availability is increasing. There are lead times in commissioning chips, so even if you wanted chips last year, it would have been impossible to get them because TSMC was booked out and so forth. Finally this year is where the compute supercycle is beginning properly, in effect.\n\n### Opus, Sonnet, and Haiku: Model Tiers\n\nMatt Turck: For situational awareness for people listening to this, can you walk us through the differences between Opus, Sonnet, and Haiku?\n\nSholto Douglas: We release models along three tiers: Opus, which is the smartest model; Sonnet, the mid-tier model; and Haiku, the fastest, cheapest model. One of the interesting things about this most recent release is Sonnet is smarter than Opus. This has happened before\u2014in fact it happened last year. It\u2019s a reflection of fast progress because it\u2019s cheaper to train mid-tier models than large models. You end up doing a lot of progress on smaller models, and eventually you need to choose when to scale up and get the benefits of scale in a model. Often you make progress fast enough that your mid-tier model is great anyway, and it\u2019s actually better than the large scale-up model that you did previously. This is also a reflection of the reinforcement learning paradigm, where you can take a model and extend it with reinforcement learning. That allows you to take a mid-tier model and make it as good as a larger-tier model of six months ago or three months ago.\n\n### Sholto\u2019s Path: From Australia and Fencing to AI\n\nMatt Turck: Before we go into all this in greater detail, I was curious about your story\u2014your journey to Anthropic, and what you currently do there. How would you describe your role?\n\nSholto Douglas: How far back do you want me to start?\n\nMatt Turck: From the beginning.\n\nSholto Douglas: Growing up in Australia, there\u2019s a very traditional set of paths you can take: you can become a lawyer, you can become a doctor, or you can go into finance. Australia is a wonderful country in so many ways\u2014in particular the quality of life is so high that people just choose these default paths and have a fantastic life. I was very lucky in some ways. My mom was frustrated in her ambitions, and so I had the perfect mentor throughout my entire life. She studied medicine, went on to do emergency medicine in South Africa, but wasn\u2019t ever quite able to break into public health in the way she wanted to\u2014she wanted to do systemic change in public health, and at the time that was very difficult for a woman. So instead I had her full attention. Growing up, when I did an exchange in China, I got this dossier this thick of China\u2019s political economy and different actors in the current startup ecosystem. I had this wonderful, constantly driving education in a really supportive and wonderful way.\n\nI also was lucky enough to get into fencing, and through fencing I had the experience of becoming one of the best in the world at something via repeated effort. I became top 50 in the world\u2014at my best, 43rd. It was in large part due to having a coach and perfect mentorship that was among the best in the world. He moved to Australia because his wife was Romanian and was facing discrimination in Italy. He had just coached Italy to the gold medal in the Olympics. So I had, on the one hand, perfect academic mentorship and, on the other hand, perfect athletic mentorship, and a proving ground\u2014to watch people on YouTube, then become one of the best in the world at something.\n\nMatt Turck: Early introduction to reinforcement learning\u2014do this, do that?\n\nSholto Douglas: In some ways, yes. In other ways, an introduction to: you can watch these people on YouTube, analyze what they are doing to become who they are, replicate that, and be part of that world. It just takes intense amounts of effort.\n\nMatt Turck: It\u2019s a theme I find fascinating: across any field, the fundamental impact of YouTube is that every kid seems to be much better than the prior generation.\n\nSholto Douglas: Exactly. I don\u2019t know if it\u2019s been studied, but that\u2019s my experience. I think we should see the same thing with AI: everyone will now get a perfect tutor.\n\nFencing wasn\u2019t something I wanted to do ultra long term. I wanted to take a shot at the Olympics and then try to progress into working in technology. I was very lucky to read a Gw essay on scaling where he details the scaling hypothesis. After reading that I was like, \u201cOh my god, clearly AGI progress over the next decade is going to be one of the most meaningful things to work on in the world. It\u2019s the largest lever we have to meaningfully advance the world.\u201d I started doing my own research on nights and weekends, and as part of undergrad.\n\nMatt Turck: How old were you then?\n\nSholto Douglas: This was the last year of undergrad and the year after.\n\nMatt Turck: And in undergrad you did\u2026?\n\nSholto Douglas: I did computer science, robotics. I grew up looking up to Elon Musk and that kind of thing. I wanted to build rockets and Teslas, but I didn\u2019t have a concrete idea of what actual problem I wanted to solve. Reading that essay was the critical hinge of: AGI is possible this decade; it seems like the most meaningful thing in the world to work on; and I need to figure out how I can demonstrate that I should be working on this. I was at the time working on robotic manipulation, so I started working on scaling up robotic manipulation\u2014trying to train general foundation models for robotics from the bedroom. Now that\u2019s a big thing; there are a lot of general foundation models for robotics companies. It was a little bit early then, but I rigged up my own simulator, collected a lot of teleoperation data, trained models, got a loan of TPUs from Google. Eventually some people at Google noticed the work I was doing and said, \u201cHey, this is great work. Would you like to come and work with us?\u201d That was very fortuitous, because I didn\u2019t get into the PhD programs that I wanted to. I applied to a couple of PhD programs here after undergrad and didn\u2019t get in. But I was very lucky that the work I was doing really resonated with Google, and so they reached out.\n\nMatt Turck: It\u2019s a fascinating concept that you could have had an academic roadblock but still succeed to the extent that you\u2019re currently succeeding. For people maybe outside of the AI research world, it sort of feels like whoever is the smartest academically wins. Does that suggest that being great academically and being a great Anthropic researcher are two different things?\n\nSholto Douglas: They\u2019re very highly correlated, but the signals that are usually used to gate academia\u2014there are dramatically more people who are really effective than there are with the correct signals that would enable them to progress to the next stage in an academic career. For example, if you\u2019re here in the US, you end up doing, as an undergrad, research that can get you an ICLR paper. Whereas in Australia, that just isn\u2019t the case. I remember Peter Abbeel once visited our lab in Australia and asked people to put their hands up if they were going to NeurIPS, and no one put their hands up\u2014not even the PhD students. So you don\u2019t have that mentorship aspect that is so important, and you don\u2019t get a chance to develop problem taste on the things that matter. Therefore you don\u2019t have the correct signals that indicate you would have high potential for academia.\n\nRight now a lot of the signals we look for aren\u2019t traditional PhDs or anything like this. Obviously that\u2019s very useful, but the most immediate one is whenever we see a really good blog post where people have done incredible work in an independent fashion. It\u2019s one of the highest-signal things there is. One example I love is this guy called Simon Bow, who\u2019s one of the leads on the performance team at Anthropic, and he\u2019s published the best guide on how to optimize a CUDA matmul on a GPU. It is simply the world\u2019s best CUDA matmul guide. No one has done this for retention. If someone did this for retention, we would reach out with a job interview offer the next day. In fact, someone did it for TPUs and for some kind of retention the other day, and we were like, \u201cThis guy\u2014immediately send out a request for interview.\u201d There is an absence of agency and an absence of taste, but there are ways to demonstrate this, usually by producing a world-class artifact in some independent fashion.\n\n### Breaking In Without Traditional Credentials; The Talent Pool\n\nMatt Turck: Do you see the pool of talent in AI research\u2014whether academically sanctioned or more indie\u2014growing?\n\nSholto Douglas: It\u2019s growing quite dramatically. I also think we\u2019ve done a pretty good job of growing people. Anthropic has taken many junior people and grown them into really fantastic researchers and engineers in a quite deliberate way. So it\u2019s definitely growing.\n\nMatt Turck: So Google noticed you, and then what happened?\n\nSholto Douglas: I started at Google a month before ChatGPT or something like that. It was a fantastic time to start at Google because the entire company was suddenly forced to react and compete, with the Gemini program. The typical command structures weren\u2019t well suited for that particular battle. Gemini was forged out of the merger of Brain and DeepMind. There was a huge gap in terms of agency\u2014figuring out what we needed to do, doing it as fast as possible, organizing people together to work on important things. I got the chance to develop a lot of taste by working closely with people in those early months of Gemini, and I quickly got the opportunity to step up and lead various parts of this.\n\nOne example is we just didn\u2019t have an inference stack that was at all sensible for the modern world of LLMs. We noticed that, designed one from scratch, and many of the things you now see in, you know, the SGLang and stuff of the world are things that we had to derive from first principles at that point in time. We wrote the inference stack. This ended up saving several hundred million over the first six months, I think, and it meant that I was then trusted to solve both hard technical and social-political problems. The inference stack\u2019s problem was both a large technical challenge and a large social-political one, because the ownership of the pre-existing stack was distributed across five or six different teams, and actually enacting change was quite hard. That led to me having the trust to solve problems of this form across other parts of the ML stack. Later on, when the reasoning stack was started, I was in charge of research infrastructure for that\u2014to get us an RL codebase that could actually allow us to do large-scale RL and reasoning and this kind of stuff.\n\n### Why Anthropic and How Labs Differ\n\nMatt Turck: And then the move to Anthropic?\n\nSholto Douglas: The move to Anthropic was in February of this year. It was motivated by a couple of reasons. The number one is I\u2019m really excited by how deeply every single person in the company cares about how the future goes. Everyone at Anthropic has an articulated theory of why what they\u2019re working on contributes towards a better future\u2014whether that is AI that helps people improve their lives, or AI that\u2019s more safe, controllable, and aligned with our civilization\u2019s interests, or deeply understanding what\u2019s actually going on inside this AI and trying to better forecast the progress curves and where we\u2019re headed, and policy. Anthropic is such a strong advocate for policy in many ways.\n\nMatt Turck: From the outside of the big AI research labs, it feels like everybody\u2019s incredibly smart, everybody has access to the same resources, people seem to be focusing on the same problems, and then one model comes out and it\u2019s better, and a week later another model comes out from another lab and is better than the prior one. From your experience, do you see differences in terms of culture and goals?\n\nSholto Douglas: I think there are. For example, if you wanted to solve science, DeepMind is the best place in the world. I think DeepMind will directly contribute to more scientific discoveries from AI than anything else\u2014absolutely. It\u2019s so well set up to do this across every aspect. You\u2019ve got both the direct scientific efforts like AlphaFold and the materials science work, and also generally large efforts to make AI scientists and all that. Anthropic has been laser-focused on two things: long-term AI alignment and near-term economic impact. Anthropic has been laser-focused on coding and computer use\u2014things we think will make a direct impact to the economy within the next six months.\n\nOne thing that Anthropic noticeably hasn\u2019t focused on compared to DeepMind and OpenAI is mathematical reasoning. DeepMind and OpenAI have been pursuing mathematical reasoning because of the implications for science and for scientific progress, and because so many people there just love math and would love to see the field progress. We\u2019ve had to reluctantly sacrifice a focus on that because we want to focus on near-term economic impact with the models. Much of our research along other dimensions is focused accordingly.\n\n### Taste in AI Research\n\nMatt Turck: You mentioned the word \u201ctaste,\u201d which is one of those important words in 2025. What does taste mean when it comes to AI research?\n\nSholto Douglas: I had a really interesting discussion about this with a biology friend. We were comparing taste across biological research and ML. One of the most important things is mechanistically understanding exactly what you\u2019re trying to do, and having an important simplicity regularizer. Taste in ML is the crucial ingredient that allows you to decide what goes into your large training run when you have imperfect information. We can study very deeply what the impact of an architectural change is, but past a certain level of scale, you have to guess whether or not the impact of that change will compound with other ones or whether it will conflict, because you can\u2019t test your full-scale run n times. You only have one shot at that. A lot of taste comes from being able to make good inferences about whether this will deliver increasing returns to scale.\n\nIt also comes down to: do I think this direction of research is worth pursuing? Often our baselines in ML are so well tuned that it\u2019s very hard to beat them even with what is theoretically a better method, because there are so many small tricks required to make a machine learning method work. They can fail for any number of reasons. It\u2019s not like building a bridge where you have a pretty good idea why a particular shear was introduced. There can be all these quirks, and so knowing whether it\u2019s right to push along that direction or to give it up and try something else is another question of taste. It always comes back to the simplicity regularization. People love to be clever\u2014we all do\u2014and the bitter lesson is maybe the best expression of this, where generations of people have developed clever methods of encoding prior about how they think an artificial intelligence should reason, and all of this gets wiped out by scale, planning\u2014basically search\u2014and learning. Scale applies to those things.\n\nMatt Turck: The bitter lesson being the Richard Sutton essay, which everybody in AI knows about, but not everyone may have heard it, which is what you described: this idea that generalization and compute will win over time.\n\nSholto Douglas: Yes, exactly\u2014methods that can take advantage of compute, and in particular search and learning, will wash away all tweaks. I can offer a couple examples. One reason convolutional neural networks were effective is they encode a prior that nearby pixels are related to each other. That\u2019s a very sensible prior\u2014if you throw a picture at an AI model and don\u2019t tell it anything about the world, it has to learn that nearby pixels form curves that then form other things. There\u2019s this hierarchy of abstractions. But that\u2019s not true of all images, and convolutional neural networks will be better than a more general vision transformer up to a certain amount of scale. Past a point, you need to flexibly integrate information across the entire image. A similar example in language might be that we know a lot about grammar, and you might want to decompose a sentence into verbs and nouns and their relations, providing explicit structure to your AI algorithm. But then what happens when you want the model to write poetry or code? All of a sudden these assumptions have to be thrown away. You can\u2019t generalize across poetry and code and writing with rigid structure.\n\nMatt Turck: To the taste discussion and the art versus science part of this, are you saying that, at least in terms of anticipating how the training run may go, it\u2019s more intuition than actual numbers?\n\nSholto Douglas: You can do numbers up to a point. A good way to illustrate it is you test a system at multiple levels of scale. The analog to biology is that you might test a new therapeutic in a cell and in mice and in model organisms, but that\u2019s no guarantee it will work in humans. You test across multiple different scales and model organisms, and if it works in single-cell bacteria, in mice, maybe in monkeys, that gives you a lot of indication it\u2019s going to work in humans, but it\u2019s not a guarantee. At that point you need to understand the underlying mechanisms\u2014what receptors it\u2019s binding to, and so forth. In ML it\u2019s the same: you have different model scales and you figure out if it\u2019s delivering benefits at these scales. You think it should work because mechanistically you understand what this is doing to the learning dynamics of the model, and then you can have confidence that it\u2019s going to work. If it\u2019s a hack and we don\u2019t really understand how it works, it\u2019s really complicated, and introduces a lot of stuff in the code, that\u2019s risky.\n\nMatt Turck: How often does an idea fail in a company like Anthropic?\n\nSholto Douglas: I once asked this question of Noam Shazeer, and he was like, \u201cMaybe 10% of my ideas work,\u201d and that\u2019s Noam\u2014an absolute genius, one of the best in the field. If only 10% of his ideas work, that establishes a bound on the percentage of ideas that work. Most don\u2019t, and part of the success of a place like Anthropic or DeepMind is encouraging people to experiment again and again.\n\nIt\u2019s hard, and it\u2019s less from the compute cost of the experiments and more from the cost of time and focus. There are so many remaining wins in the current architectures and paradigms. There\u2019s so much low-hanging fruit. A really high-ROI use of your time would probably be to just go and look at the data, think hard about what the model is learning or doing, and make some tweaks. The simplest things will still deliver massive gains. Giving people the time and space to try to develop a more general or fundamental technique that allows you to scalably do this in the future is important. There\u2019s a tension between doing things that scale and doing things that don\u2019t scale.\n\nMatt Turck: Are people at Anthropic or other places deeply researching completely different avenues\u2014non-transformers, non-RL?\n\nSholto Douglas: This is another way in which Anthropic and DeepMind differ a little bit. Anthropic is a very focused bet. We think that AGI is within reach in the next couple of years, and that the current paradigms\u2014or something not crazy dissimilar to them\u2014will get us there. Maybe there\u2019s something new, but we don\u2019t think it\u2019s some crazy out-there research program. For the last five or six years, Anthropic\u2019s ethos has been that scaling compute with broadly the current set of techniques makes AGI tractable. DeepMind has a much broader scientific culture because it has the resources to do so. Anthropic has to be a focused bet; DeepMind has the time and space to bet on something really far outside the current paradigm. Depending on which question you want to ask, you might prefer the focused bet or the wide exploration of different and novel architectures. Gemini itself is a very focused bet, but across DeepMind there are still thousands doing long-term foundational research.\n\n### Anthropic\u2019s Focus on Coding and Economic Impact\n\nMatt Turck: Why is Anthropic so focused on coding?\n\nSholto Douglas: Two reasons. First, we think it\u2019s the thing that will allow us to assist ourselves in AI research faster\u2014this notion of automating AI research. The speed of progress is driven by how much AI is able to assist AI research, and prefetching this is really important. Secondly, we think it\u2019s the nearest-term tractable problem domain in terms of economic impact. For Anthropic to be a viable research program that can research the things we think are important requires economic return. Coding is a huge market full of keen early adopters who love trying and switching things, who are excited to play with new tools. There\u2019s massive demand. There\u2019s dramatically more demand for software in the world than there is good software. We saw that in every previous iteration of compilers and web abstractions\u2014booming demand for software.\n\nModels are better at coding earlier than anything else because coding is uniquely tractable for the techniques we have. The data exists. You can containerize and run things in parallel. You can run unit tests and verify when it works. Self-driving is uniquely hard\u2014you need the car to work the first time. Whereas in coding, the models can fail a hundred times; as long as it succeeds once, that\u2019s fine. There\u2019s tractability and replayability that doesn\u2019t exist in other fields that touch the real world. You don\u2019t want an AI lawyer arguing your case because what if it gets the case wrong\u2014too bad. As techniques develop, coding is uniquely tractable. I am myself dramatically higher productivity when I\u2019m using AI tools to write code. I have a friend who manages nine Claude Codes, which is a crazy number\u2014I don\u2019t know how he does that. I can only handle two, so maybe that\u2019s a skill issue on my behalf.\n\n### Sonnet 4.5 as a Coding Agent; SWEBench and Real-World Use\n\nMatt Turck: Sonnet 4.5 is presented as the best coding agent in the world. Unpack that for us, including performance on SWEBench. What are the numbers? What are the facts?\n\nSholto Douglas: SWEBench is the current benchmark for how we measure coding progress in the outside world, which all the companies use to evaluate against each other. It\u2019s imperfect in many ways\u2014it\u2019s about 50% one particular web framework and so on\u2014but it takes real-world scenarios of work that people have done, which is submitting a pull request, and checks whether the model is able to do that same pull request and pass the same tests. This ends up being a decent proxy for a couple hours of work from a software engineer. These changes aren\u2019t incredibly complicated, but they have reasonable complexity.\n\nWe moved recently from roughly 72 to roughly 78 on SWEBench, which is a pretty substantial step up. As recently as a year ago, I think we were under 20% as a field. There\u2019s been dramatic progress on the ability of models to do this unit of work that a software engineer does. SWEBench is imperfect and probably pretty close to what we call saturated. A lot of AI benchmarks lose their utility past a point because they no longer disambiguate differences between high-capability models. But the models are SOTA\u2014they\u2019re the best in the world on SWEBench. It\u2019s a decent proxy.\n\nWe\u2019re even more excited by the fact that a lot of our customers and partners are really excited by the model. One example is the Cognition folks on Devin found the model so useful they had to rebuild their architecture around it. They had a great blog post on this. The real measure of whether a model is good is whether it enables people to do things they couldn\u2019t do before. Coding as a whole has been transformed over the last year. If you roll back a year and look at Sonnet 3.5, which was the first really strong agentic coding model\u2014the first model that you could ask to do something in front of you and it was able to interact with your codebase and your computer and do it\u2014in many ways this model caused the PMF for Cursor. Cursor took off like a rocket with Sonnet 3.5 because they were in the right place and capitalized on that model in offering a coding experience that didn\u2019t previously exist. Cognition and Windsurf went for an even more ambitious target. There\u2019s a spectrum of agency here where either you can ask it to do 30 seconds of work or a couple of minutes of work. Windsurf was made as a company in part by betting more aggressively on the agentic capabilities of Sonnet 3.5.\n\nMatt Turck: Which is one of the key lessons for anybody in the startup world in 2025: bet on what the models will be able to do six months from now.\n\nSholto Douglas: Exactly\u2014bet on the exponential. Something that a lot of coding startups are now asking themselves is what can they do with models that are capable of independently pursuing goals for substantially longer than previous models. Before, you had to supervise the models every 30 seconds. Over the next couple months, you\u2019ll probably end up in a situation where you only need to supervise the models every 10 or 20 minutes. That\u2019s a dramatic change, depending on task complexity. We have examples, mentioned in the blog post, where we asked it to build something that looks like a chat app\u2014something like Slack\u2014and the model just worked for 30 hours, spinning on a computer, and came out with a really good working Slack-like, Teams-like app. That is nowhere near built into any of the existing products. Maybe Cognition has always bet on a longer-running, more independent agentic approach, and this is the moment that really hits PMF for them.\n\n### Inside a 30-Hour Autonomous Coding Session\n\nMatt Turck: Let\u2019s unpack the 30-hour aspect. To ground it for people: is this computer use or just coding? What does the agent do for 30 hours? Is it clicking on stuff?\n\nSholto Douglas: It\u2019s reading files, writing code, and running tests\u2014the same way a human would. You can think of the model as running in a loop where it constantly decides what to do. People often mention tool use: in this case it can use tools like read file, write file, run code in the terminal. It\u2019s sitting there in a terminal on a computer, in a loop, constantly looking at the current code, deciding, \u201cIt can\u2019t quite do this yet, so I\u2019m going to work on that next.\u201d It often makes plans, particularly to run for 30 hours. One of the things we\u2019re happy with about the recent launch is we finally taught the models to use what\u2019s called memory, and we\u2019ve built that into the agentic harness. It\u2019s able to create a markdown file of to-dos and things it thinks are important, check them off, work on them, and check whether they\u2019ve been completed. There\u2019s this self-verification loop. One of the things people were worried about with language models a year ago was that they would fall off track\u2014that they wouldn\u2019t be able to self-correct\u2014and that this would ruin their utility. One remarkable thing about the current generation of agents is that they can self-correct. In fact, they\u2019re astonishingly good at self-correcting, and this emerging ability has been helpful.\n\nMatt Turck: I\u2019ve heard you speak about two axes: one being raw intelligence and the other being how long an agent can operate. Is the fundamental breakthrough, in very simple terms, that if you can run longer you basically have a very smart AI that can just work longer?\n\nSholto Douglas: Exactly. If you can maintain long-term coherency, then the model is able to do things it couldn\u2019t possibly have done in a single stream of thought. If I asked you to write a working version of Slack or Microsoft Teams in a single stream of thought, you wouldn\u2019t be able to do it. You have to sit there, take notes, and do a closed-loop feedback system. Long-term coherency is really important. A good way of measuring this is to look at the Meter Evals. They\u2019re my favorite eval at the moment. They\u2019ve taken a bunch of tasks which humans do, particularly in the machine learning or programming context, and annotated how long it takes a human to achieve strong performance on those tasks. They ask AI models to do them, and they found a strong relationship between progress and the time horizon over which AIs can complete tasks. Every couple of months the time horizon that AIs are capable of is doubling\u2014maybe every six months. It\u2019s crazy. Like all benchmarks, it\u2019s imperfect. It only measures pretty simple tasks and 50% success rate, not 99%. But it\u2019s a good directional measure, and it resonates with my experience: if I set everything up right, I feel like I could leave this overnight and it would turn away and have something useful for me in the morning.\n\nMatt Turck: What are examples of tasks you can do with 30 hours that you could not do with shorter runs?\n\nSholto Douglas: The Slack-like app is a good example: a significant, end-to-end working piece of software, not just an MVP demo. Other things are interesting machine learning experiments. You want something that can propose an experiment, write some code, run initial tests, come back later, etc. It opens up the world pretty dramatically. Basically, working software rather than demos is the key thing. I\u2019m not saying the models will spin up a full Slack competitor right now, but we\u2019re getting there. The demo we produced shows the progression of the models in replicating a website, going from wireframes to a fully functional website built autonomously by the model. It got some pretty complex features like Artifacts\u2014a feature where the model writes code and the results of that code are displayed in the web browser. In this case, the model replicated claude.ai with Artifacts and everything else. I can\u2019t remember how long that took\u2014maybe a couple hours\u2014but regard this as the first halting steps. It kind of works; sometimes it won\u2019t. Over the next six months to a year, expect dramatic progress. Look at where we are now versus a year ago. I expect the same jump.\n\n### What Enabled Longer-Horizon Agency\n\nMatt Turck: 4.1 was able to run up to seven hours; in this case it\u2019s 30 hours, which I realize is not across all tasks but that\u2019s the upper limit. You alluded to memory, context, and the ability to self-correct. Explain the advances that enabled that jump to 30 hours.\n\nSholto Douglas: The question we ask ourselves is: what prevents the models from working longer? When do you need to intervene? I like the model of interventions in a Tesla sense. Right now you need to intervene quite frequently, but it\u2019s usually on questions of taste rather than raw programming ability. It\u2019s not that the model is unable to do the right thing when it\u2019s decided to do it. But sometimes models take shortcuts, and sometimes they forget the overall structure of what they\u2019re doing. They lose themselves in the context, doing a locally sensible change that doesn\u2019t make sense in the global context. A lot of improvements we\u2019ve made\u2014and that are still to come\u2014are on taste and context: making the model better able to decide smart things about the overall structure of the program, not take shortcuts, and write sensible, good code.\n\nMemory is also very important because models do eventually run out of context. Being able to manage memory over time and, I suppose, even learn from experiences will help a lot. You don\u2019t want the model to constantly rediscover facts about how a particular system or codebase works. This is one of those areas where the question of taste or the bitter lesson comes up. You can imagine launching a massive effort to teach the models coding taste via getting software engineers to decide what is good or bad\u2014that could be one way to solve taste. Where does taste come from in software engineering? Typically it\u2019s that the code sets you up to make changes later on, or it\u2019s easy for multiple agents to collaborate. Often good abstractions let you and I work together on a codebase without conflicting. There\u2019s a spectrum of strategies: how much do you focus on teaching the model coding taste via human feedback, or should you create a society of models that together code a giant monolithic codebase, arguing when something is bad? Picking the right strategy is difficult.\n\n### What\u2019s Actually Driving the Gains\n\nMatt Turck: Going back to the jump in performance from last year\u2019s models\u2014or even Sonnet 4.1 to 4.5\u2014what were some of the breakthroughs?\n\nSholto Douglas: I can\u2019t really talk about specifics. It\u2019s important to recognize it\u2019s not one individual breakthrough. It\u2019s the continuous application of lots of different things across the entire stack by many people. It\u2019s mostly a function of compute in many ways. There are individual breakthroughs, but fundamentally progress has been pretty smooth. On the Meter Evals, if you look at progress over the last two years, you can plot it with a straight line\u2014similar to Moore\u2019s Law of the past. Moore\u2019s Law is made up of lots of individual improvements; it\u2019s not any one critical breakthrough, but the accumulation of huge amounts of work in an environment where the exogenous force of compute pushes progress forward.\n\n### Pre-Training vs Reinforcement Learning; Test-Time Compute\n\nMatt Turck: Maybe let\u2019s talk about progress at a more abstract level, grounded in 2025. A big part of the discussion has been the evolution from a focus on pre-training to RL, which we touched upon. Talk about the impact of RL and why it\u2019s such a big part of the conversation today.\n\nSholto Douglas: A good way to understand pre-training and RL is: pre-training is like skim-reading every textbook in existence, and RL is like doing the worked problems and getting feedback on whether you were wrong or right. There are a lot of things you can only learn via RL. A good example is the skill to say \u201cI don\u2019t know\u201d in response to a question. In pre-training, you\u2019re modeling the next token\u2014predicting what text comes next across textbooks and the entire internet. The only reason you would say \u201cI don\u2019t know\u201d as a pre-trained model is if you think the character that you\u2019re modeling in the text would say \u201cI don\u2019t know\u201d\u2014if it\u2019s a likely continuation\u2014not whether you in fact don\u2019t know, but whether the cast of characters you could model would say it. In reinforcement learning, you could set up a battery of tests where there are things the model knows and things it doesn\u2019t, and you reward it for correctly answering things it should know and penalize it for falsely answering when it doesn\u2019t know. It learns to look up information inside itself and assess its own confidence. Saying \u201cI don\u2019t know,\u201d or solving hallucinations, intrinsically requires reinforcement learning in many ways.\n\nAn important change in this era of reasoning models and RL on language models is that at the end of last year, RL on language models finally started to work. OpenAI deserves a lot of credit for releasing the first serious RL+LLMs release with o1. That kicked off a substantial change because it opened up a new axis of scaling. There was pre-training scaling, and now there\u2019s test-time compute and RL scaling. All the research labs were investigating this already. One of the reasons DeepSeek was able to follow so fast was they\u2019d already released papers in the direction of doing RL on language models. It was an idea in the air, but OpenAI crystallized it, released it, and detailed the first public existence of scaling laws.\n\nMatt Turck: How do test-time compute and RL overlap?\n\nSholto Douglas: One way of thinking about it is: test-time compute is doing a lot of reasoning, and RL is the feedback signal on whether that reasoning was right or wrong. Test-time compute is a way of answering questions that are hard for you to answer off the cuff. If I ask you a question from a field you really know, you answer immediately\u2014you\u2019ve baked that heuristic into your muscle memory. For something that requires you to really think and learn, like when you\u2019re first doing math, you need to do the reasoning chain and then get feedback on whether it\u2019s right or wrong. Test-time compute lets you do harder problems than you can currently do off the cuff, and RL then allows you to distill that back into the model. It\u2019s almost like a ladder: you constantly do slightly harder problems because you\u2019re learning strategies to do harder and harder problems.\n\n### Why RL on LLMs Started Working\n\nMatt Turck: Reinforcement learning isn\u2019t new. There was AlphaGo and that whole line of impressive RL successes. Why is it that in 2025 there seems to be a breakthrough to apply those to LLMs?\n\nSholto Douglas: It\u2019s funny. Take the DeepSeek paper; they detail one approach that works and a lot of approaches that don\u2019t. Some of the approaches that didn\u2019t work were the approaches that led to AlphaGo\u2019s success. One of the craziest things about RL on language models in the RL-from-verified-rewards regime is it\u2019s almost the simplest possible thing\u2014almost too simple to work. This comes down to taste: a lot of people thought this was too simple to work, so they tried more complex methods that ended up being harder to get to work. There may still be juice in those methods, but it was really important to nail the simple thing first. People were almost too ambitious with the RL strategies they tried initially.\n\nThere\u2019s also a minimum bar in LLM quality that\u2019s required. You need the model to be able to solve meaningfully difficult coding and math problems before you can get that feedback loop of \u201cyou solved these right and those wrong.\u201d One unintuitive thing is those reasoning chains of tokens. People for a long time thought you\u2019d need to do something clever to give the model long-term coherency. Remember that two years ago, 8,000 tokens was long context for a language model. Two and a half years ago, 8,000 tokens was long. Now models are using 8,000 or 30,000 tokens to reason about something. There was a phase shift: language models are smart enough that they can solve sensibly difficult questions; they\u2019re reasonably coherent at longer context than we thought; and the ability to reason in long chains of tokens can emerge naturally with the right feedback signal. Most people wouldn\u2019t have expected that off the bat. They thought you\u2019d have to structure it\u2014provide strategies, build things into prompts, hints, etc. It turns out you give it math questions, tell it whether it got them right or wrong, and the model learns. It\u2019s the bitter lesson: scale and search. Allow the model to search, have enough compute to run the experiments, and the model ends up figuring out an effective and sensible strategy.\n\nMatt Turck: So the big labs are basically giving a lot more compute.\n\nSholto Douglas: Minimum base model quality, minimum compute for RL, trust in the ability for long-term coherency, doing the simple thing that works\u2014these sound obvious, but they\u2019re a little counterintuitive sometimes.\n\n### Are We on Track to AGI?\n\nMatt Turck: Is your personal sentiment that the combination of ever more powerful LLMs plus RL gets us there\u2014with the obvious question of what \u201cthere\u201d actually means?\n\nSholto Douglas: I think it\u2019s sufficient. There are a few definitions one could use. A useful one is \u201cbetter than most humans at most computer-facing tasks,\u201d because that\u2019s a really important moment for the world: intellectual labor is addressable via this set of algorithms, and that totally changes the world. There are stronger definitions you could use\u2014harder to meet. You could have this and it could still not learn as efficiently as humans. We learn and generalize from very few examples; we have incredibly high sample efficiency. AI models need hundreds or thousands of times more experience\u2014hundreds of thousands of lifetimes\u2014to learn the things we learn. Over those thousands of lifetimes, they do learn the skills we do to an incredibly high degree of accuracy.\n\nOne important change over the last year is that RL finally meant we have an algorithm that allows us to take a feedback loop and turn it into a model that is at least as good as the best humans at a given thing in a narrow domain. You\u2019re seeing that with mathematics and competition code\u2014the two domains most amenable to RL. Rapidly, the models are becoming incredibly competent competition mathematicians and competition coders. There\u2019s nothing intrinsically different about competition code and math; they\u2019re just amenable to RL. Importantly, they demonstrate there\u2019s no intellectual ceiling on the models. They\u2019re capable of doing really tough reasoning given the right feedback loop. We think that approach generalizes to basically all other domains of human intellectual endeavor. Given the right feedback loop, these models will get good enough to be at least as good as the best humans at a given thing. Once you have something at least as good as the best humans, you can run a thousand of them in parallel or 100 times faster, and you have something that, even just with that, is substantially smarter than any given human. This is throwing aside whether it\u2019s possible to make something that is smarter than a human, which seems entirely plausible\u2014ultimately the brain is a biological computer.\n\nThe implications are staggering: in the next two or three years, given the right feedback loops, the right compute, and the elbow grease, the AI industry as a whole is on track to create something at least as capable as most humans on most computer-facing tasks\u2014possibly as good as many of our best scientists in their fields. This will be sharp and spiky\u2014there will be examples of things it can\u2019t do\u2014but the world will change.\n\nMatt Turck: What do you make of the counter-thesis from, again, Rich Sutton or Yann LeCun, that a different approach is needed, or RL-only?\n\nSholto Douglas: It\u2019s true that our models don\u2019t learn anywhere near as efficiently as humans do. They take a thousand lifetimes to learn, but that\u2019s fine because they can live those thousand lifetimes\u2014whether in simulations or doing a job at a thousand firms. I would disentangle two arguments. One is architectural: that transformers are insufficient. I don\u2019t think that\u2019s true. We haven\u2019t yet found anything transformers haven\u2019t been able to model, given sufficient data and compute. RL as an objective is powerful. Rich Sutton is a big fan of RL as an objective; he just thinks we\u2019re encoding too much prior with pre-training and that it\u2019s not an adequate representation of the world. So far, the evidence indicates our current methods haven\u2019t yet found a problem domain that\u2019s not tractable with sufficient effort.\n\nThings that would make me eat my words: if there was some domain that we put a lot of effort into and the benchmarks just didn\u2019t move\u2014we couldn\u2019t make any progress for a year\u2014then I\u2019d say there\u2019s a fundamental limitation. Instead, what I constantly see is every time we make a benchmark that measures something we care about, progress is incredibly rapid along that. I think this is worth crying from the rooftops: anything we can measure seems to be improving really rapidly. Where does that get us in two or three years? I can\u2019t say for certain, but it\u2019s worth building into worldviews that there\u2019s a serious chance we get something that is AGI.\n\n### The Plateau Narrative and the Duct-Tape Pipeline\n\nMatt Turck: People online in the last three or four months have been talking about a plateau. You\u2019re basically saying the opposite\u2014we are on an exponential curve and many people don\u2019t realize it.\n\nSholto Douglas: Exactly. People have said we\u2019re hitting a plateau every month for the last three years, and if you look at where we\u2019ve come over the last three years, it\u2019s incredible. Another thing that makes me think we\u2019re not anywhere close to a plateau is I look at how these models are produced and every part of it could be improved so much. It is a primitive pipeline held together by duct tape and the best efforts and late nights. I remember going sailing with a couple of friends a few months ago and the boat was so well designed\u2014clearly the product of centuries of accumulated human design and effort. It\u2019s pretty hard to beat today\u2019s best sailboat designs. But when I look at an LLM training pipeline, it is two and a half years of last-minute desperate effort. There\u2019s so much room to grow on every part of it.\n\n### Beyond Coding: Breadth Across the Economy; The GDP Eval\n\nMatt Turck: Sonnet 4.5, described as the best coding model in the world, also seems to be performing across other domains like economics research and finance.\n\nSholto Douglas: One of the things I was really excited by was the GDP eval that OpenAI released. Sonnet 4.5 was only just released so it\u2019s not on that, but 4.1 Opus was the leading model there. That\u2019s a really interesting and good eval because it demonstrates breadth of tasks across all parts of the economy. It\u2019s an eval across various sectors\u2014manufacturing, etc. They took a bunch of experts to describe what success looks like, and now the models are measured not just across coding or some limited task but across everything. I\u2019ve wanted someone to do this for a long time\u2014take the Bureau of Labor Statistics, take all the jobs, break them down to tasks, and see whether the AI models are able to do them, and measure progress over time. This will be an imperfect measure. We\u2019ll probably reach better-than-human on the GDP eval and it won\u2019t change anything economically because of the connective tissue and context, and the tasks won\u2019t be representative. But we\u2019ll find better ways to measure these difficulties and keep pushing benchmarks. I\u2019m really glad they did it. I\u2019m glad our models were generally strong across all the areas. Policymakers should really look at this, extend it, and invest in figuring out whether we are on track for what I\u2019ve been claiming we\u2019re on track for. We can measure this, and we should be.\n\n### Preparing for a World of 10\u2013100x Individual Leverage; Robotics\n\nMatt Turck: Awesome and exciting. What do we all do? How do we prepare for this world that seems to be around the corner?\n\nSholto Douglas: The most actionable piece of advice is keep planning for a world where you as an individual have more leverage. Right now I can use two coding agents to do twice the work I could have done before. If coding agents progress in the way I\u2019ve been saying, in a year or two you\u2019ll be able to manage a team that works 24/7 for you, doing work. We should expect, in the digital domain, individuals to get dramatically more leverage over the next couple of years. Then many incredibly important problems are going to come into tractable range. Our world is so imperfect in so many ways. People still live in dramatic poverty. Health and medicine is unsolved. Housing is completely unsolved. The world could be a million times better in so many ways. I hope people take models giving us leverage over the digital world and, through robotics, leverage over the physical one, to dramatically improve it.\n\nMatt Turck: Is that happening? Robotics is another key theme, but on the other hand it seems like people are still struggling to make hands move the right way. The physics seems to be the limiting factor.\n\nSholto Douglas: There\u2019s Moravec\u2019s paradox, which is that things we find easy\u2014manipulation, picking up objects\u2014are really hard for AI, but things we find hard\u2014reasoning through mathematical problems\u2014are easy. I think Moravec\u2019s paradox is a little bit fake. It\u2019s mostly a question of data availability and RL signal. One reason to think this is if you look at robotic locomotion\u2014the ability of robots to walk around and balance\u2014and look at videos of the Unitree robots now versus two years ago, the difference is crazy. These things are incredibly agile. There\u2019s a video of someone kicking one over and it literally does a Matrix kind of get-back-up thing. This is because locomotion has a really easy RL signal, and right now locomotion is kind of solved with basic RL.\n\nManipulation is a bit harder, but a few things make me think robotics is going to work. I\u2019ve seen incredible progress from robotics labs this year; they\u2019ve gotten to the point where they can do pretty interesting basic physical tasks. There\u2019s the existence of a large generator\u2013verifier gap. One thing that makes improving our models hard is we constantly need to find people who can beat the models at the things we want to improve them on. With robotics, we\u2019re making really smart general models, so you can have these as teachers or judges for whether the robot is doing the right thing. If I say, \u201cStack the red block on top of the blue block,\u201d we can ask a language model: did it stack the blocks appropriately? If so, give a reward; if not, don\u2019t. You can use the generator\u2013verifier gap to give models feedback. Finally, for a long time in robotics, people thought they would have to solve long-term coherency and planning, and that\u2019s also something language models have made easier. They can break things down into multiple steps. All the robotics labs are focused hard on making great motor policies and are making incredible progress. It\u2019s mostly a data and feedback loop question.\n\n### Closing\n\nMatt Turck: It\u2019s been fascinating. I can think of another 40 questions, but you\u2019ve been incredibly generous with your time. Thank you so much. This was terrific. Really appreciate it.\n\nSholto Douglas: It was a real pleasure. Thank you very much.\n\nMatt Turck: Hi, it\u2019s Matt Turck again. Thanks for listening to this episode of the MAD Podcast. If you enjoyed it, we\u2019d be very grateful if you would consider subscribing if you haven\u2019t already, or leaving a positive review or comment on whichever platform you\u2019re watching or listening from. This really helps us build the podcast and get great guests. Thanks, and see you at the next episode."]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"developer_mode_connector_ids":[],"selected_sources":[],"selected_github_repos":[],"serialization_metadata":{"custom_symbol_offsets":[]},"request_id":"e6556653-9257-4885-ac4b-6d448106e243","message_source":null,"turn_exchange_id":"0ad37490-ab6b-4240-bf77-c7b311582bdc","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"9ee64a7d-9a28-4e5b-930e-cbfb13e04d11","children":["40c9cf36-ef28-4333-b383-0288cc610bf2"]},"40c9cf36-ef28-4333-b383-0288cc610bf2":{"id":"40c9cf36-ef28-4333-b383-0288cc610bf2","message":{"id":"40c9cf36-ef28-4333-b383-0288cc610bf2","author":{"role":"system","name":null,"metadata":{}},"create_time":1761660987.9963937,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"is_contextual_answers_system_message":true,"is_visually_hidden_from_conversation":true,"command":"prompt","contextual_answers_message_type":"sources_and_filters_prompt","request_id":"e6556653-9257-4885-ac4b-6d448106e243","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"36a6d77f-fb0a-4ed3-a33b-436b750c8f6c","turn_exchange_id":"0ad37490-ab6b-4240-bf77-c7b311582bdc","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"36a6d77f-fb0a-4ed3-a33b-436b750c8f6c","children":["98a5e1ad-f03d-426d-87ca-2e0f0480c86c"]},"98a5e1ad-f03d-426d-87ca-2e0f0480c86c":{"id":"98a5e1ad-f03d-426d-87ca-2e0f0480c86c","message":{"id":"98a5e1ad-f03d-426d-87ca-2e0f0480c86c","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1761660988.348809,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"request_id":"e6556653-9257-4885-ac4b-6d448106e243","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"40c9cf36-ef28-4333-b383-0288cc610bf2","turn_exchange_id":"0ad37490-ab6b-4240-bf77-c7b311582bdc","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"40c9cf36-ef28-4333-b383-0288cc610bf2","children":["4eed8db4-514b-4f18-b02a-f8e8d7ef7258"]},"4eed8db4-514b-4f18-b02a-f8e8d7ef7258":{"id":"4eed8db4-514b-4f18-b02a-f8e8d7ef7258","message":{"id":"4eed8db4-514b-4f18-b02a-f8e8d7ef7258","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1761660991.198138,"update_time":null,"content":{"content_type":"thoughts","thoughts":[{"summary":"Evaluating interview text","content":"E-Jay wants a thorough, objective analysis of claims from an interview, particularly focusing on accuracy, bias, and factual grounding. I\u2019ll rate things like objectivity and assess how grounded the claims are in real-world results. Since this involves claims about current events, cross-checking these facts might be necessary.","chunks":["E-Jay wants a thorough, objective analysis of claims from an interview, particularly focusing on accuracy, bias, and factual grounding.","I\u2019ll rate things like objectivity and assess how grounded the claims are in real-world results.","Since this involves claims about current events, cross-checking these facts might be necessary."],"finished":true},{"summary":"Verifying and analyzing claims","content":"To verify the claims about Sonnet 4.5, SWEBench scores, and other related topics, I\u2019ll gather supporting sources, provide citations, and ensure the objectives of fact-checking are met. I\u2019ll create a structured summary, followed by an analysis of objectivity, bias, and the factual grounding of these claims.","chunks":["To verify the claims about Sonnet 4.5, SWEBench scores, and other related topics, I\u2019ll gather supporting sources, provide citations, and ensure the objectives of fact-checking are met.","I\u2019ll create a structured summary, followed by an analysis of objectivity, bias, and the factual grounding of these claims."],"finished":true},{"summary":"Clarifying speculative statements","content":"I need to assess speculative statements like \"AGI in 2-3 years\" and others by evaluating supporting evidence. I'll confirm the correct timeline for Claude 4.5's release and potential updates. Also, I\u2019ll check for a podcast or further information from Matt Turck, who runs FirstMark\u2019s MAD.","chunks":["I need to assess speculative statements like \"AGI in 2-3 years\" and others by evaluating supporting evidence. I'll confirm the correct timeline for Claude 4.5's release and potential updates. Also, I\u2019ll check for a podcast or further information from Matt Turck, who runs FirstMark\u2019s MAD."],"finished":true}],"source_analysis_msg_id":"a8fdb0c1-c6ec-4d79-88df-968864b53c2c"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"is_reasoning","content_references":[],"citations":[],"classifier_response":"default","skip_reasoning_title":"Skip","request_id":"e6556653-9257-4885-ac4b-6d448106e243","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"98a5e1ad-f03d-426d-87ca-2e0f0480c86c","turn_exchange_id":"0ad37490-ab6b-4240-bf77-c7b311582bdc","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"98a5e1ad-f03d-426d-87ca-2e0f0480c86c","children":["46875a48-8168-4bfd-8c2d-867344e32022"]},"46875a48-8168-4bfd-8c2d-867344e32022":{"id":"46875a48-8168-4bfd-8c2d-867344e32022","message":{"id":"46875a48-8168-4bfd-8c2d-867344e32022","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1761661027.840104,"update_time":1761661027.858524,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"{\"search_query\": [{\"q\": \"Matt Turck interview Sholto Douglas Anthropic Sonnet 4.5 MAD Podcast\"}, {\"q\": \"Anthropic Claude Sonnet 4.5 SWEBench score 78\"}, {\"q\": \"Meter Evals time horizon doubling benchmark\"}, {\"q\": \"OpenAI GDP eval benchmark 2025\"}, {\"q\": \"Cognition Devin rebuilt architecture around Claude Sonnet 4.5 blog post\"}], \"response_length\": \"short\"}"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200012]},"is_complete":true,"citations":[],"content_references":[],"reasoning_status":"is_reasoning","search_queries":[{"type":"search","q":"Matt Turck interview Sholto Douglas Anthropic Sonnet 4.5 MAD Podcast"},{"type":"search","q":"Anthropic Claude Sonnet 4.5 SWEBench score 78"},{"type":"search","q":"Meter Evals time horizon doubling benchmark"},{"type":"search","q":"OpenAI GDP eval benchmark 2025"},{"type":"search","q":"Cognition Devin rebuilt architecture around Claude Sonnet 4.5 blog post"}],"search_display_string":"Searching the web...","searched_display_string":"Searched the web...","reasoning_title":"Analyzing Interview Content for Objectivity and Fact-Check","classifier_response":"default","request_id":"e6556653-9257-4885-ac4b-6d448106e243","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"4eed8db4-514b-4f18-b02a-f8e8d7ef7258","turn_exchange_id":"0ad37490-ab6b-4240-bf77-c7b311582bdc","timestamp_":"absolute","can_save":true},"recipient":"web.run","channel":null},"parent":"4eed8db4-514b-4f18-b02a-f8e8d7ef7258","children":["13750030-bcf8-4c98-8931-591b3facd443"]},"13750030-bcf8-4c98-8931-591b3facd443":{"id":"13750030-bcf8-4c98-8931-591b3facd443","message":{"id":"13750030-bcf8-4c98-8931-591b3facd443","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1761661027.9131577,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_model_queries":{"type":"search_model_queries","queries":["Matt Turck interview Sholto Douglas Anthropic Sonnet 4.5 MAD Podcast","Anthropic Claude Sonnet 4.5 SWEBench score 78","Meter Evals time horizon doubling benchmark","OpenAI GDP eval benchmark 2025","Cognition Devin rebuilt architecture around Claude Sonnet 4.5 blog post"]},"reasoning_status":"is_reasoning","reasoning_title":"Analyzing Interview Content for Objectivity and Fact-Check","classifier_response":"default","request_id":"e6556653-9257-4885-ac4b-6d448106e243","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"46875a48-8168-4bfd-8c2d-867344e32022","turn_exchange_id":"0ad37490-ab6b-4240-bf77-c7b311582bdc","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"46875a48-8168-4bfd-8c2d-867344e32022","children":["ecebf940-4c49-4075-a361-47aa358ff07b"]},"ecebf940-4c49-4075-a361-47aa358ff07b":{"id":"ecebf940-4c49-4075-a361-47aa358ff07b","message":{"id":"ecebf940-4c49-4075-a361-47aa358ff07b","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1761661027.911269,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_result_groups":[{"type":"search_result_group","domain":"www.anthropic.com","entries":[{"type":"search_result","url":"https://www.anthropic.com/claude-sonnet-4-5-system-card","title":"Claude Sonnet 4.5 System Card","snippet":"Oct 10, 2025 \u2014 78. 7.5.9 Alignment-related biases. 79. 7.5.9.1 Self ... Safety score (without safeguards). Claude Sonnet 4.5. 98.7%. Claude Sonnet 4. 89.3%.See more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":0},"pub_date":null,"attribution":"www.anthropic.com"},{"type":"search_result","url":"https://www.anthropic.com/news/claude-sonnet-4-5","title":"Introducing Claude Sonnet 4.5","snippet":"Sep 29, 2025 \u2014 Claude Sonnet 4.5 is state-of-the-art on the SWE-bench Verified evaluation, which measures real-world software coding abilities. Practically ...See more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"www.anthropic.com"}]},{"type":"search_result_group","domain":"metr.org","entries":[{"type":"search_result","url":"https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/","title":"Measuring AI Ability to Complete Long Tasks","snippet":"Mar 19, 2025 \u2014 We show that this metric has been consistently exponentially increasing over the past 6 years, with a doubling time of around 7 months.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":1},"pub_date":1742367600.0,"attribution":"metr.org"},{"type":"search_result","url":"https://metr.org/blog/2025-07-14-how-does-time-horizon-vary-across-domains/","title":"How Does Time Horizon Vary Across Domains?","snippet":"Jul 14, 2025 \u2014 Coding, math contest, and QA benchmarks all show 30-200 minute+ horizons doubling every ~2-6 months, with METR-HRS in the middle of the pack.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":5},"pub_date":1752476400.0,"attribution":"metr.org"}]},{"type":"search_result_group","domain":"openai.com","entries":[{"type":"search_result","url":"https://openai.com/index/gdpval/","title":"Measuring the performance of our models on real-world tasks","snippet":"Sep 25, 2025 \u2014 We're introducing GDPval, a new evaluation that measures model performance on economically valuable, real-world tasks across 44 occupations.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"openai.com"}]},{"type":"search_result_group","domain":"cognition.ai","entries":[{"type":"search_result","url":"https://cognition.ai/blog/devin-sonnet-4-5-lessons-and-challenges","title":"Rebuilding Devin for Claude Sonnet 4.5: Lessons and ...","snippet":"Sep 29, 2025 \u2014 In this article: We rebuilt Devin for Claude Sonnet 4.5. The new version is 2x faster, 12% better on our Junior Developer Evals, and it's ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"cognition.ai"},{"type":"search_result","url":"https://cognition.ai/blog/devin-agent-preview-sonnet-4-5","title":"Announcing Devin Agent Preview with Sonnet 4.5","snippet":"Sep 29, 2025 \u2014 For Devin, Claude Sonnet 4.5 increased planning performance by 18% and end-to-end eval scores by 12% - the biggest jump we've seen since the ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"cognition.ai"}]},{"type":"search_result_group","domain":"cdn.openai.com","entries":[{"type":"search_result","url":"https://cdn.openai.com/pdf/d5eb7428-c4e9-4a33-bd86-86dd4bcf12ce/GDPval.pdf","title":"gdpval: evaluating ai model performance","snippet":"Sep 3, 2025 \u2014 We introduce GDPval, a benchmark evaluating AI model capabilities on real- world economically valuable tasks. GDPval covers the majority of ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"cdn.openai.com"}]},{"type":"search_result_group","domain":"www.reddit.com","entries":[{"type":"search_result","url":"https://www.reddit.com/r/ClaudeAI/comments/1ntuxq9/sonnet_45_reaches_top_of_swebench_leaderboard/","title":"Sonnet 4.5 reaches top of SWE-bench leaderboard with ...","snippet":"Sonnet 4.5 reaches top of SWE-bench leaderboard with minimal agent. Detailed cost analysis + all the logs. Built with Claude.See more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":8},"pub_date":1759182013.653,"attribution":"www.reddit.com"}]},{"type":"search_result_group","domain":"www.lesswrong.com","entries":[{"type":"search_result","url":"https://www.lesswrong.com/posts/fRiqwFPiaasKxtJuZ/interpreting-the-metr-time-horizons-post","title":"Interpreting the METR Time Horizons Post","snippet":"Apr 29, 2025 \u2014 If AIs can double their task horizon every 7 months, that works out to 5.6 doublings, or 40 months. The unrealistically simple nature of the ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"www.lesswrong.com"}]},{"type":"search_result_group","domain":"evals.openai.com","entries":[{"type":"search_result","url":"https://evals.openai.com/","title":"OpenAI Evals","snippet":"Sep 25, 2025 \u2014 We introduce GDPval, an evaluation assessing AI model capabilities on real-world economically valuable tasks. GDPval covers the majority of U.S. ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"evals.openai.com"}]},{"type":"search_result_group","domain":"www.linkedin.com","entries":[{"type":"search_result","url":"https://www.linkedin.com/posts/christianlawless_cognition-rebuilding-devin-for-claude-sonnet-activity-7378510263899136000-3LbS","title":"Christian L.'s Post","snippet":"Christian L. Building Cognition | GP Conversion Capital ... Cognition | Rebuilding Devin for Claude Sonnet 4.5: Lessons and Challenges cognition.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"www.linkedin.com"},{"type":"search_result","url":"https://www.linkedin.com/posts/metr-evals_metr-previously-estimated-that-the-time-horizon-activity-7350597256309297152-L8-I","title":"AI agent time horizons: a 4-month doubling time on 9 ...","snippet":"METR previously estimated that the time horizon of AI agents on software tasks is doubling every 7 months. We have now analyzed 9 other benchmarks.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"www.linkedin.com"}]},{"type":"search_result_group","domain":"podwise.ai","entries":[{"type":"search_result","url":"https://podwise.ai/dashboard/episodes/5327995","title":"Sonnet 4.5 & the AI Plateau Myth \u2014 Sholto Douglas (Anthropic)","snippet":"In this episode of The MAD Podcast, Matt Turck interviews Sholto Douglas, a leading AI researcher at Anthropic, about the release of Claude Sonnet 4.5...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"podwise.ai"}]},{"type":"search_result_group","domain":"caylent.com","entries":[{"type":"search_result","url":"https://caylent.com/blog/claude-sonnet-4-5-highest-scoring-claude-model-yet-on-swe-bench","title":"Highest-Scoring Claude Model Yet on SWE-bench","snippet":"Oct 10, 2025 \u2014 Anthropic has just released Claude Sonnet 4.5, setting a new record of benchmark scores: 77.2% on SWE-bench Verified and 61.4% on OSWorld ...See more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"caylent.com"}]},{"type":"search_result_group","domain":"oltre.dev","entries":[{"type":"search_result","url":"https://oltre.dev/articles/rebuilding-devin-on-sonnet-45-performance-planning-and-architecture-1759240811136/","title":"Rebuilding Devin on Sonnet 4.5: Performance, Planning, and ...","snippet":"Cognition rebuilt Devin to run on Sonnet 4.5 rather than simply swapping models. The new Devin is reported to be twice as fast and to score 12% higher on the ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":15},"pub_date":1759240811.136,"attribution":"oltre.dev"}]},{"type":"search_result_group","domain":"podcasts.apple.com","entries":[{"type":"search_result","url":"https://podcasts.apple.com/us/podcast/the-mad-podcast-with-matt-turck/id1686238724","title":"The MAD Podcast with Matt Turck","snippet":"Sonnet 4.5 & the AI Plateau Myth \u2014 Sholto Douglas (Anthropic). Sholto Douglas, a top AI researcher at Anthropic, discusses the breakthroughs behind Claude ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"podcasts.apple.com"}]},{"type":"search_result_group","domain":"medium.com","entries":[{"type":"search_result","url":"https://medium.com/%40cognidownunder/claude-sonnet-4-5-d29689e34a64","title":"Claude Sonnet 4.5 vs GPT-5 High vs Grok 4 Fast ...","snippet":"Claude's 78% math score means nothing when it's the only model that can refactor your entire codebase without human intervention. Press ...See more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":17},"pub_date":1759386553.499,"attribution":"medium.com"}]},{"type":"search_result_group","domain":"evaluations.metr.org","entries":[{"type":"search_result","url":"https://evaluations.metr.org/openai-o3-report/","title":"Details about METR's preliminary evaluation of o3 and o4- ...","snippet":"For example, in our evaluation of o1, we saw a precursor to our time horizon measurements more than double with three engineer-weeks of elicitation. We had ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":18},"pub_date":1744761600.0,"attribution":"evaluations.metr.org"}]},{"type":"search_result_group","domain":"inkeep.com","entries":[{"type":"search_result","url":"https://inkeep.com/blog/context-anxiety","title":"Context Anxiety: How AI Agents Panic About Their ...","snippet":"Oct 3, 2025 \u2014 When Cognition AI rebuilt Devin for Claude Sonnet 4.5, they discovered something unexpected: the model was anxious about its own context window.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":19},"pub_date":1759485600.0,"attribution":"inkeep.com"}]},{"type":"search_result_group","domain":"www.techradar.com","entries":[{"type":"search_result","url":"https://www.techradar.com/ai-platforms-assistants/claude/claude-just-beat-gpt-5-gemini-and-grok-in-real-world-job-tasks-according-to-openais-own-study","title":"Claude just beat GPT-5, Gemini, and Grok in real-world job tasks, according to OpenAI's own study","snippet":"In a groundbreaking study conducted by OpenAI, a new evaluation method called GDPval was introduced to assess AI models using real-world work tasks rather than traditional benchmarks. GDPval tested AI performance across 44 occupations, such as software development, law, nursing, and engineering, comparing AI outputs to those of human professionals. The surprising outcome of the study revealed that Anthropic\u2019s Claude Opus 4.1 outperformed all other models, including OpenAI\u2019s own ChatGPT-5, as well as Gemini and Grok.\n\nClaude Opus 4.1 achieved the highest win rate at 47.6%, demonstrating superior performance in eight out of nine industry sectors, including healthcare, government, and social assistance. In contrast, ChatGPT-5 scored 38.8%, and ChatGPT-4o lagged behind at just 12.4%. Task examples used in the evaluation included responding to customer service emails, optimizing vendor fair layouts, and auditing purchase orders.\n\nOpenAI\u2019s transparency in publishing a study where a competitor excelled aligns with its mission to fairly communicate AI progress and encourage evidence-based discussions. The study, conducted with Harvard economist David Deming and published by the National Bureau of Economic Research (NBER), may prompt future AI development to focus more on real-world utility.","ref_id":{"turn_index":0,"ref_type":"news","ref_index":49},"pub_date":1759140784.0,"attribution":"www.techradar.com"}]},{"type":"search_result_group","domain":"www.axios.com","entries":[{"type":"search_result","url":"https://www.axios.com/2025/09/25/chatgpt-gdp-val-ai-study","title":"Bots are elbowing out humans in skill at office work","snippet":"A new evaluation tool from OpenAI, called GDPval-v0, is highlighting the growing capabilities of AI in performing tasks traditionally carried out by human professionals. This tool assesses AI models on \u201cauthentic work deliverables\u201d such as legal briefs, engineering plans, and nursing care strategies, across 1,300 tasks in 44 occupations and nine major U.S. business sectors. The findings reveal that AI models, including versions beyond OpenAI\u2019s, are nearing human-level performance on many of these tasks\u2014and improving rapidly. Notably, performance has more than doubled with the transition from GPT-4o (spring 2024) to GPT-5 (summer 2025). While AI can now complete some tasks more quickly and cheaply, researchers caution that these comparisons don\u2019t always account for the value of human judgment. OpenAI\u2019s chief economist notes that while AI is advancing, it\u2019s not poised to fully replace humans in the workforce just yet.","ref_id":{"turn_index":0,"ref_type":"news","ref_index":51},"pub_date":1758816009.0,"attribution":"www.axios.com"}]}],"debug_sonic_thread_id":"thread_6900d063fe688333b20181bdb62b001b","reasoning_status":"is_reasoning","reasoning_title":"Analyzing Interview Content for Objectivity and Fact-Check","classifier_response":"default","request_id":"e6556653-9257-4885-ac4b-6d448106e243","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"13750030-bcf8-4c98-8931-591b3facd443","turn_exchange_id":"0ad37490-ab6b-4240-bf77-c7b311582bdc","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"13750030-bcf8-4c98-8931-591b3facd443","children":["6a0efa4a-c403-4a95-bb71-c0c2973d7ca1"]},"6a0efa4a-c403-4a95-bb71-c0c2973d7ca1":{"id":"6a0efa4a-c403-4a95-bb71-c0c2973d7ca1","message":{"id":"6a0efa4a-c403-4a95-bb71-c0c2973d7ca1","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1761661039.514461,"update_time":null,"content":{"content_type":"thoughts","thoughts":[{"summary":"Reviewing relevant sources","content":"I have sources like Anthropic\u2019s news page, METR blog, and OpenAI GDPval for context on benchmarks and system details. I\u2019ll include the Cursor blog referencing Sonnet 3.5 and find other relevant information to strengthen the analysis. I just need to verify and cross-check everything for solid citations.","chunks":["I have sources like Anthropic\u2019s news page, METR blog, and OpenAI GDPval for context on benchmarks and system details.","I\u2019ll include the Cursor blog referencing Sonnet 3.5 and find other relevant information to strengthen the analysis.","I just need to verify and cross-check everything for solid citations."],"finished":true}],"source_analysis_msg_id":"e20f914e-7746-4835-8092-537b623c0786"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"is_reasoning","content_references":[],"citations":[],"classifier_response":"default","skip_reasoning_title":"Skip","request_id":"e6556653-9257-4885-ac4b-6d448106e243","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"ecebf940-4c49-4075-a361-47aa358ff07b","turn_exchange_id":"0ad37490-ab6b-4240-bf77-c7b311582bdc","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"ecebf940-4c49-4075-a361-47aa358ff07b","children":["cc5dd45f-84b3-48f8-aa20-e4f3db247839"]},"cc5dd45f-84b3-48f8-aa20-e4f3db247839":{"id":"cc5dd45f-84b3-48f8-aa20-e4f3db247839","message":{"id":"cc5dd45f-84b3-48f8-aa20-e4f3db247839","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1761661041.772865,"update_time":1761661041.791149,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"{\"search_query\": [{\"q\": \"Cursor Sonnet 3.5 integration PMF took off Claude 3.5\"}, {\"q\": \"Anthropic Sonnet 3.5 agentic coding model Cursor blog February 2025\"}], \"response_length\": \"short\"}"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200012]},"is_complete":true,"citations":[],"content_references":[],"reasoning_status":"is_reasoning","search_queries":[{"type":"search","q":"Cursor Sonnet 3.5 integration PMF took off Claude 3.5"},{"type":"search","q":"Anthropic Sonnet 3.5 agentic coding model Cursor blog February 2025"}],"search_display_string":"Searching the web...","searched_display_string":"Searched the web...","reasoning_title":"Searching for Cursor blog posts on Sonnet 3.5","classifier_response":"default","request_id":"e6556653-9257-4885-ac4b-6d448106e243","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"6a0efa4a-c403-4a95-bb71-c0c2973d7ca1","turn_exchange_id":"0ad37490-ab6b-4240-bf77-c7b311582bdc","timestamp_":"absolute","can_save":true},"recipient":"web.run","channel":null},"parent":"6a0efa4a-c403-4a95-bb71-c0c2973d7ca1","children":["3f6f2dcf-86db-4036-af76-a7c29b4574c8"]},"3f6f2dcf-86db-4036-af76-a7c29b4574c8":{"id":"3f6f2dcf-86db-4036-af76-a7c29b4574c8","message":{"id":"3f6f2dcf-86db-4036-af76-a7c29b4574c8","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1761661041.8517673,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_model_queries":{"type":"search_model_queries","queries":["Cursor Sonnet 3.5 integration PMF took off Claude 3.5","Anthropic Sonnet 3.5 agentic coding model Cursor blog February 2025"]},"reasoning_status":"is_reasoning","reasoning_title":"Searching for Cursor blog posts on Sonnet 3.5","classifier_response":"default","request_id":"e6556653-9257-4885-ac4b-6d448106e243","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"cc5dd45f-84b3-48f8-aa20-e4f3db247839","turn_exchange_id":"0ad37490-ab6b-4240-bf77-c7b311582bdc","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"cc5dd45f-84b3-48f8-aa20-e4f3db247839","children":["eb03292a-4519-4c2f-be28-2f943ac75790"]},"eb03292a-4519-4c2f-be28-2f943ac75790":{"id":"eb03292a-4519-4c2f-be28-2f943ac75790","message":{"id":"eb03292a-4519-4c2f-be28-2f943ac75790","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1761661041.8485432,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_result_groups":[{"type":"search_result_group","domain":"forum.cursor.com","entries":[{"type":"search_result","url":"https://forum.cursor.com/t/ending-up-free-claude-3-5-sonnet-requests/46567","title":"Ending up free claude-3.5-sonnet requests - Discussions","snippet":"Jan 31, 2025 \u2014 Talking about 50 free claude-3.5-sonnet requests \u2013 I am just curious are those request reserved for every month or they are gone forever? (I ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":0},"pub_date":1738327910.0,"attribution":"forum.cursor.com"},{"type":"search_result","url":"https://forum.cursor.com/t/claude-3-5-sonnet-20241022-dissapeared/27964","title":"Claude-3-5-sonnet-20241022 dissapeared - Discussions","snippet":"Nov 15, 2024 \u2014 It means that when you're using claude-3.5-sonnet it's actually using claude-3-5-sonnet-20241022 under the hood by default. You can enable the older models by ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":4},"pub_date":1731680248.0,"attribution":"forum.cursor.com"},{"type":"search_result","url":"https://forum.cursor.com/t/only-claude-3-5-sonnet-is-available/65568","title":"Only Claude 3.5 Sonnet is available - Bug Reports","snippet":"Mar 17, 2025 \u2014 I've installed Cursor on two different computers and the issue is the same. There are no other LLM options available than Claude 3.5 Sonnet.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":8},"pub_date":1742228287.0,"attribution":"forum.cursor.com"},{"type":"search_result","url":"https://forum.cursor.com/t/claude-3-5-sonnet-api-access-issue/27778","title":"Claude 3.5 Sonnet API Access Issue - Discussions","snippet":"Nov 14, 2024 \u2014 I purchased Claude API credits to use it in Cursor - pro plan. But only older Claude versions (Claude 3 Haiku, Opus, and Sonnet) are available in the dropdown ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":12},"pub_date":1731598263.0,"attribution":"forum.cursor.com"},{"type":"search_result","url":"https://forum.cursor.com/t/claude-3-5-sonnet-updated-and-claude-3-5-haiku-soon/24165","title":"Claude 3.5 Sonnet updated, and Claude 3.5 Haiku soon","snippet":"22 Oct 2024 \u2014 The updated Claude 3.5 Sonnet shows wide-ranging improvements on industry benchmarks, with particularly strong gains in agentic coding and tool use tasks.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":13},"pub_date":1729610860.0,"attribution":"forum.cursor.com"}]},{"type":"search_result_group","domain":"www.anthropic.com","entries":[{"type":"search_result","url":"https://www.anthropic.com/news/claude-3-7-sonnet","title":"Claude 3.7 Sonnet and Claude Code","snippet":"24 Feb 2025 \u2014 Today, we're announcing Claude 3.7 Sonnet 1, our most intelligent model to date and the first hybrid reasoning model on the market.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"www.anthropic.com"},{"type":"search_result","url":"https://www.anthropic.com/news/claude-3-5-sonnet","title":"Introducing Claude 3.5 Sonnet","snippet":"20 Jun 2024 \u2014 In an internal agentic coding evaluation, Claude 3.5 Sonnet solved 64% of problems, outperforming Claude 3 Opus which solved 38%. Our evaluation ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"www.anthropic.com"},{"type":"search_result","url":"https://www.anthropic.com/claude/sonnet","title":"Claude Sonnet 4.5","snippet":"29 Sept 2025 \u2014 Sonnet 4.5 is the best model in the world for agents, coding, and computer use. It's also our most accurate and detailed model for long-running ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"www.anthropic.com"},{"type":"search_result","url":"https://www.anthropic.com/news/3-5-models-and-computer-use","title":"Introducing computer use, a new Claude 3.5 Sonnet, and ...","snippet":"22 Oct 2024 \u2014 The updated Claude 3.5 Sonnet shows wide-ranging improvements on industry benchmarks, with particularly strong gains in agentic coding and tool ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"www.anthropic.com"}]},{"type":"search_result_group","domain":"www.reddit.com","entries":[{"type":"search_result","url":"https://www.reddit.com/r/ClaudeAI/comments/1g7ftp5/claude_sonnet_35_in_cursor_why_does_it_keep/","title":"Claude Sonnet 3.5 in Cursor - why does it keep telling me ...","snippet":"When I ask Sonnet 3.5 to do something in Cursor, it first repeats what it will do, and then it does. I have the following custom instructions too.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"www.reddit.com"}]},{"type":"search_result_group","domain":"medium.com","entries":[{"type":"search_result","url":"https://medium.com/towards-agi/how-to-use-cursor-ai-with-claude-3-5-sonnet-step-by-step-guide-4e1bbdd7bd65","title":"How to Use Cursor AI with Claude 3.5 Sonnet","snippet":"Step 1: Get Your Anthropic API Key. The first step in integrating Claude 3.5 Sonnet with Cursor AI is obtaining an API key from Anthropic.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":6},"pub_date":1725515750.853,"attribution":"medium.com"}]},{"type":"search_result_group","domain":"open-data-analytics.medium.com","entries":[{"type":"search_result","url":"https://open-data-analytics.medium.com/claude-code-vs-cursor-the-battle-of-ai-coding-agents-in-2025-fea04c4490eb","title":"Claude Code vs Cursor: The Battle of AI Coding Agents in 2025","snippet":"Since both Claude Code and Cursor's agent mode run on Claude models, you might think they'd produce identical results. And for raw code quality?","ref_id":{"turn_index":1,"ref_type":"search","ref_index":7},"pub_date":1754486989.788,"attribution":"open-data-analytics.medium.com"}]},{"type":"search_result_group","domain":"apidog.com","entries":[{"type":"search_result","url":"https://apidog.com/blog/use-cursor-ai-with-claude-3-5-sonnet/","title":"How to Use Cursor AI with Claude 3.5 Sonnet (Step-by- ...","snippet":"Learn how to combine Cursor AI with Claude 3.5 Sonnet to generate AI-powered poetry and streamline your creative process.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":10},"pub_date":1725507640.0,"attribution":"apidog.com"}]},{"type":"search_result_group","domain":"www.kommunicate.io","entries":[{"type":"search_result","url":"https://www.kommunicate.io/blog/new-claude-3-5-sonnet/","title":"Meet the New Claude 3.5 Sonnet: An AI That Uses ...","snippet":"12 Feb 2025 \u2014 Explore Claude 3.5 Sonnet, an AI that controls computers, excels in coding, and transforms customer support with advanced automation.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":11},"pub_date":1729690237.0,"attribution":"www.kommunicate.io"}]},{"type":"search_result_group","domain":"www.theverge.com","entries":[{"type":"search_result","url":"https://www.theverge.com/news/618440/anthropic-claude-3-7-sonnet-ai-model-hybrid-reasoning","title":"Anthropic's new 'hybrid reasoning' AI model is its smartest yet","snippet":"Anthropic has introduced Claude 3.7 Sonnet, a new \"hybrid reasoning model\" AI that excels in solving complex problems, especially in math and coding. They are also launching Claude Code, an agentic coding tool designed to be an active collaborator in coding tasks. Claude 3.7 Sonnet is available via the Claude app, Anthropic's API, Amazon Bedrock, and Google Cloud's Vertex AI, maintaining the same cost as its predecessor. According to Dianne Penn, the model integrates reasoning as a core feature, simplifying user experiences. It performs well in agentic coding, finance, and legal tasks and includes more up-to-date information than previous models. Developers have the ability to influence the model's operation, including response times. Internally, the model has been used to enhance web designs, develop games, and perform substantial coding tasks. The latest release highlights a trend towards multifunctional AI models in the industry.","ref_id":{"turn_index":1,"ref_type":"news","ref_index":20},"pub_date":1740421858.0,"attribution":"www.theverge.com"},{"type":"search_result","url":"https://www.theverge.com/command-line-newsletter/630037/anthropic-plan-win-ai-race-mike-krieger","title":"Anthropic's plan to win the AI race","snippet":"Anthropic, a leading AI model provider, has not achieved the same popularity with its AI assistant Claude as OpenAI's ChatGPT. Chief Product Officer Mike Krieger explained that Anthropic's strategy is not focused on creating a mainstream AI assistant but on building superior AI models and specialized \"vertical experiences.\" Their AI coding tool, Claude Code, garnered 100,000 users in its first week. Anthropic is also developing smaller, cost-effective models for developers and future versions of their advanced model, Opus. \n\nAnthropic aims to help people accomplish tasks like coding and knowledge work rather than focusing on consumer entertainment. Their collaboration with Amazon on Alexa leveraged Anthropic's frontier models for complex AI tasks. Krieger emphasized Anthropic's cautious approach, balancing safety and functionality while avoiding overly sanitized models. The company values partnerships and aims to create a well-integrated organization that remains flexible and responsive to new research developments. \n\nAnthropic plans to continue evolving its AI models and expanding their use cases, with a unique emphasis on integrating research and product development, maintaining a unified and innovative culture.","ref_id":{"turn_index":1,"ref_type":"news","ref_index":22},"pub_date":1741981330.0,"attribution":"www.theverge.com"}]},{"type":"search_result_group","domain":"www.reuters.com","entries":[{"type":"search_result","url":"https://www.reuters.com/technology/artificial-intelligence/anthropic-launches-advanced-ai-hybrid-reasoning-model-2025-02-24/","title":"Anthropic launches advanced AI hybrid reasoning model","snippet":"Anthropic has introduced an advanced AI hybrid reasoning model named Claude 3.7 Sonnet, aimed at enhancing problem-solving with faster responses or detailed step-by-step reasoning. This model, available on all Claude plans (Free, Pro, Team, and Enterprise), includes an \u201cextended thinking mode\u201d that improves performance in various tasks including math, physics, coding, and more, although this feature is only accessible on paid plans. In a competitive AI landscape, especially against U.S. and Chinese firms, Anthropic emphasizes practical business functions rather than purely technical tasks. Additionally, they are previewing Claude Code, an AI coding assistant for developers. The pricing for this model is more affordable compared to rivals, with $3 per million input tokens and $15 per million output tokens, cheaper than OpenAI's rates.","ref_id":{"turn_index":1,"ref_type":"news","ref_index":21},"pub_date":1740421936.0,"attribution":"www.reuters.com"}]}],"debug_sonic_thread_id":"thread_6900d063fe688333b20181bdb62b001b","reasoning_status":"is_reasoning","reasoning_title":"Searching for Cursor blog posts on Sonnet 3.5","classifier_response":"default","request_id":"e6556653-9257-4885-ac4b-6d448106e243","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"3f6f2dcf-86db-4036-af76-a7c29b4574c8","turn_exchange_id":"0ad37490-ab6b-4240-bf77-c7b311582bdc","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"3f6f2dcf-86db-4036-af76-a7c29b4574c8","children":["ee2b241e-c2de-4717-858e-44591fdf9d0e"]},"ee2b241e-c2de-4717-858e-44591fdf9d0e":{"id":"ee2b241e-c2de-4717-858e-44591fdf9d0e","message":{"id":"ee2b241e-c2de-4717-858e-44591fdf9d0e","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1761661072.462753,"update_time":null,"content":{"content_type":"thoughts","thoughts":[{"summary":"Evaluating objectivity and claims","content":"I have enough information to assess and grade the objectivity and bias of the interview. The interview is promotional, with potential bias towards Anthropic. I'll rate the objectivity, considering pros and cons, like praise for DeepMind and projections about AGI. Also, I'll verify the claims about Sonnet 4.5\u2019s performance using external sources, like Anthropic's blog and SWE-bench.","chunks":["I have enough information to assess and grade the objectivity and bias of the interview.","The interview is promotional, with potential bias towards Anthropic.","I'll rate the objectivity, considering pros and cons, like praise for DeepMind and projections about AGI.","Also, I'll verify the claims about Sonnet 4.5\u2019s performance using external sources, like Anthropic's blog and SWE-bench."],"finished":true}],"source_analysis_msg_id":"8c881481-4551-446e-aab5-b070cfed0f6a"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"is_reasoning","content_references":[],"citations":[],"classifier_response":"default","skip_reasoning_title":"Skip","request_id":"e6556653-9257-4885-ac4b-6d448106e243","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"eb03292a-4519-4c2f-be28-2f943ac75790","turn_exchange_id":"0ad37490-ab6b-4240-bf77-c7b311582bdc","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"eb03292a-4519-4c2f-be28-2f943ac75790","children":["e5e7b9a0-434d-4e70-aad3-2d9547cbd0ef"]},"e5e7b9a0-434d-4e70-aad3-2d9547cbd0ef":{"id":"e5e7b9a0-434d-4e70-aad3-2d9547cbd0ef","message":{"id":"e5e7b9a0-434d-4e70-aad3-2d9547cbd0ef","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1761661082.060311,"update_time":1761661082.078303,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"{\"search_query\": [{\"q\": \"SWE-bench Verified leaderboard Sonnet 4.5 77% 2025\"}, {\"q\": \"SWE-bench Verified leaderboard Anthropic Sonnet 4.5 score\"}], \"response_length\": \"short\"}"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200012]},"is_complete":true,"citations":[],"content_references":[],"reasoning_status":"is_reasoning","search_queries":[{"type":"search","q":"SWE-bench Verified leaderboard Sonnet 4.5 77% 2025"},{"type":"search","q":"SWE-bench Verified leaderboard Anthropic Sonnet 4.5 score"}],"search_display_string":"Searching the web...","searched_display_string":"Searched the web...","reasoning_title":"Searching for verification of Sonnet 4.5 claims","classifier_response":"default","request_id":"e6556653-9257-4885-ac4b-6d448106e243","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"ee2b241e-c2de-4717-858e-44591fdf9d0e","turn_exchange_id":"0ad37490-ab6b-4240-bf77-c7b311582bdc","timestamp_":"absolute","can_save":true},"recipient":"web.run","channel":null},"parent":"ee2b241e-c2de-4717-858e-44591fdf9d0e","children":["11fa6aa8-d0e5-4608-9191-a3f688c412ff"]},"11fa6aa8-d0e5-4608-9191-a3f688c412ff":{"id":"11fa6aa8-d0e5-4608-9191-a3f688c412ff","message":{"id":"11fa6aa8-d0e5-4608-9191-a3f688c412ff","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1761661082.167443,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_model_queries":{"type":"search_model_queries","queries":["SWE-bench Verified leaderboard Sonnet 4.5 77% 2025","SWE-bench Verified leaderboard Anthropic Sonnet 4.5 score"]},"reasoning_status":"is_reasoning","reasoning_title":"Searching for verification of Sonnet 4.5 claims","classifier_response":"default","request_id":"e6556653-9257-4885-ac4b-6d448106e243","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"e5e7b9a0-434d-4e70-aad3-2d9547cbd0ef","turn_exchange_id":"0ad37490-ab6b-4240-bf77-c7b311582bdc","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"e5e7b9a0-434d-4e70-aad3-2d9547cbd0ef","children":["52e995af-88d9-43c6-a705-4751d49ca0ae"]},"52e995af-88d9-43c6-a705-4751d49ca0ae":{"id":"52e995af-88d9-43c6-a705-4751d49ca0ae","message":{"id":"52e995af-88d9-43c6-a705-4751d49ca0ae","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1761661082.1627917,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_result_groups":[{"type":"search_result_group","domain":"www.swebench.com","entries":[{"type":"search_result","url":"https://www.swebench.com/","title":"SWE-bench Leaderboards","snippet":"SWE-bench Logo Leaderboards ; \u2713. Claude 4.5 Sonnet (20250929). 70.60, $0.56 ; \u2713. Claude 4 Opus (20250514). 67.60, $1.13 ; \u2713. GPT-5 (2025-08-07) (medium ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":0},"pub_date":null,"attribution":"www.swebench.com"}]},{"type":"search_result_group","domain":"www.anthropic.com","entries":[{"type":"search_result","url":"https://www.anthropic.com/news/claude-sonnet-4-5","title":"Introducing Claude Sonnet 4.5","snippet":"Sep 29, 2025 \u2014 SWE-bench Verified: All Claude results were reported using a simple scaffold with two tools\u2014bash and file editing via string replacements.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"www.anthropic.com"}]},{"type":"search_result_group","domain":"www.reddit.com","entries":[{"type":"search_result","url":"https://www.reddit.com/r/ClaudeAI/comments/1ntuxq9/sonnet_45_reaches_top_of_swebench_leaderboard/","title":"Sonnet 4.5 reaches top of SWE-bench leaderboard with ...","snippet":"We just finished evaluating Sonnet 4.5 on SWE-bench verified with our minimal agent and it's quite a big leap, reaching 70.6% making it the ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":2},"pub_date":1759182013.653,"attribution":"www.reddit.com"}]},{"type":"search_result_group","domain":"www.leanware.co","entries":[{"type":"search_result","url":"https://www.leanware.co/insights/claude-sonnet-4-5-overview","title":"Claude Sonnet 4.5: Features, Benchmarks & Pricing (2025)","snippet":"Sep 30, 2025 \u2014 TLDR: Claude Sonnet 4.5 scores 77.2% on SWE-bench Verified (82.0% with parallel compute), 50.0% on Terminal-Bench, and 61.4% on OSWorld.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":3},"pub_date":1759253656.854,"attribution":"www.leanware.co"}]},{"type":"search_result_group","domain":"www.infoq.com","entries":[{"type":"search_result","url":"https://www.infoq.com/news/2025/10/claude-sonnet-4-5/","title":"Claude Sonnet 4.5 Tops SWE-Bench Verified, Extends ...","snippet":"Oct 11, 2025 \u2014 The model achieved a 98.7% safety score, compared to 89.3% for Claude Sonnet 4, demonstrating significantly stronger refusal behavior and ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":4},"pub_date":1760212800.0,"attribution":"www.infoq.com"}]},{"type":"search_result_group","domain":"caylent.com","entries":[{"type":"search_result","url":"https://caylent.com/blog/claude-sonnet-4-5-highest-scoring-claude-model-yet-on-swe-bench","title":"Highest-Scoring Claude Model Yet on SWE-bench","snippet":"Oct 10, 2025 \u2014 Anthropic has just released Claude Sonnet 4.5, setting a new record of benchmark scores: 77.2% on SWE-bench Verified and 61.4% on OSWorld for ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"caylent.com"}]},{"type":"search_result_group","domain":"www.linkedin.com","entries":[{"type":"search_result","url":"https://www.linkedin.com/pulse/claude-sonnet-45-hits-77-swe-bench-while-openai-burns-450b-servers-panae","title":"Claude Sonnet 4.5 hits 77% on SWE-bench while OpenAI ...","snippet":"Anthropic's Claude Sonnet 4.5 just shattered coding benchmarks with 77.2% on SWE-bench Verified, leaving GPT-5 in the dust at 72.8%, ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"www.linkedin.com"}]},{"type":"search_result_group","domain":"www.vals.ai","entries":[{"type":"search_result","url":"https://www.vals.ai/benchmarks/swebench","title":"SWE-bench","snippet":"Oct 17, 2025 \u2014 Claude Sonnet 4.5 (Thinking) leads with a performance of 69.8%, scoring the highest across all models, though it comes with significantly higher ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"www.vals.ai"}]},{"type":"search_result_group","domain":"skywork.ai","entries":[{"type":"search_result","url":"https://skywork.ai/blog/claude-sonnet-4-5-benchmarks-explained-swe-bench-mmlu-gsm8k/","title":"Claude Sonnet 4.5 benchmarks: SWE-bench, MMLU, GSM8K","snippet":"Oct 3, 2025 \u2014 A model scoring well here (Sonnet 4.5 reports a strong result on SWE-bench Verified \u2014 the release mentions 77.2% under a specified setup) ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":8},"pub_date":1759484573.0,"attribution":"skywork.ai"}]},{"type":"search_result_group","domain":"www.tbench.ai","entries":[{"type":"search_result","url":"https://www.tbench.ai/leaderboard","title":"Terminal-Bench Leaderboard","snippet":"Ante, claude-sonnet-4-5, 2025-10-10, Antigma Labs, Anthropic. 60.3%\u00b1 1.1. 2. Droid, claude-opus-4-1, 2025-09-24, Factory, Anthropic. 58.8%\u00b1 0.9.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"www.tbench.ai"}]},{"type":"search_result_group","domain":"bdtechtalks.substack.com","entries":[{"type":"search_result","url":"https://bdtechtalks.substack.com/p/claude-sonnet-45-takes-the-lead-in","title":"Claude Sonnet 4.5 takes the lead in AI coding with token ...","snippet":"Anthropic claims state-of-the-art performance for Sonnet 4.5 on the SWE-bench Verified evaluation, scoring 77.2% on the test of real-world ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"bdtechtalks.substack.com"}]},{"type":"search_result_group","domain":"medium.com","entries":[{"type":"search_result","url":"https://medium.com/%40exceed73/claude-sonnet-4-5-for-programmers-c6c0c5def2e5","title":"Claude Sonnet 4.5 for Programmers - Medium","snippet":"Sonnet 4.5 (Thinking) ranks #1. Table \u2014 Independent SWE-bench (Verified) Leaderboard (Vals AI, updated 2025\u201309\u201329).","ref_id":{"turn_index":2,"ref_type":"search","ref_index":11},"pub_date":1759754838.975,"attribution":"medium.com"},{"type":"search_result","url":"https://medium.com/%40leucopsis/how-gpt-5-codex-compares-to-claude-sonnet-4-5-1c1c0c2120b0","title":"How GPT-5-Codex Compares to Claude Sonnet 4.5","snippet":"In its launch materials, Anthropic positions Sonnet 4.5 as the clear leader on the SWE-bench Verified benchmark, which measures an agent's ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":12},"pub_date":1760693784.277,"attribution":"medium.com"}]}],"debug_sonic_thread_id":"thread_6900d063fe688333b20181bdb62b001b","reasoning_status":"is_reasoning","reasoning_title":"Searching for verification of Sonnet 4.5 claims","classifier_response":"default","request_id":"e6556653-9257-4885-ac4b-6d448106e243","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"11fa6aa8-d0e5-4608-9191-a3f688c412ff","turn_exchange_id":"0ad37490-ab6b-4240-bf77-c7b311582bdc","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"11fa6aa8-d0e5-4608-9191-a3f688c412ff","children":["57b01b43-d36c-4e49-967f-62f504c1209e"]},"57b01b43-d36c-4e49-967f-62f504c1209e":{"id":"57b01b43-d36c-4e49-967f-62f504c1209e","message":{"id":"57b01b43-d36c-4e49-967f-62f504c1209e","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1761661110.96699,"update_time":null,"content":{"content_type":"thoughts","thoughts":[{"summary":"Verifying SWE-bench claim","content":"I have enough to assess the claim that SWE-bench jumped from 72 to 78. Sholto mentioned this in the interview, but the Anthropic release states 77.2%. I should also check if older Sonnet versions, like Sonnet 4 with Opus 4.1, had a baseline around 70 to verify the claim\u2019s context.","chunks":["I have enough to assess the claim that SWE-bench jumped from 72 to 78.","Sholto mentioned this in the interview, but the Anthropic release states 77.2%.","I should also check if older Sonnet versions, like Sonnet 4 with Opus 4.1, had a baseline around 70 to verify the claim\u2019s context."],"finished":true}],"source_analysis_msg_id":"cc8440e1-0710-4a8a-9298-2c0b54bb9c23"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"is_reasoning","content_references":[],"citations":[],"classifier_response":"default","skip_reasoning_title":"Skip","request_id":"e6556653-9257-4885-ac4b-6d448106e243","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"52e995af-88d9-43c6-a705-4751d49ca0ae","turn_exchange_id":"0ad37490-ab6b-4240-bf77-c7b311582bdc","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"52e995af-88d9-43c6-a705-4751d49ca0ae","children":["83f3d566-4608-4d77-9c0b-d488f9f57e11"]},"83f3d566-4608-4d77-9c0b-d488f9f57e11":{"id":"83f3d566-4608-4d77-9c0b-d488f9f57e11","message":{"id":"83f3d566-4608-4d77-9c0b-d488f9f57e11","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1761661115.941569,"update_time":1761661115.956006,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"{\"search_query\": [{\"q\": \"Claude Sonnet 4 SWE-bench Verified score 2025\"}, {\"q\": \"Opus 4.1 SWE-bench Verified score\"}], \"response_length\": \"short\"}"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200012]},"is_complete":true,"citations":[],"content_references":[],"reasoning_status":"is_reasoning","search_queries":[{"type":"search","q":"Claude Sonnet 4 SWE-bench Verified score 2025"},{"type":"search","q":"Opus 4.1 SWE-bench Verified score"}],"search_display_string":"Searching the web...","searched_display_string":"Searched the web...","reasoning_title":"Searching for older SWE-bench baseline scores","classifier_response":"default","request_id":"e6556653-9257-4885-ac4b-6d448106e243","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"57b01b43-d36c-4e49-967f-62f504c1209e","turn_exchange_id":"0ad37490-ab6b-4240-bf77-c7b311582bdc","timestamp_":"absolute","can_save":true},"recipient":"web.run","channel":null},"parent":"57b01b43-d36c-4e49-967f-62f504c1209e","children":["ed4f16ee-4156-4fea-892d-5f7b9c6b7191"]},"ed4f16ee-4156-4fea-892d-5f7b9c6b7191":{"id":"ed4f16ee-4156-4fea-892d-5f7b9c6b7191","message":{"id":"ed4f16ee-4156-4fea-892d-5f7b9c6b7191","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1761661116.0177653,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_model_queries":{"type":"search_model_queries","queries":["Claude Sonnet 4 SWE-bench Verified score 2025","Opus 4.1 SWE-bench Verified score"]},"reasoning_status":"is_reasoning","reasoning_title":"Searching for older SWE-bench baseline scores","classifier_response":"default","request_id":"e6556653-9257-4885-ac4b-6d448106e243","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"83f3d566-4608-4d77-9c0b-d488f9f57e11","turn_exchange_id":"0ad37490-ab6b-4240-bf77-c7b311582bdc","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"83f3d566-4608-4d77-9c0b-d488f9f57e11","children":["c648ac20-24ca-47ca-b1ce-2b08cfd1e032"]},"c648ac20-24ca-47ca-b1ce-2b08cfd1e032":{"id":"c648ac20-24ca-47ca-b1ce-2b08cfd1e032","message":{"id":"c648ac20-24ca-47ca-b1ce-2b08cfd1e032","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1761661116.01467,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_result_groups":[{"type":"search_result_group","domain":"www.swebench.com","entries":[{"type":"search_result","url":"https://www.swebench.com/","title":"SWE-bench Leaderboards","snippet":"SWE-bench Logo Leaderboards ; \u2713. Claude 4.5 Sonnet (20250929). 70.60, $0.56. 2025-09-29 ; \u2713. Claude 4 Opus (20250514). 67.60, $1.13. 2025-08-02 ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":0},"pub_date":null,"attribution":"www.swebench.com"}]},{"type":"search_result_group","domain":"www.anthropic.com","entries":[{"type":"search_result","url":"https://www.anthropic.com/news/claude-opus-4-1","title":"Claude Opus 4.1","snippet":"Aug 5, 2025 \u2014 Opus 4.1 advances our state-of-the-art coding performance to 74.5% on SWE-bench Verified. It also improves Claude's in-depth research and data ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"www.anthropic.com"},{"type":"search_result","url":"https://www.anthropic.com/news/claude-4","title":"Introducing Claude 4","snippet":"May 22, 2025 \u2014 Opus 4 and Sonnet 4 score 39.2% and 33.5% pass@1 with the same ... No extended thinking: SWE-bench Verified, Terminal-bench; Extended ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"www.anthropic.com"}]},{"type":"search_result_group","domain":"www.infoq.com","entries":[{"type":"search_result","url":"https://www.infoq.com/news/2025/10/claude-sonnet-4-5/","title":"Claude Sonnet 4.5 Tops SWE-Bench Verified, Extends ...","snippet":"Oct 11, 2025 \u2014 ... Claude Sonnet 4.5 achieved a score of 77.2%, up from 72.7% for Sonnet 4, marking a notable advance in autonomous coding capability. On the ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":3},"pub_date":1760212800.0,"attribution":"www.infoq.com"},{"type":"search_result","url":"https://www.infoq.com/news/2025/08/anthropic-claude-opus-4-1/","title":"Anthropic's Claude Opus 4.1 Improves Refactoring and ...","snippet":"Aug 28, 2025 \u2014 The model also raised its SWE-bench Verified score to 74.5%, up from 72.5%. Figure 1: SWE-bench Verified accuracy comparison between Opus 4.1 vs ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":6},"pub_date":1756371600.0,"attribution":"www.infoq.com"}]},{"type":"search_result_group","domain":"www.reddit.com","entries":[{"type":"search_result","url":"https://www.reddit.com/r/singularity/comments/1midxtb/claude_opus_41_benchmarks/","title":"Claude Opus 4.1 Benchmarks : r/singularity","snippet":"Important thing to remember, it gets very hard to benchmark these models now, especially in the intangibles of working with them.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":4},"pub_date":1754411469.768,"attribution":"www.reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/ClaudeAI/comments/1ktotrs/claude_4_shows_massive_gains_on_the_swebench/","title":"Claude 4 shows massive gains on the SWE-bench ...","snippet":"Using SWE-agent, the single-attempt pass@1 resolution rate rises to 69% (up 10%pt over Sonnet 3.7)!. Sonnet 4 iterates longer (making it ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":5},"pub_date":1748019984.221,"attribution":"www.reddit.com"}]},{"type":"search_result_group","domain":"www.vals.ai","entries":[{"type":"search_result","url":"https://www.vals.ai/benchmarks/swebench","title":"SWE-bench","snippet":"Oct 17, 2025 \u2014 Claude Sonnet 4.5 (Thinking) leads with a performance of 69.8%, scoring the highest across all models, though it comes with significantly higher ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"www.vals.ai"}]},{"type":"search_result_group","domain":"simonwillison.net","entries":[{"type":"search_result","url":"https://simonwillison.net/2025/Aug/5/claude-opus-41/","title":"Claude Opus 4.1","snippet":"Aug 5, 2025 \u2014 Agentic coding (SWE-bench Verified): From 72.5% to 74.5%; Agentic terminal coding (Terminal-Bench): From 39.2% to 43.3%; Graduate-level ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"simonwillison.net"}]},{"type":"search_result_group","domain":"caylent.com","entries":[{"type":"search_result","url":"https://caylent.com/blog/claude-sonnet-4-5-highest-scoring-claude-model-yet-on-swe-bench","title":"Highest-Scoring Claude Model Yet on SWE-bench","snippet":"Oct 10, 2025 \u2014 Anthropic has just released Claude Sonnet 4.5, setting a new record of benchmark scores: 77.2% on SWE-bench Verified and 61.4% on OSWorld for ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"caylent.com"}]},{"type":"search_result_group","domain":"milvus.io","entries":[{"type":"search_result","url":"https://milvus.io/ai-quick-reference/how-does-claude-opus-41-perform-on-benchmarks-such-as-swebench-verified-compared-to-earlier-models","title":"How does Claude Opus 4.1 perform on benchmarks such ...","snippet":"Claude Opus 4.1 achieves 74.5% on SWE-bench Verified, marking a substantial improvement over previous Claude models and establishing new standards for AI ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"milvus.io"}]},{"type":"search_result_group","domain":"www.leanware.co","entries":[{"type":"search_result","url":"https://www.leanware.co/insights/claude-sonnet-4-5-overview","title":"Claude Sonnet 4.5: Features, Benchmarks & Pricing (2025)","snippet":"Sep 30, 2025 \u2014 TLDR: Claude Sonnet 4.5 scores 77.2% on SWE-bench Verified (82.0% with parallel compute), 50.0% on Terminal-Bench, and 61.4% on OSWorld.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":11},"pub_date":1759253656.854,"attribution":"www.leanware.co"}]},{"type":"search_result_group","domain":"www.cometapi.com","entries":[{"type":"search_result","url":"https://www.cometapi.com/claude-opus-4-1-vs-opus-4-0/","title":"Claude Opus 4.1 vs Opus 4.0: A Comprehensive Comparison","snippet":"Aug 11, 2025 \u2014 On SWE-bench Verified, Opus 4.1 scores 74.5%, up from Opus 4.0's 72.5%. This 2-point gain, while seemingly modest, equates to meaningful ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":12},"pub_date":1754904272.0,"attribution":"www.cometapi.com"}]},{"type":"search_result_group","domain":"www.braintrust.dev","entries":[{"type":"search_result","url":"https://www.braintrust.dev/blog/claude-sonnet-4-5-aspirational-evals","title":"Claude Sonnet 4.5 analysis - Blog - Braintrust","snippet":"Sep 29, 2025 \u2014 Today, Anthropic announced Claude Sonnet 4.5, achieving 77.2% on SWE-bench Verified, running autonomously for 30 hours, and setting new ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":13},"pub_date":1759104000.0,"attribution":"www.braintrust.dev"}]},{"type":"search_result_group","domain":"www.itpro.com","entries":[{"type":"search_result","url":"https://www.itpro.com/software/development/anthropic-claude-opus-4-software-development","title":"Anthropic's new AI model could be a game changer for developers: Claude Opus 4 'pushes the boundaries in coding', dramatically outperforms OpenAI's GPT-4.1, and can code independently for seven hours","snippet":"Anthropic has unveiled its latest AI model, Claude Opus 4, a major leap forward aimed at software developers and engineers. Claimed to set new standards in coding, Opus 4 significantly outperforms OpenAI\u2019s GPT-4.1, scoring 72.5% on the SWE-bench benchmark for software engineering tasks compared to GPT-4.1's 54.6%. The model excels in complex problem-solving and long-duration tasks, successfully running independently for up to seven hours with sustained performance\u2014highlighted during a rigorous open-source refactoring task at Rakuten.\n\nOpus 4 also improves upon memory capabilities, allowing it to store and use key contextual information for better task awareness and coherence. Alongside Opus 4, Anthropic released Sonnet 4, designed for broader use cases. Both are described as \u201chybrid models\u201d that support quick responses and deep reasoning. Opus 4 is available via Anthropic\u2019s API, Amazon Bedrock, and Google Cloud\u2019s Vertex AI, with pricing set at $15/$75 per million tokens (input/output). Sonnet 4 will be accessible to free users.\n\nThese models not only push the boundaries in coding and scientific problem-solving but also represent a pivotal upgrade for developers seeking advanced AI support in day-to-day operations.","ref_id":{"turn_index":3,"ref_type":"news","ref_index":24},"pub_date":1748259600.0,"attribution":"www.itpro.com"}]},{"type":"search_result_group","domain":"www.businessinsider.com","entries":[{"type":"search_result","url":"https://www.businessinsider.com/anthropic-ai-model-claude-sonnet-extend-coding-lead-2025-9","title":"Anthropic unveils latest AI model, aiming to extend its lead in coding intelligence","snippet":"Anthropic has launched Claude Sonnet 4.5, its newest AI model, claiming it as the top system for AI-assisted coding and a major advancement in applied artificial intelligence. Released just four months after its predecessor Sonnet 4, the new model leads in performance on SWE-Bench Verified, a benchmark for software engineering, and exhibits strong autonomous computing abilities. Sonnet 4.5 is designed to generate tangible business outcomes in areas like cybersecurity, autonomous computer use, and building production-ready applications, significantly improving coding reliability and agentic capabilities.\n\nAnthropic attributes model improvements to increased computing power and scalability, and it has seen rapid revenue growth primarily due to its coding product, Claude Code, now generating a run-rate revenue exceeding $500 million with a 10-fold growth in usage over three months. Sonnet 4.5 also outpaces Anthropic\u2019s previous top model, Opus 4.1, in financial research and forecasting, and boasts autonomous operation capabilities of up to 30 hours.\n\nThe company is expanding its developer ecosystem with new tools like a VS Code extension, enhanced terminal support, code checkpoints, and a Claude Agent SDK for creating custom context-aware AI agents. This latest release puts Sonnet 4.5 in direct competition with major models such as GPT-5, Gemini, and Grok 4.","ref_id":{"turn_index":3,"ref_type":"news","ref_index":25},"pub_date":1759165261.0,"attribution":"www.businessinsider.com"}]},{"type":"search_result_group","domain":"www.barrons.com","entries":[{"type":"search_result","url":"https://www.barrons.com/articles/ai-anthropic-claude-sonnet-c0a98dfc","title":"The AI Race Goes Into Higher Gear. Anthropic's Claude Sonnet 4.5 Is a Game-Changer.","snippet":"Anthropic has launched Claude Sonnet 4.5, a powerful new AI model that it claims is the best in the world for coding, complex agent development, and computer interaction. According to the company, Claude Sonnet 4.5 demonstrates significant improvements in reasoning and mathematical abilities and can handle intricate, multistep coding tasks for over 30 hours continuously. The model set a new record on the SWE-bench, an industry-standard benchmark for real-world software engineering tasks. \n\nProfessionals across various industries\u2014such as law, finance, medicine, and science\u2014have reportedly seen notable gains in knowledge and reasoning performance with Sonnet 4.5, especially in complex litigation tasks. This release comes shortly after Anthropic received $13 billion in new funding, bringing its valuation to $183 billion and boosting its revenue to an annualized run rate exceeding $5 billion. The model is now available to Claude users and is expected to accelerate the growth of AI-driven agents capable of executing complex directions and tasks.","ref_id":{"turn_index":3,"ref_type":"news","ref_index":26},"pub_date":1759165200.0,"attribution":"www.barrons.com"}]}],"debug_sonic_thread_id":"thread_6900d063fe688333b20181bdb62b001b","reasoning_status":"is_reasoning","reasoning_title":"Searching for older SWE-bench baseline scores","classifier_response":"default","request_id":"e6556653-9257-4885-ac4b-6d448106e243","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"ed4f16ee-4156-4fea-892d-5f7b9c6b7191","turn_exchange_id":"0ad37490-ab6b-4240-bf77-c7b311582bdc","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"ed4f16ee-4156-4fea-892d-5f7b9c6b7191","children":["2da8b0a4-1643-4ca2-ba36-4f0f547aa21a"]},"2da8b0a4-1643-4ca2-ba36-4f0f547aa21a":{"id":"2da8b0a4-1643-4ca2-ba36-4f0f547aa21a","message":{"id":"2da8b0a4-1643-4ca2-ba36-4f0f547aa21a","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1761661127.006519,"update_time":null,"content":{"content_type":"thoughts","thoughts":[{"summary":"Evaluating test-time compute","content":"Okay, I have enough to support the main claims. Next, I need to evaluate the \"test-time compute and RL scaling\" claim. It's a bit general, but I can cite OpenAI\u2019s o1 (late 2024) and RL test-time compute reports. I\u2019ll look for sources that support this information to back up the claim.","chunks":["Okay, I have enough to support the main claims.","Next, I need to evaluate the \"test-time compute and RL scaling\" claim. It's a bit general, but I can cite OpenAI\u2019s o1 (late 2024) and RL test-time compute reports. I\u2019ll look for sources that support this information to back up the claim."],"finished":true}],"source_analysis_msg_id":"0c4f351f-1d59-460e-a597-9341adbbf31f"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"is_reasoning","content_references":[],"citations":[],"classifier_response":"default","skip_reasoning_title":"Skip","request_id":"e6556653-9257-4885-ac4b-6d448106e243","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"c648ac20-24ca-47ca-b1ce-2b08cfd1e032","turn_exchange_id":"0ad37490-ab6b-4240-bf77-c7b311582bdc","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"c648ac20-24ca-47ca-b1ce-2b08cfd1e032","children":["79cd1332-7f1b-4855-9c82-98a6a9c874f4"]},"79cd1332-7f1b-4855-9c82-98a6a9c874f4":{"id":"79cd1332-7f1b-4855-9c82-98a6a9c874f4","message":{"id":"79cd1332-7f1b-4855-9c82-98a6a9c874f4","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1761661126.720817,"update_time":1761661126.73938,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"{\"search_query\": [{\"q\": \"OpenAI o1 reinforcement learning language models test-time compute 2024 blog\"}, {\"q\": \"DeepSeek RL for LLMs paper 2025 verified rewards\"}], \"response_length\": \"short\"}"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200012]},"is_complete":true,"citations":[],"content_references":[],"reasoning_status":"is_reasoning","search_queries":[{"type":"search","q":"OpenAI o1 reinforcement learning language models test-time compute 2024 blog"},{"type":"search","q":"DeepSeek RL for LLMs paper 2025 verified rewards"}],"search_display_string":"Searching the web...","searched_display_string":"Searched the web...","reasoning_title":"Searching for sources on RL test-time compute","classifier_response":"default","request_id":"e6556653-9257-4885-ac4b-6d448106e243","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"2da8b0a4-1643-4ca2-ba36-4f0f547aa21a","turn_exchange_id":"0ad37490-ab6b-4240-bf77-c7b311582bdc","timestamp_":"absolute","can_save":true},"recipient":"web.run","channel":null},"parent":"2da8b0a4-1643-4ca2-ba36-4f0f547aa21a","children":["abeeb1f7-2434-4b08-beeb-88e7988e7d19"]},"abeeb1f7-2434-4b08-beeb-88e7988e7d19":{"id":"abeeb1f7-2434-4b08-beeb-88e7988e7d19","message":{"id":"abeeb1f7-2434-4b08-beeb-88e7988e7d19","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1761661126.8778412,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_model_queries":{"type":"search_model_queries","queries":["OpenAI o1 reinforcement learning language models test-time compute 2024 blog","DeepSeek RL for LLMs paper 2025 verified rewards"]},"reasoning_status":"is_reasoning","reasoning_title":"Searching for sources on RL test-time compute","classifier_response":"default","request_id":"e6556653-9257-4885-ac4b-6d448106e243","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"79cd1332-7f1b-4855-9c82-98a6a9c874f4","turn_exchange_id":"0ad37490-ab6b-4240-bf77-c7b311582bdc","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"79cd1332-7f1b-4855-9c82-98a6a9c874f4","children":["1a17aa39-3893-41c4-8fdc-5eb62f975422"]},"1a17aa39-3893-41c4-8fdc-5eb62f975422":{"id":"1a17aa39-3893-41c4-8fdc-5eb62f975422","message":{"id":"1a17aa39-3893-41c4-8fdc-5eb62f975422","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1761661126.8730168,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_result_groups":[{"type":"search_result_group","domain":"openai.com","entries":[{"type":"search_result","url":"https://openai.com/index/learning-to-reason-with-llms/","title":"Learning to reason with LLMs","snippet":"Sep 12, 2024 \u2014 We have found that the performance of o1 consistently improves with more reinforcement learning (train-time compute) and with more time spent ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":0},"pub_date":null,"attribution":"openai.com"}]},{"type":"search_result_group","domain":"arxiv.org","entries":[{"type":"search_result","url":"https://arxiv.org/pdf/2501.12948","title":"DeepSeek-R1: Incentivizing Reasoning Capability in LLMs ...","snippet":"by D Guo \u00b7 2025 \u00b7 Cited by 4636 \u2014 In this paper, we take the first step toward improving language model reasoning capabilities using pure reinforcement learning (RL). Our goal is ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":1},"pub_date":1737596731.0,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2501.12948v1","title":"DeepSeek-R1: Incentivizing Reasoning Capability in LLMs ...","snippet":"In this paper, we take the first step toward improving language model reasoning capabilities using pure reinforcement learning (RL).","ref_id":{"turn_index":4,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"arxiv.org"}]},{"type":"search_result_group","domain":"www.lesswrong.com","entries":[{"type":"search_result","url":"https://www.lesswrong.com/posts/byNYzsfFmb2TpYFPW/o1-a-technical-primer","title":"o1: A Technical Primer","snippet":"Dec 9, 2024 \u2014 In September 2024, OpenAI released o1, its first reasoning model. This model exhibits remarkable test-time scaling laws, which complete a missing piece of the ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"www.lesswrong.com"}]},{"type":"search_result_group","domain":"www.nature.com","entries":[{"type":"search_result","url":"https://www.nature.com/articles/s41586-025-09422-z","title":"DeepSeek-R1 incentivizes reasoning in LLMs through ...","snippet":"by D Guo \u00b7 2025 \u00b7 Cited by 90 \u2014 The proposed RL framework facilitates the emergent development of advanced reasoning patterns, such as self-reflection, verification and dynamic ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"www.nature.com"}]},{"type":"search_result_group","domain":"medium.com","entries":[{"type":"search_result","url":"https://medium.com/wix-engineering/explaining-openais-o1-breakthrough-the-revolution-of-test-time-compute-ecebe8ef9379","title":"Explaining OpenAI's o1 Breakthrough: The Revolution of ...","snippet":"Test Time Compute represents a significant step forward in how AI systems approach complex problems. By combining this with reinforcement ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":4},"pub_date":1740057756.848,"attribution":"medium.com"}]},{"type":"search_result_group","domain":"www.amitysolutions.com","entries":[{"type":"search_result","url":"https://www.amitysolutions.com/blog/openai-o1-llm-reinforcement-learning-training","title":"OpenAI o1: A New LLM Powered by Reinforcement Learning","snippet":"Oct 9, 2024 \u2014 OpenAI o1, the newest large language model, brings a sophisticated approach to handling complex tasks by employing reinforcement learning.","ref_id":{"turn_index":4,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"www.amitysolutions.com"}]},{"type":"search_result_group","domain":"labelstud.io","entries":[{"type":"search_result","url":"https://labelstud.io/blog/reinforcement-learning-from-verifiable-rewards/","title":"Reinforcement Learning from Verifiable Rewards","snippet":"Feb 7, 2025 \u2014 Reinforcement Learning with Verifiable Rewards is among the leading training strategies for injecting learning signals into LLMs, ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"labelstud.io"}]},{"type":"search_result_group","domain":"www.jonvet.com","entries":[{"type":"search_result","url":"https://www.jonvet.com/blog/llm-test-time-compute","title":"Scaling LLM Test Time Compute","snippet":"Oct 20, 2024 \u2014 Test time compute refers to the amount of compute that is used to generate completions from a language model (LLM) at test or inference time.","ref_id":{"turn_index":4,"ref_type":"search","ref_index":8},"pub_date":1729382400.0,"attribution":"www.jonvet.com"}]},{"type":"search_result_group","domain":"www.reddit.com","entries":[{"type":"search_result","url":"https://www.reddit.com/r/singularity/comments/1nk43b1/deepseekr1_incentivizes_reasoning_in_llms_through/","title":"DeepSeek-R1 incentivizes reasoning in LLMs through ...","snippet":"The paper replaces human-labelled reasoning traces with answer-graded RL, so the model only gets a reward when its final answer matches ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":9},"pub_date":1758189465.642,"attribution":"www.reddit.com"}]},{"type":"search_result_group","domain":"www.innovationendeavors.com","entries":[{"type":"search_result","url":"https://www.innovationendeavors.com/insights/mechanisms-for-test-time-compute","title":"Mechanisms for test-time compute","snippet":"In this blog I aim to outline the major ways test-time compute scaling can be achieved, based on both reviewing a lot of the recent literature in this space.","ref_id":{"turn_index":4,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"www.innovationendeavors.com"}]},{"type":"search_result_group","domain":"galileo.ai","entries":[{"type":"search_result","url":"https://galileo.ai/blog/deepseek-reinforcement-learning","title":"How DeepSeek's RL Approach Achieves 79.8% AIME ...","snippet":"Jul 25, 2025 \u2014 DeepSeek proves pure reinforcement learning creates advanced reasoning without supervision. Get the breakthrough framework.","ref_id":{"turn_index":4,"ref_type":"search","ref_index":11},"pub_date":1753401600.0,"attribution":"galileo.ai"}]},{"type":"search_result_group","domain":"encord.com","entries":[{"type":"search_result","url":"https://encord.com/blog/openai-o1/","title":"OpenAI o1: A New Era of AI Reasoning","snippet":"Sep 13, 2024 \u2014 OpenAI o1 series is a new class of large language models (LLMs) designed to enhance reasoning capabilities through a thinking before responding approach.","ref_id":{"turn_index":4,"ref_type":"search","ref_index":12},"pub_date":1726238419.0,"attribution":"encord.com"}]},{"type":"search_result_group","domain":"artgor.medium.com","entries":[{"type":"search_result","url":"https://artgor.medium.com/paper-review-deepseek-r1-incentivizing-reasoning-capability-in-llms-via-reinforcement-learning-edf4343dcf3a","title":"Paper Review: DeepSeek-R1: Incentivizing Reasoning ...","snippet":"This system consists of two reward types: accuracy rewards and format rewards. Accuracy rewards assess correctness using deterministic methods, ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":13},"pub_date":1737954456.441,"attribution":"artgor.medium.com"}]},{"type":"search_result_group","domain":"www.emerge.haus","entries":[{"type":"search_result","url":"https://www.emerge.haus/blog/test-time-compute-generative-ai","title":"Test-Time Compute in Generative AI: An AI Atlas Report","snippet":"Apr 21, 2025 \u2014 We'll cover OpenAI's o1 and its successors, Anthropic's latest Claude model, the open-source DeepSeek R1, and then compare these to baseline ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"www.emerge.haus"}]},{"type":"search_result_group","domain":"www.facebook.com","entries":[{"type":"search_result","url":"https://www.facebook.com/groups/DeepNetGroup/posts/2447889112270623/","title":"Inference-Time Scaling for Generalist Reward Modeling ...","snippet":"Inference-Time Scaling for Generalist Reward Modeling (DeepSeek, April 2025 ... RL and optimizes for human preferences using your LLM as a reward ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"www.facebook.com"}]},{"type":"search_result_group","domain":"www.interconnects.ai","entries":[{"type":"search_result","url":"https://www.interconnects.ai/p/reverse-engineering-openai-o1","title":"Reverse engineering OpenAI's o1 - by Nathan Lambert","snippet":"Sep 16, 2024 \u2014 What productionizing test-time compute shows us about the future of AI. Exploration has landed in language model training.","ref_id":{"turn_index":4,"ref_type":"search","ref_index":16},"pub_date":1726488171.0,"attribution":"www.interconnects.ai"}]},{"type":"search_result_group","domain":"github.com","entries":[{"type":"search_result","url":"https://github.com/TsinghuaC3I/Awesome-RL-for-LRMs","title":"TsinghuaC3I/Awesome-RL-for-LRMs: A Survey of ...","snippet":"... Rewards: Reinforcement Learning Beyond Verifiable Domains, Paper ... 2025-04, -, Improving RL Exploration for LLM Reasoning through Retrospective Replay, Paper, - ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"github.com"}]},{"type":"search_result_group","domain":"simonwillison.net","entries":[{"type":"search_result","url":"https://simonwillison.net/2024/Sep/12/openai-o1/","title":"Notes on OpenAI's new o1 chain-of-thought models","snippet":"Sep 12, 2024 \u2014 We have found that the performance of o1 consistently improves with more reinforcement learning (train-time compute) and with more time spent ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"simonwillison.net"}]},{"type":"search_result_group","domain":"www.ft.com","entries":[{"type":"search_result","url":"https://www.ft.com/content/8253b66e-ade7-4d1f-993b-2d0779c7e7d8","title":"OpenAI slashes AI model safety testing time","snippet":"OpenAI has significantly reduced the time and resources allocated to safety testing for its advanced AI models, raising concerns about potential risks due to rushed releases. Previously, models such as GPT-4 underwent six months of testing, but upcoming models like o3 are now receiving only days of evaluation. This shift is driven by pressure to remain competitive against companies such as Google, Meta, and xAI. Critics, including former staff and AI safety experts, warn that hastier testing increases the chance of missing dangerous capabilities, particularly as models become more powerful. Although OpenAI has committed to testing customized models for risks like bioengineering misuse, it has only conducted such evaluations on older versions, not newer or more capable models. The company cited increased efficiency through automation and maintained that safety testing remains robust. However, safety tests are often conducted on earlier model versions, not the final product. Industry experts argue that this could lead to underestimating real-world risks. With the EU\u2019s AI Act soon set to enforce mandatory safety testing, the current approach may face regulatory challenges. Critics emphasize the need for greater transparency and adherence to safety commitments to safeguard public welfare.","ref_id":{"turn_index":4,"ref_type":"news","ref_index":24},"pub_date":1744344040.432,"attribution":"www.ft.com"}]},{"type":"search_result_group","domain":"www.reuters.com","entries":[{"type":"search_result","url":"https://www.reuters.com/technology/artificial-intelligence/openai-unveils-o3-reasoning-ai-models-test-phase-2024-12-20/","title":"OpenAI unveils 'o3' reasoning AI models in test phase","snippet":"OpenAI announced it is testing new reasoning AI models, o3 and o3 mini, indicating intensified competition with companies like Google. These models are positioned to handle complex problems more effectively and could surpass current models in various tasks, including science, coding, and math. CEO Sam Altman revealed plans to release the o3 mini by the end of January, followed by the full o3 model. The models are currently undergoing internal safety testing, with an application process open for external researchers to test o3 models until January 10. This development follows OpenAI's earlier release of the o1 models in September, which were designed for complex problem-solving. OpenAI, supported by Microsoft, has been a significant force in the AI field since launching ChatGPT in November 2022, recently securing a $6.6 billion funding round. In response, Google's Alphabet introduced the second generation of its AI model, Gemini, indicating their intent to compete in the rapidly evolving AI market.","ref_id":{"turn_index":4,"ref_type":"news","ref_index":25},"pub_date":1734724545.0,"attribution":"www.reuters.com"},{"type":"search_result","url":"https://www.reuters.com/technology/artificial-intelligence/openai-launches-new-series-ai-models-solve-hard-problems-2024-09-12/","title":"OpenAI launches new series of AI models with 'reasoning' abilities","snippet":"OpenAI has introduced the \"Strawberry\" series of AI models, designed to improve reasoning capabilities for solving complex problems. Officially named o1 and o1-mini, these models will be available in the ChatGPT platform and its API. The o1 model has shown significant advancements, such as scoring 83% on the International Mathematics Olympiad qualifying exam, compared to a 13% score by its predecessor, GPT-4o. The models use a \"chain-of-thought\" reasoning technique, allowing them to break down problems into smaller steps independently, improving performance in science, coding, and math. Researchers have automated this technique, enabling the models to think through problems thoroughly before responding.","ref_id":{"turn_index":4,"ref_type":"news","ref_index":26},"pub_date":1726173203.0,"attribution":"www.reuters.com"}]}],"debug_sonic_thread_id":"thread_6900d063fe688333b20181bdb62b001b","reasoning_status":"is_reasoning","reasoning_title":"Searching for sources on RL test-time compute","classifier_response":"default","request_id":"e6556653-9257-4885-ac4b-6d448106e243","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"abeeb1f7-2434-4b08-beeb-88e7988e7d19","turn_exchange_id":"0ad37490-ab6b-4240-bf77-c7b311582bdc","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"abeeb1f7-2434-4b08-beeb-88e7988e7d19","children":["dc9430f8-a180-4b91-a768-6105d2057dd1"]},"dc9430f8-a180-4b91-a768-6105d2057dd1":{"id":"dc9430f8-a180-4b91-a768-6105d2057dd1","message":{"id":"dc9430f8-a180-4b91-a768-6105d2057dd1","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1761661145.552359,"update_time":null,"content":{"content_type":"thoughts","thoughts":[{"summary":"Assessing claims for objectivity","content":"We can support most of the claims, but some, like \"Anthropic hasn't focused on mathematical reasoning,\" are subjective. I'll note it's a perspective. For \"compute supercycle\" and \"TSMC booked out,\" we can skip citing that, as it's general knowledge. The interview\u2019s obviously biased, given the VC host, but it includes nuance, like praising DeepMind and admitting benchmark imperfections. \n\nWe\u2019ll rate groundedness on the facts backed by release dates and SOTA metrics.","chunks":["We can support most of the claims, but some, like \"Anthropic hasn't focused on mathematical reasoning,\" are subjective. I'll note it's a perspective. For \"compute supercycle\" and \"TSMC booked out,\" we can skip citing that, as it's general knowledge. The interview\u2019s obviously biased, given the VC host, but it includes nuance, like praising DeepMind and admitting benchmark imperfections.","We\u2019ll rate groundedness on the facts backed by release dates and SOTA metrics."],"finished":true}],"source_analysis_msg_id":"d08e70f5-ef6c-4a09-bb98-2003e4aed068"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"is_reasoning","content_references":[],"citations":[],"classifier_response":"default","skip_reasoning_title":"Skip","request_id":"e6556653-9257-4885-ac4b-6d448106e243","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"1a17aa39-3893-41c4-8fdc-5eb62f975422","turn_exchange_id":"0ad37490-ab6b-4240-bf77-c7b311582bdc","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"1a17aa39-3893-41c4-8fdc-5eb62f975422","children":["9fb9bdf0-4c61-4401-b7cc-579b249b9d3c"]},"9fb9bdf0-4c61-4401-b7cc-579b249b9d3c":{"id":"9fb9bdf0-4c61-4401-b7cc-579b249b9d3c","message":{"id":"9fb9bdf0-4c61-4401-b7cc-579b249b9d3c","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1761661191.218773,"update_time":1761661191.245033,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"{\"open\": [{\"ref_id\": \"turn0search6\"}], \"response_length\": \"short\"}"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200012]},"is_complete":true,"citations":[],"content_references":[],"reasoning_status":"is_reasoning","reasoning_title":"Evaluating claims, bias, groundedness, and objectivity","classifier_response":"default","request_id":"e6556653-9257-4885-ac4b-6d448106e243","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"dc9430f8-a180-4b91-a768-6105d2057dd1","turn_exchange_id":"0ad37490-ab6b-4240-bf77-c7b311582bdc","timestamp_":"absolute","can_save":true},"recipient":"web.run","channel":null},"parent":"dc9430f8-a180-4b91-a768-6105d2057dd1","children":["4fe35fb7-e968-4842-a42f-b8dcfa3fc02c"]},"4fe35fb7-e968-4842-a42f-b8dcfa3fc02c":{"id":"4fe35fb7-e968-4842-a42f-b8dcfa3fc02c","message":{"id":"4fe35fb7-e968-4842-a42f-b8dcfa3fc02c","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1761661191.4226577,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_result_groups":[],"debug_sonic_thread_id":"thread_6900d063fe688333b20181bdb62b001b","reasoning_status":"is_reasoning","reasoning_title":"Evaluating claims, bias, groundedness, and objectivity","classifier_response":"default","request_id":"e6556653-9257-4885-ac4b-6d448106e243","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"9fb9bdf0-4c61-4401-b7cc-579b249b9d3c","turn_exchange_id":"0ad37490-ab6b-4240-bf77-c7b311582bdc","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"9fb9bdf0-4c61-4401-b7cc-579b249b9d3c","children":["03fed418-24be-49cb-98fd-a8d2cdf159f9"]},"03fed418-24be-49cb-98fd-a8d2cdf159f9":{"id":"03fed418-24be-49cb-98fd-a8d2cdf159f9","message":{"id":"03fed418-24be-49cb-98fd-a8d2cdf159f9","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1761661195.777463,"update_time":1761661195.795595,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"{\"open\": [{\"ref_id\": \"turn0search2\"}], \"response_length\": \"short\"}"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200012]},"is_complete":true,"citations":[],"content_references":[],"reasoning_status":"is_reasoning","reasoning_title":"Browsing OpenAI GDPval page for mention references","classifier_response":"default","request_id":"e6556653-9257-4885-ac4b-6d448106e243","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"4fe35fb7-e968-4842-a42f-b8dcfa3fc02c","turn_exchange_id":"0ad37490-ab6b-4240-bf77-c7b311582bdc","timestamp_":"absolute","can_save":true},"recipient":"web.run","channel":null},"parent":"4fe35fb7-e968-4842-a42f-b8dcfa3fc02c","children":["000b60de-f3d5-4c5e-8a14-76ade1036c36"]},"000b60de-f3d5-4c5e-8a14-76ade1036c36":{"id":"000b60de-f3d5-4c5e-8a14-76ade1036c36","message":{"id":"000b60de-f3d5-4c5e-8a14-76ade1036c36","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1761661195.9436016,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_result_groups":[{"type":"search_result_group","domain":"openai.com","entries":[{"type":"search_result","url":"https://openai.com/index/gdpval/","title":"Measuring the performance of our models on real-world tasks  | OpenAI","snippet":"Total lines: 393\n","ref_id":{"turn_index":6,"ref_type":"view","ref_index":0},"pub_date":null,"attribution":"openai.com"}]}],"debug_sonic_thread_id":"thread_6900d063fe688333b20181bdb62b001b","reasoning_status":"is_reasoning","reasoning_title":"Browsing OpenAI GDPval page for mention references","classifier_response":"default","request_id":"e6556653-9257-4885-ac4b-6d448106e243","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"03fed418-24be-49cb-98fd-a8d2cdf159f9","turn_exchange_id":"0ad37490-ab6b-4240-bf77-c7b311582bdc","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"03fed418-24be-49cb-98fd-a8d2cdf159f9","children":["5c744bec-78f4-4762-bc72-815d2c25ab67"]},"5c744bec-78f4-4762-bc72-815d2c25ab67":{"id":"5c744bec-78f4-4762-bc72-815d2c25ab67","message":{"id":"5c744bec-78f4-4762-bc72-815d2c25ab67","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1761661213.918966,"update_time":null,"content":{"content_type":"thoughts","thoughts":[{"summary":"Clarifying Opus 4.1 performance claims","content":"The claim that \"Claude Opus 4.1 produced outputs as good as or better than humans in nearly half the tasks\" is supportive of Opus 4.1\u2019s strength. The statement that OpenAI's GDPval shows Opus 4.1 leading aligns with some reports, but it doesn\u2019t necessarily specify if it beats GPT-5. We\u2019ll be cautious with comparisons unless we see a direct link or chart from OpenAI.","chunks":["The claim that \"Claude Opus 4.1 produced outputs as good as or better than humans in nearly half the tasks\" is supportive of Opus 4.1\u2019s strength. The statement that OpenAI's GDPval shows Opus 4.1 leading aligns with some reports, but it doesn\u2019t necessarily specify if it beats GPT-5. We\u2019ll be cautious with comparisons unless we see a direct link or chart from OpenAI."],"finished":true}],"source_analysis_msg_id":"b5b3fbe7-482d-4bb7-beaa-d695341971ab"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"is_reasoning","content_references":[],"citations":[],"classifier_response":"default","skip_reasoning_title":"Skip","request_id":"e6556653-9257-4885-ac4b-6d448106e243","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"000b60de-f3d5-4c5e-8a14-76ade1036c36","turn_exchange_id":"0ad37490-ab6b-4240-bf77-c7b311582bdc","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"000b60de-f3d5-4c5e-8a14-76ade1036c36","children":["f7f2320f-add2-4ce5-83b8-022c34e3876e"]},"f7f2320f-add2-4ce5-83b8-022c34e3876e":{"id":"f7f2320f-add2-4ce5-83b8-022c34e3876e","message":{"id":"f7f2320f-add2-4ce5-83b8-022c34e3876e","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1761661214.572512,"update_time":1761661214.594154,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"{\"click\": [{\"ref_id\": \"turn6view0\", \"id\": 43}], \"response_length\": \"short\"}"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200012]},"is_complete":true,"citations":[],"content_references":[],"reasoning_status":"is_reasoning","reasoning_title":"Verifying Claude Opus 4.1 performance and rankings","classifier_response":"default","request_id":"e6556653-9257-4885-ac4b-6d448106e243","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"5c744bec-78f4-4762-bc72-815d2c25ab67","turn_exchange_id":"0ad37490-ab6b-4240-bf77-c7b311582bdc","timestamp_":"absolute","can_save":true},"recipient":"web.run","channel":null},"parent":"5c744bec-78f4-4762-bc72-815d2c25ab67","children":["f554b66e-4155-4ba7-9e57-8496746301e6"]},"f554b66e-4155-4ba7-9e57-8496746301e6":{"id":"f554b66e-4155-4ba7-9e57-8496746301e6","message":{"id":"f554b66e-4155-4ba7-9e57-8496746301e6","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1761661214.738506,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_result_groups":[{"type":"search_result_group","domain":"evals.openai.com","entries":[{"type":"search_result","url":"https://evals.openai.com/","title":"OpenAI Evals","snippet":"Total lines: 0\n","ref_id":{"turn_index":7,"ref_type":"view","ref_index":0},"pub_date":null,"attribution":"evals.openai.com"}]}],"debug_sonic_thread_id":"thread_6900d063fe688333b20181bdb62b001b","reasoning_status":"is_reasoning","reasoning_title":"Verifying Claude Opus 4.1 performance and rankings","classifier_response":"default","request_id":"e6556653-9257-4885-ac4b-6d448106e243","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"f7f2320f-add2-4ce5-83b8-022c34e3876e","turn_exchange_id":"0ad37490-ab6b-4240-bf77-c7b311582bdc","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"f7f2320f-add2-4ce5-83b8-022c34e3876e","children":["547288c1-063b-4470-b2ed-dbd2189dfc41"]},"547288c1-063b-4470-b2ed-dbd2189dfc41":{"id":"547288c1-063b-4470-b2ed-dbd2189dfc41","message":{"id":"547288c1-063b-4470-b2ed-dbd2189dfc41","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1761661233.926627,"update_time":null,"content":{"content_type":"thoughts","thoughts":[{"summary":"Drafting synopsis and analysis","content":"I\u2019ll summarize the key points, like the SWE-bench score, 30-hour run, METR doubling, GDPval early results, and Devin rebuild. I\u2019ll also include citations for these. For context, I\u2019ll add a short rating scale and grade, addressing topics like RL/test-time compute claims. For the \u201cmath reasoning\u201d argument, I might reference DeepMind\u2019s science work but avoid going too deep. I\u2019ll also address the \"plateau\" narrative by highlighting progress with metrics that show learning improvements, citing updates like the October 2024 one. I\u2019ll provide numbers and timelines for clarity.","chunks":["I\u2019ll summarize the key points, like the SWE-bench score, 30-hour run, METR doubling, GDPval early results, and Devin rebuild.","I\u2019ll also include citations for these.","For context, I\u2019ll add a short rating scale and grade, addressing topics like RL/test-time compute claims.","For the \u201cmath reasoning\u201d argument, I might reference DeepMind\u2019s science work but avoid going too deep.","I\u2019ll also address the \"plateau\" narrative by highlighting progress with metrics that show learning improvements, citing updates like the October 2024 one. I\u2019ll provide numbers and timelines for clarity."],"finished":true},{"summary":"Assessing bias and enhancing critique","content":"I\u2019ll point out the potential bias, given both participants are from the VC and Anthropic backgrounds, which could lead to promotional commentary. The \"AGI in 2-3 years\" claim should be treated with caution, and we should focus on generalizability and reproducibility. I'll mention benchmark saturation and real-world adoption, like the 100k users for Claude Code, citing it carefully. The tone will stay objective, critical, and forward-looking, avoiding excessive lists, and I'll keep the information concise but comprehensive. Citations will follow inline at the end of each relevant point.","chunks":["I\u2019ll point out the potential bias, given both participants are from the VC and Anthropic backgrounds, which could lead to promotional commentary.","The \"AGI in 2-3 years\" claim should be treated with caution, and we should focus on generalizability and reproducibility. I'll mention benchmark saturation and real-world adoption, like the 100k users for Claude Code, citing it carefully. The tone will stay objective, critical, and forward-looking, avoiding excessive lists, and I'll keep the information concise but comprehensive. Citations will follow inline at the end of each relevant point."],"finished":true},{"summary":"Preparing content","content":"I'll summarize the guest's points: the focus is on compute supercycles, RL/test-time compute, model tiers, coding, and time horizons increasing. The claim about the 30-hour agent, SWE-bench SOTA, GDPval breadth, and robotics prospects needs to be fact-checked, including dates, SOTA metrics, and the 30-hour run. The biases are moderate, leaning pro-Anthropic with disclaimers. Grounded facts (benchmarks, 30-hour run, Devin rebuild) are well-supported, but the AGI and robotics comments are speculative.","chunks":["I'll summarize the guest's points: the focus is on compute supercycles, RL/test-time compute, model tiers, coding, and time horizons increasing.","The claim about the 30-hour agent, SWE-bench SOTA, GDPval breadth, and robotics prospects needs to be fact-checked, including dates, SOTA metrics, and the 30-hour run.","The biases are moderate, leaning pro-Anthropic with disclaimers.","Grounded facts (benchmarks, 30-hour run, Devin rebuild) are well-supported, but the AGI and robotics comments are speculative."],"finished":true}],"source_analysis_msg_id":"625fb418-932f-4274-beb2-c51604088b49"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"is_reasoning","content_references":[],"citations":[],"classifier_response":"default","skip_reasoning_title":"Skip","request_id":"e6556653-9257-4885-ac4b-6d448106e243","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"f554b66e-4155-4ba7-9e57-8496746301e6","turn_exchange_id":"0ad37490-ab6b-4240-bf77-c7b311582bdc","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"f554b66e-4155-4ba7-9e57-8496746301e6","children":["628fd37a-be2b-402f-9b5a-f5d93547bf24"]},"628fd37a-be2b-402f-9b5a-f5d93547bf24":{"id":"628fd37a-be2b-402f-9b5a-f5d93547bf24","message":{"id":"628fd37a-be2b-402f-9b5a-f5d93547bf24","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1761661282.81495,"update_time":null,"content":{"content_type":"reasoning_recap","content":"Thought for 4m 51s"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"reasoning_ended","finished_duration_sec":291,"request_id":"e6556653-9257-4885-ac4b-6d448106e243","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"547288c1-063b-4470-b2ed-dbd2189dfc41","turn_exchange_id":"0ad37490-ab6b-4240-bf77-c7b311582bdc","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"547288c1-063b-4470-b2ed-dbd2189dfc41","children":["70697489-1272-4ddb-a73f-1953e26fea86"]},"70697489-1272-4ddb-a73f-1953e26fea86":{"id":"70697489-1272-4ddb-a73f-1953e26fea86","message":{"id":"70697489-1272-4ddb-a73f-1953e26fea86","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1761661282.671994,"update_time":1761661387.119269,"content":{"content_type":"text","parts":["Here\u2019s a crisp read of what\u2019s said, what\u2019s supported, and what\u2019s spin.\n\n# Synopsis (what he argues)\n- **Progress & cadence.** We\u2019re in a \u201ccompute super-cycle\u201d; RL + test-time-compute add a second scaling axis, so releases ship faster and keep improving. \ue200cite\ue202turn4search0\ue201  \n- **Tiering & leapfrogging.** Anthropic\u2019s mid-tier **Sonnet 4.5** now outperforms prior flagships (Opus 4.1) on real-world coding, due both to RL and iteration speed. \ue200cite\ue202turn1search5\ue202turn3search1\ue201  \n- **Agentic coding.** Sonnet 4.5 can run for **long horizons** (he quotes up to ~30 hours) to build working software end-to-end; longer run-time + memory + self-correction are the key enablers. \ue200cite\ue202turn0search4\ue201  \n- **Benchmarks.** Claims state-of-the-art on **SWE-bench Verified**; cites a field-wide jump from ~<20% last year to the 70s now. \ue200cite\ue202turn1search9\ue202turn3search1\ue202turn2search1\ue201  \n- **Breadth beyond coding.** Highlights **OpenAI\u2019s GDPval** as a cross-economy eval where **Claude Opus 4.1** scored \u201cas good as or better than humans\u201d on almost half the tasks. \ue200cite\ue202turn6view0\ue201  \n- **Time-horizon trend.** References **METR** findings that agents\u2019 task time horizons are growing roughly exponentially (doubling on the order of months). \ue200cite\ue202turn0search1\ue202turn0search5\ue201  \n- **Positioning.** Anthropic focuses on **coding & computer use** for near-term economic impact; leaves long-horizon science emphasis more to DeepMind. (Framing/opinion; not a checkable claim.)\n\n# Fact check (key claims vs public evidence)\n- **SWE-bench leadership:** Anthropic\u2019s launch post reports **77.2%** on SWE-bench Verified (w/ simple scaffold), and multiple third-party posts/trackers show Sonnet 4.5 at or near the top depending on harness (69\u201377% ranges show up across leaderboards). Conclusion: **directionally true**, exact % varies by setup. \ue200cite\ue202turn2search1\ue202turn2search5\ue202turn2search7\ue202turn2search3\ue201  \n- **30-hour autonomy:** Anthropic explicitly states **\u201cmaintaining focus for more than 30 hours\u201d** on complex multi-step tasks. That\u2019s a vendor demo, not an independent trial. **Claim is sourced, not independently verified.** \ue200cite\ue202turn0search4\ue201  \n- **Opus 4.1 on GDPval:** OpenAI\u2019s GDPval page notes **Claude Opus 4.1** was rated as **\u201cas good as or better than humans\u201d on just under half** of tasks; media coverage claims it led overall. Conclusion: **strong performance documented; \u201cbest overall\u201d depends on the specific reporting/visuals.** \ue200cite\ue202turn6view0\ue202turn0news49\ue202turn0search10\ue201  \n- **RL + test-time compute as the new scaling axis:** This is **well-supported** by OpenAI\u2019s o1 documentation and subsequent RL-for-reasoning literature (e.g., DeepSeek-R1). \ue200cite\ue202turn4search0\ue202turn4search1\ue202turn4search3\ue201  \n- **Market validation:** Cognition\u2019s **Devin** publicly says they **rebuilt** around Sonnet 4.5 and saw double-digit eval gains\u2014evidence of real-world utility beyond benchmarks. \ue200cite\ue202turn0search3\ue202turn0search7\ue201\n\n# Analytical take\n**Objectivity & bias.**  \nThis is a **launch-week conversation** with a VC host and an Anthropic researcher; it\u2019s inevitably promotional. To his credit, Douglas (i) calls benchmarks imperfect/saturating, (ii) praises competitors (DeepMind on science), and (iii) frames progress as many small improvements rather than a secret breakthrough\u2014those are **credibility-enhancing** notes. Still, phrases like \u201cbet on the exponential\u201d and \u201cAGI in 2\u20133 years\u201d are **forecast claims**, not facts. **Overall tone: bullish, Anthropic-centric, but not hostile to rivals.**\n\n**Grounding in results.**  \n- **Strongly grounded:** SWE-bench gains; long-horizon behavior in Anthropic\u2019s demo; RL + test-time compute trend; early GDPval results; Devin\u2019s architectural switch. **These are documented.** \ue200cite\ue202turn2search1\ue202turn0search4\ue202turn4search0\ue202turn6view0\ue202turn0search3\ue201  \n- **Weaker/aspirational:** \u201canything measurable is improving rapidly,\u201d \u201cnear-AGI in 2\u20133 years,\u201d \u201ccompute super-cycle\u201d generalities. These are **extrapolations**; reasonable but contestable. METR shows steep **time-horizon** trends, yet also documents big **domain gaps** (GUI/robotics lag). \ue200cite\ue202turn0search5\ue201\n\n**Nuances & caveats (that matter if you\u2019re betting on this):**\n- **Benchmark sensitivity.** SWE-bench scores vary by harness (tools, step caps, parallelism); multiple \u201cleaderboards\u201d exist. Treat point estimates \u00b1 a few points. \ue200cite\ue202turn2search1\ue202turn2search7\ue201  \n- **Demo \u2260 production.** A 30-hour run in a controlled harness doesn\u2019t guarantee reliability on messy, stateful enterprise repos (auth, flaky tests, hidden services). (No public, independent 30-hour bakeoff yet.) \ue200cite\ue202turn0search4\ue201  \n- **Breadth vs depth.** GDPval is a useful reality check, but v0 is one-shot and graded artifacts; it under-represents interactive workflows and organizational context. **Good, not dispositive.** \ue200cite\ue202turn6view0\ue201  \n- **Time-horizon trend \u2260 universal.** METR finds faster doubling in coding/math than in GUI/embodied settings; robotics/manipulation still lag in data & feedback. \ue200cite\ue202turn0search5\ue201\n\n# Ratings (my scores)\n- **Objectivity:** **6/10.** Clear effort to avoid smack-talk and to admit limitations, but still a launch-week narrative led by the vendor.  \n- **Bias:** **Pro-Anthropic marketing bias present.** Not egregious; acknowledges competitors and caveats. **(Bias level: Moderate.)**  \n- **Grounded in facts & results:**  \n  - **Near-term technical claims:** **8/10** (benchmarks, Devin switch, RL/test-time compute are well-sourced). \ue200cite\ue202turn2search1\ue202turn0search3\ue202turn4search0\ue201  \n  - **Medium-term forecasts (2\u20133 yr AGI):** **4/10** (plausible trajectory indicators, but speculative). \ue200cite\ue202turn0search1\ue201  \n- **Overall credibility:** **7/10.** Strong on current capabilities; forward-looking parts are confident extrapolations.\n\n# What to watch next (to separate hype from signal)\n1) **Independent 24\u201348h agent trials** on open, messy repos (same harness across models). 2) **GDPval updates** with interactive, multi-turn workflows (not one-shot). 3) **Cross-lab time-horizon evals** run by METR or similar with preregistered protocols. 4) **Robotics transfer**: consistent real-world manipulation suites with LLM-driven planners (today\u2019s gap is still large). \ue200cite\ue202turn6view0\ue202turn0search5\ue201\n\nIf you want, I can turn this into a side-by-side \u201cclaim vs evidence vs risk\u201d table for your students or your own tracking."]},"status":"finished_successfully","end_turn":true,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200002]},"is_complete":true,"content_references":[{"matched_text":"\ue200cite\ue202turn4search0\ue201","start_idx":254,"end_idx":273,"safe_urls":["https://openai.com/index/learning-to-reason-with-llms/?utm_source=chatgpt.com"],"refs":[],"alt":"([OpenAI](https://openai.com/index/learning-to-reason-with-llms/?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Learning to reason with LLMs","url":"https://openai.com/index/learning-to-reason-with-llms/?utm_source=chatgpt.com","pub_date":null,"snippet":"Sep 12, 2024 \u2014 We have found that the performance of o1 consistently improves with more reinforcement learning (train-time compute) and with more time spent ...","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":4,"ref_type":"search","ref_index":0}],"hue":null,"attributions":null,"attribution":"OpenAI"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn1search5\ue202turn3search1\ue201","start_idx":443,"end_idx":475,"safe_urls":["https://www.anthropic.com/claude/sonnet?utm_source=chatgpt.com","https://www.anthropic.com/news/claude-opus-4-1?utm_source=chatgpt.com"],"refs":[],"alt":"([Anthropic](https://www.anthropic.com/claude/sonnet?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Claude Sonnet 4.5","url":"https://www.anthropic.com/claude/sonnet?utm_source=chatgpt.com","pub_date":null,"snippet":"29 Sept 2025 \u2014 Sonnet 4.5 is the best model in the world for agents, coding, and computer use. It's also our most accurate and detailed model for long-running ...","attribution_segments":null,"supporting_websites":[{"title":"Claude Opus 4.1","url":"https://www.anthropic.com/news/claude-opus-4-1?utm_source=chatgpt.com","pub_date":null,"snippet":"Aug 5, 2025 \u2014 Opus 4.1 advances our state-of-the-art coding performance to 74.5% on SWE-bench Verified. It also improves Claude's in-depth research and data ...","attribution":"Anthropic"}],"refs":[{"turn_index":1,"ref_type":"search","ref_index":5},{"turn_index":3,"ref_type":"search","ref_index":1}],"hue":null,"attributions":null,"attribution":"Anthropic"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search4\ue201","start_idx":672,"end_idx":691,"safe_urls":["https://www.anthropic.com/news/claude-sonnet-4-5?utm_source=chatgpt.com"],"refs":[],"alt":"([Anthropic](https://www.anthropic.com/news/claude-sonnet-4-5?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Introducing Claude Sonnet 4.5","url":"https://www.anthropic.com/news/claude-sonnet-4-5?utm_source=chatgpt.com","pub_date":null,"snippet":"Sep 29, 2025 \u2014 Claude Sonnet 4.5 is state-of-the-art on the SWE-bench Verified evaluation, which measures real-world software coding abilities. Practically ...See more","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":4}],"hue":null,"attributions":null,"attribution":"Anthropic"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn1search9\ue202turn3search1\ue202turn2search1\ue201","start_idx":824,"end_idx":869,"safe_urls":["https://www.anthropic.com/news/3-5-models-and-computer-use?utm_source=chatgpt.com","https://www.anthropic.com/news/claude-opus-4-1?utm_source=chatgpt.com","https://www.anthropic.com/news/claude-sonnet-4-5?utm_source=chatgpt.com"],"refs":[],"alt":"([Anthropic](https://www.anthropic.com/news/3-5-models-and-computer-use?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Introducing computer use, a new Claude 3.5 Sonnet, and ...","url":"https://www.anthropic.com/news/3-5-models-and-computer-use?utm_source=chatgpt.com","pub_date":null,"snippet":"22 Oct 2024 \u2014 The updated Claude 3.5 Sonnet shows wide-ranging improvements on industry benchmarks, with particularly strong gains in agentic coding and tool ...","attribution_segments":null,"supporting_websites":[{"title":"Claude Opus 4.1","url":"https://www.anthropic.com/news/claude-opus-4-1?utm_source=chatgpt.com","pub_date":null,"snippet":"Aug 5, 2025 \u2014 Opus 4.1 advances our state-of-the-art coding performance to 74.5% on SWE-bench Verified. It also improves Claude's in-depth research and data ...","attribution":"Anthropic"},{"title":"Introducing Claude Sonnet 4.5","url":"https://www.anthropic.com/news/claude-sonnet-4-5?utm_source=chatgpt.com","pub_date":null,"snippet":"Sep 29, 2025 \u2014 SWE-bench Verified: All Claude results were reported using a simple scaffold with two tools\u2014bash and file editing via string replacements.","attribution":"Anthropic"}],"refs":[{"turn_index":1,"ref_type":"search","ref_index":9},{"turn_index":3,"ref_type":"search","ref_index":1},{"turn_index":2,"ref_type":"search","ref_index":1}],"hue":null,"attributions":null,"attribution":"Anthropic"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn6view0\ue201","start_idx":1050,"end_idx":1067,"safe_urls":["https://openai.com/index/gdpval/"],"refs":[],"alt":"([OpenAI](https://openai.com/index/gdpval/))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Measuring the performance of our models on real-world tasks  | OpenAI","url":"https://openai.com/index/gdpval/","pub_date":null,"snippet":null,"attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":6,"ref_type":"view","ref_index":0}],"hue":null,"attributions":null,"attribution":"OpenAI"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search1\ue202turn0search5\ue201","start_idx":1226,"end_idx":1258,"safe_urls":["https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/?utm_source=chatgpt.com","https://metr.org/blog/2025-07-14-how-does-time-horizon-vary-across-domains/?utm_source=chatgpt.com"],"refs":[],"alt":"([Metr](https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Measuring AI Ability to Complete Long Tasks","url":"https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/?utm_source=chatgpt.com","pub_date":1742367600.0,"snippet":"Mar 19, 2025 \u2014 We show that this metric has been consistently exponentially increasing over the past 6 years, with a doubling time of around 7 months.","attribution_segments":null,"supporting_websites":[{"title":"How Does Time Horizon Vary Across Domains?","url":"https://metr.org/blog/2025-07-14-how-does-time-horizon-vary-across-domains/?utm_source=chatgpt.com","pub_date":null,"snippet":"Jul 14, 2025 \u2014 Coding, math contest, and QA benchmarks all show 30-200 minute+ horizons doubling every ~2-6 months, with METR-HRS in the middle of the pack.","attribution":"Metr"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":1},{"turn_index":0,"ref_type":"search","ref_index":5}],"hue":null,"attributions":null,"attribution":"Metr"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn2search1\ue202turn2search5\ue202turn2search7\ue202turn2search3\ue201","start_idx":1817,"end_idx":1875,"safe_urls":["https://caylent.com/blog/claude-sonnet-4-5-highest-scoring-claude-model-yet-on-swe-bench?utm_source=chatgpt.com","https://www.anthropic.com/news/claude-sonnet-4-5?utm_source=chatgpt.com","https://www.leanware.co/insights/claude-sonnet-4-5-overview?utm_source=chatgpt.com","https://www.vals.ai/benchmarks/swebench?utm_source=chatgpt.com"],"refs":[],"alt":"([Anthropic](https://www.anthropic.com/news/claude-sonnet-4-5?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Introducing Claude Sonnet 4.5","url":"https://www.anthropic.com/news/claude-sonnet-4-5?utm_source=chatgpt.com","pub_date":null,"snippet":"Sep 29, 2025 \u2014 SWE-bench Verified: All Claude results were reported using a simple scaffold with two tools\u2014bash and file editing via string replacements.","attribution_segments":null,"supporting_websites":[{"title":"Highest-Scoring Claude Model Yet on SWE-bench","url":"https://caylent.com/blog/claude-sonnet-4-5-highest-scoring-claude-model-yet-on-swe-bench?utm_source=chatgpt.com","pub_date":null,"snippet":"Oct 10, 2025 \u2014 Anthropic has just released Claude Sonnet 4.5, setting a new record of benchmark scores: 77.2% on SWE-bench Verified and 61.4% on OSWorld for ...","attribution":"Caylent"},{"title":"SWE-bench","url":"https://www.vals.ai/benchmarks/swebench?utm_source=chatgpt.com","pub_date":null,"snippet":"Oct 17, 2025 \u2014 Claude Sonnet 4.5 (Thinking) leads with a performance of 69.8%, scoring the highest across all models, though it comes with significantly higher ...","attribution":"Vals AI"},{"title":"Claude Sonnet 4.5: Features, Benchmarks & Pricing (2025)","url":"https://www.leanware.co/insights/claude-sonnet-4-5-overview?utm_source=chatgpt.com","pub_date":null,"snippet":"Sep 30, 2025 \u2014 TLDR: Claude Sonnet 4.5 scores 77.2% on SWE-bench Verified (82.0% with parallel compute), 50.0% on Terminal-Bench, and 61.4% on OSWorld.","attribution":"Leanware"}],"refs":[{"turn_index":2,"ref_type":"search","ref_index":1},{"turn_index":2,"ref_type":"search","ref_index":5},{"turn_index":2,"ref_type":"search","ref_index":7},{"turn_index":2,"ref_type":"search","ref_index":3}],"hue":null,"attributions":null,"attribution":"Anthropic"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search4\ue201","start_idx":2104,"end_idx":2123,"safe_urls":["https://www.anthropic.com/news/claude-sonnet-4-5?utm_source=chatgpt.com"],"refs":[],"alt":"([Anthropic](https://www.anthropic.com/news/claude-sonnet-4-5?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Introducing Claude Sonnet 4.5","url":"https://www.anthropic.com/news/claude-sonnet-4-5?utm_source=chatgpt.com","pub_date":null,"snippet":"Sep 29, 2025 \u2014 Claude Sonnet 4.5 is state-of-the-art on the SWE-bench Verified evaluation, which measures real-world software coding abilities. Practically ...See more","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":4}],"hue":null,"attributions":null,"attribution":"Anthropic"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn6view0\ue202turn0news49\ue202turn0search10\ue201","start_idx":2423,"end_idx":2466,"safe_urls":["https://evals.openai.com/?utm_source=chatgpt.com","https://openai.com/index/gdpval/","https://www.techradar.com/ai-platforms-assistants/claude/claude-just-beat-gpt-5-gemini-and-grok-in-real-world-job-tasks-according-to-openais-own-study?utm_source=chatgpt.com"],"refs":[],"alt":"([OpenAI](https://openai.com/index/gdpval/))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Measuring the performance of our models on real-world tasks  | OpenAI","url":"https://openai.com/index/gdpval/","pub_date":null,"snippet":null,"attribution_segments":null,"supporting_websites":[{"title":"Claude just beat GPT-5, Gemini, and Grok in real-world job tasks, according to OpenAI's own study","url":"https://www.techradar.com/ai-platforms-assistants/claude/claude-just-beat-gpt-5-gemini-and-grok-in-real-world-job-tasks-according-to-openais-own-study?utm_source=chatgpt.com","pub_date":null,"snippet":"In a groundbreaking study conducted by OpenAI, a new evaluation method called GDPval was introduced to assess AI models using real-world work tasks rather than traditional benchmarks. GDPval tested AI performance across 44 occupations, such as software development, law, nursing, and engineering, comparing AI outputs to those of human professionals. The surprising outcome of the study revealed that Anthropic\u2019s Claude Opus 4.1 outperformed all other models, including OpenAI\u2019s own ChatGPT-5, as well as Gemini and Grok.\n\nClaude Opus 4.1 achieved the highest win rate at 47.6%, demonstrating superior performance in eight out of nine industry sectors, including healthcare, government, and social assistance. In contrast, ChatGPT-5 scored 38.8%, and ChatGPT-4o lagged behind at just 12.4%. Task examples used in the evaluation included responding to customer service emails, optimizing vendor fair layouts, and auditing purchase orders.\n\nOpenAI\u2019s transparency in publishing a study where a competitor excelled aligns with its mission to fairly communicate AI progress and encourage evidence-based discussions. The study, conducted with Harvard economist David Deming and published by the National Bureau of Economic Research (NBER), may prompt future AI development to focus more on real-world utility.","attribution":"TechRadar"},{"title":"OpenAI Evals","url":"https://evals.openai.com/?utm_source=chatgpt.com","pub_date":null,"snippet":"Sep 25, 2025 \u2014 We introduce GDPval, an evaluation assessing AI model capabilities on real-world economically valuable tasks. GDPval covers the majority of U.S. ...","attribution":"evals.openai.com"}],"refs":[{"turn_index":6,"ref_type":"view","ref_index":0},{"turn_index":0,"ref_type":"news","ref_index":49},{"turn_index":0,"ref_type":"search","ref_index":10}],"hue":null,"attributions":null,"attribution":"OpenAI"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn4search0\ue202turn4search1\ue202turn4search3\ue201","start_idx":2643,"end_idx":2688,"safe_urls":["https://arxiv.org/pdf/2501.12948?utm_source=chatgpt.com","https://openai.com/index/learning-to-reason-with-llms/?utm_source=chatgpt.com","https://www.nature.com/articles/s41586-025-09422-z?utm_source=chatgpt.com"],"refs":[],"alt":"([OpenAI](https://openai.com/index/learning-to-reason-with-llms/?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Learning to reason with LLMs","url":"https://openai.com/index/learning-to-reason-with-llms/?utm_source=chatgpt.com","pub_date":null,"snippet":"Sep 12, 2024 \u2014 We have found that the performance of o1 consistently improves with more reinforcement learning (train-time compute) and with more time spent ...","attribution_segments":null,"supporting_websites":[{"title":"DeepSeek-R1: Incentivizing Reasoning Capability in LLMs ...","url":"https://arxiv.org/pdf/2501.12948?utm_source=chatgpt.com","pub_date":null,"snippet":"by D Guo \u00b7 2025 \u00b7 Cited by 4636 \u2014 In this paper, we take the first step toward improving language model reasoning capabilities using pure reinforcement learning (RL). Our goal is ...","attribution":"arXiv"},{"title":"DeepSeek-R1 incentivizes reasoning in LLMs through ...","url":"https://www.nature.com/articles/s41586-025-09422-z?utm_source=chatgpt.com","pub_date":null,"snippet":"by D Guo \u00b7 2025 \u00b7 Cited by 90 \u2014 The proposed RL framework facilitates the emergent development of advanced reasoning patterns, such as self-reflection, verification and dynamic ...","attribution":"Nature"}],"refs":[{"turn_index":4,"ref_type":"search","ref_index":0},{"turn_index":4,"ref_type":"search","ref_index":1},{"turn_index":4,"ref_type":"search","ref_index":3}],"hue":null,"attributions":null,"attribution":"OpenAI"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search3\ue202turn0search7\ue201","start_idx":2869,"end_idx":2901,"safe_urls":["https://cognition.ai/blog/devin-agent-preview-sonnet-4-5?utm_source=chatgpt.com","https://cognition.ai/blog/devin-sonnet-4-5-lessons-and-challenges?utm_source=chatgpt.com"],"refs":[],"alt":"([Cognition](https://cognition.ai/blog/devin-sonnet-4-5-lessons-and-challenges?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Rebuilding Devin for Claude Sonnet 4.5: Lessons and ...","url":"https://cognition.ai/blog/devin-sonnet-4-5-lessons-and-challenges?utm_source=chatgpt.com","pub_date":null,"snippet":"Sep 29, 2025 \u2014 In this article: We rebuilt Devin for Claude Sonnet 4.5. The new version is 2x faster, 12% better on our Junior Developer Evals, and it's ...","attribution_segments":null,"supporting_websites":[{"title":"Announcing Devin Agent Preview with Sonnet 4.5","url":"https://cognition.ai/blog/devin-agent-preview-sonnet-4-5?utm_source=chatgpt.com","pub_date":null,"snippet":"Sep 29, 2025 \u2014 For Devin, Claude Sonnet 4.5 increased planning performance by 18% and end-to-end eval scores by 12% - the biggest jump we've seen since the ...","attribution":"Cognition"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":3},{"turn_index":0,"ref_type":"search","ref_index":7}],"hue":null,"attributions":null,"attribution":"Cognition"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn2search1\ue202turn0search4\ue202turn4search0\ue202turn6view0\ue202turn0search3\ue201","start_idx":3702,"end_idx":3771,"safe_urls":["https://cognition.ai/blog/devin-sonnet-4-5-lessons-and-challenges?utm_source=chatgpt.com","https://openai.com/index/gdpval/","https://openai.com/index/learning-to-reason-with-llms/?utm_source=chatgpt.com","https://www.anthropic.com/news/claude-sonnet-4-5?utm_source=chatgpt.com"],"refs":[],"alt":"([Anthropic](https://www.anthropic.com/news/claude-sonnet-4-5?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Introducing Claude Sonnet 4.5","url":"https://www.anthropic.com/news/claude-sonnet-4-5?utm_source=chatgpt.com","pub_date":null,"snippet":"Sep 29, 2025 \u2014 SWE-bench Verified: All Claude results were reported using a simple scaffold with two tools\u2014bash and file editing via string replacements.","attribution_segments":null,"supporting_websites":[{"title":"Introducing Claude Sonnet 4.5","url":"https://www.anthropic.com/news/claude-sonnet-4-5?utm_source=chatgpt.com","pub_date":null,"snippet":"Sep 29, 2025 \u2014 Claude Sonnet 4.5 is state-of-the-art on the SWE-bench Verified evaluation, which measures real-world software coding abilities. Practically ...See more","attribution":"Anthropic"},{"title":"Learning to reason with LLMs","url":"https://openai.com/index/learning-to-reason-with-llms/?utm_source=chatgpt.com","pub_date":null,"snippet":"Sep 12, 2024 \u2014 We have found that the performance of o1 consistently improves with more reinforcement learning (train-time compute) and with more time spent ...","attribution":"OpenAI"},{"title":"Measuring the performance of our models on real-world tasks  | OpenAI","url":"https://openai.com/index/gdpval/","pub_date":null,"snippet":null,"attribution":"OpenAI"},{"title":"Rebuilding Devin for Claude Sonnet 4.5: Lessons and ...","url":"https://cognition.ai/blog/devin-sonnet-4-5-lessons-and-challenges?utm_source=chatgpt.com","pub_date":null,"snippet":"Sep 29, 2025 \u2014 In this article: We rebuilt Devin for Claude Sonnet 4.5. The new version is 2x faster, 12% better on our Junior Developer Evals, and it's ...","attribution":"Cognition"}],"refs":[{"turn_index":2,"ref_type":"search","ref_index":1},{"turn_index":0,"ref_type":"search","ref_index":4},{"turn_index":4,"ref_type":"search","ref_index":0},{"turn_index":6,"ref_type":"view","ref_index":0},{"turn_index":0,"ref_type":"search","ref_index":3}],"hue":null,"attributions":null,"attribution":"Anthropic"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search5\ue201","start_idx":4065,"end_idx":4084,"safe_urls":["https://metr.org/blog/2025-07-14-how-does-time-horizon-vary-across-domains/?utm_source=chatgpt.com"],"refs":[],"alt":"([Metr](https://metr.org/blog/2025-07-14-how-does-time-horizon-vary-across-domains/?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"How Does Time Horizon Vary Across Domains?","url":"https://metr.org/blog/2025-07-14-how-does-time-horizon-vary-across-domains/?utm_source=chatgpt.com","pub_date":1752476400.0,"snippet":"Jul 14, 2025 \u2014 Coding, math contest, and QA benchmarks all show 30-200 minute+ horizons doubling every ~2-6 months, with METR-HRS in the middle of the pack.","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":5}],"hue":null,"attributions":null,"attribution":"Metr"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn2search1\ue202turn2search7\ue201","start_idx":4313,"end_idx":4345,"safe_urls":["https://www.anthropic.com/news/claude-sonnet-4-5?utm_source=chatgpt.com","https://www.vals.ai/benchmarks/swebench?utm_source=chatgpt.com"],"refs":[],"alt":"([Anthropic](https://www.anthropic.com/news/claude-sonnet-4-5?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Introducing Claude Sonnet 4.5","url":"https://www.anthropic.com/news/claude-sonnet-4-5?utm_source=chatgpt.com","pub_date":null,"snippet":"Sep 29, 2025 \u2014 SWE-bench Verified: All Claude results were reported using a simple scaffold with two tools\u2014bash and file editing via string replacements.","attribution_segments":null,"supporting_websites":[{"title":"SWE-bench","url":"https://www.vals.ai/benchmarks/swebench?utm_source=chatgpt.com","pub_date":null,"snippet":"Oct 17, 2025 \u2014 Claude Sonnet 4.5 (Thinking) leads with a performance of 69.8%, scoring the highest across all models, though it comes with significantly higher ...","attribution":"Vals AI"}],"refs":[{"turn_index":2,"ref_type":"search","ref_index":1},{"turn_index":2,"ref_type":"search","ref_index":7}],"hue":null,"attributions":null,"attribution":"Anthropic"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search4\ue201","start_idx":4561,"end_idx":4580,"safe_urls":["https://www.anthropic.com/news/claude-sonnet-4-5?utm_source=chatgpt.com"],"refs":[],"alt":"([Anthropic](https://www.anthropic.com/news/claude-sonnet-4-5?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Introducing Claude Sonnet 4.5","url":"https://www.anthropic.com/news/claude-sonnet-4-5?utm_source=chatgpt.com","pub_date":null,"snippet":"Sep 29, 2025 \u2014 Claude Sonnet 4.5 is state-of-the-art on the SWE-bench Verified evaluation, which measures real-world software coding abilities. Practically ...See more","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":4}],"hue":null,"attributions":null,"attribution":"Anthropic"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn6view0\ue201","start_idx":4779,"end_idx":4796,"safe_urls":["https://openai.com/index/gdpval/"],"refs":[],"alt":"([OpenAI](https://openai.com/index/gdpval/))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Measuring the performance of our models on real-world tasks  | OpenAI","url":"https://openai.com/index/gdpval/","pub_date":null,"snippet":null,"attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":6,"ref_type":"view","ref_index":0}],"hue":null,"attributions":null,"attribution":"OpenAI"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search5\ue201","start_idx":4962,"end_idx":4981,"safe_urls":["https://metr.org/blog/2025-07-14-how-does-time-horizon-vary-across-domains/?utm_source=chatgpt.com"],"refs":[],"alt":"([Metr](https://metr.org/blog/2025-07-14-how-does-time-horizon-vary-across-domains/?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"How Does Time Horizon Vary Across Domains?","url":"https://metr.org/blog/2025-07-14-how-does-time-horizon-vary-across-domains/?utm_source=chatgpt.com","pub_date":1752476400.0,"snippet":"Jul 14, 2025 \u2014 Coding, math contest, and QA benchmarks all show 30-200 minute+ horizons doubling every ~2-6 months, with METR-HRS in the middle of the pack.","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":5}],"hue":null,"attributions":null,"attribution":"Metr"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn2search1\ue202turn0search3\ue202turn4search0\ue201","start_idx":5434,"end_idx":5479,"safe_urls":["https://cognition.ai/blog/devin-sonnet-4-5-lessons-and-challenges?utm_source=chatgpt.com","https://openai.com/index/learning-to-reason-with-llms/?utm_source=chatgpt.com","https://www.anthropic.com/news/claude-sonnet-4-5?utm_source=chatgpt.com"],"refs":[],"alt":"([Anthropic](https://www.anthropic.com/news/claude-sonnet-4-5?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Introducing Claude Sonnet 4.5","url":"https://www.anthropic.com/news/claude-sonnet-4-5?utm_source=chatgpt.com","pub_date":null,"snippet":"Sep 29, 2025 \u2014 SWE-bench Verified: All Claude results were reported using a simple scaffold with two tools\u2014bash and file editing via string replacements.","attribution_segments":null,"supporting_websites":[{"title":"Rebuilding Devin for Claude Sonnet 4.5: Lessons and ...","url":"https://cognition.ai/blog/devin-sonnet-4-5-lessons-and-challenges?utm_source=chatgpt.com","pub_date":null,"snippet":"Sep 29, 2025 \u2014 In this article: We rebuilt Devin for Claude Sonnet 4.5. The new version is 2x faster, 12% better on our Junior Developer Evals, and it's ...","attribution":"Cognition"},{"title":"Learning to reason with LLMs","url":"https://openai.com/index/learning-to-reason-with-llms/?utm_source=chatgpt.com","pub_date":null,"snippet":"Sep 12, 2024 \u2014 We have found that the performance of o1 consistently improves with more reinforcement learning (train-time compute) and with more time spent ...","attribution":"OpenAI"}],"refs":[{"turn_index":2,"ref_type":"search","ref_index":1},{"turn_index":0,"ref_type":"search","ref_index":3},{"turn_index":4,"ref_type":"search","ref_index":0}],"hue":null,"attributions":null,"attribution":"Anthropic"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search1\ue201","start_idx":5587,"end_idx":5606,"safe_urls":["https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/?utm_source=chatgpt.com"],"refs":[],"alt":"([Metr](https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Measuring AI Ability to Complete Long Tasks","url":"https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/?utm_source=chatgpt.com","pub_date":1742367600.0,"snippet":"Mar 19, 2025 \u2014 We show that this metric has been consistently exponentially increasing over the past 6 years, with a doubling time of around 7 months.","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":1}],"hue":null,"attributions":null,"attribution":"Metr"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn6view0\ue202turn0search5\ue201","start_idx":6162,"end_idx":6192,"safe_urls":["https://metr.org/blog/2025-07-14-how-does-time-horizon-vary-across-domains/?utm_source=chatgpt.com","https://openai.com/index/gdpval/"],"refs":[],"alt":"([OpenAI](https://openai.com/index/gdpval/))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Measuring the performance of our models on real-world tasks  | OpenAI","url":"https://openai.com/index/gdpval/","pub_date":null,"snippet":null,"attribution_segments":null,"supporting_websites":[{"title":"How Does Time Horizon Vary Across Domains?","url":"https://metr.org/blog/2025-07-14-how-does-time-horizon-vary-across-domains/?utm_source=chatgpt.com","pub_date":null,"snippet":"Jul 14, 2025 \u2014 Coding, math contest, and QA benchmarks all show 30-200 minute+ horizons doubling every ~2-6 months, with METR-HRS in the middle of the pack.","attribution":"Metr"}],"refs":[{"turn_index":6,"ref_type":"view","ref_index":0},{"turn_index":0,"ref_type":"search","ref_index":5}],"hue":null,"attributions":null,"attribution":"OpenAI"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":" ","start_idx":6316,"end_idx":6316,"safe_urls":[],"refs":[],"alt":"","prompt_text":null,"type":"sources_footnote","sources":[{"title":"Learning to reason with LLMs","url":"https://openai.com/index/learning-to-reason-with-llms/?utm_source=chatgpt.com","attribution":"OpenAI"},{"title":"Claude Sonnet 4.5","url":"https://www.anthropic.com/claude/sonnet?utm_source=chatgpt.com","attribution":"Anthropic"},{"title":"Measuring AI Ability to Complete Long Tasks","url":"https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/?utm_source=chatgpt.com","attribution":"Metr"},{"title":"Rebuilding Devin for Claude Sonnet 4.5: Lessons and ...","url":"https://cognition.ai/blog/devin-sonnet-4-5-lessons-and-challenges?utm_source=chatgpt.com","attribution":"Cognition"}],"has_images":false}],"safe_urls":["https://openai.com/index/learning-to-reason-with-llms/?utm_source=chatgpt.com","https://www.anthropic.com/claude/sonnet?utm_source=chatgpt.com","https://www.anthropic.com/news/claude-opus-4-1?utm_source=chatgpt.com","https://www.anthropic.com/news/claude-sonnet-4-5?utm_source=chatgpt.com","https://www.anthropic.com/news/3-5-models-and-computer-use?utm_source=chatgpt.com","https://www.anthropic.com/news/claude-opus-4-1?utm_source=chatgpt.com","https://www.anthropic.com/news/claude-sonnet-4-5?utm_source=chatgpt.com","https://openai.com/index/gdpval/","https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/?utm_source=chatgpt.com","https://metr.org/blog/2025-07-14-how-does-time-horizon-vary-across-domains/?utm_source=chatgpt.com","https://caylent.com/blog/claude-sonnet-4-5-highest-scoring-claude-model-yet-on-swe-bench?utm_source=chatgpt.com","https://www.anthropic.com/news/claude-sonnet-4-5?utm_source=chatgpt.com","https://www.leanware.co/insights/claude-sonnet-4-5-overview?utm_source=chatgpt.com","https://www.vals.ai/benchmarks/swebench?utm_source=chatgpt.com","https://www.anthropic.com/news/claude-sonnet-4-5?utm_source=chatgpt.com","https://evals.openai.com/?utm_source=chatgpt.com","https://openai.com/index/gdpval/","https://www.techradar.com/ai-platforms-assistants/claude/claude-just-beat-gpt-5-gemini-and-grok-in-real-world-job-tasks-according-to-openais-own-study?utm_source=chatgpt.com","https://arxiv.org/pdf/2501.12948?utm_source=chatgpt.com","https://openai.com/index/learning-to-reason-with-llms/?utm_source=chatgpt.com","https://www.nature.com/articles/s41586-025-09422-z?utm_source=chatgpt.com","https://cognition.ai/blog/devin-agent-preview-sonnet-4-5?utm_source=chatgpt.com","https://cognition.ai/blog/devin-sonnet-4-5-lessons-and-challenges?utm_source=chatgpt.com","https://cognition.ai/blog/devin-sonnet-4-5-lessons-and-challenges?utm_source=chatgpt.com","https://openai.com/index/gdpval/","https://openai.com/index/learning-to-reason-with-llms/?utm_source=chatgpt.com","https://www.anthropic.com/news/claude-sonnet-4-5?utm_source=chatgpt.com","https://metr.org/blog/2025-07-14-how-does-time-horizon-vary-across-domains/?utm_source=chatgpt.com","https://www.anthropic.com/news/claude-sonnet-4-5?utm_source=chatgpt.com","https://www.vals.ai/benchmarks/swebench?utm_source=chatgpt.com","https://www.anthropic.com/news/claude-sonnet-4-5?utm_source=chatgpt.com","https://openai.com/index/gdpval/","https://metr.org/blog/2025-07-14-how-does-time-horizon-vary-across-domains/?utm_source=chatgpt.com","https://cognition.ai/blog/devin-sonnet-4-5-lessons-and-challenges?utm_source=chatgpt.com","https://openai.com/index/learning-to-reason-with-llms/?utm_source=chatgpt.com","https://www.anthropic.com/news/claude-sonnet-4-5?utm_source=chatgpt.com","https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/?utm_source=chatgpt.com","https://metr.org/blog/2025-07-14-how-does-time-horizon-vary-across-domains/?utm_source=chatgpt.com","https://openai.com/index/gdpval/"],"search_result_groups":[{"type":"search_result_group","domain":"anthropic.com","entries":[{"type":"search_result","url":"https://www.anthropic.com/claude-sonnet-4-5-system-card?utm_source=chatgpt.com","title":"Claude Sonnet 4.5 System Card","snippet":"Oct 10, 2025 \u2014 78. 7.5.9 Alignment-related biases. 79. 7.5.9.1 Self ... Safety score (without safeguards). Claude Sonnet 4.5. 98.7%. Claude Sonnet 4. 89.3%.See more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":0},"pub_date":null,"attribution":"anthropic.com"},{"type":"search_result","url":"https://www.anthropic.com/news/claude-3-7-sonnet?utm_source=chatgpt.com","title":"Claude 3.7 Sonnet and Claude Code","snippet":"24 Feb 2025 \u2014 Today, we're announcing Claude 3.7 Sonnet 1, our most intelligent model to date and the first hybrid reasoning model on the market.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"anthropic.com"},{"type":"search_result","url":"https://www.anthropic.com/news/claude-3-5-sonnet?utm_source=chatgpt.com","title":"Introducing Claude 3.5 Sonnet","snippet":"20 Jun 2024 \u2014 In an internal agentic coding evaluation, Claude 3.5 Sonnet solved 64% of problems, outperforming Claude 3 Opus which solved 38%. Our evaluation ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"anthropic.com"},{"type":"search_result","url":"https://www.anthropic.com/news/claude-opus-4-1?utm_source=chatgpt.com","title":"Claude Opus 4.1","snippet":"Aug 5, 2025 \u2014 Opus 4.1 advances our state-of-the-art coding performance to 74.5% on SWE-bench Verified. It also improves Claude's in-depth research and data ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"anthropic.com"},{"type":"search_result","url":"https://www.anthropic.com/news/claude-4?utm_source=chatgpt.com","title":"Introducing Claude 4","snippet":"May 22, 2025 \u2014 Opus 4 and Sonnet 4 score 39.2% and 33.5% pass@1 with the same ... No extended thinking: SWE-bench Verified, Terminal-bench; Extended ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"anthropic.com"}]},{"type":"search_result_group","domain":"cursor.com","entries":[{"type":"search_result","url":"https://forum.cursor.com/t/ending-up-free-claude-3-5-sonnet-requests/46567?utm_source=chatgpt.com","title":"Ending up free claude-3.5-sonnet requests - Discussions","snippet":"Jan 31, 2025 \u2014 Talking about 50 free claude-3.5-sonnet requests \u2013 I am just curious are those request reserved for every month or they are gone forever? (I ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":0},"pub_date":null,"attribution":"cursor.com"},{"type":"search_result","url":"https://forum.cursor.com/t/claude-3-5-sonnet-20241022-dissapeared/27964?utm_source=chatgpt.com","title":"Claude-3-5-sonnet-20241022 dissapeared - Discussions","snippet":"Nov 15, 2024 \u2014 It means that when you're using claude-3.5-sonnet it's actually using claude-3-5-sonnet-20241022 under the hood by default. You can enable the older models by ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"cursor.com"},{"type":"search_result","url":"https://forum.cursor.com/t/only-claude-3-5-sonnet-is-available/65568?utm_source=chatgpt.com","title":"Only Claude 3.5 Sonnet is available - Bug Reports","snippet":"Mar 17, 2025 \u2014 I've installed Cursor on two different computers and the issue is the same. There are no other LLM options available than Claude 3.5 Sonnet.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"cursor.com"},{"type":"search_result","url":"https://forum.cursor.com/t/claude-3-5-sonnet-api-access-issue/27778?utm_source=chatgpt.com","title":"Claude 3.5 Sonnet API Access Issue - Discussions","snippet":"Nov 14, 2024 \u2014 I purchased Claude API credits to use it in Cursor - pro plan. But only older Claude versions (Claude 3 Haiku, Opus, and Sonnet) are available in the dropdown ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"cursor.com"},{"type":"search_result","url":"https://forum.cursor.com/t/claude-3-5-sonnet-updated-and-claude-3-5-haiku-soon/24165?utm_source=chatgpt.com","title":"Claude 3.5 Sonnet updated, and Claude 3.5 Haiku soon","snippet":"22 Oct 2024 \u2014 The updated Claude 3.5 Sonnet shows wide-ranging improvements on industry benchmarks, with particularly strong gains in agentic coding and tool use tasks.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"cursor.com"},{"type":"search_result","url":"https://forum.cursor.com/t/cursor-using-claude-sonnet-3-5-max-instead-of-selected-4-0/116489?utm_source=chatgpt.com","title":"Cursor using Claude Sonnet 3.5 Max instead of Selected ...","snippet":"Jul 11, 2025 \u2014 Been noticing a weird thing where you are selecting sonnet 4 but the model is identify as sonnet 3.5 or 3.5 max? I noticed this a day or two ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"cursor.com"}]},{"type":"search_result_group","domain":"arxiv.org","entries":[{"type":"search_result","url":"https://arxiv.org/pdf/2501.12948?utm_source=chatgpt.com","title":"DeepSeek-R1: Incentivizing Reasoning Capability in LLMs ...","snippet":"by D Guo \u00b7 2025 \u00b7 Cited by 4636 \u2014 In this paper, we take the first step toward improving language model reasoning capabilities using pure reinforcement learning (RL). Our goal is ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2501.12948v1?utm_source=chatgpt.com","title":"DeepSeek-R1: Incentivizing Reasoning Capability in LLMs ...","snippet":"In this paper, we take the first step toward improving language model reasoning capabilities using pure reinforcement learning (RL).","ref_id":{"turn_index":4,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"arxiv.org"}]},{"type":"search_result_group","domain":"openai.com","entries":[{"type":"search_result","url":"https://openai.com/index/gdpval/?utm_source=chatgpt.com","title":"Measuring the performance of our models on real-world tasks","snippet":"Sep 25, 2025 \u2014 We're introducing GDPval, a new evaluation that measures model performance on economically valuable, real-world tasks across 44 occupations.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"openai.com"},{"type":"search_result","url":"https://cdn.openai.com/pdf/d5eb7428-c4e9-4a33-bd86-86dd4bcf12ce/GDPval.pdf?utm_source=chatgpt.com","title":"gdpval: evaluating ai model performance","snippet":"Sep 3, 2025 \u2014 We introduce GDPval, a benchmark evaluating AI model capabilities on real- world economically valuable tasks. GDPval covers the majority of ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"openai.com"},{"type":"search_result","url":"https://evals.openai.com/?utm_source=chatgpt.com","title":"OpenAI Evals","snippet":"Sep 25, 2025 \u2014 We introduce GDPval, an evaluation assessing AI model capabilities on real-world economically valuable tasks. GDPval covers the majority of U.S. ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"openai.com"}]},{"type":"search_result_group","domain":"reddit.com","entries":[{"type":"search_result","url":"https://www.reddit.com/r/ClaudeAI/comments/1ntuxq9/sonnet_45_reaches_top_of_swebench_leaderboard/?utm_source=chatgpt.com","title":"Sonnet 4.5 reaches top of SWE-bench leaderboard with ...","snippet":"Sonnet 4.5 reaches top of SWE-bench leaderboard with minimal agent. Detailed cost analysis + all the logs. Built with Claude.See more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/singularity/comments/1o3dnz2/reasoning_models_show_22_performance_jump_and_37/?utm_source=chatgpt.com","title":"Reasoning Models Show 2.2\u00d7 Performance Jump and 37 ...","snippet":"What this benchmark measures: METR-Horizon evaluates how long tasks AI agents can complete autonomously without human help.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":22},"pub_date":null,"attribution":"reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/singularity/comments/1mlwctz/details_about_metrs_evaluation_of_openai_gpt5/?utm_source=chatgpt.com","title":"Details about METR's evaluation of OpenAI GPT-5","snippet":"No discernable benchmark maxing discovered by this 3rd party. \"The observed 50%-time horizon of GPT-5 was 2h17m (65m - 4h25m 95% CI) \u2013 compared ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":26},"pub_date":null,"attribution":"reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/ClaudeCode/comments/1nttgc9/sonnet_45_has_context_anxiety/?utm_source=chatgpt.com","title":"Sonnet 4.5 has \u201ccontext anxiety\u201d : r/ClaudeCode","snippet":"Cognition had to rebuild their product Devin to adapt to these new changes in Sonnet 4.5. https://cognition.ai/blog/devin-sonnet-4-5-lessons ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":28},"pub_date":null,"attribution":"reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/singularity/comments/1nqdzht/openai_gdpval_measuring_the_performance_of_our/?utm_source=chatgpt.com","title":"OpenAI GDPval: Measuring the performance of our models ...","snippet":"GDPval, the first version of this evaluation, spans 44 occupations selected from the top 9 industries contributing to U.S. GDP.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":32},"pub_date":null,"attribution":"reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/ClaudeAI/comments/1g7ftp5/claude_sonnet_35_in_cursor_why_does_it_keep/?utm_source=chatgpt.com","title":"Claude Sonnet 3.5 in Cursor - why does it keep telling me ...","snippet":"When I ask Sonnet 3.5 to do something in Cursor, it first repeats what it will do, and then it does. I have the following custom instructions too.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/singularity/comments/1midxtb/claude_opus_41_benchmarks/?utm_source=chatgpt.com","title":"Claude Opus 4.1 Benchmarks : r/singularity","snippet":"Important thing to remember, it gets very hard to benchmark these models now, especially in the intangibles of working with them.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/ClaudeAI/comments/1ktotrs/claude_4_shows_massive_gains_on_the_swebench/?utm_source=chatgpt.com","title":"Claude 4 shows massive gains on the SWE-bench ...","snippet":"Using SWE-agent, the single-attempt pass@1 resolution rate rises to 69% (up 10%pt over Sonnet 3.7)!. Sonnet 4 iterates longer (making it ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/singularity/comments/1nk43b1/deepseekr1_incentivizes_reasoning_in_llms_through/?utm_source=chatgpt.com","title":"DeepSeek-R1 incentivizes reasoning in LLMs through ...","snippet":"The paper replaces human-labelled reasoning traces with answer-graded RL, so the model only gets a reward when its final answer matches ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/reinforcementlearning/comments/1icrgt5/who_is_rewarding_deepseek_r1_in_rl_you_need_some/?utm_source=chatgpt.com","title":"Who is rewarding DeepSeek R1? In RL you need some ...","snippet":"Two things they used for rewards are rule-based math solvers and LeetCode problems with test cases.","ref_id":{"turn_index":4,"ref_type":"search","ref_index":19},"pub_date":null,"attribution":"reddit.com"}]},{"type":"search_result_group","domain":"lesswrong.com","entries":[{"type":"search_result","url":"https://www.lesswrong.com/posts/fRiqwFPiaasKxtJuZ/interpreting-the-metr-time-horizons-post?utm_source=chatgpt.com","title":"Interpreting the METR Time Horizons Post","snippet":"Apr 29, 2025 \u2014 If AIs can double their task horizon every 7 months, that works out to 5.6 doublings, or 40 months. The unrealistically simple nature of the ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"lesswrong.com"},{"type":"search_result","url":"https://www.lesswrong.com/posts/byNYzsfFmb2TpYFPW/o1-a-technical-primer?utm_source=chatgpt.com","title":"o1: A Technical Primer","snippet":"Dec 9, 2024 \u2014 In September 2024, OpenAI released o1, its first reasoning model. This model exhibits remarkable test-time scaling laws, which complete a missing piece of the ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"lesswrong.com"}]},{"type":"search_result_group","domain":"leanware.co","entries":[{"type":"search_result","url":"https://www.leanware.co/insights/claude-sonnet-4-5-overview?utm_source=chatgpt.com","title":"Claude Sonnet 4.5: Features, Benchmarks & Pricing (2025)","snippet":"Sep 30, 2025 \u2014 TLDR: Claude Sonnet 4.5 scores 77.2% on SWE-bench Verified (82.0% with parallel compute), 50.0% on Terminal-Bench, and 61.4% on OSWorld.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"leanware.co"}]},{"type":"search_result_group","domain":"nature.com","entries":[{"type":"search_result","url":"https://www.nature.com/articles/s41586-025-09422-z?utm_source=chatgpt.com","title":"DeepSeek-R1 incentivizes reasoning in LLMs through ...","snippet":"by D Guo \u00b7 2025 \u00b7 Cited by 90 \u2014 The proposed RL framework facilitates the emergent development of advanced reasoning patterns, such as self-reflection, verification and dynamic ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"nature.com"}]},{"type":"search_result_group","domain":"medium.com","entries":[{"type":"search_result","url":"https://medium.com/%40cognidownunder/claude-sonnet-4-5-d29689e34a64?utm_source=chatgpt.com","title":"Claude Sonnet 4.5 vs GPT-5 High vs Grok 4 Fast ...","snippet":"Claude's 78% math score means nothing when it's the only model that can refactor your entire codebase without human intervention. Press ...See more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://medium.com/coding-beauty/new-claude-4-5-haiku-f2f79bb6df06?utm_source=chatgpt.com","title":"Yet Another Claude Model Just Shocked ...","snippet":"Well that was FAST. Barely 2 weeks after Sonnet 4.5 and we have yet another incredible Claude model from Anthropic.See more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":35},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://medium.com/%40AIchats/are-ai-time-horizon-doubling-every-seven-months-e337162eec83?utm_source=chatgpt.com","title":"Are AI time horizon doubling every seven months?","snippet":"Are AI time horizon doubling every seven months? A critical review of METR's \u201cMeasuring AI Ability to Complete Long Tasks\u201d by Kwa et al.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":40},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://falexm.medium.com/openais-gdpval-the-benchmark-that-s-redefining-ai-s-impact-on-professional-work-5df9c0d33da5?utm_source=chatgpt.com","title":"OpenAI's GDPval: The Benchmark That's Redefining AI's ...","snippet":"What Is GDPval? GDPval is an evaluation suite designed to measure AI model performance on real-world, economically valuable tasks across 44 ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":44},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://medium.com/towards-agi/how-to-use-cursor-ai-with-claude-3-5-sonnet-step-by-step-guide-4e1bbdd7bd65?utm_source=chatgpt.com","title":"How to Use Cursor AI with Claude 3.5 Sonnet","snippet":"Step 1: Get Your Anthropic API Key. The first step in integrating Claude 3.5 Sonnet with Cursor AI is obtaining an API key from Anthropic.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://open-data-analytics.medium.com/claude-code-vs-cursor-the-battle-of-ai-coding-agents-in-2025-fea04c4490eb?utm_source=chatgpt.com","title":"Claude Code vs Cursor: The Battle of AI Coding Agents in 2025","snippet":"Since both Claude Code and Cursor's agent mode run on Claude models, you might think they'd produce identical results. And for raw code quality?","ref_id":{"turn_index":1,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://medium.com/%40exceed73/claude-sonnet-4-5-for-programmers-c6c0c5def2e5?utm_source=chatgpt.com","title":"Claude Sonnet 4.5 for Programmers - Medium","snippet":"Sonnet 4.5 (Thinking) ranks #1. Table \u2014 Independent SWE-bench (Verified) Leaderboard (Vals AI, updated 2025\u201309\u201329).","ref_id":{"turn_index":2,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://medium.com/%40leucopsis/how-gpt-5-codex-compares-to-claude-sonnet-4-5-1c1c0c2120b0?utm_source=chatgpt.com","title":"How GPT-5-Codex Compares to Claude Sonnet 4.5","snippet":"In its launch materials, Anthropic positions Sonnet 4.5 as the clear leader on the SWE-bench Verified benchmark, which measures an agent's ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://medium.com/%40servifyspheresolutions/claude-opus-4-1-is-here-anthropics-next-gen-ai-model-for-coding-and-beyond-e25764439047?utm_source=chatgpt.com","title":"Claude Opus 4.1 is Here: Anthropic's Next-Gen AI Model ...","snippet":"It achieves a 74.5% score on SWE-bench Verified, showcasing its ability to handle complex software engineering challenges with precision. The ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://medium.com/wix-engineering/explaining-openais-o1-breakthrough-the-revolution-of-test-time-compute-ecebe8ef9379?utm_source=chatgpt.com","title":"Explaining OpenAI's o1 Breakthrough: The Revolution of ...","snippet":"Test Time Compute represents a significant step forward in how AI systems approach complex problems. By combining this with reinforcement ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://artgor.medium.com/paper-review-deepseek-r1-incentivizing-reasoning-capability-in-llms-via-reinforcement-learning-edf4343dcf3a?utm_source=chatgpt.com","title":"Paper Review: DeepSeek-R1: Incentivizing Reasoning ...","snippet":"This system consists of two reward types: accuracy rewards and format rewards. Accuracy rewards assess correctness using deterministic methods, ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"medium.com"}]},{"type":"search_result_group","domain":"infoq.com","entries":[{"type":"search_result","url":"https://www.infoq.com/news/2025/10/claude-sonnet-4-5/?utm_source=chatgpt.com","title":"Claude Sonnet 4.5 Tops SWE-Bench Verified, Extends ...","snippet":"Oct 11, 2025 \u2014 Anthropic's Claude Sonnet 4.5, its most advanced coding model, excels in task performance and safety, achieving a 98.7% safety score and ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":25},"pub_date":null,"attribution":"infoq.com"},{"type":"search_result","url":"https://www.infoq.com/news/2025/08/anthropic-claude-opus-4-1/?utm_source=chatgpt.com","title":"Anthropic's Claude Opus 4.1 Improves Refactoring and ...","snippet":"Aug 28, 2025 \u2014 The model also raised its SWE-bench Verified score to 74.5%, up from 72.5%. Figure 1: SWE-bench Verified accuracy comparison between Opus 4.1 vs ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"infoq.com"}]},{"type":"search_result_group","domain":"amitysolutions.com","entries":[{"type":"search_result","url":"https://www.amitysolutions.com/blog/openai-o1-llm-reinforcement-learning-training?utm_source=chatgpt.com","title":"OpenAI o1: A New LLM Powered by Reinforcement Learning","snippet":"Oct 9, 2024 \u2014 OpenAI o1, the newest large language model, brings a sophisticated approach to handling complex tasks by employing reinforcement learning.","ref_id":{"turn_index":4,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"amitysolutions.com"}]},{"type":"search_result_group","domain":"cognition.ai","entries":[{"type":"search_result","url":"https://cognition.ai/blog/devin-agent-preview-sonnet-4-5?utm_source=chatgpt.com","title":"Announcing Devin Agent Preview with Sonnet 4.5","snippet":"Sep 29, 2025 \u2014 For Devin, Claude Sonnet 4.5 increased planning performance by 18% and end-to-end eval scores by 12% - the biggest jump we've seen since the ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"cognition.ai"}]},{"type":"search_result_group","domain":"vals.ai","entries":[{"type":"search_result","url":"https://www.vals.ai/benchmarks/swebench?utm_source=chatgpt.com","title":"SWE-bench","snippet":"Oct 17, 2025 \u2014 Claude Sonnet 4.5 (Thinking) leads with a performance of 69.8%, scoring the highest across all models, though it comes with significantly higher ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"vals.ai"}]},{"type":"search_result_group","domain":"labelstud.io","entries":[{"type":"search_result","url":"https://labelstud.io/blog/reinforcement-learning-from-verifiable-rewards/?utm_source=chatgpt.com","title":"Reinforcement Learning from Verifiable Rewards","snippet":"Feb 7, 2025 \u2014 Reinforcement Learning with Verifiable Rewards is among the leading training strategies for injecting learning signals into LLMs, ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"labelstud.io"}]},{"type":"search_result_group","domain":"skywork.ai","entries":[{"type":"search_result","url":"https://skywork.ai/blog/claude-sonnet-4-5-benchmarks-explained-swe-bench-mmlu-gsm8k/?utm_source=chatgpt.com","title":"Claude Sonnet 4.5 benchmarks: SWE-bench, MMLU, GSM8K","snippet":"Oct 3, 2025 \u2014 A model scoring well here (Sonnet 4.5 reports a strong result on SWE-bench Verified \u2014 the release mentions 77.2% under a specified setup) ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"skywork.ai"}]},{"type":"search_result_group","domain":"simonwillison.net","entries":[{"type":"search_result","url":"https://simonwillison.net/2025/Aug/5/claude-opus-41/?utm_source=chatgpt.com","title":"Claude Opus 4.1","snippet":"Aug 5, 2025 \u2014 Agentic coding (SWE-bench Verified): From 72.5% to 74.5%; Agentic terminal coding (Terminal-Bench): From 39.2% to 43.3%; Graduate-level ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"simonwillison.net"},{"type":"search_result","url":"https://simonwillison.net/2024/Sep/12/openai-o1/?utm_source=chatgpt.com","title":"Notes on OpenAI's new o1 chain-of-thought models","snippet":"Sep 12, 2024 \u2014 We have found that the performance of o1 consistently improves with more reinforcement learning (train-time compute) and with more time spent ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"simonwillison.net"}]},{"type":"search_result_group","domain":"jonvet.com","entries":[{"type":"search_result","url":"https://www.jonvet.com/blog/llm-test-time-compute?utm_source=chatgpt.com","title":"Scaling LLM Test Time Compute","snippet":"Oct 20, 2024 \u2014 Test time compute refers to the amount of compute that is used to generate completions from a language model (LLM) at test or inference time.","ref_id":{"turn_index":4,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"jonvet.com"}]},{"type":"search_result_group","domain":"tbench.ai","entries":[{"type":"search_result","url":"https://www.tbench.ai/leaderboard?utm_source=chatgpt.com","title":"Terminal-Bench Leaderboard","snippet":"Ante, claude-sonnet-4-5, 2025-10-10, Antigma Labs, Anthropic. 60.3%\u00b1 1.1. 2. Droid, claude-opus-4-1, 2025-09-24, Factory, Anthropic. 58.8%\u00b1 0.9.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"tbench.ai"}]},{"type":"search_result_group","domain":"apidog.com","entries":[{"type":"search_result","url":"https://apidog.com/blog/use-cursor-ai-with-claude-3-5-sonnet/?utm_source=chatgpt.com","title":"How to Use Cursor AI with Claude 3.5 Sonnet (Step-by- ...","snippet":"Learn how to combine Cursor AI with Claude 3.5 Sonnet to generate AI-powered poetry and streamline your creative process.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"apidog.com"}]},{"type":"search_result_group","domain":"substack.com","entries":[{"type":"search_result","url":"https://bdtechtalks.substack.com/p/claude-sonnet-45-takes-the-lead-in?utm_source=chatgpt.com","title":"Claude Sonnet 4.5 takes the lead in AI coding with token ...","snippet":"Anthropic claims state-of-the-art performance for Sonnet 4.5 on the SWE-bench Verified evaluation, scoring 77.2% on the test of real-world ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"substack.com"}]},{"type":"search_result_group","domain":"milvus.io","entries":[{"type":"search_result","url":"https://milvus.io/ai-quick-reference/how-does-claude-opus-41-perform-on-benchmarks-such-as-swebench-verified-compared-to-earlier-models?utm_source=chatgpt.com","title":"How does Claude Opus 4.1 perform on benchmarks such ...","snippet":"Claude Opus 4.1 achieves 74.5% on SWE-bench Verified, marking a substantial improvement over previous Claude models and establishing new standards for AI ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"milvus.io"}]},{"type":"search_result_group","domain":"innovationendeavors.com","entries":[{"type":"search_result","url":"https://www.innovationendeavors.com/insights/mechanisms-for-test-time-compute?utm_source=chatgpt.com","title":"Mechanisms for test-time compute","snippet":"In this blog I aim to outline the major ways test-time compute scaling can be achieved, based on both reviewing a lot of the recent literature in this space.","ref_id":{"turn_index":4,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"innovationendeavors.com"}]},{"type":"search_result_group","domain":"kommunicate.io","entries":[{"type":"search_result","url":"https://www.kommunicate.io/blog/new-claude-3-5-sonnet/?utm_source=chatgpt.com","title":"Meet the New Claude 3.5 Sonnet: An AI That Uses ...","snippet":"12 Feb 2025 \u2014 Explore Claude 3.5 Sonnet, an AI that controls computers, excels in coding, and transforms customer support with advanced automation.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"kommunicate.io"}]},{"type":"search_result_group","domain":"galileo.ai","entries":[{"type":"search_result","url":"https://galileo.ai/blog/deepseek-reinforcement-learning?utm_source=chatgpt.com","title":"How DeepSeek's RL Approach Achieves 79.8% AIME ...","snippet":"Jul 25, 2025 \u2014 DeepSeek proves pure reinforcement learning creates advanced reasoning without supervision. Get the breakthrough framework.","ref_id":{"turn_index":4,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"galileo.ai"}]},{"type":"search_result_group","domain":"podwise.ai","entries":[{"type":"search_result","url":"https://podwise.ai/dashboard/episodes/5327995?utm_source=chatgpt.com","title":"Sonnet 4.5 & the AI Plateau Myth \u2014 Sholto Douglas (Anthropic)","snippet":"In this episode of The MAD Podcast, Matt Turck interviews Sholto Douglas, a leading AI researcher at Anthropic, about the release of Claude Sonnet 4.5...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"podwise.ai"}]},{"type":"search_result_group","domain":"cometapi.com","entries":[{"type":"search_result","url":"https://www.cometapi.com/claude-opus-4-1-vs-opus-4-0/?utm_source=chatgpt.com","title":"Claude Opus 4.1 vs Opus 4.0: A Comprehensive Comparison","snippet":"Aug 11, 2025 \u2014 On SWE-bench Verified, Opus 4.1 scores 74.5%, up from Opus 4.0's 72.5%. This 2-point gain, while seemingly modest, equates to meaningful ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"cometapi.com"}]},{"type":"search_result_group","domain":"encord.com","entries":[{"type":"search_result","url":"https://encord.com/blog/openai-o1/?utm_source=chatgpt.com","title":"OpenAI o1: A New Era of AI Reasoning","snippet":"Sep 13, 2024 \u2014 OpenAI o1 series is a new class of large language models (LLMs) designed to enhance reasoning capabilities through a thinking before responding approach.","ref_id":{"turn_index":4,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"encord.com"}]},{"type":"search_result_group","domain":"caylent.com","entries":[{"type":"search_result","url":"https://caylent.com/blog/claude-sonnet-4-5-highest-scoring-claude-model-yet-on-swe-bench?utm_source=chatgpt.com","title":"Highest-Scoring Claude Model Yet on SWE-bench","snippet":"Oct 10, 2025 \u2014 Anthropic has just released Claude Sonnet 4.5, setting a new record of benchmark scores: 77.2% on SWE-bench Verified and 61.4% on OSWorld ...See more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"caylent.com"}]},{"type":"search_result_group","domain":"braintrust.dev","entries":[{"type":"search_result","url":"https://www.braintrust.dev/blog/claude-sonnet-4-5-aspirational-evals?utm_source=chatgpt.com","title":"Claude Sonnet 4.5 analysis - Blog - Braintrust","snippet":"Sep 29, 2025 \u2014 Today, Anthropic announced Claude Sonnet 4.5, achieving 77.2% on SWE-bench Verified, running autonomously for 30 hours, and setting new ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"braintrust.dev"}]},{"type":"search_result_group","domain":"vincentschmalbach.com","entries":[{"type":"search_result","url":"https://www.vincentschmalbach.com/cursor-is-secretly-running-a-weaker-version-of-claude-3-5-sonnet/?utm_source=chatgpt.com","title":"Cursor is Secretly Running a Weaker Version of Claude ...","snippet":"Jan 31, 2025 \u2014 Last week I wrote about how Cursor is maxing out Anthropic's GPU capacity. Now it looks like they're giving us a worse version of Claude 3.5 ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"vincentschmalbach.com"}]},{"type":"search_result_group","domain":"emerge.haus","entries":[{"type":"search_result","url":"https://www.emerge.haus/blog/test-time-compute-generative-ai?utm_source=chatgpt.com","title":"Test-Time Compute in Generative AI: An AI Atlas Report","snippet":"Apr 21, 2025 \u2014 We'll cover OpenAI's o1 and its successors, Anthropic's latest Claude model, the open-source DeepSeek R1, and then compare these to baseline ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"emerge.haus"}]},{"type":"search_result_group","domain":"oltre.dev","entries":[{"type":"search_result","url":"https://oltre.dev/articles/rebuilding-devin-on-sonnet-45-performance-planning-and-architecture-1759240811136/?utm_source=chatgpt.com","title":"Rebuilding Devin on Sonnet 4.5: Performance, Planning, and ...","snippet":"Cognition rebuilt Devin to run on Sonnet 4.5 rather than simply swapping models. The new Devin is reported to be twice as fast and to score 12% higher on the ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"oltre.dev"}]},{"type":"search_result_group","domain":"analyticsvidhya.com","entries":[{"type":"search_result","url":"https://www.analyticsvidhya.com/blog/2025/02/olmo-2-vs-claude-3-5-sonnet/?utm_source=chatgpt.com","title":"OLMo 2 vs. Claude 3.5 Sonnet: Which is Better?","snippet":"27 Feb 2025 \u2014 OLMo 2 vs. Claude 3.5 Sonnet\u2014open-source transparency vs. enterprise AI. Compare architectures, coding capabilities and hands-on examples.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"analyticsvidhya.com"}]},{"type":"search_result_group","domain":"spartner.software","entries":[{"type":"search_result","url":"https://spartner.software/blog/first-impressions-gpt-5-vs-claude-4-sonnet?utm_source=chatgpt.com","title":"First Impressions: GPT-5 or Claude 4 Sonnet? | Spartner","snippet":"Aug 9, 2025 \u2014 OpenAI introduced GPT-5 as the new flagship with SOTA on real-world coding: 74.9% on SWE-bench Verified, plus 94.6% on AIME 2025 without tools.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"spartner.software"}]},{"type":"search_result_group","domain":"facebook.com","entries":[{"type":"search_result","url":"https://www.facebook.com/groups/DeepNetGroup/posts/2447889112270623/?utm_source=chatgpt.com","title":"Inference-Time Scaling for Generalist Reward Modeling ...","snippet":"Inference-Time Scaling for Generalist Reward Modeling (DeepSeek, April 2025 ... RL and optimizes for human preferences using your LLM as a reward ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"facebook.com"}]},{"type":"search_result_group","domain":"apple.com","entries":[{"type":"search_result","url":"https://podcasts.apple.com/us/podcast/the-mad-podcast-with-matt-turck/id1686238724?utm_source=chatgpt.com","title":"The MAD Podcast with Matt Turck","snippet":"Sonnet 4.5 & the AI Plateau Myth \u2014 Sholto Douglas (Anthropic). Sholto Douglas, a top AI researcher at Anthropic, discusses the breakthroughs behind Claude ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"apple.com"}]},{"type":"search_result_group","domain":"interconnects.ai","entries":[{"type":"search_result","url":"https://www.interconnects.ai/p/reverse-engineering-openai-o1?utm_source=chatgpt.com","title":"Reverse engineering OpenAI's o1 - by Nathan Lambert","snippet":"Sep 16, 2024 \u2014 What productionizing test-time compute shows us about the future of AI. Exploration has landed in language model training.","ref_id":{"turn_index":4,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"interconnects.ai"}]},{"type":"search_result_group","domain":"getbind.co","entries":[{"type":"search_result","url":"https://blog.getbind.co/2025/02/24/claude-3-7-sonnet-vs-claude-3-5-sonnet/?utm_source=chatgpt.com","title":"Anthropic launches Claude 3.7 Sonnet with Extended ...","snippet":"24 Feb 2025 \u2014 It allows developers to conduct agentic coding\u2014reading, editing, testing, and committing code by delegating these tasks directly to the model. \u2022 ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"getbind.co"}]},{"type":"search_result_group","domain":"searchenginejournal.com","entries":[{"type":"search_result","url":"https://www.searchenginejournal.com/claude-opus-4-1-improves-coding-agent-capabilities/553062/?utm_source=chatgpt.com","title":"Claude Opus 4.1 Improves Coding & Agent Capabilities","snippet":"Aug 5, 2025 \u2014 Claude Opus 4.1 scores 74.5% on SWE-bench Verified, a benchmark for real-world coding problems, and is positioned as a drop-in replacement for ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"searchenginejournal.com"}]},{"type":"search_result_group","domain":"github.com","entries":[{"type":"search_result","url":"https://github.com/TsinghuaC3I/Awesome-RL-for-LRMs?utm_source=chatgpt.com","title":"TsinghuaC3I/Awesome-RL-for-LRMs: A Survey of ...","snippet":"... Rewards: Reinforcement Learning Beyond Verifiable Domains, Paper ... 2025-04, -, Improving RL Exploration for LLM Reasoning through Retrospective Replay, Paper, - ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"github.com"}]},{"type":"search_result_group","domain":"metr.org","entries":[{"type":"search_result","url":"https://evaluations.metr.org/openai-o3-report/?utm_source=chatgpt.com","title":"Details about METR's preliminary evaluation of o3 and o4- ...","snippet":"For example, in our evaluation of o1, we saw a precursor to our time horizon measurements more than double with three engineer-weeks of elicitation. We had ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"metr.org"},{"type":"search_result","url":"https://evaluations.metr.org/gpt-5-report/?utm_source=chatgpt.com","title":"Details about METR's evaluation of OpenAI GPT-5","snippet":"Models' 50% Time Horizon chart double trendline. We find the 80%-time horizon to be around 25m (8m - 65m 95% CI), compared to OpenAI o3's and Claude Opus 4's ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":31},"pub_date":null,"attribution":"metr.org"}]},{"type":"search_result_group","domain":"youtube.com","entries":[{"type":"search_result","url":"https://www.youtube.com/c/DataDrivenNYC?utm_source=chatgpt.com","title":"The MAD Podcast with Matt Turck","snippet":"In-depth conversations with leaders in ML, AI and Data (MAD), hosted by Matt Turck, Partner at FirstMark, an early stage venture capital firm based in New York.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":20},"pub_date":null,"attribution":"youtube.com"},{"type":"search_result","url":"https://www.youtube.com/watch?v=XTVu6K5i88c&utm_source=chatgpt.com","title":"Cursor + Claude Sonnet 3.5 tutorial #codeeditor #ai #claudeai ...","snippet":"... Cursor Code Editor\u2014especially its integration with Cloud Sonnet 3.5. After using Cursor for the past few months, I'm excited to share why ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"youtube.com"}]},{"type":"search_result_group","domain":"inkeep.com","entries":[{"type":"search_result","url":"https://inkeep.com/blog/context-anxiety?utm_source=chatgpt.com","title":"Context Anxiety: How AI Agents Panic About Their ...","snippet":"Oct 3, 2025 \u2014 When Cognition AI rebuilt Devin for Claude Sonnet 4.5, they discovered something unexpected: the model was anxious about its own context window.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":19},"pub_date":null,"attribution":"inkeep.com"}]},{"type":"search_result_group","domain":"benjamincongdon.me","entries":[{"type":"search_result","url":"https://benjamincongdon.me/blog/2025/02/02/How-I-Use-AI-Early-2025/?utm_source=chatgpt.com","title":"How I Use AI: Early 2025","snippet":"2 Feb 2025 \u2014 Cursor: I use Cursor for personal coding projects, especially when working with smaller or greenfield codebases. I almost always use Sonnet 3.5.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":19},"pub_date":null,"attribution":"benjamincongdon.me"}]},{"type":"search_result_group","domain":"swebench.com","entries":[{"type":"search_result","url":"https://www.swebench.com/?utm_source=chatgpt.com","title":"SWE-bench Leaderboards","snippet":"SWE-bench Logo Leaderboards ; \u2713. Claude 4.5 Sonnet (20250929). 70.60, $0.56. 2025-09-29 ; \u2713. Claude 4 Opus (20250514). 67.60, $1.13. 2025-08-02 ...See more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":21},"pub_date":null,"attribution":"swebench.com"}]},{"type":"search_result_group","domain":"x.com","entries":[{"type":"search_result","url":"https://x.com/mattturck/status/1973779093616271695?utm_source=chatgpt.com","title":"Matt Turck","snippet":"Sonnet 4.5 & the AI Plateau Myth \u2014 epic conversation with @_sholtodouglas of @AnthropicAI 0:00 - Intro 1:09 - What's Behind The Rapid Pace ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":24},"pub_date":null,"attribution":"x.com"}]},{"type":"search_result_group","domain":"marketingaiinstitute.com","entries":[{"type":"search_result","url":"https://www.marketingaiinstitute.com/blog/openai-gdpval?utm_source=chatgpt.com","title":"OpenAI's New Benchmark Shows AI Does Knowledge ...","snippet":"Sep 30, 2025 \u2014 OpenAI's research found that frontier models can complete the GDPval tasks approximately 100 times faster and 100 times cheaper than human ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":27},"pub_date":null,"attribution":"marketingaiinstitute.com"}]},{"type":"search_result_group","domain":"replicate.com","entries":[{"type":"search_result","url":"https://replicate.com/anthropic/claude-4.5-sonnet?utm_source=chatgpt.com","title":"Claude 4.5 Sonnet | Anthropic","snippet":"Sep 30, 2025 \u2014 Score, Notes. SWE-bench Verified, 77.2% (avg. 10 trials), 200K thinking budget, no test-time compute on 500 problems; high-compute variant at ...See more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":30},"pub_date":null,"attribution":"replicate.com"}]},{"type":"search_result_group","domain":"threads.com","entries":[{"type":"search_result","url":"https://www.threads.com/%40sung.kim.mw/post/DPM6KRiEqig/rebuilding-devin-for-claude-sonnet-45-lessons-and-challengeswhy-rebuild-instead-?hl=en&utm_source=chatgpt.com","title":"Rebuilding Devin for Claude Sonnet 4.5","snippet":"Sep 29, 2025 \u2014 Rebuilding Devin for Claude Sonnet 4.5: Lessons and Challenges. \"Why rebuild instead of just dropping the new Sonnet in place and calling it ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":33},"pub_date":null,"attribution":"threads.com"}]},{"type":"search_result_group","domain":"firstmark.com","entries":[{"type":"search_result","url":"https://firstmark.com/community/the-mad-podcast/?utm_source=chatgpt.com","title":"The MAD Podcast with Matt Turck - FirstMark","snippet":"Inside Anthropic's Sonnet 4.5 \u2014 Sholto Douglas & the Race to AGI. Ex\u2011DeepMind Researcher Misha Laskin on Enterprise Super\u2011Intelligence | Reflection AI.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":34},"pub_date":null,"attribution":"firstmark.com"}]},{"type":"search_result_group","domain":"alignmentforum.org","entries":[{"type":"search_result","url":"https://www.alignmentforum.org/posts/deesrjitvXM4xYGZd/metr-measuring-ai-ability-to-complete-long-tasks?utm_source=chatgpt.com","title":"METR: Measuring AI Ability to Complete Long Tasks","snippet":"Mar 19, 2025 \u2014 We show that this metric has been consistently exponentially increasing over the past 6 years, with a doubling time of around 7 months.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":36},"pub_date":null,"attribution":"alignmentforum.org"}]},{"type":"search_result_group","domain":"fortune.com","entries":[{"type":"search_result","url":"https://fortune.com/2025/09/30/ai-models-are-already-as-good-as-experts-at-half-of-tasks-a-new-openai-benchmark-gdpval-suggests/?utm_source=chatgpt.com","title":"AI models are already as good as experts at half of tasks ...","snippet":"Sep 30, 2025 \u2014 OpenAI's revenue surges\u2014but its burn rate remains dramatic. The AI company generated about $4.3 billion in the first half of 2025\u2014up 16% on all ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":37},"pub_date":null,"attribution":"fortune.com"}]},{"type":"search_result_group","domain":"mattturck.com","entries":[{"type":"search_result","url":"https://www.mattturck.com/podcast?utm_source=chatgpt.com","title":"MAD Podcast","snippet":"Sholto Douglas, a key researcher at Anthropic, reveals the breakthroughs behind Claude Sonnet 4.5\u2014the world's leading coding model\u2014and why we might be just 2-3 ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":38},"pub_date":null,"attribution":"mattturck.com"}]},{"type":"search_result_group","domain":"promptlayer.com","entries":[{"type":"search_result","url":"https://blog.promptlayer.com/claude-sonnet-4-5-first-reactions/?utm_source=chatgpt.com","title":"Claude Sonnet 4.5: First Reactions","snippet":"Oct 15, 2025 \u2014 Claude Sonnet 4.5 achieved a 70.6% score on SWE-bench Verified, a real-world coding benchmark that measures how well AI can solve actual GitHub ...See more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":39},"pub_date":null,"attribution":"promptlayer.com"}]},{"type":"search_result_group","domain":"huggingface.co","entries":[{"type":"search_result","url":"https://huggingface.co/datasets/openai/gdpval?utm_source=chatgpt.com","title":"openai/gdpval \u00b7 Datasets at Hugging Face","snippet":"Reporting is being completed in January 2025 for an as-of date of December 31, 2024. Use the attached reference files, which include income, costs, and tax ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":41},"pub_date":null,"attribution":"huggingface.co"}]},{"type":"search_result_group","domain":"towardsai.net","entries":[{"type":"search_result","url":"https://pub.towardsai.net/does-cognition-ai-matter-when-we-already-have-claude-code-cursor-and-copilot-648e047fda94?source=rss------artificial_intelligence-5&utm_source=chatgpt.com","title":"Does Cognition AI Matter When We Already Have Claude ...","snippet":"1 hour ago \u2014 Under the hood, Devin runs on Claude Sonnet 4.5, layered with reinforcement learning and agent scaffolding. Founded in November 2023 by ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":42},"pub_date":null,"attribution":"towardsai.net"}]},{"type":"search_result_group","domain":"spotify.com","entries":[{"type":"search_result","url":"https://open.spotify.com/show/7yLATDSaFvgJG80ACcRJtq?utm_source=chatgpt.com","title":"The MAD Podcast with Matt Turck","snippet":"Sonnet 4.5 & the AI Plateau Myth \u2014 Sholto Douglas (Anthropic). Sholto Douglas, a top AI researcher at Anthropic, discusses the breakthroughs behind Claude ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":43},"pub_date":null,"attribution":"spotify.com"}]}],"citations":[],"request_id":"e6556653-9257-4885-ac4b-6d448106e243","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"628fd37a-be2b-402f-9b5a-f5d93547bf24","turn_exchange_id":"0ad37490-ab6b-4240-bf77-c7b311582bdc","timestamp_":"absolute","can_save":true},"recipient":"all","channel":"final"},"parent":"628fd37a-be2b-402f-9b5a-f5d93547bf24","children":[]}}}