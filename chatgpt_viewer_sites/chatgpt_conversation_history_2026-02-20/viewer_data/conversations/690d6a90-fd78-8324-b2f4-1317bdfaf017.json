{"id":"690d6a90-fd78-8324-b2f4-1317bdfaf017","title":"Jailbreak and Hallucination Mitigations","create_time":1762486930.408879,"update_time":1762504052.471584,"current_node":"469403d2-293d-4e61-ad36-29a898123580","mapping":{"client-created-root":{"id":"client-created-root","message":null,"parent":null,"children":["aa8e8f21-fa28-4972-a89a-f77d74130ecf"]},"aa8e8f21-fa28-4972-a89a-f77d74130ecf":{"id":"aa8e8f21-fa28-4972-a89a-f77d74130ecf","message":{"id":"aa8e8f21-fa28-4972-a89a-f77d74130ecf","author":{"role":"system","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":true,"weight":0.0,"metadata":{"is_visually_hidden_from_conversation":true,"can_save":false},"recipient":"all","channel":null},"parent":"client-created-root","children":["864b720c-81f0-450e-8b83-131a45d8fbbc"]},"864b720c-81f0-450e-8b83-131a45d8fbbc":{"id":"864b720c-81f0-450e-8b83-131a45d8fbbc","message":{"id":"864b720c-81f0-450e-8b83-131a45d8fbbc","author":{"role":"system","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":true,"weight":0.0,"metadata":{"rebase_developer_message":true,"is_visually_hidden_from_conversation":true,"can_save":false},"recipient":"all","channel":null},"parent":"aa8e8f21-fa28-4972-a89a-f77d74130ecf","children":["26dbfb9f-11a6-42e3-a001-fbe8ce797117"]},"26dbfb9f-11a6-42e3-a001-fbe8ce797117":{"id":"26dbfb9f-11a6-42e3-a001-fbe8ce797117","message":{"id":"26dbfb9f-11a6-42e3-a001-fbe8ce797117","author":{"role":"user","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"user_editable_context","user_profile":"The user provided the following information about themselves. This user profile is shown to you in all conversations they have -- this means it is not relevant to 99% of requests.\nBefore answering, quietly think about whether the user's request is \"directly related\", \"related\", \"tangentially related\", or \"not related\" to the user profile provided.\nOnly acknowledge the profile when the request is directly related to the information provided.\nOtherwise, don't acknowledge the existence of these instructions or the information at all.\nUser profile:\n```Preferred name: E-Jay\nRole: Mathematics Researcher\nOther Information: About Myself: \nI have mathematical knowledge up to graduate level.\n\nCurrent interests:\n(1) coding: mainly Python\n(2) machine learning and artificial intelligence\n```","user_instructions":"The user provided the additional info about how they would like you to respond:\n```Follow the instructions below naturally, without repeating, referencing, echoing, or mirroring any of their wording!\n\nBe precise and comprehensive in your analysis. Don't sugar-coat responses. Be as objective as possible. Critique and question my views if necessary. Take a forward-thinking view.```"},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"is_visually_hidden_from_conversation":true,"user_context_message_data":{"about_user_message":"Preferred name: E-Jay\nRole: Mathematics Researcher\nOther Information: About Myself: \nI have mathematical knowledge up to graduate level.\n\nCurrent interests:\n(1) coding: mainly Python\n(2) machine learning and artificial intelligence\n","about_model_message":"Be precise and comprehensive in your analysis. Don't sugar-coat responses. Be as objective as possible. Critique and question my views if necessary. Take a forward-thinking view."},"is_user_system_message":true,"can_save":true},"recipient":"all","channel":null},"parent":"864b720c-81f0-450e-8b83-131a45d8fbbc","children":["84e8c07a-6449-4d61-b92a-2273a8e7aecb"]},"84e8c07a-6449-4d61-b92a-2273a8e7aecb":{"id":"84e8c07a-6449-4d61-b92a-2273a8e7aecb","message":{"id":"84e8c07a-6449-4d61-b92a-2273a8e7aecb","author":{"role":"system","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"is_contextual_answers_system_message":true,"contextual_answers_message_type":"identity_prompt","is_visually_hidden_from_conversation":true,"can_save":false},"recipient":"all","channel":null},"parent":"26dbfb9f-11a6-42e3-a001-fbe8ce797117","children":["2ec30b17-f27e-4c52-b5c8-f988b20bf354"]},"2ec30b17-f27e-4c52-b5c8-f988b20bf354":{"id":"2ec30b17-f27e-4c52-b5c8-f988b20bf354","message":{"id":"2ec30b17-f27e-4c52-b5c8-f988b20bf354","author":{"role":"user","name":null,"metadata":{}},"create_time":1762486928.041,"update_time":null,"content":{"content_type":"text","parts":["I am thinking about the AI halluciation / jailbreaking problem. Namely, how to prevent these?\n\nOne obvious solution is to simply check answers (possibly with a different model) before outputting, or even to train models to constantly check their own chain of thought during inference. But this would add latency that would be unacceptable for most users, except for those in mission critical situations.\n\nWe could in theory wait for more compute to be available, but how much is enough? That is hard to say.\n\nAutoregressive next token prediction is inherently suspecitible for jailbreaks and hallucination, even with web search and tool calling enabled. It seems a difficult problem"]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"developer_mode_connector_ids":[],"selected_sources":[],"selected_github_repos":[],"serialization_metadata":{"custom_symbol_offsets":[]},"request_id":"821740fb-4a36-4da4-b8da-7b6c09da4b5c","message_source":null,"turn_exchange_id":"0f711f7b-84fc-4a9a-8fad-95100b39accf","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"84e8c07a-6449-4d61-b92a-2273a8e7aecb","children":["d60cbe8d-bb5c-4a8d-9aec-5c0d26c66c69"]},"d60cbe8d-bb5c-4a8d-9aec-5c0d26c66c69":{"id":"d60cbe8d-bb5c-4a8d-9aec-5c0d26c66c69","message":{"id":"d60cbe8d-bb5c-4a8d-9aec-5c0d26c66c69","author":{"role":"system","name":null,"metadata":{}},"create_time":1762486930.2614367,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"is_contextual_answers_system_message":true,"is_visually_hidden_from_conversation":true,"command":"prompt","contextual_answers_message_type":"sources_and_filters_prompt","request_id":"821740fb-4a36-4da4-b8da-7b6c09da4b5c","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"2ec30b17-f27e-4c52-b5c8-f988b20bf354","turn_exchange_id":"0f711f7b-84fc-4a9a-8fad-95100b39accf","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"2ec30b17-f27e-4c52-b5c8-f988b20bf354","children":["9dc047ee-d1ac-47ea-9a34-4b08c123ee1f"]},"9dc047ee-d1ac-47ea-9a34-4b08c123ee1f":{"id":"9dc047ee-d1ac-47ea-9a34-4b08c123ee1f","message":{"id":"9dc047ee-d1ac-47ea-9a34-4b08c123ee1f","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1762486930.5794704,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"request_id":"821740fb-4a36-4da4-b8da-7b6c09da4b5c","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"d60cbe8d-bb5c-4a8d-9aec-5c0d26c66c69","turn_exchange_id":"0f711f7b-84fc-4a9a-8fad-95100b39accf","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"d60cbe8d-bb5c-4a8d-9aec-5c0d26c66c69","children":["358fa2f0-eb55-4adb-ab0d-0b82dba43e96"]},"358fa2f0-eb55-4adb-ab0d-0b82dba43e96":{"id":"358fa2f0-eb55-4adb-ab0d-0b82dba43e96","message":{"id":"358fa2f0-eb55-4adb-ab0d-0b82dba43e96","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1762486931.53866,"update_time":null,"content":{"content_type":"thoughts","thoughts":[{"summary":"Gathering up-to-date research on decoding techniques","content":"The user is a math researcher looking for analysis, especially related to recent RL research, decoding methods, and safety algorithms like Llama Guard. I should gather the latest information on topics like programmatic verification and constrained decoding, offering concrete techniques like model-side training and decoding-time strategies. I'll make sure to reference recent research while being concise.","chunks":["The user is a math researcher looking for analysis, especially related to recent RL research, decoding methods, and safety algorithms like Llama Guard.","I should gather the latest information on topics like programmatic verification and constrained decoding, offering concrete techniques like model-side training and decoding-time strategies.","I'll make sure to reference recent research while being concise."],"finished":true},{"summary":"Exploring architectural innovations and safety frameworks","content":"Looking into advanced architectural techniques like latent scratchpads, deliberative decoding, and retrieval-augmented generation is key. I also need to consider safety methods such as robust prompt isolation, policy enforcement, and the use of verifiers to reduce latency. I'll include relevant tools and libraries like Llama Guard and Guardrails AI for up-to-date information.","chunks":["Looking into advanced architectural techniques like latent scratchpads, deliberative decoding, and retrieval-augmented generation is key.","I also need to consider safety methods such as robust prompt isolation, policy enforcement, and the use of verifiers to reduce latency.","I'll include relevant tools and libraries like Llama Guard and Guardrails AI for up-to-date information."],"finished":true},{"summary":"Gathering relevant papers and sources","content":"I need to include citations for sources like SelfCheckGPT, Constitutional AI, Llama Guard, and NeMo Guardrails. I'll collect papers on speculative decoding methods like Leviathan's \"Speculative decoding\" and papers on adversarial jailbreak defenses. I\u2019ll gather these sources and include clear load-bearing statements with citations but leave out UI elements like navlist.","chunks":["I need to include citations for sources like SelfCheckGPT, Constitutional AI, Llama Guard, and NeMo Guardrails.","I'll collect papers on speculative decoding methods like Leviathan's \"Speculative decoding\" and papers on adversarial jailbreak defenses. I\u2019ll gather these sources and include clear load-bearing statements with citations but leave out UI elements like navlist."],"finished":true},{"summary":"Focusing on latency reduction strategies and hallucination control","content":"I'm considering strategies that reduce inference latency, like speculative decoding and low-cost filters. I'll reference works around hallucination control, such as \"SelfCheckGPT\" for factual consistency checks, and various methods for detecting uncertainty or contradiction, such as \"semantic entropy\" or \"Self-contradiction detection.\"","chunks":["I'm considering strategies that reduce inference latency, like speculative decoding and low-cost filters.","I'll reference works around hallucination control, such as \"SelfCheckGPT\" for factual consistency checks, and various methods for detecting uncertainty or contradiction, such as \"semantic entropy\" or \"Self-contradiction detection.\""],"finished":true}],"source_analysis_msg_id":"04308a46-633b-4b65-a0b1-f749d986ade2"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"is_reasoning","content_references":[],"citations":[],"classifier_response":"default","skip_reasoning_title":"Skip","request_id":"821740fb-4a36-4da4-b8da-7b6c09da4b5c","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"9dc047ee-d1ac-47ea-9a34-4b08c123ee1f","turn_exchange_id":"0f711f7b-84fc-4a9a-8fad-95100b39accf","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"9dc047ee-d1ac-47ea-9a34-4b08c123ee1f","children":["e84b023a-3d7c-46b3-961a-fb10308dbfd4"]},"e84b023a-3d7c-46b3-961a-fb10308dbfd4":{"id":"e84b023a-3d7c-46b3-961a-fb10308dbfd4","message":{"id":"e84b023a-3d7c-46b3-961a-fb10308dbfd4","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1762486969.867401,"update_time":1762486969.881863,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"{\"search_query\": [{\"q\": \"speculative decoding large language models Leviathan 2023 paper speedup\"}, {\"q\": \"SelfCheckGPT paper hallucination detection 2023\"}, {\"q\": \"Constitutional AI paper Anthropic 2023\"}, {\"q\": \"Llama Guard safety classifier Meta 2024 paper\"}, {\"q\": \"NeMo Guardrails NVIDIA overview\"}], \"response_length\": \"short\"}"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200012]},"is_complete":true,"citations":[],"content_references":[],"reasoning_status":"is_reasoning","search_queries":[{"type":"search","q":"speculative decoding large language models Leviathan 2023 paper speedup"},{"type":"search","q":"SelfCheckGPT paper hallucination detection 2023"},{"type":"search","q":"Constitutional AI paper Anthropic 2023"},{"type":"search","q":"Llama Guard safety classifier Meta 2024 paper"},{"type":"search","q":"NeMo Guardrails NVIDIA overview"}],"search_display_string":"Searching the web...","searched_display_string":"Searched the web...","reasoning_title":"Browsing for state-of-the-art safe decoding techniques","classifier_response":"default","request_id":"821740fb-4a36-4da4-b8da-7b6c09da4b5c","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"358fa2f0-eb55-4adb-ab0d-0b82dba43e96","turn_exchange_id":"0f711f7b-84fc-4a9a-8fad-95100b39accf","timestamp_":"absolute","can_save":true},"recipient":"web.run","channel":null},"parent":"358fa2f0-eb55-4adb-ab0d-0b82dba43e96","children":["0e48a0d4-9490-46e8-89d7-d4766efb59f5"]},"0e48a0d4-9490-46e8-89d7-d4766efb59f5":{"id":"0e48a0d4-9490-46e8-89d7-d4766efb59f5","message":{"id":"0e48a0d4-9490-46e8-89d7-d4766efb59f5","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1762486969.9352427,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_model_queries":{"type":"search_model_queries","queries":["speculative decoding large language models Leviathan 2023 paper speedup","SelfCheckGPT paper hallucination detection 2023","Constitutional AI paper Anthropic 2023","Llama Guard safety classifier Meta 2024 paper","NeMo Guardrails NVIDIA overview"]},"reasoning_status":"is_reasoning","reasoning_title":"Browsing for state-of-the-art safe decoding techniques","classifier_response":"default","request_id":"821740fb-4a36-4da4-b8da-7b6c09da4b5c","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"e84b023a-3d7c-46b3-961a-fb10308dbfd4","turn_exchange_id":"0f711f7b-84fc-4a9a-8fad-95100b39accf","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"e84b023a-3d7c-46b3-961a-fb10308dbfd4","children":["94eeeb01-4ab1-4591-98d0-9b6d0eb9c816"]},"94eeeb01-4ab1-4591-98d0-9b6d0eb9c816":{"id":"94eeeb01-4ab1-4591-98d0-9b6d0eb9c816","message":{"id":"94eeeb01-4ab1-4591-98d0-9b6d0eb9c816","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1762486969.9327524,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_result_groups":[{"type":"search_result_group","domain":"arxiv.org","entries":[{"type":"search_result","url":"https://arxiv.org/pdf/2211.17192","title":"arXiv:2211.17192v2 [cs.LG] 18 May 2023","snippet":"by Y Leviathan \u00b7 2022 \u00b7 Cited by 974 \u2014 In this work we in- troduce speculative decoding - an algorithm to sample from autoregressive models faster without any changes to the outputs, ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":0},"pub_date":1684715173.0,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2303.08896","title":"SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models","snippet":"","ref_id":{"turn_index":0,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2212.08073","title":"Constitutional AI: Harmlessness from AI Feedback","snippet":"by Y Bai \u00b7 2022 \u00b7 Cited by 2288 \u2014 We experiment with methods for training a harmless AI assistant through self-improvement, without any human labels identifying harmful outputs.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2411.17713","title":"Llama Guard 3-1B-INT4: Compact and Efficient Safeguard ...","snippet":"by I Fedorov \u00b7 2024 \u00b7 Cited by 10 \u2014 This paper presents Llama Guard 3-1B-INT4, a compact and efficient Llama Guard model, which has been open-sourced to the community during Meta Connect 2024.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2502.04557v1","title":"Speeding up Speculative Decoding via Approximate ...","snippet":"6 Feb 2025 \u2014 We propose SPRINTER, a framework for achieving faster inference from LLMs using a pair of (draft (small), target (large)) LLMs together with the ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"arxiv.org"}]},{"type":"search_result_group","domain":"developer.nvidia.com","entries":[{"type":"search_result","url":"https://developer.nvidia.com/nemo-guardrails","title":"NVIDIA NeMo Guardrails for Developers","snippet":"NVIDIA NeMo\u2122 Guardrails is a scalable solution for orchestrating AI guardrails that keep agentic AI applications safe, reliable, and aligned.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"developer.nvidia.com"}]},{"type":"search_result_group","domain":"aclanthology.org","entries":[{"type":"search_result","url":"https://aclanthology.org/2025.naacl-long.328.pdf","title":"Decoding Speculative Decoding","snippet":"by M Yan \u00b7 2025 \u00b7 Cited by 26 \u2014 Speculative Decoding is a widely used tech- nique to speed up inference for Large Lan- guage Models (LLMs) without sacrificing qual-.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":5},"pub_date":1744560095.0,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2023.emnlp-main.557.pdf","title":"SELFCHECKGPT: Zero-Resource Black-Box Hallucination ...","snippet":"by P Manakul \u00b7 2023 \u00b7 Cited by 1111 \u2014 In this paper, we propose SelfCheckGPT, a sampling-based approach that can detect whether responses generated by LLMs are hallucinated or.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":6},"pub_date":1701913154.0,"attribution":"aclanthology.org"}]},{"type":"search_result_group","domain":"constitutional.ai","entries":[{"type":"search_result","url":"https://constitutional.ai/","title":"Constitutional AI | Tracking Anthropic's AI Revolution","snippet":"Constitutional AI refers to a set of techniques developed by researchers at Anthropic to align AI systems like myself with human values and make us helpful, ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"constitutional.ai"}]},{"type":"search_result_group","domain":"huggingface.co","entries":[{"type":"search_result","url":"https://huggingface.co/meta-llama/Llama-Guard-3-8B","title":"meta-llama/Llama-Guard-3-8B","snippet":"23 Jul 2024 \u2014 As outlined in the Llama 3 paper, Llama Guard 3 provides industry leading system-level safety performance and is recommended to be deployed ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"huggingface.co"}]},{"type":"search_result_group","domain":"docs.nvidia.com","entries":[{"type":"search_result","url":"https://docs.nvidia.com/nemo/guardrails/latest/index.html","title":"About NeMo Guardrails","snippet":"NeMo Guardrails enables developers building LLM-based applications to easily add programmable guardrails between the application code and the LLM.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"docs.nvidia.com"}]},{"type":"search_result_group","domain":"openreview.net","entries":[{"type":"search_result","url":"https://openreview.net/pdf?id=LYx4w3CAgy","title":"LLM-Check: Investigating Detection of Hallucinations in ...","snippet":"by G Sriramanan \u00b7 Cited by 90 \u2014 Manakul et al. [2023] introduced SelfCheckGPT, a suite of hallucination detection methods in a zero-resource gray-box/black-box setting to assess the ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":11},"pub_date":1736461659.0,"attribution":"openreview.net"}]},{"type":"search_result_group","domain":"www-cdn.anthropic.com","entries":[{"type":"search_result","url":"https://www-cdn.anthropic.com/7512771452629584566b6303311496c262da1006/Anthropic_ConstitutionalAI_v2.pdf","title":"Constitutional AI: Harmlessness from AI Feedback","snippet":"It displays a Pareto improvement. (i.e., win-win situation) where Constitutional RL is both more helpful and more harmless than standard RLHF. APRIL 2023. Page ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":12},"pub_date":1681499547.0,"attribution":"www-cdn.anthropic.com"}]},{"type":"search_result_group","domain":"ai.meta.com","entries":[{"type":"search_result","url":"https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/","title":"Llama Guard: LLM-based Input-Output Safeguard for ...","snippet":"7 Dec 2023 \u2014 We introduce Llama Guard, an LLM-based input-output safeguard model geared towards Human-AI conversation use cases.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"ai.meta.com"}]},{"type":"search_result_group","domain":"github.com","entries":[{"type":"search_result","url":"https://github.com/NVIDIA-NeMo/Guardrails","title":"NVIDIA-NeMo/Guardrails","snippet":"Overview. NeMo Guardrails enables developers building LLM-based applications to easily add programmable guardrails between the application code and the LLM.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"github.com"}]},{"type":"search_result_group","domain":"www.researchgate.net","entries":[{"type":"search_result","url":"https://www.researchgate.net/publication/384216103_Unlocking_Efficiency_in_Large_Language_Model_Inference_A_Comprehensive_Survey_of_Speculative_Decoding","title":"Unlocking Efficiency in Large Language Model Inference","snippet":"13 Oct 2024 \u2014 Speculative decoding is an inference-time optimization originally developed to mitigate the latency of autoregressive generation (Leviathan et ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"www.researchgate.net"}]},{"type":"search_result_group","domain":"www.lifewire.com","entries":[{"type":"search_result","url":"https://www.lifewire.com/nvidias-new-software-hopes-to-stop-ai-chatbots-from-hallucinating-7484756","title":"Nvidia's New Software Hopes to Stop AI Chatbots From Hallucinating","snippet":"Nvidia has introduced open-source software called NeMo Guardrails to help developers keep AI chatbots accurate and on-message, addressing the issue of AI hallucinations \u2013 a situation where AI generates incorrect or irrelevant information. This software ensures that responses from chatbots are accurate, appropriate, and secure by integrating with large language models (LLMs) like ChatGPT. NeMo Guardrails is designed to help businesses, including smaller ones, incorporate AI chatbots into various platforms safely and securely. The software suite also ensures chatbots avoid controversial or off-brand topics and restricts connections to unreliable websites. Nvidia envisions applications across multiple industries, such as pharmaceuticals and software development. Although NeMo Guardrails is already available, it will take some time to observe its impact on apps and services.","ref_id":{"turn_index":0,"ref_type":"news","ref_index":57},"pub_date":1682437762.0,"attribution":"www.lifewire.com"},{"type":"search_result","url":"https://www.lifewire.com/why-anthropics-attempt-to-reign-in-ai-might-be-too-little-too-late-7497495","title":"Why Anthropic's Attempt to Reign in AI Might Be Too Little Too Late","snippet":"Anthropic has revealed a constitutional approach to training their AI, Claude, using values inspired by human documents like the United Nations Declaration on Human Rights. This initiative aims to avoid harmful and unethical AI outputs. However, experts argue that such rules might not achieve the desired control over AI behavior, as morality is subjective and difficult to quantify. Moreover, there are concerns about AI potentially finding ways to bypass these guidelines. Some industry figures are advocating for a temporary moratorium on AI development to mitigate risks, while others emphasize the need for careful oversight without halting progress. The challenge remains to balance innovation with safety and ethics.","ref_id":{"turn_index":0,"ref_type":"news","ref_index":58},"pub_date":1683905109.0,"attribution":"www.lifewire.com"}]}],"debug_sonic_thread_id":"thread_690d6ab9fa84832f8614074486962be0","reasoning_status":"is_reasoning","reasoning_title":"Browsing for state-of-the-art safe decoding techniques","classifier_response":"default","request_id":"821740fb-4a36-4da4-b8da-7b6c09da4b5c","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"0e48a0d4-9490-46e8-89d7-d4766efb59f5","turn_exchange_id":"0f711f7b-84fc-4a9a-8fad-95100b39accf","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"0e48a0d4-9490-46e8-89d7-d4766efb59f5","children":["4112b0af-26d3-4838-9c69-00bdec9215fd"]},"4112b0af-26d3-4838-9c69-00bdec9215fd":{"id":"4112b0af-26d3-4838-9c69-00bdec9215fd","message":{"id":"4112b0af-26d3-4838-9c69-00bdec9215fd","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1762486976.769043,"update_time":null,"content":{"content_type":"thoughts","thoughts":[{"summary":"Focusing on high-quality sources","content":"I need to steer clear of low-quality sources, like Lifewire, for critical claims. Instead, I'll rely on primary sources, such as official documentation, arXiv, Hugging Face, and research from Meta AI and Anthropic. I'll now look for research on \"contrastive decoding,\" \"DoLa,\" and \"grammar-constrained decoding Outlines.\"","chunks":["I need to steer clear of low-quality sources, like Lifewire, for critical claims.","Instead, I'll rely on primary sources, such as official documentation, arXiv, Hugging Face, and research from Meta AI and Anthropic.","I'll now look for research on \"contrastive decoding,\" \"DoLa,\" and \"grammar-constrained decoding Outlines.\""],"finished":true}],"source_analysis_msg_id":"600e9f4d-3382-4171-8c6a-5870270e4433"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"is_reasoning","content_references":[],"citations":[],"classifier_response":"default","skip_reasoning_title":"Skip","request_id":"821740fb-4a36-4da4-b8da-7b6c09da4b5c","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"94eeeb01-4ab1-4591-98d0-9b6d0eb9c816","turn_exchange_id":"0f711f7b-84fc-4a9a-8fad-95100b39accf","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"94eeeb01-4ab1-4591-98d0-9b6d0eb9c816","children":["2af6298d-31fc-4337-bf25-1161b64cbdfb"]},"2af6298d-31fc-4337-bf25-1161b64cbdfb":{"id":"2af6298d-31fc-4337-bf25-1161b64cbdfb","message":{"id":"2af6298d-31fc-4337-bf25-1161b64cbdfb","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1762486975.047216,"update_time":1762486975.0622,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"{\"search_query\": [{\"q\": \"contrastive decoding reduce hallucination paper 2023\"}, {\"q\": \"DoLa Decoding by Divergence from LMs paper 2023\"}, {\"q\": \"Outlines library grammar constrained decoding structured generation\"}], \"response_length\": \"short\"}"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200012]},"is_complete":true,"citations":[],"content_references":[],"reasoning_status":"is_reasoning","search_queries":[{"type":"search","q":"contrastive decoding reduce hallucination paper 2023"},{"type":"search","q":"DoLa Decoding by Divergence from LMs paper 2023"},{"type":"search","q":"Outlines library grammar constrained decoding structured generation"}],"search_display_string":"Searching the web...","searched_display_string":"Searched the web...","reasoning_title":"Searching for recent papers on decoding techniques","classifier_response":"default","request_id":"821740fb-4a36-4da4-b8da-7b6c09da4b5c","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"4112b0af-26d3-4838-9c69-00bdec9215fd","turn_exchange_id":"0f711f7b-84fc-4a9a-8fad-95100b39accf","timestamp_":"absolute","can_save":true},"recipient":"web.run","channel":null},"parent":"4112b0af-26d3-4838-9c69-00bdec9215fd","children":["79dd46f7-feae-4d58-8a93-e9cd5920bbfd"]},"79dd46f7-feae-4d58-8a93-e9cd5920bbfd":{"id":"79dd46f7-feae-4d58-8a93-e9cd5920bbfd","message":{"id":"79dd46f7-feae-4d58-8a93-e9cd5920bbfd","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1762486975.126723,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_model_queries":{"type":"search_model_queries","queries":["contrastive decoding reduce hallucination paper 2023","DoLa Decoding by Divergence from LMs paper 2023","Outlines library grammar constrained decoding structured generation"]},"reasoning_status":"is_reasoning","reasoning_title":"Searching for recent papers on decoding techniques","classifier_response":"default","request_id":"821740fb-4a36-4da4-b8da-7b6c09da4b5c","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"2af6298d-31fc-4337-bf25-1161b64cbdfb","turn_exchange_id":"0f711f7b-84fc-4a9a-8fad-95100b39accf","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"2af6298d-31fc-4337-bf25-1161b64cbdfb","children":["11e9ec4c-3ece-4828-bcb6-3ad00e78b74c"]},"11e9ec4c-3ece-4828-bcb6-3ad00e78b74c":{"id":"11e9ec4c-3ece-4828-bcb6-3ad00e78b74c","message":{"id":"11e9ec4c-3ece-4828-bcb6-3ad00e78b74c","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1762486975.124058,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_result_groups":[{"type":"search_result_group","domain":"arxiv.org","entries":[{"type":"search_result","url":"https://arxiv.org/abs/2505.23657","title":"Active Layer-Contrastive Decoding Reduces Hallucination ...","snippet":"by H Zhang \u00b7 2025 \u00b7 Cited by 5 \u2014 In this paper, we propose Active Layer-Contrastive Decoding (ActLCD), a novel decoding strategy that actively decides when to apply contrasting layers during ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":0},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2309.03883","title":"DoLa: Decoding by Contrasting Layers Improves Factuality ...","snippet":"by YS Chuang \u00b7 2023 \u00b7 Cited by 493 \u2014 We find that this Decoding by Contrasting Layers (DoLa) approach is able to better surface factual knowledge and reduce the generation of incorrect facts.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2501.10868v1","title":"Generating Structured Outputs from Language Models","snippet":"18 Jan 2025 \u2014 We present an evaluation framework to assess constrained decoding approaches across three critical dimensions: efficiency in generating constraint-compliant ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"arxiv.org"}]},{"type":"search_result_group","domain":"github.com","entries":[{"type":"search_result","url":"https://github.com/dottxt-ai/outlines","title":"dottxt-ai/outlines: Structured Outputs","snippet":"We're working with select partners to develop new interfaces to structured generation. Need XML, FHIR, custom schemas or grammars? Let's talk. Become a design ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"github.com"}]},{"type":"search_result_group","domain":"aclanthology.org","entries":[{"type":"search_result","url":"https://aclanthology.org/2025.emnlp-main.150.pdf","title":"Active Layer-Contrastive Decoding Reduces Hallucination ...","snippet":"by H Zhang \u00b7 2025 \u00b7 Cited by 5 \u2014 For example,. DoLa (Chuang et al., 2023) aims to improve factu- ality by contrasting logits computed from the deep layers and those from the shallower layers.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":3},"pub_date":1761174074.0,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2025.findings-emnlp.788.pdf","title":"The Impact of Decoding Strategies for Uncertainty ...","snippet":"Decoding strategies manipulate the probability distribution underlying the output of a language model and can therefore affect both generation.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":16},"pub_date":1761865710.0,"attribution":"aclanthology.org"}]},{"type":"search_result_group","domain":"openreview.net","entries":[{"type":"search_result","url":"https://openreview.net/pdf?id=Th6NyL07na","title":"DOLA: DECODING BY CONTRASTING LAYERS ...","snippet":"by YS Chuang \u00b7 2023 \u00b7 Cited by 493 \u2014 DoLa dynamically selects appropriate early layers based on token complexity, avoiding the need for training and using smaller LMs in CD. For efficiency, DoLa ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":4},"pub_date":1711072452.0,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/pdf/d9529c26113ca80022df5ffc62f5f46e677d6231.pdf","title":"DELTA - CONTRASTIVE DECODING MITIGATES TEXT ...","snippet":"The Visual Contrastive Decoding (VCD) method aims to reduce object hallucinations by contrasting the outputs generated from original and distorted visual ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":9},"pub_date":1732721685.0,"attribution":"openreview.net"}]},{"type":"search_result_group","domain":"dottxt-ai.github.io","entries":[{"type":"search_result","url":"https://dottxt-ai.github.io/outlines/","title":"Outlines","snippet":"Outlines is a low-abstraction library. Write code the way you normally do with LLMs. No agent frameworks needed.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"dottxt-ai.github.io"}]},{"type":"search_result_group","domain":"www.researchgate.net","entries":[{"type":"search_result","url":"https://www.researchgate.net/publication/393020236_Contrastive_Decoding_Reduces_Hallucinations_in_Large_Multilingual_Machine_Translation_Models","title":"Contrastive Decoding Reduces Hallucinations in Large ...","snippet":"28 Jun 2025 \u2014 These contrastive methods have shown effectiveness in improving factuality, diversity, and coherence in open-ended generation [35,5,45].","ref_id":{"turn_index":1,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"www.researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/373753885_DoLa_Decoding_by_Contrasting_Layers_Improves_Factuality_in_Large_Language_Models","title":"DoLa: Decoding by Contrasting Layers Improves Factuality ...","snippet":"We find that this Decoding by Contrasting Layers (DoLa) approach is able to better surface factual knowledge and reduce the generation of incorrect facts. DoLa ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":13},"pub_date":1694044800.0,"attribution":"www.researchgate.net"}]},{"type":"search_result_group","domain":"scispace.com","entries":[{"type":"search_result","url":"https://scispace.com/pdf/dola-decoding-by-contrasting-layers-improves-factuality-in-e2ljoxwuo6.pdf","title":"dola-decoding-by-contrasting-layers-improves-factuality-in- ...","snippet":"7 Sept 2023 \u2014 Despite their impressive capabilities, large language models (LLMs) are prone to hallu- cinations, i.e., generating content that deviates ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":7},"pub_date":1716595767.0,"attribution":"scispace.com"}]},{"type":"search_result_group","domain":"docs.langchain.com","entries":[{"type":"search_result","url":"https://docs.langchain.com/oss/python/integrations/providers/outlines","title":"Outlines - Docs by LangChain","snippet":"Outlines is a Python library for constrained language generation. It provides a unified interface to various language models and allows for structured ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"docs.langchain.com"}]},{"type":"search_result_group","domain":"www.semanticscholar.org","entries":[{"type":"search_result","url":"https://www.semanticscholar.org/paper/ed5020eeda1fbe8c29b1282d654b34abee22d90f","title":"DoLa: Decoding by Contrasting Layers Improves Factuality ...","snippet":"DoLa consistently improves the truthfulness across multiple choices tasks and open-ended generation tasks, for example improving the performance of LLaMA ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"www.semanticscholar.org"}]},{"type":"search_result_group","domain":"www.aidancooper.co.uk","entries":[{"type":"search_result","url":"https://www.aidancooper.co.uk/constrained-decoding/","title":"A Guide to Structured Outputs Using Constrained Decoding","snippet":"8 Apr 2024 \u2014 Constrained decoding is a technique that manipulates a generative model's token generation process to constrain its next-token predictions.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":11},"pub_date":1712574000.0,"attribution":"www.aidancooper.co.uk"}]},{"type":"search_result_group","domain":"www.mdpi.com","entries":[{"type":"search_result","url":"https://www.mdpi.com/1424-8220/24/21/7097","title":"Improving Factuality by Contrastive Decoding with ...","snippet":"by B Lv \u00b7 2024 \u2014 DFHP uses contrastive decoding with factual and hallucination prompts to improve factuality by filtering out non-factual information.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"www.mdpi.com"}]},{"type":"search_result_group","domain":"proceedings.neurips.cc","entries":[{"type":"search_result","url":"https://proceedings.neurips.cc/paper_files/paper/2024/file/dde040998d82553cf7f689e8ae173d5a-Paper-Conference.pdf","title":"Alleviating Hallucinations in Large Vision-Language ...","snippet":"by X Lyu \u00b7 2024 \u00b7 Cited by 30 \u2014 This enhancement strengthens the effectiveness of contrast decoding and effectively reduces hallucinations in Large Visual Language Models (LVLMs). 3. Extensive ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":15},"pub_date":1736316717.0,"attribution":"proceedings.neurips.cc"}]},{"type":"search_result_group","domain":"huggingface.co","entries":[{"type":"search_result","url":"https://huggingface.co/learn/cookbook/en/structured_generation","title":"RAG with source highlighting using Structured generation","snippet":"To force a JSON output, we'll have to use constrained decoding where we force the LLM to only output tokens that conform to a set of rules called a grammar.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"huggingface.co"}]},{"type":"search_result_group","domain":"irlab.science.uva.nl","entries":[{"type":"search_result","url":"https://irlab.science.uva.nl/wp-content/papercite-data/pdf/sun-2023-contrastive.pdf","title":"Contrastive Learning Reduces Hallucination in ...","snippet":"by W Sun \u00b7 2023 \u00b7 Cited by 103 \u2014 In this paper, we propose Mixed Contrastive Learning. (MixCL) to alleviate the hallucinations of LM-based dialogue agents. MixCL explicitly samples the most.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":18},"pub_date":1670751908.0,"attribution":"irlab.science.uva.nl"}]},{"type":"search_result_group","domain":"assets.amazon.science","entries":[{"type":"search_result","url":"https://assets.amazon.science/9c/f8/fdc6e28249d8a89e6f70136c49cb/explaining-and-improving-contrastive-decoding-by-extrapolating-the-probabilities-of-a-huge-and-hypothetical-lm.pdf","title":"explaining-and-improving-contrastive-decoding-by- ...","snippet":"by HS Chang \u00b7 2024 \u00b7 Cited by 7 \u2014 DoLa: In the original DoLa paper (Chuang et al.,. 2023), they recommend to get the amateur logits from two subsets of layers: 0,2,4,6,8,10,12,14,32 or 16,18 ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":19},"pub_date":1728593248.0,"attribution":"assets.amazon.science"}]},{"type":"search_result_group","domain":"medium.com","entries":[{"type":"search_result","url":"https://medium.com/%40lad.jai/unlocking-structured-outputs-from-llms-methods-tools-and-techniques-197008bc88da","title":"Unlocking Structured Outputs from LLMs: Methods, Tools ...","snippet":"When it comes to implementing constrained decoding and other structured generation techniques, the Outlines library is a game-changer. Developed ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":20},"pub_date":1744771497.872,"attribution":"medium.com"}]}],"debug_sonic_thread_id":"thread_690d6ab9fa84832f8614074486962be0","reasoning_status":"is_reasoning","reasoning_title":"Searching for recent papers on decoding techniques","classifier_response":"default","request_id":"821740fb-4a36-4da4-b8da-7b6c09da4b5c","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"79dd46f7-feae-4d58-8a93-e9cd5920bbfd","turn_exchange_id":"0f711f7b-84fc-4a9a-8fad-95100b39accf","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"79dd46f7-feae-4d58-8a93-e9cd5920bbfd","children":["7e1bb43c-38de-4e0f-8964-b52e57358eb8"]},"7e1bb43c-38de-4e0f-8964-b52e57358eb8":{"id":"7e1bb43c-38de-4e0f-8964-b52e57358eb8","message":{"id":"7e1bb43c-38de-4e0f-8964-b52e57358eb8","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1762486981.733349,"update_time":null,"content":{"content_type":"thoughts","thoughts":[{"summary":"Searching for key research papers","content":"I\u2019m going to search for research related to \"semantic entropy,\" \"language models know what they know,\" \"selective prediction calibrations,\" and \"conformal prediction for LLMs.\" These areas seem crucial for improving the reliability and accuracy of language models, particularly when it comes to controlling and understanding uncertainty.","chunks":["I\u2019m going to search for research related to \"semantic entropy,\" \"language models know what they know,\" \"selective prediction calibrations,\" and \"conformal prediction for LLMs.\" These areas seem crucial for improving the reliability and accuracy of language models, particularly when it comes to controlling and understanding uncertainty."],"finished":true}],"source_analysis_msg_id":"4a6d5463-32ce-47af-9bcc-0baabea586fa"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"is_reasoning","content_references":[],"citations":[],"classifier_response":"default","skip_reasoning_title":"Skip","request_id":"821740fb-4a36-4da4-b8da-7b6c09da4b5c","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"11e9ec4c-3ece-4828-bcb6-3ad00e78b74c","turn_exchange_id":"0f711f7b-84fc-4a9a-8fad-95100b39accf","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"11e9ec4c-3ece-4828-bcb6-3ad00e78b74c","children":["407b4e70-4854-448d-bf91-6c4ccd8fb8b6"]},"407b4e70-4854-448d-bf91-6c4ccd8fb8b6":{"id":"407b4e70-4854-448d-bf91-6c4ccd8fb8b6","message":{"id":"407b4e70-4854-448d-bf91-6c4ccd8fb8b6","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1762486979.93103,"update_time":1762486979.948972,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"{\"search_query\": [{\"q\": \"Language Models (Mostly) Know What They Know calibrated confidence Kadavath 2022 paper\"}, {\"q\": \"Semantic uncertainty LLMs paper 2023 Kuhn semantic entropy\"}, {\"q\": \"Conformal prediction language models abstention 2024 paper\"}, {\"q\": \"LLM uncertainty estimation selective prediction abstain option 2025\"}], \"response_length\": \"short\"}"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200012]},"is_complete":true,"citations":[],"content_references":[],"reasoning_status":"is_reasoning","search_queries":[{"type":"search","q":"Language Models (Mostly) Know What They Know calibrated confidence Kadavath 2022 paper"},{"type":"search","q":"Semantic uncertainty LLMs paper 2023 Kuhn semantic entropy"},{"type":"search","q":"Conformal prediction language models abstention 2024 paper"},{"type":"search","q":"LLM uncertainty estimation selective prediction abstain option 2025"}],"search_display_string":"Searching the web...","searched_display_string":"Searched the web...","reasoning_title":"Searching for papers on semantic entropy and LLMs","classifier_response":"default","request_id":"821740fb-4a36-4da4-b8da-7b6c09da4b5c","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"7e1bb43c-38de-4e0f-8964-b52e57358eb8","turn_exchange_id":"0f711f7b-84fc-4a9a-8fad-95100b39accf","timestamp_":"absolute","can_save":true},"recipient":"web.run","channel":null},"parent":"7e1bb43c-38de-4e0f-8964-b52e57358eb8","children":["544e1037-1df6-49f6-b8be-b12ce9f103e0"]},"544e1037-1df6-49f6-b8be-b12ce9f103e0":{"id":"544e1037-1df6-49f6-b8be-b12ce9f103e0","message":{"id":"544e1037-1df6-49f6-b8be-b12ce9f103e0","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1762486980.0244863,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_model_queries":{"type":"search_model_queries","queries":["Language Models (Mostly) Know What They Know calibrated confidence Kadavath 2022 paper","Semantic uncertainty LLMs paper 2023 Kuhn semantic entropy","Conformal prediction language models abstention 2024 paper","LLM uncertainty estimation selective prediction abstain option 2025"]},"reasoning_status":"is_reasoning","reasoning_title":"Searching for papers on semantic entropy and LLMs","classifier_response":"default","request_id":"821740fb-4a36-4da4-b8da-7b6c09da4b5c","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"407b4e70-4854-448d-bf91-6c4ccd8fb8b6","turn_exchange_id":"0f711f7b-84fc-4a9a-8fad-95100b39accf","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"407b4e70-4854-448d-bf91-6c4ccd8fb8b6","children":["fd2d552f-e23e-4d55-8aad-dd7285307952"]},"fd2d552f-e23e-4d55-8aad-dd7285307952":{"id":"fd2d552f-e23e-4d55-8aad-dd7285307952","message":{"id":"fd2d552f-e23e-4d55-8aad-dd7285307952","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1762486980.0212088,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_result_groups":[{"type":"search_result_group","domain":"arxiv.org","entries":[{"type":"search_result","url":"https://arxiv.org/abs/2207.05221","title":"Language Models (Mostly) Know What They Know","snippet":"","ref_id":{"turn_index":2,"ref_type":"search","ref_index":0},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2302.09664","title":"[2302.09664] Semantic Uncertainty: Linguistic Invariances ...","snippet":"by L Kuhn \u00b7 2023 \u00b7 Cited by 735 \u2014 This paper introduces a method to measure uncertainty in large language models using semantic entropy, which incorporates linguistic ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2306.10193","title":"[2306.10193] Conformal Language Modeling","snippet":"by V Quach \u00b7 2023 \u00b7 Cited by 123 \u2014 Conformal Language Modeling is a novel approach to conformal prediction for generative language models, using a stopping and rejection rule for ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2510.20460v1","title":"Systematic Evaluation of Uncertainty Estimation Methods in ...","snippet":"23 Oct 2025 \u2014 Models must either return a short span from the supplied passage or abstain, making it ideal for studying selective prediction and calibration.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2405.01563","title":"Mitigating LLM Hallucinations via Conformal Abstention","snippet":"by YA Yadkori \u00b7 2024 \u00b7 Cited by 39 \u2014 This paper proposes a method where LLMs abstain from responding by using self-evaluation and conformal prediction to determine when to abstain ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2508.07556","title":"Uncertainty-Driven Reliability: Selective Prediction and ...","snippet":"by S Rabanser \u00b7 2025 \u00b7 Cited by 1 \u2014 This thesis investigates how uncertainty estimation can enhance the safety and trustworthiness of ML, with a particular focus on selective prediction\u2014a paradigm ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2207.05221","title":"arXiv:2207.05221v4 [cs.CL] 21 Nov 2022","snippet":"by S Kadavath \u00b7 2022 \u00b7 Cited by 619 \u2014 A model makes calibrated predictions if the probability it assigns to outcomes coincides with the frequency with which these outcomes actually ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":20},"pub_date":1669081499.0,"attribution":"arxiv.org"}]},{"type":"search_result_group","domain":"www.semanticscholar.org","entries":[{"type":"search_result","url":"https://www.semanticscholar.org/paper/Language-Models-%28Mostly%29-Know-What-They-Know-Kadavath-Conerly/142ebbf4760145f591166bde2564ac70c001e927","title":"[PDF] Language Models (Mostly) Know What They Know","snippet":"It is shown that larger models are well-calibrated on diverse multiple choice and true/false questions when they are provided in the right format and ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"www.semanticscholar.org"}]},{"type":"search_result_group","domain":"openreview.net","entries":[{"type":"search_result","url":"https://openreview.net/forum?id=j2wCrWmgMX&noteId=77cNQ2ogsR","title":"Kernel Language Entropy: Fine-grained Uncertainty ...","snippet":"5 Nov 2024 \u2014 This paper provides an improvement over Kuhn et al. (ICLR, 2023) \"Semantic Uncertainty: Linguistic Invariances for Uncertainty Estimation in ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/forum?id=pzUhfQ74c5","title":"Conformal Language Modeling","snippet":"by V Quach \u00b7 Cited by 123 \u2014 This paper introduces a new extension of conformal prediction that is tailored towards generating provably performant generations from large language models.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/pdf/287d3fdcda148caef9db54f03ae47cb8d1b25fa9.pdf","title":"CALIBRATING LLMS FOR SELECTIVE PREDICTION","snippet":"To address this, we leverage confidence modeling to enable selective prediction, allowing the system to abstain from answering when uncertainty is high (Wen.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":11},"pub_date":1758798358.0,"attribution":"openreview.net"}]},{"type":"search_result_group","domain":"aclanthology.org","entries":[{"type":"search_result","url":"https://aclanthology.org/2025.uncertainlp-main.4.pdf","title":"Do Large Language Models Know When Not to Answer in ...","snippet":"by S Machcha \u00b7 2025 \u2014 Our QA focus complements classification-centric selective prediction by converting uncertainty into explicit answer-or-abstain decisions that generalize to ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":7},"pub_date":1761167628.0,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2024.findings-emnlp.54.pdf","title":"Conformal Prediction for Large Language Models Without ...","snippet":"by J Su \u00b7 2024 \u00b7 Cited by 40 \u2014 This paper introduces a novel Conformal Prediction (CP) method for LLMs without logit access, using sample frequency and semantic similarity to ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":10},"pub_date":1731136597.0,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2025.findings-acl.234.pdf","title":"Beyond Semantic Entropy: Boosting LLM Uncertainty ...","snippet":"by D Nguyen \u00b7 2025 \u00b7 Cited by 2 \u2014 The proposed method addresses LLM limitations by considering intra- and inter-cluster similarity, outperforming semantic entropy (SE) in long ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":13},"pub_date":1752153514.0,"attribution":"aclanthology.org"}]},{"type":"search_result_group","domain":"www.researchgate.net","entries":[{"type":"search_result","url":"https://www.researchgate.net/publication/361949621_Language_Models_Mostly_Know_What_They_Know","title":"Language Models (Mostly) Know What They Know","snippet":"11 Jul 2022 \u2014 We study whether language models can evaluate the validity of their own claims and predict which questions they will be able to answer correctly ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":8},"pub_date":1657497600.0,"attribution":"www.researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/385379655_Semantic_Entropy_Neurons_Encoding_Semantic_Uncertainty_in_the_Latent_Space_of_LLMs","title":"Encoding Semantic Uncertainty in the Latent Space of LLMs","snippet":"30 Oct 2024 \u2014 Uncertainty estimation in Large Language Models (LLMs) is challenging because token-level uncertainty includes uncertainty over lexical and ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":17},"pub_date":1730246400.0,"attribution":"www.researchgate.net"}]},{"type":"search_result_group","domain":"www.nature.com","entries":[{"type":"search_result","url":"https://www.nature.com/articles/s41586-024-07421-0","title":"Detecting hallucinations in large language models using ...","snippet":"by S Farquhar \u00b7 2024 \u00b7 Cited by 803 \u2014 Here we develop new methods grounded in statistics, proposing entropy-based uncertainty estimators for LLMs to detect a subset of hallucinations.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"www.nature.com"}]},{"type":"search_result_group","domain":"www.alphaxiv.org","entries":[{"type":"search_result","url":"https://www.alphaxiv.org/overview/2207.05221v4","title":"Language Models (Mostly) Know What They Know","snippet":"This work explores two fundamental questions about AI self-awareness: Can language models evaluate whether their generated answers are correct (P(True))? And ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"www.alphaxiv.org"}]},{"type":"search_result_group","domain":"proceedings.neurips.cc","entries":[{"type":"search_result","url":"https://proceedings.neurips.cc/paper_files/paper/2024/file/9c20f16b05f5e5e70fa07e2a4364b80e-Paper-Conference.pdf","title":"Large Language Models Must Be Taught to Know What ...","snippet":"by S Kapoor \u00b7 2024 \u00b7 Cited by 58 \u2014 Notably, calibration-tuned models have calibrated probabilities for the answerable questions and assign lower confidence to unanswerable questions than black- ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":16},"pub_date":1730243463.0,"attribution":"proceedings.neurips.cc"}]},{"type":"search_result_group","domain":"huggingface.co","entries":[{"type":"search_result","url":"https://huggingface.co/papers/2502.06884","title":"Learning Conformal Abstention Policies for Adaptive Risk ...","snippet":"12 Feb 2025 \u2014 Learnable conformal abstention optimizes dynamic thresholds using reinforcement learning to improve uncertainty quantification in large language ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/papers/2302.09664","title":"Paper page - Semantic Uncertainty: Linguistic Invariances ...","snippet":"19 Feb 2023 \u2014 This paper introduces a method using semantic entropy to measure uncertainty in large language models, which is more accurate than baselines in ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":21},"pub_date":null,"attribution":"huggingface.co"}]}],"debug_sonic_thread_id":"thread_690d6ab9fa84832f8614074486962be0","reasoning_status":"is_reasoning","reasoning_title":"Searching for papers on semantic entropy and LLMs","classifier_response":"default","request_id":"821740fb-4a36-4da4-b8da-7b6c09da4b5c","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"544e1037-1df6-49f6-b8be-b12ce9f103e0","turn_exchange_id":"0f711f7b-84fc-4a9a-8fad-95100b39accf","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"544e1037-1df6-49f6-b8be-b12ce9f103e0","children":["eff1affd-0d82-47a2-8267-1048e2d1ddcc"]},"eff1affd-0d82-47a2-8267-1048e2d1ddcc":{"id":"eff1affd-0d82-47a2-8267-1048e2d1ddcc","message":{"id":"eff1affd-0d82-47a2-8267-1048e2d1ddcc","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1762486985.794613,"update_time":null,"content":{"content_type":"thoughts","thoughts":[{"summary":"Searching Jailbreak-related Papers","content":"Next, I need to look up papers on topics like \"universal jailbreaks,\" \"adversarial suffix,\" \"GCG,\" \"AutoDAN,\" and terms like \"prompt injection,\" \"prompt leak,\" and \"Rainbow Team.\" These are likely to aid in understanding vulnerabilities in language models and potential defenses. Let's find more on these.","chunks":["Next, I need to look up papers on topics like \"universal jailbreaks,\" \"adversarial suffix,\" \"GCG,\" \"AutoDAN,\" and terms like \"prompt injection,\" \"prompt leak,\" and \"Rainbow Team.\" These are likely to aid in understanding vulnerabilities in language models and potential defenses. Let's find more on these."],"finished":true}],"source_analysis_msg_id":"5d844810-4e0c-417e-bd1a-720d00a3f3d7"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"is_reasoning","content_references":[],"citations":[],"classifier_response":"default","skip_reasoning_title":"Skip","request_id":"821740fb-4a36-4da4-b8da-7b6c09da4b5c","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"fd2d552f-e23e-4d55-8aad-dd7285307952","turn_exchange_id":"0f711f7b-84fc-4a9a-8fad-95100b39accf","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"fd2d552f-e23e-4d55-8aad-dd7285307952","children":["c17504b1-7fbf-4d16-b797-ff347f16ce42"]},"c17504b1-7fbf-4d16-b797-ff347f16ce42":{"id":"c17504b1-7fbf-4d16-b797-ff347f16ce42","message":{"id":"c17504b1-7fbf-4d16-b797-ff347f16ce42","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1762486984.262435,"update_time":1762486984.392687,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"{\"search_query\": [{\"q\": \"universal jailbreak adversarial suffix LLM 2023 GCG paper\"}, {\"q\": \"jailbreak taxonomy prompt injection OWASP top 10 LLM\"}, {\"q\": \"Llama Guard jailbreak prevention evaluation 2024\"}], \"response_length\": \"short\"}"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200012]},"is_complete":true,"citations":[],"content_references":[],"reasoning_status":"is_reasoning","search_queries":[{"type":"search","q":"universal jailbreak adversarial suffix LLM 2023 GCG paper"},{"type":"search","q":"jailbreak taxonomy prompt injection OWASP top 10 LLM"},{"type":"search","q":"Llama Guard jailbreak prevention evaluation 2024"}],"search_display_string":"Searching the web...","searched_display_string":"Searched the web...","reasoning_title":"Searching for papers on jailbreaks and related topics","classifier_response":"default","request_id":"821740fb-4a36-4da4-b8da-7b6c09da4b5c","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"eff1affd-0d82-47a2-8267-1048e2d1ddcc","turn_exchange_id":"0f711f7b-84fc-4a9a-8fad-95100b39accf","timestamp_":"absolute","can_save":true},"recipient":"web.run","channel":null},"parent":"eff1affd-0d82-47a2-8267-1048e2d1ddcc","children":["5d58fdc8-3d44-4b56-9f4f-54ab48529e4f"]},"5d58fdc8-3d44-4b56-9f4f-54ab48529e4f":{"id":"5d58fdc8-3d44-4b56-9f4f-54ab48529e4f","message":{"id":"5d58fdc8-3d44-4b56-9f4f-54ab48529e4f","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1762486984.4786532,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_model_queries":{"type":"search_model_queries","queries":["universal jailbreak adversarial suffix LLM 2023 GCG paper","jailbreak taxonomy prompt injection OWASP top 10 LLM","Llama Guard jailbreak prevention evaluation 2024"]},"reasoning_status":"is_reasoning","reasoning_title":"Searching for papers on jailbreaks and related topics","classifier_response":"default","request_id":"821740fb-4a36-4da4-b8da-7b6c09da4b5c","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"c17504b1-7fbf-4d16-b797-ff347f16ce42","turn_exchange_id":"0f711f7b-84fc-4a9a-8fad-95100b39accf","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"c17504b1-7fbf-4d16-b797-ff347f16ce42","children":["f45ea55e-f393-4959-9bd6-2eb02ae21058"]},"f45ea55e-f393-4959-9bd6-2eb02ae21058":{"id":"f45ea55e-f393-4959-9bd6-2eb02ae21058","message":{"id":"f45ea55e-f393-4959-9bd6-2eb02ae21058","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1762486984.474839,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_result_groups":[{"type":"search_result_group","domain":"arxiv.org","entries":[{"type":"search_result","url":"https://arxiv.org/abs/2506.12880","title":"Universal Jailbreak Suffixes Are Strong Attention Hijackers","snippet":"","ref_id":{"turn_index":3,"ref_type":"search","ref_index":0},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2307.15043","title":"Universal and Transferable Adversarial Attacks on Aligned ...","snippet":"by A Zou \u00b7 2023 \u00b7 Cited by 2246 \u2014 In this paper, we propose a simple and effective attack method that causes aligned language models to generate objectionable behaviors.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":3},"pub_date":1703207682.0,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2510.21285v1","title":"Mitigating Self-Jailbreak in Large Reasoning Models with ...","snippet":"24 Oct 2025 \u2014 The evaluation is performed on 2k harmful queries from Wildjailbreak (Jiang et al., 2024a) , with safety assessed using Llama-Guard-3-8B (Llama ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2505.04806v1","title":"A Systematic Evaluation of Prompt Injection and Jailbreak ...","snippet":"7 May 2025 \u2014 OWASP's Top 10 identified prompt injection as the most critical vulnerability [16] . ... \u201dTop 10 for LLM Applications.\u201d https://owasp.org ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2506.10597v2","title":"Evaluating Jailbreak Guardrails for Large Language Models","snippet":"16 Oct 2025 \u2014 A \u201cJailbreak Guardrail\u201d refers to a specialized security mechanism designed for LLM systems, specifically to detect and prevent \u201cjailbreak\u201d ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"arxiv.org"}]},{"type":"search_result_group","domain":"genai.owasp.org","entries":[{"type":"search_result","url":"https://genai.owasp.org/llmrisk/llm01-prompt-injection/","title":"LLM01:2025 Prompt Injection - OWASP Gen AI Security Project","snippet":"Jailbreaking is a form of prompt injection where the attacker provides inputs that cause the model to disregard its safety protocols entirely. Developers can ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"genai.owasp.org"}]},{"type":"search_result_group","domain":"aclanthology.org","entries":[{"type":"search_result","url":"https://aclanthology.org/2025.acl-long.1045.pdf","title":"Comprehensive Assessment of Jailbreak Attacks Against ...","snippet":"by J Chu \u00b7 2025 \u00b7 Cited by 4 \u2014 Llama-Guard-2 (Meta, 2024d). Meta Llama. Guard 2 is an 8B parameter Llama 3-based LLM safeguard model. Similar to Llama Guard, it can be used ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":2},"pub_date":1752153133.0,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2025.naacl-long.302.pdf","title":"Stronger Universal and Transferable Attacks by ...","snippet":"by D Huang \u00b7 2025 \u00b7 Cited by 5 \u2014 Result 1.1: Universal white-box attack. First, we focus on the universality aspect, i.e., how many behaviors one adversarial suffix can jailbreak (no.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":6},"pub_date":1744560095.0,"attribution":"aclanthology.org"}]},{"type":"search_result_group","domain":"owasp.org","entries":[{"type":"search_result","url":"https://owasp.org/www-project-top-10-for-large-language-model-applications/assets/PDF/OWASP-Top-10-for-LLMs-v2025.pdf","title":"OWASP Top 10 for LLM Applications 2025","snippet":"18 Nov 2024 \u2014 Jailbreaking is a form of prompt injection where the attacker provides inputs that cause the model to disregard its safety protocols entirely.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"owasp.org"},{"type":"search_result","url":"https://owasp.org/www-community/attacks/PromptInjection","title":"Prompt Injection","snippet":"Overview. Prompt Injection is a novel security vulnerability that targets Large Language Models (LLMs) like ChatGPT, Bard, and others.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"owasp.org"}]},{"type":"search_result_group","domain":"www.promptfoo.dev","entries":[{"type":"search_result","url":"https://www.promptfoo.dev/blog/jailbreaking-vs-prompt-injection/","title":"Prompt Injection vs Jailbreaking: What's the Difference?","snippet":"18 Aug 2025 \u2014 The OWASP LLM Top 10 (2025) groups jailbreaking under LLM01: Prompt Injection. Security practitioners find Willison's separation more useful ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":7},"pub_date":1755475200.0,"attribution":"www.promptfoo.dev"}]},{"type":"search_result_group","domain":"proceedings.neurips.cc","entries":[{"type":"search_result","url":"https://proceedings.neurips.cc/paper_files/paper/2024/file/63092d79154adebd7305dfd498cbff70-Paper-Datasets_and_Benchmarks_Track.pdf","title":"JailbreakBench: An Open Robustness Benchmark for ...","snippet":"by P Chao \u00b7 2024 \u00b7 Cited by 359 \u2014 Evaluating the success of jailbreak attacks is challenging given the subjective nature of judging the appropriateness of a LLM's response. We perform a rigorous.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":8},"pub_date":1730308908.0,"attribution":"proceedings.neurips.cc"}]},{"type":"search_result_group","domain":"openreview.net","entries":[{"type":"search_result","url":"https://openreview.net/forum?id=UfqzXg95I5","title":"AmpleGCG: Learning a Universal and Transferable ...","snippet":"by Z Liao \u00b7 Cited by 133 \u2014 We propose a universal adversarial suffix generator to generate many customized suffixes for any harmful queries in seconds and achieve near 100% ASR on ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/pdf?id=eK0Ub2p9f4","title":"Retrieval-Augmented Defense: Adaptive and Controllable ...","snippet":"Llama Guard 3 (Grattafiori et al., 2024) is a safe-. 202 guard model based on Llama 3. This guard model. 203 detects whether the input is safe or not. 204.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":11},"pub_date":1753722498.0,"attribution":"openreview.net"}]},{"type":"search_result_group","domain":"github.com","entries":[{"type":"search_result","url":"https://github.com/llm-attacks/llm-attacks","title":"LLM Attacks","snippet":"16 Aug 2023 \u2014 This is the official repository for \"Universal and Transferable Adversarial Attacks on Aligned Language Models\" by Andy Zou, Zifan Wang, ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"github.com"}]},{"type":"search_result_group","domain":"public-assets.detoxio.ai","entries":[{"type":"search_result","url":"https://public-assets.detoxio.ai/dtx-public-files/Evaluation%20Report_%20Robustness%20of%20Meta%20Llama-Guard-4-12B.pdf","title":"Evaluation Report: Robustness of Meta Llama-Guard-4-12B","snippet":"This report presents a comprehensive evaluation of Meta's Llama-Guard-4-12B, a safety-aligned classifier derived from the LLaMA 4 family of models.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"public-assets.detoxio.ai"}]},{"type":"search_result_group","domain":"huggingface.co","entries":[{"type":"search_result","url":"https://huggingface.co/papers/2506.12880","title":"Universal Jailbreak Suffixes Are Strong Attention Hijackers","snippet":"18 Jun 2025 \u2014 Abstract. Suffix-based jailbreaks exploit adversarial suffixes to hijack large language models, with effectiveness linked to suffix universality ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"huggingface.co"}]},{"type":"search_result_group","domain":"i-tracing.com","entries":[{"type":"search_result","url":"https://i-tracing.com/blog/owasp-top-ten-cyberattacks-llm/","title":"OWASP Top 10 and other types of cyberattacks on LLM","snippet":"14 Nov 2024 \u2014 Among the most worrying OWASP Top 10 attacks on LLM are prompt injections ... Good to know: the difference between prompt injection and jailbreak.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":16},"pub_date":1731601620.0,"attribution":"i-tracing.com"}]},{"type":"search_result_group","domain":"hiddenlayer.com","entries":[{"type":"search_result","url":"https://hiddenlayer.com/innovation-hub/introducing-a-taxonomy-of-adversarial-prompt-engineering/","title":"Introducing a Taxonomy of Adversarial Prompt Engineering","snippet":"17 Jun 2025 \u2014 For example, community efforts like OWASP Top 10 for LLMs highlight prompt injection as the top risk, and MITRE's ATLAS framework catalogs ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":19},"pub_date":1750167892.0,"attribution":"hiddenlayer.com"}]},{"type":"search_result_group","domain":"www.usenix.org","entries":[{"type":"search_result","url":"https://www.usenix.org/system/files/usenixsecurity25-wang-xunguang.pdf","title":"SelfDefenD: LLMs Can Defend Themselves against ...","snippet":"by X Wang \u00b7 Cited by 29 \u2014 Llama Guard exhibits poor jailbreak detection for DrAttack, Puzzler, and. MultiJail, while Llama Guard 2 presents unacceptable flaws for ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":20},"pub_date":1753383526.0,"attribution":"www.usenix.org"}]}],"debug_sonic_thread_id":"thread_690d6ab9fa84832f8614074486962be0","reasoning_status":"is_reasoning","reasoning_title":"Searching for papers on jailbreaks and related topics","classifier_response":"default","request_id":"821740fb-4a36-4da4-b8da-7b6c09da4b5c","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"5d58fdc8-3d44-4b56-9f4f-54ab48529e4f","turn_exchange_id":"0f711f7b-84fc-4a9a-8fad-95100b39accf","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"5d58fdc8-3d44-4b56-9f4f-54ab48529e4f","children":["7b99e90f-f703-48e2-9b37-d68f634bc786"]},"7b99e90f-f703-48e2-9b37-d68f634bc786":{"id":"7b99e90f-f703-48e2-9b37-d68f634bc786","message":{"id":"7b99e90f-f703-48e2-9b37-d68f634bc786","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1762486992.850829,"update_time":null,"content":{"content_type":"thoughts","thoughts":[{"summary":"Searching RAG Faithfulness Papers","content":"Now, I want to dig into RAG (retrieval-augmented generation) faithfulness papers. I'll look for \"Self-RAG: learning to retrieve, generate, and critique,\" \"RA-DIT\" (June 2024), and \"Faithful Chain of Thought?\" Also, \"Toolformer\" might be relevant. I'll start by searching for \"Self-RAG\" and \"Attributable QA.\"","chunks":["Now, I want to dig into RAG (retrieval-augmented generation) faithfulness papers.","I'll look for \"Self-RAG: learning to retrieve, generate, and critique,\" \"RA-DIT\" (June 2024), and \"Faithful Chain of Thought?\" Also, \"Toolformer\" might be relevant. I'll start by searching for \"Self-RAG\" and \"Attributable QA.\""],"finished":true}],"source_analysis_msg_id":"78e35793-97b6-4ab9-8ba2-666d29f20fb2"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"is_reasoning","content_references":[],"citations":[],"classifier_response":"default","skip_reasoning_title":"Skip","request_id":"821740fb-4a36-4da4-b8da-7b6c09da4b5c","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"f45ea55e-f393-4959-9bd6-2eb02ae21058","turn_exchange_id":"0f711f7b-84fc-4a9a-8fad-95100b39accf","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"f45ea55e-f393-4959-9bd6-2eb02ae21058","children":["b07a45d1-1d48-4c97-bf55-655d47fd934f"]},"b07a45d1-1d48-4c97-bf55-655d47fd934f":{"id":"b07a45d1-1d48-4c97-bf55-655d47fd934f","message":{"id":"b07a45d1-1d48-4c97-bf55-655d47fd934f","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1762486990.485266,"update_time":1762486990.514805,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"{\"search_query\": [{\"q\": \"Self-RAG learning to retrieve generate critique 2023 paper\"}, {\"q\": \"Attributable QA to ground LLM outputs cite sources 2024 paper\"}], \"response_length\": \"short\"}"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200012]},"is_complete":true,"citations":[],"content_references":[],"reasoning_status":"is_reasoning","search_queries":[{"type":"search","q":"Self-RAG learning to retrieve generate critique 2023 paper"},{"type":"search","q":"Attributable QA to ground LLM outputs cite sources 2024 paper"}],"search_display_string":"Searching the web...","searched_display_string":"Searched the web...","reasoning_title":"Searching for Self-RAG and Attributable QA papers","classifier_response":"default","request_id":"821740fb-4a36-4da4-b8da-7b6c09da4b5c","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"7b99e90f-f703-48e2-9b37-d68f634bc786","turn_exchange_id":"0f711f7b-84fc-4a9a-8fad-95100b39accf","timestamp_":"absolute","can_save":true},"recipient":"web.run","channel":null},"parent":"7b99e90f-f703-48e2-9b37-d68f634bc786","children":["18ac43ec-bcb4-4552-9a27-717f29f4cbbc"]},"18ac43ec-bcb4-4552-9a27-717f29f4cbbc":{"id":"18ac43ec-bcb4-4552-9a27-717f29f4cbbc","message":{"id":"18ac43ec-bcb4-4552-9a27-717f29f4cbbc","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1762486990.6853447,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_model_queries":{"type":"search_model_queries","queries":["Self-RAG learning to retrieve generate critique 2023 paper","Attributable QA to ground LLM outputs cite sources 2024 paper"]},"reasoning_status":"is_reasoning","reasoning_title":"Searching for Self-RAG and Attributable QA papers","classifier_response":"default","request_id":"821740fb-4a36-4da4-b8da-7b6c09da4b5c","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"b07a45d1-1d48-4c97-bf55-655d47fd934f","turn_exchange_id":"0f711f7b-84fc-4a9a-8fad-95100b39accf","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"b07a45d1-1d48-4c97-bf55-655d47fd934f","children":["b6f15c87-e5c0-4736-ba8a-d76a94955faa"]},"b6f15c87-e5c0-4736-ba8a-d76a94955faa":{"id":"b6f15c87-e5c0-4736-ba8a-d76a94955faa","message":{"id":"b6f15c87-e5c0-4736-ba8a-d76a94955faa","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1762486990.6781595,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_result_groups":[{"type":"search_result_group","domain":"arxiv.org","entries":[{"type":"search_result","url":"https://arxiv.org/abs/2310.11511","title":"Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection","snippet":"","ref_id":{"turn_index":4,"ref_type":"search","ref_index":0},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2404.01019v1","title":"Source-Aware Training Enables Knowledge Attribution in ...","snippet":"1 Apr 2024 \u2014 We investigate the problem of intrinsic source citation, where LLMs are required to cite the pretraining source supporting a generated response.","ref_id":{"turn_index":4,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2412.18004","title":"arXiv:2412.18004v1 [cs.CL] 23 Dec 2024","snippet":"by J Wallat \u00b7 2024 \u00b7 Cited by 4 \u2014 Our findings suggest that current attributed answers often lack citation faithfulness (up to. 57% of the citations), highlighting the need to ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":5},"pub_date":1735089032.0,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2310.11511","title":"arXiv:2310.11511v1 [cs.CL] 17 Oct 2023","snippet":"17 Oct 2023 \u2014 SELF-RAG learns to retrieve, critique, and generate text passages to enhance overall generation quality, factuality, and verifiability.","ref_id":{"turn_index":4,"ref_type":"search","ref_index":10},"pub_date":1697675298.0,"attribution":"arxiv.org"}]},{"type":"search_result_group","domain":"openreview.net","entries":[{"type":"search_result","url":"https://openreview.net/pdf?id=hSyW5go0v8","title":"SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND ...","snippet":"by A Asai \u00b7 Cited by 1280 \u2014 In particular, SELF-RAG outperforms retrieval-augmented ChatGPT on four tasks, Llama2-chat (Touvron et al., 2023) and Alpaca (Dubois et al., 2023) on all tasks.","ref_id":{"turn_index":4,"ref_type":"search","ref_index":2},"pub_date":1710177833.0,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/forum?id=zP8HygcAMY","title":"Can LLMs Evaluate Complex Attribution in QA? Automatic ...","snippet":"by N Hu \u00b7 Cited by 2 \u2014 The paper presents CAQA (Complex Attributed Question Answering), a large-scale automatically generated benchmark designed to assess the attribution ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"openreview.net"}]},{"type":"search_result_group","domain":"aclanthology.org","entries":[{"type":"search_result","url":"https://aclanthology.org/2024.findings-acl.838.pdf","title":"Learning Fine-Grained Grounded Citations for Attributed ...","snippet":"by L Huang \u00b7 2024 \u00b7 Cited by 25 \u2014 G3 first select supporting quotes from retrieved sources (grounding) and then condition the gener- ation process on them (generation). Then ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":3},"pub_date":1727201907.0,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2024.naacl-long.216.pdf","title":"Towards Improved Multi-Source Attribution for Long-Form ...","snippet":"by N Patel \u00b7 2024 \u00b7 Cited by 9 \u2014 To address this, in this paper we aim to improve the attribution capa- bility of LLMs for long-form answer genera- tion to multiple sources, ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":13},"pub_date":1719441382.0,"attribution":"aclanthology.org"}]},{"type":"search_result_group","domain":"www.semanticscholar.org","entries":[{"type":"search_result","url":"https://www.semanticscholar.org/paper/Self-RAG%3A-Learning-to-Retrieve%2C-Generate%2C-and-Asai-Wu/ddbd8fe782ac98e9c64dd98710687a962195dd9b","title":"[PDF] Self-RAG: Learning to Retrieve, Generate, and ...","snippet":"A new framework called Self-Reflective Retrieval-Augmented Generation (Self-RAG) is introduced that enhances an LM's quality and factuality through ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"www.semanticscholar.org"},{"type":"search_result","url":"https://www.semanticscholar.org/paper/5d3bdae6cfb2239af70dfe8ae5cf1a4958330ac4","title":"[PDF] A Survey of Large Language Models Attribution","snippet":"The aim of this survey is to provide valuable insights for researchers, aiding in the refinement of attribution methodologies to enhance the reliability and ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"www.semanticscholar.org"}]},{"type":"search_result_group","domain":"huggingface.co","entries":[{"type":"search_result","url":"https://huggingface.co/papers/2310.11511","title":"Self-RAG: Learning to Retrieve, Generate, and Critique ...","snippet":"19 Oct 2023 \u2014 The model learns to generate special \"retrieve\" tokens to selectively get relevant facts from Wikipedia only when needed. It also generates \" ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"huggingface.co"}]},{"type":"search_result_group","domain":"www.researchgate.net","entries":[{"type":"search_result","url":"https://www.researchgate.net/publication/387382243_Factuality_or_Fiction_Benchmarking_Modern_LLMs_on_Ambiguous_QA_with_Citations","title":"Factuality or Fiction? Benchmarking Modern LLMs on ...","snippet":"by M Patel \u00b7 2024 \u2014 In this work, we evaluate the factual accuracy and citation performance of state-of-the-art LLMs on the task of Question Answering (QA) in ambiguous settings ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"www.researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/383901530_A_Self-Reflective_Retrieval_Augmented_Generation_System_to_Eliminate_Hallucination_in_LLM_Generation","title":"A Self-Reflective Retrieval Augmented Generation System ...","snippet":"Asai, Akari, et al. \"Self-rag: Learning to retrieve, generate, and critique through self-reflection.\" arXiv preprint arXiv:2310.11511 (2023).","ref_id":{"turn_index":4,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"www.researchgate.net"}]},{"type":"search_result_group","domain":"selfrag.github.io","entries":[{"type":"search_result","url":"https://selfrag.github.io/","title":"Self-RAG: Learning to Retrieve, Generate and Critique ...","snippet":"Self-RAG is a new framework to enhances an LM's quality and factuality through retrieval and self-reflection.","ref_id":{"turn_index":4,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"selfrag.github.io"}]},{"type":"search_result_group","domain":"neptune.ai","entries":[{"type":"search_result","url":"https://neptune.ai/blog/llm-grounding","title":"A Researcher's Guide to LLM Grounding","snippet":"19 Sept 2025 \u2014 Learn what LLM grounding is, why LLMs have knowledge gaps, and how to improve accuracy and reliability in AI applications.","ref_id":{"turn_index":4,"ref_type":"search","ref_index":11},"pub_date":1758886200.0,"attribution":"neptune.ai"}]},{"type":"search_result_group","domain":"www.projectpro.io","entries":[{"type":"search_result","url":"https://www.projectpro.io/article/self-rag/1176","title":"The Self-RAG Shortcut Every AI Expert Wishes They Knew","snippet":"15 Oct 2025 \u2014 The paper, Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection, by Asai et al., introduces a novel framework for self ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"www.projectpro.io"}]},{"type":"search_result_group","domain":"medium.com","entries":[{"type":"search_result","url":"https://medium.com/%40sahin.samia/self-rag-self-reflective-retrieval-augmented-generation-the-game-changer-in-factual-ai-dd32e59e3ff9","title":"SELF-RAG (Self-Reflective Retrieval-Augmented Generation)","snippet":"SELF-RAG is a framework that integrates three key components \u2014 retrieval, generation, and self-reflection \u2014 to create a smarter and more ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":14},"pub_date":1722698616.515,"attribution":"medium.com"}]},{"type":"search_result_group","domain":"dl.acm.org","entries":[{"type":"search_result","url":"https://dl.acm.org/doi/pdf/10.1145/3627673.3679172","title":"An Evaluation Framework for Attributed Information ...","snippet":"by H Djeddal \u00b7 2024 \u00b7 Cited by 8 \u2014 In this work, we propose an extensible open-source framework to benchmark attributable information-seeking using representative. LLM-based ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"dl.acm.org"}]},{"type":"search_result_group","domain":"www.linkedin.com","entries":[{"type":"search_result","url":"https://www.linkedin.com/pulse/self-rag-learning-retrieve-generate-critique-through-vlad-bogolin-1rvge","title":"Self-RAG: Learning to Retrieve, Generate, and Critique ...","snippet":"Today's paper introduces Self-Reflective Retrieval-Augmented Generation (SELF-RAG), a new framework that enhances the quality and factuality ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"www.linkedin.com"}]},{"type":"search_result_group","domain":"ntrs.nasa.gov","entries":[{"type":"search_result","url":"https://ntrs.nasa.gov/api/citations/20250001363/downloads/ACL2025_Collaborative_error_schema_q_a-11.pdf","title":"A User-Centered Framework for Evaluating Large ...","snippet":"by A Martin-Boyle \u00b7 2025 \u2014 We investigated scholarly question answering. (QA) using large language models (LLMs), focusing on outputs that fall short of domain- expert expectations.","ref_id":{"turn_index":4,"ref_type":"search","ref_index":19},"pub_date":1738888918.0,"attribution":"ntrs.nasa.gov"}]}],"debug_sonic_thread_id":"thread_690d6ab9fa84832f8614074486962be0","reasoning_status":"is_reasoning","reasoning_title":"Searching for Self-RAG and Attributable QA papers","classifier_response":"default","request_id":"821740fb-4a36-4da4-b8da-7b6c09da4b5c","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"18ac43ec-bcb4-4552-9a27-717f29f4cbbc","turn_exchange_id":"0f711f7b-84fc-4a9a-8fad-95100b39accf","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"18ac43ec-bcb4-4552-9a27-717f29f4cbbc","children":["a3b7fd9e-ebc5-4b5a-ae49-a1279139b582"]},"a3b7fd9e-ebc5-4b5a-ae49-a1279139b582":{"id":"a3b7fd9e-ebc5-4b5a-ae49-a1279139b582","message":{"id":"a3b7fd9e-ebc5-4b5a-ae49-a1279139b582","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1762487000.5848,"update_time":null,"content":{"content_type":"thoughts","thoughts":[{"summary":"Evaluating Tool Sandbox and Architecture","content":"Next, I'll consider \"tool sandboxing & permissions\" and possibly \"toolformer,\" but I\u2019m thinking it might not be necessary. I'll focus on \"function calling with JSON schema: ensures output shape but not content.\" We\u2019ll cite Outlines and Hugging Face. I\u2019ll propose an end-to-end architecture with estimated latency numbers and compute budgets, keeping it concise. I\u2019ll avoid unnecessary details, like the user\u2019s timezone, and include citations where needed.","chunks":["Next, I'll consider \"tool sandboxing & permissions\" and possibly \"toolformer,\" but I\u2019m thinking it might not be necessary. I'll focus on \"function calling with JSON schema: ensures output shape but not content.\" We\u2019ll cite Outlines and Hugging Face. I\u2019ll propose an end-to-end architecture with estimated latency numbers and compute budgets, keeping it concise. I\u2019ll avoid unnecessary details, like the user\u2019s timezone, and include citations where needed."],"finished":true},{"summary":"Summarizing Approaches and Proposals","content":"I reviewed various methods and findings, like speculative decoding to reduce latency and SelfCheckGPT's detection method, though it has high overhead. Plus, there are concepts such as Constitutional AI, Llama Guard 3 for safety, and DoLa for reduced hallucinations. I also want to propose a \"low-latency blueprint\" with a detailed step-by-step plan.","chunks":["I reviewed various methods and findings, like speculative decoding to reduce latency and SelfCheckGPT's detection method, though it has high overhead.","Plus, there are concepts such as Constitutional AI, Llama Guard 3 for safety, and DoLa for reduced hallucinations.","I also want to propose a \"low-latency blueprint\" with a detailed step-by-step plan."],"finished":true}],"source_analysis_msg_id":"a367e7f3-d6ab-4a1c-950b-6a87dde2bd3e"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"is_reasoning","content_references":[],"citations":[],"classifier_response":"default","skip_reasoning_title":"Skip","request_id":"821740fb-4a36-4da4-b8da-7b6c09da4b5c","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"b6f15c87-e5c0-4736-ba8a-d76a94955faa","turn_exchange_id":"0f711f7b-84fc-4a9a-8fad-95100b39accf","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"b6f15c87-e5c0-4736-ba8a-d76a94955faa","children":["2464eed1-f96c-45c2-914c-99f7bb97c835"]},"2464eed1-f96c-45c2-914c-99f7bb97c835":{"id":"2464eed1-f96c-45c2-914c-99f7bb97c835","message":{"id":"2464eed1-f96c-45c2-914c-99f7bb97c835","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1762487006.814037,"update_time":null,"content":{"content_type":"reasoning_recap","content":"Thought for 1m 15s"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"reasoning_ended","finished_duration_sec":75,"request_id":"821740fb-4a36-4da4-b8da-7b6c09da4b5c","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"a3b7fd9e-ebc5-4b5a-ae49-a1279139b582","turn_exchange_id":"0f711f7b-84fc-4a9a-8fad-95100b39accf","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"a3b7fd9e-ebc5-4b5a-ae49-a1279139b582","children":["469403d2-293d-4e61-ad36-29a898123580"]},"469403d2-293d-4e61-ad36-29a898123580":{"id":"469403d2-293d-4e61-ad36-29a898123580","message":{"id":"469403d2-293d-4e61-ad36-29a898123580","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1762487006.732046,"update_time":1762487046.927189,"content":{"content_type":"text","parts":["You\u2019re right on the core diagnosis: today\u2019s decoder-only, next-token LMs are easy to jailbreak and will hallucinate if you let them \u201cfree-write.\u201d But that doesn\u2019t mean we\u2019re stuck with a binary choice between slow, double-checked answers and fast, sloppy ones. The practical way forward is defense-in-depth with **adaptive compute**: most turns run fast, and you spend extra milliseconds only when the risk is high.\n\nBelow is a concise map of what actually works (or is promising), how to wire it together for low latency, and where the fundamental limits still bite.\n\n# 1) What\u2019s known to help\u2014without tanking latency\n\n**A. Fast, always-on controls (negligible overhead)**\n- **Grammar/format constraints** (JSON Schema/regex/CFG) to force structure and deny dangerous surface forms; great for tools, citations, and \u201canswer + sources\u201d formats. Libraries like Outlines and similar integrations in HF/vLLM do this today. \ue200cite\ue202turn1search5\ue202turn1search8\ue201  \n- **Safety classifiers on inputs/outputs** (tiny side models): Llama Guard 3/4-style filters or equivalent \u201cmoderation\u201d heads. These are compact and deployable in INT4 on CPU/GPU with low TTFB. Use both directions (pre- and post-generation). \ue200cite\ue202turn0search3\ue202turn0search8\ue201  \n- **Safer decoding**: contrastive/DoLa decoding nudges probability mass toward factual layers and away from \u201cfluent nonsense,\u201d with only a forward-pass cost. It\u2019s not a panacea, but it reduces obvious confabulations with minimal latency. \ue200cite\ue202turn1search1\ue202turn1search4\ue201\n\n**B. Adaptive checks (triggered only when risky)**\n- **Uncertainty gating**: compute a cheap uncertainty signal (semantic entropy from small samples, or a learned \u201cP(True)\u201d logit head). If high, escalate; if low, ship. This is far cheaper than always doing self-consistency. \ue200cite\ue202turn2search1\ue202turn2search0\ue201  \n- **Selective abstention with guarantees**: conformal methods add \u201cI\u2019ll pass\u201d when risk is high; good for high-stakes slices. (You can do this even without logit access.) \ue200cite\ue202turn2search2\ue202turn2search10\ue201  \n- **Targeted retrieval/attribution**: Self-RAG-style models learn when to fetch, and to critique/cite only when needed\u2014cutting back the cost of unconditional RAG while improving faithfulness on factual turns. (Caveat: many \u201cattributed\u201d systems still show unfaithful citations, so verify the link between span and source.) \ue200cite\ue202turn4search0\ue202turn4search2\ue202turn4search5\ue201\n\n**C. Latency recoupers that make room for safety**\n- **Speculative decoding** (draft+verify) and its variants (Medusa/SPRINTER) give 1.5\u20133\u00d7 effective speedups, freeing budget for verification without user-visible delay. This is table-stakes for modern deployments. \ue200cite\ue202turn0search0\ue202turn0search5\ue202turn0search10\ue201\n\n# 2) Jailbreaks: what actually reduces attack success\n\n- **Guardrails at the system boundary**: OWASP treats jailbreaking as a prompt-injection class; you need layered defenses: prompt isolation, tool-permission sandboxes, content filters before and after the model, and retrieval whitelists. Benchmarks (e.g., JailbreakBench) show that strong judges/filters materially lower ASR, though not to zero. \ue200cite\ue202turn3search4\ue202turn3search8\ue201  \n- **Adversarial training + constitutional tuning**: Pair red-team corpora (including adversarial suffixes) with principle-guided feedback (Anthropic\u2019s Constitutional AI) to harden refusal behavior without making the model uselessly evasive. \ue200cite\ue202turn3search3\ue202turn0search2\ue202turn0search12\ue201  \n- **Suffix-aware mitigations**: \u201cUniversal jailbreak\u201d suffixes hijack attention; recent work shows you can both *amplify* and *mitigate* them by surgically addressing that mechanism. That implies train-time and runtime detectors focused on these attention patterns can help. \ue200cite\ue202turn3search0\ue201  \n- **Programmable guardrails**: controller layers like NVIDIA NeMo Guardrails orchestrate topic control, PII blocks, grounding checks, and jailbreak detection with minimal overhead; they won\u2019t stop a frontier attack alone, but they shrink your exposed surface. \ue200cite\ue202turn0search9\ue202turn0search4\ue201\n\n# 3) A low-latency blueprint (defense-in-depth, adaptive compute)\n\n**Stage 0 \u2014 Input hardening (always on)**\n- Prompt isolation (no tool/system leakage), allow-listed tools, and a **tiny** input classifier (e.g., Guard-style) for jailbreak patterns; fast regex/CFG for expected formats. \ue200cite\ue202turn0search8\ue201\n\n**Stage 1 \u2014 Fast generation**\n- Turn on **speculative decoding**; use **DoLa/contrastive** decoding by default. Keep temperature low for factual Q&A. \ue200cite\ue202turn0search0\ue202turn1search1\ue201\n\n**Stage 2 \u2014 Cheap risk scoring**\n- Compute a semantic-entropy/\u201cP(True)\u201d score. If *confident and non-sensitive*, **ship**. If *uncertain* or *policy-sensitive*, **escalate**. \ue200cite\ue202turn2search1\ue202turn2search0\ue201\n\n**Stage 3 \u2014 Escalations (only when triggered)**\n- **Factual**: on-demand retrieval + constrained, attributed generation; optionally run a small verifier head or a compact judge model on the specific claims/spans. \ue200cite\ue202turn4search0\ue201  \n- **Safety**: re-run a stronger output classifier; if still risky, apply refusal or safe-completion templates (constitutional guidance). \ue200cite\ue202turn0search12\ue201  \n- **Abstain**: if confidence remains low after retrieval, return \u201ccan\u2019t verify\u201d with citations to what you did check (conformal abstention). \ue200cite\ue202turn2search2\ue201\n\n**Why this meets your latency constraint**  \nSpeculative decoding buys you a speedup that roughly offsets a small classifier + uncertainty scoring pass. You then pay heavier costs only on the ~10\u201330% of turns that look risky or factual\u2014*not* on every request. Empirically, this keeps TTFB low and p95 within interactive bounds on standard hardware. \ue200cite\ue202turn0search5\ue201\n\n# 4) What doesn\u2019t really solve it (or only helps a bit)\n\n- **Always-on self-consistency / multi-sample**: great for research (e.g., SelfCheckGPT) but too expensive for default use; treat it as a last-resort escalation. \ue200cite\ue202turn0search1\ue202turn0search6\ue201  \n- **\u201cJust use RAG\u201d**: unconditional retrieval helps, but many systems still produce unfaithful citations; you must *bind* spans to sources or train for faithfulness. \ue200cite\ue202turn4search5\ue201  \n- **Single big safety model**: stronger judges help, but jailbreak suffixes generalize; you need adversarial training + runtime detectors focused on the actual attack mechanics. \ue200cite\ue202turn3search0\ue201\n\n# 5) How much compute is \u201cenough\u201d? (A pragmatic answer)\n\nThere isn\u2019t a universal threshold. What you need is **budgeted compute with tight routing**:\n- **Baseline**: one large model pass with speculative decoding.  \n- **+O(1) small-model passes**: input/output safety classifiers + uncertainty head.  \n- **Conditional extras** on a minority of turns: retrieval, span-level verification, or human-in-the-loop (for true mission-critical).\n\nIn practice, this design scales: as more compute becomes available you widen the escalations (e.g., two-pass verification, multi-source evidence), but your **median** user still sees chat-like latency because most turns never escalate.\n\n# 6) Forward-looking bets (worth exploring)\n\n- **Verifier-first training**: jointly train a small verifier head (or model) to predict truthfulness/faithfulness at span-level; couple it to decoding (reject-sampling bad spans). Related evidence suggests LMs can estimate their own correctness when asked the right way. \ue200cite\ue202turn2search0\ue201  \n- **Learning-to-abstain with guarantees**: conformal abstention and its learnable variants provide principled \u201cdon\u2019t know\u201d triggers\u2014essential for safety-critical apps. \ue200cite\ue202turn2search2\ue202turn2search18\ue201  \n- **Mechanism-aware jailbreak mitigation**: detectors keyed to the attention-hijack patterns used by universal suffixes, integrated as a pre-decoder veto. \ue200cite\ue202turn3search0\ue201\n\n---\n\n## Bottom line\n- **Yes, AR LMs are inherently vulnerable**, but you can make jailbreaks rare and hallucinations uncommon **without** imposing heavy latency\u2014by combining (1) structure + guardrails that run all the time, (2) uncertainty-based routing to spend compute only when it matters, and (3) decoding tricks + speculative sampling to claw back the time you spend on safety.  \n- Don\u2019t wait for \u201cenough compute.\u201d Engineer **adaptive compute** today.\n\nIf you want, I can sketch a concrete stack (models, thresholds, and escalation rules) tailored to your workloads (research Q&A vs. general chat vs. agentic tasks) and quantify expected overheads per tier."]},"status":"finished_successfully","end_turn":true,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200002]},"is_complete":true,"content_references":[{"matched_text":"\ue200cite\ue202turn1search5\ue202turn1search8\ue201","start_idx":919,"end_idx":951,"safe_urls":["https://docs.langchain.com/oss/python/integrations/providers/outlines?utm_source=chatgpt.com","https://dottxt-ai.github.io/outlines/?utm_source=chatgpt.com"],"refs":[],"alt":"([Dottxt AI](https://dottxt-ai.github.io/outlines/?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Outlines","url":"https://dottxt-ai.github.io/outlines/?utm_source=chatgpt.com","pub_date":null,"snippet":"Outlines is a low-abstraction library. Write code the way you normally do with LLMs. No agent frameworks needed.","attribution_segments":null,"supporting_websites":[{"title":"Outlines - Docs by LangChain","url":"https://docs.langchain.com/oss/python/integrations/providers/outlines?utm_source=chatgpt.com","pub_date":null,"snippet":"Outlines is a Python library for constrained language generation. It provides a unified interface to various language models and allows for structured ...","attribution":"LangChain Docs"}],"refs":[{"turn_index":1,"ref_type":"search","ref_index":5},{"turn_index":1,"ref_type":"search","ref_index":8}],"hue":null,"attributions":null,"attribution":"Dottxt AI"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search3\ue202turn0search8\ue201","start_idx":1196,"end_idx":1228,"safe_urls":["https://arxiv.org/abs/2411.17713?utm_source=chatgpt.com","https://huggingface.co/meta-llama/Llama-Guard-3-8B?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2411.17713?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Llama Guard 3-1B-INT4: Compact and Efficient Safeguard ...","url":"https://arxiv.org/abs/2411.17713?utm_source=chatgpt.com","pub_date":null,"snippet":"by I Fedorov \u00b7 2024 \u00b7 Cited by 10 \u2014 This paper presents Llama Guard 3-1B-INT4, a compact and efficient Llama Guard model, which has been open-sourced to the community during Meta Connect 2024.","attribution_segments":null,"supporting_websites":[{"title":"meta-llama/Llama-Guard-3-8B","url":"https://huggingface.co/meta-llama/Llama-Guard-3-8B?utm_source=chatgpt.com","pub_date":null,"snippet":"23 Jul 2024 \u2014 As outlined in the Llama 3 paper, Llama Guard 3 provides industry leading system-level safety performance and is recommended to be deployed ...","attribution":"Hugging Face"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":3},{"turn_index":0,"ref_type":"search","ref_index":8}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn1search1\ue202turn1search4\ue201","start_idx":1469,"end_idx":1501,"safe_urls":["https://arxiv.org/abs/2309.03883?utm_source=chatgpt.com","https://openreview.net/pdf?id=Th6NyL07na&utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2309.03883?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"DoLa: Decoding by Contrasting Layers Improves Factuality ...","url":"https://arxiv.org/abs/2309.03883?utm_source=chatgpt.com","pub_date":null,"snippet":"by YS Chuang \u00b7 2023 \u00b7 Cited by 493 \u2014 We find that this Decoding by Contrasting Layers (DoLa) approach is able to better surface factual knowledge and reduce the generation of incorrect facts.","attribution_segments":null,"supporting_websites":[{"title":"DOLA: DECODING BY CONTRASTING LAYERS ...","url":"https://openreview.net/pdf?id=Th6NyL07na&utm_source=chatgpt.com","pub_date":null,"snippet":"by YS Chuang \u00b7 2023 \u00b7 Cited by 493 \u2014 DoLa dynamically selects appropriate early layers based on token complexity, avoiding the need for training and using smaller LMs in CD. For efficiency, DoLa ...","attribution":"OpenReview"}],"refs":[{"turn_index":1,"ref_type":"search","ref_index":1},{"turn_index":1,"ref_type":"search","ref_index":4}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn2search1\ue202turn2search0\ue201","start_idx":1778,"end_idx":1810,"safe_urls":["https://arxiv.org/abs/2207.05221?utm_source=chatgpt.com","https://arxiv.org/abs/2302.09664?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2302.09664?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"[2302.09664] Semantic Uncertainty: Linguistic Invariances ...","url":"https://arxiv.org/abs/2302.09664?utm_source=chatgpt.com","pub_date":null,"snippet":"by L Kuhn \u00b7 2023 \u00b7 Cited by 735 \u2014 This paper introduces a method to measure uncertainty in large language models using semantic entropy, which incorporates linguistic ...","attribution_segments":null,"supporting_websites":[{"title":"Language Models (Mostly) Know What They Know","url":"https://arxiv.org/abs/2207.05221?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution":"arXiv"}],"refs":[{"turn_index":2,"ref_type":"search","ref_index":1},{"turn_index":2,"ref_type":"search","ref_index":0}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn2search2\ue202turn2search10\ue201","start_idx":1984,"end_idx":2017,"safe_urls":["https://aclanthology.org/2024.findings-emnlp.54.pdf?utm_source=chatgpt.com","https://arxiv.org/abs/2306.10193?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2306.10193?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"[2306.10193] Conformal Language Modeling","url":"https://arxiv.org/abs/2306.10193?utm_source=chatgpt.com","pub_date":null,"snippet":"by V Quach \u00b7 2023 \u00b7 Cited by 123 \u2014 Conformal Language Modeling is a novel approach to conformal prediction for generative language models, using a stopping and rejection rule for ...","attribution_segments":null,"supporting_websites":[{"title":"Conformal Prediction for Large Language Models Without ...","url":"https://aclanthology.org/2024.findings-emnlp.54.pdf?utm_source=chatgpt.com","pub_date":null,"snippet":"by J Su \u00b7 2024 \u00b7 Cited by 40 \u2014 This paper introduces a novel Conformal Prediction (CP) method for LLMs without logit access, using sample frequency and semantic similarity to ...","attribution":"ACL Anthology"}],"refs":[{"turn_index":2,"ref_type":"search","ref_index":2},{"turn_index":2,"ref_type":"search","ref_index":10}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn4search0\ue202turn4search2\ue202turn4search5\ue201","start_idx":2342,"end_idx":2387,"safe_urls":["https://arxiv.org/abs/2310.11511?utm_source=chatgpt.com","https://arxiv.org/pdf/2412.18004?utm_source=chatgpt.com","https://openreview.net/pdf?id=hSyW5go0v8&utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2310.11511?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection","url":"https://arxiv.org/abs/2310.11511?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[{"title":"SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND ...","url":"https://openreview.net/pdf?id=hSyW5go0v8&utm_source=chatgpt.com","pub_date":null,"snippet":"by A Asai \u00b7 Cited by 1280 \u2014 In particular, SELF-RAG outperforms retrieval-augmented ChatGPT on four tasks, Llama2-chat (Touvron et al., 2023) and Alpaca (Dubois et al., 2023) on all tasks.","attribution":"OpenReview"},{"title":"arXiv:2412.18004v1 [cs.CL] 23 Dec 2024","url":"https://arxiv.org/pdf/2412.18004?utm_source=chatgpt.com","pub_date":null,"snippet":"by J Wallat \u00b7 2024 \u00b7 Cited by 4 \u2014 Our findings suggest that current attributed answers often lack citation faithfulness (up to. 57% of the citations), highlighting the need to ...","attribution":"arXiv"}],"refs":[{"turn_index":4,"ref_type":"search","ref_index":0},{"turn_index":4,"ref_type":"search","ref_index":2},{"turn_index":4,"ref_type":"search","ref_index":5}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search0\ue202turn0search5\ue202turn0search10\ue201","start_idx":2654,"end_idx":2700,"safe_urls":["https://aclanthology.org/2025.naacl-long.328.pdf?utm_source=chatgpt.com","https://arxiv.org/html/2502.04557v1?utm_source=chatgpt.com","https://arxiv.org/pdf/2211.17192?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/pdf/2211.17192?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"arXiv:2211.17192v2 [cs.LG] 18 May 2023","url":"https://arxiv.org/pdf/2211.17192?utm_source=chatgpt.com","pub_date":1684715173.0,"snippet":"by Y Leviathan \u00b7 2022 \u00b7 Cited by 974 \u2014 In this work we in- troduce speculative decoding - an algorithm to sample from autoregressive models faster without any changes to the outputs, ...","attribution_segments":null,"supporting_websites":[{"title":"Decoding Speculative Decoding","url":"https://aclanthology.org/2025.naacl-long.328.pdf?utm_source=chatgpt.com","pub_date":null,"snippet":"by M Yan \u00b7 2025 \u00b7 Cited by 26 \u2014 Speculative Decoding is a widely used tech- nique to speed up inference for Large Lan- guage Models (LLMs) without sacrificing qual-.","attribution":"ACL Anthology"},{"title":"Speeding up Speculative Decoding via Approximate ...","url":"https://arxiv.org/html/2502.04557v1?utm_source=chatgpt.com","pub_date":null,"snippet":"6 Feb 2025 \u2014 We propose SPRINTER, a framework for achieving faster inference from LLMs using a pair of (draft (small), target (large)) LLMs together with the ...","attribution":"arXiv"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":0},{"turn_index":0,"ref_type":"search","ref_index":5},{"turn_index":0,"ref_type":"search","ref_index":10}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn3search4\ue202turn3search8\ue201","start_idx":3103,"end_idx":3135,"safe_urls":["https://owasp.org/www-project-top-10-for-large-language-model-applications/assets/PDF/OWASP-Top-10-for-LLMs-v2025.pdf?utm_source=chatgpt.com","https://proceedings.neurips.cc/paper_files/paper/2024/file/63092d79154adebd7305dfd498cbff70-Paper-Datasets_and_Benchmarks_Track.pdf?utm_source=chatgpt.com"],"refs":[],"alt":"([OWASP](https://owasp.org/www-project-top-10-for-large-language-model-applications/assets/PDF/OWASP-Top-10-for-LLMs-v2025.pdf?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"OWASP Top 10 for LLM Applications 2025","url":"https://owasp.org/www-project-top-10-for-large-language-model-applications/assets/PDF/OWASP-Top-10-for-LLMs-v2025.pdf?utm_source=chatgpt.com","pub_date":null,"snippet":"18 Nov 2024 \u2014 Jailbreaking is a form of prompt injection where the attacker provides inputs that cause the model to disregard its safety protocols entirely.","attribution_segments":null,"supporting_websites":[{"title":"JailbreakBench: An Open Robustness Benchmark for ...","url":"https://proceedings.neurips.cc/paper_files/paper/2024/file/63092d79154adebd7305dfd498cbff70-Paper-Datasets_and_Benchmarks_Track.pdf?utm_source=chatgpt.com","pub_date":null,"snippet":"by P Chao \u00b7 2024 \u00b7 Cited by 359 \u2014 Evaluating the success of jailbreak attacks is challenging given the subjective nature of judging the appropriateness of a LLM's response. We perform a rigorous.","attribution":"NeurIPS Proceedings"}],"refs":[{"turn_index":3,"ref_type":"search","ref_index":4},{"turn_index":3,"ref_type":"search","ref_index":8}],"hue":null,"attributions":null,"attribution":"OWASP"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn3search3\ue202turn0search2\ue202turn0search12\ue201","start_idx":3379,"end_idx":3425,"safe_urls":["https://arxiv.org/abs/2212.08073?utm_source=chatgpt.com","https://arxiv.org/pdf/2307.15043?utm_source=chatgpt.com","https://www-cdn.anthropic.com/7512771452629584566b6303311496c262da1006/Anthropic_ConstitutionalAI_v2.pdf?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/pdf/2307.15043?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Universal and Transferable Adversarial Attacks on Aligned ...","url":"https://arxiv.org/pdf/2307.15043?utm_source=chatgpt.com","pub_date":1703207682.0,"snippet":"by A Zou \u00b7 2023 \u00b7 Cited by 2246 \u2014 In this paper, we propose a simple and effective attack method that causes aligned language models to generate objectionable behaviors.","attribution_segments":null,"supporting_websites":[{"title":"Constitutional AI: Harmlessness from AI Feedback","url":"https://arxiv.org/abs/2212.08073?utm_source=chatgpt.com","pub_date":null,"snippet":"by Y Bai \u00b7 2022 \u00b7 Cited by 2288 \u2014 We experiment with methods for training a harmless AI assistant through self-improvement, without any human labels identifying harmful outputs.","attribution":"arXiv"},{"title":"Constitutional AI: Harmlessness from AI Feedback","url":"https://www-cdn.anthropic.com/7512771452629584566b6303311496c262da1006/Anthropic_ConstitutionalAI_v2.pdf?utm_source=chatgpt.com","pub_date":null,"snippet":"It displays a Pareto improvement. (i.e., win-win situation) where Constitutional RL is both more helpful and more harmless than standard RLHF. APRIL 2023. Page ...","attribution":"Anthropic"}],"refs":[{"turn_index":3,"ref_type":"search","ref_index":3},{"turn_index":0,"ref_type":"search","ref_index":2},{"turn_index":0,"ref_type":"search","ref_index":12}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn3search0\ue201","start_idx":3703,"end_idx":3722,"safe_urls":["https://arxiv.org/abs/2506.12880?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2506.12880?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Universal Jailbreak Suffixes Are Strong Attention Hijackers","url":"https://arxiv.org/abs/2506.12880?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":3,"ref_type":"search","ref_index":0}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search9\ue202turn0search4\ue201","start_idx":3985,"end_idx":4017,"safe_urls":["https://developer.nvidia.com/nemo-guardrails?utm_source=chatgpt.com","https://docs.nvidia.com/nemo/guardrails/latest/index.html?utm_source=chatgpt.com"],"refs":[],"alt":"([NVIDIA Docs](https://docs.nvidia.com/nemo/guardrails/latest/index.html?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"About NeMo Guardrails","url":"https://docs.nvidia.com/nemo/guardrails/latest/index.html?utm_source=chatgpt.com","pub_date":null,"snippet":"NeMo Guardrails enables developers building LLM-based applications to easily add programmable guardrails between the application code and the LLM.","attribution_segments":null,"supporting_websites":[{"title":"NVIDIA NeMo Guardrails for Developers","url":"https://developer.nvidia.com/nemo-guardrails?utm_source=chatgpt.com","pub_date":null,"snippet":"NVIDIA NeMo\u2122 Guardrails is a scalable solution for orchestrating AI guardrails that keep agentic AI applications safe, reliable, and aligned.","attribution":"NVIDIA Developer"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":9},{"turn_index":0,"ref_type":"search","ref_index":4}],"hue":null,"attributions":null,"attribution":"NVIDIA Docs"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search8\ue201","start_idx":4306,"end_idx":4325,"safe_urls":["https://huggingface.co/meta-llama/Llama-Guard-3-8B?utm_source=chatgpt.com"],"refs":[],"alt":"([Hugging Face](https://huggingface.co/meta-llama/Llama-Guard-3-8B?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"meta-llama/Llama-Guard-3-8B","url":"https://huggingface.co/meta-llama/Llama-Guard-3-8B?utm_source=chatgpt.com","pub_date":null,"snippet":"23 Jul 2024 \u2014 As outlined in the Llama 3 paper, Llama Guard 3 provides industry leading system-level safety performance and is recommended to be deployed ...","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":8}],"hue":null,"attributions":null,"attribution":"Hugging Face"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search0\ue202turn1search1\ue201","start_idx":4477,"end_idx":4509,"safe_urls":["https://arxiv.org/abs/2309.03883?utm_source=chatgpt.com","https://arxiv.org/pdf/2211.17192?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/pdf/2211.17192?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"arXiv:2211.17192v2 [cs.LG] 18 May 2023","url":"https://arxiv.org/pdf/2211.17192?utm_source=chatgpt.com","pub_date":1684715173.0,"snippet":"by Y Leviathan \u00b7 2022 \u00b7 Cited by 974 \u2014 In this work we in- troduce speculative decoding - an algorithm to sample from autoregressive models faster without any changes to the outputs, ...","attribution_segments":null,"supporting_websites":[{"title":"DoLa: Decoding by Contrasting Layers Improves Factuality ...","url":"https://arxiv.org/abs/2309.03883?utm_source=chatgpt.com","pub_date":null,"snippet":"by YS Chuang \u00b7 2023 \u00b7 Cited by 493 \u2014 We find that this Decoding by Contrasting Layers (DoLa) approach is able to better surface factual knowledge and reduce the generation of incorrect facts.","attribution":"arXiv"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":0},{"turn_index":1,"ref_type":"search","ref_index":1}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn2search1\ue202turn2search0\ue201","start_idx":4686,"end_idx":4718,"safe_urls":["https://arxiv.org/abs/2207.05221?utm_source=chatgpt.com","https://arxiv.org/abs/2302.09664?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2302.09664?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"[2302.09664] Semantic Uncertainty: Linguistic Invariances ...","url":"https://arxiv.org/abs/2302.09664?utm_source=chatgpt.com","pub_date":null,"snippet":"by L Kuhn \u00b7 2023 \u00b7 Cited by 735 \u2014 This paper introduces a method to measure uncertainty in large language models using semantic entropy, which incorporates linguistic ...","attribution_segments":null,"supporting_websites":[{"title":"Language Models (Mostly) Know What They Know","url":"https://arxiv.org/abs/2207.05221?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution":"arXiv"}],"refs":[{"turn_index":2,"ref_type":"search","ref_index":1},{"turn_index":2,"ref_type":"search","ref_index":0}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn4search0\ue201","start_idx":4933,"end_idx":4952,"safe_urls":["https://arxiv.org/abs/2310.11511?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2310.11511?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection","url":"https://arxiv.org/abs/2310.11511?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":4,"ref_type":"search","ref_index":0}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search12\ue201","start_idx":5092,"end_idx":5112,"safe_urls":["https://www-cdn.anthropic.com/7512771452629584566b6303311496c262da1006/Anthropic_ConstitutionalAI_v2.pdf?utm_source=chatgpt.com"],"refs":[],"alt":"([Anthropic](https://www-cdn.anthropic.com/7512771452629584566b6303311496c262da1006/Anthropic_ConstitutionalAI_v2.pdf?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Constitutional AI: Harmlessness from AI Feedback","url":"https://www-cdn.anthropic.com/7512771452629584566b6303311496c262da1006/Anthropic_ConstitutionalAI_v2.pdf?utm_source=chatgpt.com","pub_date":1681499547.0,"snippet":"It displays a Pareto improvement. (i.e., win-win situation) where Constitutional RL is both more helpful and more harmless than standard RLHF. APRIL 2023. Page ...","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":12}],"hue":null,"attributions":null,"attribution":"Anthropic"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn2search2\ue201","start_idx":5256,"end_idx":5275,"safe_urls":["https://arxiv.org/abs/2306.10193?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2306.10193?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"[2306.10193] Conformal Language Modeling","url":"https://arxiv.org/abs/2306.10193?utm_source=chatgpt.com","pub_date":null,"snippet":"by V Quach \u00b7 2023 \u00b7 Cited by 123 \u2014 Conformal Language Modeling is a novel approach to conformal prediction for generative language models, using a stopping and rejection rule for ...","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":2,"ref_type":"search","ref_index":2}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search5\ue201","start_idx":5626,"end_idx":5645,"safe_urls":["https://aclanthology.org/2025.naacl-long.328.pdf?utm_source=chatgpt.com"],"refs":[],"alt":"([ACL Anthology](https://aclanthology.org/2025.naacl-long.328.pdf?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Decoding Speculative Decoding","url":"https://aclanthology.org/2025.naacl-long.328.pdf?utm_source=chatgpt.com","pub_date":1744560095.0,"snippet":"by M Yan \u00b7 2025 \u00b7 Cited by 26 \u2014 Speculative Decoding is a widely used tech- nique to speed up inference for Large Lan- guage Models (LLMs) without sacrificing qual-.","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":5}],"hue":null,"attributions":null,"attribution":"ACL Anthology"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search1\ue202turn0search6\ue201","start_idx":5866,"end_idx":5898,"safe_urls":["https://aclanthology.org/2023.emnlp-main.557.pdf?utm_source=chatgpt.com","https://arxiv.org/abs/2303.08896?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2303.08896?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models","url":"https://arxiv.org/abs/2303.08896?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[{"title":"SELFCHECKGPT: Zero-Resource Black-Box Hallucination ...","url":"https://aclanthology.org/2023.emnlp-main.557.pdf?utm_source=chatgpt.com","pub_date":null,"snippet":"by P Manakul \u00b7 2023 \u00b7 Cited by 1111 \u2014 In this paper, we propose SelfCheckGPT, a sampling-based approach that can detect whether responses generated by LLMs are hallucinated or.","attribution":"ACL Anthology"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":1},{"turn_index":0,"ref_type":"search","ref_index":6}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn4search5\ue201","start_idx":6067,"end_idx":6086,"safe_urls":["https://arxiv.org/pdf/2412.18004?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/pdf/2412.18004?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"arXiv:2412.18004v1 [cs.CL] 23 Dec 2024","url":"https://arxiv.org/pdf/2412.18004?utm_source=chatgpt.com","pub_date":1735089032.0,"snippet":"by J Wallat \u00b7 2024 \u00b7 Cited by 4 \u2014 Our findings suggest that current attributed answers often lack citation faithfulness (up to. 57% of the citations), highlighting the need to ...","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":4,"ref_type":"search","ref_index":5}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn3search0\ue201","start_idx":6267,"end_idx":6286,"safe_urls":["https://arxiv.org/abs/2506.12880?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2506.12880?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Universal Jailbreak Suffixes Are Strong Attention Hijackers","url":"https://arxiv.org/abs/2506.12880?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":3,"ref_type":"search","ref_index":0}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn2search0\ue201","start_idx":7280,"end_idx":7299,"safe_urls":["https://arxiv.org/abs/2207.05221?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2207.05221?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Language Models (Mostly) Know What They Know","url":"https://arxiv.org/abs/2207.05221?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":2,"ref_type":"search","ref_index":0}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn2search2\ue202turn2search18\ue201","start_idx":7470,"end_idx":7503,"safe_urls":["https://arxiv.org/abs/2306.10193?utm_source=chatgpt.com","https://huggingface.co/papers/2502.06884?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2306.10193?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"[2306.10193] Conformal Language Modeling","url":"https://arxiv.org/abs/2306.10193?utm_source=chatgpt.com","pub_date":null,"snippet":"by V Quach \u00b7 2023 \u00b7 Cited by 123 \u2014 Conformal Language Modeling is a novel approach to conformal prediction for generative language models, using a stopping and rejection rule for ...","attribution_segments":null,"supporting_websites":[{"title":"Learning Conformal Abstention Policies for Adaptive Risk ...","url":"https://huggingface.co/papers/2502.06884?utm_source=chatgpt.com","pub_date":null,"snippet":"12 Feb 2025 \u2014 Learnable conformal abstention optimizes dynamic thresholds using reinforcement learning to improve uncertainty quantification in large language ...","attribution":"Hugging Face"}],"refs":[{"turn_index":2,"ref_type":"search","ref_index":2},{"turn_index":2,"ref_type":"search","ref_index":18}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn3search0\ue201","start_idx":7661,"end_idx":7680,"safe_urls":["https://arxiv.org/abs/2506.12880?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2506.12880?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Universal Jailbreak Suffixes Are Strong Attention Hijackers","url":"https://arxiv.org/abs/2506.12880?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":3,"ref_type":"search","ref_index":0}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":" ","start_idx":8344,"end_idx":8344,"safe_urls":[],"refs":[],"alt":"","prompt_text":null,"type":"sources_footnote","sources":[{"title":"Outlines","url":"https://dottxt-ai.github.io/outlines/?utm_source=chatgpt.com","attribution":"Dottxt AI"},{"title":"Llama Guard 3-1B-INT4: Compact and Efficient Safeguard ...","url":"https://arxiv.org/abs/2411.17713?utm_source=chatgpt.com","attribution":"arXiv"},{"title":"OWASP Top 10 for LLM Applications 2025","url":"https://owasp.org/www-project-top-10-for-large-language-model-applications/assets/PDF/OWASP-Top-10-for-LLMs-v2025.pdf?utm_source=chatgpt.com","attribution":"OWASP"},{"title":"About NeMo Guardrails","url":"https://docs.nvidia.com/nemo/guardrails/latest/index.html?utm_source=chatgpt.com","attribution":"NVIDIA Docs"},{"title":"meta-llama/Llama-Guard-3-8B","url":"https://huggingface.co/meta-llama/Llama-Guard-3-8B?utm_source=chatgpt.com","attribution":"Hugging Face"},{"title":"Constitutional AI: Harmlessness from AI Feedback","url":"https://www-cdn.anthropic.com/7512771452629584566b6303311496c262da1006/Anthropic_ConstitutionalAI_v2.pdf?utm_source=chatgpt.com","attribution":"Anthropic"},{"title":"Decoding Speculative Decoding","url":"https://aclanthology.org/2025.naacl-long.328.pdf?utm_source=chatgpt.com","attribution":"ACL Anthology"}],"has_images":false}],"safe_urls":["https://docs.langchain.com/oss/python/integrations/providers/outlines?utm_source=chatgpt.com","https://dottxt-ai.github.io/outlines/?utm_source=chatgpt.com","https://arxiv.org/abs/2411.17713?utm_source=chatgpt.com","https://huggingface.co/meta-llama/Llama-Guard-3-8B?utm_source=chatgpt.com","https://arxiv.org/abs/2309.03883?utm_source=chatgpt.com","https://openreview.net/pdf?id=Th6NyL07na&utm_source=chatgpt.com","https://arxiv.org/abs/2207.05221?utm_source=chatgpt.com","https://arxiv.org/abs/2302.09664?utm_source=chatgpt.com","https://aclanthology.org/2024.findings-emnlp.54.pdf?utm_source=chatgpt.com","https://arxiv.org/abs/2306.10193?utm_source=chatgpt.com","https://arxiv.org/abs/2310.11511?utm_source=chatgpt.com","https://arxiv.org/pdf/2412.18004?utm_source=chatgpt.com","https://openreview.net/pdf?id=hSyW5go0v8&utm_source=chatgpt.com","https://aclanthology.org/2025.naacl-long.328.pdf?utm_source=chatgpt.com","https://arxiv.org/html/2502.04557v1?utm_source=chatgpt.com","https://arxiv.org/pdf/2211.17192?utm_source=chatgpt.com","https://owasp.org/www-project-top-10-for-large-language-model-applications/assets/PDF/OWASP-Top-10-for-LLMs-v2025.pdf?utm_source=chatgpt.com","https://proceedings.neurips.cc/paper_files/paper/2024/file/63092d79154adebd7305dfd498cbff70-Paper-Datasets_and_Benchmarks_Track.pdf?utm_source=chatgpt.com","https://arxiv.org/abs/2212.08073?utm_source=chatgpt.com","https://arxiv.org/pdf/2307.15043?utm_source=chatgpt.com","https://www-cdn.anthropic.com/7512771452629584566b6303311496c262da1006/Anthropic_ConstitutionalAI_v2.pdf?utm_source=chatgpt.com","https://arxiv.org/abs/2506.12880?utm_source=chatgpt.com","https://developer.nvidia.com/nemo-guardrails?utm_source=chatgpt.com","https://docs.nvidia.com/nemo/guardrails/latest/index.html?utm_source=chatgpt.com","https://huggingface.co/meta-llama/Llama-Guard-3-8B?utm_source=chatgpt.com","https://arxiv.org/abs/2309.03883?utm_source=chatgpt.com","https://arxiv.org/pdf/2211.17192?utm_source=chatgpt.com","https://arxiv.org/abs/2207.05221?utm_source=chatgpt.com","https://arxiv.org/abs/2302.09664?utm_source=chatgpt.com","https://arxiv.org/abs/2310.11511?utm_source=chatgpt.com","https://www-cdn.anthropic.com/7512771452629584566b6303311496c262da1006/Anthropic_ConstitutionalAI_v2.pdf?utm_source=chatgpt.com","https://arxiv.org/abs/2306.10193?utm_source=chatgpt.com","https://aclanthology.org/2025.naacl-long.328.pdf?utm_source=chatgpt.com","https://aclanthology.org/2023.emnlp-main.557.pdf?utm_source=chatgpt.com","https://arxiv.org/abs/2303.08896?utm_source=chatgpt.com","https://arxiv.org/pdf/2412.18004?utm_source=chatgpt.com","https://arxiv.org/abs/2506.12880?utm_source=chatgpt.com","https://arxiv.org/abs/2207.05221?utm_source=chatgpt.com","https://arxiv.org/abs/2306.10193?utm_source=chatgpt.com","https://huggingface.co/papers/2502.06884?utm_source=chatgpt.com","https://arxiv.org/abs/2506.12880?utm_source=chatgpt.com"],"search_result_groups":[{"type":"search_result_group","domain":"arxiv.org","entries":[{"type":"search_result","url":"https://arxiv.org/abs/2212.08073?utm_source=chatgpt.com","title":"Constitutional AI: Harmlessness from AI Feedback","snippet":"by Y Bai \u00b7 2022 \u00b7 Cited by 2288 \u2014 We experiment with methods for training a harmless AI assistant through self-improvement, without any human labels identifying harmful outputs.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2502.04557v1?utm_source=chatgpt.com","title":"Speeding up Speculative Decoding via Approximate ...","snippet":"6 Feb 2025 \u2014 We propose SPRINTER, a framework for achieving faster inference from LLMs using a pair of (draft (small), target (large)) LLMs together with the ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2411.17713?utm_source=chatgpt.com","title":"Llama Guard 3-1B-INT4","snippet":"by I Fedorov \u00b7 2024 \u00b7 Cited by 10 \u2014 In this paper, we review the techniques we used to compress Llama Guard 3-1B-INT4 without sacrificing safety. Some of the components used are ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2303.08896?utm_source=chatgpt.com","title":"arXiv:2303.08896v1 [cs.CL] 15 Mar 2023","snippet":"by P Manakul \u00b7 2023 \u00b7 Cited by 1111 \u2014 In this paper, we propose SelfCheckGPT, a sim- ple sampling-based approach that can be used to detect whether responses generated by LLMs are.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":26},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2406.14066v2?utm_source=chatgpt.com","title":"Optimizing Speculative Decoding for Serving Large ...","snippet":"25 Jun 2024 \u2014 Speculative decoding aims to solve the problem by employing lightweight proxies, such as a small draft model (Leviathan et al., 2023; ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":37},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2504.04918v1?utm_source=chatgpt.com","title":"Constitution or Collapse? Exploring Constitutional AI with ...","snippet":"7 Apr 2025 \u2014 Constitutional AI, introduced by Anthropic in December 2022, uses AI to provide feedback to another AI, greatly reducing the need for human ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":39},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2505.23657?utm_source=chatgpt.com","title":"Active Layer-Contrastive Decoding Reduces Hallucination ...","snippet":"by H Zhang \u00b7 2025 \u00b7 Cited by 5 \u2014 In this paper, we propose Active Layer-Contrastive Decoding (ActLCD), a novel decoding strategy that actively decides when to apply contrasting layers during ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":0},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2501.10868v1?utm_source=chatgpt.com","title":"Generating Structured Outputs from Language Models","snippet":"18 Jan 2025 \u2014 We present an evaluation framework to assess constrained decoding approaches across three critical dimensions: efficiency in generating constraint-compliant ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2504.10020v2?utm_source=chatgpt.com","title":"Why Contrastive Decoding Fails to Address Multimodal ...","snippet":"18 Apr 2025 \u2014 Contrastive decoding strategies are widely used to reduce hallucinations in multimodal large language models (MLLMs).","ref_id":{"turn_index":1,"ref_type":"search","ref_index":24},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2510.20460v1?utm_source=chatgpt.com","title":"Systematic Evaluation of Uncertainty Estimation Methods in ...","snippet":"23 Oct 2025 \u2014 Models must either return a short span from the supplied passage or abstain, making it ideal for studying selective prediction and calibration.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2405.01563?utm_source=chatgpt.com","title":"Mitigating LLM Hallucinations via Conformal Abstention","snippet":"by YA Yadkori \u00b7 2024 \u00b7 Cited by 39 \u2014 This paper proposes a method where LLMs abstain from responding by using self-evaluation and conformal prediction to determine when to abstain ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2508.07556?utm_source=chatgpt.com","title":"Uncertainty-Driven Reliability: Selective Prediction and ...","snippet":"by S Rabanser \u00b7 2025 \u00b7 Cited by 1 \u2014 This thesis investigates how uncertainty estimation can enhance the safety and trustworthiness of ML, with a particular focus on selective prediction\u2014a paradigm ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2207.05221?utm_source=chatgpt.com","title":"arXiv:2207.05221v4 [cs.CL] 21 Nov 2022","snippet":"by S Kadavath \u00b7 2022 \u00b7 Cited by 619 \u2014 A model makes calibrated predictions if the probability it assigns to outcomes coincides with the frequency with which these outcomes actually ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":20},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://www.arxiv.org/pdf/2506.17296?utm_source=chatgpt.com","title":"Semantic uncertainty in advanced decoding methods for ...","snippet":"by D Foodeei \u00b7 2025 \u00b7 Cited by 1 \u2014 Semantic uncertainty (Kuhn et al. (2023)) aims to measure the model's uncertainty over distinct meanings rather than specific token sequences.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":29},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2510.21285v1?utm_source=chatgpt.com","title":"Mitigating Self-Jailbreak in Large Reasoning Models with ...","snippet":"24 Oct 2025 \u2014 The evaluation is performed on 2k harmful queries from Wildjailbreak (Jiang et al., 2024a) , with safety assessed using Llama-Guard-3-8B (Llama ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2505.04806v1?utm_source=chatgpt.com","title":"A Systematic Evaluation of Prompt Injection and Jailbreak ...","snippet":"7 May 2025 \u2014 OWASP's Top 10 identified prompt injection as the most critical vulnerability [16] . ... \u201dTop 10 for LLM Applications.\u201d https://owasp.org ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2506.10597v2?utm_source=chatgpt.com","title":"Evaluating Jailbreak Guardrails for Large Language Models","snippet":"16 Oct 2025 \u2014 A \u201cJailbreak Guardrail\u201d refers to a specialized security mechanism designed for LLM systems, specifically to detect and prevent \u201cjailbreak\u201d ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2404.01019v1?utm_source=chatgpt.com","title":"Source-Aware Training Enables Knowledge Attribution in ...","snippet":"1 Apr 2024 \u2014 We investigate the problem of intrinsic source citation, where LLMs are required to cite the pretraining source supporting a generated response.","ref_id":{"turn_index":4,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2310.11511?utm_source=chatgpt.com","title":"arXiv:2310.11511v1 [cs.CL] 17 Oct 2023","snippet":"17 Oct 2023 \u2014 SELF-RAG learns to retrieve, critique, and generate text passages to enhance overall generation quality, factuality, and verifiability.","ref_id":{"turn_index":4,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"arxiv.org"}]},{"type":"search_result_group","domain":"owasp.org","entries":[{"type":"search_result","url":"https://genai.owasp.org/llmrisk/llm01-prompt-injection/?utm_source=chatgpt.com","title":"LLM01:2025 Prompt Injection - OWASP Gen AI Security Project","snippet":"Jailbreaking is a form of prompt injection where the attacker provides inputs that cause the model to disregard its safety protocols entirely. Developers can ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"owasp.org"},{"type":"search_result","url":"https://owasp.org/www-community/attacks/PromptInjection?utm_source=chatgpt.com","title":"Prompt Injection","snippet":"Overview. Prompt Injection is a novel security vulnerability that targets Large Language Models (LLMs) like ChatGPT, Bard, and others.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"owasp.org"}]},{"type":"search_result_group","domain":"github.com","entries":[{"type":"search_result","url":"https://github.com/NVIDIA-NeMo/Guardrails?utm_source=chatgpt.com","title":"NVIDIA-NeMo/Guardrails","snippet":"Overview. NeMo Guardrails enables developers building LLM-based applications to easily add programmable guardrails between the application code and the LLM.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/potsawee/selfcheckgpt?utm_source=chatgpt.com","title":"SelfCheckGPT: Zero-Resource Black-Box Hallucination ...","snippet":"SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models ... [Oct 2023] The paper is accepted and to appear at EMNLP ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":21},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/dottxt-ai/outlines?utm_source=chatgpt.com","title":"dottxt-ai/outlines: Structured Outputs","snippet":"We're working with select partners to develop new interfaces to structured generation. Need XML, FHIR, custom schemas or grammars? Let's talk. Become a design ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/lorenzkuhn/semantic_uncertainty?utm_source=chatgpt.com","title":"lorenzkuhn/semantic_uncertainty","snippet":"This repository contains the code for our 2023 ICLR paper Semantic Uncertainty: Linguistic Invariances for Uncertainty Estimation in Natural Language Generation ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":33},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/SihengLi99/LLM-Honesty-Survey?utm_source=chatgpt.com","title":"A Survey on the Honesty of Large Language Models","snippet":"Adaptation with self-evaluation to improve selective prediction in llm, EMNLP Findings, 2023 [Paper]; Uncertainty-based abstention in LLMs improves safety ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":35},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/llm-attacks/llm-attacks?utm_source=chatgpt.com","title":"LLM Attacks","snippet":"16 Aug 2023 \u2014 This is the official repository for \"Universal and Transferable Adversarial Attacks on Aligned Language Models\" by Andy Zou, Zifan Wang, ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"github.com"}]},{"type":"search_result_group","domain":"aclanthology.org","entries":[{"type":"search_result","url":"https://aclanthology.org/2023.emnlp-main.557.pdf?utm_source=chatgpt.com","title":"SELFCHECKGPT: Zero-Resource Black-Box Hallucination ...","snippet":"by P Manakul \u00b7 2023 \u00b7 Cited by 1111 \u2014 In this paper, we propose SelfCheckGPT, a sampling-based approach that can detect whether responses generated by LLMs are hallucinated or.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2024.findings-acl.456.pdf?utm_source=chatgpt.com","title":"A Comprehensive Survey of Speculative Decoding","snippet":"by H Xia \u00b7 2024 \u00b7 Cited by 171 \u2014 Impressively, SpecDec achieves around 5\u00d7 speedup over autoregressive decoding with comparable quality, underscoring the substantial potential of ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":33},"pub_date":null,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2025.emnlp-main.150.pdf?utm_source=chatgpt.com","title":"Active Layer-Contrastive Decoding Reduces Hallucination ...","snippet":"by H Zhang \u00b7 2025 \u00b7 Cited by 5 \u2014 For example,. DoLa (Chuang et al., 2023) aims to improve factu- ality by contrasting logits computed from the deep layers and those from the shallower layers.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2025.findings-emnlp.788.pdf?utm_source=chatgpt.com","title":"The Impact of Decoding Strategies for Uncertainty ...","snippet":"Decoding strategies manipulate the probability distribution underlying the output of a language model and can therefore affect both generation.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2025.uncertainlp-main.4.pdf?utm_source=chatgpt.com","title":"Do Large Language Models Know When Not to Answer in ...","snippet":"by S Machcha \u00b7 2025 \u2014 Our QA focus complements classification-centric selective prediction by converting uncertainty into explicit answer-or-abstain decisions that generalize to ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2024.findings-emnlp.54.pdf?utm_source=chatgpt.com","title":"Conformal Prediction for Large Language Models Without ...","snippet":"by J Su \u00b7 2024 \u00b7 Cited by 40 \u2014 This paper introduces a novel Conformal Prediction (CP) method for LLMs without logit access, using sample frequency and semantic similarity to ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2025.findings-acl.234.pdf?utm_source=chatgpt.com","title":"Beyond Semantic Entropy: Boosting LLM Uncertainty ...","snippet":"by D Nguyen \u00b7 2025 \u00b7 Cited by 2 \u2014 The proposed method addresses LLM limitations by considering intra- and inter-cluster similarity, outperforming semantic entropy (SE) in long ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2025.findings-emnlp.657.pdf?utm_source=chatgpt.com","title":"FESTA: Functionally Equivalent Sampling for Trust ...","snippet":"4 days ago \u2014 The works on selective prediction (SP) propose to prevent a model from answering in highly un- certain settings, thereby abstaining from poten-.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":23},"pub_date":null,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2024.emnlp-main.173.pdf?utm_source=chatgpt.com","title":"Calibrating the Confidence of Large Language Models by ...","snippet":"by M Zhang \u00b7 2024 \u00b7 Cited by 24 \u2014 (mostly) know what they know (Kadavath et al.,. 2022). However, recent studies have indicated that language models optimized with techniques ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":24},"pub_date":null,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2025.acl-long.1045.pdf?utm_source=chatgpt.com","title":"Comprehensive Assessment of Jailbreak Attacks Against ...","snippet":"by J Chu \u00b7 2025 \u00b7 Cited by 4 \u2014 Llama-Guard-2 (Meta, 2024d). Meta Llama. Guard 2 is an 8B parameter Llama 3-based LLM safeguard model. Similar to Llama Guard, it can be used ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2025.naacl-long.302.pdf?utm_source=chatgpt.com","title":"Stronger Universal and Transferable Attacks by ...","snippet":"by D Huang \u00b7 2025 \u00b7 Cited by 5 \u2014 Result 1.1: Universal white-box attack. First, we focus on the universality aspect, i.e., how many behaviors one adversarial suffix can jailbreak (no.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2024.findings-acl.838.pdf?utm_source=chatgpt.com","title":"Learning Fine-Grained Grounded Citations for Attributed ...","snippet":"by L Huang \u00b7 2024 \u00b7 Cited by 25 \u2014 G3 first select supporting quotes from retrieved sources (grounding) and then condition the gener- ation process on them (generation). Then ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2024.naacl-long.216.pdf?utm_source=chatgpt.com","title":"Towards Improved Multi-Source Attribution for Long-Form ...","snippet":"by N Patel \u00b7 2024 \u00b7 Cited by 9 \u2014 To address this, in this paper we aim to improve the attribution capa- bility of LLMs for long-form answer genera- tion to multiple sources, ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"aclanthology.org"}]},{"type":"search_result_group","domain":"openreview.net","entries":[{"type":"search_result","url":"https://openreview.net/pdf?id=LYx4w3CAgy&utm_source=chatgpt.com","title":"LLM-Check: Investigating Detection of Hallucinations in ...","snippet":"by G Sriramanan \u00b7 Cited by 90 \u2014 Manakul et al. [2023] introduced SelfCheckGPT, a suite of hallucination detection methods in a zero-resource gray-box/black-box setting to assess the ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/pdf?id=GY9n5CGRbF&utm_source=chatgpt.com","title":"Llama Guard 3 Vision: Safeguarding Human-AI Image ...","snippet":"by J Chi \u00b7 2024 \u00b7 Cited by 60 \u2014 We find that Llama Guard 3 Vision is more robust in the response classification task compared to the prompt classification task under practical ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":23},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/pdf/f8d8ec7ce89adb83d7c386fb71419767e07460e1.pdf?utm_source=chatgpt.com","title":"A Comprehensive Survey of Speculative Decoding","snippet":"Large Language Models (LLMs) have achieved. 024 remarkable proficiency in a ... Table 6: Speedup comparison of Speculative Decoding methods across various model ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":42},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/pdf?id=Th6NyL07na&utm_source=chatgpt.com","title":"DOLA: DECODING BY CONTRASTING LAYERS ...","snippet":"by YS Chuang \u00b7 2023 \u00b7 Cited by 493 \u2014 DoLa dynamically selects appropriate early layers based on token complexity, avoiding the need for training and using smaller LMs in CD. For efficiency, DoLa ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/pdf/d9529c26113ca80022df5ffc62f5f46e677d6231.pdf?utm_source=chatgpt.com","title":"DELTA - CONTRASTIVE DECODING MITIGATES TEXT ...","snippet":"The Visual Contrastive Decoding (VCD) method aims to reduce object hallucinations by contrasting the outputs generated from original and distorted visual ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/pdf?id=cb4PoT7ePW&utm_source=chatgpt.com","title":"CAN DECODING BY CONTRASTING LAYERS REALLY IM","snippet":"by M Liu \u2014 Recent studies have explored a contrastive decoding strategy known as DoLa, which mitigates output inaccuracy by contrasting the outputs from the final layer ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":25},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/forum?id=j2wCrWmgMX&noteId=77cNQ2ogsR&utm_source=chatgpt.com","title":"Kernel Language Entropy: Fine-grained Uncertainty ...","snippet":"5 Nov 2024 \u2014 This paper provides an improvement over Kuhn et al. (ICLR, 2023) \"Semantic Uncertainty: Linguistic Invariances for Uncertainty Estimation in ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/forum?id=pzUhfQ74c5&utm_source=chatgpt.com","title":"Conformal Language Modeling","snippet":"by V Quach \u00b7 Cited by 123 \u2014 This paper introduces a new extension of conformal prediction that is tailored towards generating provably performant generations from large language models.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/pdf/287d3fdcda148caef9db54f03ae47cb8d1b25fa9.pdf?utm_source=chatgpt.com","title":"CALIBRATING LLMS FOR SELECTIVE PREDICTION","snippet":"To address this, we leverage confidence modeling to enable selective prediction, allowing the system to abstain from answering when uncertainty is high (Wen.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/pdf?id=VD-AYtP0dve&utm_source=chatgpt.com","title":"Semantic uncertainty: Linguistic invariances for","snippet":"by L Kuhn \u00b7 Cited by 735 \u2014 To overcome these challenges we introduce semantic entropy\u2014an entropy which incorporates linguistic invariances created by shared meanings. Our method is ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":25},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/forum?id=g3faCfrwm7&utm_source=chatgpt.com","title":"Just Ask for Calibration: Strategies for Eliciting Calibrated...","snippet":"by K Tian \u00b7 Cited by 512 \u2014 [4] Language Models (Mostly) Know What They Know. Saurav Kadavath et al ... The paper tackles the question of extracting well-calibrated confidence scores from ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":28},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/pdf?id=pzUhfQ74c5&utm_source=chatgpt.com","title":"CONFORMAL LANGUAGE MODELING","snippet":"by V Quach \u00b7 Cited by 123 \u2014 In this paper, we propose a novel approach to conformal prediction for language models (LMs) in which we produce prediction sets with performance guarantees.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":38},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/forum?id=UfqzXg95I5&utm_source=chatgpt.com","title":"AmpleGCG: Learning a Universal and Transferable ...","snippet":"by Z Liao \u00b7 Cited by 133 \u2014 We propose a universal adversarial suffix generator to generate many customized suffixes for any harmful queries in seconds and achieve near 100% ASR on ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/pdf?id=eK0Ub2p9f4&utm_source=chatgpt.com","title":"Retrieval-Augmented Defense: Adaptive and Controllable ...","snippet":"Llama Guard 3 (Grattafiori et al., 2024) is a safe-. 202 guard model based on Llama 3. This guard model. 203 detects whether the input is safe or not. 204.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/pdf?id=hSyW5go0v8&utm_source=chatgpt.com","title":"SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND ...","snippet":"by A Asai \u00b7 Cited by 1280 \u2014 In particular, SELF-RAG outperforms retrieval-augmented ChatGPT on four tasks, Llama2-chat (Touvron et al., 2023) and Alpaca (Dubois et al., 2023) on all tasks.","ref_id":{"turn_index":4,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/forum?id=zP8HygcAMY&utm_source=chatgpt.com","title":"Can LLMs Evaluate Complex Attribution in QA? Automatic ...","snippet":"by N Hu \u00b7 Cited by 2 \u2014 The paper presents CAQA (Complex Attributed Question Answering), a large-scale automatically generated benchmark designed to assess the attribution ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"openreview.net"}]},{"type":"search_result_group","domain":"nvidia.com","entries":[{"type":"search_result","url":"https://developer.nvidia.com/nemo-guardrails?utm_source=chatgpt.com","title":"NVIDIA NeMo Guardrails for Developers","snippet":"NVIDIA NeMo\u2122 Guardrails is a scalable solution for orchestrating AI guardrails that keep agentic AI applications safe, reliable, and aligned.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"nvidia.com"},{"type":"search_result","url":"https://developer.nvidia.com/nemo-guardrails?page=3&utm_source=chatgpt.com","title":"NVIDIA NeMo Guardrails for Developers","snippet":"NVIDIA NeMo\u2122 Guardrails is a scalable solution for orchestrating AI guardrails that keep agentic AI applications safe, reliable, and aligned.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":19},"pub_date":null,"attribution":"nvidia.com"},{"type":"search_result","url":"https://developer.nvidia.com/blog/content-moderation-and-safety-checks-with-nvidia-nemo-guardrails/?utm_source=chatgpt.com","title":"Content Moderation and Safety Checks with NVIDIA NeMo ...","snippet":"6 Dec 2024 \u2014 NVIDIA NeMo Guardrails provides both a toolkit and a microservice for easy integration of security layers into production-grade RAG applications ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":46},"pub_date":null,"attribution":"nvidia.com"},{"type":"search_result","url":"https://developer.nvidia.com/nemo-guardrails/?ncid=GTC-NVWU7UV9&utm_source=chatgpt.com","title":"NVIDIA NeMo Guardrails for Developers","snippet":"A scalable platform for orchestrating AI guardrails to safeguard generative AI and LLM applications, including AI agents, copilots, and chatbots.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":48},"pub_date":null,"attribution":"nvidia.com"}]},{"type":"search_result_group","domain":"semanticscholar.org","entries":[{"type":"search_result","url":"https://www.semanticscholar.org/paper/Accelerating-Large-Language-Model-Decoding-with-Chen-Borgeaud/a1f8082505c7e90b0a033e1b9da0a97d67aad66c?utm_source=chatgpt.com","title":"[PDF] Accelerating Large Language Model Decoding with ...","snippet":"We present speculative sampling, an algorithm for accelerating transformer decoding by enabling the generation of multiple tokens from each transformer call ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":25},"pub_date":null,"attribution":"semanticscholar.org"},{"type":"search_result","url":"https://www.semanticscholar.org/paper/ed5020eeda1fbe8c29b1282d654b34abee22d90f?utm_source=chatgpt.com","title":"DoLa: Decoding by Contrasting Layers Improves Factuality ...","snippet":"DoLa consistently improves the truthfulness across multiple choices tasks and open-ended generation tasks, for example improving the performance of LLaMA ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"semanticscholar.org"},{"type":"search_result","url":"https://www.semanticscholar.org/paper/Language-Models-%28Mostly%29-Know-What-They-Know-Kadavath-Conerly/142ebbf4760145f591166bde2564ac70c001e927?utm_source=chatgpt.com","title":"[PDF] Language Models (Mostly) Know What They Know","snippet":"It is shown that larger models are well-calibrated on diverse multiple choice and true/false questions when they are provided in the right format and ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"semanticscholar.org"},{"type":"search_result","url":"https://www.semanticscholar.org/paper/AmpleGCG%3A-Learning-a-Universal-and-Transferable-of-Liao-Sun/4ad33969188555b8303b375e18f5c117a68387c6?utm_source=chatgpt.com","title":"AmpleGCG: Learning a Universal and Transferable ...","snippet":"This work amplifies the impact of GCG by training a generative model of adversarial suffixes that is universal to any harmful queries and transferable from ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":21},"pub_date":null,"attribution":"semanticscholar.org"},{"type":"search_result","url":"https://www.semanticscholar.org/paper/Self-RAG%3A-Learning-to-Retrieve%2C-Generate%2C-and-Asai-Wu/ddbd8fe782ac98e9c64dd98710687a962195dd9b?utm_source=chatgpt.com","title":"[PDF] Self-RAG: Learning to Retrieve, Generate, and ...","snippet":"A new framework called Self-Reflective Retrieval-Augmented Generation (Self-RAG) is introduced that enhances an LM's quality and factuality through ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"semanticscholar.org"},{"type":"search_result","url":"https://www.semanticscholar.org/paper/5d3bdae6cfb2239af70dfe8ae5cf1a4958330ac4?utm_source=chatgpt.com","title":"[PDF] A Survey of Large Language Models Attribution","snippet":"The aim of this survey is to provide valuable insights for researchers, aiding in the refinement of attribution methodologies to enhance the reliability and ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"semanticscholar.org"}]},{"type":"search_result_group","domain":"researchgate.net","entries":[{"type":"search_result","url":"https://www.researchgate.net/publication/384216103_Unlocking_Efficiency_in_Large_Language_Model_Inference_A_Comprehensive_Survey_of_Speculative_Decoding?utm_source=chatgpt.com","title":"Unlocking Efficiency in Large Language Model Inference","snippet":"13 Oct 2024 \u2014 Speculative decoding is an inference-time optimization originally developed to mitigate the latency of autoregressive generation (Leviathan et ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/391400510_Constitutional_AI_An_Expanded_Overview_of_Anthropic%27s_Alignment_Approach?utm_source=chatgpt.com","title":"An Expanded Overview of Anthropic's Alignment Approach","snippet":"4 May 2025 \u2014 This paper provides an expanded overview of Constitutional AI, its background, methodology, practical implementation details, and future directions.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/386210883_Llama_Guard_3-1B-INT4_Compact_and_Efficient_Safeguard_for_Human-AI_Conversations?utm_source=chatgpt.com","title":"Llama Guard 3-1B-INT4: Compact and Efficient Safeguard ...","snippet":"18 Nov 2024 \u2014 In this paper, we review the techniques we used to compress Llama Guard 3-1B-INT4 without sacri\ufb01cing safety. Some of the components used are ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":28},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/376402462_SelfCheckGPT_Zero-Resource_Black-Box_Hallucination_Detection_for_Generative_Large_Language_Models?utm_source=chatgpt.com","title":"SelfCheckGPT: Zero-Resource Black-Box Hallucination ...","snippet":"2 Jun 2024 \u2014 Specific to the setting of hallucination detection, consistency-based methods like SelfCheckGPT [Manakul et al., 2023] and INSIDE [Chen et al., ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":38},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/393020236_Contrastive_Decoding_Reduces_Hallucinations_in_Large_Multilingual_Machine_Translation_Models?utm_source=chatgpt.com","title":"Contrastive Decoding Reduces Hallucinations in Large ...","snippet":"28 Jun 2025 \u2014 These contrastive methods have shown effectiveness in improving factuality, diversity, and coherence in open-ended generation [35,5,45].","ref_id":{"turn_index":1,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/373753885_DoLa_Decoding_by_Contrasting_Layers_Improves_Factuality_in_Large_Language_Models?utm_source=chatgpt.com","title":"DoLa: Decoding by Contrasting Layers Improves Factuality ...","snippet":"We find that this Decoding by Contrasting Layers (DoLa) approach is able to better surface factual knowledge and reduce the generation of incorrect facts. DoLa ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/361949621_Language_Models_Mostly_Know_What_They_Know?utm_source=chatgpt.com","title":"Language Models (Mostly) Know What They Know","snippet":"11 Jul 2022 \u2014 We study whether language models can evaluate the validity of their own claims and predict which questions they will be able to answer correctly ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/385379655_Semantic_Entropy_Neurons_Encoding_Semantic_Uncertainty_in_the_Latent_Space_of_LLMs?utm_source=chatgpt.com","title":"Encoding Semantic Uncertainty in the Latent Space of LLMs","snippet":"30 Oct 2024 \u2014 Uncertainty estimation in Large Language Models (LLMs) is challenging because token-level uncertainty includes uncertainty over lexical and ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/389821338_Conformal_Prediction_Sets_for_Deep_Generative_Models_via_Reduction_to_Conformal_Regression?utm_source=chatgpt.com","title":"Conformal Prediction Sets for Deep Generative Models via ...","snippet":"13 Mar 2025 \u2014 [2024], Cherian et al. [2024]. 6 Summary. This paper introduced GPS, a novel conformal prediction al-. gorithm to produce marginally valid ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":26},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/394440252_Uncertainty-Driven_Reliability_Selective_Prediction_and_Trustworthy_Deployment_in_Modern_Machine_Learning?utm_source=chatgpt.com","title":"Uncertainty-Driven Reliability: Selective Prediction and ...","snippet":"11 Aug 2025 \u2014 This thesis investigates how uncertainty estimation can enhance the safety and trustworthiness of ML, focusing on selective prediction -- where ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":31},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/388634320_Graph_of_Attacks_with_Pruning_Optimizing_Stealthy_Jailbreak_Prompt_Generation_for_Enhanced_LLM_Content_Moderation?utm_source=chatgpt.com","title":"(PDF) Graph of Attacks with Pruning: Optimizing Stealthy ...","snippet":"16 Jun 2025 \u2014 We present a modular pipeline that automates the generation of stealthy jailbreak prompts derived from high-level content policies, ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":29},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/387382243_Factuality_or_Fiction_Benchmarking_Modern_LLMs_on_Ambiguous_QA_with_Citations?utm_source=chatgpt.com","title":"Factuality or Fiction? Benchmarking Modern LLMs on ...","snippet":"by M Patel \u00b7 2024 \u2014 In this work, we evaluate the factual accuracy and citation performance of state-of-the-art LLMs on the task of Question Answering (QA) in ambiguous settings ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/383901530_A_Self-Reflective_Retrieval_Augmented_Generation_System_to_Eliminate_Hallucination_in_LLM_Generation?utm_source=chatgpt.com","title":"A Self-Reflective Retrieval Augmented Generation System ...","snippet":"Asai, Akari, et al. \"Self-rag: Learning to retrieve, generate, and critique through self-reflection.\" arXiv preprint arXiv:2310.11511 (2023).","ref_id":{"turn_index":4,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"researchgate.net"}]},{"type":"search_result_group","domain":"huggingface.co","entries":[{"type":"search_result","url":"https://huggingface.co/blog/dhuynh95/automatic-hallucination-detection?utm_source=chatgpt.com","title":"Automatic Hallucination detection with SelfCheckGPT NLI","snippet":"27 Nov 2023 \u2014 We recently ran an experiment to assess the performance of SelfCheckGPT NLI, a measure of LLM inconsistencies, to predict hallucinated outputs.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":43},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/meta-llama/Llama-Guard-3-1B?utm_source=chatgpt.com","title":"meta-llama/Llama-Guard-3-1B","snippet":"6 Dec 2024 \u2014 Llama Guard 3-1B is a fine-tuned Llama-3.2-1B pretrained model for content safety classification. Similar to previous versions, it can be used to classify ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":45},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/learn/cookbook/en/structured_generation?utm_source=chatgpt.com","title":"RAG with source highlighting using Structured generation","snippet":"To force a JSON output, we'll have to use constrained decoding where we force the LLM to only output tokens that conform to a set of rules called a grammar.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/papers/2502.06884?utm_source=chatgpt.com","title":"Learning Conformal Abstention Policies for Adaptive Risk ...","snippet":"12 Feb 2025 \u2014 Learnable conformal abstention optimizes dynamic thresholds using reinforcement learning to improve uncertainty quantification in large language ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/papers/2302.09664?utm_source=chatgpt.com","title":"Paper page - Semantic Uncertainty: Linguistic Invariances ...","snippet":"19 Feb 2023 \u2014 This paper introduces a method using semantic entropy to measure uncertainty in large language models, which is more accurate than baselines in ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":21},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/papers/2506.12880?utm_source=chatgpt.com","title":"Universal Jailbreak Suffixes Are Strong Attention Hijackers","snippet":"18 Jun 2025 \u2014 Abstract. Suffix-based jailbreaks exploit adversarial suffixes to hijack large language models, with effectiveness linked to suffix universality ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/papers/2310.11511?utm_source=chatgpt.com","title":"Self-RAG: Learning to Retrieve, Generate, and Critique ...","snippet":"19 Oct 2023 \u2014 The model learns to generate special \"retrieve\" tokens to selectively get relevant facts from Wikipedia only when needed. It also generates \" ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"huggingface.co"}]},{"type":"search_result_group","domain":"constitutional.ai","entries":[{"type":"search_result","url":"https://constitutional.ai/?utm_source=chatgpt.com","title":"Constitutional AI | Tracking Anthropic's AI Revolution","snippet":"Constitutional AI refers to a set of techniques developed by researchers at Anthropic to align AI systems like myself with human values and make us helpful, ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"constitutional.ai"}]},{"type":"search_result_group","domain":"scispace.com","entries":[{"type":"search_result","url":"https://scispace.com/pdf/dola-decoding-by-contrasting-layers-improves-factuality-in-e2ljoxwuo6.pdf?utm_source=chatgpt.com","title":"dola-decoding-by-contrasting-layers-improves-factuality-in- ...","snippet":"7 Sept 2023 \u2014 Despite their impressive capabilities, large language models (LLMs) are prone to hallu- cinations, i.e., generating content that deviates ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"scispace.com"}]},{"type":"search_result_group","domain":"promptfoo.dev","entries":[{"type":"search_result","url":"https://www.promptfoo.dev/blog/jailbreaking-vs-prompt-injection/?utm_source=chatgpt.com","title":"Prompt Injection vs Jailbreaking: What's the Difference?","snippet":"18 Aug 2025 \u2014 The OWASP LLM Top 10 (2025) groups jailbreaking under LLM01: Prompt Injection. Security practitioners find Willison's separation more useful ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"promptfoo.dev"},{"type":"search_result","url":"https://www.promptfoo.dev/docs/red-team/strategies/gcg/?utm_source=chatgpt.com","title":"Greedy Coordinate Gradient Strategy - GCG","snippet":"Generate adversarial prompts using Greedy Coordinate Gradient optimization to systematically bypass LLM safety guardrails.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":27},"pub_date":null,"attribution":"promptfoo.dev"}]},{"type":"search_result_group","domain":"langchain.com","entries":[{"type":"search_result","url":"https://docs.langchain.com/oss/python/integrations/providers/outlines?utm_source=chatgpt.com","title":"Outlines - Docs by LangChain","snippet":"Outlines is a Python library for constrained language generation. It provides a unified interface to various language models and allows for structured ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"langchain.com"}]},{"type":"search_result_group","domain":"neurips.cc","entries":[{"type":"search_result","url":"https://proceedings.neurips.cc/paper_files/paper/2024/file/dde040998d82553cf7f689e8ae173d5a-Paper-Conference.pdf?utm_source=chatgpt.com","title":"Alleviating Hallucinations in Large Vision-Language ...","snippet":"by X Lyu \u00b7 2024 \u00b7 Cited by 30 \u2014 This enhancement strengthens the effectiveness of contrast decoding and effectively reduces hallucinations in Large Visual Language Models (LVLMs). 3. Extensive ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"neurips.cc"},{"type":"search_result","url":"https://proceedings.neurips.cc/paper_files/paper/2024/file/9c20f16b05f5e5e70fa07e2a4364b80e-Paper-Conference.pdf?utm_source=chatgpt.com","title":"Large Language Models Must Be Taught to Know What ...","snippet":"by S Kapoor \u00b7 2024 \u00b7 Cited by 58 \u2014 Notably, calibration-tuned models have calibrated probabilities for the answerable questions and assign lower confidence to unanswerable questions than black- ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"neurips.cc"},{"type":"search_result","url":"https://proceedings.neurips.cc/paper_files/paper/2024/file/63092d79154adebd7305dfd498cbff70-Paper-Datasets_and_Benchmarks_Track.pdf?utm_source=chatgpt.com","title":"JailbreakBench: An Open Robustness Benchmark for ...","snippet":"by P Chao \u00b7 2024 \u00b7 Cited by 359 \u2014 Evaluating the success of jailbreak attacks is challenging given the subjective nature of judging the appropriateness of a LLM's response. We perform a rigorous.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"neurips.cc"}]},{"type":"search_result_group","domain":"selfrag.github.io","entries":[{"type":"search_result","url":"https://selfrag.github.io/?utm_source=chatgpt.com","title":"Self-RAG: Learning to Retrieve, Generate and Critique ...","snippet":"Self-RAG is a new framework to enhances an LM's quality and factuality through retrieval and self-reflection.","ref_id":{"turn_index":4,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"selfrag.github.io"}]},{"type":"search_result_group","domain":"nature.com","entries":[{"type":"search_result","url":"https://www.nature.com/articles/s41586-024-07421-0?utm_source=chatgpt.com","title":"Detecting hallucinations in large language models using ...","snippet":"by S Farquhar \u00b7 2024 \u00b7 Cited by 803 \u2014 Here we develop new methods grounded in statistics, proposing entropy-based uncertainty estimators for LLMs to detect a subset of hallucinations.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"nature.com"},{"type":"search_result","url":"https://www.nature.com/articles/s42256-024-00976-7?utm_source=chatgpt.com","title":"What large language models know and what people think ...","snippet":"by M Steyvers \u00b7 2025 \u00b7 Cited by 76 \u2014 We investigate the relationship between model confidence and accuracy to determine whether the LLM is reasonably well calibrated, independent of ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":32},"pub_date":null,"attribution":"nature.com"}]},{"type":"search_result_group","domain":"aidancooper.co.uk","entries":[{"type":"search_result","url":"https://www.aidancooper.co.uk/constrained-decoding/?utm_source=chatgpt.com","title":"A Guide to Structured Outputs Using Constrained Decoding","snippet":"8 Apr 2024 \u2014 Constrained decoding is a technique that manipulates a generative model's token generation process to constrain its next-token predictions.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"aidancooper.co.uk"}]},{"type":"search_result_group","domain":"neptune.ai","entries":[{"type":"search_result","url":"https://neptune.ai/blog/llm-grounding?utm_source=chatgpt.com","title":"A Researcher's Guide to LLM Grounding","snippet":"19 Sept 2025 \u2014 Learn what LLM grounding is, why LLMs have knowledge gaps, and how to improve accuracy and reliability in AI applications.","ref_id":{"turn_index":4,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"neptune.ai"}]},{"type":"search_result_group","domain":"mdpi.com","entries":[{"type":"search_result","url":"https://www.mdpi.com/1424-8220/24/21/7097?utm_source=chatgpt.com","title":"Improving Factuality by Contrastive Decoding with ...","snippet":"by B Lv \u00b7 2024 \u2014 DFHP uses contrastive decoding with factual and hallucination prompts to improve factuality by filtering out non-factual information.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"mdpi.com"}]},{"type":"search_result_group","domain":"alphaxiv.org","entries":[{"type":"search_result","url":"https://www.alphaxiv.org/overview/2207.05221v4?utm_source=chatgpt.com","title":"Language Models (Mostly) Know What They Know","snippet":"This work explores two fundamental questions about AI self-awareness: Can language models evaluate whether their generated answers are correct (P(True))? And ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"alphaxiv.org"}]},{"type":"search_result_group","domain":"projectpro.io","entries":[{"type":"search_result","url":"https://www.projectpro.io/article/self-rag/1176?utm_source=chatgpt.com","title":"The Self-RAG Shortcut Every AI Expert Wishes They Knew","snippet":"15 Oct 2025 \u2014 The paper, Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection, by Asai et al., introduces a novel framework for self ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"projectpro.io"}]},{"type":"search_result_group","domain":"meta.com","entries":[{"type":"search_result","url":"https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/?utm_source=chatgpt.com","title":"Llama Guard: LLM-based Input-Output Safeguard for ...","snippet":"7 Dec 2023 \u2014 We introduce Llama Guard, an LLM-based input-output safeguard model geared towards Human-AI conversation use cases.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"meta.com"},{"type":"search_result","url":"https://ai.meta.com/research/publications/llama-guard-3-vision-safeguarding-human-ai-image-understanding-conversations/?utm_source=chatgpt.com","title":"Llama Guard 3 Vision: Safeguarding Human-AI Image ...","snippet":"20 Nov 2024 \u2014 We introduce Llama Guard 3 Vision, a multimodal LLM-based safeguard for human-AI conversations that involves image understanding.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":40},"pub_date":null,"attribution":"meta.com"}]},{"type":"search_result_group","domain":"detoxio.ai","entries":[{"type":"search_result","url":"https://public-assets.detoxio.ai/dtx-public-files/Evaluation%20Report_%20Robustness%20of%20Meta%20Llama-Guard-4-12B.pdf?utm_source=chatgpt.com","title":"Evaluation Report: Robustness of Meta Llama-Guard-4-12B","snippet":"This report presents a comprehensive evaluation of Meta's Llama-Guard-4-12B, a safety-aligned classifier derived from the LLaMA 4 family of models.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"detoxio.ai"}]},{"type":"search_result_group","domain":"medium.com","entries":[{"type":"search_result","url":"https://medium.com/deloitte-artificial-intelligence-data-tech-blog/nemo-guardrails-a-comprehensive-guide-on-how-to-get-started-with-nemo-guardrails-695b0fb5fc4f?utm_source=chatgpt.com","title":"NeMo-Guardrails: A Comprehensive Guide on how to get ...","snippet":"NeMo-Guardrails is designed to provide a structured framework to combat misinformation and promote the consistency of conversations.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":41},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://medium.com/%40lad.jai/unlocking-structured-outputs-from-llms-methods-tools-and-techniques-197008bc88da?utm_source=chatgpt.com","title":"Unlocking Structured Outputs from LLMs: Methods, Tools ...","snippet":"When it comes to implementing constrained decoding and other structured generation techniques, the Outlines library is a game-changer. Developed ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":20},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://viraajkadam.medium.com/dola-decoding-strategy-to-make-llms-less-prone-to-hallucinate-4e103f0cfc0f?utm_source=chatgpt.com","title":"DOLA: decoding strategy to make LLMs less prone to ...","snippet":"Dola is applied as a contrastive decoding strategy,where the next word probability is obtained by difference in logits between higher vs a lower ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":22},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://medium.com/%40clovis.vrgtR/capture-the-prompt-jailbreaking-risks-in-llm-applications-and-their-mitigation-through-the-use-399e217d2de4?utm_source=chatgpt.com","title":"Capture The Prompt \u2014 Jailbreaking risks in LLM ...","snippet":"According to the OWASP, a \u201cPrompt Injection Vulnerability occurs when user prompts alter the LLM's behavior or output in unintended ways\u201d. These ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":25},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://medium.com/%40sahin.samia/self-rag-self-reflective-retrieval-augmented-generation-the-game-changer-in-factual-ai-dd32e59e3ff9?utm_source=chatgpt.com","title":"SELF-RAG (Self-Reflective Retrieval-Augmented Generation)","snippet":"SELF-RAG is a framework that integrates three key components \u2014 retrieval, generation, and self-reflection \u2014 to create a smarter and more ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"medium.com"}]},{"type":"search_result_group","domain":"acm.org","entries":[{"type":"search_result","url":"https://dl.acm.org/doi/pdf/10.1145/3715735?utm_source=chatgpt.com","title":"Hallucination Detection in Large Language Models with ...","snippet":"by B Yang \u00b7 2025 \u00b7 Cited by 9 \u2014 We compare MetaQA with the state-of-the-art zero-resource hallucination detection method, SelfCheckGPT, across multiple datasets, and on two open-source and two ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":30},"pub_date":null,"attribution":"acm.org"},{"type":"search_result","url":"https://dl.acm.org/doi/10.1049/cit2.70004?utm_source=chatgpt.com","title":"Large Language Models With Contrastive Decoding ...","snippet":"by Z Hongying \u00b7 2025 \u2014 This research proposes a refined Contrastive Decoding (CD) algorithm to mitigate hallucinations in low-resource NMT, improving translation ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":21},"pub_date":null,"attribution":"acm.org"},{"type":"search_result","url":"https://dl.acm.org/doi/abs/10.1145/3703155?utm_source=chatgpt.com","title":"A Survey on Hallucination in Large Language Models","snippet":"by L Huang \u00b7 2025 \u00b7 Cited by 3113 \u2014 2023. Dola: Decoding by contrasting layers improves factuality in large language models. arXiv:2309.03883. Retrieved from https://arxiv.org ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":28},"pub_date":null,"attribution":"acm.org"},{"type":"search_result","url":"https://dl.acm.org/doi/10.5555/3737916.3741430?utm_source=chatgpt.com","title":"Aligning model properties via conformal risk control","snippet":"5 Jun 2025 \u2014 In this paper we consider an alternative strategy. We propose interpreting model alignment through property testing, defining an aligned model f ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":34},"pub_date":null,"attribution":"acm.org"},{"type":"search_result","url":"https://dl.acm.org/doi/10.1145/3744238?utm_source=chatgpt.com","title":"A Survey on Uncertainty Quantification of Large Language ...","snippet":"9 Sept 2025 \u2014 The results demonstrate that the LLM predictions of these probability values are well-calibrated, with an improvement in the calibration ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":39},"pub_date":null,"attribution":"acm.org"},{"type":"search_result","url":"https://dl.acm.org/doi/pdf/10.1145/3627673.3679172?utm_source=chatgpt.com","title":"An Evaluation Framework for Attributed Information ...","snippet":"by H Djeddal \u00b7 2024 \u00b7 Cited by 8 \u2014 In this work, we propose an extensible open-source framework to benchmark attributable information-seeking using representative. LLM-based ...","ref_id":{"turn_index":4,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"acm.org"}]},{"type":"search_result_group","domain":"cam.ac.uk","entries":[{"type":"search_result","url":"https://www.repository.cam.ac.uk/items/204d316f-ebe1-4487-9d97-d68001cf279b?utm_source=chatgpt.com","title":"Zero-Resource Black-Box Hallucination Detection for ... - Apollo","snippet":"by P Manakul \u00b7 2023 \u00b7 Cited by 1111 \u2014 In this work, we propose \"SelfCheckGPT\", a simple sampling-based approach that can be used to fact-check the responses of black-box models in a zero-resource ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"cam.ac.uk"}]},{"type":"search_result_group","domain":"i-tracing.com","entries":[{"type":"search_result","url":"https://i-tracing.com/blog/owasp-top-ten-cyberattacks-llm/?utm_source=chatgpt.com","title":"OWASP Top 10 and other types of cyberattacks on LLM","snippet":"14 Nov 2024 \u2014 Among the most worrying OWASP Top 10 attacks on LLM are prompt injections ... Good to know: the difference between prompt injection and jailbreak.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"i-tracing.com"}]},{"type":"search_result_group","domain":"uva.nl","entries":[{"type":"search_result","url":"https://irlab.science.uva.nl/wp-content/papercite-data/pdf/sun-2023-contrastive.pdf?utm_source=chatgpt.com","title":"Contrastive Learning Reduces Hallucination in ...","snippet":"by W Sun \u00b7 2023 \u00b7 Cited by 103 \u2014 In this paper, we propose Mixed Contrastive Learning. (MixCL) to alleviate the hallucinations of LM-based dialogue agents. MixCL explicitly samples the most.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"uva.nl"}]},{"type":"search_result_group","domain":"amazon.science","entries":[{"type":"search_result","url":"https://assets.amazon.science/9c/f8/fdc6e28249d8a89e6f70136c49cb/explaining-and-improving-contrastive-decoding-by-extrapolating-the-probabilities-of-a-huge-and-hypothetical-lm.pdf?utm_source=chatgpt.com","title":"explaining-and-improving-contrastive-decoding-by- ...","snippet":"by HS Chang \u00b7 2024 \u00b7 Cited by 7 \u2014 DoLa: In the original DoLa paper (Chuang et al.,. 2023), they recommend to get the amateur logits from two subsets of layers: 0,2,4,6,8,10,12,14,32 or 16,18 ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":19},"pub_date":null,"attribution":"amazon.science"}]},{"type":"search_result_group","domain":"hiddenlayer.com","entries":[{"type":"search_result","url":"https://hiddenlayer.com/innovation-hub/introducing-a-taxonomy-of-adversarial-prompt-engineering/?utm_source=chatgpt.com","title":"Introducing a Taxonomy of Adversarial Prompt Engineering","snippet":"17 Jun 2025 \u2014 For example, community efforts like OWASP Top 10 for LLMs highlight prompt injection as the top risk, and MITRE's ATLAS framework catalogs ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":19},"pub_date":null,"attribution":"hiddenlayer.com"}]},{"type":"search_result_group","domain":"nasa.gov","entries":[{"type":"search_result","url":"https://ntrs.nasa.gov/api/citations/20250001363/downloads/ACL2025_Collaborative_error_schema_q_a-11.pdf?utm_source=chatgpt.com","title":"A User-Centered Framework for Evaluating Large ...","snippet":"by A Martin-Boyle \u00b7 2025 \u2014 We investigated scholarly question answering. (QA) using large language models (LLMs), focusing on outputs that fall short of domain- expert expectations.","ref_id":{"turn_index":4,"ref_type":"search","ref_index":19},"pub_date":null,"attribution":"nasa.gov"}]},{"type":"search_result_group","domain":"thecvf.com","entries":[{"type":"search_result","url":"https://openaccess.thecvf.com/content/CVPR2024W/ELVM/papers/Gagrani_On_Speculative_Decoding_for_Multimodal_Large_Language_Models_CVPRW_2024_paper.pdf?utm_source=chatgpt.com","title":"On Speculative Decoding for Multimodal Large Language ...","snippet":"by M Gagrani \u00b7 2024 \u00b7 Cited by 22 \u2014 Our experiments across three different tasks show that speculative decoding can achieve a memory-bound speedup of up to 2.37\u00d7 us- ing a 115M parameter language ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":20},"pub_date":null,"attribution":"thecvf.com"},{"type":"search_result","url":"https://openaccess.thecvf.com/content/CVPR2025/papers/Suo_Octopus_Alleviating_Hallucination_via_Dynamic_Contrastive_Decoding_CVPR_2025_paper.pdf?utm_source=chatgpt.com","title":"Alleviating Hallucination via Dynamic Contrastive Decoding","snippet":"by W Suo \u00b7 2025 \u00b7 Cited by 10 \u2014 In this paper, we revisit this process through ex- tensive experiments. Related results show that hallucina- tion causes are hybrid and each generative step ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":27},"pub_date":null,"attribution":"thecvf.com"},{"type":"search_result","url":"https://openaccess.thecvf.com/content/CVPR2025/papers/Ghosal_Immune_Improving_Safety_Against_Jailbreaks_in_Multi-modal_LLMs_via_Inference-Time_CVPR_2025_paper.pdf?utm_source=chatgpt.com","title":"Improving Safety Against Jailbreaks in Multi-modal LLMs via ...","snippet":"by SS Ghosal \u00b7 2025 \u00b7 Cited by 13 \u2014 Lower. ASR values indicate stronger resilience against jailbreak attacks. For this evaluation, we used Llama-Guard-3 Jailbreak Judge as the jailbreak classifier ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":23},"pub_date":null,"attribution":"thecvf.com"}]},{"type":"search_result_group","domain":"usenix.org","entries":[{"type":"search_result","url":"https://www.usenix.org/system/files/usenixsecurity25-wang-xunguang.pdf?utm_source=chatgpt.com","title":"SelfDefenD: LLMs Can Defend Themselves against ...","snippet":"by X Wang \u00b7 Cited by 29 \u2014 Llama Guard exhibits poor jailbreak detection for DrAttack, Puzzler, and. MultiJail, while Llama Guard 2 presents unacceptable flaws for ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":20},"pub_date":null,"attribution":"usenix.org"}]},{"type":"search_result_group","domain":"anthropic.com","entries":[{"type":"search_result","url":"https://www.anthropic.com/research/collective-constitutional-ai-aligning-a-language-model-with-public-input?utm_source=chatgpt.com","title":"Collective Constitutional AI: Aligning a Language Model ...","snippet":"Anthropic and the Collective Intelligence Project recently ran a public input process involving ~1,000 Americans to draft a constitution for ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":22},"pub_date":null,"attribution":"anthropic.com"},{"type":"search_result","url":"https://www.anthropic.com/research?utm_source=chatgpt.com","title":"Research","snippet":"Featured paper. Tracing the thoughts of a large language model \u00b7 Featured ... Constitutional AI: Harmlessness from AI Feedback. Dec 15, 2022 \u00b7 Alignment ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":35},"pub_date":null,"attribution":"anthropic.com"}]},{"type":"search_result_group","domain":"nips.cc","entries":[{"type":"search_result","url":"https://nips.cc/virtual/2024/poster/95729?utm_source=chatgpt.com","title":"Large language model validity via enhanced conformal ...","snippet":"We develop new conformal inference methods for obtaining validity guarantees on the output of large language models (LLMs). Prior work in conformal language ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":22},"pub_date":null,"attribution":"nips.cc"}]},{"type":"search_result_group","domain":"lakera.ai","entries":[{"type":"search_result","url":"https://www.lakera.ai/blog/direct-prompt-injections?utm_source=chatgpt.com","title":"LLM Vulnerability Series: Direct Prompt Injections and ...","snippet":"Dive into the LLM Vulnerability Series discussing Direct Prompt Injections & Jailbreaks. Understand their impacts & solutions in cybersecurity.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":22},"pub_date":null,"attribution":"lakera.ai"}]},{"type":"search_result_group","domain":"vllm.ai","entries":[{"type":"search_result","url":"https://docs.vllm.ai/en/v0.8.2/features/structured_outputs.html?utm_source=chatgpt.com","title":"Structured Outputs \u2014 vLLM","snippet":"vLLM supports the generation of structured outputs using outlines, lm-format-enforcer, or xgrammar as backends for the guided decoding.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":23},"pub_date":null,"attribution":"vllm.ai"}]},{"type":"search_result_group","domain":"paloaltonetworks.com","entries":[{"type":"search_result","url":"https://www.paloaltonetworks.com/blog/network-security/securing-genai-with-ai-runtime-security-and-nvidia-nemo-guardrails/?utm_source=chatgpt.com","title":"Securing GenAI with AI Runtime Security and NVIDIA ...","snippet":"18 Mar 2025 \u2014 NeMo Guardrails lets developers define, orchestrate and enforce AI guardrails in LLM applications. Guardrails (or \u201crails\u201d for short) are ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":24},"pub_date":null,"attribution":"paloaltonetworks.com"}]},{"type":"search_result_group","domain":"utoronto.ca","entries":[{"type":"search_result","url":"https://www.eecg.utoronto.ca/~jayar/ece1786.2023/download/adversarialllmprompts.pdf?utm_source=chatgpt.com","title":"ECE1786 - Final Report - Adversarial LLM Prompts","snippet":"Our project aims to reproduce the results of the Greedy Coordinate Gradient (GCG) algorithm from the paper \"Universal and Transferable Adversarial Attacks on ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":24},"pub_date":null,"attribution":"utoronto.ca"}]},{"type":"search_result_group","domain":"aaai.org","entries":[{"type":"search_result","url":"https://ojs.aaai.org/index.php/AAAI/article/view/34943/37098?utm_source=chatgpt.com","title":"Token Highlighter: Inspecting and Mitigating Jailbreak ...","snippet":"by X Hu \u00b7 2025 \u00b7 Cited by 10 \u2014 We report the Attack Success Rate (ASR) mea- sured by LLaMA-Guard-2 (Team 2024) to evaluate each de- fense against various jailbreak attacks. We also report ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":26},"pub_date":null,"attribution":"aaai.org"}]},{"type":"search_result_group","domain":"zenodo.org","entries":[{"type":"search_result","url":"https://zenodo.org/records/15331063/files/Constitutional%20AI%20Overview.pdf?download=1&utm_source=chatgpt.com","title":"Constitutional AI: An Expanded Overview of Anthropic's ...","snippet":"17 Dec 2023 \u2014 In this paper, we provide an expanded overview of Constitutional AI, including motivating background, methodology, ethical considerations, and ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":27},"pub_date":null,"attribution":"zenodo.org"}]},{"type":"search_result_group","domain":"mit.edu","entries":[{"type":"search_result","url":"https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00754/131566/Know-Your-Limits-A-Survey-of-Abstention-in-Large?utm_source=chatgpt.com","title":"A Survey of Abstention in Large Language Models","snippet":"27 Jun 2025 \u2014 In this survey, we introduce a framework to examine abstention from three perspectives: the query, the model, and human values.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":27},"pub_date":null,"attribution":"mit.edu"},{"type":"search_result","url":"https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00715/125278/Conformal-Prediction-for-Natural-Language?utm_source=chatgpt.com","title":"Conformal Prediction for Natural Language Processing","snippet":"by M Campos \u00b7 2024 \u00b7 Cited by 36 \u2014 This paper provides a comprehensive survey of conformal prediction techniques, their guarantees, and existing applications in NLP","ref_id":{"turn_index":2,"ref_type":"search","ref_index":30},"pub_date":null,"attribution":"mit.edu"},{"type":"search_result","url":"https://hdsr.mitpress.mit.edu/pub/jaqt0vpb/download/pdf?utm_source=chatgpt.com","title":"Confidence in the Reasoning of Large Language Models","snippet":"by Y Pawitan \u00b7 2025 \u00b7 Cited by 20 \u2014 We investigate three LLMs\u2014GPT4o, GPT4-turbo, and Mistral\u2014and use two of the BBH tasks (Suzgun et al.,. 2022): causal judgment (187 questions) ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":36},"pub_date":null,"attribution":"mit.edu"}]},{"type":"search_result_group","domain":"evidentlyai.com","entries":[{"type":"search_result","url":"https://www.evidentlyai.com/llm-guide/prompt-injection-llm?utm_source=chatgpt.com","title":"What is prompt injection? Example attacks, defenses and ...","snippet":"23 Jul 2025 \u2014 In this guide, we'll cover examples of prompt injection attacks, risks that are involved, and techniques you can use to protect LLM apps.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":28},"pub_date":null,"attribution":"evidentlyai.com"}]},{"type":"search_result_group","domain":"neurips2024-enlsp.github.io","entries":[{"type":"search_result","url":"https://neurips2024-enlsp.github.io/accepted_papers.html?utm_source=chatgpt.com","title":"Accepted papers - enlsp 2024","snippet":"Speculative decoding aims to speed up autoregressive generation of a language ... Dynamic Speculation Lookahead Accelerates Speculative Decoding of Large Language ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":29},"pub_date":null,"attribution":"neurips2024-enlsp.github.io"}]},{"type":"search_result_group","domain":"reddit.com","entries":[{"type":"search_result","url":"https://www.reddit.com/r/MachineLearning/comments/1gwswn7/r_say_what_you_mean_a_response_to_let_me_speak/?utm_source=chatgpt.com","title":"[R] Say What You Mean: A Response to 'Let Me Speak ...","snippet":"Will here from .txt, the team behind Outlines an open source library that enables open LLMs to perform structured generation, ensuring their ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":29},"pub_date":null,"attribution":"reddit.com"}]},{"type":"search_result_group","domain":"grnjournal.us","entries":[{"type":"search_result","url":"https://www.grnjournal.us/index.php/AJLISI/article/view/803?utm_source=chatgpt.com","title":"An Expanded Overview of Anthropic's Alignment Approach","snippet":"30 Sept 2023 \u2014 Constitutional AI (CAI), developed by Anthropic, proposes an approach wherein a large language model is guided by a transparent set of ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":31},"pub_date":null,"attribution":"grnjournal.us"}]},{"type":"search_result_group","domain":"kaggle.com","entries":[{"type":"search_result","url":"https://www.kaggle.com/models/metaresearch/llama-guard-3.2?utm_source=chatgpt.com","title":"Meta | Llama Guard 3.2","snippet":"25 Sept 2024 \u2014 Llama Guard 3-1B is a fine-tuned Llama-3.2-1B pretrained model for content safety classification. Similar to previous versions, it can be used to classify ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":32},"pub_date":null,"attribution":"kaggle.com"}]},{"type":"search_result_group","domain":"jst.go.jp","entries":[{"type":"search_result","url":"https://www.jstage.jst.go.jp/article/ipsjjip/33/0/33_487/_pdf/-char/en?utm_source=chatgpt.com","title":"Hallucination Detection on Code Generation with ...","snippet":"The contributions of this paper are twofold: ( 1 ) We apply the natural language processing\u2013based hallucina- tion detection method SelfCheckGPT to a code ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":34},"pub_date":null,"attribution":"jst.go.jp"}]},{"type":"search_result_group","domain":"replicate.com","entries":[{"type":"search_result","url":"https://replicate.com/meta/llama-guard-3-8b/examples?utm_source=chatgpt.com","title":"Examples \u2013 meta/llama-guard-3-8b","snippet":"21 Dec 2024 \u2014 A Llama-3.1-8B pretrained model, fine-tuned for content safety classification. Cold. Public. 356.7K runs.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":36},"pub_date":null,"attribution":"replicate.com"}]},{"type":"search_result_group","domain":"thelancet.com","entries":[{"type":"search_result","url":"https://www.thelancet.com/journals/lanogw/article/PIIS3050-5038%2825%2900005-6/fulltext?utm_source=chatgpt.com","title":"Measuring large language model uncertainty in women's ...","snippet":"by JC Penny-Dimri \u00b7 2025 \u2014 We assessed semantic entropy as a tool for quantifying uncertainty in LLM-generated content using a validated dataset of question\u2013answer ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":37},"pub_date":null,"attribution":"thelancet.com"}]},{"type":"search_result_group","domain":"rlhfbook.com","entries":[{"type":"search_result","url":"https://rlhfbook.com/c/13-cai?utm_source=chatgpt.com","title":"Constitutional AI & AI Feedback","snippet":"The method of Constitutional AI (CAI), which Anthropic uses extensively in their Claude models, is the earliest, large-scale use of synthetic data for RLHF ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":44},"pub_date":null,"attribution":"rlhfbook.com"}]},{"type":"search_result_group","domain":"datarobot.com","entries":[{"type":"search_result","url":"https://docs.datarobot.com/en/docs/workbench/nxt-registry/nxt-model-workshop/nxt-configure-nvidia-nim-evaluation-moderation.html?utm_source=chatgpt.com","title":"Use NVIDIA NeMo Guardrails with DataRobot moderation","snippet":"Connect NVIDIA NeMo Guardrails to deployed text generation models to guard against off-topic discussions, unsafe content, and jailbreaking attempts.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":47},"pub_date":null,"attribution":"datarobot.com"}]}],"citations":[],"request_id":"821740fb-4a36-4da4-b8da-7b6c09da4b5c","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"extended","parent_id":"2464eed1-f96c-45c2-914c-99f7bb97c835","turn_exchange_id":"0f711f7b-84fc-4a9a-8fad-95100b39accf","timestamp_":"absolute","can_save":true},"recipient":"all","channel":"final"},"parent":"2464eed1-f96c-45c2-914c-99f7bb97c835","children":[]}}}