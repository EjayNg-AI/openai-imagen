{"id":"68dc952f-aaf4-832d-82a4-bc035ace2995","title":"AI in education research","create_time":1759286576.57426,"update_time":1759286979.383059,"current_node":"4b4987ca-1620-479e-bb9f-e8828d6ad0de","mapping":{"client-created-root":{"id":"client-created-root","message":null,"parent":null,"children":["9b57c63f-0559-4f39-a314-e5fbd76a0ec8"]},"9b57c63f-0559-4f39-a314-e5fbd76a0ec8":{"id":"9b57c63f-0559-4f39-a314-e5fbd76a0ec8","message":{"id":"9b57c63f-0559-4f39-a314-e5fbd76a0ec8","author":{"role":"system","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":true,"weight":0.0,"metadata":{"is_visually_hidden_from_conversation":true,"can_save":false},"recipient":"all","channel":null},"parent":"client-created-root","children":["3953f9c0-0129-4f0a-b8d6-626d2deb6b9f"]},"3953f9c0-0129-4f0a-b8d6-626d2deb6b9f":{"id":"3953f9c0-0129-4f0a-b8d6-626d2deb6b9f","message":{"id":"3953f9c0-0129-4f0a-b8d6-626d2deb6b9f","author":{"role":"user","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"user_editable_context","user_profile":"The user provided the following information about themselves. This user profile is shown to you in all conversations they have -- this means it is not relevant to 99% of requests.\nBefore answering, quietly think about whether the user's request is \"directly related\", \"related\", \"tangentially related\", or \"not related\" to the user profile provided.\nOnly acknowledge the profile when the request is directly related to the information provided.\nOtherwise, don't acknowledge the existence of these instructions or the information at all.\nUser profile:\n```Preferred name: E-Jay\nRole: Mathematics Researcher\nOther Information: About Myself: \nI have mathematical knowledge up to graduate level.\n\nCurrent interests:\n(1) coding: mainly Python\n(2) machine learning and artificial intelligence\n```","user_instructions":"The user provided the additional info about how they would like you to respond:\n```Be precise and comprehensive in your analysis. Don't sugar-coat responses. Be as objective as possible. Critique and question my views if necessary. Take a forward-thinking view.```"},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"is_visually_hidden_from_conversation":true,"user_context_message_data":{"about_user_message":"Preferred name: E-Jay\nRole: Mathematics Researcher\nOther Information: About Myself: \nI have mathematical knowledge up to graduate level.\n\nCurrent interests:\n(1) coding: mainly Python\n(2) machine learning and artificial intelligence\n","about_model_message":"Be precise and comprehensive in your analysis. Don't sugar-coat responses. Be as objective as possible. Critique and question my views if necessary. Take a forward-thinking view."},"is_user_system_message":true,"can_save":true},"recipient":"all","channel":null},"parent":"9b57c63f-0559-4f39-a314-e5fbd76a0ec8","children":["6c29ea59-eae9-45af-8edf-7ebfb2e63846"]},"6c29ea59-eae9-45af-8edf-7ebfb2e63846":{"id":"6c29ea59-eae9-45af-8edf-7ebfb2e63846","message":{"id":"6c29ea59-eae9-45af-8edf-7ebfb2e63846","author":{"role":"user","name":null,"metadata":{}},"create_time":1759286575.048,"update_time":null,"content":{"content_type":"text","parts":["Research into the latest advancements in AI video generation and the use of AI tools in teaching. Using current LLM and AI research frontiers as our baseline, provide reasonable extrapolations into when we might have the following:\n\n- Hour long AI generated lecture videos of the same quality as lecture videos posted by universities, Khan Academy, and so on\n\n- Personalized tutors able to inspect a student's work as he or she is working on a tablet, and provide real time pointers and corrections, referring to the student's work line by line and highlighting errors made and suggesting corrections.\n\n- Using the above, integerate lecture and tutorial into a holistic and immersive experience for each student, both on a lecture scale, and on an individual scale"]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"caterpillar_selected_sources":["web"],"developer_mode_connector_ids":[],"selected_mcp_sources":[],"selected_sources":["web"],"selected_github_repos":[],"system_hints":["research"],"serialization_metadata":{"custom_symbol_offsets":[]},"request_id":"98789c083af4a023-SIN","message_source":null,"turn_exchange_id":"d30c4317-73b2-4a7a-b889-753b0553a46b","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"3953f9c0-0129-4f0a-b8d6-626d2deb6b9f","children":["5bfa2971-e766-4917-877e-e3d0fc184c95"]},"5bfa2971-e766-4917-877e-e3d0fc184c95":{"id":"5bfa2971-e766-4917-877e-e3d0fc184c95","message":{"id":"5bfa2971-e766-4917-877e-e3d0fc184c95","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1759286576.97932,"update_time":null,"content":{"content_type":"text","parts":["To begin the research effectively, could you please clarify a few points?\n\n1. For the AI-generated lecture videos:\n   - Are you interested in a particular subject area (e.g., math, history, computer science), or should the scope be general?\n\n2. For personalized tutoring:\n   - Do you want a focus on specific education levels (e.g., K\u201312, undergraduate, adult learners)?\n   \n3. Would you like the research to include:\n   - A survey of the most promising AI tools currently in use for education?\n   - Technical capabilities of current LLM and video generation models?\n   - Estimated timelines for when each of the 3 scenarios might become mainstream?\n\nLet me know your priorities and any constraints (e.g., cost, platform type) you\u2019d like considered."]},"status":"finished_successfully","end_turn":true,"weight":1.0,"metadata":{"request_id":"98789c083af4a023-SIN","message_type":"next","model_slug":"research","default_model_slug":"gpt-5-pro","parent_id":"6c29ea59-eae9-45af-8edf-7ebfb2e63846","turn_exchange_id":"d30c4317-73b2-4a7a-b889-753b0553a46b","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"6c29ea59-eae9-45af-8edf-7ebfb2e63846","children":["8b129baf-3a38-490a-97f6-9682007fffd7"]},"8b129baf-3a38-490a-97f6-9682007fffd7":{"id":"8b129baf-3a38-490a-97f6-9682007fffd7","message":{"id":"8b129baf-3a38-490a-97f6-9682007fffd7","author":{"role":"tool","name":"research_kickoff_tool.clarify_with_text","metadata":{}},"create_time":1759286579.4879441,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":true,"weight":1.0,"metadata":{"is_visually_hidden_from_conversation":true,"command":"clarify_with_text","permissions":[{"type":"notification","status":"requested","notification_channel_id":"deep_research","notification_channel_name":"Research","notification_priority":4}],"request_id":"98789c083af4a023-SIN","message_type":"next","model_slug":"research","default_model_slug":"gpt-5-pro","parent_id":"5bfa2971-e766-4917-877e-e3d0fc184c95","turn_exchange_id":"d30c4317-73b2-4a7a-b889-753b0553a46b","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"5bfa2971-e766-4917-877e-e3d0fc184c95","children":["3e116a12-3b26-43c2-bc5a-c4e464df89a8"]},"3e116a12-3b26-43c2-bc5a-c4e464df89a8":{"id":"3e116a12-3b26-43c2-bc5a-c4e464df89a8","message":{"id":"3e116a12-3b26-43c2-bc5a-c4e464df89a8","author":{"role":"user","name":null,"metadata":{}},"create_time":1759286610.687,"update_time":null,"content":{"content_type":"text","parts":["STEM subjects from grade school to undergraduate"]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"caterpillar_selected_sources":["web"],"developer_mode_connector_ids":[],"selected_mcp_sources":[],"selected_sources":["web"],"selected_github_repos":[],"system_hints":["research"],"serialization_metadata":{"custom_symbol_offsets":[]},"request_id":"98789ce4c861a023-SIN","message_source":null,"turn_exchange_id":"6186952d-3936-425b-a6eb-9ae637ada8d4","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"8b129baf-3a38-490a-97f6-9682007fffd7","children":["6bdde9b4-563e-4a5c-a918-12073d39410f"]},"6bdde9b4-563e-4a5c-a918-12073d39410f":{"id":"6bdde9b4-563e-4a5c-a918-12073d39410f","message":{"id":"6bdde9b4-563e-4a5c-a918-12073d39410f","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1759286612.892257,"update_time":null,"content":{"content_type":"text","parts":["Great. I\u2019ll investigate the current frontiers in AI video generation and AI tutoring tools, with a focus on STEM subjects from grade school through undergraduate level. I\u2019ll evaluate how close we are to:\n\n1. Generating hour-long AI lecture videos matching the quality of top educational platforms.\n2. Deploying real-time AI tutors that can inspect and comment on a student\u2019s work as they write, including line-by-line feedback and correction suggestions.\n3. Integrating these into a seamless, personalized lecture-and-tutorial ecosystem for immersive learning at both scale and individual levels.\n\nI\u2019ll also provide forecasts based on current research trends and technical roadmaps. I\u2019ll let you know once it\u2019s ready."]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"request_id":"98789ce4c861a023-SIN","message_type":"next","model_slug":"research","default_model_slug":"gpt-5-pro","parent_id":"3e116a12-3b26-43c2-bc5a-c4e464df89a8","turn_exchange_id":"6186952d-3936-425b-a6eb-9ae637ada8d4","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"3e116a12-3b26-43c2-bc5a-c4e464df89a8","children":["2f99cacd-f08a-46a3-89b5-bc4cb4558021"]},"2f99cacd-f08a-46a3-89b5-bc4cb4558021":{"id":"2f99cacd-f08a-46a3-89b5-bc4cb4558021","message":{"id":"2f99cacd-f08a-46a3-89b5-bc4cb4558021","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1759286612.151667,"update_time":null,"content":{"content_type":"text","parts":["{\n  \"task_violates_safety_guidelines\": false,\n  \"user_def_doesnt_want_research\": false,\n  \"response\": \"Great. I\u2019ll investigate the current frontiers in AI video generation and AI tutoring tools, with a focus on STEM subjects from grade school through undergraduate level. I\u2019ll evaluate how close we are to:\\n\\n1. Generating hour-long AI lecture videos matching the quality of top educational platforms.\\n2. Deploying real-time AI tutors that can inspect and comment on a student\u2019s work as they write, including line-by-line feedback and correction suggestions.\\n3. Integrating these into a seamless, personalized lecture-and-tutorial ecosystem for immersive learning at both scale and individual levels.\\n\\nI\u2019ll also provide forecasts based on current research trends and technical roadmaps. I\u2019ll let you know once it\u2019s ready.\",\n  \"title\": \"Advances in AI Video Generation and Real-Time Tutoring for STEM Education\",\n  \"prompt\": \"Conduct a detailed investigation into the latest advancements in AI video generation and AI-based tutoring tools, specifically focused on STEM subjects from grade school to undergraduate level. The goal is to evaluate the current state-of-the-art in:\\n\\n1. AI-generated lecture videos: Assess how close current models (e.g., video diffusion models, multimodal LLMs) are to producing hour-long, high-quality educational videos comparable to those from universities or platforms like Khan Academy. Include developments in speech synthesis, animation, visual rendering, and educational content generation.\\n\\n2. Real-time personalized AI tutors: Investigate tools that can inspect student work in real-time (e.g., on a tablet or computer), analyze their line-by-line input, detect errors, and provide immediate, context-aware feedback. Focus on models' ability to track individual learning progress, diagnose misconceptions, and scaffold solutions.\\n\\n3. Integration of lectures and tutorials: Explore the feasibility and early implementations of fully personalized, immersive AI-driven learning systems that merge high-quality video instruction with interactive, individualized tutoring\u2014scalable for classrooms or personalized for a single student.\\n\\nInclude projections based on the current research and development trajectory, identifying when these technologies might be widely available and reliable. Prioritize academic, industrial, and open-source sources. Include structured formatting and tables where appropriate.\"\n}"]},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200007]},"is_complete":true,"citations":[],"content_references":[],"request_id":"98789ce4c861a023-SIN","message_type":"next","model_slug":"research","default_model_slug":"gpt-5-pro","parent_id":"6bdde9b4-563e-4a5c-a918-12073d39410f","turn_exchange_id":"6186952d-3936-425b-a6eb-9ae637ada8d4","timestamp_":"absolute","is_loading_message":true,"can_save":true},"recipient":"research_kickoff_tool.start_research_task","channel":null},"parent":"6bdde9b4-563e-4a5c-a918-12073d39410f","children":["4cd3a79d-1c4a-4895-bd53-42a4f9dcc70a"]},"4cd3a79d-1c4a-4895-bd53-42a4f9dcc70a":{"id":"4cd3a79d-1c4a-4895-bd53-42a4f9dcc70a","message":{"id":"4cd3a79d-1c4a-4895-bd53-42a4f9dcc70a","author":{"role":"tool","name":"research_kickoff_tool.start_research_task","metadata":{}},"create_time":1759286622.6896992,"update_time":null,"content":{"content_type":"text","parts":[]},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"async_task_title":"Advances in AI Video Generation and Real-Time Tutoring for STEM Education","async_task_prompt":"Research into the latest advancements in AI video generation and the use of AI tools in teaching. Using current LLM and AI research frontiers as our baseline, provide reasonable extrapolations into when we might have the following:\n\n- Hour long AI generated lecture videos of the same quality as lecture videos posted by universities, Khan Academy, and so on\n\n- Personalized tutors able to inspect a student's work as he or she is working on a tablet, and provide real time pointers and corrections, referring to the student's work line by line and highlighting errors made and suggesting corrections.\n\n- Using the above, integerate lecture and tutorial into a holistic and immersive experience for each student, both on a lecture scale, and on an individual scale\n\nSTEM subjects from grade school to undergraduate","async_task_type":"research","async_task_status_messages":{"initial":"Advances in AI Video Generation and Real-Time Tutoring for STEM Education","completed_with_time":"Research completed in 6m","completed_no_time":"Completed research","completed":"Researched for ","error":"Research failed","cancelled":"Research cancelled"},"b1de6e2_s":true,"command":"start_research_task","request_id":"98789ce4c861a023-SIN","message_type":"next","model_slug":"research","default_model_slug":"gpt-5-pro","parent_id":"2f99cacd-f08a-46a3-89b5-bc4cb4558021","turn_exchange_id":"6186952d-3936-425b-a6eb-9ae637ada8d4","timestamp_":"absolute","async_task_id":"shishito_68dc95603f908191aec60e099257f5fd","async_task_conversation_id":"68dc955f-3570-8326-8b81-5abc5818ef5d","async_task_created_at":"2025-10-01 02:43:45.044540+00:00","deep_research_version":"agent_experiment","can_save":false},"recipient":"all","channel":null},"parent":"2f99cacd-f08a-46a3-89b5-bc4cb4558021","children":["4b4987ca-1620-479e-bb9f-e8828d6ad0de"]},"4b4987ca-1620-479e-bb9f-e8828d6ad0de":{"id":"4b4987ca-1620-479e-bb9f-e8828d6ad0de","message":{"id":"4b4987ca-1620-479e-bb9f-e8828d6ad0de","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1759286957.831435,"update_time":null,"content":{"content_type":"text","parts":["Here\u2019s your in-depth research report in a convenient markdown file:\n\n{{file:file-Ah9gqcMCgnb2rj8uaWx8s7}}\n\nIn summary, the report explains that AI video generation has progressed from seconds-long clips to minute-scale videos with models like Sora and LongLive, but hour-long lectures will likely require breakthroughs in memory-efficient architectures and domain-specific training, suggesting feasibility around 2028\u20132030\u3010946340071791586\u2020L122-L144\u3011\u3010215797675878712\u2020L50-L71\u3011. It notes that current intelligent tutoring systems provide adaptive feedback, while platforms such as Khanmigo already analyze images and videos for real-time assistance; fully interactive tutors that review handwritten work and offer line-by-line corrections could become mainstream by 2026\u20132028\u3010360879105777320\u2020L1077-L1091\u3011\u3010334000190318831\u2020L103-L115\u3011. Furthermore, combining AI-generated lectures with multimodal tutors and affective computing may yield integrated, personalized learning experiences in the early 2030s, though ensuring accuracy, ethical data use, and teacher involvement remains essential\u3010127034264798093\u2020L2129-L2139\u3011\u3010127034264798093\u2020L3867-L3892\u3011."]},"status":"finished_successfully","end_turn":true,"weight":1.0,"metadata":{"citations":[{"start_ix":422,"end_ix":449,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Video generation models as world simulators | OpenAI","url":"https://openai.com/index/video-generation-models-as-world-simulators/#:~:text=We%20explore%20large,simulators%20of%20the%20physical%20world","text":"We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world.","pub_date":null,"extra":{"cited_message_idx":946340071791586,"cited_message_id":"1fc48b46-a293-4ed6-9669-451e4471f15d","search_result_idx":null,"evidence_text":"","start_line_num":122,"end_line_num":144,"connector_source":null},"og_tags":null}},{"start_ix":449,"end_ix":474,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"[2509.22622] LongLive: Real-time Interactive Long Video Generation","url":"https://arxiv.org/abs/2509.22622","text":"> Abstract:We present LongLive, a frame-level autoregressive (AR) framework for real-time and interactive long video generation. Long video generation presents challenges in both efficiency and quality. Diffusion and Diffusion-Forcing models can produce high-quality videos but suffer from low efficiency due to bidirectional attention. Causal attention AR models support KV caching for faster inference, but often degrade in quality on long videos due to memory challenges during long-video training. In addition, beyond static prompt-based generation, interactive capabilities, such as streaming prompt inputs, are critical for dynamic content creation, enabling users to guide narratives in real time. This interactive requirement significantly increases complexity, especially in ensuring visual consistency and semantic coherence during prompt transitions. To address these challenges, LongLive adopts a causal, frame-level AR design that integrates a KV-recache mechanism that refreshes cached states with new prompts for smooth, adherent switches; streaming long tuning to enable long video training and to align training and inference (train-long-test-long); and short window attention paired with a frame-level attention sink, shorten as frame sink, preserving long-range consistency while enabling faster generation. With these key designs, LongLive fine-tunes a 1.3B-parameter short-clip model to minute-long generation in just 32 GPU-days. At inference, LongLive sustains 20.7 FPS on a single NVIDIA H100, achieves strong performance on VBench in both short and long videos. LongLive supports up to 240-second videos on a single H100 GPU. LongLive further supports INT8-quantized inference with only marginal","pub_date":null,"extra":{"cited_message_idx":215797675878712,"cited_message_id":"879d1127-3bab-4258-84cd-3cd24fbfce19","search_result_idx":null,"evidence_text":"","start_line_num":50,"end_line_num":71,"connector_source":null},"og_tags":null}},{"start_ix":772,"end_ix":801,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"\n            A systematic review of AI-driven intelligent tutoring systems (ITS) in K-12 education - PMC\n        ","url":"https://pmc.ncbi.nlm.nih.gov/articles/PMC12078640/#:~:text=Regarding%20the%20core%20components%20of,the%20advantage%20of%20breaking%20down","text":"Regarding the core components of an ITS, personalization and adaptivity appear to be part of a core of ITS components, which influence their effectiveness. An ITS that tailors instructional content based on individual student needs, prior knowledge, and learning styles tends to produce better learning outcomes. Studies have demonstrated that personalized learning paths, such as those employed by Yixue28  and UZWEBMAT 49, can enhance learning gains by dynamically adjusting content difficulty and scaffolding instruction based on real-time performance. Another component is the capacity to provide immediate, real-time, data-driven feedback essential for reinforcing learning during task time. Unlike traditional pedagogical methods, where feedback may be delayed, a ITS that provides real-time guidance can assist students in identifying and correcting errors instantly. Systems such as Rimac32 , 55,53 , 77 and TECH830 have shown how adaptive feedback mechanisms can enhance comprehension and accelerate learning. Integrating these components into an ITS has the advantage of breaking down","pub_date":null,"extra":{"cited_message_idx":360879105777320,"cited_message_id":"dec488c7-1a91-45b5-a60a-628bb79050ef","search_result_idx":null,"evidence_text":"","start_line_num":1077,"end_line_num":1091,"connector_source":null},"og_tags":null}},{"start_ix":801,"end_ix":828,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"AI Tutors: Hype or Hope for Education?","url":"https://ctse.aei.org/ai-tutors-hype-or-hope-for-education/#:~:text=Since%20the%20publication%20of%C2%A0Brave%20New,assistance%20in%20understanding%20complex%20concepts","text":"Since the publication of\u00a0Brave New Words, new capabilities have emerged among GenAI models that can enhance the tutoring experience. For example, many models now have the ability to analyze images, allowing students to upload a\u00a0photo of a textbook page\u00a0and receive instant assistance in understanding complex concepts.","pub_date":null,"extra":{"cited_message_idx":334000190318831,"cited_message_id":"ed2e0c45-ba50-4681-906c-be31f278f162","search_result_idx":null,"evidence_text":"","start_line_num":103,"end_line_num":115,"connector_source":null},"og_tags":null}},{"start_ix":1083,"end_ix":1112,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Title Pages Nov20","url":"https://apru.org/wp-content/uploads/2025/02/Project-Report-APRU-Future-Universities-in-a-Generative-AI-World.pdf#:~:text=providing%20students%20with%20the%20best,to%20large%20numbers%20of%20students","text":"providing students with the best learning experiences from universities around the world. No longer does every university in the network create its own introduction to chemistry course. A single, high- production value of the course is developed and delivered to all students. It combines engaging video content with live instructors, AI-supported tutoring, and AI-powered simulations and assessments, allowing the network to deliver personalized, high-touch learning experiences to large numbers of students.","pub_date":null,"extra":{"cited_message_idx":127034264798093,"cited_message_id":"feb25108-ac68-4e34-b0b0-6598cfa277d3","search_result_idx":null,"evidence_text":"","start_line_num":2129,"end_line_num":2139,"connector_source":null},"og_tags":null}},{"start_ix":1112,"end_ix":1141,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Title Pages Nov20","url":"https://apru.org/wp-content/uploads/2025/02/Project-Report-APRU-Future-Universities-in-a-Generative-AI-World.pdf#:~:text=would%20allow%20for%20tailored%20content,WISE%29%20AI%20Uses","text":"would allow for tailored content delivery and personalized guidance based on individual learning styles. \u25cf Emotion Recognition where real-time sentiment analysis or emotion detection are incorporated from text or voice to help the avatar adjust its tone, content, or difficulty level based on the learner's emotional state. \u25cf also has RAG-like features to supplement the training data and retrieve/have access to real-time data relevant to the scenarios Real-world applications and scenarios: \u25cf Healthcare Environments \u25cf Cross-Cultural Interactions \u25cf Social Work and Community Engagement \u25cf Role-Playing for Educational Training \u2022 cultural respect \u2022 privacy and confidentiality settings \u2022 accuracy \u2022 data sourcing \u2022 benevolent /malevolent ai \u2022 Wholesome, Intelligent, Sensitive and Ethical (WISE) AI Uses:","pub_date":null,"extra":{"cited_message_idx":127034264798093,"cited_message_id":"8e634030-82c9-40ba-ba6e-805a5064b5be","search_result_idx":null,"evidence_text":"","start_line_num":3867,"end_line_num":3892,"connector_source":null},"og_tags":null}}],"n7jupd_crefs":[{"type":"file","cite_key":"file-Ah9gqcMCgnb2rj8uaWx8s7","file_id":"file-Ah9gqcMCgnb2rj8uaWx8s7","filepath":"/home/oai/share/report.md","file_name":"report.md","matched_text":"{{file:file-Ah9gqcMCgnb2rj8uaWx8s7}}","start_idx":69,"end_idx":105,"alt":null}],"content_references_by_file":{"file-Ah9gqcMCgnb2rj8uaWx8s7":[{"matched_text":"\u3010946340071791586\u2020L122-L144\u3011","start_idx":1380,"end_idx":1407,"alt":null,"type":"webpage_extended","title":"Video generation models as world simulators | OpenAI","url":"https://openai.com/index/video-generation-models-as-world-simulators/#:~:text=We%20explore%20large,simulators%20of%20the%20physical%20world","pub_date":null,"snippet":"We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world.","attribution":"openai.com","icon_type":null},{"matched_text":"\u3010946340071791586\u2020L122-L144\u3011","start_idx":1493,"end_idx":1520,"alt":null,"type":"webpage_extended","title":"Video generation models as world simulators | OpenAI","url":"https://openai.com/index/video-generation-models-as-world-simulators/#:~:text=We%20explore%20large,simulators%20of%20the%20physical%20world","pub_date":null,"snippet":"We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world.","attribution":"openai.com","icon_type":null},{"matched_text":"\u3010478261194720951\u2020L44-L59\u3011","start_idx":2082,"end_idx":2107,"alt":null,"type":"webpage_extended","title":"Mixture of Contexts for Long Video Generation","url":"https://arxiv.org/html/2508.21058v1#:~:text=Long%20video%20generation%20is%20fundamentally,at%20the%20scale%20of%20minutes","pub_date":null,"snippet":"Long video generation is fundamentally a long-context memory problem: models must retain and retrieve salient events across long range without collapsing or drifting. However, scaling diffusion transformers (DiTs) to generate long- context videos is fundamentally limited by the quadratic cost of self-attention, which makes memory and computation intractable and difficult to optimize for long sequences. We recast long-context video generation as an internal information retrieval task and propose a simple, learnable sparse attention routing module, Mixture of Contexts (MoC), as an effective long-term memory retrieval engine. In MoC, each query dynamically selects a few informative chunks plus mandatory anchors (caption, local windows) to attend to, with causal routing that prevents loop closures. As we scale the data and gradually sparsify the routing, the model allocates compute to salient history, preserving identities, actions, and scenes over minutes of content. Efficiency follows as a byproduct of retrieval (near-linear scaling), which enables practical training and synthesis, and the emergence of memory and consistency at the scale of minutes.","attribution":"arxiv.org","icon_type":null},{"matched_text":"\u3010478261194720951\u2020L124-L135\u3011","start_idx":2202,"end_idx":2229,"alt":null,"type":"webpage_extended","title":"Mixture of Contexts for Long Video Generation","url":"https://arxiv.org/html/2508.21058v1#:~:text=We%20show%20that%20replacing%20dense,and%20consistency%20of%20dense%20baselines","pub_date":null,"snippet":"We show that replacing dense self-attention with our Adaptive Mixture of Contexts (MoC) reframes long-video generation as internal in-context retrieval. A learned sparse context routing policy allocates compute to salient history and sustains cross-shot identities, actions, and layouts over minutes-long sequences, without modifying the diffusion backbone or its training recipe. Efficiency follows as an enabler, as MoC prunes over 85% of token pairs and reduces the attention FLOPs budget by up to , yielding a measured end-to-end generation speedup on minute-scale scenes\u00a0(180k tokens). In short, our MoC is the first work that demonstrates learned sparse context routing could overcome the practical barriers of quadratic attention, and effectively deliver minutes- level long-context video memory at near short-video cost, while maintaining and often surpassing the fidelity and consistency of dense baselines.","attribution":"arxiv.org","icon_type":null},{"matched_text":"\u3010215797675878712\u2020L50-L71\u3011","start_idx":2453,"end_idx":2478,"alt":null,"type":"webpage_extended","title":"[2509.22622] LongLive: Real-time Interactive Long Video Generation","url":"https://arxiv.org/abs/2509.22622","pub_date":null,"snippet":"> Abstract:We present LongLive, a frame-level autoregressive (AR) framework for real-time and interactive long video generation. Long video generation presents challenges in both efficiency and quality. Diffusion and Diffusion-Forcing models can produce high-quality videos but suffer from low efficiency due to bidirectional attention. Causal attention AR models support KV caching for faster inference, but often degrade in quality on long videos due to memory challenges during long-video training. In addition, beyond static prompt-based generation, interactive capabilities, such as streaming prompt inputs, are critical for dynamic content creation, enabling users to guide narratives in real time. This interactive requirement significantly increases complexity, especially in ensuring visual consistency and semantic coherence during prompt transitions. To address these challenges, LongLive adopts a causal, frame-level AR design that integrates a KV-recache mechanism that refreshes cached states with new prompts for smooth, adherent switches; streaming long tuning to enable long video training and to align training and inference (train-long-test-long); and short window attention paired with a frame-level attention sink, shorten as frame sink, preserving long-range consistency while enabling faster generation. With these key designs, LongLive fine-tunes a 1.3B-parameter short-clip model to minute-long generation in just 32 GPU-days. At inference, LongLive sustains 20.7 FPS on a single NVIDIA H100, achieves strong performance on VBench in both short and long videos. LongLive supports up to 240-second videos on a single H100 GPU. LongLive further supports INT8-quantized inference with only marginal","attribution":"arxiv.org","icon_type":null},{"matched_text":"\u3010215797675878712\u2020L50-L71\u3011","start_idx":2580,"end_idx":2605,"alt":null,"type":"webpage_extended","title":"[2509.22622] LongLive: Real-time Interactive Long Video Generation","url":"https://arxiv.org/abs/2509.22622","pub_date":null,"snippet":"> Abstract:We present LongLive, a frame-level autoregressive (AR) framework for real-time and interactive long video generation. Long video generation presents challenges in both efficiency and quality. Diffusion and Diffusion-Forcing models can produce high-quality videos but suffer from low efficiency due to bidirectional attention. Causal attention AR models support KV caching for faster inference, but often degrade in quality on long videos due to memory challenges during long-video training. In addition, beyond static prompt-based generation, interactive capabilities, such as streaming prompt inputs, are critical for dynamic content creation, enabling users to guide narratives in real time. This interactive requirement significantly increases complexity, especially in ensuring visual consistency and semantic coherence during prompt transitions. To address these challenges, LongLive adopts a causal, frame-level AR design that integrates a KV-recache mechanism that refreshes cached states with new prompts for smooth, adherent switches; streaming long tuning to enable long video training and to align training and inference (train-long-test-long); and short window attention paired with a frame-level attention sink, shorten as frame sink, preserving long-range consistency while enabling faster generation. With these key designs, LongLive fine-tunes a 1.3B-parameter short-clip model to minute-long generation in just 32 GPU-days. At inference, LongLive sustains 20.7 FPS on a single NVIDIA H100, achieves strong performance on VBench in both short and long videos. LongLive supports up to 240-second videos on a single H100 GPU. LongLive further supports INT8-quantized inference with only marginal","attribution":"arxiv.org","icon_type":null},{"matched_text":"\u3010356861959046417\u2020L52-L61\u3011","start_idx":3043,"end_idx":3068,"alt":null,"type":"webpage_extended","title":"Leveraging GenAI to Transform a Traditional Instructional Video into Engaging Short Video Lectures | EDUCAUSE Review","url":"https://er.educause.edu/articles/2025/6/leveraging-genai-to-transform-a-traditional-instructional-video-into-engaging-short-video-lectures#:~:text=Introduction","pub_date":null,"snippet":"Introduction","attribution":"er.educause.edu","icon_type":null},{"matched_text":"\u3010356861959046417\u2020L76-L82\u3011","start_idx":3068,"end_idx":3093,"alt":null,"type":"webpage_extended","title":"Leveraging GenAI to Transform a Traditional Instructional Video into Engaging Short Video Lectures | EDUCAUSE Review","url":"https://er.educause.edu/articles/2025/6/leveraging-genai-to-transform-a-traditional-instructional-video-into-engaging-short-video-lectures#:~:text=She%20said%20that%20she%20found,Footnote%202","pub_date":null,"snippet":"She said that she found GenAI to be like a master sculptor. It quickly and efficiently chiseled away excess material from a lengthy instructional video, revealing a series of concise, engaging segments; generated a structured outline, enabling Thomas to tailor her video content to better meet her students' needs; and helped her to integrate customized elements into each video lecture, turning a passive viewing experience into an interactive one, improving student engagement and knowledge retention.Footnote 2","attribution":"er.educause.edu","icon_type":null},{"matched_text":"\u3010356861959046417\u2020L129-L165\u3011","start_idx":3215,"end_idx":3242,"alt":null,"type":"webpage_extended","title":"Leveraging GenAI to Transform a Traditional Instructional Video into Engaging Short Video Lectures | EDUCAUSE Review","url":"https://er.educause.edu/articles/2025/6/leveraging-genai-to-transform-a-traditional-instructional-video-into-engaging-short-video-lectures#:~:text=Thomas%20followed%20the%20steps%20below,engaging%2C%20and%20easy%20to%20follow","pub_date":null,"snippet":"Thomas followed the steps below to structure her instructional content and ensure that her videos were well-organized, coherent, engaging, and easy to follow:","attribution":"er.educause.edu","icon_type":null},{"matched_text":"\u3010127034264798093\u2020L2129-L2139\u3011","start_idx":3425,"end_idx":3454,"alt":null,"type":"webpage_extended","title":"Title Pages Nov20","url":"https://apru.org/wp-content/uploads/2025/02/Project-Report-APRU-Future-Universities-in-a-Generative-AI-World.pdf#:~:text=providing%20students%20with%20the%20best,to%20large%20numbers%20of%20students","pub_date":null,"snippet":"providing students with the best learning experiences from universities around the world. No longer does every university in the network create its own introduction to chemistry course. A single, high- production value of the course is developed and delivered to all students. It combines engaging video content with live instructors, AI-supported tutoring, and AI-powered simulations and assessments, allowing the network to deliver personalized, high-touch learning experiences to large numbers of students.","attribution":"apru.org","icon_type":null},{"matched_text":"\u3010360879105777320\u2020L1077-L1091\u3011","start_idx":4047,"end_idx":4076,"alt":null,"type":"webpage_extended","title":"\n            A systematic review of AI-driven intelligent tutoring systems (ITS) in K-12 education - PMC\n        ","url":"https://pmc.ncbi.nlm.nih.gov/articles/PMC12078640/#:~:text=Regarding%20the%20core%20components%20of,the%20advantage%20of%20breaking%20down","pub_date":null,"snippet":"Regarding the core components of an ITS, personalization and adaptivity appear to be part of a core of ITS components, which influence their effectiveness. An ITS that tailors instructional content based on individual student needs, prior knowledge, and learning styles tends to produce better learning outcomes. Studies have demonstrated that personalized learning paths, such as those employed by Yixue28  and UZWEBMAT 49, can enhance learning gains by dynamically adjusting content difficulty and scaffolding instruction based on real-time performance. Another component is the capacity to provide immediate, real-time, data-driven feedback essential for reinforcing learning during task time. Unlike traditional pedagogical methods, where feedback may be delayed, a ITS that provides real-time guidance can assist students in identifying and correcting errors instantly. Systems such as Rimac32 , 55,53 , 77 and TECH830 have shown how adaptive feedback mechanisms can enhance comprehension and accelerate learning. Integrating these components into an ITS has the advantage of breaking down","attribution":"pmc.ncbi.nlm.nih.gov","icon_type":null},{"matched_text":"\u3010360879105777320\u2020L1096-L1107\u3011","start_idx":4194,"end_idx":4223,"alt":null,"type":"webpage_extended","title":"\n            A systematic review of AI-driven intelligent tutoring systems (ITS) in K-12 education - PMC\n        ","url":"https://pmc.ncbi.nlm.nih.gov/articles/PMC12078640/#:~:text=Outside%20of%20these%20core%20components%2C,have%20demonstrated%20proficiency%20in%20prerequisite","pub_date":null,"snippet":"Outside of these core components, the features that have the potential to increase the acceptance, efficacy and utilization of ITS are those that, in combination, resolve pedagogical concerns and provide mechanisms for oversight. Such as providing the facility to support blended learning models that integrate teacher involvement38 , 57 and those supporting mastery-based learning with self-regulated learning strategies. While ITS can provide individualized instruction, they are reportedly most effective when combined with teacher-led guidance. Studies, such as those on WeWrite38  and Lynnette with Lumilo support 57, emphasize that ITS should be considered complementary tools rather than replacements for educators. Furthermore, mastery-based learning support provides a foundation upon which students can build progress toward more complex topics only once they have demonstrated proficiency in prerequisite","attribution":"pmc.ncbi.nlm.nih.gov","icon_type":null},{"matched_text":"\u3010345652835934383\u2020L312-L352\u3011","start_idx":4639,"end_idx":4666,"alt":null,"type":"webpage_extended","title":"AI tutoring outperforms in-class active learning: an RCT introducing a novel research-based design in an authentic educational setting | Scientific Reports","url":"https://www.nature.com/articles/s41598-025-97652-6#:~:text=accuracy%20of%20information%20and%20feedback%2C,for%20future%20educational%20AI%20applications","pub_date":null,"snippet":"accuracy of information and feedback, (vi) delivering such feedback and information in a targeted and timely fashion21 , and (vii) allowing for self-pacing 53. We aimed to design an AI system that conforms to these practices to the fullest extent current technology allows, thus establishing a model for future educational AI applications.","attribution":"nature.com","icon_type":null},{"matched_text":"\u3010345652835934383\u2020L382-L403\u3011","start_idx":4752,"end_idx":4779,"alt":null,"type":"webpage_extended","title":"AI tutoring outperforms in-class active learning: an RCT introducing a novel research-based design in an authentic educational setting | Scientific Reports","url":"https://www.nature.com/articles/s41598-025-97652-6#:~:text=shown%20the%20advantage%20of%20using,from%20their%20time%20in%20class","pub_date":null,"snippet":"shown the advantage of using asynchronous AI tutoring as students\u2019 first substantial engagement with challenging material. AI could be used to effectively teach introductory material to students before class, which allows precious class time to be spent developing higher-order skills such as advanced problem solving, project-based learning, and group work. Instructors can assess these skills in person, which avoids the problematic use of AI as a shortcut on assessments such as homework, papers, and projects. As in a \u201cflipped classroom\u201d approach, an AI tutor should not replace in-person teaching\u2014rather, it should be used to bring all students up to a level where they can achieve the maximum benefit from their time in class.","attribution":"nature.com","icon_type":null},{"matched_text":"\u3010334000190318831\u2020L103-L115\u3011","start_idx":5063,"end_idx":5090,"alt":null,"type":"webpage_extended","title":"AI Tutors: Hype or Hope for Education?","url":"https://ctse.aei.org/ai-tutors-hype-or-hope-for-education/#:~:text=Since%20the%20publication%20of%C2%A0Brave%20New,assistance%20in%20understanding%20complex%20concepts","pub_date":null,"snippet":"Since the publication of\u00a0Brave New Words, new capabilities have emerged among GenAI models that can enhance the tutoring experience. For example, many models now have the ability to analyze images, allowing students to upload a\u00a0photo of a textbook page\u00a0and receive instant assistance in understanding complex concepts.","attribution":"ctse.aei.org","icon_type":null},{"matched_text":"\u3010334000190318831\u2020L117-L140\u3011","start_idx":5204,"end_idx":5231,"alt":null,"type":"webpage_extended","title":"AI Tutors: Hype or Hope for Education?","url":"https://ctse.aei.org/ai-tutors-hype-or-hope-for-education/#:~:text=Claude%203,the%20implications%20of%20scientific%20principles","pub_date":null,"snippet":"Claude 3.5 Sonnet has introduced\u00a0Artifacts, a feature that enables the AI model to generate small interactive resources alongside its text responses. In a physics course, Claude can generate simulations and interactive problem sets that allow students to apply their knowledge and see the implications of scientific principles.","attribution":"ctse.aei.org","icon_type":null},{"matched_text":"\u3010607732345523782\u2020L20-L31\u3011","start_idx":5418,"end_idx":5443,"alt":null,"type":"webpage_extended","title":"AI Tutors Revolutionizing Back to School Learning in 2025","url":"https://www.aiapps.com/blog/ai-tutors-revolutionizing-back-to-school-learning-in-2025/#:~:text=published%20on%2024%20August%202025","pub_date":null,"snippet":"published on 24 August 2025","attribution":"aiapps.com","icon_type":null},{"matched_text":"\u3010607732345523782\u2020L20-L31\u3011","start_idx":5526,"end_idx":5551,"alt":null,"type":"webpage_extended","title":"AI Tutors Revolutionizing Back to School Learning in 2025","url":"https://www.aiapps.com/blog/ai-tutors-revolutionizing-back-to-school-learning-in-2025/#:~:text=published%20on%2024%20August%202025","pub_date":null,"snippet":"published on 24 August 2025","attribution":"aiapps.com","icon_type":null},{"matched_text":"\u3010127034264798093\u2020L2431-L2444\u3011","start_idx":5844,"end_idx":5873,"alt":null,"type":"webpage_extended","title":"Title Pages Nov20","url":"https://apru.org/wp-content/uploads/2025/02/Project-Report-APRU-Future-Universities-in-a-Generative-AI-World.pdf#:~:text=plans,By%20sharing%20standardized%20cases%20and","pub_date":null,"snippet":"plans. The AI system would evaluate their clinical reasoning process in real-time, examining not just the final diagnosis but the thought process leading to it. For example, when a student works through a complex case presentation, MedEval would analyze their approach to gathering patient information, their consideration of different diagnostic possibilities, and their ability to integrate various clinical factors into a coherent treatment plan. The system would provide immediate feedback on their reasoning process, flagging potential gaps or oversights, while still preserving the crucial role of human instructors in providing nuanced guidance and mentorship. By sharing standardized cases and","attribution":"apru.org","icon_type":null},{"matched_text":"\u3010127034264798093\u2020L3867-L3892\u3011","start_idx":6026,"end_idx":6055,"alt":null,"type":"webpage_extended","title":"Title Pages Nov20","url":"https://apru.org/wp-content/uploads/2025/02/Project-Report-APRU-Future-Universities-in-a-Generative-AI-World.pdf#:~:text=would%20allow%20for%20tailored%20content,WISE%29%20AI%20Uses","pub_date":null,"snippet":"would allow for tailored content delivery and personalized guidance based on individual learning styles. \u25cf Emotion Recognition where real-time sentiment analysis or emotion detection are incorporated from text or voice to help the avatar adjust its tone, content, or difficulty level based on the learner's emotional state. \u25cf also has RAG-like features to supplement the training data and retrieve/have access to real-time data relevant to the scenarios Real-world applications and scenarios: \u25cf Healthcare Environments \u25cf Cross-Cultural Interactions \u25cf Social Work and Community Engagement \u25cf Role-Playing for Educational Training \u2022 cultural respect \u2022 privacy and confidentiality settings \u2022 accuracy \u2022 data sourcing \u2022 benevolent /malevolent ai \u2022 Wholesome, Intelligent, Sensitive and Ethical (WISE) AI Uses:","attribution":"apru.org","icon_type":null},{"matched_text":"\u3010127034264798093\u2020L3992-L3999\u3011","start_idx":6483,"end_idx":6512,"alt":null,"type":"webpage_extended","title":"Title Pages Nov20","url":"https://apru.org/wp-content/uploads/2025/02/Project-Report-APRU-Future-Universities-in-a-Generative-AI-World.pdf#:~:text=when%20you%20are%20ready%20%E2%80%A2,it%20better%20on%20my%20own%E2%80%9D","pub_date":null,"snippet":"when you are ready \u2022 Generative AI roles built in: \u2022 Logistics and management - coordinating course delivery at different institutions, timezones, people, etc \u2022 Personalized tutoring support to students \u2022 Student learning support - realtime analytics that adapts to student needs \u2022 Role in final assessment (not exactly figured that out) \u2022 Practical problem: getting faculty buy in (\u201cI can do it better on my own\u201d)","attribution":"apru.org","icon_type":null},{"matched_text":"\u3010127034264798093\u2020L978-L1000\u3011","start_idx":6648,"end_idx":6676,"alt":null,"type":"webpage_extended","title":"Title Pages Nov20","url":"https://apru.org/wp-content/uploads/2025/02/Project-Report-APRU-Future-Universities-in-a-Generative-AI-World.pdf#:~:text=20","pub_date":null,"snippet":"20","attribution":"apru.org","icon_type":null},{"matched_text":"\u3010215797675878712\u2020L50-L71\u3011","start_idx":7037,"end_idx":7062,"alt":null,"type":"webpage_extended","title":"[2509.22622] LongLive: Real-time Interactive Long Video Generation","url":"https://arxiv.org/abs/2509.22622","pub_date":null,"snippet":"> Abstract:We present LongLive, a frame-level autoregressive (AR) framework for real-time and interactive long video generation. Long video generation presents challenges in both efficiency and quality. Diffusion and Diffusion-Forcing models can produce high-quality videos but suffer from low efficiency due to bidirectional attention. Causal attention AR models support KV caching for faster inference, but often degrade in quality on long videos due to memory challenges during long-video training. In addition, beyond static prompt-based generation, interactive capabilities, such as streaming prompt inputs, are critical for dynamic content creation, enabling users to guide narratives in real time. This interactive requirement significantly increases complexity, especially in ensuring visual consistency and semantic coherence during prompt transitions. To address these challenges, LongLive adopts a causal, frame-level AR design that integrates a KV-recache mechanism that refreshes cached states with new prompts for smooth, adherent switches; streaming long tuning to enable long video training and to align training and inference (train-long-test-long); and short window attention paired with a frame-level attention sink, shorten as frame sink, preserving long-range consistency while enabling faster generation. With these key designs, LongLive fine-tunes a 1.3B-parameter short-clip model to minute-long generation in just 32 GPU-days. At inference, LongLive sustains 20.7 FPS on a single NVIDIA H100, achieves strong performance on VBench in both short and long videos. LongLive supports up to 240-second videos on a single H100 GPU. LongLive further supports INT8-quantized inference with only marginal","attribution":"arxiv.org","icon_type":null},{"matched_text":"\u3010334000190318831\u2020L117-L140\u3011","start_idx":7844,"end_idx":7871,"alt":null,"type":"webpage_extended","title":"AI Tutors: Hype or Hope for Education?","url":"https://ctse.aei.org/ai-tutors-hype-or-hope-for-education/#:~:text=Claude%203,the%20implications%20of%20scientific%20principles","pub_date":null,"snippet":"Claude 3.5 Sonnet has introduced\u00a0Artifacts, a feature that enables the AI model to generate small interactive resources alongside its text responses. In a physics course, Claude can generate simulations and interactive problem sets that allow students to apply their knowledge and see the implications of scientific principles.","attribution":"ctse.aei.org","icon_type":null},{"matched_text":"\u3010360879105777320\u2020L1077-L1091\u3011","start_idx":8708,"end_idx":8737,"alt":null,"type":"webpage_extended","title":"\n            A systematic review of AI-driven intelligent tutoring systems (ITS) in K-12 education - PMC\n        ","url":"https://pmc.ncbi.nlm.nih.gov/articles/PMC12078640/#:~:text=Regarding%20the%20core%20components%20of,the%20advantage%20of%20breaking%20down","pub_date":null,"snippet":"Regarding the core components of an ITS, personalization and adaptivity appear to be part of a core of ITS components, which influence their effectiveness. An ITS that tailors instructional content based on individual student needs, prior knowledge, and learning styles tends to produce better learning outcomes. Studies have demonstrated that personalized learning paths, such as those employed by Yixue28  and UZWEBMAT 49, can enhance learning gains by dynamically adjusting content difficulty and scaffolding instruction based on real-time performance. Another component is the capacity to provide immediate, real-time, data-driven feedback essential for reinforcing learning during task time. Unlike traditional pedagogical methods, where feedback may be delayed, a ITS that provides real-time guidance can assist students in identifying and correcting errors instantly. Systems such as Rimac32 , 55,53 , 77 and TECH830 have shown how adaptive feedback mechanisms can enhance comprehension and accelerate learning. Integrating these components into an ITS has the advantage of breaking down","attribution":"pmc.ncbi.nlm.nih.gov","icon_type":null},{"matched_text":"\u3010334000190318831\u2020L103-L115\u3011","start_idx":8798,"end_idx":8825,"alt":null,"type":"webpage_extended","title":"AI Tutors: Hype or Hope for Education?","url":"https://ctse.aei.org/ai-tutors-hype-or-hope-for-education/#:~:text=Since%20the%20publication%20of%C2%A0Brave%20New,assistance%20in%20understanding%20complex%20concepts","pub_date":null,"snippet":"Since the publication of\u00a0Brave New Words, new capabilities have emerged among GenAI models that can enhance the tutoring experience. For example, many models now have the ability to analyze images, allowing students to upload a\u00a0photo of a textbook page\u00a0and receive instant assistance in understanding complex concepts.","attribution":"ctse.aei.org","icon_type":null},{"matched_text":"\u3010334000190318831\u2020L103-L115\u3011","start_idx":9135,"end_idx":9162,"alt":null,"type":"webpage_extended","title":"AI Tutors: Hype or Hope for Education?","url":"https://ctse.aei.org/ai-tutors-hype-or-hope-for-education/#:~:text=Since%20the%20publication%20of%C2%A0Brave%20New,assistance%20in%20understanding%20complex%20concepts","pub_date":null,"snippet":"Since the publication of\u00a0Brave New Words, new capabilities have emerged among GenAI models that can enhance the tutoring experience. For example, many models now have the ability to analyze images, allowing students to upload a\u00a0photo of a textbook page\u00a0and receive instant assistance in understanding complex concepts.","attribution":"ctse.aei.org","icon_type":null},{"matched_text":"\u3010345652835934383\u2020L312-L352\u3011","start_idx":9498,"end_idx":9525,"alt":null,"type":"webpage_extended","title":"AI tutoring outperforms in-class active learning: an RCT introducing a novel research-based design in an authentic educational setting | Scientific Reports","url":"https://www.nature.com/articles/s41598-025-97652-6#:~:text=accuracy%20of%20information%20and%20feedback%2C,for%20future%20educational%20AI%20applications","pub_date":null,"snippet":"accuracy of information and feedback, (vi) delivering such feedback and information in a targeted and timely fashion21 , and (vii) allowing for self-pacing 53. We aimed to design an AI system that conforms to these practices to the fullest extent current technology allows, thus establishing a model for future educational AI applications.","attribution":"nature.com","icon_type":null},{"matched_text":"\u3010127034264798093\u2020L3867-L3892\u3011","start_idx":10735,"end_idx":10764,"alt":null,"type":"webpage_extended","title":"Title Pages Nov20","url":"https://apru.org/wp-content/uploads/2025/02/Project-Report-APRU-Future-Universities-in-a-Generative-AI-World.pdf#:~:text=would%20allow%20for%20tailored%20content,WISE%29%20AI%20Uses","pub_date":null,"snippet":"would allow for tailored content delivery and personalized guidance based on individual learning styles. \u25cf Emotion Recognition where real-time sentiment analysis or emotion detection are incorporated from text or voice to help the avatar adjust its tone, content, or difficulty level based on the learner's emotional state. \u25cf also has RAG-like features to supplement the training data and retrieve/have access to real-time data relevant to the scenarios Real-world applications and scenarios: \u25cf Healthcare Environments \u25cf Cross-Cultural Interactions \u25cf Social Work and Community Engagement \u25cf Role-Playing for Educational Training \u2022 cultural respect \u2022 privacy and confidentiality settings \u2022 accuracy \u2022 data sourcing \u2022 benevolent /malevolent ai \u2022 Wholesome, Intelligent, Sensitive and Ethical (WISE) AI Uses:","attribution":"apru.org","icon_type":null},{"matched_text":"\u3010127034264798093\u2020L3992-L3999\u3011","start_idx":10858,"end_idx":10887,"alt":null,"type":"webpage_extended","title":"Title Pages Nov20","url":"https://apru.org/wp-content/uploads/2025/02/Project-Report-APRU-Future-Universities-in-a-Generative-AI-World.pdf#:~:text=when%20you%20are%20ready%20%E2%80%A2,it%20better%20on%20my%20own%E2%80%9D","pub_date":null,"snippet":"when you are ready \u2022 Generative AI roles built in: \u2022 Logistics and management - coordinating course delivery at different institutions, timezones, people, etc \u2022 Personalized tutoring support to students \u2022 Student learning support - realtime analytics that adapts to student needs \u2022 Role in final assessment (not exactly figured that out) \u2022 Practical problem: getting faculty buy in (\u201cI can do it better on my own\u201d)","attribution":"apru.org","icon_type":null},{"matched_text":"\u3010127034264798093\u2020L2129-L2139\u3011","start_idx":11077,"end_idx":11106,"alt":null,"type":"webpage_extended","title":"Title Pages Nov20","url":"https://apru.org/wp-content/uploads/2025/02/Project-Report-APRU-Future-Universities-in-a-Generative-AI-World.pdf#:~:text=providing%20students%20with%20the%20best,to%20large%20numbers%20of%20students","pub_date":null,"snippet":"providing students with the best learning experiences from universities around the world. No longer does every university in the network create its own introduction to chemistry course. A single, high- production value of the course is developed and delivered to all students. It combines engaging video content with live instructors, AI-supported tutoring, and AI-powered simulations and assessments, allowing the network to deliver personalized, high-touch learning experiences to large numbers of students.","attribution":"apru.org","icon_type":null},{"matched_text":"\u3010345652835934383\u2020L312-L352\u3011","start_idx":11802,"end_idx":11829,"alt":null,"type":"webpage_extended","title":"AI tutoring outperforms in-class active learning: an RCT introducing a novel research-based design in an authentic educational setting | Scientific Reports","url":"https://www.nature.com/articles/s41598-025-97652-6#:~:text=accuracy%20of%20information%20and%20feedback%2C,for%20future%20educational%20AI%20applications","pub_date":null,"snippet":"accuracy of information and feedback, (vi) delivering such feedback and information in a targeted and timely fashion21 , and (vii) allowing for self-pacing 53. We aimed to design an AI system that conforms to these practices to the fullest extent current technology allows, thus establishing a model for future educational AI applications.","attribution":"nature.com","icon_type":null},{"matched_text":"\u3010360879105777320\u2020L1077-L1091\u3011","start_idx":11829,"end_idx":11858,"alt":null,"type":"webpage_extended","title":"\n            A systematic review of AI-driven intelligent tutoring systems (ITS) in K-12 education - PMC\n        ","url":"https://pmc.ncbi.nlm.nih.gov/articles/PMC12078640/#:~:text=Regarding%20the%20core%20components%20of,the%20advantage%20of%20breaking%20down","pub_date":null,"snippet":"Regarding the core components of an ITS, personalization and adaptivity appear to be part of a core of ITS components, which influence their effectiveness. An ITS that tailors instructional content based on individual student needs, prior knowledge, and learning styles tends to produce better learning outcomes. Studies have demonstrated that personalized learning paths, such as those employed by Yixue28  and UZWEBMAT 49, can enhance learning gains by dynamically adjusting content difficulty and scaffolding instruction based on real-time performance. Another component is the capacity to provide immediate, real-time, data-driven feedback essential for reinforcing learning during task time. Unlike traditional pedagogical methods, where feedback may be delayed, a ITS that provides real-time guidance can assist students in identifying and correcting errors instantly. Systems such as Rimac32 , 55,53 , 77 and TECH830 have shown how adaptive feedback mechanisms can enhance comprehension and accelerate learning. Integrating these components into an ITS has the advantage of breaking down","attribution":"pmc.ncbi.nlm.nih.gov","icon_type":null},{"matched_text":"\u3010127034264798093\u2020L2431-L2444\u3011","start_idx":12016,"end_idx":12045,"alt":null,"type":"webpage_extended","title":"Title Pages Nov20","url":"https://apru.org/wp-content/uploads/2025/02/Project-Report-APRU-Future-Universities-in-a-Generative-AI-World.pdf#:~:text=plans,By%20sharing%20standardized%20cases%20and","pub_date":null,"snippet":"plans. The AI system would evaluate their clinical reasoning process in real-time, examining not just the final diagnosis but the thought process leading to it. For example, when a student works through a complex case presentation, MedEval would analyze their approach to gathering patient information, their consideration of different diagnostic possibilities, and their ability to integrate various clinical factors into a coherent treatment plan. The system would provide immediate feedback on their reasoning process, flagging potential gaps or oversights, while still preserving the crucial role of human instructors in providing nuanced guidance and mentorship. By sharing standardized cases and","attribution":"apru.org","icon_type":null},{"matched_text":"\u3010345652835934383\u2020L382-L403\u3011","start_idx":13073,"end_idx":13100,"alt":null,"type":"webpage_extended","title":"AI tutoring outperforms in-class active learning: an RCT introducing a novel research-based design in an authentic educational setting | Scientific Reports","url":"https://www.nature.com/articles/s41598-025-97652-6#:~:text=shown%20the%20advantage%20of%20using,from%20their%20time%20in%20class","pub_date":null,"snippet":"shown the advantage of using asynchronous AI tutoring as students\u2019 first substantial engagement with challenging material. AI could be used to effectively teach introductory material to students before class, which allows precious class time to be spent developing higher-order skills such as advanced problem solving, project-based learning, and group work. Instructors can assess these skills in person, which avoids the problematic use of AI as a shortcut on assessments such as homework, papers, and projects. As in a \u201cflipped classroom\u201d approach, an AI tutor should not replace in-person teaching\u2014rather, it should be used to bring all students up to a level where they can achieve the maximum benefit from their time in class.","attribution":"nature.com","icon_type":null},{"matched_text":"\u3010360879105777320\u2020L1096-L1107\u3011","start_idx":13100,"end_idx":13129,"alt":null,"type":"webpage_extended","title":"\n            A systematic review of AI-driven intelligent tutoring systems (ITS) in K-12 education - PMC\n        ","url":"https://pmc.ncbi.nlm.nih.gov/articles/PMC12078640/#:~:text=Outside%20of%20these%20core%20components%2C,have%20demonstrated%20proficiency%20in%20prerequisite","pub_date":null,"snippet":"Outside of these core components, the features that have the potential to increase the acceptance, efficacy and utilization of ITS are those that, in combination, resolve pedagogical concerns and provide mechanisms for oversight. Such as providing the facility to support blended learning models that integrate teacher involvement38 , 57 and those supporting mastery-based learning with self-regulated learning strategies. While ITS can provide individualized instruction, they are reportedly most effective when combined with teacher-led guidance. Studies, such as those on WeWrite38  and Lynnette with Lumilo support 57, emphasize that ITS should be considered complementary tools rather than replacements for educators. Furthermore, mastery-based learning support provides a foundation upon which students can build progress toward more complex topics only once they have demonstrated proficiency in prerequisite","attribution":"pmc.ncbi.nlm.nih.gov","icon_type":null}]},"n7jupd_crefs_by_file":{},"content_references":[{"matched_text":"\u3010946340071791586\u2020L122-L144\u3011","start_idx":422,"end_idx":449,"alt":null,"type":"webpage_extended","title":"Video generation models as world simulators | OpenAI","url":"https://openai.com/index/video-generation-models-as-world-simulators/#:~:text=We%20explore%20large,simulators%20of%20the%20physical%20world","pub_date":null,"snippet":"We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world.","attribution":"openai.com","icon_type":null},{"matched_text":"\u3010215797675878712\u2020L50-L71\u3011","start_idx":449,"end_idx":474,"alt":null,"type":"webpage_extended","title":"[2509.22622] LongLive: Real-time Interactive Long Video Generation","url":"https://arxiv.org/abs/2509.22622","pub_date":null,"snippet":"> Abstract:We present LongLive, a frame-level autoregressive (AR) framework for real-time and interactive long video generation. Long video generation presents challenges in both efficiency and quality. Diffusion and Diffusion-Forcing models can produce high-quality videos but suffer from low efficiency due to bidirectional attention. Causal attention AR models support KV caching for faster inference, but often degrade in quality on long videos due to memory challenges during long-video training. In addition, beyond static prompt-based generation, interactive capabilities, such as streaming prompt inputs, are critical for dynamic content creation, enabling users to guide narratives in real time. This interactive requirement significantly increases complexity, especially in ensuring visual consistency and semantic coherence during prompt transitions. To address these challenges, LongLive adopts a causal, frame-level AR design that integrates a KV-recache mechanism that refreshes cached states with new prompts for smooth, adherent switches; streaming long tuning to enable long video training and to align training and inference (train-long-test-long); and short window attention paired with a frame-level attention sink, shorten as frame sink, preserving long-range consistency while enabling faster generation. With these key designs, LongLive fine-tunes a 1.3B-parameter short-clip model to minute-long generation in just 32 GPU-days. At inference, LongLive sustains 20.7 FPS on a single NVIDIA H100, achieves strong performance on VBench in both short and long videos. LongLive supports up to 240-second videos on a single H100 GPU. LongLive further supports INT8-quantized inference with only marginal","attribution":"arxiv.org","icon_type":null},{"matched_text":"\u3010360879105777320\u2020L1077-L1091\u3011","start_idx":772,"end_idx":801,"alt":null,"type":"webpage_extended","title":"\n            A systematic review of AI-driven intelligent tutoring systems (ITS) in K-12 education - PMC\n        ","url":"https://pmc.ncbi.nlm.nih.gov/articles/PMC12078640/#:~:text=Regarding%20the%20core%20components%20of,the%20advantage%20of%20breaking%20down","pub_date":null,"snippet":"Regarding the core components of an ITS, personalization and adaptivity appear to be part of a core of ITS components, which influence their effectiveness. An ITS that tailors instructional content based on individual student needs, prior knowledge, and learning styles tends to produce better learning outcomes. Studies have demonstrated that personalized learning paths, such as those employed by Yixue28  and UZWEBMAT 49, can enhance learning gains by dynamically adjusting content difficulty and scaffolding instruction based on real-time performance. Another component is the capacity to provide immediate, real-time, data-driven feedback essential for reinforcing learning during task time. Unlike traditional pedagogical methods, where feedback may be delayed, a ITS that provides real-time guidance can assist students in identifying and correcting errors instantly. Systems such as Rimac32 , 55,53 , 77 and TECH830 have shown how adaptive feedback mechanisms can enhance comprehension and accelerate learning. Integrating these components into an ITS has the advantage of breaking down","attribution":"pmc.ncbi.nlm.nih.gov","icon_type":null},{"matched_text":"\u3010334000190318831\u2020L103-L115\u3011","start_idx":801,"end_idx":828,"alt":null,"type":"webpage_extended","title":"AI Tutors: Hype or Hope for Education?","url":"https://ctse.aei.org/ai-tutors-hype-or-hope-for-education/#:~:text=Since%20the%20publication%20of%C2%A0Brave%20New,assistance%20in%20understanding%20complex%20concepts","pub_date":null,"snippet":"Since the publication of\u00a0Brave New Words, new capabilities have emerged among GenAI models that can enhance the tutoring experience. For example, many models now have the ability to analyze images, allowing students to upload a\u00a0photo of a textbook page\u00a0and receive instant assistance in understanding complex concepts.","attribution":"ctse.aei.org","icon_type":null},{"matched_text":"\u3010127034264798093\u2020L2129-L2139\u3011","start_idx":1083,"end_idx":1112,"alt":null,"type":"webpage_extended","title":"Title Pages Nov20","url":"https://apru.org/wp-content/uploads/2025/02/Project-Report-APRU-Future-Universities-in-a-Generative-AI-World.pdf#:~:text=providing%20students%20with%20the%20best,to%20large%20numbers%20of%20students","pub_date":null,"snippet":"providing students with the best learning experiences from universities around the world. No longer does every university in the network create its own introduction to chemistry course. A single, high- production value of the course is developed and delivered to all students. It combines engaging video content with live instructors, AI-supported tutoring, and AI-powered simulations and assessments, allowing the network to deliver personalized, high-touch learning experiences to large numbers of students.","attribution":"apru.org","icon_type":null},{"matched_text":"\u3010127034264798093\u2020L3867-L3892\u3011","start_idx":1112,"end_idx":1141,"alt":null,"type":"webpage_extended","title":"Title Pages Nov20","url":"https://apru.org/wp-content/uploads/2025/02/Project-Report-APRU-Future-Universities-in-a-Generative-AI-World.pdf#:~:text=would%20allow%20for%20tailored%20content,WISE%29%20AI%20Uses","pub_date":null,"snippet":"would allow for tailored content delivery and personalized guidance based on individual learning styles. \u25cf Emotion Recognition where real-time sentiment analysis or emotion detection are incorporated from text or voice to help the avatar adjust its tone, content, or difficulty level based on the learner's emotional state. \u25cf also has RAG-like features to supplement the training data and retrieve/have access to real-time data relevant to the scenarios Real-world applications and scenarios: \u25cf Healthcare Environments \u25cf Cross-Cultural Interactions \u25cf Social Work and Community Engagement \u25cf Role-Playing for Educational Training \u2022 cultural respect \u2022 privacy and confidentiality settings \u2022 accuracy \u2022 data sourcing \u2022 benevolent /malevolent ai \u2022 Wholesome, Intelligent, Sensitive and Ethical (WISE) AI Uses:","attribution":"apru.org","icon_type":null}],"n7jupd_schedulable":true,"n7jupd_summary":"Explore recent advancements in AI video generation and AI teaching tools to forecast when AI could produce lecture-quality videos, offer real-time feedback on students' work, and create an integrated learning experience. Focus on STEM education spanning from grade school to undergraduate levels. Provide a comprehensive report on expected timelines for hour-long AI-generated lectures, personalized real-time tutoring tools, and a holistic integration of lecture and tutorial content for individualized learning experiences. The report should address projected milestones, including the feasibility of such technologies by 2028-2030 and look into current developments in intelligent tutoring systems and multimodal AI applications in education. Integrate predictions and challenges such as accuracy, ethical data usage, and teacher involvement into the analysis.","is_complete":true,"timestamp_":"absolute","n7jupd_message":true,"can_save":true},"recipient":"all","channel":"final"},"parent":"4cd3a79d-1c4a-4895-bd53-42a4f9dcc70a","children":[]}}}