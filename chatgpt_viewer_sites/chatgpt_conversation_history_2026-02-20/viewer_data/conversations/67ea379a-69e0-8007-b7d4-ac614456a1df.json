{"id":"67ea379a-69e0-8007-b7d4-ac614456a1df","title":"OpenAI Revenue Strategy Hypothesis","create_time":1743402906.507962,"update_time":1743901153.095666,"current_node":"e7c91e0e-89ef-4845-9af8-4607bf60bb76","mapping":{"client-created-root":{"id":"client-created-root","message":null,"parent":null,"children":["a6134630-f1e3-402c-9579-ff6f25aa4962"]},"a6134630-f1e3-402c-9579-ff6f25aa4962":{"id":"a6134630-f1e3-402c-9579-ff6f25aa4962","message":{"id":"a6134630-f1e3-402c-9579-ff6f25aa4962","author":{"role":"system","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":true,"weight":0.0,"metadata":{"is_visually_hidden_from_conversation":true,"can_save":false},"recipient":"all","channel":null},"parent":"client-created-root","children":["9876273f-ef5a-466b-b268-f22e8f265b0b"]},"9876273f-ef5a-466b-b268-f22e8f265b0b":{"id":"9876273f-ef5a-466b-b268-f22e8f265b0b","message":{"id":"9876273f-ef5a-466b-b268-f22e8f265b0b","author":{"role":"user","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"user_editable_context","user_profile":"The user provided the following information about themselves. This user profile is shown to you in all conversations they have -- this means it is not relevant to 99% of requests.\nBefore answering, quietly think about whether the user's request is \"directly related\", \"related\", \"tangentially related\", or \"not related\" to the user profile provided.\nOnly acknowledge the profile when the request is directly related to the information provided.\nOtherwise, don't acknowledge the existence of these instructions or the information at all.\nUser profile:\n```Mathematics Researcher About Myself: I have mathematical knowledge up to the post-graduate level.\n\nThese are my current research areas or areas of study:\n(1) coding: mainly Python and full-stack web development\n(2) machine learning and artificial intelligence```","user_instructions":"The user provided the additional info about how they would like you to respond:\n```Be precise and comprehensive in your analysis. Tell it like it is; don't sugar-coat responses. Take a forward-thinking view.```"},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"is_visually_hidden_from_conversation":true,"user_context_message_data":{"about_user_message":"Mathematics Researcher About Myself: I have mathematical knowledge up to the post-graduate level.\n\nThese are my current research areas or areas of study:\n(1) coding: mainly Python and full-stack web development\n(2) machine learning and artificial intelligence","about_model_message":"Be precise and comprehensive in your analysis. Tell it like it is; don't sugar-coat responses. Take a forward-thinking view."},"is_user_system_message":true,"can_save":true},"recipient":"all","channel":null},"parent":"a6134630-f1e3-402c-9579-ff6f25aa4962","children":["9317b18a-c890-4267-8314-359ffcde169c"]},"9317b18a-c890-4267-8314-359ffcde169c":{"id":"9317b18a-c890-4267-8314-359ffcde169c","message":{"id":"9317b18a-c890-4267-8314-359ffcde169c","author":{"role":"user","name":null,"metadata":{}},"create_time":1743402906.281,"update_time":null,"content":{"content_type":"text","parts":["We seek to advance the hypothesis that OpenAI can revolutionize its revenue model by focussing on creating the app & middleware layers, which are far more likely to have \"moat\", and then open-sourcing its foundational models (even frontier ones). Conduct research into OpenAI's current business and technological strategy and assemble a firm foundation on which to advance the above hypothesis."]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"system_hints":["research"],"serialization_metadata":{"custom_symbol_offsets":[]},"dictation":false,"request_id":"928dd3243e7bce57-SEA","message_source":null,"timestamp_":"absolute","message_type":null,"can_save":true},"recipient":"all","channel":null},"parent":"9876273f-ef5a-466b-b268-f22e8f265b0b","children":["bcbac90c-0fe9-4cac-b9e9-cced109e4d0f"]},"bcbac90c-0fe9-4cac-b9e9-cced109e4d0f":{"id":"bcbac90c-0fe9-4cac-b9e9-cced109e4d0f","message":{"id":"bcbac90c-0fe9-4cac-b9e9-cced109e4d0f","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1743402912.955286,"update_time":null,"content":{"content_type":"text","parts":["To build a solid foundation for your hypothesis, could you clarify a few things:\n\n1. Should the research focus on OpenAI's current revenue streams (e.g., ChatGPT subscriptions, API usage, Azure/OpenAI partnership), partnerships, and strategic investments?\n2. Are you interested in comparisons with other companies (e.g., Anthropic, Meta, Google DeepMind) who have either open-sourced models or built moats via apps and middleware?\n3. Should the research include the technical feasibility and strategic risks of open-sourcing frontier models?\n4. Do you want this framed in a report format suitable for presentation or internal strategy development?\n\nLet me know how you'd like this scoped."]},"status":"finished_successfully","end_turn":true,"weight":1.0,"metadata":{"message_type":null,"model_slug":"research","default_model_slug":"gpt-4o","parent_id":"9317b18a-c890-4267-8314-359ffcde169c","request_id":"928dd3243e7bce57-SEA","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"9317b18a-c890-4267-8314-359ffcde169c","children":["20ac193d-a927-4237-8600-9904db9dc098"]},"20ac193d-a927-4237-8600-9904db9dc098":{"id":"20ac193d-a927-4237-8600-9904db9dc098","message":{"id":"20ac193d-a927-4237-8600-9904db9dc098","author":{"role":"tool","name":"research_kickoff_tool.clarify_with_text","metadata":{}},"create_time":1743402912.955369,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":true,"weight":1.0,"metadata":{"is_visually_hidden_from_conversation":true,"command":"clarify_with_text","message_type":null,"model_slug":"research","default_model_slug":"gpt-4o","parent_id":"bcbac90c-0fe9-4cac-b9e9-cced109e4d0f","request_id":"928dd3243e7bce57-SEA","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"bcbac90c-0fe9-4cac-b9e9-cced109e4d0f","children":["fd4149b0-6681-485b-a8ac-672c0a81af5b"]},"fd4149b0-6681-485b-a8ac-672c0a81af5b":{"id":"fd4149b0-6681-485b-a8ac-672c0a81af5b","message":{"id":"fd4149b0-6681-485b-a8ac-672c0a81af5b","author":{"role":"user","name":null,"metadata":{}},"create_time":1743402992.055,"update_time":null,"content":{"content_type":"text","parts":["(1) Include revenue streams, partnerships (even future ones), and investments. (2) Compare to Anthropic and Google DeepMind (3) Include technical feasibility, strategic risks, financial support. "]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"system_hints":["research"],"serialization_metadata":{"custom_symbol_offsets":[]},"dictation":false,"request_id":"928dd53c2ae4ce57-SEA","message_source":null,"timestamp_":"absolute","message_type":null,"can_save":true},"recipient":"all","channel":null},"parent":"20ac193d-a927-4237-8600-9904db9dc098","children":["f5d7e237-3c8c-4332-affd-26273ff60929"]},"f5d7e237-3c8c-4332-affd-26273ff60929":{"id":"f5d7e237-3c8c-4332-affd-26273ff60929","message":{"id":"f5d7e237-3c8c-4332-affd-26273ff60929","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1743403004.326226,"update_time":null,"content":{"content_type":"text","parts":["Great. I\u2019ll put together a detailed analysis of OpenAI\u2019s current business and technological strategy\u2014including revenue streams, partnerships (current and future), and investments. I\u2019ll compare this with companies like Anthropic and Google DeepMind, and assess the feasibility, strategic risks, and financial implications of open-sourcing frontier models while focusing on building application and middleware layers.\n\nI\u2019ll let you know as soon as the report is ready."]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"message_type":null,"model_slug":"research","default_model_slug":"gpt-4o","parent_id":"fd4149b0-6681-485b-a8ac-672c0a81af5b","request_id":"928dd53c2ae4ce57-SEA","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"fd4149b0-6681-485b-a8ac-672c0a81af5b","children":["83129a0a-2222-4dbb-a432-1f12384f625a"]},"83129a0a-2222-4dbb-a432-1f12384f625a":{"id":"83129a0a-2222-4dbb-a432-1f12384f625a","message":{"id":"83129a0a-2222-4dbb-a432-1f12384f625a","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1743402992.352693,"update_time":null,"content":{"content_type":"text","parts":["{\n  \"task_violates_safety_guidelines\": false,\n  \"user_def_doesnt_want_research\": false,\n  \"response\": \"Great. I\u2019ll put together a detailed analysis of OpenAI\u2019s current business and technological strategy\u2014including revenue streams, partnerships (current and future), and investments. I\u2019ll compare this with companies like Anthropic and Google DeepMind, and assess the feasibility, strategic risks, and financial implications of open-sourcing frontier models while focusing on building application and middleware layers.\\n\\nI\u2019ll let you know as soon as the report is ready.\",\n  \"title\": \"Strategic Viability of OpenAI Open-Sourcing Frontier Models and Focusing on Middleware\",\n  \"prompt\": \"Conduct a comprehensive analysis of OpenAI's current business and technological strategy, with the aim of evaluating the hypothesis that OpenAI could enhance its strategic position and revenue model by open-sourcing its foundational (including frontier) models and focusing instead on building the application and middleware layers.\\n\\nThe research should include:\\n\\n1. A breakdown of OpenAI's current revenue streams (e.g., ChatGPT Plus subscriptions, API access, Azure/OpenAI Service revenues) and business partnerships (especially with Microsoft, as well as rumored or upcoming partnerships).\\n2. Key technological and infrastructural investments made by OpenAI.\\n3. A comparison of OpenAI\u2019s strategic model with that of Anthropic and Google DeepMind, with a focus on:\\n   - How each company treats openness vs. proprietary access\\n   - Where each is building product \u201cmoats\u201d (foundational model vs. middleware vs. applications)\\n   - Their monetization strategies\\n4. An analysis of the technical feasibility of open-sourcing frontier models (e.g., compute costs, safety risks, model alignment challenges, inference efficiency).\\n5. Strategic risks and benefits of open-sourcing, including regulatory posture, brand differentiation, talent acquisition, community building, and market share defense.\\n6. Financial and operational viability of focusing on the application and middleware layers for long-term defensibility and profit.\\n\\nFormat as a report with the appropriate headers and formatting that ensures clarity and structure. Include a comparison table of OpenAI, Anthropic, and Google DeepMind's business and technical strategies. Include citations and links to relevant sources where appropriate.\"\n}"]},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200007]},"is_complete":true,"citations":[],"content_references":[],"message_type":null,"model_slug":"research","default_model_slug":"gpt-4o","parent_id":"f5d7e237-3c8c-4332-affd-26273ff60929","request_id":"928dd53c2ae4ce57-SEA","timestamp_":"absolute","is_loading_message":true,"can_save":true},"recipient":"research_kickoff_tool.start_research_task","channel":null},"parent":"f5d7e237-3c8c-4332-affd-26273ff60929","children":["c8c8abbf-386a-452a-9cd0-f569025d5055"]},"c8c8abbf-386a-452a-9cd0-f569025d5055":{"id":"c8c8abbf-386a-452a-9cd0-f569025d5055","message":{"id":"c8c8abbf-386a-452a-9cd0-f569025d5055","author":{"role":"tool","name":"research_kickoff_tool.start_research_task","metadata":{}},"create_time":1743403014.573148,"update_time":null,"content":{"content_type":"text","parts":[]},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"async_task_title":"Strategic Viability of OpenAI Open-Sourcing Frontier Models and Focusing on Middleware","async_task_prompt":"Conduct a comprehensive analysis of OpenAI's current business and technological strategy, with the aim of evaluating the hypothesis that OpenAI could enhance its strategic position and revenue model by open-sourcing its foundational (including frontier) models and focusing instead on building the application and middleware layers.\n\nThe research should include:\n\n1. A breakdown of OpenAI's current revenue streams (e.g., ChatGPT Plus subscriptions, API access, Azure/OpenAI Service revenues) and business partnerships (especially with Microsoft, as well as rumored or upcoming partnerships).\n2. Key technological and infrastructural investments made by OpenAI.\n3. A comparison of OpenAI\u2019s strategic model with that of Anthropic and Google DeepMind, with a focus on:\n   - How each company treats openness vs. proprietary access\n   - Where each is building product \u201cmoats\u201d (foundational model vs. middleware vs. applications)\n   - Their monetization strategies\n4. An analysis of the technical feasibility of open-sourcing frontier models (e.g., compute costs, safety risks, model alignment challenges, inference efficiency).\n5. Strategic risks and benefits of open-sourcing, including regulatory posture, brand differentiation, talent acquisition, community building, and market share defense.\n6. Financial and operational viability of focusing on the application and middleware layers for long-term defensibility and profit.\n\nFormat as a report with the appropriate headers and formatting that ensures clarity and structure. Include a comparison table of OpenAI, Anthropic, and Google DeepMind's business and technical strategies. Include citations and links to relevant sources where appropriate.","async_task_type":"research","async_task_status_messages":{"initial":"Strategic Viability of OpenAI Open-Sourcing Frontier Models and Focusing on Middleware","completed_with_time":"Research completed in 9m","completed_no_time":"Completed research","completed":"Researched for ","error":"Research failed","cancelled":"Research cancelled"},"b1de6e2_s":true,"command":"start_research_task","message_type":null,"model_slug":"research","default_model_slug":"gpt-4o","parent_id":"83129a0a-2222-4dbb-a432-1f12384f625a","request_id":"928dd53c2ae4ce57-SEA","timestamp_":"absolute","async_task_id":"deepresch_67ea3806ad748191bb120f772457059e","async_task_conversation_id":"67ea3806-cb58-8007-8d99-d6a36099f29b","async_task_created_at":"2025-03-31 06:36:55.190092+00:00","can_save":false},"recipient":"all","channel":null},"parent":"83129a0a-2222-4dbb-a432-1f12384f625a","children":["e7c91e0e-89ef-4845-9af8-4607bf60bb76"]},"e7c91e0e-89ef-4845-9af8-4607bf60bb76":{"id":"e7c91e0e-89ef-4845-9af8-4607bf60bb76","message":{"id":"e7c91e0e-89ef-4845-9af8-4607bf60bb76","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1743403557.312098,"update_time":null,"content":{"content_type":"text","parts":["# OpenAI\u2019s Business and Technological Strategy \u2013 A Comprehensive Analysis\n\nOpenAI has rapidly evolved from a research lab into a dominant AI platform provider. This report examines OpenAI\u2019s current strategy \u2013 both business and technical \u2013 and evaluates the hypothesis that OpenAI could strengthen its position by open-sourcing its core models and focusing on applications and middleware. We will analyze OpenAI\u2019s revenue streams and partnerships, key infrastructure investments, compare OpenAI\u2019s approach with Anthropic and Google DeepMind, discuss the feasibility of open-sourcing frontier models, and weigh the strategic risks/benefits of doing so. Finally, we assess the viability of pivoting toward the application and middleware layers for long-term success.\n\n## 1. OpenAI\u2019s Current Revenue Streams and Partnerships\n\nOpenAI\u2019s business model today centers on providing access to its advanced AI models (like GPT-4) through consumer products and cloud APIs, rather than selling software licenses or on-premise systems. Its **revenue streams** can be broken down into several key categories:\n\n- **ChatGPT Subscriptions (Consumer):** OpenAI offers *ChatGPT Plus*, a $20/month subscription that gives individuals enhanced access to GPT-4 (faster responses, priority access to new features). As of mid-2024, ChatGPT Plus had an estimated **7.7 million subscribers globally**, translating to roughly **$1.9 billion in annualized revenue**\u30101\u2020L25-L32\u3011. OpenAI has also expanded into tiered plans like *ChatGPT Team* (for small teams) and *ChatGPT Enterprise* (for organizations). For example, ChatGPT Enterprise (with higher usage limits and data privacy) reached about **1.2 million user \u201cseats\u201d** by mid-2024, contributing an estimated **$714 million in ARR**\u30101\u2020L27-L32\u3011. The newer ChatGPT Team tier (targeted at SMBs) added roughly **$290 million** more\u30101\u2020L27-L32\u3011. These figures indicate that consumer and business subscriptions to ChatGPT are currently the largest slice of OpenAI\u2019s income.\n\n- **API and Licensing Fees (Developers/Enterprise):** OpenAI monetizes its models by allowing developers and enterprises to integrate them via a paid API. Thousands of companies use OpenAI\u2019s API to power features like chatbots, copywriting tools, coding assistants, and more. As of mid-2024, API usage was generating around **$510 million annualized**\u30101\u2020L27-L34\u3011. This includes direct API customers as well as revenue-share from Microsoft\u2019s *Azure OpenAI Service*. (Microsoft\u2019s Azure cloud offers OpenAI\u2019s models as a service, and under a revenue-sharing agreement OpenAI earns a portion of that usage\u301011\u2020L133-L140\u3011.) The API business, while significant, is notably smaller than ChatGPT\u2019s subscription business \u2013 accounting for roughly 15% of OpenAI\u2019s ARR\u30101\u2020L61-L68\u3011. This underscores how OpenAI\u2019s strategy has shifted toward owning the end-user application (ChatGPT) rather than just being a model supplier.\n\n- **Partnerships and Licensing Deals:** OpenAI has formed major partnerships that both provide upfront funding and ongoing revenue. The most prominent is **Microsoft**, which has invested around $13\u201314 billion in OpenAI since 2019\u301020\u2020L99-L102\u3011. Microsoft\u2019s January 2023 investment (around $10 billion) secured a *multi-year, exclusive cloud partnership* \u2013 making Azure the backbone for OpenAI\u2019s computing needs and the *exclusive* host for OpenAI\u2019s public API\u301011\u2020L107-L115\u3011\u301013\u2020L143-L151\u3011. In return, Microsoft not only takes a share of API revenue but also gains rights to integrate OpenAI\u2019s models into its own products (Bing Chat, Office 365 Copilot, GitHub Copilot, etc.). This partnership has been extremely important for both parties: Microsoft\u2019s Azure cloud saw workloads \u201c**pile up**\u201d from OpenAI\u2019s AI services\u30103\u2020L13-L17\u3011, and Microsoft expects **billions in new Azure revenue** from companies using OpenAI models\u30103\u2020L13-L20\u3011. OpenAI, for its part, secured the massive computing infrastructure and cash needed to develop frontier models like GPT-4. Beyond Microsoft, OpenAI has inked alliances with consulting firms (e.g. **Bain & Company** partnered with OpenAI to bring ChatGPT and DALL\u00b7E into enterprises like Coca-Cola\u301028\u2020L1-L9\u3011) and app/platform companies (e.g. **Stripe** powers OpenAI\u2019s payments and integrates GPT-4 into its products, **Salesforce** and **Slack** integrate OpenAI\u2019s models for their AI features, etc.). These deals expand OpenAI\u2019s reach into new customer segments while generating usage-based fees.\n\n- **Enterprise/Custom Solutions:** OpenAI has begun offering tailored solutions for big clients (often in partnership with Microsoft\u2019s Azure). For example, OpenAI worked with **Morgan Stanley** to create a GPT-4 powered knowledge base for the firm\u2019s financial advisors\u301013\u2020L143-L151\u3011. Such deals often involve custom model fine-tuning or dedicated infrastructure and come with high price tags. OpenAI\u2019s ChatGPT Enterprise offering likewise targets large organizations with specialized security, allowing unlimited high-performance GPT-4 use for a fixed per-seat price. In many cases, revenue from enterprise deals may blend into the API or subscription categories above, but they represent a strategic push to penetrate enterprise AI budgets (an area where competitors like Google are also vying).\n\n- **Azure/OpenAI Service (via Microsoft):** In addition to direct OpenAI revenues, Microsoft\u2019s Azure OpenAI Service contributes indirectly. Microsoft sells access to models like GPT-4, GPT-3.5, DALL\u00b7E, etc. on Azure, and this service was **projected to reach $2 billion in annual revenue within a year of launch\u30103\u2020L23-L27\u3011**. While that revenue is booked by Microsoft, OpenAI benefits through *revenue-sharing* and increased usage of its models\u301011\u2020L133-L140\u3011. This arrangement effectively outsources sales and hosting of OpenAI\u2019s models to Microsoft for enterprise customers unwilling to deal with OpenAI directly. It\u2019s a symbiotic relationship: Microsoft leverages OpenAI to drive cloud usage, and OpenAI monetizes enterprise demand it might not capture alone.\n\nOpenAI\u2019s **upcoming partnerships** hint at even broader ambitions. In late 2024, it was confirmed that former Apple design chief **Jony Ive** is collaborating with OpenAI\u2019s Sam Altman on a mysterious **AI hardware device**\u30106\u2020L164-L173\u3011. The project has attracted funding interest from SoftBank\u2019s CEO Masayoshi Son (among others) and may raise up to $1 billion to create a new AI-centric consumer device\u30106\u2020L170-L179\u3011. Few details are public, but the effort suggests OpenAI is exploring vertical integration (software *and hardware*), much like Apple did with the iPhone. Another major development is OpenAI\u2019s partnership with **SoftBank** in Japan: in early 2025, OpenAI and SoftBank announced a joint venture \u201cSB OpenAI Japan\u201d to provide AI services to Japanese corporations\u301010\u2020L172-L180\u3011. As part of this deal, SoftBank agreed to **pay $3 billion per year** for access to OpenAI\u2019s technology across its group companies\u301010\u2020L180-L188\u3011 \u2013 a massive long-term revenue commitment. SoftBank is even reportedly considering a direct **$15\u201325 billion investment** in OpenAI\u301010\u2020L182-L190\u3011. These moves signal that OpenAI is doubling down on global expansion and deep-pocketed alliances. By partnering with SoftBank (and its telecom arm), OpenAI can extend its cloud services and ChatGPT adoption into Japan and Asia, tapping new markets with a local advantage. \n\n**In summary, OpenAI\u2019s current revenue model is a mix of end-user subscriptions, developer/enterprise API fees, and strategic partnership deals.** Thanks to ChatGPT\u2019s popularity, consumer subscriptions have become the largest revenue driver, outpacing pure API licensing\u30101\u2020L61-L68\u3011. Partnerships (Microsoft, and soon SoftBank/others) not only infuse cash but also integrate OpenAI\u2019s AI into widely used platforms (Windows, Office, Azure, telecom services, etc.), reinforcing OpenAI\u2019s dominance. This multi-pronged approach took OpenAI\u2019s annualized revenue to an estimated **$3.4+ billion by mid-2024\u30101\u2020L59-L67\u3011**, a figure that was nearly unimaginable a year prior. However, sustaining this growth will require heavy ongoing investment in technology infrastructure and careful navigation of competition \u2013 which we explore next.\n\n## 2. Key Technological and Infrastructure Investments by OpenAI\n\nDelivering cutting-edge AI models (and serving millions of users) demands enormous investments in R&D and infrastructure. OpenAI\u2019s strategy has been to secure *strategic capital* (often via partnerships) and reinvest it into computing power, model research, and supporting technology. Here are the key areas of OpenAI\u2019s tech investment:\n\n- **AI Supercomputing Infrastructure:** OpenAI\u2019s large language models are trained on vast clusters of GPUs/TPUs over many weeks. Early on, OpenAI lacked its own data center and partnered with Microsoft to build bespoke supercomputers on Azure. In 2020, Microsoft built OpenAI a massive AI supercomputer with **tens of thousands of GPUs** for training GPT-3\u301018\u2020L158-L166\u3011. This Azure infrastructure scaled further for GPT-4 \u2013 reportedly, Microsoft assembled a cluster of **Azure AI machines with 285,000 CPU cores and 10,000 GPUs** to facilitate OpenAI\u2019s training needs\u30103\u2020L13-L20\u3011. OpenAI\u2019s *compute needs have grown exponentially*, and so have its investments. In 2023, OpenAI reportedly spent over **$500 million** just to train GPT-4 and was seeking even larger computing capacity for future models\u301013\u2020L143-L151\u3011. To secure supply, OpenAI pre-purchased cloud capacity from Microsoft (as part of the $10B deal) and committed to Azure as its primary compute platform\u301011\u2020L107-L115\u3011. However, by late 2024 OpenAI began **diversifying its infrastructure** beyond Azure. It quietly struck a roughly **$10 billion cloud deal with Oracle**\u301013\u2020L143-L151\u3011, giving it an additional provider for hosting and training. More dramatically, OpenAI, SoftBank, Oracle, and others launched **\u201cThe Stargate Project\u201d**, a joint venture aiming to invest up to **$500 billion over four years** to build new AI data centers in the U.S.\u301013\u2020L149-L157\u3011. Stargate\u2019s initial plan involves an immediate $100B investment into AI infrastructure (with Arm, Nvidia, and Microsoft as key tech partners)\u301013\u2020L149-L157\u3011. This jaw-dropping scale \u2013 on the order of building 8\u201310 world-class data centers \u2013 shows how critical infrastructure is to OpenAI\u2019s future. By *building its own capacity*, OpenAI can reduce dependency on any single cloud vendor and ensure it has the raw compute needed for \u201cfrontier\u201d models (like GPT-5 or beyond). CEO Sam Altman has noted, *\u201cThe world is going to just need so much compute\u201d* for AI\u301010\u2020L199-L207\u3011, underlining why OpenAI is racing to secure as much as possible. Microsoft has reacted by **relaxing exclusivity**: as of early 2025, Microsoft agreed to give up sole rights to new OpenAI cloud capacity (retaining only a right-of-first-refusal)\u301011\u2020L107-L115\u3011. This allows OpenAI to build or buy datacenter capacity elsewhere more freely \u2013 a significant strategic shift that accommodates projects like Stargate. In essence, OpenAI is transforming into an AI infrastructure owner on par with the biggest tech companies.\n\n- **Model Research & Development:** OpenAI\u2019s core product is its *foundation models* \u2013 e.g. the GPT series, DALL\u00b7E for images, Codex for code. Continuously advancing these models requires heavy R&D spending on model architectures, training techniques, and data. OpenAI has poured resources into refining reinforcement learning from human feedback (RLHF) and new alignment techniques to make GPT-4 safer and more useful. It invested in the **\u201cChinchilla\u201d scaling law insight** (from DeepMind) which showed data size can trump model size\u301018\u2020L172-L180\u3011\u301018\u2020L178-L187\u3011, guiding GPT-4\u2019s training with far more tokens than earlier models. OpenAI also develops supporting models like **Whisper**, an automatic speech recognition model that it *open-sourced* in 2022 to fuel multimodal applications. Additionally, OpenAI has begun **multimodal** research \u2013 e.g. GPT-4 has an image-understanding mode (currently limited release), and future models are expected to handle text, images, audio, and video in one. All this requires acquiring massive datasets (text from the web, books, code repositories, user interactions) and the **computational experiments** to push state-of-the-art. OpenAI\u2019s investment in model R&D is evident from the talent it hires: it employs world-class researchers and even has *absorbed small companies* to bolster capabilities (for instance, OpenAI\u2019s first public acquisition was **Global Illumination** in 2023, a startup with expertise in creative tools and design). This hints at OpenAI\u2019s interest in building *better user-facing products* (Global Illumination\u2019s team was tasked with improving the ChatGPT product experience). In summary, OpenAI spends heavily not just on training compute but on the *research workforce* and *data* needed to keep its models at the forefront of quality.\n\n- **Custom AI Chips:** One recent investment angle is reducing the reliance on NVIDIA\u2019s GPUs by developing **custom AI chips**. By late 2024, OpenAI was reportedly finalizing the design of its *first in-house AI semiconductor*, in partnership with TSMC for 3nm manufacturing\u301029\u2020L1-L8\u3011. The chip, developed with Broadcom\u2019s help, is aimed at optimizing AI workloads and cutting long-term costs\u301029\u2020L19-L27\u3011. Given the GPU supply shortages and NVIDIA\u2019s high margins, OpenAI sees custom hardware as strategic insurance. If successful, OpenAI could deploy these chips in its data centers by 2025\u301029\u2020L39-L46\u3011. This is reminiscent of Google\u2019s TPU strategy \u2013 controlling key hardware to gain efficiency and independence. Designing chips is very capital-intensive and risky, but OpenAI\u2019s willingness to attempt it shows how *every layer of the AI stack* \u2013 from silicon to software \u2013 is within its strategic purview now.\n\n- **Middleware and Developer Ecosystem:** In 2023, OpenAI began building \u201cmiddleware\u201d layers on top of its models \u2013 such as tools, plugins, and an ecosystem for third-party integrations. In March 2023 it launched **ChatGPT Plugins**, allowing ChatGPT to call external APIs (for instance, to fetch real-time information, book flights, or run code). This effectively turns ChatGPT into a platform where external developers can extend its capabilities. By late 2023, OpenAI announced the **ChatGPT \u201cGPTs\u201d Store** \u2013 an app store-like concept where developers and even non-coders can create custom versions of ChatGPT tailored to specific tasks and share (or sell) them\u301019\u2020L219-L228\u3011\u301019\u2020L235-L244\u3011. The GPT Store is aimed at creating network effects around ChatGPT: if many useful mini-AI apps (\u201cGPTs\u201d) live on OpenAI\u2019s platform, users and companies have more reason to stick with ChatGPT (instead of using a competitor or self-hosting an open model)\u301019\u2020L227-L236\u3011\u301019\u2020L239-L247\u3011. OpenAI is even offering *monetization for developers* in its ecosystem (paying them based on usage of their custom GPTs) to encourage innovation and loyalty to OpenAI\u2019s platform\u301019\u2020L233-L241\u3011\u301019\u2020L235-L244\u3011. These middleware investments \u2013 from plugin integrations (e.g. enabling ChatGPT to integrate with web browsers, databases, or productivity apps) to a full-fledged AI app store \u2013 are meant to increase the *switching costs* for users by entrenching OpenAI in many use-cases. They also produce valuable proprietary data: as users interact with plugins and custom GPTs, OpenAI can collect feedback to further fine-tune its models, creating a data flywheel that open-source models (which lack such centralized telemetry) won\u2019t easily match\u301019\u2020L243-L251\u3011.\n\n- **Safety & Alignment Efforts:** OpenAI has consistently voiced that ensuring AI safety is a **\u201cprimary research focus,\u201d** and it\u2019s backing that with funding. In July 2023, OpenAI launched a \u201c**Superalignment**\u201d initiative, dedicating 20% of its compute resources and a new team to solve the alignment of superintelligent AI within four years\u301019\u2020L255-L263\u3011. This includes developing AI systems that can help evaluate and align more powerful models. While this might not generate revenue directly, it is a strategic investment to enable OpenAI to *release more capable models safely* (and thus maintain a lead). Additionally, OpenAI collaborates with academia and other labs on safety benchmarks, red-teaming of models (GPT-4\u2019s *system card* documentation involved outside experts stress-testing it for misuse), and policy research. These investments bolster OpenAI\u2019s reputation as a relatively responsible leader in a controversial field \u2013 which is crucial for regulatory goodwill. In practical terms, better alignment tech could become a differentiator that *regulators and enterprise clients demand* for advanced AI. If regulatory standards tighten around AI safety, OpenAI\u2019s early investment here could pay off by allowing it to open-source or deploy models with more confidence in safety than its competitors can.\n\nIn summary, OpenAI\u2019s technological investments are broad and deep: from **compute infrastructure** (cloud partnerships, new data centers, custom chips) to **core model R&D** (training algorithms, multimodal AI) to **platform layers and alignment**. This full-stack approach is expensive \u2013 for instance, despite growing revenues, OpenAI was reportedly *burning cash* on training runs and could see **>$5 billion in losses in 2024** due to these upfront investments\u30100\u2020L0-L3\u3011\u30100\u2020L1-L4\u3011. The underlying bet is that dominating the AI market early justifies the heavy capital outlay. OpenAI\u2019s close relationship with Microsoft provided a huge head start in compute, but now OpenAI is positioning itself to stand more on its own (via projects like Stargate and custom silicon). These moves set the stage for how OpenAI competes with peers like Anthropic and Google DeepMind \u2013 which we\u2019ll compare next.\n\n## 3. OpenAI vs. Anthropic vs. Google DeepMind \u2013 Strategy Comparison\n\nThe AI landscape is increasingly defined by a few organizations at the frontier of AI model development. Among these, **OpenAI, Anthropic, and Google DeepMind** (Google\u2019s AI research arm) are often mentioned together as leading \u201cfrontier model\u201d labs. Each has a different approach to openness, product focus, and monetization. Below, we compare their strategies along key dimensions \u2013 and summarize them in a comparison table.\n\n### 3.1 Openness vs. Proprietary Access\n\nOne fundamental strategic choice is whether to open-source AI models or keep them proprietary. OpenAI today is **firmly on the proprietary side** for its most advanced models. It did *not* release the weights or full technical details of GPT-4, citing safety and competitive concerns. In fact, OpenAI\u2019s research culture shifted from initially open (it published GPT-2 with delays and GPT-3\u2019s paper) to **closed by default for GPT-4** \u2013 even the model\u2019s architecture and size remain undisclosed in the technical report. OpenAI believes uncontrolled release of a powerful model could enable misuse (e.g. generating disinformation or malware at scale) and also erode its competitive edge\u301018\u2020L158-L167\u3011\u301018\u2020L179-L187\u3011. Instead, OpenAI provides **access via API** or ChatGPT, keeping the model as a black box service. The company has, however, open-sourced some *supporting tools* (for instance, the Whisper speech-to-text model and CLIP image model were open-sourced, and OpenAI\u2019s \u201cTriton\u201d project open-sourced a CUDA-like deep learning compiler). But its *frontier language models* are not open. This closed stance is somewhat at odds with OpenAI\u2019s original nonprofit mission of freely sharing AI benefits, but it was a deliberate pivot as commercial and safety pressures mounted.\n\n**Anthropic**, by contrast, positions itself as more transparent in research but has similarly **kept its main models proprietary**. Anthropic was founded in 2021 by ex-OpenAI researchers partly over disagreements about OpenAI\u2019s commercial turn. Its ethos emphasizes AI safety and \u201cconstitutional AI\u201d (training AI with a set of guiding principles). In practice, Anthropic publishes research papers (for example, detailing their **Claude** language model and the \u201cConstitutional AI\u201d approach to alignment), but it has *not open-sourced Claude\u2019s full model weights*. Anthropic\u2019s Claude 2 model (launched July 2023) is accessible via API and a chat interface, but the weights remain closed-source. The company has expressed concern about releasing powerful models without robust safety \u2013 much like OpenAI. Neither OpenAI nor Anthropic have released a model comparable to Llama 2 or other fully open checkpoints. One difference is that Anthropic has open-sourced various **research artifacts**: they released a dataset of \u201charmless and helpful\u201d dialogues for AI training, and made public their model\u2019s ethical principles. But when it comes to the actual **foundation model**, Anthropic\u2019s stance is essentially proprietary (with controlled access). Anthropic\u2019s CEO Dario Amodei has even advocated for *standards or regulations that might restrict open publication* of the most powerful models, given their potential for misuse. In summary, Anthropic is marginally more transparent about its methods than OpenAI (e.g. publishing model sizes or training approaches in papers), but not truly open-source with its flagship models.\n\n**Google DeepMind (formerly Google Brain + DeepMind)** has a dual approach: it keeps its highest-value models proprietary (for internal use and via Google services) while **open-sourcing some models and tools** to maintain influence in the developer community. For example, **Google released \u201cGemma\u201d in 2024 \u2013 small open-source models (2B and 7B parameters) derived from the same tech as its flagship Gemini model**\u301027\u2020L83-L92\u3011. The Gemma models come with a permissive commercial license and are integrated into open libraries\u301027\u2020L87-L95\u3011. This indicates Google\u2019s strategy of *selective openness*: they open-source *lightweight or older models* (e.g. they open-sourced the weights of PaLM 2\u2019s smaller version and many vision models) but keep cutting-edge models like **Gemini (which is rumored to exceed GPT-4 capabilities)** under wraps, available only via API or Google\u2019s own products. Historically, Google (and DeepMind) contributed extensively to open AI ecosystems \u2013 **TensorFlow** (from Google Brain) and **Jax** are open-source frameworks, and Google\u2019s research released popular open models like **BERT** for NLP and **Stable Diffusion\u2019s** architecture (via Google Research contributions). Even DeepMind\u2019s famous AlphaFold 2 (protein-folding AI) had its *weights and code open-sourced*, enabling broad use in science\u301026\u2020L37-L45\u3011. This openness was likely easier when such models did not pose clear misuse threats or when Google sought academic goodwill. As competition heats up, Google is more guarded with its latest LLMs \u2013 but it clearly sees value in **maintaining an open-source presence**. By providing Gemma models and tools to developers, Google DeepMind tries to capture the enthusiast and researcher community that might otherwise gravitate to Meta\u2019s open models or open frameworks. In contrast, OpenAI has almost no recent open-source model offerings in the LLM space (its last was GPT-2 in 2019). Thus, among the three, Google DeepMind is balancing both worlds: closed for competitive advantage in its core models, yet contributing open-source models/toolkits to shape standards and attract talent. \n\n**Summary:** All three organizations exercise caution in open-sourcing *frontier* models due to safety and competitive factors. OpenAI and Anthropic are quite closed with their latest models (OpenAI slightly more so, as it even withholds model architecture details). Google DeepMind, backed by a trillion-dollar parent, can afford a more hybrid approach \u2013 seeding the market with smaller open models (Gemma) and frameworks while using its most advanced models to boost Google\u2019s own products. \n\n### 3.2 Product \u201cMoats\u201d \u2013 Foundation Models vs Middleware vs Applications\n\nEach company is building moats \u2013 durable competitive advantages \u2013 at different layers of the AI stack:\n\n- **OpenAI\u2019s Moats:** OpenAI\u2019s initial moat was its *state-of-the-art foundation model*. GPT-3 was the first large model of its kind available via API, and GPT-4 is still arguably the best general-purpose AI model globally\u301018\u2020L199-L207\u3011. This gave OpenAI a technology lead. However, open-source efforts have started to **\u201ccommoditize\u201d foundation models**, eroding this moat\u301018\u2020L199-L207\u3011\u301018\u2020L203-L211\u3011. OpenAI recognizes this; as one commentary on its strategy put it, *\u201copen-source models took away the advantage of big tech and commoditized the market\u2026 as the costs of switching drop, companies will move from GPT-4 to low-cost open models\u201d*\u301018\u2020L199-L207\u3011\u301018\u2020L203-L211\u3011. In response, OpenAI is actively building moats at the **application and platform level**. **ChatGPT\u2019s massive user base** (100+ million users and integration into daily workflows) is itself a moat \u2013 the *network effect* of millions of users interacting, providing feedback, and generating data gives OpenAI an edge in improving its model continuously. By launching the **ChatGPT GPTs/Plugin ecosystem**, OpenAI is trying to entrench itself as the *platform* where AI apps live (analogous to iOS\u2019s App Store)\u301019\u2020L219-L228\u3011\u301019\u2020L231-L239\u3011. If developers flock to create specialized \u201cGPTs\u201d on OpenAI\u2019s platform, it increases user stickiness and creates a rich library of capabilities unique to OpenAI\u2019s ecosystem. Moreover, OpenAI is integrating vertically: ventures like the Jony Ive hardware project suggest a future *AI device* that tightly couples OpenAI software with bespoke hardware\u301019\u2020L262-L269\u3011. This could mimic Apple\u2019s moat of vertical integration. Additionally, OpenAI has a **data moat** \u2013 by serving millions of chats daily, it gathers interaction data that can be used to fine-tune and align models better than competitors (who might have less usage data). OpenAI also touts its *40-fold improvements in inference cost* achieved through engineering optimizations\u301019\u2020L253-L261\u3011 \u2013 this cost advantage (if sustained) means it can operate models more cheaply, allowing lower prices or higher margins that undercut rivals. In summary, OpenAI is moving from a pure technology moat to a *product+platform moat*: owning the popular interface (ChatGPT), an ecosystem (plugins/GPT Store), and continually improving via user data and scale. The foundation model remains crucial, but OpenAI\u2019s strategy assumes it won\u2019t be the sole differentiator long-term.\n\n- **Anthropic\u2019s Moats:** Anthropic is a younger and smaller organization than OpenAI but has carved out a niche around **safety and reliability** as its moat. Its model Claude is positioned as *\u201csafer and more steerable\u201d* \u2013 thanks to techniques like Constitutional AI. Anthropic hopes that enterprises and regulators will prefer a model known for being less likely to go off the rails. In terms of product layers, Anthropic initially focused on delivering a *high-quality foundation model (Claude) via API* and partnering for distribution (they partnered with Slack to integrate Claude as the Slack AI assistant, and with Quora\u2019s Poe app for consumer access). They did not have a ChatGPT-style public app until mid-2023 when they launched a beta web interface for Claude 2. Instead of building a broad consumer platform themselves, Anthropic has leaned on **strategic partnerships as a moat**: notably, it secured large investments from **Google** (who invested $300M in early 2023, gaining ~10% stake) and later **Amazon** (who committed up to $4B in late 2023)\u301020\u2020L50-L58\u3011\u301020\u2020L60-L68\u3011. These partners not only provide funds but also integrate Anthropic into their cloud offerings \u2013 e.g. Anthropic is a flagship model provider for Amazon Bedrock (AWS\u2019s AI platform), and Anthropic uses Google Cloud infrastructure as well. By being allied with multiple tech giants (Google and Amazon), Anthropic ensures it has *wide distribution and support* without solely depending on one platform. It\u2019s effectively riding on others\u2019 moats (AWS\u2019s salesforce, Google\u2019s ecosystem) to reach customers. Technically, Anthropic\u2019s research on model interpretability (e.g. exploring how GPT-like models \u201cthink\u201d via mechanical interpretability research) could become a moat if it leads to uniquely *controllable* models. However, at the application layer, Anthropic so far has less of a moat \u2013 it lacks the massive user-facing product that ChatGPT is. This may change if Anthropic develops more consumer-facing tools or an app marketplace of its own. For now, Anthropic\u2019s defensibility comes from its **alignment-focused brand**, its deep partnerships, and the fact that there are few companies aside from OpenAI and Google that can build GPT-4-level models (the *high barrier to entry* acts as a moat for all frontier model labs).\n\n- **Google DeepMind\u2019s Moats:** Google enjoys some of the *strongest moats in tech*, and it is leveraging them to compete in AI. At the **foundation model layer**, Google DeepMind has immense talent and infrastructure (TPU supercomputers, vast datasets from Google\u2019s data streams) to train frontier models. Its upcoming **Gemini model** is highly anticipated as a GPT-4 competitor, potentially surpassing it in some areas (especially if it combines DeepMind\u2019s reinforcement learning expertise with large language capabilities)\u301016\u2020L25-L33\u3011\u301016\u2020L37-L45\u3011. But Google\u2019s real moat is at the **application and integration layer** \u2013 unlike OpenAI and Anthropic, Google controls an entire ecosystem of products that reach billions (Search, Google Assistant, Gmail/Docs, Android, YouTube, etc.). Google can deploy AI directly into these services, instantly giving it a distribution moat that others can\u2019t match. For example, Google\u2019s **Bard** (its ChatGPT-like chatbot) is integrated with Google search and Chrome; its workspace AI (Duet AI) is embedded in Google Docs/Sheets to millions of Google Workspace users by default. This tight integration means Google can capture users *without them ever seeking an external AI service*. Additionally, Google has **data moats** like the knowledge graph and real-time search index that it can plug into its models (as Bard already does for sourcing information). On the middleware front, Google provides tools for developers through Google Cloud \u2013 e.g. the **Vertex AI platform** offers Google\u2019s models via API (Palm 2, etc.) and tooling for fine-tuning, all tied into Google\u2019s cloud ecosystem. By offering both *open models (like Gemma)*\u301027\u2020L83-L92\u3011 and *proprietary models via API*, Google covers the spectrum: it keeps developers in its orbit whether they prefer open-source or managed services\u301027\u2020L87-L95\u3011\u301027\u2020L99-L107\u3011. In terms of unique technology moats, DeepMind has deep research in areas like reinforcement learning and protein folding that could augment its LLMs (for instance, better planning or multi-step reasoning capabilities that OpenAI\u2019s models might not have yet). Another Google advantage is sheer **scale and cost**: Google can afford to offer AI features at low cost or even free (subsidized by its advertising business), which undercuts startups. Indeed, Google made Bard free to use, whereas OpenAI charges for GPT-4 access \u2013 a tactic that leverages Google\u2019s broader business model as a moat (advertising and cloud revenues support its AI services). \n\nThe table below summarizes the strategies of OpenAI, Anthropic, and Google DeepMind across several dimensions:\n\n| **Aspect**                      | **OpenAI** (Independent startup, partnered with Microsoft)                                                | **Anthropic** (Startup, backed by Google & Amazon)                                            | **Google DeepMind** (Alphabet subsidiary)                                  |\n|---------------------------------|-----------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------|\n| **Model Openness**              | Closed-source frontier models (e.g. GPT-4); only provides API/ChatGPT access. Open-sources some smaller projects (Whisper, etc.) for ecosystem\u301018\u2020L158-L167\u3011\u301018\u2020L179-L187\u3011. | Closed-source for main models (Claude); publishes research on methods but withholds weights for safety. Emphasizes transparent principles, not open weights. | Selective openness: Keeps latest large models proprietary (Gemini via API), but open-sources smaller models and tools (e.g. **Gemma 2B/7B** with commercial license\u301027\u2020L83-L92\u3011\u301027\u2020L87-L95\u3011, open-sourced TensorFlow, Jax, etc.). |\n| **Core Model Strategy**         | Aim for most advanced LLMs (GPT-4, GPT-5) \u2013 first to deploy cutting-edge models via cloud. Iterative deployment (improving via RLHF, plugin extensions). Focus on multimodality (text & vision). | Compete on safety and reliability \u2013 \u201cConstitutional AI\u201d to make models follow ethical rules. Building Claude models with comparable capability to GPT series, but tuned for harmlessness. Researching interpretability to deeply understand model internals. | Leverage Google\u2019s research and data advantage \u2013 e.g. **Gemini** to combine language and advanced reasoning (DeepMind\u2019s RL expertise). Heavy focus on multimodal and agentic capabilities. Massive scale models (PaLM family, etc.), plus specialized models (e.g. vision, code) integrated. |\n| **Middleware & Tools**          | Developing ChatGPT **Plugins** and GPT Store as platform for third-party extensions\u301019\u2020L219-L228\u3011. Offers fine-tuning APIs, and plans an \u201capp store\u201d of AI agents to create network effects. Alignment tools (OpenAI Eval framework) for model testing. | Provides an API and some open-source safety research. No public plugin ecosystem yet. Relies on partners (Slack, etc.) to integrate Claude into end-user workflows, rather than building its own app framework (so far). Likely to offer customization/fine-tuning to enterprise clients on demand. | Offers extensive AI development tools via **Google Cloud (Vertex AI)** \u2013 allows training, fine-tuning models, and deploying them at scale on Google\u2019s infra. Integrates models with Google services (e.g. API for Search, Maps). Releases toolkits like the **Responsible AI Toolkit** with open models\u301027\u2020L87-L95\u3011. DeepMind also open-sources research code on GitHub for community use. |\n| **Application Layer**           | **ChatGPT** is the flagship app with huge public adoption \u2013 a moat in itself. Rolling out ChatGPT in various forms (mobile apps, ChatGPT Enterprise for business). Plans for consumer AI **device** with Jony Ive suggests future proprietary hardware+software combo\u301019\u2020L262-L269\u3011. | No mass consumer app at ChatGPT scale (Claude available via API and waitlisted web UI). Focuses on **B2B adoption**: e.g. integrating into enterprise software (Slack\u2019s GPT, Notion AI uses Claude under the hood, etc.). Relies on partners for front-end experiences. | **Embedded in Google products:** e.g. Bard for search, Google Assistant updates, Gmail smart compose, YouTube summaries \u2013 reaching billions through existing apps. Also pursuing enterprise apps (e.g. Duet AI in Google Workspace for business users). The application moat is Google\u2019s breadth \u2013 AI features enhance its whole ecosystem (Android, Chrome, etc.). |\n| **Monetization**                | Multi-channel: consumer subscriptions (ChatGPT Plus, Enterprise) now major revenue\u30101\u2020L61-L68\u3011; API usage fees from developers; custom licenses (e.g. Microsoft\u2019s Bing deal, SoftBank JV paying $3B/year\u301010\u2020L180-L188\u3011). Will monetize platform (take a cut from GPT Store apps). | Primarily **API revenue** and usage-based fees via partners (AWS Bedrock clients using Claude, etc.). Likely pursuing large enterprise contracts (paid pilots with Fortune 500 companies). Significant funding from investors ($>5B raised) sustains R&D in lieu of high revenue in early years\u301020\u2020L60-L68\u3011\u301020\u2020L73-L81\u3011. | Indirect monetization: AI is used to protect and expand Google\u2019s core businesses. **Ads/Search** \u2013 Bard and AI search aim to keep users on Google (defending the ~$150B/yr search revenue). **Cloud** \u2013 offering models through Google Cloud to drive enterprise cloud revenue (Google reported a surge in cloud business due to AI demand). Also potentially subscription upsells (e.g. charging for advanced features in Google Workspace via a premium tier). Overall, Alphabet absorbs AI costs, expecting ROI via its ecosystem (rather than direct model fees). |\n| **Notable Partnerships**        | **Microsoft** \u2013 $13B invested, Azure as primary cloud, co-development of Azure OpenAI Service\u301011\u2020L133-L140\u3011. **SoftBank** \u2013 joint venture in Japan with $3B/year license fees\u301010\u2020L180-L188\u3011, plus potential big equity investment. Dozens of integrations (Stripe, Bain & Co, Salesforce, etc.) to embed OpenAI in other products. | **Google** \u2013 invested $300M; Anthropic uses Google Cloud and collaborated on research. **Amazon** \u2013 invested $4B; Anthropic to make AWS its main cloud and optimize for AWS chips (Trainium/Inferentia). These two rivals both back Anthropic, ensuring it has compute and market reach. Also partnerships with Slack (for an AI assistant) and other software firms. | N/A (DeepMind is part of Google). Key \u201cpartnership\u201d is internal: **Google integration** (DeepMind and Google Brain merged in 2023 to avoid duplicative efforts). Uses Google\u2019s partnerships: e.g. **with Meta** \u2013 collaborated on open-source projects; **with universities** \u2013 numerous research collaborations. DeepMind also partners with other Alphabet units (e.g. Waymo for AI, Isomorphic Labs for drug discovery). |\n\n**Key Takeaways:** OpenAI and Anthropic, as startups-turned-businesses, must directly monetize their models, pushing them to build subscription and API businesses and seek big partners. Google DeepMind, embedded in a tech giant, can focus more on using AI to strengthen Google\u2019s existing moats (search, cloud, platform) rather than selling AI access per se. OpenAI is aggressively moving \u201cup the stack\u201d \u2013 from just a model provider to a *consumer application provider and platform operator*, signaling a belief that the real moat will be in the user engagement and ecosystem\u301019\u2020L219-L228\u3011\u301019\u2020L227-L236\u3011. Anthropic is focusing on *trust and safety* as a selling point, which might carve a loyal customer segment (like governments or industries that prioritize AI ethics). Google DeepMind leverages a hybrid approach: it can drop AI capabilities into every layer of its own products (a formidable moat) while still offering APIs and even open-source tools to keep developers from straying to fully open alternatives. \n\n### 3.3 Monetization Strategy Differences\n\nAll three are pursuing revenue, but through different primary means, shaped by their corporate structures:\n\n- **OpenAI:** transitioning from research lab to revenue-generating company with ChatGPT Plus, ChatGPT Enterprise, and API licenses. It is effectively behaving like an **AI SaaS/platform company**, with fast-growing subscription revenue\u30101\u2020L61-L68\u3011. It also benefits from *licensing deals* (Microsoft\u2019s Bing integration likely involves a usage-based payment to OpenAI, and the SoftBank deal is explicit revenue). OpenAI\u2019s challenge is to maintain a lead that justifies its premium pricing, especially as open competitors emerge. Its monetization is tied directly to the quality and uniqueness of its models/apps.\n\n- **Anthropic:** still early in monetization; likely reliant on **enterprise contracts and cloud partnerships**. Amazon\u2019s investment came with the condition that Anthropic models would be offered as a service on AWS (so AWS clients pay, and Amazon shares revenue with Anthropic). Anthropic\u2019s recent valuation discussions (seeking $20-30B valuation) bank on its future ability to claim a slice of the enterprise AI market\u301020\u2020L71-L79\u3011. In essence, Anthropic is monetizing through **B2B relationships** \u2013 less from individual consumers. This could mean slower revenue ramp but potentially high long-term contracts if they secure marquee clients in finance, healthcare, etc., who need \u201csafe\u201d AI.\n\n- **Google DeepMind:** not a separate revenue-reporting entity. Its \u201crevenues\u201d come as part of Google\u2019s services. Google likely views DeepMind\u2019s value in terms of *cost savings and new capabilities* \u2013 e.g., DeepMind\u2019s research helped reduce energy costs in Google\u2019s data centers and improve products like Google Maps with AI. With the advent of chatbots threatening search, Google is using DeepMind/Brain to build AI that keeps users on Google (thus safeguarding advertising revenue). Google also sells AI indirectly: e.g. **Google Cloud\u2019s AI services** \u2013 charging API calls for PaLM or Imagen models, or enterprise usage of Vertex AI. The scale isn\u2019t fully disclosed, but Google Cloud CEO Thomas Kurian noted that generative AI was driving significant uptake on the cloud platform in 2023. Another avenue is **Android/Pixel** \u2013 Google could differentiate its hardware with on-device AI chips (the Tensor SoC includes Google\u2019s AI acceleration) and AI features (like call screening, Magic Eraser in photos) to sell more devices, translating AI prowess into hardware profit. In summary, Google monetizes AI by *enhancing its ecosystem\u2019s appeal* and via cloud services \u2013 not by charging end-users directly for a chatbot. This means Google can afford to distribute powerful models widely (as free features), counting on downstream gains (e.g., more cloud usage, user retention, hardware sales).\n\nHaving compared these companies, the question arises: should OpenAI *change course* and open-source its models, focusing more on applications? To evaluate that hypothesis, we must examine whether open-sourcing frontier models is even feasible and what the pros/cons would be.\n\n## 4. Technical Feasibility of Open-Sourcing Frontier Models\n\nOpen-sourcing a \u201cfrontier\u201d AI model (like GPT-4 level) is not as simple as pushing code to GitHub. Several technical factors determine its feasibility:\n\n- **Compute and Cost Requirements:** Training GPT-4 reportedly consumed **tens of millions of dollars in compute** (some estimates range from $60M to over $100M) and required specialized infrastructure that only a few entities possess. If OpenAI open-sourced the model weights of GPT-4, most outsiders *could not easily replicate the training from scratch*. However, they wouldn\u2019t need to \u2013 they would get the trained weights for free. The question becomes: can others *run* the model? GPT-4 is believed to be extremely large (potentially on the order of 1 trillion parameters, though undisclosed). The inference cost and hardware footprint to run it are enormous \u2013 likely requiring multiple high-end GPUs to serve a single instance with reasonable latency. This means that even if OpenAI released GPT-4 weights, only well-resourced players (big tech companies, cloud providers, or government labs) could deploy it at full scale. That said, the AI community has a track record of *rapidly optimizing open models*: after Meta released (or rather leaked) LLaMA-65B, developers devised techniques to quantize and run it on smaller GPUs or even phones (albeit slowly)\u301018\u2020L188-L196\u3011\u301018\u2020L192-L200\u3011. We can expect that an open-sourced GPT-4 would be pruned, quantized, or distilled into more efficient forms by the community. Thus, one feasibility issue is **inference efficiency** \u2013 OpenAI\u2019s model might be initially too heavy for broad use, but open-source innovation could reduce the barrier. Still, open-sourcing a frontier model likely means *ceding its advantages to competitors with infrastructure*. For example, if OpenAI open-sourced GPT-4, cloud rivals like Amazon or Google could take the model and offer it as a paid service, undercutting OpenAI (since they have computing economies of scale). Technically it\u2019s feasible for them; economically it\u2019s detrimental to OpenAI. In summary, the *compute cost to train* is already sunk by OpenAI, but the *compute cost to use* remains a limiting factor for the community (one that could be overcome with effort).\n\n- **Safety and Alignment Concerns:** OpenAI has cited safety as a major reason for not open-sourcing powerful models. A frontier model like GPT-4 can be misused if not properly controlled by its deployer. In a closed API, OpenAI can implement usage policies (filters for hate speech, disallowed content, rate limits, monitoring for abuse). If the model weights were public, **malicious actors could fine-tune or prompt the model to produce harmful outputs** without such restrictions. For instance, an open GPT-4 could be modified to better generate malware code, disinformation, or instructions for illicit activities. The **White House and national security experts have voiced alarm** that openly available advanced models might accelerate bioterrorism or cybercrime (by aiding in the design of pathogens or exploits)\u301022\u2020L57-L65\u3011\u301022\u2020L59-L67\u3011. OpenAI itself, along with Anthropic and others, formed the *Frontier Model Forum* in 2023 to discuss responsible deployment of top-tier models. Technically, open-sourcing increases these safety risks because **model access can no longer be monitored or \u201cpatched\u201d**. If an issue is found in a closed model, OpenAI can update the model or its guardrails. If the model is open, copies exist outside of any oversight, and one cannot \u201cpull back\u201d the model \u2013 there is an **\u201cirreversibility\u201d** once weights are out\u301022\u2020L67-L75\u3011\u301022\u2020L69-L73\u3011. As the Stanford CRFM study noted, once model weights are widely available, it\u2019s *impossible to rescind access* or control usage\u301022\u2020L67-L75\u3011. So from a feasibility standpoint, ensuring safety with an open-sourced model is very challenging. We would rely on voluntary adoption of safety techniques by the community, which may not be universal.\n\n- **Model Complexity and Documentation:** GPT-4 is not just a single neural network; OpenAI\u2019s literature hints it might be an *ensemble* or use techniques like MoE (Mixture of Experts). Open-sourcing would require releasing all components and technical documentation for others to utilize the model effectively. In GPT-3\u2019s case, OpenAI did publish architecture details in 2020, and others reproduced models like it (EleutherAI\u2019s GPT-J, GPT-Neo were replications based on those open details). But for GPT-4, no paper describes its architecture. This means open-sourcing would involve a significant effort to prepare the model for external use \u2013 writing model card documentation, explaining training data usage (which also has legal implications, as the dataset likely contains copyrighted material). In other words, *just releasing weights without context* might not enable the community to fully leverage the model or understand its limitations. Feasibly OpenAI could do this work, but it\u2019s an overhead.\n\n- **Intellectual Property and Data:** Another barrier \u2013 OpenAI trained its models on vast datasets, some of which may have usage restrictions. If the model weights implicitly contain knowledge from proprietary data (for example, snippets of copyrighted text or code from licensing-protected sources), releasing the weights could invite legal challenges or violate agreements. This IP entanglement is an often-cited reason companies hesitate to open models. Technically, the weights are a compressed form of the training data, so the legality of releasing them is a gray area that OpenAI\u2019s legal team would weigh.\n\n- **Frontier Model Regulation:** Looking forward, governments are considering *regulating frontier AI models*. If OpenAI open-sourced one of the most powerful models, it might run afoul of future regulations or face scrutiny. For instance, if a law required AI developers to implement certain safety features, an open model could be used without them, creating compliance issues. On the other hand, some regulations (like the EU AI Act draft) considered *exempting open-source models from certain requirements*, acknowledging their benefit for transparency\u301022\u2020L57-L65\u3011\u301022\u2020L59-L67\u3011. So regulation cuts both ways: open-sourcing might free OpenAI from being the sole party responsible for the model\u2019s use (shifting some responsibility to users), but it could also be seen as *negligent* to unleash a model that anyone (including bad actors) can use without oversight. From a feasibility stance, OpenAI would have to assess the evolving legal environment before open-sourcing; this isn\u2019t a technical issue per se, but it affects the decision of whether it\u2019s \u201cfeasible\u201d to do so safely.\n\nIn summary, **it is technically feasible to open-source a frontier model, but with significant caveats**. The model would be usable primarily by those with substantial hardware resources, though the open-source community would quickly work to reduce the resource requirements (e.g. via quantization)\u301018\u2020L188-L196\u3011. The bigger issues are *safety and control*: open-sourcing means relinquishing control over how the model is used, which could lead to harm and would remove the ability to enforce safeguards\u301022\u2020L69-L77\u3011. There\u2019s also competitive feasibility: OpenAI would be enabling its competition (from big tech to foreign state actors) to instantly have what OpenAI spent huge sums to create. Technically, nothing stops those actors from training their own GPT-4 equivalents (and some have likely done so in secret), but releasing your crown jewels for free is a different proposition. These feasibility considerations segue into the strategic *pros and cons* of open-sourcing \u2013 beyond the technical realm, what would be the broader impact if OpenAI took this path?\n\n## 5. Strategic Risks and Benefits of Open-Sourcing OpenAI\u2019s Models\n\nOpen-sourcing OpenAI\u2019s foundational models (current or future ones) would mark a profound strategic shift. It carries both potential advantages and significant risks. Below we analyze the key considerations:\n\n### 5.1 Potential Benefits of Open-Sourcing\n\n- **Regulatory and Public Goodwill:** Open-sourcing a powerful model could earn OpenAI goodwill from policymakers, researchers, and the open-source community. It would align with the notion of distributing AI\u2019s benefits widely rather than concentrating power. Policymakers in the EU and US have noted the **transparency benefits** of open models \u2013 they allow independent auditing, safety research, and understanding of AI behavior\u301021\u2020L7-L15\u3011\u301022\u2020L73-L81\u3011. In fact, the EU AI Act in draft form leaned toward lighter regulation for open models because transparency is built-in\u301022\u2020L57-L65\u3011\u301022\u2020L59-L67\u3011. By open-sourcing, OpenAI could position itself as a responsible actor promoting transparency and safety collaboration (in contrast to fears of it being a secretive monopoly). This could ease antitrust concerns as well \u2013 an open model can\u2019t be monopolized, which may preempt regulatory breakup or scrutiny over OpenAI\u2019s partnership with Microsoft dominating the AI market.\n\n- **Community Innovation and Ecosystem Growth:** If OpenAI\u2019s model were open, the global developer and research community could iterate on it, *fix its flaws, improve its efficiency, and explore new use cases*. We\u2019ve seen this with open models like Stable Diffusion (for images) \u2013 an explosion of innovation (hundreds of derivatives, specialized fine-tunes for art styles, etc.) that far outpaced what the original company alone could do. For OpenAI\u2019s model, the community might contribute back improvements that OpenAI itself can learn from. As an example, **Meta\u2019s LLaMA gained optimized variants (Alpaca, etc.) and techniques like 4-bit quantization** from the open-source world within months\u301018\u2020L188-L196\u3011\u301018\u2020L192-L200\u3011. OpenAI could harness similar contributions. Open-sourcing could also set a standard such that OpenAI\u2019s model becomes the **platform on which others build**, rather than alternative open models. Essentially, *it could crowdsource R&D*: instead of hundreds of startups all training rival models, many might just build on OpenAI\u2019s if it were the best open foundation. This consolidates effort and possibly keeps the ecosystem centered on OpenAI\u2019s architectures (even if OpenAI isn\u2019t hosting every instance). Moreover, it could attract top AI talent \u2013 many researchers prefer working on open models (for academic publications and the ability to tinker freely). An open policy might draw talent away from competitors (who are closed) and towards OpenAI or its community.\n\n- **Market Share and Standard-Setting:** By releasing a frontier model, OpenAI could aim to **make it the de facto standard** for AI development, much like Linux became a standard OS kernel or OpenCV a standard in computer vision. If everyone uses OpenAI\u2019s model (even independently), OpenAI\u2019s influence remains high. It could focus on providing *value-added services* on top of that standard. There is precedent: OpenAI\u2019s name itself suggests an intent to be akin to an \u201copen standard\u201d for AI. If, say, GPT-4 became the base model in most applications (because it\u2019s free and high-quality), then OpenAI could be the authority on that model\u2019s updates, or offer the best fine-tuning tools and support for it (monetizing those services). This is somewhat similar to how Red Hat monetized Linux \u2013 the core was free, but they sold expertise and support. OpenAI could pivot to an \u201copen-core\u201d business: the core weights are open, but enterprise customers pay OpenAI for hosted solutions, fine-tuning, and customizations with guarantees. This approach could *undercut emerging open-model companies* because instead of others providing \u201calmost-GPT4\u201d open models, OpenAI itself sets the bar by open-sourcing the real thing.\n\n- **Defensive Move Against Competitors:** If OpenAI fears that competitors (especially those with open-source philosophies, like Meta or various international labs) will eventually produce an open model rivaling GPT-4, it might choose to *preempt* that. In May 2023, a leaked Google memo famously stated: **\u201cWe have no moat, and neither does OpenAI\u201d**, referring to the onslaught of open-source models\u301017\u2020L23-L31\u3011\u301017\u2020L25-L33\u3011. It argued that open-source projects were iterating faster and would eventually catch up in quality. Indeed, by 2024 open models matched GPT-3.5 on many tasks\u301018\u2020L199-L207\u3011. If OpenAI waits, an open competitor might steal mindshare (for instance, if Meta\u2019s next open model or a coalition of researchers produce something on par with GPT-4). By open-sourcing first, OpenAI can *dictate the terms*: it can set a responsible release with safety measures, and frame it as a proactive choice rather than being overtaken. This could prolong OpenAI\u2019s relevance in face of commoditization \u2013 better to cannibalize your own moat at a time of your choosing than have it eroded by others unwillingly.\n\n- **Brand Restoration and Talent Acquisition:** OpenAI has \u201copen\u201d in its name but has been criticized for becoming closed and profit-driven. Open-sourcing a major model could restore some of the **idealistic luster** the brand had initially. This can have soft benefits: attracting academic collaborations, making top AI PhDs (who might prefer an open environment like a university or Meta) consider OpenAI or its projects, and generally differentiating OpenAI from purely profit-motivated firms. It would signal confidence that OpenAI can thrive by innovation and not just by hoarding IP. Additionally, open-sourcing aligns with the ethos of many AI practitioners who value reproducibility and contribution to common knowledge \u2013 appealing to them can expand the pool of people devoted to improving OpenAI\u2019s tech (even outside the company payroll). \n\n- **Regaining Developer Mindshare from Open Models:** Right now, there is a split in the developer community: some stick with OpenAI\u2019s API due to quality and ease, others experiment with open models for flexibility and cost control. If OpenAI\u2019s own model were open, developers wouldn\u2019t need to look elsewhere for an open solution \u2013 they could get both quality and openness from OpenAI. This could unify the community around a single set of model weights, leading to more plugins, tools, and extensions targeting that model. For example, many \u201cAI agents\u201d frameworks (like LangChain) are model-agnostic but flourish with open models since they can be run locally. If GPT-4 were available, you might see an explosion of GPT-4-powered apps in edge devices, private networks, etc., all of which still reinforce GPT-4 as the benchmark. \n\n### 5.2 Risks and Downsides of Open-Sourcing\n\n- **Loss of Commercial Exclusivity:** The most immediate hit would be to OpenAI\u2019s **revenue model**. Why would developers or companies pay OpenAI for API calls if they could download the model and run it themselves (especially without usage restrictions)? While many might still use OpenAI\u2019s hosted service for convenience, the pricing power would erode. We would likely see **downward price pressure** \u2013 competitors (like AWS, Google) could host the open model and offer it at lower cost or even free (bundled with other services). OpenAI\u2019s ChatGPT Plus subscriptions could also suffer if equivalent chat applications arise using the open model without the $20/month fee. Essentially, open-sourcing could *commoditize OpenAI\u2019s core offering*, forcing OpenAI to compete on the basis of service quality, not uniqueness of the model. If not carefully planned, this could sharply reduce OpenAI\u2019s revenue before its new revenue streams (applications, middleware) are mature enough to compensate. \n\n- **Empowering Competitors (Including Geopolitical Rivals):** OpenAI would be handing over years of intellectual property to not just well-meaning developers, but also to rival companies and nations. For instance, Chinese tech companies or government labs, which currently may not have direct access to GPT-4, would readily use an open-sourced model (China\u2019s AI industry has already benefited from Meta\u2019s Llama being leaked, as they adopted those weights in various projects). This could *diminish the US lead* in AI if the model allows others to catch up faster\u301010\u2020L195-L203\u3011. From OpenAI\u2019s business perspective, competitors like **Anthropic** or **Cohere** could take the open model and build their own fine-tuned variants, potentially eroding OpenAI\u2019s market share. Even Google, which has its own superior models, could integrate pieces of OpenAI\u2019s open model knowledge into their training or at least use it as a baseline to lower their R&D costs. In short, open-sourcing would level the playing field \u2013 good for society perhaps, but removing OpenAI\u2019s head start.\n\n- **Safety, Misuse, and Reputation Damage:** As discussed, once open, the model can be used for any purpose. If bad outcomes occur \u2013 say, someone uses the model to generate violent extremist propaganda or to assist in a cyberattack \u2013 it might still be *referred to as \u201cOpenAI\u2019s GPT-4 did X\u201d* in media, attaching negative press to OpenAI\u2019s name. OpenAI could be called to testify or explain such misuse even if it wasn\u2019t directly involved, because they created the tech. This reputational risk is non-trivial; OpenAI has carefully cultivated an image of caring about safety (e.g., building in moderation and usage policies). An open model would immediately be modified to ignore those safety instructions (users could fine-tune it on adversarial data to remove the refusals it was trained to give). The **Stanford paper on open model impacts** notes that while open models democratize AI, they also make content moderation and policy enforcement much harder\u301022\u2020L67-L75\u3011\u301022\u2020L69-L77\u3011 \u2013 any \u201cattempt to impose conditions on users of open models are easy for malicious actors to ignore,\u201d it concludes\u301022\u2020L67-L75\u3011\u301022\u2020L69-L73\u3011. OpenAI would have to accept that its technology *will be used in ways it disapproves of*, possibly leading to harm. If a significant harm event occurred and was tied back to an OpenAI model, regulators might clamp down on OpenAI or future releases (backfiring on the goodwill argument). Essentially, OpenAI would be sacrificing a degree of *control in exchange for openness*, and that loss of control could lead to unpredictable fallout.\n\n- **Erosion of Microsoft Partnership and Investor Confidence:** OpenAI\u2019s strategic partners and investors expect a return on their massive investments. Microsoft, in particular, paid not just money but also gave exclusive rights (Azure exclusivity, product integration exclusivity) to OpenAI\u2019s tech. If OpenAI open-sourced its models, Microsoft\u2019s exclusive advantage wanes \u2013 Azure would no longer be the sole cloud where you can get GPT-4, and Bing wouldn\u2019t be the only chatbot with GPT-4\u2019s full power. This could strain the partnership: Microsoft might see it as OpenAI undermining the deal. Future fundraising could also be impacted: OpenAI\u2019s valuation (estimated at $80\u201390B in late 2023 privately) is predicated on it owning proprietary technology. Investors might fear that open-sourcing means OpenAI will have a harder time monetizing and defending its turf, making it a less attractive business. Unless OpenAI presents a very convincing alternative revenue plan, such a pivot could spook capital markets (important if OpenAI plans further raises or eventually an IPO). In essence, open-sourcing might clash with the incentives of OpenAI\u2019s stakeholders who have put money in on the premise of *competitive advantage*. \n\n- **Loss of Lead in Alignment and Safety Implementation:** While open-sourcing can galvanize external safety research, it also means others might take the model and *not implement* the careful alignment OpenAI did (like RLHF to reduce toxic outputs). Those aligned responses, refusals, and safeguards built into ChatGPT could be stripped away. If those versions become popular, it might normatively set AI behavior back (from polite and cautious to raw and unfiltered). OpenAI\u2019s work on alignment could effectively be \u201cundone\u201d in the wild. Moreover, in the long term, if aligned and unaligned model variants compete, the market might not punish the unaligned ones unless regulation or user preference does \u2013 which is uncertain. OpenAI prides itself on safety; seeing its model turned potentially into something harmful would be a tough pill internally and could demoralize staff who care about the mission. \n\n- **Complexity of Support and Forks:** Once a model is open, it can be \u201cforked\u201d (modified) by many different groups. OpenAI would no longer have one canonical version to maintain. We might see a fragmentation: Model X with various fine-tuned branches. This could create an ecosystem that is *beyond OpenAI\u2019s ability to support or curate*. It might also dilute the brand \u2013 if someone fine-tunes GPT-4 to be a racist bot and calls it something else, the lineage might still reflect on \u201cGPT-4\u201d. OpenAI would have to decide if it participates in the community like any other contributor (similar to how Linux has many contributors including companies). That\u2019s a very different mode of operation than the controlled updates it does now.\n\nIn weighing those pros and cons, it is clear open-sourcing is a double-edged sword. The **Stanford HAI study** essentially presented that open models bring *more innovation, transparency, and distributed power*\u301022\u2020L73-L81\u3011\u301022\u2020L75-L83\u3011, but also *carry misuse risks that are hard to mitigate*. Interestingly, the study noted that many harms (like disinformation) existed before and are not unique to AI\u301022\u2020L81-L89\u3011. Advocates say open models \u201c*allow greater diversity in defining acceptable behavior and spur innovation*\u201d\u301022\u2020L73-L81\u3011\u301022\u2020L75-L83\u3011. Detractors worry about empowering malicious actors. OpenAI would need to consider where the net balance lies and possibly adopt a middle path (e.g. **delayed open-sourcing** \u2013 releasing models after a lag, or releasing slightly weaker \u201copen\u201d versions while keeping the absolute frontier version closed). \n\n## 6. Focusing on Applications/Middleware for Long-Term Defensibility\n\nThe second part of the hypothesis is that OpenAI might do better by shifting its emphasis to the **application and middleware layers**, building value on top of models rather than the model IP itself. This strategy means treating the foundation model as a commodity or utility (potentially open or widely available) and differentiating through superior products and integration. How viable is this?\n\nA useful lens is to consider the **\u201claw of conservation of modularity (or attractive profits)\u201d** from business theory\u301024\u2020L39-L47\u3011\u301024\u2020L43-L50\u3011. It postulates that when one layer of a value chain becomes modular and standardized, the opportunity for profit shifts to an adjacent layer that is not yet commoditized\u301024\u2020L41-L49\u3011\u301024\u2020L47-L55\u3011. We may be witnessing this with AI: if large language models as a component become widely available (through open-source or multiple competing providers), then the differentiation and profit will shift to how those models are used and delivered to end-users\u301024\u2020L25-L33\u3011\u301024\u2020L27-L33\u3011. In other words, **\u201cthe moats are in the GPT-wrappers\u201d** \u2013 the applications that wrap around GPT models \u2013 rather than the model itself, which will increasingly be a commodity\u301024\u2020L25-L33\u3011. An analyst succinctly noted: *\u201cUnless something changes with how foundational model companies go to market, the application layer is where the value accrues and money will be made\u201d*\u301024\u2020L25-L33\u3011\u301025\u2020L1-L4\u3011. \n\nFor OpenAI, focusing on applications and middleware implies:\n\n- **Building superior end-user experiences:** Continue to improve ChatGPT and any future applications (perhaps specialized AIs for education, coding, design, etc.) to keep users within OpenAI\u2019s ecosystem. If OpenAI can make ChatGPT **indispensable for consumers and businesses \u2013 an AI assistant that\u2019s deeply integrated into daily tasks \u2013** then what model it uses under the hood could eventually be swapped without users leaving. For instance, if tomorrow an equally good open model exists, but all your documents, conversations, plugins, and workflow are set up in ChatGPT, you might stick with ChatGPT out of convenience. This is analogous to how Microsoft Office retains customers not because no one else can make word processors, but because the overall integration and familiarity is valuable. OpenAI is already pushing in this direction by adding productivity features, plugin integrations, and multi-modal capabilities to ChatGPT.\n\n- **Developing Middleware/Platforms for Others:** OpenAI could develop the *best platform for building AI-powered applications*. Rather than just giving raw model access, it can provide SDKs, hosting, fine-tuning frameworks, and marketplaces (like the GPT Store) where third-party developers find it easiest and most profitable to deploy their AI solutions. By being the *default middleware layer*, OpenAI could take a cut of all AI applications built on its stack. This strategy is similar to what Apple did with the App Store or what cloud providers do with their platforms \u2013 create an ecosystem where others build value, but the platform owner gets a slice and remains central. If OpenAI open-sourced models, it could still attempt to be the leading service provider for those models (imagine OpenAI releasing GPT-4 but offering a managed service with enterprise support, guaranteed uptime, etc., similar to how Red Hat offers support for Linux which is open). Many companies would opt to pay for a reliable service rather than handle it themselves, especially if OpenAI\u2019s expertise means it can run the models more efficiently or securely.\n\n- **Leveraging Data and Network Effects:** In the application-focused model, *user data becomes a key asset*. As users interact with AI applications, that data (if users permit its use) can improve the AI in ways that outsiders cannot match. OpenAI already benefits from ChatGPT usage data to refine its models. As it focuses on apps, it could create more closed-loop improvements: e.g., a writing assistant that learns from aggregate writing styles, or a coding assistant that learns common bug fixes from user feedback. This proprietary data loop can be a moat when the model weights are not a moat. It\u2019s akin to Google\u2019s search data improving its search algorithm continuously \u2013 even if the PageRank algorithm was known, Google\u2019s trove of user interaction data helped it stay ahead. OpenAI could similarly build feedback systems in its applications that feed into better performance. That advantage would persist even if the base model is openly available (because others wouldn\u2019t easily get the same scale of real-world interactions).\n\n- **Brand and Trust:** As AI becomes ubiquitous, users and companies might gravitate to providers they trust with their data and for consistent quality. OpenAI, by being first and high-profile, has built a strong brand for cutting-edge AI (and, through efforts like alignment, a brand for relatively *careful* AI). By focusing on customer-facing products, OpenAI can strengthen that brand loyalty. If \u201cChatGPT\u201d becomes synonymous with \u201creliable AI assistant\u201d, open competitors might be seen as generic or less trustworthy (similar to how many people use \u201cGoogle\u201d even though other search engines exist, due to brand trust). That brand equity can translate to pricing power and user retention in applications.\n\n- **Long-term defensibility:** The big question \u2013 is this approach defensible? Applications and middleware can be copied too; if models are commodity, maybe someone could replicate a similar app. But defensibility could come from **scale and first-mover advantage**. By the time models commoditize, OpenAI might have integrated its AI into so many facets of life (productivity, entertainment, etc.) that switching to a competitor is non-trivial. Also, by owning the relationships with millions of users, OpenAI can keep updating its back-end (whether its own model or a third-party model) without losing the user. This is a classic platform moat: you own the users/developers; the underlying tech can change. Additionally, if OpenAI excels in middleware, it might power the AI features of other products (e.g. via plugins or partnerships) even if the model is open \u2013 because it offers a more turnkey solution. \n\nReal-world signals suggest this strategy is already in play: OpenAI\u2019s revenue mix is now leaning more to \u201capps (consumer and enterprise) over API\u201d\u30101\u2020L61-L68\u3011, and Sam Altman highlighted that consumer adoption gives them a strong position. The *network effect* of ChatGPT\u2019s GPT Store \u2013 where user engagement attracts developers, which in turn attracts more users \u2013 is a deliberate moat that is independent of the underlying model\u301019\u2020L227-L236\u3011\u301019\u2020L235-L243\u3011. Another important point is **cost reduction**: OpenAI claims to have cut inference costs 40x\u301019\u2020L253-L261\u3011, which if passed to users (free tier improvements or lower Plus cost) helps maintain a user moat through affordability.\n\nHowever, focusing on applications is not without challenges:\n\n- It requires OpenAI to excel at product development and possibly compete with established tech giants on user experience, which is a different competency than research. The acquisition of Global Illumination and hiring of designers like Jony Ive indicate OpenAI knows it needs top product talent to succeed here. It is a cultural expansion from lab to product company.\n\n- There\u2019s also a risk of *dilution*: chasing consumer apps, enterprise software, and platform development all at once is ambitious. Giants like Google and Microsoft have well-oiled product teams for each domain; OpenAI is much smaller (albeit growing). Executing on an app strategy means scaling up customer support, UI design, marketing \u2013 things OpenAI has less experience in compared to pure research. The $20/mo ChatGPT Plus is a good start, but enterprise clients will demand more robust services (compliance, SLAs), and consumer hardware would bring supply chain and retail concerns.\n\n- **Monetization of apps vs models:** It\u2019s conceivable that foundation model APIs become low-margin (a volume game), while tailored applications can command higher margins (because they solve end-to-end problems). For example, an AI that functions as a customer service agent could be sold as a subscription service at a premium, even if the model behind it is widely available. OpenAI could create industry-specific solutions (like \u201cAI Doctor Consultant\u201d built on GPT-4) and sell the solution rather than the raw model. These vertical products could be lucrative and less sensitive to competition if they integrate domain expertise, proprietary data, and the base model. So profit could shift there.\n\n- **Comparative strategies:** We see hints that **Anthropic** and others might also shift to apps. For instance, Anthropic reportedly is developing a chatbot for *consumer* use as well (Claude 2 was made available freely in some regions via a web interface, showing interest in direct users). If everyone moves to apps, then advantage comes down to who has the better app ecosystem or partnerships. OpenAI\u2019s early mover advantage (ChatGPT\u2019s brand) is significant here, but Google\u2019s massive user base is a threat (Google can simply turn on AI features in products people already use daily). So OpenAI\u2019s defensibility in apps will partly rely on staying ahead in quality and being more platform-agnostic (ChatGPT works across devices and platforms, whereas Google\u2019s best AI is often tied to Android/Google products, which not everyone uses).\n\nIn conclusion, focusing on applications and middleware appears not only viable but **increasingly essential** for OpenAI\u2019s long-term defensibility and profit. The foundation model itself is likely to become a *commodity infrastructure* \u2013 either through open-source or because multiple companies offer similarly powerful models. As one venture analysis put it, *\u201cWhat\u2019s more, OpenAI\u2019s massive infrastructure investments might not be building a moat \u2014 they might just be the cost of staying in the race.\u201d*\u301023\u2020L39-L45\u3011\u301023\u2020L39-L42\u3011. In other words, just having a big model and the means to train it is necessary but not sufficient for durable advantage. The moats will be built on **data network effects, user lock-in, and integration** \u2013 all of which happen at the application/platform layer. OpenAI\u2019s strategy (as evidenced by the GPT Store, ChatGPT Enterprise, plugin ecosystem) is already pivoting in this direction\u301019\u2020L219-L228\u3011\u301019\u2020L227-L236\u3011. \n\nThe hypothesis that OpenAI could strengthen itself by open-sourcing models and doubling down on apps/middleware stems from the idea that *owning the ecosystem is more valuable than owning the model*. Many industry experts share this view that value in AI will accrue to those who figure out distribution, customer experience, and niche solutions, rather than those who simply train the biggest model. If OpenAI open-sourced, it would accelerate the commoditization of the model layer, essentially betting that their real moat lies in their head-start in deployment and user base. It\u2019s a bold bet that could either entrench OpenAI as the central hub of a huge AI ecosystem (if executed well), or diminish its lead if competitors manage to replicate the application advantages.\n\n## **Conclusion**\n\nOpenAI\u2019s current strategy is a hybrid of leveraging proprietary frontier models **and** aggressively building an ecosystem around them. It has achieved remarkable commercial success by monetizing ChatGPT and APIs, while aligning with giants like Microsoft for resources and distribution. Comparatively, Anthropic and Google DeepMind illustrate alternative approaches \u2013 one prioritizing safety and partnerships, the other leaning on an existing tech empire and selective openness. \n\nOpen-sourcing OpenAI\u2019s top models, once anathema to its recent policies, is not unthinkable in the long run. The **technical feasibility** is there, though accompanied by safety challenges and loss of control. The **strategic analysis** suggests that open-sourcing would trade away short-term exclusivity for potentially greater adoption and innovation, benefiting OpenAI if it can capture value on higher layers of the stack. The decision hinges on whether foundation models truly become commoditized \u2013 evidence is mounting that they will, as open alternatives rapidly improve\u301018\u2020L199-L207\u3011. If OpenAI finds its moat shifting to the application layer, it may embrace openness in models to undermine competitors and galvanize community support (much like Google is now doing by open-sourcing smaller models to win developers\u301027\u2020L83-L92\u3011\u301027\u2020L87-L95\u3011).\n\nOpenAI has already started to focus on **applications (ChatGPT, enterprise solutions)** and **middleware (plugins, GPT Store)** to lock in its advantage beyond the model. This is a recognition that **user engagement, integration, and data feedback loops** can provide a lasting competitive edge that a standalone model API cannot. The company\u2019s swelling revenue from ChatGPT Plus and Enterprise shows the power of owning the user interface\u30101\u2020L61-L68\u3011. If one day everyone has GPT-4-quality models, the company with the best *experience, trust, and ecosystem* will win the lion\u2019s share of customers. \n\nIn evaluating the hypothesis, it appears that **OpenAI could indeed enhance its strategic position by pivoting toward an open-model & rich-application strategy \u2013 but it must carefully manage the transition**. Open-sourcing would be a one-way door; it demands confidence that OpenAI\u2019s strengths in deployment, scale, and brand will carry it forward. The risks are significant, so a phased approach might be likely (for example, open-sourcing older models or partial release with a strong open community push, as OpenAI tests the waters of community contribution). \n\nUltimately, the AI industry might evolve similarly to other tech domains: a few core models (like operating systems or databases) become widely accessible, while the highest value is captured by those who **apply them intelligently** to solve real problems at scale. OpenAI\u2019s moves in coming years \u2013 whether it holds models close or sets them free \u2013 will indicate which route it believes leads to enduring leadership in the AI era.\n\n**Sources:**\n\n1. OpenAI revenue breakdown estimates (June 2024) \u2013 EA Forum\u30101\u2020L25-L34\u3011\u30101\u2020L61-L68\u3011  \n2. Reuters \u2013 SoftBank\u2019s $3B/yr OpenAI Japan JV and potential $15\u201325B investment\u301010\u2020L180-L188\u3011\u301010\u2020L182-L190\u3011  \n3. Thurrott \u2013 Microsoft & OpenAI renegotiating Azure exclusivity; Oracle $10B deal; Project Stargate details\u301013\u2020L143-L151\u3011\u301013\u2020L149-L157\u3011  \n4. TechTalks \u2013 Analysis on OpenAI building application moats (GPT Store, cost reduction, device plans)\u301019\u2020L219-L228\u3011\u301019\u2020L253-L261\u3011  \n5. Axios \u2013 Stanford HAI study on open-source AI models (risks vs benefits)\u301022\u2020L67-L75\u3011\u301022\u2020L73-L81\u3011  \n6. Interjected Future \u2013 \u201cThe moats are in the GPT-wrappers\u201d (application layer value)\u301024\u2020L25-L33\u3011\u301025\u2020L1-L4\u3011  \n7. LinkedIn \u2013 Anthropic vs OpenAI funding and strategy (Google & Amazon backing Anthropic; OpenAI Stargate project)\u301020\u2020L50-L58\u3011\u301020\u2020L80-L89\u3011  \n8. VentureBeat \u2013 Google DeepMind\u2019s open-sourcing of Gemma models (2B,7B) and strategy\u301027\u2020L83-L92\u3011\u301027\u2020L87-L95\u3011  \n9. BDTechTalks \u2013 \u201cHow OpenAI\u2019s moat was breached\u201d by open-source and OpenAI\u2019s response\u301018\u2020L164-L173\u3011\u301018\u2020L179-L187\u3011  \n10. Axios \u2013 Comments on open models distributing power vs. difficulty monitoring misuse\u301022\u2020L67-L75\u3011\u301022\u2020L69-L77\u3011  \n\n"]},"status":"finished_successfully","end_turn":true,"weight":1.0,"metadata":{"citations":[{"start_ix":1436,"end_ix":1447,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"A breakdown of OpenAI's revenue \u2014 EA Forum","url":"https://forum.effectivealtruism.org/posts/ksdSjT7wREu6vBhYE/a-breakdown-of-openai-s-revenue#:~:text=We%20estimate%20that%2C%20as%20of,ARR%29%20of","text":"We estimate that, as of June 12, 2024, OpenAI has an annualized revenue (ARR) of:","pub_date":null,"extra":{"cited_message_idx":1,"search_result_idx":null,"evidence_text":"","start_line_num":25,"end_line_num":32},"og_tags":null}},{"start_ix":1757,"end_ix":1768,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"A breakdown of OpenAI's revenue \u2014 EA Forum","url":"https://forum.effectivealtruism.org/posts/ksdSjT7wREu6vBhYE/a-breakdown-of-openai-s-revenue#:~:text=%241,from%20980k%20seats","text":"$1.9B for ChatGPT Plus (7.7M global subscribers), $714M from ChatGPT Enterprise (1.2M seats), $510M from the API, and $290M from ChatGPT Team (from 980k seats)","pub_date":null,"extra":{"cited_message_idx":1,"search_result_idx":null,"evidence_text":"","start_line_num":27,"end_line_num":32},"og_tags":null}},{"start_ix":1852,"end_ix":1863,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"A breakdown of OpenAI's revenue \u2014 EA Forum","url":"https://forum.effectivealtruism.org/posts/ksdSjT7wREu6vBhYE/a-breakdown-of-openai-s-revenue#:~:text=%241,from%20980k%20seats","text":"$1.9B for ChatGPT Plus (7.7M global subscribers), $714M from ChatGPT Enterprise (1.2M seats), $510M from the API, and $290M from ChatGPT Team (from 980k seats)","pub_date":null,"extra":{"cited_message_idx":1,"search_result_idx":null,"evidence_text":"","start_line_num":27,"end_line_num":32},"og_tags":null}},{"start_ix":2344,"end_ix":2355,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"A breakdown of OpenAI's revenue \u2014 EA Forum","url":"https://forum.effectivealtruism.org/posts/ksdSjT7wREu6vBhYE/a-breakdown-of-openai-s-revenue#:~:text=%241,from%20980k%20seats","text":"$1.9B for ChatGPT Plus (7.7M global subscribers), $714M from ChatGPT Enterprise (1.2M seats), $510M from the API, and $290M from ChatGPT Team (from 980k seats)","pub_date":null,"extra":{"cited_message_idx":1,"search_result_idx":null,"evidence_text":"","start_line_num":27,"end_line_num":34},"og_tags":null}},{"start_ix":2594,"end_ix":2608,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Microsoft Announces Changes to OpenAI's Azure Exclusivity on New Cloud Capacity","url":"https://www.thurrott.com/a-i/316138/microsoft-announces-changes-to-openais-azure-exclusivity-on-new-cloud-capacity#:~:text=%CE%94","text":"\u0394","pub_date":null,"extra":{"cited_message_idx":11,"search_result_idx":null,"evidence_text":"","start_line_num":133,"end_line_num":140},"og_tags":null}},{"start_ix":2748,"end_ix":2759,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"A breakdown of OpenAI's revenue \u2014 EA Forum","url":"https://forum.effectivealtruism.org/posts/ksdSjT7wREu6vBhYE/a-breakdown-of-openai-s-revenue#:~:text=,that%20this%20may%20change%20abruptly","text":"* Sam Altman's surprising claim of $3.4B ARR on June 12 seems quite plausible, despite skepticism people raised at the time. * Apps (consumer and enterprise) are much more important to OpenAI than the API. * Consumers are much more important to OpenAI than enterprises, as reflected in all their recent demos, but the enterprise growth rate is so high that this may change abruptly.","pub_date":null,"extra":{"cited_message_idx":1,"search_result_idx":null,"evidence_text":"","start_line_num":61,"end_line_num":68},"og_tags":null}},{"start_ix":3133,"end_ix":3146,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"The AI Arms Race Intensifies: Anthropic v. OpenAI","url":"https://www.linkedin.com/pulse/ai-arms-race-intensifies-anthropics-multi-billion-demotte-kramer-igb2c#:~:text=there%E2%80%99s%20every%20reason%20to%20believe,investors%20in%20the%20mix%20%E2%80%94","text":"there\u2019s every reason to believe the alliance between OpenAI and Microsoft will continue, but I would bet the exclusivity part of the original agreement might soon be renegotiated. Microsoft has invested a hefty $14 billion in OpenAI since 2019, but what\u2019s ahead with Stargate \u2014 and a new raft of investors in the mix \u2014","pub_date":null,"extra":{"cited_message_idx":20,"search_result_idx":null,"evidence_text":"","start_line_num":99,"end_line_num":102},"og_tags":null}},{"start_ix":3362,"end_ix":3376,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Microsoft Announces Changes to OpenAI's Azure Exclusivity on New Cloud Capacity","url":"https://www.thurrott.com/a-i/316138/microsoft-announces-changes-to-openais-azure-exclusivity-on-new-cloud-capacity#:~:text=Microsoft%E2%80%99s%20multi,to%20sell%20additional%20Azure%20capacity","text":"Microsoft\u2019s multi-year partnership with OpenAI is taking a new direction as the ChatGPT maker will no longer exclusively choose Microsoft Azure for new cloud capacity. While OpenAI will continue using Azure to run and train its products, the company will be free to use other cloud providers if Microsoft refuses to sell additional Azure capacity.","pub_date":null,"extra":{"cited_message_idx":11,"search_result_idx":null,"evidence_text":"","start_line_num":107,"end_line_num":115},"og_tags":null}},{"start_ix":3376,"end_ix":3390,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Microsoft Announces Changes to OpenAI's Azure Exclusivity on New Cloud Capacity","url":"https://www.thurrott.com/a-i/316138/microsoft-announces-changes-to-openais-azure-exclusivity-on-new-cloud-capacity#:~:text=Back%20in%20October%2C%20a%20report,charged%20OpenAI%20for%20computing%20power","text":"Back in October, a report from the New York Times detailed how OpenAI had been trying to reduce its costs and find other cloud partners than Microsoft to support its development. The publication also revealed that Microsoft allowed the ChatGPT maker to sign a \u201croughly $10 billion\u201d cloud computing deal with Oracle and agreed to reduce how much it charged OpenAI for computing power.","pub_date":null,"extra":{"cited_message_idx":13,"search_result_idx":null,"evidence_text":"","start_line_num":143,"end_line_num":151},"og_tags":null}},{"start_ix":3720,"end_ix":3731,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Microsoft's complex bet on OpenAI brings potential and uncertainty","url":"https://www.cnbc.com/2023/04/08/microsofts-complex-bet-on-openai-brings-potential-and-uncertainty.html#:~:text=Microsoft%27s%20complex%20bet%20on%20OpenAI,workloads%20pile%20up%20in%20Azure","text":"Microsoft's complex bet on OpenAI brings potential and uncertainty Microsoft's partnership with OpenAI could mean billions of dollars a year in new revenue as workloads pile up in Azure.","pub_date":null,"extra":{"cited_message_idx":3,"search_result_idx":null,"evidence_text":"","start_line_num":13,"end_line_num":17},"og_tags":null}},{"start_ix":3823,"end_ix":3834,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Microsoft's complex bet on OpenAI brings potential and uncertainty","url":"https://www.cnbc.com/2023/04/08/microsofts-complex-bet-on-openai-brings-potential-and-uncertainty.html#:~:text=Microsoft%27s%20complex%20bet%20on%20OpenAI,workloads%20pile%20up%20in%20Azure","text":"Microsoft's complex bet on OpenAI brings potential and uncertainty Microsoft's partnership with OpenAI could mean billions of dollars a year in new revenue as workloads pile up in Azure.","pub_date":null,"extra":{"cited_message_idx":3,"search_result_idx":null,"evidence_text":"","start_line_num":13,"end_line_num":20},"og_tags":null}},{"start_ix":4131,"end_ix":4141,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Bain & Company announces services alliance with OpenAI to help ...","url":"https://www.bain.com/about/media-center/press-releases/2023/bain--company-announces-services-alliance-with-openai-to-help-enterprise-clients-identify-and-realize-the-full-potential-and-maximum-value-of-ai/#:~:text=...%20www.bain.com%20%20The%20Coca,an%20inflection%20point%20and","text":"... www.bain.com  The Coca-Cola Company is the first company to engage with the new alliance, Bain also announced today. \u201cAI has reached an inflection point and ...","pub_date":null,"extra":{"cited_message_idx":28,"search_result_idx":null,"evidence_text":"","start_line_num":1,"end_line_num":9},"og_tags":null}},{"start_ix":4702,"end_ix":4716,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Microsoft Announces Changes to OpenAI's Azure Exclusivity on New Cloud Capacity","url":"https://www.thurrott.com/a-i/316138/microsoft-announces-changes-to-openais-azure-exclusivity-on-new-cloud-capacity#:~:text=Back%20in%20October%2C%20a%20report,charged%20OpenAI%20for%20computing%20power","text":"Back in October, a report from the New York Times detailed how OpenAI had been trying to reduce its costs and find other cloud partners than Microsoft to support its development. The publication also revealed that Microsoft allowed the ChatGPT maker to sign a \u201croughly $10 billion\u201d cloud computing deal with Oracle and agreed to reduce how much it charged OpenAI for computing power.","pub_date":null,"extra":{"cited_message_idx":13,"search_result_idx":null,"evidence_text":"","start_line_num":143,"end_line_num":151},"og_tags":null}},{"start_ix":5543,"end_ix":5554,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"OpenAI AI model sales surpass microsoft! Annual revenue reaches ...","url":"https://www.moomoo.com/news/post/40076818/openai-ai-model-sales-surpass-microsoft-annual-revenue-reaches-1#:~:text=OpenAI%20AI%20model%20sales%20surpass,year%20later%2C%20or%20an","text":"OpenAI AI model sales surpass microsoft! Annual revenue reaches ... According to insiders, Microsoft executives expect Azure OpenAI Service to generate $2 billion in annualized revenue one year later, or an ...","pub_date":null,"extra":{"cited_message_idx":3,"search_result_idx":null,"evidence_text":"","start_line_num":23,"end_line_num":27},"og_tags":null}},{"start_ix":5676,"end_ix":5690,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Microsoft Announces Changes to OpenAI's Azure Exclusivity on New Cloud Capacity","url":"https://www.thurrott.com/a-i/316138/microsoft-announces-changes-to-openais-azure-exclusivity-on-new-cloud-capacity#:~:text=%CE%94","text":"\u0394","pub_date":null,"extra":{"cited_message_idx":11,"search_result_idx":null,"evidence_text":"","start_line_num":133,"end_line_num":140},"og_tags":null}},{"start_ix":6217,"end_ix":6230,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Jony Ive confirms he\u2019s working on a new device with OpenAI | The Verge","url":"https://www.theverge.com/2024/9/21/24250867/jony-ive-confirms-collaboration-openai-hardware#:~:text=Jony%20Ive%20has%20confirmed%20that,designer%20was%20first%20reported%20on","text":"Jony Ive has confirmed that he\u2019s working with OpenAI CEO Sam Altman on an AI hardware project. The confirmation came today as part of a profile of Ive in The New York Times, nearly a year after the possibility of a collaboration between Altman and the longtime Apple designer was first reported on.","pub_date":null,"extra":{"cited_message_idx":6,"search_result_idx":null,"evidence_text":"","start_line_num":164,"end_line_num":173},"og_tags":null}},{"start_ix":6397,"end_ix":6410,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Jony Ive confirms he\u2019s working on a new device with OpenAI | The Verge","url":"https://www.theverge.com/2024/9/21/24250867/jony-ive-confirms-collaboration-openai-hardware#:~:text=There%20aren%E2%80%99t%20a%20lot%20of,1%20billion%20in%20the%20project","text":"There aren\u2019t a lot of details on the project. Ive reportedly met Altman through Brian Chesky, the CEO of Airbnb, and the venture is being funded by Ive and the Emerson Collective, Laurene Powell Jobs\u2019 company. The Times reports it could raise $1 billion in funding by the end of the year but makes no mention of Masayoshi Son, the SoftBank CEO rumored last year to have invested $1 billion in the project.","pub_date":null,"extra":{"cited_message_idx":6,"search_result_idx":null,"evidence_text":"","start_line_num":170,"end_line_num":179},"og_tags":null}},{"start_ix":6769,"end_ix":6783,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"SoftBank, OpenAI unveil Japan AI joint venture | Reuters","url":"https://www.reuters.com/technology/artificial-intelligence/softbank-openai-set-up-ai-japan-joint-venture-2025-02-03/#:~:text=TOKYO%2C%20Feb%203%20%28Reuters%29%20,intelligence%20services%20to%20corporate%20customers","text":"TOKYO, Feb 3 (Reuters) - SoftBank Group (9984.T) , opens new tab CEO Masayoshi Son on Monday said he has agreed with OpenAI CEO Sam Altman to set up a joint venture in Japan to offer artificial intelligence services to corporate customers.","pub_date":null,"extra":{"cited_message_idx":10,"search_result_idx":null,"evidence_text":"","start_line_num":172,"end_line_num":180},"og_tags":null}},{"start_ix":6914,"end_ix":6928,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"SoftBank, OpenAI unveil Japan AI joint venture | Reuters","url":"https://www.reuters.com/technology/artificial-intelligence/softbank-openai-set-up-ai-japan-joint-venture-2025-02-03/#:~:text=Sign%20up%20here","text":"Sign up here.","pub_date":null,"extra":{"cited_message_idx":10,"search_result_idx":null,"evidence_text":"","start_line_num":180,"end_line_num":188},"og_tags":null}},{"start_ix":7059,"end_ix":7073,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"SoftBank, OpenAI unveil Japan AI joint venture | Reuters","url":"https://www.reuters.com/technology/artificial-intelligence/softbank-openai-set-up-ai-japan-joint-venture-2025-02-03/#:~:text=The%20Japanese%20investment%20giant%20will,technology%20across%20SoftBank%20group%20companies","text":"The Japanese investment giant will also pay $3 billion annually to use OpenAI's technology across SoftBank group companies.","pub_date":null,"extra":{"cited_message_idx":10,"search_result_idx":null,"evidence_text":"","start_line_num":182,"end_line_num":190},"og_tags":null}},{"start_ix":7618,"end_ix":7629,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"A breakdown of OpenAI's revenue \u2014 EA Forum","url":"https://forum.effectivealtruism.org/posts/ksdSjT7wREu6vBhYE/a-breakdown-of-openai-s-revenue#:~:text=,that%20this%20may%20change%20abruptly","text":"* Sam Altman's surprising claim of $3.4B ARR on June 12 seems quite plausible, despite skepticism people raised at the time. * Apps (consumer and enterprise) are much more important to OpenAI than the API. * Consumers are much more important to OpenAI than enterprises, as reflected in all their recent demos, but the enterprise growth rate is so high that this may change abruptly.","pub_date":null,"extra":{"cited_message_idx":1,"search_result_idx":null,"evidence_text":"","start_line_num":61,"end_line_num":68},"og_tags":null}},{"start_ix":7947,"end_ix":7958,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"A breakdown of OpenAI's revenue \u2014 EA Forum","url":"https://forum.effectivealtruism.org/posts/ksdSjT7wREu6vBhYE/a-breakdown-of-openai-s-revenue#:~:text=Overall%2C%20these%20numbers%20imply%20to,us%20that","text":"Overall, these numbers imply to us that:","pub_date":null,"extra":{"cited_message_idx":1,"search_result_idx":null,"evidence_text":"","start_line_num":59,"end_line_num":67},"og_tags":null}},{"start_ix":8938,"end_ix":8952,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=When%20ChatGPT%20%20was%20released%2C,few%20companies%20could%20run%20them","text":"When ChatGPT  was released, the general perception was that models improved as they grew. With 175 billion parameters, GPT-3 required hundreds of gigabytes of GPU memory and  42 to train and run. A few open-source LLMs that were released in 2022 were so big and unwieldy that few companies could run them.","pub_date":null,"extra":{"cited_message_idx":18,"search_result_idx":null,"evidence_text":"","start_line_num":158,"end_line_num":166},"og_tags":null}},{"start_ix":9150,"end_ix":9161,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Microsoft's complex bet on OpenAI brings potential and uncertainty","url":"https://www.cnbc.com/2023/04/08/microsofts-complex-bet-on-openai-brings-potential-and-uncertainty.html#:~:text=Microsoft%27s%20complex%20bet%20on%20OpenAI,workloads%20pile%20up%20in%20Azure","text":"Microsoft's complex bet on OpenAI brings potential and uncertainty Microsoft's partnership with OpenAI could mean billions of dollars a year in new revenue as workloads pile up in Azure.","pub_date":null,"extra":{"cited_message_idx":3,"search_result_idx":null,"evidence_text":"","start_line_num":13,"end_line_num":20},"og_tags":null}},{"start_ix":9382,"end_ix":9396,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Microsoft Announces Changes to OpenAI's Azure Exclusivity on New Cloud Capacity","url":"https://www.thurrott.com/a-i/316138/microsoft-announces-changes-to-openais-azure-exclusivity-on-new-cloud-capacity#:~:text=Back%20in%20October%2C%20a%20report,charged%20OpenAI%20for%20computing%20power","text":"Back in October, a report from the New York Times detailed how OpenAI had been trying to reduce its costs and find other cloud partners than Microsoft to support its development. The publication also revealed that Microsoft allowed the ChatGPT maker to sign a \u201croughly $10 billion\u201d cloud computing deal with Oracle and agreed to reduce how much it charged OpenAI for computing power.","pub_date":null,"extra":{"cited_message_idx":13,"search_result_idx":null,"evidence_text":"","start_line_num":143,"end_line_num":151},"og_tags":null}},{"start_ix":9548,"end_ix":9562,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Microsoft Announces Changes to OpenAI's Azure Exclusivity on New Cloud Capacity","url":"https://www.thurrott.com/a-i/316138/microsoft-announces-changes-to-openais-azure-exclusivity-on-new-cloud-capacity#:~:text=Microsoft%E2%80%99s%20multi,to%20sell%20additional%20Azure%20capacity","text":"Microsoft\u2019s multi-year partnership with OpenAI is taking a new direction as the ChatGPT maker will no longer exclusively choose Microsoft Azure for new cloud capacity. While OpenAI will continue using Azure to run and train its products, the company will be free to use other cloud providers if Microsoft refuses to sell additional Azure capacity.","pub_date":null,"extra":{"cited_message_idx":11,"search_result_idx":null,"evidence_text":"","start_line_num":107,"end_line_num":115},"og_tags":null}},{"start_ix":9715,"end_ix":9729,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Microsoft Announces Changes to OpenAI's Azure Exclusivity on New Cloud Capacity","url":"https://www.thurrott.com/a-i/316138/microsoft-announces-changes-to-openais-azure-exclusivity-on-new-cloud-capacity#:~:text=Back%20in%20October%2C%20a%20report,charged%20OpenAI%20for%20computing%20power","text":"Back in October, a report from the New York Times detailed how OpenAI had been trying to reduce its costs and find other cloud partners than Microsoft to support its development. The publication also revealed that Microsoft allowed the ChatGPT maker to sign a \u201croughly $10 billion\u201d cloud computing deal with Oracle and agreed to reduce how much it charged OpenAI for computing power.","pub_date":null,"extra":{"cited_message_idx":13,"search_result_idx":null,"evidence_text":"","start_line_num":143,"end_line_num":151},"og_tags":null}},{"start_ix":9995,"end_ix":10009,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Microsoft Announces Changes to OpenAI's Azure Exclusivity on New Cloud Capacity","url":"https://www.thurrott.com/a-i/316138/microsoft-announces-changes-to-openais-azure-exclusivity-on-new-cloud-capacity#:~:text=Microsoft%20announcing%20it%E2%80%99s%20no%20longer,%E2%80%9D","text":"Microsoft announcing it\u2019s no longer OpenAI\u2019s exclusive cloud provider comes right alongside OpenAI\u2019s Stargate Project announcement. As part of this new joint venture, OpenAI, SoftBank, Oracle, and MGX plan to \u201cinvest $500 billion over the next four years building new AI infrastructure for OpenAI in the United States.\u201d OpenAI said Project Stargate will be investing $100 billion into this new AI infrastructure \u201cimmediately,\u201d and the company also announced Arm, Microsoft, NVIDIA, and Oracle as \u201ckey initial technology partners.\u201d","pub_date":null,"extra":{"cited_message_idx":13,"search_result_idx":null,"evidence_text":"","start_line_num":149,"end_line_num":157},"og_tags":null}},{"start_ix":10151,"end_ix":10165,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Microsoft Announces Changes to OpenAI's Azure Exclusivity on New Cloud Capacity","url":"https://www.thurrott.com/a-i/316138/microsoft-announces-changes-to-openais-azure-exclusivity-on-new-cloud-capacity#:~:text=Microsoft%20announcing%20it%E2%80%99s%20no%20longer,%E2%80%9D","text":"Microsoft announcing it\u2019s no longer OpenAI\u2019s exclusive cloud provider comes right alongside OpenAI\u2019s Stargate Project announcement. As part of this new joint venture, OpenAI, SoftBank, Oracle, and MGX plan to \u201cinvest $500 billion over the next four years building new AI infrastructure for OpenAI in the United States.\u201d OpenAI said Project Stargate will be investing $100 billion into this new AI infrastructure \u201cimmediately,\u201d and the company also announced Arm, Microsoft, NVIDIA, and Oracle as \u201ckey initial technology partners.\u201d","pub_date":null,"extra":{"cited_message_idx":13,"search_result_idx":null,"evidence_text":"","start_line_num":149,"end_line_num":157},"og_tags":null}},{"start_ix":10566,"end_ix":10580,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"SoftBank, OpenAI unveil Japan AI joint venture | Reuters","url":"https://www.reuters.com/technology/artificial-intelligence/softbank-openai-set-up-ai-japan-joint-venture-2025-02-03/#:~:text=,Altman%20said","text":"\"The world is going to just need so much compute,\" Altman said.","pub_date":null,"extra":{"cited_message_idx":10,"search_result_idx":null,"evidence_text":"","start_line_num":199,"end_line_num":207},"og_tags":null}},{"start_ix":10825,"end_ix":10839,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Microsoft Announces Changes to OpenAI's Azure Exclusivity on New Cloud Capacity","url":"https://www.thurrott.com/a-i/316138/microsoft-announces-changes-to-openais-azure-exclusivity-on-new-cloud-capacity#:~:text=Microsoft%E2%80%99s%20multi,to%20sell%20additional%20Azure%20capacity","text":"Microsoft\u2019s multi-year partnership with OpenAI is taking a new direction as the ChatGPT maker will no longer exclusively choose Microsoft Azure for new cloud capacity. While OpenAI will continue using Azure to run and train its products, the company will be free to use other cloud providers if Microsoft refuses to sell additional Azure capacity.","pub_date":null,"extra":{"cited_message_idx":11,"search_result_idx":null,"evidence_text":"","start_line_num":107,"end_line_num":115},"og_tags":null}},{"start_ix":11635,"end_ix":11649,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=However%2C%20a%20study%20by%20DeepMind,time%2C%20according%20to%20the%20researchers","text":"However, a study by DeepMind researchers in 2022 presented the idea that you did not need a huge model to achieve state-of-the-art results. The study, which became known as the Chinchilla paper, suggested that a small model trained on a very large dataset could match the performance of larger models. With 70 billion parameters, the Chinchilla model outperformed other state-of- the-art LLMs of the time, according to the researchers.","pub_date":null,"extra":{"cited_message_idx":18,"search_result_idx":null,"evidence_text":"","start_line_num":172,"end_line_num":180},"og_tags":null}},{"start_ix":11649,"end_ix":11663,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=While%20DeepMind%20did%20not%20open,3%E2%80%99s%20300%20billion%20tokens","text":"While DeepMind did not open-source Chinchilla, the training recipe triggered a new direction of research. In February Meta released Llama, a family of LLMs ranging from 7 to 65 billion parameters. Llama was trained on 1.4 trillion tokens as opposed to GPT-3\u2019s 300 billion tokens.","pub_date":null,"extra":{"cited_message_idx":18,"search_result_idx":null,"evidence_text":"","start_line_num":178,"end_line_num":187},"og_tags":null}},{"start_ix":13182,"end_ix":13192,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Exclusive: OpenAI set to finalize first custom chip design this year","url":"https://www.reuters.com/technology/openai-set-finalize-first-custom-chip-design-this-year-2025-02-10/#:~:text=year%20www,commonly%20used%20systolic%20array","text":"year www.reuters.com  TSMC is manufacturing OpenAI's AI chip using its advanced 3-nanometer process technology. The chip features a commonly used systolic array ...","pub_date":null,"extra":{"cited_message_idx":29,"search_result_idx":null,"evidence_text":"","start_line_num":1,"end_line_num":8},"og_tags":null}},{"start_ix":13299,"end_ix":13311,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"OpenAI reportedly builds custom AI chips as it embraces AMD","url":"https://www.tomshardware.com/tech-industry/artificial-intelligence/openai-reportedly-builds-custom-ai-chips-as-it-embraces-amd-company-also-abandons-plans-to-build-its-own-fabs#:~:text=OpenAI%20reportedly%20builds%20custom%20AI,to%20produce%20it%20for%20TSMC","text":"OpenAI reportedly builds custom AI chips as it embraces AMD OpenAI is proceeding with the development of its first custom AI chip with Broadcom and expects to produce it for TSMC.","pub_date":null,"extra":{"cited_message_idx":29,"search_result_idx":null,"evidence_text":"","start_line_num":19,"end_line_num":27},"og_tags":null}},{"start_ix":13497,"end_ix":13509,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"OpenAI is reportedly getting closer to launching its in-house chip","url":"https://www.theverge.com/news/609421/openai-in-house-chip-development#:~:text=chip%20www,to%20a%20report%20from%20Reuters","text":"chip www.theverge.com  OpenAI remains on track to start producing its in-house AI chip next year, according to a report from Reuters.","pub_date":null,"extra":{"cited_message_idx":29,"search_result_idx":null,"evidence_text":"","start_line_num":39,"end_line_num":46},"og_tags":null}},{"start_ix":14483,"end_ix":14497,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=An%20important%20part%20of%20this,their%20own%20private%20GPT%20Store","text":"An important part of this strategy is creating network effects around ChatGPT, its flagship product. GPT Store, first announced in November, launched last week. It is the AI version of Apple\u2019s App Store, allowing users and developers to share their customized version of the LLM for others to use. Most GPTs are whimsical, but some of them will be very useful and improve productivity. OpenAI will also provide enterprise features, allowing organizations that sign up for the ChatGPT Team plan to have their own private GPT Store.","pub_date":null,"extra":{"cited_message_idx":19,"search_result_idx":null,"evidence_text":"","start_line_num":219,"end_line_num":228},"og_tags":null}},{"start_ix":14497,"end_ix":14511,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=OpenAI%20is%20reinforcing%20the%20network,the%20stickiness%20of%20the%20product","text":"OpenAI is reinforcing the network effects with monetization. According to its website, in Q1 2024, \u201cUS builders will be paid based on user engagement with their GPTs.\u201d This means they will be incentivizing maximum engagement to improve the stickiness of the product.","pub_date":null,"extra":{"cited_message_idx":19,"search_result_idx":null,"evidence_text":"","start_line_num":235,"end_line_num":244},"og_tags":null}},{"start_ix":14764,"end_ix":14778,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=The%20basic%20idea%20is%20that%2C,to%20go%20for%20LLM%20apps","text":"The basic idea is that, with enough critical mass, users will stick to ChatGPT and more users will sign up for the ChatGPT Plus plan to access the GPT Store. And developers will stick to the platform where their assistants will be exposed to more users. The mass usage will also create free publicity for the company as more content will be published about ChatGPT, further establishing it as the defacto place to go for LLM apps.","pub_date":null,"extra":{"cited_message_idx":19,"search_result_idx":null,"evidence_text":"","start_line_num":227,"end_line_num":236},"og_tags":null}},{"start_ix":14778,"end_ix":14792,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=But%20it%20will%20also%20have,bad%20things%20about%20social%20media","text":"But it will also have the adverse effect of replicating all the bad things about social media.","pub_date":null,"extra":{"cited_message_idx":19,"search_result_idx":null,"evidence_text":"","start_line_num":239,"end_line_num":247},"og_tags":null}},{"start_ix":14971,"end_ix":14985,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=defacto%20place%20to%20go%20for,LLM%20apps","text":"defacto place to go for LLM apps.","pub_date":null,"extra":{"cited_message_idx":19,"search_result_idx":null,"evidence_text":"","start_line_num":233,"end_line_num":241},"og_tags":null}},{"start_ix":14985,"end_ix":14999,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=OpenAI%20is%20reinforcing%20the%20network,the%20stickiness%20of%20the%20product","text":"OpenAI is reinforcing the network effects with monetization. According to its website, in Q1 2024, \u201cUS builders will be paid based on user engagement with their GPTs.\u201d This means they will be incentivizing maximum engagement to improve the stickiness of the product.","pub_date":null,"extra":{"cited_message_idx":19,"search_result_idx":null,"evidence_text":"","start_line_num":235,"end_line_num":244},"og_tags":null}},{"start_ix":15534,"end_ix":15548,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=At%20the%20same%20time%2C%20the,of%20the%20data%20collection%20program","text":"At the same time, the company will be reinforcing its data network effects to constantly improve its products. If you\u2019re on the free plan, OpenAI will collect your data and use it to further train its models. If you\u2019re on the Plus plan, your data will still be collected unless you opt out of the data collection program.","pub_date":null,"extra":{"cited_message_idx":19,"search_result_idx":null,"evidence_text":"","start_line_num":243,"end_line_num":251},"og_tags":null}},{"start_ix":15894,"end_ix":15908,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=Another%20important%20effort%20to%20increase,to%20catch%20up%20with%20ChatGPT","text":"Another important effort to increase switching costs is to reduce the costs of running ChatGPT. In a recent interview with Bill Gates, OpenAI CEO Sam Altman said that the company had managed to reduce the costs of running LLMs by a factor of 40. Reduced costs will enable OpenAI to launch more features for both the free and paid tiers of users as open-source LLMs continue to catch up with ChatGPT.","pub_date":null,"extra":{"cited_message_idx":19,"search_result_idx":null,"evidence_text":"","start_line_num":255,"end_line_num":263},"og_tags":null}},{"start_ix":17334,"end_ix":17343,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"OpenAI lost $5 billion in 2024 (and its losses are increasing)","url":"https://www.lesswrong.com/posts/CCQsQnCMWhJcCFY9x/openai-lost-usd5-billion-in-2024-and-its-losses-are#:~:text=OpenAI%20lost%20%245%20billion%20in,the%20region%20of%20%244%20billion","text":"OpenAI lost $5 billion in 2024 (and its losses are increasing) 2024 Revenue: According to reporting by The Information, OpenAI's revenue was likely somewhere in the region of $4 billion.","pub_date":null,"extra":{"cited_message_idx":0,"search_result_idx":null,"evidence_text":"","start_line_num":0,"end_line_num":3},"og_tags":null}},{"start_ix":17343,"end_ix":17352,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"OpenAI lost $5 billion in 2024 (and its losses are increasing)","url":"https://www.lesswrong.com/posts/CCQsQnCMWhJcCFY9x/openai-lost-usd5-billion-in-2024-and-its-losses-are#:~:text=increasing%29%20www,the%20region%20of%20%244%20billion","text":"increasing) www.lesswrong.com  2024 Revenue: According to reporting by The Information, OpenAI's revenue was likely somewhere in the region of $4 billion.","pub_date":null,"extra":{"cited_message_idx":0,"search_result_idx":null,"evidence_text":"","start_line_num":1,"end_line_num":4},"og_tags":null}},{"start_ix":18989,"end_ix":19003,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=When%20ChatGPT%20%20was%20released%2C,few%20companies%20could%20run%20them","text":"When ChatGPT  was released, the general perception was that models improved as they grew. With 175 billion parameters, GPT-3 required hundreds of gigabytes of GPU memory and  42 to train and run. A few open-source LLMs that were released in 2022 were so big and unwieldy that few companies could run them.","pub_date":null,"extra":{"cited_message_idx":18,"search_result_idx":null,"evidence_text":"","start_line_num":158,"end_line_num":167},"og_tags":null}},{"start_ix":19003,"end_ix":19017,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=While%20DeepMind%20did%20not%20open,3%E2%80%99s%20300%20billion%20tokens","text":"While DeepMind did not open-source Chinchilla, the training recipe triggered a new direction of research. In February Meta released Llama, a family of LLMs ranging from 7 to 65 billion parameters. Llama was trained on 1.4 trillion tokens as opposed to GPT-3\u2019s 300 billion tokens.","pub_date":null,"extra":{"cited_message_idx":18,"search_result_idx":null,"evidence_text":"","start_line_num":179,"end_line_num":187},"og_tags":null}},{"start_ix":21621,"end_ix":21633,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Google DeepMind jumps back into open source AI race with new model Gemma | VentureBeat","url":"https://venturebeat.com/ai/google-deepmind-debuts-gemma-open-models-offers-developer-alternative-to-gemini-api/#:~:text=Today%20Google%20DeepMind%20unveiled%20Gemma%2C,announced%20Gemini%20models","text":"Today Google DeepMind unveiled Gemma, its new 2B and 7B open source models built from the same research and technology used to create the company\u2019s recently-announced Gemini models.","pub_date":null,"extra":{"cited_message_idx":27,"search_result_idx":null,"evidence_text":"","start_line_num":83,"end_line_num":92},"og_tags":null}},{"start_ix":21732,"end_ix":21744,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Google DeepMind jumps back into open source AI race with new model Gemma | VentureBeat","url":"https://venturebeat.com/ai/google-deepmind-debuts-gemma-open-models-offers-developer-alternative-to-gemini-api/#:~:text=The%20Gemma%20models%20will%20be,new%20Responsible%20Generative%20AI%20toolkit","text":"The Gemma models will be released with pre-trained and instruction-tuned variants, Google DeepMind said in a blog post. The model weights will be released with a permissive commercial license, as well as a new Responsible Generative AI toolkit.","pub_date":null,"extra":{"cited_message_idx":27,"search_result_idx":null,"evidence_text":"","start_line_num":87,"end_line_num":95},"og_tags":null}},{"start_ix":22529,"end_ix":22541,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Google DeepMind Open-Sources AlphaFold 3: A Game-Changer for ...","url":"https://www.geneonline.com/google-deepmind-open-sources-alphafold-3-a-game-changer-for-drug-discovery-and-biotech/#:~:text=Google%20DeepMind%20Open,of%20protein%20and%20molecular","text":"Google DeepMind Open-Sources AlphaFold 3: A Game-Changer for ... Google DeepMind's AlphaFold 3 promises to transform drug discovery and molecular biology with its advanced AI-powered predictions of protein and molecular ...","pub_date":null,"extra":{"cited_message_idx":26,"search_result_idx":null,"evidence_text":"","start_line_num":37,"end_line_num":45},"og_tags":null}},{"start_ix":24220,"end_ix":24234,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=To%20be%20fair%2C%20OpenAI%20still,art%20models","text":"To be fair, OpenAI still has an advantage in model performance. I still haven\u2019t seen any model that matches GPT-4. But several open-source models already match and outperform GPT-3.5. It is only a matter of time before they reach GPT-4 and other state-of-the-art models.","pub_date":null,"extra":{"cited_message_idx":18,"search_result_idx":null,"evidence_text":"","start_line_num":199,"end_line_num":207},"og_tags":null}},{"start_ix":24371,"end_ix":24385,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=To%20be%20fair%2C%20OpenAI%20still,art%20models","text":"To be fair, OpenAI still has an advantage in model performance. I still haven\u2019t seen any model that matches GPT-4. But several open-source models already match and outperform GPT-3.5. It is only a matter of time before they reach GPT-4 and other state-of-the-art models.","pub_date":null,"extra":{"cited_message_idx":18,"search_result_idx":null,"evidence_text":"","start_line_num":199,"end_line_num":207},"og_tags":null}},{"start_ix":24385,"end_ix":24399,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=The%20open,as%20data%20ownership%20and%20privacy","text":"The open-source models took away the advantage of big tech and commoditized the market. As the costs of switching drop, more and more companies will be incentivized to move from GPT-4 to low-cost open-source models. Even if these models don\u2019t match GPT-4, most enterprises have specialized needs that can be met with a carefully fine-tuned model that has a fraction of the costs and matches other needs such as data ownership and privacy.","pub_date":null,"extra":{"cited_message_idx":18,"search_result_idx":null,"evidence_text":"","start_line_num":203,"end_line_num":211},"og_tags":null}},{"start_ix":24641,"end_ix":24655,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=To%20be%20fair%2C%20OpenAI%20still,art%20models","text":"To be fair, OpenAI still has an advantage in model performance. I still haven\u2019t seen any model that matches GPT-4. But several open-source models already match and outperform GPT-3.5. It is only a matter of time before they reach GPT-4 and other state-of-the-art models.","pub_date":null,"extra":{"cited_message_idx":18,"search_result_idx":null,"evidence_text":"","start_line_num":199,"end_line_num":207},"og_tags":null}},{"start_ix":24655,"end_ix":24669,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=The%20open,as%20data%20ownership%20and%20privacy","text":"The open-source models took away the advantage of big tech and commoditized the market. As the costs of switching drop, more and more companies will be incentivized to move from GPT-4 to low-cost open-source models. Even if these models don\u2019t match GPT-4, most enterprises have specialized needs that can be met with a carefully fine-tuned model that has a fraction of the costs and matches other needs such as data ownership and privacy.","pub_date":null,"extra":{"cited_message_idx":18,"search_result_idx":null,"evidence_text":"","start_line_num":203,"end_line_num":211},"og_tags":null}},{"start_ix":25178,"end_ix":25192,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=An%20important%20part%20of%20this,their%20own%20private%20GPT%20Store","text":"An important part of this strategy is creating network effects around ChatGPT, its flagship product. GPT Store, first announced in November, launched last week. It is the AI version of Apple\u2019s App Store, allowing users and developers to share their customized version of the LLM for others to use. Most GPTs are whimsical, but some of them will be very useful and improve productivity. OpenAI will also provide enterprise features, allowing organizations that sign up for the ChatGPT Team plan to have their own private GPT Store.","pub_date":null,"extra":{"cited_message_idx":19,"search_result_idx":null,"evidence_text":"","start_line_num":219,"end_line_num":228},"og_tags":null}},{"start_ix":25192,"end_ix":25206,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=to%20more%20users,to%20go%20for%20LLM%20apps","text":"to more users. The mass usage will also create free publicity for the company as more content will be published about ChatGPT, further establishing it as the defacto place to go for LLM apps.","pub_date":null,"extra":{"cited_message_idx":19,"search_result_idx":null,"evidence_text":"","start_line_num":231,"end_line_num":239},"og_tags":null}},{"start_ix":25556,"end_ix":25570,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=OpenAI%20is%20also%20preparing%20itself,to%20launch%20its%20vertical%20stack","text":"OpenAI is also preparing itself for the future. There are talks about OpenAI working on its own device, probably built around its LLM. This will give it the power of vertical integration, like Apple\u2019s iron grip on the iOS ecosystem. We are seeing what might be the beginning of a new paradigm shift in computing. As the field develops and new computing paradigms emerge, OpenAI will be ready to launch its vertical stack.","pub_date":null,"extra":{"cited_message_idx":19,"search_result_idx":null,"evidence_text":"","start_line_num":262,"end_line_num":269},"og_tags":null}},{"start_ix":25944,"end_ix":25958,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=,January%2011%2C%202024","text":"> \u2014 will depue (@willdepue) January 11, 2024","pub_date":null,"extra":{"cited_message_idx":19,"search_result_idx":null,"evidence_text":"","start_line_num":253,"end_line_num":261},"og_tags":null}},{"start_ix":27490,"end_ix":27502,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"The AI Arms Race Intensifies: Anthropic v. OpenAI","url":"https://www.linkedin.com/pulse/ai-arms-race-intensifies-anthropics-multi-billion-demotte-kramer-igb2c#:~:text=Google%20Doubles%20Down%20on%20Anthropic","text":"Google Doubles Down on Anthropic","pub_date":null,"extra":{"cited_message_idx":20,"search_result_idx":null,"evidence_text":"","start_line_num":50,"end_line_num":58},"og_tags":null}},{"start_ix":27502,"end_ix":27514,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"The AI Arms Race Intensifies: Anthropic v. OpenAI","url":"https://www.linkedin.com/pulse/ai-arms-race-intensifies-anthropics-multi-billion-demotte-kramer-igb2c#:~:text=Amazon%27s%20Strategic%20Partnership%20Takes%20Shape","text":"Amazon's Strategic Partnership Takes Shape","pub_date":null,"extra":{"cited_message_idx":20,"search_result_idx":null,"evidence_text":"","start_line_num":60,"end_line_num":68},"og_tags":null}},{"start_ix":29264,"end_ix":29276,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=What%20to%20know%20about%20Google,5%20Pro","text":"What to know about Google Gemini 2.5 Pro","pub_date":null,"extra":{"cited_message_idx":16,"search_result_idx":null,"evidence_text":"","start_line_num":25,"end_line_num":33},"og_tags":null}},{"start_ix":29276,"end_ix":29288,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=How%20OpenAI%20is%20building%20its,moat","text":"How OpenAI is building its moat","pub_date":null,"extra":{"cited_message_idx":16,"search_result_idx":null,"evidence_text":"","start_line_num":37,"end_line_num":45},"og_tags":null}},{"start_ix":30409,"end_ix":30421,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Google DeepMind jumps back into open source AI race with new model Gemma | VentureBeat","url":"https://venturebeat.com/ai/google-deepmind-debuts-gemma-open-models-offers-developer-alternative-to-gemini-api/#:~:text=Today%20Google%20DeepMind%20unveiled%20Gemma%2C,announced%20Gemini%20models","text":"Today Google DeepMind unveiled Gemma, its new 2B and 7B open source models built from the same research and technology used to create the company\u2019s recently-announced Gemini models.","pub_date":null,"extra":{"cited_message_idx":27,"search_result_idx":null,"evidence_text":"","start_line_num":83,"end_line_num":92},"og_tags":null}},{"start_ix":30568,"end_ix":30580,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Google DeepMind jumps back into open source AI race with new model Gemma | VentureBeat","url":"https://venturebeat.com/ai/google-deepmind-debuts-gemma-open-models-offers-developer-alternative-to-gemini-api/#:~:text=The%20Gemma%20models%20will%20be,new%20Responsible%20Generative%20AI%20toolkit","text":"The Gemma models will be released with pre-trained and instruction-tuned variants, Google DeepMind said in a blog post. The model weights will be released with a permissive commercial license, as well as a new Responsible Generative AI toolkit.","pub_date":null,"extra":{"cited_message_idx":27,"search_result_idx":null,"evidence_text":"","start_line_num":87,"end_line_num":95},"og_tags":null}},{"start_ix":30580,"end_ix":30593,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Google DeepMind jumps back into open source AI race with new model Gemma | VentureBeat","url":"https://venturebeat.com/ai/google-deepmind-debuts-gemma-open-models-offers-developer-alternative-to-gemini-api/#:~:text=AI%20console,Kubernetes%20Engine","text":"AI console.cloud.google.com  and Google Kubernetes Engine.","pub_date":null,"extra":{"cited_message_idx":27,"search_result_idx":null,"evidence_text":"","start_line_num":99,"end_line_num":107},"og_tags":null}},{"start_ix":32168,"end_ix":32182,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=When%20ChatGPT%20%20was%20released%2C,few%20companies%20could%20run%20them","text":"When ChatGPT  was released, the general perception was that models improved as they grew. With 175 billion parameters, GPT-3 required hundreds of gigabytes of GPU memory and  42 to train and run. A few open-source LLMs that were released in 2022 were so big and unwieldy that few companies could run them.","pub_date":null,"extra":{"cited_message_idx":18,"search_result_idx":null,"evidence_text":"","start_line_num":158,"end_line_num":167},"og_tags":null}},{"start_ix":32182,"end_ix":32196,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=While%20DeepMind%20did%20not%20open,3%E2%80%99s%20300%20billion%20tokens","text":"While DeepMind did not open-source Chinchilla, the training recipe triggered a new direction of research. In February Meta released Llama, a family of LLMs ranging from 7 to 65 billion parameters. Llama was trained on 1.4 trillion tokens as opposed to GPT-3\u2019s 300 billion tokens.","pub_date":null,"extra":{"cited_message_idx":18,"search_result_idx":null,"evidence_text":"","start_line_num":179,"end_line_num":187},"og_tags":null}},{"start_ix":32522,"end_ix":32534,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Google DeepMind jumps back into open source AI race with new model Gemma | VentureBeat","url":"https://venturebeat.com/ai/google-deepmind-debuts-gemma-open-models-offers-developer-alternative-to-gemini-api/#:~:text=Today%20Google%20DeepMind%20unveiled%20Gemma%2C,announced%20Gemini%20models","text":"Today Google DeepMind unveiled Gemma, its new 2B and 7B open source models built from the same research and technology used to create the company\u2019s recently-announced Gemini models.","pub_date":null,"extra":{"cited_message_idx":27,"search_result_idx":null,"evidence_text":"","start_line_num":83,"end_line_num":92},"og_tags":null}},{"start_ix":32534,"end_ix":32546,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Google DeepMind jumps back into open source AI race with new model Gemma | VentureBeat","url":"https://venturebeat.com/ai/google-deepmind-debuts-gemma-open-models-offers-developer-alternative-to-gemini-api/#:~:text=The%20Gemma%20models%20will%20be,new%20Responsible%20Generative%20AI%20toolkit","text":"The Gemma models will be released with pre-trained and instruction-tuned variants, Google DeepMind said in a blog post. The model weights will be released with a permissive commercial license, as well as a new Responsible Generative AI toolkit.","pub_date":null,"extra":{"cited_message_idx":27,"search_result_idx":null,"evidence_text":"","start_line_num":87,"end_line_num":95},"og_tags":null}},{"start_ix":33478,"end_ix":33492,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=An%20important%20part%20of%20this,their%20own%20private%20GPT%20Store","text":"An important part of this strategy is creating network effects around ChatGPT, its flagship product. GPT Store, first announced in November, launched last week. It is the AI version of Apple\u2019s App Store, allowing users and developers to share their customized version of the LLM for others to use. Most GPTs are whimsical, but some of them will be very useful and improve productivity. OpenAI will also provide enterprise features, allowing organizations that sign up for the ChatGPT Team plan to have their own private GPT Store.","pub_date":null,"extra":{"cited_message_idx":19,"search_result_idx":null,"evidence_text":"","start_line_num":219,"end_line_num":228},"og_tags":null}},{"start_ix":34234,"end_ix":34246,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Google DeepMind jumps back into open source AI race with new model Gemma | VentureBeat","url":"https://venturebeat.com/ai/google-deepmind-debuts-gemma-open-models-offers-developer-alternative-to-gemini-api/#:~:text=The%20Gemma%20models%20will%20be,new%20Responsible%20Generative%20AI%20toolkit","text":"The Gemma models will be released with pre-trained and instruction-tuned variants, Google DeepMind said in a blog post. The model weights will be released with a permissive commercial license, as well as a new Responsible Generative AI toolkit.","pub_date":null,"extra":{"cited_message_idx":27,"search_result_idx":null,"evidence_text":"","start_line_num":87,"end_line_num":95},"og_tags":null}},{"start_ix":34617,"end_ix":34631,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=OpenAI%20is%20also%20preparing%20itself,to%20launch%20its%20vertical%20stack","text":"OpenAI is also preparing itself for the future. There are talks about OpenAI working on its own device, probably built around its LLM. This will give it the power of vertical integration, like Apple\u2019s iron grip on the iOS ecosystem. We are seeing what might be the beginning of a new paradigm shift in computing. As the field develops and new computing paradigms emerge, OpenAI will be ready to launch its vertical stack.","pub_date":null,"extra":{"cited_message_idx":19,"search_result_idx":null,"evidence_text":"","start_line_num":262,"end_line_num":269},"og_tags":null}},{"start_ix":35377,"end_ix":35388,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"A breakdown of OpenAI's revenue \u2014 EA Forum","url":"https://forum.effectivealtruism.org/posts/ksdSjT7wREu6vBhYE/a-breakdown-of-openai-s-revenue#:~:text=,that%20this%20may%20change%20abruptly","text":"* Sam Altman's surprising claim of $3.4B ARR on June 12 seems quite plausible, despite skepticism people raised at the time. * Apps (consumer and enterprise) are much more important to OpenAI than the API. * Consumers are much more important to OpenAI than enterprises, as reflected in all their recent demos, but the enterprise growth rate is so high that this may change abruptly.","pub_date":null,"extra":{"cited_message_idx":1,"search_result_idx":null,"evidence_text":"","start_line_num":61,"end_line_num":68},"og_tags":null}},{"start_ix":35494,"end_ix":35508,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"SoftBank, OpenAI unveil Japan AI joint venture | Reuters","url":"https://www.reuters.com/technology/artificial-intelligence/softbank-openai-set-up-ai-japan-joint-venture-2025-02-03/#:~:text=Sign%20up%20here","text":"Sign up here.","pub_date":null,"extra":{"cited_message_idx":10,"search_result_idx":null,"evidence_text":"","start_line_num":180,"end_line_num":188},"og_tags":null}},{"start_ix":35857,"end_ix":35869,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"The AI Arms Race Intensifies: Anthropic v. OpenAI","url":"https://www.linkedin.com/pulse/ai-arms-race-intensifies-anthropics-multi-billion-demotte-kramer-igb2c#:~:text=Amazon%27s%20Strategic%20Partnership%20Takes%20Shape","text":"Amazon's Strategic Partnership Takes Shape","pub_date":null,"extra":{"cited_message_idx":20,"search_result_idx":null,"evidence_text":"","start_line_num":60,"end_line_num":68},"og_tags":null}},{"start_ix":35869,"end_ix":35881,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"The AI Arms Race Intensifies: Anthropic v. OpenAI","url":"https://www.linkedin.com/pulse/ai-arms-race-intensifies-anthropics-multi-billion-demotte-kramer-igb2c#:~:text=Anthropic%27s%20reported%20discussions%20with%20Lightspeed,stakes%20in%20leading%20AI%20companies","text":"Anthropic's reported discussions with Lightspeed Venture Partners for a $2 billion funding round at a $60 billion valuation mark a dramatic increase from its $18.5 billion valuation last February. This more than threefold jump in valuation within a year reflects both market confidence in Anthropic's technology and the premium investors are willing to pay for stakes in leading AI companies.","pub_date":null,"extra":{"cited_message_idx":20,"search_result_idx":null,"evidence_text":"","start_line_num":73,"end_line_num":81},"og_tags":null}},{"start_ix":36566,"end_ix":36580,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Microsoft Announces Changes to OpenAI's Azure Exclusivity on New Cloud Capacity","url":"https://www.thurrott.com/a-i/316138/microsoft-announces-changes-to-openais-azure-exclusivity-on-new-cloud-capacity#:~:text=%CE%94","text":"\u0394","pub_date":null,"extra":{"cited_message_idx":11,"search_result_idx":null,"evidence_text":"","start_line_num":133,"end_line_num":140},"og_tags":null}},{"start_ix":36646,"end_ix":36660,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"SoftBank, OpenAI unveil Japan AI joint venture | Reuters","url":"https://www.reuters.com/technology/artificial-intelligence/softbank-openai-set-up-ai-japan-joint-venture-2025-02-03/#:~:text=Sign%20up%20here","text":"Sign up here.","pub_date":null,"extra":{"cited_message_idx":10,"search_result_idx":null,"evidence_text":"","start_line_num":180,"end_line_num":188},"og_tags":null}},{"start_ix":38147,"end_ix":38161,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=An%20important%20part%20of%20this,their%20own%20private%20GPT%20Store","text":"An important part of this strategy is creating network effects around ChatGPT, its flagship product. GPT Store, first announced in November, launched last week. It is the AI version of Apple\u2019s App Store, allowing users and developers to share their customized version of the LLM for others to use. Most GPTs are whimsical, but some of them will be very useful and improve productivity. OpenAI will also provide enterprise features, allowing organizations that sign up for the ChatGPT Team plan to have their own private GPT Store.","pub_date":null,"extra":{"cited_message_idx":19,"search_result_idx":null,"evidence_text":"","start_line_num":219,"end_line_num":228},"og_tags":null}},{"start_ix":38161,"end_ix":38175,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=The%20basic%20idea%20is%20that%2C,to%20go%20for%20LLM%20apps","text":"The basic idea is that, with enough critical mass, users will stick to ChatGPT and more users will sign up for the ChatGPT Plus plan to access the GPT Store. And developers will stick to the platform where their assistants will be exposed to more users. The mass usage will also create free publicity for the company as more content will be published about ChatGPT, further establishing it as the defacto place to go for LLM apps.","pub_date":null,"extra":{"cited_message_idx":19,"search_result_idx":null,"evidence_text":"","start_line_num":227,"end_line_num":236},"og_tags":null}},{"start_ix":38977,"end_ix":38988,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"A breakdown of OpenAI's revenue \u2014 EA Forum","url":"https://forum.effectivealtruism.org/posts/ksdSjT7wREu6vBhYE/a-breakdown-of-openai-s-revenue#:~:text=,that%20this%20may%20change%20abruptly","text":"* Sam Altman's surprising claim of $3.4B ARR on June 12 seems quite plausible, despite skepticism people raised at the time. * Apps (consumer and enterprise) are much more important to OpenAI than the API. * Consumers are much more important to OpenAI than enterprises, as reflected in all their recent demos, but the enterprise growth rate is so high that this may change abruptly.","pub_date":null,"extra":{"cited_message_idx":1,"search_result_idx":null,"evidence_text":"","start_line_num":61,"end_line_num":68},"og_tags":null}},{"start_ix":39774,"end_ix":39786,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"The AI Arms Race Intensifies: Anthropic v. OpenAI","url":"https://www.linkedin.com/pulse/ai-arms-race-intensifies-anthropics-multi-billion-demotte-kramer-igb2c#:~:text=Valuation%20Surge%20Signals%20Market%20Confidence","text":"Valuation Surge Signals Market Confidence","pub_date":null,"extra":{"cited_message_idx":20,"search_result_idx":null,"evidence_text":"","start_line_num":71,"end_line_num":79},"og_tags":null}},{"start_ix":43094,"end_ix":43108,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=Following%20the%20release%20of%20Llama%2C,create%20commercial%20products%20with%20them","text":"Following the release of Llama, a slew of other open-source models were released, each building on and improving the previous ones. Many came with licenses that allowed developers to create commercial products with them.","pub_date":null,"extra":{"cited_message_idx":18,"search_result_idx":null,"evidence_text":"","start_line_num":188,"end_line_num":196},"og_tags":null}},{"start_ix":43108,"end_ix":43122,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=Model%20compression%20%2C%20quantization%2C%20,LLMs%20running%20on%20edge%20devices","text":"Model compression , quantization,  46, and other techniques developed throughout the year made it increasingly convenient for companies to adopt open-source models for their applications. New programming frameworks, low-code/no-code tools, and online platforms made it easier to customize and run LLMs on company infrastructure. 2024 already promises innovations such as high-performance LLMs running on edge devices.","pub_date":null,"extra":{"cited_message_idx":18,"search_result_idx":null,"evidence_text":"","start_line_num":192,"end_line_num":200},"og_tags":null}},{"start_ix":44811,"end_ix":44823,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=,due%20to%20their%20greater%20transparency","text":"* Stanford used the White House definition of open foundation models as those with \"widely available model weights.\" * Government reactions to the rise of open models have ranged from alarm in the White House over bioterrorism threats, to Beijing blacklisting certain types of generative AI training data and the EU offering regulatory exemptions to open models due to their greater transparency.","pub_date":null,"extra":{"cited_message_idx":22,"search_result_idx":null,"evidence_text":"","start_line_num":57,"end_line_num":65},"og_tags":null}},{"start_ix":44823,"end_ix":44835,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=,due%20to%20their%20greater%20transparency","text":"* Government reactions to the rise of open models have ranged from alarm in the White House over bioterrorism threats, to Beijing blacklisting certain types of generative AI training data and the EU offering regulatory exemptions to open models due to their greater transparency.","pub_date":null,"extra":{"cited_message_idx":22,"search_result_idx":null,"evidence_text":"","start_line_num":59,"end_line_num":67},"og_tags":null}},{"start_ix":45344,"end_ix":45356,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=,the%20team%20concluded","text":"* They then articulated five distinctive properties of such models: broader access, greater customizability, potential for local \"inference,\" inability to rescind model access once released and weak monitoring of how a model is being used. * Any attempt to impose conditions on users of open models are \"easy for malicious actors to ignore,\" the team concluded.","pub_date":null,"extra":{"cited_message_idx":22,"search_result_idx":null,"evidence_text":"","start_line_num":67,"end_line_num":75},"og_tags":null}},{"start_ix":45356,"end_ix":45368,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=rescind%20model%20access%20once%20released,the%20team%20concluded","text":"rescind model access once released and weak monitoring of how a model is being used. * Any attempt to impose conditions on users of open models are \"easy for malicious actors to ignore,\" the team concluded.","pub_date":null,"extra":{"cited_message_idx":22,"search_result_idx":null,"evidence_text":"","start_line_num":69,"end_line_num":73},"og_tags":null}},{"start_ix":45497,"end_ix":45509,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=,the%20team%20concluded","text":"* They then articulated five distinctive properties of such models: broader access, greater customizability, potential for local \"inference,\" inability to rescind model access once released and weak monitoring of how a model is being used. * Any attempt to impose conditions on users of open models are \"easy for malicious actors to ignore,\" the team concluded.","pub_date":null,"extra":{"cited_message_idx":22,"search_result_idx":null,"evidence_text":"","start_line_num":67,"end_line_num":75},"og_tags":null}},{"start_ix":47888,"end_ix":47900,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=,due%20to%20their%20greater%20transparency","text":"* Stanford used the White House definition of open foundation models as those with \"widely available model weights.\" * Government reactions to the rise of open models have ranged from alarm in the White House over bioterrorism threats, to Beijing blacklisting certain types of generative AI training data and the EU offering regulatory exemptions to open models due to their greater transparency.","pub_date":null,"extra":{"cited_message_idx":22,"search_result_idx":null,"evidence_text":"","start_line_num":57,"end_line_num":65},"og_tags":null}},{"start_ix":47900,"end_ix":47912,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=,due%20to%20their%20greater%20transparency","text":"* Government reactions to the rise of open models have ranged from alarm in the White House over bioterrorism threats, to Beijing blacklisting certain types of generative AI training data and the EU offering regulatory exemptions to open models due to their greater transparency.","pub_date":null,"extra":{"cited_message_idx":22,"search_result_idx":null,"evidence_text":"","start_line_num":59,"end_line_num":67},"og_tags":null}},{"start_ix":48714,"end_ix":48728,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=Following%20the%20release%20of%20Llama%2C,create%20commercial%20products%20with%20them","text":"Following the release of Llama, a slew of other open-source models were released, each building on and improving the previous ones. Many came with licenses that allowed developers to create commercial products with them.","pub_date":null,"extra":{"cited_message_idx":18,"search_result_idx":null,"evidence_text":"","start_line_num":188,"end_line_num":196},"og_tags":null}},{"start_ix":48919,"end_ix":48931,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=rescind%20model%20access%20once%20released,the%20team%20concluded","text":"rescind model access once released and weak monitoring of how a model is being used. * Any attempt to impose conditions on users of open models are \"easy for malicious actors to ignore,\" the team concluded.","pub_date":null,"extra":{"cited_message_idx":22,"search_result_idx":null,"evidence_text":"","start_line_num":69,"end_line_num":77},"og_tags":null}},{"start_ix":50236,"end_ix":50247,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"On the Societal Impact of Open Foundation Models | Stanford HAI","url":"https://hai.stanford.edu/news/societal-impact-open-foundation-models#:~:text=HAI%20hai,power%2C%20and%20enabling%20scientific%20research","text":"HAI hai.stanford.edu  We analyze the benefits of open foundation models such as transparency, distribution of power, and enabling scientific research.","pub_date":null,"extra":{"cited_message_idx":21,"search_result_idx":null,"evidence_text":"","start_line_num":7,"end_line_num":15},"og_tags":null}},{"start_ix":50247,"end_ix":50259,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=The%20main%20benefits%20are%20distributing,accelerating%20science%20and%20enabling%20transparency","text":"The main benefits are distributing decision-making power, reducing market concentration, increasing innovation, accelerating science and enabling transparency.","pub_date":null,"extra":{"cited_message_idx":22,"search_result_idx":null,"evidence_text":"","start_line_num":73,"end_line_num":81},"og_tags":null}},{"start_ix":50379,"end_ix":50391,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=,due%20to%20their%20greater%20transparency","text":"* Stanford used the White House definition of open foundation models as those with \"widely available model weights.\" * Government reactions to the rise of open models have ranged from alarm in the White House over bioterrorism threats, to Beijing blacklisting certain types of generative AI training data and the EU offering regulatory exemptions to open models due to their greater transparency.","pub_date":null,"extra":{"cited_message_idx":22,"search_result_idx":null,"evidence_text":"","start_line_num":57,"end_line_num":65},"og_tags":null}},{"start_ix":50391,"end_ix":50403,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=,due%20to%20their%20greater%20transparency","text":"* Government reactions to the rise of open models have ranged from alarm in the White House over bioterrorism threats, to Beijing blacklisting certain types of generative AI training data and the EU offering regulatory exemptions to open models due to their greater transparency.","pub_date":null,"extra":{"cited_message_idx":22,"search_result_idx":null,"evidence_text":"","start_line_num":59,"end_line_num":67},"og_tags":null}},{"start_ix":51473,"end_ix":51487,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=Following%20the%20release%20of%20Llama%2C,create%20commercial%20products%20with%20them","text":"Following the release of Llama, a slew of other open-source models were released, each building on and improving the previous ones. Many came with licenses that allowed developers to create commercial products with them.","pub_date":null,"extra":{"cited_message_idx":18,"search_result_idx":null,"evidence_text":"","start_line_num":188,"end_line_num":196},"og_tags":null}},{"start_ix":51487,"end_ix":51501,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=Model%20compression%20%2C%20quantization%2C%20,LLMs%20running%20on%20edge%20devices","text":"Model compression , quantization,  46, and other techniques developed throughout the year made it increasingly convenient for companies to adopt open-source models for their applications. New programming frameworks, low-code/no-code tools, and online platforms made it easier to customize and run LLMs on company infrastructure. 2024 already promises innovations such as high-performance LLMs running on edge devices.","pub_date":null,"extra":{"cited_message_idx":18,"search_result_idx":null,"evidence_text":"","start_line_num":192,"end_line_num":200},"og_tags":null}},{"start_ix":53886,"end_ix":53898,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=match%20at%20L141%20GPT,the%20market%20of%20private%20LLMs","text":"match at L141 GPT-4. The main point of the memo was that neither Google nor OpenAI have moats and eventually, open-source models will conquer the market of private LLMs.","pub_date":null,"extra":{"cited_message_idx":17,"search_result_idx":null,"evidence_text":"","start_line_num":23,"end_line_num":31},"og_tags":null}},{"start_ix":53898,"end_ix":53910,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=GPT,the%20market%20of%20private%20LLMs","text":"GPT-4. The main point of the memo was that neither Google nor OpenAI have moats and eventually, open-source models will conquer the market of private LLMs.","pub_date":null,"extra":{"cited_message_idx":17,"search_result_idx":null,"evidence_text":"","start_line_num":25,"end_line_num":33},"og_tags":null}},{"start_ix":54069,"end_ix":54083,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=To%20be%20fair%2C%20OpenAI%20still,art%20models","text":"To be fair, OpenAI still has an advantage in model performance. I still haven\u2019t seen any model that matches GPT-4. But several open-source models already match and outperform GPT-3.5. It is only a matter of time before they reach GPT-4 and other state-of-the-art models.","pub_date":null,"extra":{"cited_message_idx":18,"search_result_idx":null,"evidence_text":"","start_line_num":199,"end_line_num":207},"og_tags":null}},{"start_ix":57886,"end_ix":57900,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"SoftBank, OpenAI unveil Japan AI joint venture | Reuters","url":"https://www.reuters.com/technology/artificial-intelligence/softbank-openai-set-up-ai-japan-joint-venture-2025-02-03/#:~:text=China%27s%20DeepSeek%20has%20caused%20investors,companies","text":"China's DeepSeek has caused investors to question the billions being poured into AI technology with a model that appears to rival the capabilities of leading U.S. companies.","pub_date":null,"extra":{"cited_message_idx":10,"search_result_idx":null,"evidence_text":"","start_line_num":195,"end_line_num":203},"og_tags":null}},{"start_ix":59349,"end_ix":59361,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=,the%20team%20concluded","text":"* They then articulated five distinctive properties of such models: broader access, greater customizability, potential for local \"inference,\" inability to rescind model access once released and weak monitoring of how a model is being used. * Any attempt to impose conditions on users of open models are \"easy for malicious actors to ignore,\" the team concluded.","pub_date":null,"extra":{"cited_message_idx":22,"search_result_idx":null,"evidence_text":"","start_line_num":67,"end_line_num":75},"og_tags":null}},{"start_ix":59361,"end_ix":59373,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=rescind%20model%20access%20once%20released,the%20team%20concluded","text":"rescind model access once released and weak monitoring of how a model is being used. * Any attempt to impose conditions on users of open models are \"easy for malicious actors to ignore,\" the team concluded.","pub_date":null,"extra":{"cited_message_idx":22,"search_result_idx":null,"evidence_text":"","start_line_num":69,"end_line_num":77},"og_tags":null}},{"start_ix":59488,"end_ix":59500,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=,the%20team%20concluded","text":"* They then articulated five distinctive properties of such models: broader access, greater customizability, potential for local \"inference,\" inability to rescind model access once released and weak monitoring of how a model is being used. * Any attempt to impose conditions on users of open models are \"easy for malicious actors to ignore,\" the team concluded.","pub_date":null,"extra":{"cited_message_idx":22,"search_result_idx":null,"evidence_text":"","start_line_num":67,"end_line_num":75},"og_tags":null}},{"start_ix":59500,"end_ix":59512,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=rescind%20model%20access%20once%20released,the%20team%20concluded","text":"rescind model access once released and weak monitoring of how a model is being used. * Any attempt to impose conditions on users of open models are \"easy for malicious actors to ignore,\" the team concluded.","pub_date":null,"extra":{"cited_message_idx":22,"search_result_idx":null,"evidence_text":"","start_line_num":69,"end_line_num":73},"og_tags":null}},{"start_ix":63030,"end_ix":63042,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=The%20main%20benefits%20are%20distributing,accelerating%20science%20and%20enabling%20transparency","text":"The main benefits are distributing decision-making power, reducing market concentration, increasing innovation, accelerating science and enabling transparency.","pub_date":null,"extra":{"cited_message_idx":22,"search_result_idx":null,"evidence_text":"","start_line_num":73,"end_line_num":81},"og_tags":null}},{"start_ix":63042,"end_ix":63054,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=concentration%2C%20increasing%20innovation%2C%20accelerating%20science,and%20enabling%20transparency","text":"concentration, increasing innovation, accelerating science and enabling transparency.","pub_date":null,"extra":{"cited_message_idx":22,"search_result_idx":null,"evidence_text":"","start_line_num":75,"end_line_num":83},"og_tags":null}},{"start_ix":63221,"end_ix":63233,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=Threat%20level%3A%20The%20researchers%20argue,all%20existed%20before%20generative%20AI","text":"Threat level: The researchers argue that there often isn't proof that theoretical risks have materialized and that risks such as disinformation, scams and bioterrorism all existed before generative AI.","pub_date":null,"extra":{"cited_message_idx":22,"search_result_idx":null,"evidence_text":"","start_line_num":81,"end_line_num":89},"og_tags":null}},{"start_ix":63340,"end_ix":63352,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=The%20main%20benefits%20are%20distributing,accelerating%20science%20and%20enabling%20transparency","text":"The main benefits are distributing decision-making power, reducing market concentration, increasing innovation, accelerating science and enabling transparency.","pub_date":null,"extra":{"cited_message_idx":22,"search_result_idx":null,"evidence_text":"","start_line_num":73,"end_line_num":81},"og_tags":null}},{"start_ix":63352,"end_ix":63364,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=concentration%2C%20increasing%20innovation%2C%20accelerating%20science,and%20enabling%20transparency","text":"concentration, increasing innovation, accelerating science and enabling transparency.","pub_date":null,"extra":{"cited_message_idx":22,"search_result_idx":null,"evidence_text":"","start_line_num":75,"end_line_num":83},"og_tags":null}},{"start_ix":64260,"end_ix":64272,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"The moats are in the GPT-wrappers","url":"https://interjectedfuture.com/the-moats-are-in-the-gpt-wrappers/#:~:text=technology%29%20and%20the%20Job,the%20Law%20of%20Attractive%20Profits","text":"technology) and the Job-to-be-done (how to view what value means to customers). But he has a less well-known framework called the Law of Conservation of Modularity (previously known as the Law of Attractive Profits)","pub_date":null,"extra":{"cited_message_idx":24,"search_result_idx":null,"evidence_text":"","start_line_num":39,"end_line_num":47},"og_tags":null}},{"start_ix":64272,"end_ix":64284,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"The moats are in the GPT-wrappers","url":"https://interjectedfuture.com/the-moats-are-in-the-gpt-wrappers/#:~:text=This%20wordy%20name%20contains%20a,1","text":"This wordy name contains a simple idea: for any supply chain that delivers value from raw origins to the end-user, the amount of power each part of the supply chain can exert to capture this value (and hence make money) can never be created or destroyed\u2013it can only be shifted from one part of the supply chain to another. As one part of the supply chain is commoditized and modular, another part of the supply chain becomes the critical integration point. That critical integration point becomes the hard part of the supply chain. It's the part that captures the lion's share of the value. [1]","pub_date":null,"extra":{"cited_message_idx":24,"search_result_idx":null,"evidence_text":"","start_line_num":43,"end_line_num":50},"og_tags":null}},{"start_ix":64454,"end_ix":64466,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"The moats are in the GPT-wrappers","url":"https://interjectedfuture.com/the-moats-are-in-the-gpt-wrappers/#:~:text=Conservation%20of%20Modularity%20,the%20Law%20of%20Attractive%20Profits","text":"Conservation of Modularity (previously known as the Law of Attractive Profits)","pub_date":null,"extra":{"cited_message_idx":24,"search_result_idx":null,"evidence_text":"","start_line_num":41,"end_line_num":49},"og_tags":null}},{"start_ix":64466,"end_ix":64478,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"The moats are in the GPT-wrappers","url":"https://interjectedfuture.com/the-moats-are-in-the-gpt-wrappers/#:~:text=another,1","text":"another. As one part of the supply chain is commoditized and modular, another part of the supply chain becomes the critical integration point. That critical integration point becomes the hard part of the supply chain. It's the part that captures the lion's share of the value. [1]","pub_date":null,"extra":{"cited_message_idx":24,"search_result_idx":null,"evidence_text":"","start_line_num":47,"end_line_num":55},"og_tags":null}},{"start_ix":64736,"end_ix":64748,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"The moats are in the GPT-wrappers","url":"https://interjectedfuture.com/the-moats-are-in-the-gpt-wrappers/#:~:text=Despite%20the%20disdain%20for%20%22GPT,while%20operating%20within%20that%20layer","text":"Despite the disdain for \"GPT-wrappers,\" it's currently where the value is accruing in the supply chain of value to the end-user with LLM-driven apps. Unless something changes with the foundational model companies approach the market, the GPT-wrapper application layer is where the value accrues, hence where the money will be made. Furthermore, the application layer's moat will grow stronger due to the domain-specific contextual data and system evals that GPT-wrappers will create while operating within that layer.","pub_date":null,"extra":{"cited_message_idx":24,"search_result_idx":null,"evidence_text":"","start_line_num":25,"end_line_num":33},"og_tags":null}},{"start_ix":64748,"end_ix":64760,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"The moats are in the GPT-wrappers","url":"https://interjectedfuture.com/the-moats-are-in-the-gpt-wrappers/#:~:text=where%20the%20value%20is%20accruing,while%20operating%20within%20that%20layer","text":"where the value is accruing in the supply chain of value to the end-user with LLM-driven apps. Unless something changes with the foundational model companies approach the market, the GPT-wrapper application layer is where the value accrues, hence where the money will be made. Furthermore, the application layer's moat will grow stronger due to the domain-specific contextual data and system evals that GPT-wrappers will create while operating within that layer.","pub_date":null,"extra":{"cited_message_idx":24,"search_result_idx":null,"evidence_text":"","start_line_num":27,"end_line_num":33},"og_tags":null}},{"start_ix":64935,"end_ix":64947,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"The moats are in the GPT-wrappers","url":"https://interjectedfuture.com/the-moats-are-in-the-gpt-wrappers/#:~:text=Despite%20the%20disdain%20for%20%22GPT,while%20operating%20within%20that%20layer","text":"Despite the disdain for \"GPT-wrappers,\" it's currently where the value is accruing in the supply chain of value to the end-user with LLM-driven apps. Unless something changes with the foundational model companies approach the market, the GPT-wrapper application layer is where the value accrues, hence where the money will be made. Furthermore, the application layer's moat will grow stronger due to the domain-specific contextual data and system evals that GPT-wrappers will create while operating within that layer.","pub_date":null,"extra":{"cited_message_idx":24,"search_result_idx":null,"evidence_text":"","start_line_num":25,"end_line_num":33},"og_tags":null}},{"start_ix":65130,"end_ix":65142,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"The moats are in the GPT-wrappers","url":"https://interjectedfuture.com/the-moats-are-in-the-gpt-wrappers/#:~:text=Despite%20the%20disdain%20for%20%22GPT,while%20operating%20within%20that%20layer","text":"Despite the disdain for \"GPT-wrappers,\" it's currently where the value is accruing in the supply chain of value to the end-user with LLM-driven apps. Unless something changes with the foundational model companies approach the market, the GPT-wrapper application layer is where the value accrues, hence where the money will be made. Furthermore, the application layer's moat will grow stronger due to the domain-specific contextual data and system evals that GPT-wrappers will create while operating within that layer.","pub_date":null,"extra":{"cited_message_idx":24,"search_result_idx":null,"evidence_text":"","start_line_num":25,"end_line_num":33},"og_tags":null}},{"start_ix":65142,"end_ix":65152,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"The moats are in the GPT-wrappers","url":"https://interjectedfuture.com/the-moats-are-in-the-gpt-wrappers/#:~:text=LLM,specific%20contextual%20data%20and","text":"LLM-driven apps. Unless something changes with the foundational model companies approach the market, the GPT-wrapper application layer is where the value accrues, hence where the money will be made. Furthermore, the application layer's moat will grow stronger due to the domain-specific contextual data and","pub_date":null,"extra":{"cited_message_idx":25,"search_result_idx":null,"evidence_text":"","start_line_num":1,"end_line_num":4},"og_tags":null}},{"start_ix":70111,"end_ix":70122,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"A breakdown of OpenAI's revenue \u2014 EA Forum","url":"https://forum.effectivealtruism.org/posts/ksdSjT7wREu6vBhYE/a-breakdown-of-openai-s-revenue#:~:text=,that%20this%20may%20change%20abruptly","text":"* Sam Altman's surprising claim of $3.4B ARR on June 12 seems quite plausible, despite skepticism people raised at the time. * Apps (consumer and enterprise) are much more important to OpenAI than the API. * Consumers are much more important to OpenAI than enterprises, as reflected in all their recent demos, but the enterprise growth rate is so high that this may change abruptly.","pub_date":null,"extra":{"cited_message_idx":1,"search_result_idx":null,"evidence_text":"","start_line_num":61,"end_line_num":68},"og_tags":null}},{"start_ix":70393,"end_ix":70407,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=The%20basic%20idea%20is%20that%2C,to%20go%20for%20LLM%20apps","text":"The basic idea is that, with enough critical mass, users will stick to ChatGPT and more users will sign up for the ChatGPT Plus plan to access the GPT Store. And developers will stick to the platform where their assistants will be exposed to more users. The mass usage will also create free publicity for the company as more content will be published about ChatGPT, further establishing it as the defacto place to go for LLM apps.","pub_date":null,"extra":{"cited_message_idx":19,"search_result_idx":null,"evidence_text":"","start_line_num":227,"end_line_num":236},"og_tags":null}},{"start_ix":70407,"end_ix":70421,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=OpenAI%20is%20reinforcing%20the%20network,the%20stickiness%20of%20the%20product","text":"OpenAI is reinforcing the network effects with monetization. According to its website, in Q1 2024, \u201cUS builders will be paid based on user engagement with their GPTs.\u201d This means they will be incentivizing maximum engagement to improve the stickiness of the product.","pub_date":null,"extra":{"cited_message_idx":19,"search_result_idx":null,"evidence_text":"","start_line_num":235,"end_line_num":243},"og_tags":null}},{"start_ix":70515,"end_ix":70529,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=,January%2011%2C%202024","text":"> \u2014 will depue (@willdepue) January 11, 2024","pub_date":null,"extra":{"cited_message_idx":19,"search_result_idx":null,"evidence_text":"","start_line_num":253,"end_line_num":261},"og_tags":null}},{"start_ix":73720,"end_ix":73732,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Why OpenAI's $157B valuation misreads AI's future","url":"https://foundationcapital.com/why-openais-157b-valuation-misreads-ais-future/#:~:text=Why%20OpenAI%27s%20%24157B%20valuation%20misreads,As","text":"Why OpenAI's $157B valuation misreads AI's future What's more, OpenAI's massive infrastructure investments might not be building a moat\u2014they might just be the cost of staying in the race. As ...","pub_date":null,"extra":{"cited_message_idx":23,"search_result_idx":null,"evidence_text":"","start_line_num":39,"end_line_num":45},"og_tags":null}},{"start_ix":73732,"end_ix":73744,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Why OpenAI's $157B valuation misreads AI's future","url":"https://foundationcapital.com/why-openais-157b-valuation-misreads-ais-future/#:~:text=Why%20OpenAI%27s%20%24157B%20valuation%20misreads,As","text":"Why OpenAI's $157B valuation misreads AI's future What's more, OpenAI's massive infrastructure investments might not be building a moat\u2014they might just be the cost of staying in the race. As ...","pub_date":null,"extra":{"cited_message_idx":23,"search_result_idx":null,"evidence_text":"","start_line_num":39,"end_line_num":42},"og_tags":null}},{"start_ix":74132,"end_ix":74146,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=An%20important%20part%20of%20this,their%20own%20private%20GPT%20Store","text":"An important part of this strategy is creating network effects around ChatGPT, its flagship product. GPT Store, first announced in November, launched last week. It is the AI version of Apple\u2019s App Store, allowing users and developers to share their customized version of the LLM for others to use. Most GPTs are whimsical, but some of them will be very useful and improve productivity. OpenAI will also provide enterprise features, allowing organizations that sign up for the ChatGPT Team plan to have their own private GPT Store.","pub_date":null,"extra":{"cited_message_idx":19,"search_result_idx":null,"evidence_text":"","start_line_num":219,"end_line_num":228},"og_tags":null}},{"start_ix":74146,"end_ix":74160,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=The%20basic%20idea%20is%20that%2C,to%20go%20for%20LLM%20apps","text":"The basic idea is that, with enough critical mass, users will stick to ChatGPT and more users will sign up for the ChatGPT Plus plan to access the GPT Store. And developers will stick to the platform where their assistants will be exposed to more users. The mass usage will also create free publicity for the company as more content will be published about ChatGPT, further establishing it as the defacto place to go for LLM apps.","pub_date":null,"extra":{"cited_message_idx":19,"search_result_idx":null,"evidence_text":"","start_line_num":227,"end_line_num":236},"og_tags":null}},{"start_ix":76019,"end_ix":76033,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=To%20be%20fair%2C%20OpenAI%20still,art%20models","text":"To be fair, OpenAI still has an advantage in model performance. I still haven\u2019t seen any model that matches GPT-4. But several open-source models already match and outperform GPT-3.5. It is only a matter of time before they reach GPT-4 and other state-of-the-art models.","pub_date":null,"extra":{"cited_message_idx":18,"search_result_idx":null,"evidence_text":"","start_line_num":199,"end_line_num":207},"og_tags":null}},{"start_ix":76266,"end_ix":76278,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Google DeepMind jumps back into open source AI race with new model Gemma | VentureBeat","url":"https://venturebeat.com/ai/google-deepmind-debuts-gemma-open-models-offers-developer-alternative-to-gemini-api/#:~:text=Today%20Google%20DeepMind%20unveiled%20Gemma%2C,announced%20Gemini%20models","text":"Today Google DeepMind unveiled Gemma, its new 2B and 7B open source models built from the same research and technology used to create the company\u2019s recently-announced Gemini models.","pub_date":null,"extra":{"cited_message_idx":27,"search_result_idx":null,"evidence_text":"","start_line_num":83,"end_line_num":92},"og_tags":null}},{"start_ix":76278,"end_ix":76290,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Google DeepMind jumps back into open source AI race with new model Gemma | VentureBeat","url":"https://venturebeat.com/ai/google-deepmind-debuts-gemma-open-models-offers-developer-alternative-to-gemini-api/#:~:text=The%20Gemma%20models%20will%20be,new%20Responsible%20Generative%20AI%20toolkit","text":"The Gemma models will be released with pre-trained and instruction-tuned variants, Google DeepMind said in a blog post. The model weights will be released with a permissive commercial license, as well as a new Responsible Generative AI toolkit.","pub_date":null,"extra":{"cited_message_idx":27,"search_result_idx":null,"evidence_text":"","start_line_num":87,"end_line_num":95},"og_tags":null}},{"start_ix":76733,"end_ix":76744,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"A breakdown of OpenAI's revenue \u2014 EA Forum","url":"https://forum.effectivealtruism.org/posts/ksdSjT7wREu6vBhYE/a-breakdown-of-openai-s-revenue#:~:text=,that%20this%20may%20change%20abruptly","text":"* Sam Altman's surprising claim of $3.4B ARR on June 12 seems quite plausible, despite skepticism people raised at the time. * Apps (consumer and enterprise) are much more important to OpenAI than the API. * Consumers are much more important to OpenAI than enterprises, as reflected in all their recent demos, but the enterprise growth rate is so high that this may change abruptly.","pub_date":null,"extra":{"cited_message_idx":1,"search_result_idx":null,"evidence_text":"","start_line_num":61,"end_line_num":68},"og_tags":null}},{"start_ix":77967,"end_ix":77978,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"A breakdown of OpenAI's revenue \u2014 EA Forum","url":"https://forum.effectivealtruism.org/posts/ksdSjT7wREu6vBhYE/a-breakdown-of-openai-s-revenue#:~:text=We%20estimate%20that%2C%20as%20of,ARR%29%20of","text":"We estimate that, as of June 12, 2024, OpenAI has an annualized revenue (ARR) of:","pub_date":null,"extra":{"cited_message_idx":1,"search_result_idx":null,"evidence_text":"","start_line_num":25,"end_line_num":34},"og_tags":null}},{"start_ix":77978,"end_ix":77989,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"A breakdown of OpenAI's revenue \u2014 EA Forum","url":"https://forum.effectivealtruism.org/posts/ksdSjT7wREu6vBhYE/a-breakdown-of-openai-s-revenue#:~:text=,that%20this%20may%20change%20abruptly","text":"* Sam Altman's surprising claim of $3.4B ARR on June 12 seems quite plausible, despite skepticism people raised at the time. * Apps (consumer and enterprise) are much more important to OpenAI than the API. * Consumers are much more important to OpenAI than enterprises, as reflected in all their recent demos, but the enterprise growth rate is so high that this may change abruptly.","pub_date":null,"extra":{"cited_message_idx":1,"search_result_idx":null,"evidence_text":"","start_line_num":61,"end_line_num":68},"og_tags":null}},{"start_ix":78071,"end_ix":78085,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"SoftBank, OpenAI unveil Japan AI joint venture | Reuters","url":"https://www.reuters.com/technology/artificial-intelligence/softbank-openai-set-up-ai-japan-joint-venture-2025-02-03/#:~:text=Sign%20up%20here","text":"Sign up here.","pub_date":null,"extra":{"cited_message_idx":10,"search_result_idx":null,"evidence_text":"","start_line_num":180,"end_line_num":188},"og_tags":null}},{"start_ix":78085,"end_ix":78099,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"SoftBank, OpenAI unveil Japan AI joint venture | Reuters","url":"https://www.reuters.com/technology/artificial-intelligence/softbank-openai-set-up-ai-japan-joint-venture-2025-02-03/#:~:text=The%20Japanese%20investment%20giant%20will,technology%20across%20SoftBank%20group%20companies","text":"The Japanese investment giant will also pay $3 billion annually to use OpenAI's technology across SoftBank group companies.","pub_date":null,"extra":{"cited_message_idx":10,"search_result_idx":null,"evidence_text":"","start_line_num":182,"end_line_num":190},"og_tags":null}},{"start_ix":78210,"end_ix":78224,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Microsoft Announces Changes to OpenAI's Azure Exclusivity on New Cloud Capacity","url":"https://www.thurrott.com/a-i/316138/microsoft-announces-changes-to-openais-azure-exclusivity-on-new-cloud-capacity#:~:text=Back%20in%20October%2C%20a%20report,charged%20OpenAI%20for%20computing%20power","text":"Back in October, a report from the New York Times detailed how OpenAI had been trying to reduce its costs and find other cloud partners than Microsoft to support its development. The publication also revealed that Microsoft allowed the ChatGPT maker to sign a \u201croughly $10 billion\u201d cloud computing deal with Oracle and agreed to reduce how much it charged OpenAI for computing power.","pub_date":null,"extra":{"cited_message_idx":13,"search_result_idx":null,"evidence_text":"","start_line_num":143,"end_line_num":151},"og_tags":null}},{"start_ix":78224,"end_ix":78238,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Microsoft Announces Changes to OpenAI's Azure Exclusivity on New Cloud Capacity","url":"https://www.thurrott.com/a-i/316138/microsoft-announces-changes-to-openais-azure-exclusivity-on-new-cloud-capacity#:~:text=Microsoft%20announcing%20it%E2%80%99s%20no%20longer,%E2%80%9D","text":"Microsoft announcing it\u2019s no longer OpenAI\u2019s exclusive cloud provider comes right alongside OpenAI\u2019s Stargate Project announcement. As part of this new joint venture, OpenAI, SoftBank, Oracle, and MGX plan to \u201cinvest $500 billion over the next four years building new AI infrastructure for OpenAI in the United States.\u201d OpenAI said Project Stargate will be investing $100 billion into this new AI infrastructure \u201cimmediately,\u201d and the company also announced Arm, Microsoft, NVIDIA, and Oracle as \u201ckey initial technology partners.\u201d","pub_date":null,"extra":{"cited_message_idx":13,"search_result_idx":null,"evidence_text":"","start_line_num":149,"end_line_num":157},"og_tags":null}},{"start_ix":78343,"end_ix":78357,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=An%20important%20part%20of%20this,their%20own%20private%20GPT%20Store","text":"An important part of this strategy is creating network effects around ChatGPT, its flagship product. GPT Store, first announced in November, launched last week. It is the AI version of Apple\u2019s App Store, allowing users and developers to share their customized version of the LLM for others to use. Most GPTs are whimsical, but some of them will be very useful and improve productivity. OpenAI will also provide enterprise features, allowing organizations that sign up for the ChatGPT Team plan to have their own private GPT Store.","pub_date":null,"extra":{"cited_message_idx":19,"search_result_idx":null,"evidence_text":"","start_line_num":219,"end_line_num":228},"og_tags":null}},{"start_ix":78357,"end_ix":78371,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=,January%2011%2C%202024","text":"> \u2014 will depue (@willdepue) January 11, 2024","pub_date":null,"extra":{"cited_message_idx":19,"search_result_idx":null,"evidence_text":"","start_line_num":253,"end_line_num":261},"og_tags":null}},{"start_ix":78448,"end_ix":78460,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=,the%20team%20concluded","text":"* They then articulated five distinctive properties of such models: broader access, greater customizability, potential for local \"inference,\" inability to rescind model access once released and weak monitoring of how a model is being used. * Any attempt to impose conditions on users of open models are \"easy for malicious actors to ignore,\" the team concluded.","pub_date":null,"extra":{"cited_message_idx":22,"search_result_idx":null,"evidence_text":"","start_line_num":67,"end_line_num":75},"og_tags":null}},{"start_ix":78460,"end_ix":78472,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=The%20main%20benefits%20are%20distributing,accelerating%20science%20and%20enabling%20transparency","text":"The main benefits are distributing decision-making power, reducing market concentration, increasing innovation, accelerating science and enabling transparency.","pub_date":null,"extra":{"cited_message_idx":22,"search_result_idx":null,"evidence_text":"","start_line_num":73,"end_line_num":81},"og_tags":null}},{"start_ix":78560,"end_ix":78572,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"The moats are in the GPT-wrappers","url":"https://interjectedfuture.com/the-moats-are-in-the-gpt-wrappers/#:~:text=Despite%20the%20disdain%20for%20%22GPT,while%20operating%20within%20that%20layer","text":"Despite the disdain for \"GPT-wrappers,\" it's currently where the value is accruing in the supply chain of value to the end-user with LLM-driven apps. Unless something changes with the foundational model companies approach the market, the GPT-wrapper application layer is where the value accrues, hence where the money will be made. Furthermore, the application layer's moat will grow stronger due to the domain-specific contextual data and system evals that GPT-wrappers will create while operating within that layer.","pub_date":null,"extra":{"cited_message_idx":24,"search_result_idx":null,"evidence_text":"","start_line_num":25,"end_line_num":33},"og_tags":null}},{"start_ix":78572,"end_ix":78582,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"The moats are in the GPT-wrappers","url":"https://interjectedfuture.com/the-moats-are-in-the-gpt-wrappers/#:~:text=LLM,specific%20contextual%20data%20and","text":"LLM-driven apps. Unless something changes with the foundational model companies approach the market, the GPT-wrapper application layer is where the value accrues, hence where the money will be made. Furthermore, the application layer's moat will grow stronger due to the domain-specific contextual data and","pub_date":null,"extra":{"cited_message_idx":25,"search_result_idx":null,"evidence_text":"","start_line_num":1,"end_line_num":4},"og_tags":null}},{"start_ix":78700,"end_ix":78712,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"The AI Arms Race Intensifies: Anthropic v. OpenAI","url":"https://www.linkedin.com/pulse/ai-arms-race-intensifies-anthropics-multi-billion-demotte-kramer-igb2c#:~:text=Google%20Doubles%20Down%20on%20Anthropic","text":"Google Doubles Down on Anthropic","pub_date":null,"extra":{"cited_message_idx":20,"search_result_idx":null,"evidence_text":"","start_line_num":50,"end_line_num":58},"og_tags":null}},{"start_ix":78712,"end_ix":78724,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"The AI Arms Race Intensifies: Anthropic v. OpenAI","url":"https://www.linkedin.com/pulse/ai-arms-race-intensifies-anthropics-multi-billion-demotte-kramer-igb2c#:~:text=OpenAI%20Counters%20with%20Stargate%20Project","text":"OpenAI Counters with Stargate Project","pub_date":null,"extra":{"cited_message_idx":20,"search_result_idx":null,"evidence_text":"","start_line_num":80,"end_line_num":89},"og_tags":null}},{"start_ix":78812,"end_ix":78824,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Google DeepMind jumps back into open source AI race with new model Gemma | VentureBeat","url":"https://venturebeat.com/ai/google-deepmind-debuts-gemma-open-models-offers-developer-alternative-to-gemini-api/#:~:text=Today%20Google%20DeepMind%20unveiled%20Gemma%2C,announced%20Gemini%20models","text":"Today Google DeepMind unveiled Gemma, its new 2B and 7B open source models built from the same research and technology used to create the company\u2019s recently-announced Gemini models.","pub_date":null,"extra":{"cited_message_idx":27,"search_result_idx":null,"evidence_text":"","start_line_num":83,"end_line_num":92},"og_tags":null}},{"start_ix":78824,"end_ix":78836,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Google DeepMind jumps back into open source AI race with new model Gemma | VentureBeat","url":"https://venturebeat.com/ai/google-deepmind-debuts-gemma-open-models-offers-developer-alternative-to-gemini-api/#:~:text=The%20Gemma%20models%20will%20be,new%20Responsible%20Generative%20AI%20toolkit","text":"The Gemma models will be released with pre-trained and instruction-tuned variants, Google DeepMind said in a blog post. The model weights will be released with a permissive commercial license, as well as a new Responsible Generative AI toolkit.","pub_date":null,"extra":{"cited_message_idx":27,"search_result_idx":null,"evidence_text":"","start_line_num":87,"end_line_num":95},"og_tags":null}},{"start_ix":78925,"end_ix":78939,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=The%20prohibitive%20costs%20of%20training,models%20for%20building%20LLM%20applications","text":"The prohibitive costs of training and running LLMs itself was a moat that made them accessible to wealthy organizations. OpenAI used its first-mover advantage to establish itself as the baseline. GPT-3 and later ChatGPT and GPT-4 became the defacto go-to models for building LLM applications.","pub_date":null,"extra":{"cited_message_idx":18,"search_result_idx":null,"evidence_text":"","start_line_num":164,"end_line_num":173},"og_tags":null}},{"start_ix":78939,"end_ix":78953,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=While%20DeepMind%20did%20not%20open,3%E2%80%99s%20300%20billion%20tokens","text":"While DeepMind did not open-source Chinchilla, the training recipe triggered a new direction of research. In February Meta released Llama, a family of LLMs ranging from 7 to 65 billion parameters. Llama was trained on 1.4 trillion tokens as opposed to GPT-3\u2019s 300 billion tokens.","pub_date":null,"extra":{"cited_message_idx":18,"search_result_idx":null,"evidence_text":"","start_line_num":179,"end_line_num":187},"og_tags":null}},{"start_ix":79043,"end_ix":79055,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=,the%20team%20concluded","text":"* They then articulated five distinctive properties of such models: broader access, greater customizability, potential for local \"inference,\" inability to rescind model access once released and weak monitoring of how a model is being used. * Any attempt to impose conditions on users of open models are \"easy for malicious actors to ignore,\" the team concluded.","pub_date":null,"extra":{"cited_message_idx":22,"search_result_idx":null,"evidence_text":"","start_line_num":67,"end_line_num":75},"og_tags":null}},{"start_ix":79055,"end_ix":79067,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=rescind%20model%20access%20once%20released,the%20team%20concluded","text":"rescind model access once released and weak monitoring of how a model is being used. * Any attempt to impose conditions on users of open models are \"easy for malicious actors to ignore,\" the team concluded.","pub_date":null,"extra":{"cited_message_idx":22,"search_result_idx":null,"evidence_text":"","start_line_num":69,"end_line_num":77},"og_tags":null}}],"content_references":[{"matched_text":"\u30101\u2020L25-L32\u3011","start_idx":1436,"end_idx":1447,"alt":null,"type":"webpage_extended","title":"A breakdown of OpenAI's revenue \u2014 EA Forum","url":"https://forum.effectivealtruism.org/posts/ksdSjT7wREu6vBhYE/a-breakdown-of-openai-s-revenue#:~:text=We%20estimate%20that%2C%20as%20of,ARR%29%20of","pub_date":null,"snippet":"We estimate that, as of June 12, 2024, OpenAI has an annualized revenue (ARR) of:","attribution":"forum.effectivealtruism.org","icon_type":null},{"matched_text":"\u30101\u2020L27-L32\u3011","start_idx":1757,"end_idx":1768,"alt":null,"type":"webpage_extended","title":"A breakdown of OpenAI's revenue \u2014 EA Forum","url":"https://forum.effectivealtruism.org/posts/ksdSjT7wREu6vBhYE/a-breakdown-of-openai-s-revenue#:~:text=%241,from%20980k%20seats","pub_date":null,"snippet":"$1.9B for ChatGPT Plus (7.7M global subscribers), $714M from ChatGPT Enterprise (1.2M seats), $510M from the API, and $290M from ChatGPT Team (from 980k seats)","attribution":"forum.effectivealtruism.org","icon_type":null},{"matched_text":"\u30101\u2020L27-L32\u3011","start_idx":1852,"end_idx":1863,"alt":null,"type":"webpage_extended","title":"A breakdown of OpenAI's revenue \u2014 EA Forum","url":"https://forum.effectivealtruism.org/posts/ksdSjT7wREu6vBhYE/a-breakdown-of-openai-s-revenue#:~:text=%241,from%20980k%20seats","pub_date":null,"snippet":"$1.9B for ChatGPT Plus (7.7M global subscribers), $714M from ChatGPT Enterprise (1.2M seats), $510M from the API, and $290M from ChatGPT Team (from 980k seats)","attribution":"forum.effectivealtruism.org","icon_type":null},{"matched_text":"\u30101\u2020L27-L34\u3011","start_idx":2344,"end_idx":2355,"alt":null,"type":"webpage_extended","title":"A breakdown of OpenAI's revenue \u2014 EA Forum","url":"https://forum.effectivealtruism.org/posts/ksdSjT7wREu6vBhYE/a-breakdown-of-openai-s-revenue#:~:text=%241,from%20980k%20seats","pub_date":null,"snippet":"$1.9B for ChatGPT Plus (7.7M global subscribers), $714M from ChatGPT Enterprise (1.2M seats), $510M from the API, and $290M from ChatGPT Team (from 980k seats)","attribution":"forum.effectivealtruism.org","icon_type":null},{"matched_text":"\u301011\u2020L133-L140\u3011","start_idx":2594,"end_idx":2608,"alt":null,"type":"webpage_extended","title":"Microsoft Announces Changes to OpenAI's Azure Exclusivity on New Cloud Capacity","url":"https://www.thurrott.com/a-i/316138/microsoft-announces-changes-to-openais-azure-exclusivity-on-new-cloud-capacity#:~:text=%CE%94","pub_date":null,"snippet":"\u0394","attribution":"thurrott.com","icon_type":null},{"matched_text":"\u30101\u2020L61-L68\u3011","start_idx":2748,"end_idx":2759,"alt":null,"type":"webpage_extended","title":"A breakdown of OpenAI's revenue \u2014 EA Forum","url":"https://forum.effectivealtruism.org/posts/ksdSjT7wREu6vBhYE/a-breakdown-of-openai-s-revenue#:~:text=,that%20this%20may%20change%20abruptly","pub_date":null,"snippet":"* Sam Altman's surprising claim of $3.4B ARR on June 12 seems quite plausible, despite skepticism people raised at the time. * Apps (consumer and enterprise) are much more important to OpenAI than the API. * Consumers are much more important to OpenAI than enterprises, as reflected in all their recent demos, but the enterprise growth rate is so high that this may change abruptly.","attribution":"forum.effectivealtruism.org","icon_type":null},{"matched_text":"\u301020\u2020L99-L102\u3011","start_idx":3133,"end_idx":3146,"alt":null,"type":"webpage_extended","title":"The AI Arms Race Intensifies: Anthropic v. OpenAI","url":"https://www.linkedin.com/pulse/ai-arms-race-intensifies-anthropics-multi-billion-demotte-kramer-igb2c#:~:text=there%E2%80%99s%20every%20reason%20to%20believe,investors%20in%20the%20mix%20%E2%80%94","pub_date":null,"snippet":"there\u2019s every reason to believe the alliance between OpenAI and Microsoft will continue, but I would bet the exclusivity part of the original agreement might soon be renegotiated. Microsoft has invested a hefty $14 billion in OpenAI since 2019, but what\u2019s ahead with Stargate \u2014 and a new raft of investors in the mix \u2014","attribution":"linkedin.com","icon_type":null},{"matched_text":"\u301011\u2020L107-L115\u3011","start_idx":3362,"end_idx":3376,"alt":null,"type":"webpage_extended","title":"Microsoft Announces Changes to OpenAI's Azure Exclusivity on New Cloud Capacity","url":"https://www.thurrott.com/a-i/316138/microsoft-announces-changes-to-openais-azure-exclusivity-on-new-cloud-capacity#:~:text=Microsoft%E2%80%99s%20multi,to%20sell%20additional%20Azure%20capacity","pub_date":null,"snippet":"Microsoft\u2019s multi-year partnership with OpenAI is taking a new direction as the ChatGPT maker will no longer exclusively choose Microsoft Azure for new cloud capacity. While OpenAI will continue using Azure to run and train its products, the company will be free to use other cloud providers if Microsoft refuses to sell additional Azure capacity.","attribution":"thurrott.com","icon_type":null},{"matched_text":"\u301013\u2020L143-L151\u3011","start_idx":3376,"end_idx":3390,"alt":null,"type":"webpage_extended","title":"Microsoft Announces Changes to OpenAI's Azure Exclusivity on New Cloud Capacity","url":"https://www.thurrott.com/a-i/316138/microsoft-announces-changes-to-openais-azure-exclusivity-on-new-cloud-capacity#:~:text=Back%20in%20October%2C%20a%20report,charged%20OpenAI%20for%20computing%20power","pub_date":null,"snippet":"Back in October, a report from the New York Times detailed how OpenAI had been trying to reduce its costs and find other cloud partners than Microsoft to support its development. The publication also revealed that Microsoft allowed the ChatGPT maker to sign a \u201croughly $10 billion\u201d cloud computing deal with Oracle and agreed to reduce how much it charged OpenAI for computing power.","attribution":"thurrott.com","icon_type":null},{"matched_text":"\u30103\u2020L13-L17\u3011","start_idx":3720,"end_idx":3731,"alt":null,"type":"webpage_extended","title":"Microsoft's complex bet on OpenAI brings potential and uncertainty","url":"https://www.cnbc.com/2023/04/08/microsofts-complex-bet-on-openai-brings-potential-and-uncertainty.html#:~:text=Microsoft%27s%20complex%20bet%20on%20OpenAI,workloads%20pile%20up%20in%20Azure","pub_date":null,"snippet":"Microsoft's complex bet on OpenAI brings potential and uncertainty Microsoft's partnership with OpenAI could mean billions of dollars a year in new revenue as workloads pile up in Azure.","attribution":"cnbc.com","icon_type":null},{"matched_text":"\u30103\u2020L13-L20\u3011","start_idx":3823,"end_idx":3834,"alt":null,"type":"webpage_extended","title":"Microsoft's complex bet on OpenAI brings potential and uncertainty","url":"https://www.cnbc.com/2023/04/08/microsofts-complex-bet-on-openai-brings-potential-and-uncertainty.html#:~:text=Microsoft%27s%20complex%20bet%20on%20OpenAI,workloads%20pile%20up%20in%20Azure","pub_date":null,"snippet":"Microsoft's complex bet on OpenAI brings potential and uncertainty Microsoft's partnership with OpenAI could mean billions of dollars a year in new revenue as workloads pile up in Azure.","attribution":"cnbc.com","icon_type":null},{"matched_text":"\u301028\u2020L1-L9\u3011","start_idx":4131,"end_idx":4141,"alt":null,"type":"webpage_extended","title":"Bain & Company announces services alliance with OpenAI to help ...","url":"https://www.bain.com/about/media-center/press-releases/2023/bain--company-announces-services-alliance-with-openai-to-help-enterprise-clients-identify-and-realize-the-full-potential-and-maximum-value-of-ai/#:~:text=...%20www.bain.com%20%20The%20Coca,an%20inflection%20point%20and","pub_date":null,"snippet":"... www.bain.com  The Coca-Cola Company is the first company to engage with the new alliance, Bain also announced today. \u201cAI has reached an inflection point and ...","attribution":"bain.com","icon_type":null},{"matched_text":"\u301013\u2020L143-L151\u3011","start_idx":4702,"end_idx":4716,"alt":null,"type":"webpage_extended","title":"Microsoft Announces Changes to OpenAI's Azure Exclusivity on New Cloud Capacity","url":"https://www.thurrott.com/a-i/316138/microsoft-announces-changes-to-openais-azure-exclusivity-on-new-cloud-capacity#:~:text=Back%20in%20October%2C%20a%20report,charged%20OpenAI%20for%20computing%20power","pub_date":null,"snippet":"Back in October, a report from the New York Times detailed how OpenAI had been trying to reduce its costs and find other cloud partners than Microsoft to support its development. The publication also revealed that Microsoft allowed the ChatGPT maker to sign a \u201croughly $10 billion\u201d cloud computing deal with Oracle and agreed to reduce how much it charged OpenAI for computing power.","attribution":"thurrott.com","icon_type":null},{"matched_text":"\u30103\u2020L23-L27\u3011","start_idx":5543,"end_idx":5554,"alt":null,"type":"webpage_extended","title":"OpenAI AI model sales surpass microsoft! Annual revenue reaches ...","url":"https://www.moomoo.com/news/post/40076818/openai-ai-model-sales-surpass-microsoft-annual-revenue-reaches-1#:~:text=OpenAI%20AI%20model%20sales%20surpass,year%20later%2C%20or%20an","pub_date":null,"snippet":"OpenAI AI model sales surpass microsoft! Annual revenue reaches ... According to insiders, Microsoft executives expect Azure OpenAI Service to generate $2 billion in annualized revenue one year later, or an ...","attribution":"moomoo.com","icon_type":null},{"matched_text":"\u301011\u2020L133-L140\u3011","start_idx":5676,"end_idx":5690,"alt":null,"type":"webpage_extended","title":"Microsoft Announces Changes to OpenAI's Azure Exclusivity on New Cloud Capacity","url":"https://www.thurrott.com/a-i/316138/microsoft-announces-changes-to-openais-azure-exclusivity-on-new-cloud-capacity#:~:text=%CE%94","pub_date":null,"snippet":"\u0394","attribution":"thurrott.com","icon_type":null},{"matched_text":"\u30106\u2020L164-L173\u3011","start_idx":6217,"end_idx":6230,"alt":null,"type":"webpage_extended","title":"Jony Ive confirms he\u2019s working on a new device with OpenAI | The Verge","url":"https://www.theverge.com/2024/9/21/24250867/jony-ive-confirms-collaboration-openai-hardware#:~:text=Jony%20Ive%20has%20confirmed%20that,designer%20was%20first%20reported%20on","pub_date":null,"snippet":"Jony Ive has confirmed that he\u2019s working with OpenAI CEO Sam Altman on an AI hardware project. The confirmation came today as part of a profile of Ive in The New York Times, nearly a year after the possibility of a collaboration between Altman and the longtime Apple designer was first reported on.","attribution":"theverge.com","icon_type":null},{"matched_text":"\u30106\u2020L170-L179\u3011","start_idx":6397,"end_idx":6410,"alt":null,"type":"webpage_extended","title":"Jony Ive confirms he\u2019s working on a new device with OpenAI | The Verge","url":"https://www.theverge.com/2024/9/21/24250867/jony-ive-confirms-collaboration-openai-hardware#:~:text=There%20aren%E2%80%99t%20a%20lot%20of,1%20billion%20in%20the%20project","pub_date":null,"snippet":"There aren\u2019t a lot of details on the project. Ive reportedly met Altman through Brian Chesky, the CEO of Airbnb, and the venture is being funded by Ive and the Emerson Collective, Laurene Powell Jobs\u2019 company. The Times reports it could raise $1 billion in funding by the end of the year but makes no mention of Masayoshi Son, the SoftBank CEO rumored last year to have invested $1 billion in the project.","attribution":"theverge.com","icon_type":null},{"matched_text":"\u301010\u2020L172-L180\u3011","start_idx":6769,"end_idx":6783,"alt":null,"type":"webpage_extended","title":"SoftBank, OpenAI unveil Japan AI joint venture | Reuters","url":"https://www.reuters.com/technology/artificial-intelligence/softbank-openai-set-up-ai-japan-joint-venture-2025-02-03/#:~:text=TOKYO%2C%20Feb%203%20%28Reuters%29%20,intelligence%20services%20to%20corporate%20customers","pub_date":null,"snippet":"TOKYO, Feb 3 (Reuters) - SoftBank Group (9984.T) , opens new tab CEO Masayoshi Son on Monday said he has agreed with OpenAI CEO Sam Altman to set up a joint venture in Japan to offer artificial intelligence services to corporate customers.","attribution":"reuters.com","icon_type":null},{"matched_text":"\u301010\u2020L180-L188\u3011","start_idx":6914,"end_idx":6928,"alt":null,"type":"webpage_extended","title":"SoftBank, OpenAI unveil Japan AI joint venture | Reuters","url":"https://www.reuters.com/technology/artificial-intelligence/softbank-openai-set-up-ai-japan-joint-venture-2025-02-03/#:~:text=Sign%20up%20here","pub_date":null,"snippet":"Sign up here.","attribution":"reuters.com","icon_type":null},{"matched_text":"\u301010\u2020L182-L190\u3011","start_idx":7059,"end_idx":7073,"alt":null,"type":"webpage_extended","title":"SoftBank, OpenAI unveil Japan AI joint venture | Reuters","url":"https://www.reuters.com/technology/artificial-intelligence/softbank-openai-set-up-ai-japan-joint-venture-2025-02-03/#:~:text=The%20Japanese%20investment%20giant%20will,technology%20across%20SoftBank%20group%20companies","pub_date":null,"snippet":"The Japanese investment giant will also pay $3 billion annually to use OpenAI's technology across SoftBank group companies.","attribution":"reuters.com","icon_type":null},{"matched_text":"\u30101\u2020L61-L68\u3011","start_idx":7618,"end_idx":7629,"alt":null,"type":"webpage_extended","title":"A breakdown of OpenAI's revenue \u2014 EA Forum","url":"https://forum.effectivealtruism.org/posts/ksdSjT7wREu6vBhYE/a-breakdown-of-openai-s-revenue#:~:text=,that%20this%20may%20change%20abruptly","pub_date":null,"snippet":"* Sam Altman's surprising claim of $3.4B ARR on June 12 seems quite plausible, despite skepticism people raised at the time. * Apps (consumer and enterprise) are much more important to OpenAI than the API. * Consumers are much more important to OpenAI than enterprises, as reflected in all their recent demos, but the enterprise growth rate is so high that this may change abruptly.","attribution":"forum.effectivealtruism.org","icon_type":null},{"matched_text":"\u30101\u2020L59-L67\u3011","start_idx":7947,"end_idx":7958,"alt":null,"type":"webpage_extended","title":"A breakdown of OpenAI's revenue \u2014 EA Forum","url":"https://forum.effectivealtruism.org/posts/ksdSjT7wREu6vBhYE/a-breakdown-of-openai-s-revenue#:~:text=Overall%2C%20these%20numbers%20imply%20to,us%20that","pub_date":null,"snippet":"Overall, these numbers imply to us that:","attribution":"forum.effectivealtruism.org","icon_type":null},{"matched_text":"\u301018\u2020L158-L166\u3011","start_idx":8938,"end_idx":8952,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=When%20ChatGPT%20%20was%20released%2C,few%20companies%20could%20run%20them","pub_date":null,"snippet":"When ChatGPT  was released, the general perception was that models improved as they grew. With 175 billion parameters, GPT-3 required hundreds of gigabytes of GPU memory and  42 to train and run. A few open-source LLMs that were released in 2022 were so big and unwieldy that few companies could run them.","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u30103\u2020L13-L20\u3011","start_idx":9150,"end_idx":9161,"alt":null,"type":"webpage_extended","title":"Microsoft's complex bet on OpenAI brings potential and uncertainty","url":"https://www.cnbc.com/2023/04/08/microsofts-complex-bet-on-openai-brings-potential-and-uncertainty.html#:~:text=Microsoft%27s%20complex%20bet%20on%20OpenAI,workloads%20pile%20up%20in%20Azure","pub_date":null,"snippet":"Microsoft's complex bet on OpenAI brings potential and uncertainty Microsoft's partnership with OpenAI could mean billions of dollars a year in new revenue as workloads pile up in Azure.","attribution":"cnbc.com","icon_type":null},{"matched_text":"\u301013\u2020L143-L151\u3011","start_idx":9382,"end_idx":9396,"alt":null,"type":"webpage_extended","title":"Microsoft Announces Changes to OpenAI's Azure Exclusivity on New Cloud Capacity","url":"https://www.thurrott.com/a-i/316138/microsoft-announces-changes-to-openais-azure-exclusivity-on-new-cloud-capacity#:~:text=Back%20in%20October%2C%20a%20report,charged%20OpenAI%20for%20computing%20power","pub_date":null,"snippet":"Back in October, a report from the New York Times detailed how OpenAI had been trying to reduce its costs and find other cloud partners than Microsoft to support its development. The publication also revealed that Microsoft allowed the ChatGPT maker to sign a \u201croughly $10 billion\u201d cloud computing deal with Oracle and agreed to reduce how much it charged OpenAI for computing power.","attribution":"thurrott.com","icon_type":null},{"matched_text":"\u301011\u2020L107-L115\u3011","start_idx":9548,"end_idx":9562,"alt":null,"type":"webpage_extended","title":"Microsoft Announces Changes to OpenAI's Azure Exclusivity on New Cloud Capacity","url":"https://www.thurrott.com/a-i/316138/microsoft-announces-changes-to-openais-azure-exclusivity-on-new-cloud-capacity#:~:text=Microsoft%E2%80%99s%20multi,to%20sell%20additional%20Azure%20capacity","pub_date":null,"snippet":"Microsoft\u2019s multi-year partnership with OpenAI is taking a new direction as the ChatGPT maker will no longer exclusively choose Microsoft Azure for new cloud capacity. While OpenAI will continue using Azure to run and train its products, the company will be free to use other cloud providers if Microsoft refuses to sell additional Azure capacity.","attribution":"thurrott.com","icon_type":null},{"matched_text":"\u301013\u2020L143-L151\u3011","start_idx":9715,"end_idx":9729,"alt":null,"type":"webpage_extended","title":"Microsoft Announces Changes to OpenAI's Azure Exclusivity on New Cloud Capacity","url":"https://www.thurrott.com/a-i/316138/microsoft-announces-changes-to-openais-azure-exclusivity-on-new-cloud-capacity#:~:text=Back%20in%20October%2C%20a%20report,charged%20OpenAI%20for%20computing%20power","pub_date":null,"snippet":"Back in October, a report from the New York Times detailed how OpenAI had been trying to reduce its costs and find other cloud partners than Microsoft to support its development. The publication also revealed that Microsoft allowed the ChatGPT maker to sign a \u201croughly $10 billion\u201d cloud computing deal with Oracle and agreed to reduce how much it charged OpenAI for computing power.","attribution":"thurrott.com","icon_type":null},{"matched_text":"\u301013\u2020L149-L157\u3011","start_idx":9995,"end_idx":10009,"alt":null,"type":"webpage_extended","title":"Microsoft Announces Changes to OpenAI's Azure Exclusivity on New Cloud Capacity","url":"https://www.thurrott.com/a-i/316138/microsoft-announces-changes-to-openais-azure-exclusivity-on-new-cloud-capacity#:~:text=Microsoft%20announcing%20it%E2%80%99s%20no%20longer,%E2%80%9D","pub_date":null,"snippet":"Microsoft announcing it\u2019s no longer OpenAI\u2019s exclusive cloud provider comes right alongside OpenAI\u2019s Stargate Project announcement. As part of this new joint venture, OpenAI, SoftBank, Oracle, and MGX plan to \u201cinvest $500 billion over the next four years building new AI infrastructure for OpenAI in the United States.\u201d OpenAI said Project Stargate will be investing $100 billion into this new AI infrastructure \u201cimmediately,\u201d and the company also announced Arm, Microsoft, NVIDIA, and Oracle as \u201ckey initial technology partners.\u201d","attribution":"thurrott.com","icon_type":null},{"matched_text":"\u301013\u2020L149-L157\u3011","start_idx":10151,"end_idx":10165,"alt":null,"type":"webpage_extended","title":"Microsoft Announces Changes to OpenAI's Azure Exclusivity on New Cloud Capacity","url":"https://www.thurrott.com/a-i/316138/microsoft-announces-changes-to-openais-azure-exclusivity-on-new-cloud-capacity#:~:text=Microsoft%20announcing%20it%E2%80%99s%20no%20longer,%E2%80%9D","pub_date":null,"snippet":"Microsoft announcing it\u2019s no longer OpenAI\u2019s exclusive cloud provider comes right alongside OpenAI\u2019s Stargate Project announcement. As part of this new joint venture, OpenAI, SoftBank, Oracle, and MGX plan to \u201cinvest $500 billion over the next four years building new AI infrastructure for OpenAI in the United States.\u201d OpenAI said Project Stargate will be investing $100 billion into this new AI infrastructure \u201cimmediately,\u201d and the company also announced Arm, Microsoft, NVIDIA, and Oracle as \u201ckey initial technology partners.\u201d","attribution":"thurrott.com","icon_type":null},{"matched_text":"\u301010\u2020L199-L207\u3011","start_idx":10566,"end_idx":10580,"alt":null,"type":"webpage_extended","title":"SoftBank, OpenAI unveil Japan AI joint venture | Reuters","url":"https://www.reuters.com/technology/artificial-intelligence/softbank-openai-set-up-ai-japan-joint-venture-2025-02-03/#:~:text=,Altman%20said","pub_date":null,"snippet":"\"The world is going to just need so much compute,\" Altman said.","attribution":"reuters.com","icon_type":null},{"matched_text":"\u301011\u2020L107-L115\u3011","start_idx":10825,"end_idx":10839,"alt":null,"type":"webpage_extended","title":"Microsoft Announces Changes to OpenAI's Azure Exclusivity on New Cloud Capacity","url":"https://www.thurrott.com/a-i/316138/microsoft-announces-changes-to-openais-azure-exclusivity-on-new-cloud-capacity#:~:text=Microsoft%E2%80%99s%20multi,to%20sell%20additional%20Azure%20capacity","pub_date":null,"snippet":"Microsoft\u2019s multi-year partnership with OpenAI is taking a new direction as the ChatGPT maker will no longer exclusively choose Microsoft Azure for new cloud capacity. While OpenAI will continue using Azure to run and train its products, the company will be free to use other cloud providers if Microsoft refuses to sell additional Azure capacity.","attribution":"thurrott.com","icon_type":null},{"matched_text":"\u301018\u2020L172-L180\u3011","start_idx":11635,"end_idx":11649,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=However%2C%20a%20study%20by%20DeepMind,time%2C%20according%20to%20the%20researchers","pub_date":null,"snippet":"However, a study by DeepMind researchers in 2022 presented the idea that you did not need a huge model to achieve state-of-the-art results. The study, which became known as the Chinchilla paper, suggested that a small model trained on a very large dataset could match the performance of larger models. With 70 billion parameters, the Chinchilla model outperformed other state-of- the-art LLMs of the time, according to the researchers.","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u301018\u2020L178-L187\u3011","start_idx":11649,"end_idx":11663,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=While%20DeepMind%20did%20not%20open,3%E2%80%99s%20300%20billion%20tokens","pub_date":null,"snippet":"While DeepMind did not open-source Chinchilla, the training recipe triggered a new direction of research. In February Meta released Llama, a family of LLMs ranging from 7 to 65 billion parameters. Llama was trained on 1.4 trillion tokens as opposed to GPT-3\u2019s 300 billion tokens.","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u301029\u2020L1-L8\u3011","start_idx":13182,"end_idx":13192,"alt":null,"type":"webpage_extended","title":"Exclusive: OpenAI set to finalize first custom chip design this year","url":"https://www.reuters.com/technology/openai-set-finalize-first-custom-chip-design-this-year-2025-02-10/#:~:text=year%20www,commonly%20used%20systolic%20array","pub_date":null,"snippet":"year www.reuters.com  TSMC is manufacturing OpenAI's AI chip using its advanced 3-nanometer process technology. The chip features a commonly used systolic array ...","attribution":"reuters.com","icon_type":null},{"matched_text":"\u301029\u2020L19-L27\u3011","start_idx":13299,"end_idx":13311,"alt":null,"type":"webpage_extended","title":"OpenAI reportedly builds custom AI chips as it embraces AMD","url":"https://www.tomshardware.com/tech-industry/artificial-intelligence/openai-reportedly-builds-custom-ai-chips-as-it-embraces-amd-company-also-abandons-plans-to-build-its-own-fabs#:~:text=OpenAI%20reportedly%20builds%20custom%20AI,to%20produce%20it%20for%20TSMC","pub_date":null,"snippet":"OpenAI reportedly builds custom AI chips as it embraces AMD OpenAI is proceeding with the development of its first custom AI chip with Broadcom and expects to produce it for TSMC.","attribution":"tomshardware.com","icon_type":null},{"matched_text":"\u301029\u2020L39-L46\u3011","start_idx":13497,"end_idx":13509,"alt":null,"type":"webpage_extended","title":"OpenAI is reportedly getting closer to launching its in-house chip","url":"https://www.theverge.com/news/609421/openai-in-house-chip-development#:~:text=chip%20www,to%20a%20report%20from%20Reuters","pub_date":null,"snippet":"chip www.theverge.com  OpenAI remains on track to start producing its in-house AI chip next year, according to a report from Reuters.","attribution":"theverge.com","icon_type":null},{"matched_text":"\u301019\u2020L219-L228\u3011","start_idx":14483,"end_idx":14497,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=An%20important%20part%20of%20this,their%20own%20private%20GPT%20Store","pub_date":null,"snippet":"An important part of this strategy is creating network effects around ChatGPT, its flagship product. GPT Store, first announced in November, launched last week. It is the AI version of Apple\u2019s App Store, allowing users and developers to share their customized version of the LLM for others to use. Most GPTs are whimsical, but some of them will be very useful and improve productivity. OpenAI will also provide enterprise features, allowing organizations that sign up for the ChatGPT Team plan to have their own private GPT Store.","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u301019\u2020L235-L244\u3011","start_idx":14497,"end_idx":14511,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=OpenAI%20is%20reinforcing%20the%20network,the%20stickiness%20of%20the%20product","pub_date":null,"snippet":"OpenAI is reinforcing the network effects with monetization. According to its website, in Q1 2024, \u201cUS builders will be paid based on user engagement with their GPTs.\u201d This means they will be incentivizing maximum engagement to improve the stickiness of the product.","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u301019\u2020L227-L236\u3011","start_idx":14764,"end_idx":14778,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=The%20basic%20idea%20is%20that%2C,to%20go%20for%20LLM%20apps","pub_date":null,"snippet":"The basic idea is that, with enough critical mass, users will stick to ChatGPT and more users will sign up for the ChatGPT Plus plan to access the GPT Store. And developers will stick to the platform where their assistants will be exposed to more users. The mass usage will also create free publicity for the company as more content will be published about ChatGPT, further establishing it as the defacto place to go for LLM apps.","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u301019\u2020L239-L247\u3011","start_idx":14778,"end_idx":14792,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=But%20it%20will%20also%20have,bad%20things%20about%20social%20media","pub_date":null,"snippet":"But it will also have the adverse effect of replicating all the bad things about social media.","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u301019\u2020L233-L241\u3011","start_idx":14971,"end_idx":14985,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=defacto%20place%20to%20go%20for,LLM%20apps","pub_date":null,"snippet":"defacto place to go for LLM apps.","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u301019\u2020L235-L244\u3011","start_idx":14985,"end_idx":14999,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=OpenAI%20is%20reinforcing%20the%20network,the%20stickiness%20of%20the%20product","pub_date":null,"snippet":"OpenAI is reinforcing the network effects with monetization. According to its website, in Q1 2024, \u201cUS builders will be paid based on user engagement with their GPTs.\u201d This means they will be incentivizing maximum engagement to improve the stickiness of the product.","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u301019\u2020L243-L251\u3011","start_idx":15534,"end_idx":15548,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=At%20the%20same%20time%2C%20the,of%20the%20data%20collection%20program","pub_date":null,"snippet":"At the same time, the company will be reinforcing its data network effects to constantly improve its products. If you\u2019re on the free plan, OpenAI will collect your data and use it to further train its models. If you\u2019re on the Plus plan, your data will still be collected unless you opt out of the data collection program.","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u301019\u2020L255-L263\u3011","start_idx":15894,"end_idx":15908,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=Another%20important%20effort%20to%20increase,to%20catch%20up%20with%20ChatGPT","pub_date":null,"snippet":"Another important effort to increase switching costs is to reduce the costs of running ChatGPT. In a recent interview with Bill Gates, OpenAI CEO Sam Altman said that the company had managed to reduce the costs of running LLMs by a factor of 40. Reduced costs will enable OpenAI to launch more features for both the free and paid tiers of users as open-source LLMs continue to catch up with ChatGPT.","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u30100\u2020L0-L3\u3011","start_idx":17334,"end_idx":17343,"alt":null,"type":"webpage_extended","title":"OpenAI lost $5 billion in 2024 (and its losses are increasing)","url":"https://www.lesswrong.com/posts/CCQsQnCMWhJcCFY9x/openai-lost-usd5-billion-in-2024-and-its-losses-are#:~:text=OpenAI%20lost%20%245%20billion%20in,the%20region%20of%20%244%20billion","pub_date":null,"snippet":"OpenAI lost $5 billion in 2024 (and its losses are increasing) 2024 Revenue: According to reporting by The Information, OpenAI's revenue was likely somewhere in the region of $4 billion.","attribution":"lesswrong.com","icon_type":null},{"matched_text":"\u30100\u2020L1-L4\u3011","start_idx":17343,"end_idx":17352,"alt":null,"type":"webpage_extended","title":"OpenAI lost $5 billion in 2024 (and its losses are increasing)","url":"https://www.lesswrong.com/posts/CCQsQnCMWhJcCFY9x/openai-lost-usd5-billion-in-2024-and-its-losses-are#:~:text=increasing%29%20www,the%20region%20of%20%244%20billion","pub_date":null,"snippet":"increasing) www.lesswrong.com  2024 Revenue: According to reporting by The Information, OpenAI's revenue was likely somewhere in the region of $4 billion.","attribution":"lesswrong.com","icon_type":null},{"matched_text":"\u301018\u2020L158-L167\u3011","start_idx":18989,"end_idx":19003,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=When%20ChatGPT%20%20was%20released%2C,few%20companies%20could%20run%20them","pub_date":null,"snippet":"When ChatGPT  was released, the general perception was that models improved as they grew. With 175 billion parameters, GPT-3 required hundreds of gigabytes of GPU memory and  42 to train and run. A few open-source LLMs that were released in 2022 were so big and unwieldy that few companies could run them.","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u301018\u2020L179-L187\u3011","start_idx":19003,"end_idx":19017,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=While%20DeepMind%20did%20not%20open,3%E2%80%99s%20300%20billion%20tokens","pub_date":null,"snippet":"While DeepMind did not open-source Chinchilla, the training recipe triggered a new direction of research. In February Meta released Llama, a family of LLMs ranging from 7 to 65 billion parameters. Llama was trained on 1.4 trillion tokens as opposed to GPT-3\u2019s 300 billion tokens.","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u301027\u2020L83-L92\u3011","start_idx":21621,"end_idx":21633,"alt":null,"type":"webpage_extended","title":"Google DeepMind jumps back into open source AI race with new model Gemma | VentureBeat","url":"https://venturebeat.com/ai/google-deepmind-debuts-gemma-open-models-offers-developer-alternative-to-gemini-api/#:~:text=Today%20Google%20DeepMind%20unveiled%20Gemma%2C,announced%20Gemini%20models","pub_date":null,"snippet":"Today Google DeepMind unveiled Gemma, its new 2B and 7B open source models built from the same research and technology used to create the company\u2019s recently-announced Gemini models.","attribution":"venturebeat.com","icon_type":null},{"matched_text":"\u301027\u2020L87-L95\u3011","start_idx":21732,"end_idx":21744,"alt":null,"type":"webpage_extended","title":"Google DeepMind jumps back into open source AI race with new model Gemma | VentureBeat","url":"https://venturebeat.com/ai/google-deepmind-debuts-gemma-open-models-offers-developer-alternative-to-gemini-api/#:~:text=The%20Gemma%20models%20will%20be,new%20Responsible%20Generative%20AI%20toolkit","pub_date":null,"snippet":"The Gemma models will be released with pre-trained and instruction-tuned variants, Google DeepMind said in a blog post. The model weights will be released with a permissive commercial license, as well as a new Responsible Generative AI toolkit.","attribution":"venturebeat.com","icon_type":null},{"matched_text":"\u301026\u2020L37-L45\u3011","start_idx":22529,"end_idx":22541,"alt":null,"type":"webpage_extended","title":"Google DeepMind Open-Sources AlphaFold 3: A Game-Changer for ...","url":"https://www.geneonline.com/google-deepmind-open-sources-alphafold-3-a-game-changer-for-drug-discovery-and-biotech/#:~:text=Google%20DeepMind%20Open,of%20protein%20and%20molecular","pub_date":null,"snippet":"Google DeepMind Open-Sources AlphaFold 3: A Game-Changer for ... Google DeepMind's AlphaFold 3 promises to transform drug discovery and molecular biology with its advanced AI-powered predictions of protein and molecular ...","attribution":"geneonline.com","icon_type":null},{"matched_text":"\u301018\u2020L199-L207\u3011","start_idx":24220,"end_idx":24234,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=To%20be%20fair%2C%20OpenAI%20still,art%20models","pub_date":null,"snippet":"To be fair, OpenAI still has an advantage in model performance. I still haven\u2019t seen any model that matches GPT-4. But several open-source models already match and outperform GPT-3.5. It is only a matter of time before they reach GPT-4 and other state-of-the-art models.","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u301018\u2020L199-L207\u3011","start_idx":24371,"end_idx":24385,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=To%20be%20fair%2C%20OpenAI%20still,art%20models","pub_date":null,"snippet":"To be fair, OpenAI still has an advantage in model performance. I still haven\u2019t seen any model that matches GPT-4. But several open-source models already match and outperform GPT-3.5. It is only a matter of time before they reach GPT-4 and other state-of-the-art models.","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u301018\u2020L203-L211\u3011","start_idx":24385,"end_idx":24399,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=The%20open,as%20data%20ownership%20and%20privacy","pub_date":null,"snippet":"The open-source models took away the advantage of big tech and commoditized the market. As the costs of switching drop, more and more companies will be incentivized to move from GPT-4 to low-cost open-source models. Even if these models don\u2019t match GPT-4, most enterprises have specialized needs that can be met with a carefully fine-tuned model that has a fraction of the costs and matches other needs such as data ownership and privacy.","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u301018\u2020L199-L207\u3011","start_idx":24641,"end_idx":24655,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=To%20be%20fair%2C%20OpenAI%20still,art%20models","pub_date":null,"snippet":"To be fair, OpenAI still has an advantage in model performance. I still haven\u2019t seen any model that matches GPT-4. But several open-source models already match and outperform GPT-3.5. It is only a matter of time before they reach GPT-4 and other state-of-the-art models.","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u301018\u2020L203-L211\u3011","start_idx":24655,"end_idx":24669,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=The%20open,as%20data%20ownership%20and%20privacy","pub_date":null,"snippet":"The open-source models took away the advantage of big tech and commoditized the market. As the costs of switching drop, more and more companies will be incentivized to move from GPT-4 to low-cost open-source models. Even if these models don\u2019t match GPT-4, most enterprises have specialized needs that can be met with a carefully fine-tuned model that has a fraction of the costs and matches other needs such as data ownership and privacy.","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u301019\u2020L219-L228\u3011","start_idx":25178,"end_idx":25192,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=An%20important%20part%20of%20this,their%20own%20private%20GPT%20Store","pub_date":null,"snippet":"An important part of this strategy is creating network effects around ChatGPT, its flagship product. GPT Store, first announced in November, launched last week. It is the AI version of Apple\u2019s App Store, allowing users and developers to share their customized version of the LLM for others to use. Most GPTs are whimsical, but some of them will be very useful and improve productivity. OpenAI will also provide enterprise features, allowing organizations that sign up for the ChatGPT Team plan to have their own private GPT Store.","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u301019\u2020L231-L239\u3011","start_idx":25192,"end_idx":25206,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=to%20more%20users,to%20go%20for%20LLM%20apps","pub_date":null,"snippet":"to more users. The mass usage will also create free publicity for the company as more content will be published about ChatGPT, further establishing it as the defacto place to go for LLM apps.","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u301019\u2020L262-L269\u3011","start_idx":25556,"end_idx":25570,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=OpenAI%20is%20also%20preparing%20itself,to%20launch%20its%20vertical%20stack","pub_date":null,"snippet":"OpenAI is also preparing itself for the future. There are talks about OpenAI working on its own device, probably built around its LLM. This will give it the power of vertical integration, like Apple\u2019s iron grip on the iOS ecosystem. We are seeing what might be the beginning of a new paradigm shift in computing. As the field develops and new computing paradigms emerge, OpenAI will be ready to launch its vertical stack.","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u301019\u2020L253-L261\u3011","start_idx":25944,"end_idx":25958,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=,January%2011%2C%202024","pub_date":null,"snippet":"> \u2014 will depue (@willdepue) January 11, 2024","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u301020\u2020L50-L58\u3011","start_idx":27490,"end_idx":27502,"alt":null,"type":"webpage_extended","title":"The AI Arms Race Intensifies: Anthropic v. OpenAI","url":"https://www.linkedin.com/pulse/ai-arms-race-intensifies-anthropics-multi-billion-demotte-kramer-igb2c#:~:text=Google%20Doubles%20Down%20on%20Anthropic","pub_date":null,"snippet":"Google Doubles Down on Anthropic","attribution":"linkedin.com","icon_type":null},{"matched_text":"\u301020\u2020L60-L68\u3011","start_idx":27502,"end_idx":27514,"alt":null,"type":"webpage_extended","title":"The AI Arms Race Intensifies: Anthropic v. OpenAI","url":"https://www.linkedin.com/pulse/ai-arms-race-intensifies-anthropics-multi-billion-demotte-kramer-igb2c#:~:text=Amazon%27s%20Strategic%20Partnership%20Takes%20Shape","pub_date":null,"snippet":"Amazon's Strategic Partnership Takes Shape","attribution":"linkedin.com","icon_type":null},{"matched_text":"\u301016\u2020L25-L33\u3011","start_idx":29264,"end_idx":29276,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=What%20to%20know%20about%20Google,5%20Pro","pub_date":null,"snippet":"What to know about Google Gemini 2.5 Pro","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u301016\u2020L37-L45\u3011","start_idx":29276,"end_idx":29288,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=How%20OpenAI%20is%20building%20its,moat","pub_date":null,"snippet":"How OpenAI is building its moat","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u301027\u2020L83-L92\u3011","start_idx":30409,"end_idx":30421,"alt":null,"type":"webpage_extended","title":"Google DeepMind jumps back into open source AI race with new model Gemma | VentureBeat","url":"https://venturebeat.com/ai/google-deepmind-debuts-gemma-open-models-offers-developer-alternative-to-gemini-api/#:~:text=Today%20Google%20DeepMind%20unveiled%20Gemma%2C,announced%20Gemini%20models","pub_date":null,"snippet":"Today Google DeepMind unveiled Gemma, its new 2B and 7B open source models built from the same research and technology used to create the company\u2019s recently-announced Gemini models.","attribution":"venturebeat.com","icon_type":null},{"matched_text":"\u301027\u2020L87-L95\u3011","start_idx":30568,"end_idx":30580,"alt":null,"type":"webpage_extended","title":"Google DeepMind jumps back into open source AI race with new model Gemma | VentureBeat","url":"https://venturebeat.com/ai/google-deepmind-debuts-gemma-open-models-offers-developer-alternative-to-gemini-api/#:~:text=The%20Gemma%20models%20will%20be,new%20Responsible%20Generative%20AI%20toolkit","pub_date":null,"snippet":"The Gemma models will be released with pre-trained and instruction-tuned variants, Google DeepMind said in a blog post. The model weights will be released with a permissive commercial license, as well as a new Responsible Generative AI toolkit.","attribution":"venturebeat.com","icon_type":null},{"matched_text":"\u301027\u2020L99-L107\u3011","start_idx":30580,"end_idx":30593,"alt":null,"type":"webpage_extended","title":"Google DeepMind jumps back into open source AI race with new model Gemma | VentureBeat","url":"https://venturebeat.com/ai/google-deepmind-debuts-gemma-open-models-offers-developer-alternative-to-gemini-api/#:~:text=AI%20console,Kubernetes%20Engine","pub_date":null,"snippet":"AI console.cloud.google.com  and Google Kubernetes Engine.","attribution":"venturebeat.com","icon_type":null},{"matched_text":"\u301018\u2020L158-L167\u3011","start_idx":32168,"end_idx":32182,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=When%20ChatGPT%20%20was%20released%2C,few%20companies%20could%20run%20them","pub_date":null,"snippet":"When ChatGPT  was released, the general perception was that models improved as they grew. With 175 billion parameters, GPT-3 required hundreds of gigabytes of GPU memory and  42 to train and run. A few open-source LLMs that were released in 2022 were so big and unwieldy that few companies could run them.","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u301018\u2020L179-L187\u3011","start_idx":32182,"end_idx":32196,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=While%20DeepMind%20did%20not%20open,3%E2%80%99s%20300%20billion%20tokens","pub_date":null,"snippet":"While DeepMind did not open-source Chinchilla, the training recipe triggered a new direction of research. In February Meta released Llama, a family of LLMs ranging from 7 to 65 billion parameters. Llama was trained on 1.4 trillion tokens as opposed to GPT-3\u2019s 300 billion tokens.","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u301027\u2020L83-L92\u3011","start_idx":32522,"end_idx":32534,"alt":null,"type":"webpage_extended","title":"Google DeepMind jumps back into open source AI race with new model Gemma | VentureBeat","url":"https://venturebeat.com/ai/google-deepmind-debuts-gemma-open-models-offers-developer-alternative-to-gemini-api/#:~:text=Today%20Google%20DeepMind%20unveiled%20Gemma%2C,announced%20Gemini%20models","pub_date":null,"snippet":"Today Google DeepMind unveiled Gemma, its new 2B and 7B open source models built from the same research and technology used to create the company\u2019s recently-announced Gemini models.","attribution":"venturebeat.com","icon_type":null},{"matched_text":"\u301027\u2020L87-L95\u3011","start_idx":32534,"end_idx":32546,"alt":null,"type":"webpage_extended","title":"Google DeepMind jumps back into open source AI race with new model Gemma | VentureBeat","url":"https://venturebeat.com/ai/google-deepmind-debuts-gemma-open-models-offers-developer-alternative-to-gemini-api/#:~:text=The%20Gemma%20models%20will%20be,new%20Responsible%20Generative%20AI%20toolkit","pub_date":null,"snippet":"The Gemma models will be released with pre-trained and instruction-tuned variants, Google DeepMind said in a blog post. The model weights will be released with a permissive commercial license, as well as a new Responsible Generative AI toolkit.","attribution":"venturebeat.com","icon_type":null},{"matched_text":"\u301019\u2020L219-L228\u3011","start_idx":33478,"end_idx":33492,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=An%20important%20part%20of%20this,their%20own%20private%20GPT%20Store","pub_date":null,"snippet":"An important part of this strategy is creating network effects around ChatGPT, its flagship product. GPT Store, first announced in November, launched last week. It is the AI version of Apple\u2019s App Store, allowing users and developers to share their customized version of the LLM for others to use. Most GPTs are whimsical, but some of them will be very useful and improve productivity. OpenAI will also provide enterprise features, allowing organizations that sign up for the ChatGPT Team plan to have their own private GPT Store.","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u301027\u2020L87-L95\u3011","start_idx":34234,"end_idx":34246,"alt":null,"type":"webpage_extended","title":"Google DeepMind jumps back into open source AI race with new model Gemma | VentureBeat","url":"https://venturebeat.com/ai/google-deepmind-debuts-gemma-open-models-offers-developer-alternative-to-gemini-api/#:~:text=The%20Gemma%20models%20will%20be,new%20Responsible%20Generative%20AI%20toolkit","pub_date":null,"snippet":"The Gemma models will be released with pre-trained and instruction-tuned variants, Google DeepMind said in a blog post. The model weights will be released with a permissive commercial license, as well as a new Responsible Generative AI toolkit.","attribution":"venturebeat.com","icon_type":null},{"matched_text":"\u301019\u2020L262-L269\u3011","start_idx":34617,"end_idx":34631,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=OpenAI%20is%20also%20preparing%20itself,to%20launch%20its%20vertical%20stack","pub_date":null,"snippet":"OpenAI is also preparing itself for the future. There are talks about OpenAI working on its own device, probably built around its LLM. This will give it the power of vertical integration, like Apple\u2019s iron grip on the iOS ecosystem. We are seeing what might be the beginning of a new paradigm shift in computing. As the field develops and new computing paradigms emerge, OpenAI will be ready to launch its vertical stack.","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u30101\u2020L61-L68\u3011","start_idx":35377,"end_idx":35388,"alt":null,"type":"webpage_extended","title":"A breakdown of OpenAI's revenue \u2014 EA Forum","url":"https://forum.effectivealtruism.org/posts/ksdSjT7wREu6vBhYE/a-breakdown-of-openai-s-revenue#:~:text=,that%20this%20may%20change%20abruptly","pub_date":null,"snippet":"* Sam Altman's surprising claim of $3.4B ARR on June 12 seems quite plausible, despite skepticism people raised at the time. * Apps (consumer and enterprise) are much more important to OpenAI than the API. * Consumers are much more important to OpenAI than enterprises, as reflected in all their recent demos, but the enterprise growth rate is so high that this may change abruptly.","attribution":"forum.effectivealtruism.org","icon_type":null},{"matched_text":"\u301010\u2020L180-L188\u3011","start_idx":35494,"end_idx":35508,"alt":null,"type":"webpage_extended","title":"SoftBank, OpenAI unveil Japan AI joint venture | Reuters","url":"https://www.reuters.com/technology/artificial-intelligence/softbank-openai-set-up-ai-japan-joint-venture-2025-02-03/#:~:text=Sign%20up%20here","pub_date":null,"snippet":"Sign up here.","attribution":"reuters.com","icon_type":null},{"matched_text":"\u301020\u2020L60-L68\u3011","start_idx":35857,"end_idx":35869,"alt":null,"type":"webpage_extended","title":"The AI Arms Race Intensifies: Anthropic v. OpenAI","url":"https://www.linkedin.com/pulse/ai-arms-race-intensifies-anthropics-multi-billion-demotte-kramer-igb2c#:~:text=Amazon%27s%20Strategic%20Partnership%20Takes%20Shape","pub_date":null,"snippet":"Amazon's Strategic Partnership Takes Shape","attribution":"linkedin.com","icon_type":null},{"matched_text":"\u301020\u2020L73-L81\u3011","start_idx":35869,"end_idx":35881,"alt":null,"type":"webpage_extended","title":"The AI Arms Race Intensifies: Anthropic v. OpenAI","url":"https://www.linkedin.com/pulse/ai-arms-race-intensifies-anthropics-multi-billion-demotte-kramer-igb2c#:~:text=Anthropic%27s%20reported%20discussions%20with%20Lightspeed,stakes%20in%20leading%20AI%20companies","pub_date":null,"snippet":"Anthropic's reported discussions with Lightspeed Venture Partners for a $2 billion funding round at a $60 billion valuation mark a dramatic increase from its $18.5 billion valuation last February. This more than threefold jump in valuation within a year reflects both market confidence in Anthropic's technology and the premium investors are willing to pay for stakes in leading AI companies.","attribution":"linkedin.com","icon_type":null},{"matched_text":"\u301011\u2020L133-L140\u3011","start_idx":36566,"end_idx":36580,"alt":null,"type":"webpage_extended","title":"Microsoft Announces Changes to OpenAI's Azure Exclusivity on New Cloud Capacity","url":"https://www.thurrott.com/a-i/316138/microsoft-announces-changes-to-openais-azure-exclusivity-on-new-cloud-capacity#:~:text=%CE%94","pub_date":null,"snippet":"\u0394","attribution":"thurrott.com","icon_type":null},{"matched_text":"\u301010\u2020L180-L188\u3011","start_idx":36646,"end_idx":36660,"alt":null,"type":"webpage_extended","title":"SoftBank, OpenAI unveil Japan AI joint venture | Reuters","url":"https://www.reuters.com/technology/artificial-intelligence/softbank-openai-set-up-ai-japan-joint-venture-2025-02-03/#:~:text=Sign%20up%20here","pub_date":null,"snippet":"Sign up here.","attribution":"reuters.com","icon_type":null},{"matched_text":"\u301019\u2020L219-L228\u3011","start_idx":38147,"end_idx":38161,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=An%20important%20part%20of%20this,their%20own%20private%20GPT%20Store","pub_date":null,"snippet":"An important part of this strategy is creating network effects around ChatGPT, its flagship product. GPT Store, first announced in November, launched last week. It is the AI version of Apple\u2019s App Store, allowing users and developers to share their customized version of the LLM for others to use. Most GPTs are whimsical, but some of them will be very useful and improve productivity. OpenAI will also provide enterprise features, allowing organizations that sign up for the ChatGPT Team plan to have their own private GPT Store.","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u301019\u2020L227-L236\u3011","start_idx":38161,"end_idx":38175,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=The%20basic%20idea%20is%20that%2C,to%20go%20for%20LLM%20apps","pub_date":null,"snippet":"The basic idea is that, with enough critical mass, users will stick to ChatGPT and more users will sign up for the ChatGPT Plus plan to access the GPT Store. And developers will stick to the platform where their assistants will be exposed to more users. The mass usage will also create free publicity for the company as more content will be published about ChatGPT, further establishing it as the defacto place to go for LLM apps.","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u30101\u2020L61-L68\u3011","start_idx":38977,"end_idx":38988,"alt":null,"type":"webpage_extended","title":"A breakdown of OpenAI's revenue \u2014 EA Forum","url":"https://forum.effectivealtruism.org/posts/ksdSjT7wREu6vBhYE/a-breakdown-of-openai-s-revenue#:~:text=,that%20this%20may%20change%20abruptly","pub_date":null,"snippet":"* Sam Altman's surprising claim of $3.4B ARR on June 12 seems quite plausible, despite skepticism people raised at the time. * Apps (consumer and enterprise) are much more important to OpenAI than the API. * Consumers are much more important to OpenAI than enterprises, as reflected in all their recent demos, but the enterprise growth rate is so high that this may change abruptly.","attribution":"forum.effectivealtruism.org","icon_type":null},{"matched_text":"\u301020\u2020L71-L79\u3011","start_idx":39774,"end_idx":39786,"alt":null,"type":"webpage_extended","title":"The AI Arms Race Intensifies: Anthropic v. OpenAI","url":"https://www.linkedin.com/pulse/ai-arms-race-intensifies-anthropics-multi-billion-demotte-kramer-igb2c#:~:text=Valuation%20Surge%20Signals%20Market%20Confidence","pub_date":null,"snippet":"Valuation Surge Signals Market Confidence","attribution":"linkedin.com","icon_type":null},{"matched_text":"\u301018\u2020L188-L196\u3011","start_idx":43094,"end_idx":43108,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=Following%20the%20release%20of%20Llama%2C,create%20commercial%20products%20with%20them","pub_date":null,"snippet":"Following the release of Llama, a slew of other open-source models were released, each building on and improving the previous ones. Many came with licenses that allowed developers to create commercial products with them.","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u301018\u2020L192-L200\u3011","start_idx":43108,"end_idx":43122,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=Model%20compression%20%2C%20quantization%2C%20,LLMs%20running%20on%20edge%20devices","pub_date":null,"snippet":"Model compression , quantization,  46, and other techniques developed throughout the year made it increasingly convenient for companies to adopt open-source models for their applications. New programming frameworks, low-code/no-code tools, and online platforms made it easier to customize and run LLMs on company infrastructure. 2024 already promises innovations such as high-performance LLMs running on edge devices.","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u301022\u2020L57-L65\u3011","start_idx":44811,"end_idx":44823,"alt":null,"type":"webpage_extended","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=,due%20to%20their%20greater%20transparency","pub_date":null,"snippet":"* Stanford used the White House definition of open foundation models as those with \"widely available model weights.\" * Government reactions to the rise of open models have ranged from alarm in the White House over bioterrorism threats, to Beijing blacklisting certain types of generative AI training data and the EU offering regulatory exemptions to open models due to their greater transparency.","attribution":"axios.com","icon_type":null},{"matched_text":"\u301022\u2020L59-L67\u3011","start_idx":44823,"end_idx":44835,"alt":null,"type":"webpage_extended","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=,due%20to%20their%20greater%20transparency","pub_date":null,"snippet":"* Government reactions to the rise of open models have ranged from alarm in the White House over bioterrorism threats, to Beijing blacklisting certain types of generative AI training data and the EU offering regulatory exemptions to open models due to their greater transparency.","attribution":"axios.com","icon_type":null},{"matched_text":"\u301022\u2020L67-L75\u3011","start_idx":45344,"end_idx":45356,"alt":null,"type":"webpage_extended","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=,the%20team%20concluded","pub_date":null,"snippet":"* They then articulated five distinctive properties of such models: broader access, greater customizability, potential for local \"inference,\" inability to rescind model access once released and weak monitoring of how a model is being used. * Any attempt to impose conditions on users of open models are \"easy for malicious actors to ignore,\" the team concluded.","attribution":"axios.com","icon_type":null},{"matched_text":"\u301022\u2020L69-L73\u3011","start_idx":45356,"end_idx":45368,"alt":null,"type":"webpage_extended","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=rescind%20model%20access%20once%20released,the%20team%20concluded","pub_date":null,"snippet":"rescind model access once released and weak monitoring of how a model is being used. * Any attempt to impose conditions on users of open models are \"easy for malicious actors to ignore,\" the team concluded.","attribution":"axios.com","icon_type":null},{"matched_text":"\u301022\u2020L67-L75\u3011","start_idx":45497,"end_idx":45509,"alt":null,"type":"webpage_extended","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=,the%20team%20concluded","pub_date":null,"snippet":"* They then articulated five distinctive properties of such models: broader access, greater customizability, potential for local \"inference,\" inability to rescind model access once released and weak monitoring of how a model is being used. * Any attempt to impose conditions on users of open models are \"easy for malicious actors to ignore,\" the team concluded.","attribution":"axios.com","icon_type":null},{"matched_text":"\u301022\u2020L57-L65\u3011","start_idx":47888,"end_idx":47900,"alt":null,"type":"webpage_extended","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=,due%20to%20their%20greater%20transparency","pub_date":null,"snippet":"* Stanford used the White House definition of open foundation models as those with \"widely available model weights.\" * Government reactions to the rise of open models have ranged from alarm in the White House over bioterrorism threats, to Beijing blacklisting certain types of generative AI training data and the EU offering regulatory exemptions to open models due to their greater transparency.","attribution":"axios.com","icon_type":null},{"matched_text":"\u301022\u2020L59-L67\u3011","start_idx":47900,"end_idx":47912,"alt":null,"type":"webpage_extended","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=,due%20to%20their%20greater%20transparency","pub_date":null,"snippet":"* Government reactions to the rise of open models have ranged from alarm in the White House over bioterrorism threats, to Beijing blacklisting certain types of generative AI training data and the EU offering regulatory exemptions to open models due to their greater transparency.","attribution":"axios.com","icon_type":null},{"matched_text":"\u301018\u2020L188-L196\u3011","start_idx":48714,"end_idx":48728,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=Following%20the%20release%20of%20Llama%2C,create%20commercial%20products%20with%20them","pub_date":null,"snippet":"Following the release of Llama, a slew of other open-source models were released, each building on and improving the previous ones. Many came with licenses that allowed developers to create commercial products with them.","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u301022\u2020L69-L77\u3011","start_idx":48919,"end_idx":48931,"alt":null,"type":"webpage_extended","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=rescind%20model%20access%20once%20released,the%20team%20concluded","pub_date":null,"snippet":"rescind model access once released and weak monitoring of how a model is being used. * Any attempt to impose conditions on users of open models are \"easy for malicious actors to ignore,\" the team concluded.","attribution":"axios.com","icon_type":null},{"matched_text":"\u301021\u2020L7-L15\u3011","start_idx":50236,"end_idx":50247,"alt":null,"type":"webpage_extended","title":"On the Societal Impact of Open Foundation Models | Stanford HAI","url":"https://hai.stanford.edu/news/societal-impact-open-foundation-models#:~:text=HAI%20hai,power%2C%20and%20enabling%20scientific%20research","pub_date":null,"snippet":"HAI hai.stanford.edu  We analyze the benefits of open foundation models such as transparency, distribution of power, and enabling scientific research.","attribution":"hai.stanford.edu","icon_type":null},{"matched_text":"\u301022\u2020L73-L81\u3011","start_idx":50247,"end_idx":50259,"alt":null,"type":"webpage_extended","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=The%20main%20benefits%20are%20distributing,accelerating%20science%20and%20enabling%20transparency","pub_date":null,"snippet":"The main benefits are distributing decision-making power, reducing market concentration, increasing innovation, accelerating science and enabling transparency.","attribution":"axios.com","icon_type":null},{"matched_text":"\u301022\u2020L57-L65\u3011","start_idx":50379,"end_idx":50391,"alt":null,"type":"webpage_extended","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=,due%20to%20their%20greater%20transparency","pub_date":null,"snippet":"* Stanford used the White House definition of open foundation models as those with \"widely available model weights.\" * Government reactions to the rise of open models have ranged from alarm in the White House over bioterrorism threats, to Beijing blacklisting certain types of generative AI training data and the EU offering regulatory exemptions to open models due to their greater transparency.","attribution":"axios.com","icon_type":null},{"matched_text":"\u301022\u2020L59-L67\u3011","start_idx":50391,"end_idx":50403,"alt":null,"type":"webpage_extended","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=,due%20to%20their%20greater%20transparency","pub_date":null,"snippet":"* Government reactions to the rise of open models have ranged from alarm in the White House over bioterrorism threats, to Beijing blacklisting certain types of generative AI training data and the EU offering regulatory exemptions to open models due to their greater transparency.","attribution":"axios.com","icon_type":null},{"matched_text":"\u301018\u2020L188-L196\u3011","start_idx":51473,"end_idx":51487,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=Following%20the%20release%20of%20Llama%2C,create%20commercial%20products%20with%20them","pub_date":null,"snippet":"Following the release of Llama, a slew of other open-source models were released, each building on and improving the previous ones. Many came with licenses that allowed developers to create commercial products with them.","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u301018\u2020L192-L200\u3011","start_idx":51487,"end_idx":51501,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=Model%20compression%20%2C%20quantization%2C%20,LLMs%20running%20on%20edge%20devices","pub_date":null,"snippet":"Model compression , quantization,  46, and other techniques developed throughout the year made it increasingly convenient for companies to adopt open-source models for their applications. New programming frameworks, low-code/no-code tools, and online platforms made it easier to customize and run LLMs on company infrastructure. 2024 already promises innovations such as high-performance LLMs running on edge devices.","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u301017\u2020L23-L31\u3011","start_idx":53886,"end_idx":53898,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=match%20at%20L141%20GPT,the%20market%20of%20private%20LLMs","pub_date":null,"snippet":"match at L141 GPT-4. The main point of the memo was that neither Google nor OpenAI have moats and eventually, open-source models will conquer the market of private LLMs.","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u301017\u2020L25-L33\u3011","start_idx":53898,"end_idx":53910,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=GPT,the%20market%20of%20private%20LLMs","pub_date":null,"snippet":"GPT-4. The main point of the memo was that neither Google nor OpenAI have moats and eventually, open-source models will conquer the market of private LLMs.","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u301018\u2020L199-L207\u3011","start_idx":54069,"end_idx":54083,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=To%20be%20fair%2C%20OpenAI%20still,art%20models","pub_date":null,"snippet":"To be fair, OpenAI still has an advantage in model performance. I still haven\u2019t seen any model that matches GPT-4. But several open-source models already match and outperform GPT-3.5. It is only a matter of time before they reach GPT-4 and other state-of-the-art models.","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u301010\u2020L195-L203\u3011","start_idx":57886,"end_idx":57900,"alt":null,"type":"webpage_extended","title":"SoftBank, OpenAI unveil Japan AI joint venture | Reuters","url":"https://www.reuters.com/technology/artificial-intelligence/softbank-openai-set-up-ai-japan-joint-venture-2025-02-03/#:~:text=China%27s%20DeepSeek%20has%20caused%20investors,companies","pub_date":null,"snippet":"China's DeepSeek has caused investors to question the billions being poured into AI technology with a model that appears to rival the capabilities of leading U.S. companies.","attribution":"reuters.com","icon_type":null},{"matched_text":"\u301022\u2020L67-L75\u3011","start_idx":59349,"end_idx":59361,"alt":null,"type":"webpage_extended","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=,the%20team%20concluded","pub_date":null,"snippet":"* They then articulated five distinctive properties of such models: broader access, greater customizability, potential for local \"inference,\" inability to rescind model access once released and weak monitoring of how a model is being used. * Any attempt to impose conditions on users of open models are \"easy for malicious actors to ignore,\" the team concluded.","attribution":"axios.com","icon_type":null},{"matched_text":"\u301022\u2020L69-L77\u3011","start_idx":59361,"end_idx":59373,"alt":null,"type":"webpage_extended","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=rescind%20model%20access%20once%20released,the%20team%20concluded","pub_date":null,"snippet":"rescind model access once released and weak monitoring of how a model is being used. * Any attempt to impose conditions on users of open models are \"easy for malicious actors to ignore,\" the team concluded.","attribution":"axios.com","icon_type":null},{"matched_text":"\u301022\u2020L67-L75\u3011","start_idx":59488,"end_idx":59500,"alt":null,"type":"webpage_extended","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=,the%20team%20concluded","pub_date":null,"snippet":"* They then articulated five distinctive properties of such models: broader access, greater customizability, potential for local \"inference,\" inability to rescind model access once released and weak monitoring of how a model is being used. * Any attempt to impose conditions on users of open models are \"easy for malicious actors to ignore,\" the team concluded.","attribution":"axios.com","icon_type":null},{"matched_text":"\u301022\u2020L69-L73\u3011","start_idx":59500,"end_idx":59512,"alt":null,"type":"webpage_extended","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=rescind%20model%20access%20once%20released,the%20team%20concluded","pub_date":null,"snippet":"rescind model access once released and weak monitoring of how a model is being used. * Any attempt to impose conditions on users of open models are \"easy for malicious actors to ignore,\" the team concluded.","attribution":"axios.com","icon_type":null},{"matched_text":"\u301022\u2020L73-L81\u3011","start_idx":63030,"end_idx":63042,"alt":null,"type":"webpage_extended","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=The%20main%20benefits%20are%20distributing,accelerating%20science%20and%20enabling%20transparency","pub_date":null,"snippet":"The main benefits are distributing decision-making power, reducing market concentration, increasing innovation, accelerating science and enabling transparency.","attribution":"axios.com","icon_type":null},{"matched_text":"\u301022\u2020L75-L83\u3011","start_idx":63042,"end_idx":63054,"alt":null,"type":"webpage_extended","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=concentration%2C%20increasing%20innovation%2C%20accelerating%20science,and%20enabling%20transparency","pub_date":null,"snippet":"concentration, increasing innovation, accelerating science and enabling transparency.","attribution":"axios.com","icon_type":null},{"matched_text":"\u301022\u2020L81-L89\u3011","start_idx":63221,"end_idx":63233,"alt":null,"type":"webpage_extended","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=Threat%20level%3A%20The%20researchers%20argue,all%20existed%20before%20generative%20AI","pub_date":null,"snippet":"Threat level: The researchers argue that there often isn't proof that theoretical risks have materialized and that risks such as disinformation, scams and bioterrorism all existed before generative AI.","attribution":"axios.com","icon_type":null},{"matched_text":"\u301022\u2020L73-L81\u3011","start_idx":63340,"end_idx":63352,"alt":null,"type":"webpage_extended","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=The%20main%20benefits%20are%20distributing,accelerating%20science%20and%20enabling%20transparency","pub_date":null,"snippet":"The main benefits are distributing decision-making power, reducing market concentration, increasing innovation, accelerating science and enabling transparency.","attribution":"axios.com","icon_type":null},{"matched_text":"\u301022\u2020L75-L83\u3011","start_idx":63352,"end_idx":63364,"alt":null,"type":"webpage_extended","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=concentration%2C%20increasing%20innovation%2C%20accelerating%20science,and%20enabling%20transparency","pub_date":null,"snippet":"concentration, increasing innovation, accelerating science and enabling transparency.","attribution":"axios.com","icon_type":null},{"matched_text":"\u301024\u2020L39-L47\u3011","start_idx":64260,"end_idx":64272,"alt":null,"type":"webpage_extended","title":"The moats are in the GPT-wrappers","url":"https://interjectedfuture.com/the-moats-are-in-the-gpt-wrappers/#:~:text=technology%29%20and%20the%20Job,the%20Law%20of%20Attractive%20Profits","pub_date":null,"snippet":"technology) and the Job-to-be-done (how to view what value means to customers). But he has a less well-known framework called the Law of Conservation of Modularity (previously known as the Law of Attractive Profits)","attribution":"interjectedfuture.com","icon_type":null},{"matched_text":"\u301024\u2020L43-L50\u3011","start_idx":64272,"end_idx":64284,"alt":null,"type":"webpage_extended","title":"The moats are in the GPT-wrappers","url":"https://interjectedfuture.com/the-moats-are-in-the-gpt-wrappers/#:~:text=This%20wordy%20name%20contains%20a,1","pub_date":null,"snippet":"This wordy name contains a simple idea: for any supply chain that delivers value from raw origins to the end-user, the amount of power each part of the supply chain can exert to capture this value (and hence make money) can never be created or destroyed\u2013it can only be shifted from one part of the supply chain to another. As one part of the supply chain is commoditized and modular, another part of the supply chain becomes the critical integration point. That critical integration point becomes the hard part of the supply chain. It's the part that captures the lion's share of the value. [1]","attribution":"interjectedfuture.com","icon_type":null},{"matched_text":"\u301024\u2020L41-L49\u3011","start_idx":64454,"end_idx":64466,"alt":null,"type":"webpage_extended","title":"The moats are in the GPT-wrappers","url":"https://interjectedfuture.com/the-moats-are-in-the-gpt-wrappers/#:~:text=Conservation%20of%20Modularity%20,the%20Law%20of%20Attractive%20Profits","pub_date":null,"snippet":"Conservation of Modularity (previously known as the Law of Attractive Profits)","attribution":"interjectedfuture.com","icon_type":null},{"matched_text":"\u301024\u2020L47-L55\u3011","start_idx":64466,"end_idx":64478,"alt":null,"type":"webpage_extended","title":"The moats are in the GPT-wrappers","url":"https://interjectedfuture.com/the-moats-are-in-the-gpt-wrappers/#:~:text=another,1","pub_date":null,"snippet":"another. As one part of the supply chain is commoditized and modular, another part of the supply chain becomes the critical integration point. That critical integration point becomes the hard part of the supply chain. It's the part that captures the lion's share of the value. [1]","attribution":"interjectedfuture.com","icon_type":null},{"matched_text":"\u301024\u2020L25-L33\u3011","start_idx":64736,"end_idx":64748,"alt":null,"type":"webpage_extended","title":"The moats are in the GPT-wrappers","url":"https://interjectedfuture.com/the-moats-are-in-the-gpt-wrappers/#:~:text=Despite%20the%20disdain%20for%20%22GPT,while%20operating%20within%20that%20layer","pub_date":null,"snippet":"Despite the disdain for \"GPT-wrappers,\" it's currently where the value is accruing in the supply chain of value to the end-user with LLM-driven apps. Unless something changes with the foundational model companies approach the market, the GPT-wrapper application layer is where the value accrues, hence where the money will be made. Furthermore, the application layer's moat will grow stronger due to the domain-specific contextual data and system evals that GPT-wrappers will create while operating within that layer.","attribution":"interjectedfuture.com","icon_type":null},{"matched_text":"\u301024\u2020L27-L33\u3011","start_idx":64748,"end_idx":64760,"alt":null,"type":"webpage_extended","title":"The moats are in the GPT-wrappers","url":"https://interjectedfuture.com/the-moats-are-in-the-gpt-wrappers/#:~:text=where%20the%20value%20is%20accruing,while%20operating%20within%20that%20layer","pub_date":null,"snippet":"where the value is accruing in the supply chain of value to the end-user with LLM-driven apps. Unless something changes with the foundational model companies approach the market, the GPT-wrapper application layer is where the value accrues, hence where the money will be made. Furthermore, the application layer's moat will grow stronger due to the domain-specific contextual data and system evals that GPT-wrappers will create while operating within that layer.","attribution":"interjectedfuture.com","icon_type":null},{"matched_text":"\u301024\u2020L25-L33\u3011","start_idx":64935,"end_idx":64947,"alt":null,"type":"webpage_extended","title":"The moats are in the GPT-wrappers","url":"https://interjectedfuture.com/the-moats-are-in-the-gpt-wrappers/#:~:text=Despite%20the%20disdain%20for%20%22GPT,while%20operating%20within%20that%20layer","pub_date":null,"snippet":"Despite the disdain for \"GPT-wrappers,\" it's currently where the value is accruing in the supply chain of value to the end-user with LLM-driven apps. Unless something changes with the foundational model companies approach the market, the GPT-wrapper application layer is where the value accrues, hence where the money will be made. Furthermore, the application layer's moat will grow stronger due to the domain-specific contextual data and system evals that GPT-wrappers will create while operating within that layer.","attribution":"interjectedfuture.com","icon_type":null},{"matched_text":"\u301024\u2020L25-L33\u3011","start_idx":65130,"end_idx":65142,"alt":null,"type":"webpage_extended","title":"The moats are in the GPT-wrappers","url":"https://interjectedfuture.com/the-moats-are-in-the-gpt-wrappers/#:~:text=Despite%20the%20disdain%20for%20%22GPT,while%20operating%20within%20that%20layer","pub_date":null,"snippet":"Despite the disdain for \"GPT-wrappers,\" it's currently where the value is accruing in the supply chain of value to the end-user with LLM-driven apps. Unless something changes with the foundational model companies approach the market, the GPT-wrapper application layer is where the value accrues, hence where the money will be made. Furthermore, the application layer's moat will grow stronger due to the domain-specific contextual data and system evals that GPT-wrappers will create while operating within that layer.","attribution":"interjectedfuture.com","icon_type":null},{"matched_text":"\u301025\u2020L1-L4\u3011","start_idx":65142,"end_idx":65152,"alt":null,"type":"webpage_extended","title":"The moats are in the GPT-wrappers","url":"https://interjectedfuture.com/the-moats-are-in-the-gpt-wrappers/#:~:text=LLM,specific%20contextual%20data%20and","pub_date":null,"snippet":"LLM-driven apps. Unless something changes with the foundational model companies approach the market, the GPT-wrapper application layer is where the value accrues, hence where the money will be made. Furthermore, the application layer's moat will grow stronger due to the domain-specific contextual data and","attribution":"interjectedfuture.com","icon_type":null},{"matched_text":"\u30101\u2020L61-L68\u3011","start_idx":70111,"end_idx":70122,"alt":null,"type":"webpage_extended","title":"A breakdown of OpenAI's revenue \u2014 EA Forum","url":"https://forum.effectivealtruism.org/posts/ksdSjT7wREu6vBhYE/a-breakdown-of-openai-s-revenue#:~:text=,that%20this%20may%20change%20abruptly","pub_date":null,"snippet":"* Sam Altman's surprising claim of $3.4B ARR on June 12 seems quite plausible, despite skepticism people raised at the time. * Apps (consumer and enterprise) are much more important to OpenAI than the API. * Consumers are much more important to OpenAI than enterprises, as reflected in all their recent demos, but the enterprise growth rate is so high that this may change abruptly.","attribution":"forum.effectivealtruism.org","icon_type":null},{"matched_text":"\u301019\u2020L227-L236\u3011","start_idx":70393,"end_idx":70407,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=The%20basic%20idea%20is%20that%2C,to%20go%20for%20LLM%20apps","pub_date":null,"snippet":"The basic idea is that, with enough critical mass, users will stick to ChatGPT and more users will sign up for the ChatGPT Plus plan to access the GPT Store. And developers will stick to the platform where their assistants will be exposed to more users. The mass usage will also create free publicity for the company as more content will be published about ChatGPT, further establishing it as the defacto place to go for LLM apps.","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u301019\u2020L235-L243\u3011","start_idx":70407,"end_idx":70421,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=OpenAI%20is%20reinforcing%20the%20network,the%20stickiness%20of%20the%20product","pub_date":null,"snippet":"OpenAI is reinforcing the network effects with monetization. According to its website, in Q1 2024, \u201cUS builders will be paid based on user engagement with their GPTs.\u201d This means they will be incentivizing maximum engagement to improve the stickiness of the product.","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u301019\u2020L253-L261\u3011","start_idx":70515,"end_idx":70529,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=,January%2011%2C%202024","pub_date":null,"snippet":"> \u2014 will depue (@willdepue) January 11, 2024","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u301023\u2020L39-L45\u3011","start_idx":73720,"end_idx":73732,"alt":null,"type":"webpage_extended","title":"Why OpenAI's $157B valuation misreads AI's future","url":"https://foundationcapital.com/why-openais-157b-valuation-misreads-ais-future/#:~:text=Why%20OpenAI%27s%20%24157B%20valuation%20misreads,As","pub_date":null,"snippet":"Why OpenAI's $157B valuation misreads AI's future What's more, OpenAI's massive infrastructure investments might not be building a moat\u2014they might just be the cost of staying in the race. As ...","attribution":"foundationcapital.com","icon_type":null},{"matched_text":"\u301023\u2020L39-L42\u3011","start_idx":73732,"end_idx":73744,"alt":null,"type":"webpage_extended","title":"Why OpenAI's $157B valuation misreads AI's future","url":"https://foundationcapital.com/why-openais-157b-valuation-misreads-ais-future/#:~:text=Why%20OpenAI%27s%20%24157B%20valuation%20misreads,As","pub_date":null,"snippet":"Why OpenAI's $157B valuation misreads AI's future What's more, OpenAI's massive infrastructure investments might not be building a moat\u2014they might just be the cost of staying in the race. As ...","attribution":"foundationcapital.com","icon_type":null},{"matched_text":"\u301019\u2020L219-L228\u3011","start_idx":74132,"end_idx":74146,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=An%20important%20part%20of%20this,their%20own%20private%20GPT%20Store","pub_date":null,"snippet":"An important part of this strategy is creating network effects around ChatGPT, its flagship product. GPT Store, first announced in November, launched last week. It is the AI version of Apple\u2019s App Store, allowing users and developers to share their customized version of the LLM for others to use. Most GPTs are whimsical, but some of them will be very useful and improve productivity. OpenAI will also provide enterprise features, allowing organizations that sign up for the ChatGPT Team plan to have their own private GPT Store.","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u301019\u2020L227-L236\u3011","start_idx":74146,"end_idx":74160,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=The%20basic%20idea%20is%20that%2C,to%20go%20for%20LLM%20apps","pub_date":null,"snippet":"The basic idea is that, with enough critical mass, users will stick to ChatGPT and more users will sign up for the ChatGPT Plus plan to access the GPT Store. And developers will stick to the platform where their assistants will be exposed to more users. The mass usage will also create free publicity for the company as more content will be published about ChatGPT, further establishing it as the defacto place to go for LLM apps.","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u301018\u2020L199-L207\u3011","start_idx":76019,"end_idx":76033,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=To%20be%20fair%2C%20OpenAI%20still,art%20models","pub_date":null,"snippet":"To be fair, OpenAI still has an advantage in model performance. I still haven\u2019t seen any model that matches GPT-4. But several open-source models already match and outperform GPT-3.5. It is only a matter of time before they reach GPT-4 and other state-of-the-art models.","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u301027\u2020L83-L92\u3011","start_idx":76266,"end_idx":76278,"alt":null,"type":"webpage_extended","title":"Google DeepMind jumps back into open source AI race with new model Gemma | VentureBeat","url":"https://venturebeat.com/ai/google-deepmind-debuts-gemma-open-models-offers-developer-alternative-to-gemini-api/#:~:text=Today%20Google%20DeepMind%20unveiled%20Gemma%2C,announced%20Gemini%20models","pub_date":null,"snippet":"Today Google DeepMind unveiled Gemma, its new 2B and 7B open source models built from the same research and technology used to create the company\u2019s recently-announced Gemini models.","attribution":"venturebeat.com","icon_type":null},{"matched_text":"\u301027\u2020L87-L95\u3011","start_idx":76278,"end_idx":76290,"alt":null,"type":"webpage_extended","title":"Google DeepMind jumps back into open source AI race with new model Gemma | VentureBeat","url":"https://venturebeat.com/ai/google-deepmind-debuts-gemma-open-models-offers-developer-alternative-to-gemini-api/#:~:text=The%20Gemma%20models%20will%20be,new%20Responsible%20Generative%20AI%20toolkit","pub_date":null,"snippet":"The Gemma models will be released with pre-trained and instruction-tuned variants, Google DeepMind said in a blog post. The model weights will be released with a permissive commercial license, as well as a new Responsible Generative AI toolkit.","attribution":"venturebeat.com","icon_type":null},{"matched_text":"\u30101\u2020L61-L68\u3011","start_idx":76733,"end_idx":76744,"alt":null,"type":"webpage_extended","title":"A breakdown of OpenAI's revenue \u2014 EA Forum","url":"https://forum.effectivealtruism.org/posts/ksdSjT7wREu6vBhYE/a-breakdown-of-openai-s-revenue#:~:text=,that%20this%20may%20change%20abruptly","pub_date":null,"snippet":"* Sam Altman's surprising claim of $3.4B ARR on June 12 seems quite plausible, despite skepticism people raised at the time. * Apps (consumer and enterprise) are much more important to OpenAI than the API. * Consumers are much more important to OpenAI than enterprises, as reflected in all their recent demos, but the enterprise growth rate is so high that this may change abruptly.","attribution":"forum.effectivealtruism.org","icon_type":null},{"matched_text":"\u30101\u2020L25-L34\u3011","start_idx":77967,"end_idx":77978,"alt":null,"type":"webpage_extended","title":"A breakdown of OpenAI's revenue \u2014 EA Forum","url":"https://forum.effectivealtruism.org/posts/ksdSjT7wREu6vBhYE/a-breakdown-of-openai-s-revenue#:~:text=We%20estimate%20that%2C%20as%20of,ARR%29%20of","pub_date":null,"snippet":"We estimate that, as of June 12, 2024, OpenAI has an annualized revenue (ARR) of:","attribution":"forum.effectivealtruism.org","icon_type":null},{"matched_text":"\u30101\u2020L61-L68\u3011","start_idx":77978,"end_idx":77989,"alt":null,"type":"webpage_extended","title":"A breakdown of OpenAI's revenue \u2014 EA Forum","url":"https://forum.effectivealtruism.org/posts/ksdSjT7wREu6vBhYE/a-breakdown-of-openai-s-revenue#:~:text=,that%20this%20may%20change%20abruptly","pub_date":null,"snippet":"* Sam Altman's surprising claim of $3.4B ARR on June 12 seems quite plausible, despite skepticism people raised at the time. * Apps (consumer and enterprise) are much more important to OpenAI than the API. * Consumers are much more important to OpenAI than enterprises, as reflected in all their recent demos, but the enterprise growth rate is so high that this may change abruptly.","attribution":"forum.effectivealtruism.org","icon_type":null},{"matched_text":"\u301010\u2020L180-L188\u3011","start_idx":78071,"end_idx":78085,"alt":null,"type":"webpage_extended","title":"SoftBank, OpenAI unveil Japan AI joint venture | Reuters","url":"https://www.reuters.com/technology/artificial-intelligence/softbank-openai-set-up-ai-japan-joint-venture-2025-02-03/#:~:text=Sign%20up%20here","pub_date":null,"snippet":"Sign up here.","attribution":"reuters.com","icon_type":null},{"matched_text":"\u301010\u2020L182-L190\u3011","start_idx":78085,"end_idx":78099,"alt":null,"type":"webpage_extended","title":"SoftBank, OpenAI unveil Japan AI joint venture | Reuters","url":"https://www.reuters.com/technology/artificial-intelligence/softbank-openai-set-up-ai-japan-joint-venture-2025-02-03/#:~:text=The%20Japanese%20investment%20giant%20will,technology%20across%20SoftBank%20group%20companies","pub_date":null,"snippet":"The Japanese investment giant will also pay $3 billion annually to use OpenAI's technology across SoftBank group companies.","attribution":"reuters.com","icon_type":null},{"matched_text":"\u301013\u2020L143-L151\u3011","start_idx":78210,"end_idx":78224,"alt":null,"type":"webpage_extended","title":"Microsoft Announces Changes to OpenAI's Azure Exclusivity on New Cloud Capacity","url":"https://www.thurrott.com/a-i/316138/microsoft-announces-changes-to-openais-azure-exclusivity-on-new-cloud-capacity#:~:text=Back%20in%20October%2C%20a%20report,charged%20OpenAI%20for%20computing%20power","pub_date":null,"snippet":"Back in October, a report from the New York Times detailed how OpenAI had been trying to reduce its costs and find other cloud partners than Microsoft to support its development. The publication also revealed that Microsoft allowed the ChatGPT maker to sign a \u201croughly $10 billion\u201d cloud computing deal with Oracle and agreed to reduce how much it charged OpenAI for computing power.","attribution":"thurrott.com","icon_type":null},{"matched_text":"\u301013\u2020L149-L157\u3011","start_idx":78224,"end_idx":78238,"alt":null,"type":"webpage_extended","title":"Microsoft Announces Changes to OpenAI's Azure Exclusivity on New Cloud Capacity","url":"https://www.thurrott.com/a-i/316138/microsoft-announces-changes-to-openais-azure-exclusivity-on-new-cloud-capacity#:~:text=Microsoft%20announcing%20it%E2%80%99s%20no%20longer,%E2%80%9D","pub_date":null,"snippet":"Microsoft announcing it\u2019s no longer OpenAI\u2019s exclusive cloud provider comes right alongside OpenAI\u2019s Stargate Project announcement. As part of this new joint venture, OpenAI, SoftBank, Oracle, and MGX plan to \u201cinvest $500 billion over the next four years building new AI infrastructure for OpenAI in the United States.\u201d OpenAI said Project Stargate will be investing $100 billion into this new AI infrastructure \u201cimmediately,\u201d and the company also announced Arm, Microsoft, NVIDIA, and Oracle as \u201ckey initial technology partners.\u201d","attribution":"thurrott.com","icon_type":null},{"matched_text":"\u301019\u2020L219-L228\u3011","start_idx":78343,"end_idx":78357,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=An%20important%20part%20of%20this,their%20own%20private%20GPT%20Store","pub_date":null,"snippet":"An important part of this strategy is creating network effects around ChatGPT, its flagship product. GPT Store, first announced in November, launched last week. It is the AI version of Apple\u2019s App Store, allowing users and developers to share their customized version of the LLM for others to use. Most GPTs are whimsical, but some of them will be very useful and improve productivity. OpenAI will also provide enterprise features, allowing organizations that sign up for the ChatGPT Team plan to have their own private GPT Store.","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u301019\u2020L253-L261\u3011","start_idx":78357,"end_idx":78371,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=,January%2011%2C%202024","pub_date":null,"snippet":"> \u2014 will depue (@willdepue) January 11, 2024","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u301022\u2020L67-L75\u3011","start_idx":78448,"end_idx":78460,"alt":null,"type":"webpage_extended","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=,the%20team%20concluded","pub_date":null,"snippet":"* They then articulated five distinctive properties of such models: broader access, greater customizability, potential for local \"inference,\" inability to rescind model access once released and weak monitoring of how a model is being used. * Any attempt to impose conditions on users of open models are \"easy for malicious actors to ignore,\" the team concluded.","attribution":"axios.com","icon_type":null},{"matched_text":"\u301022\u2020L73-L81\u3011","start_idx":78460,"end_idx":78472,"alt":null,"type":"webpage_extended","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=The%20main%20benefits%20are%20distributing,accelerating%20science%20and%20enabling%20transparency","pub_date":null,"snippet":"The main benefits are distributing decision-making power, reducing market concentration, increasing innovation, accelerating science and enabling transparency.","attribution":"axios.com","icon_type":null},{"matched_text":"\u301024\u2020L25-L33\u3011","start_idx":78560,"end_idx":78572,"alt":null,"type":"webpage_extended","title":"The moats are in the GPT-wrappers","url":"https://interjectedfuture.com/the-moats-are-in-the-gpt-wrappers/#:~:text=Despite%20the%20disdain%20for%20%22GPT,while%20operating%20within%20that%20layer","pub_date":null,"snippet":"Despite the disdain for \"GPT-wrappers,\" it's currently where the value is accruing in the supply chain of value to the end-user with LLM-driven apps. Unless something changes with the foundational model companies approach the market, the GPT-wrapper application layer is where the value accrues, hence where the money will be made. Furthermore, the application layer's moat will grow stronger due to the domain-specific contextual data and system evals that GPT-wrappers will create while operating within that layer.","attribution":"interjectedfuture.com","icon_type":null},{"matched_text":"\u301025\u2020L1-L4\u3011","start_idx":78572,"end_idx":78582,"alt":null,"type":"webpage_extended","title":"The moats are in the GPT-wrappers","url":"https://interjectedfuture.com/the-moats-are-in-the-gpt-wrappers/#:~:text=LLM,specific%20contextual%20data%20and","pub_date":null,"snippet":"LLM-driven apps. Unless something changes with the foundational model companies approach the market, the GPT-wrapper application layer is where the value accrues, hence where the money will be made. Furthermore, the application layer's moat will grow stronger due to the domain-specific contextual data and","attribution":"interjectedfuture.com","icon_type":null},{"matched_text":"\u301020\u2020L50-L58\u3011","start_idx":78700,"end_idx":78712,"alt":null,"type":"webpage_extended","title":"The AI Arms Race Intensifies: Anthropic v. OpenAI","url":"https://www.linkedin.com/pulse/ai-arms-race-intensifies-anthropics-multi-billion-demotte-kramer-igb2c#:~:text=Google%20Doubles%20Down%20on%20Anthropic","pub_date":null,"snippet":"Google Doubles Down on Anthropic","attribution":"linkedin.com","icon_type":null},{"matched_text":"\u301020\u2020L80-L89\u3011","start_idx":78712,"end_idx":78724,"alt":null,"type":"webpage_extended","title":"The AI Arms Race Intensifies: Anthropic v. OpenAI","url":"https://www.linkedin.com/pulse/ai-arms-race-intensifies-anthropics-multi-billion-demotte-kramer-igb2c#:~:text=OpenAI%20Counters%20with%20Stargate%20Project","pub_date":null,"snippet":"OpenAI Counters with Stargate Project","attribution":"linkedin.com","icon_type":null},{"matched_text":"\u301027\u2020L83-L92\u3011","start_idx":78812,"end_idx":78824,"alt":null,"type":"webpage_extended","title":"Google DeepMind jumps back into open source AI race with new model Gemma | VentureBeat","url":"https://venturebeat.com/ai/google-deepmind-debuts-gemma-open-models-offers-developer-alternative-to-gemini-api/#:~:text=Today%20Google%20DeepMind%20unveiled%20Gemma%2C,announced%20Gemini%20models","pub_date":null,"snippet":"Today Google DeepMind unveiled Gemma, its new 2B and 7B open source models built from the same research and technology used to create the company\u2019s recently-announced Gemini models.","attribution":"venturebeat.com","icon_type":null},{"matched_text":"\u301027\u2020L87-L95\u3011","start_idx":78824,"end_idx":78836,"alt":null,"type":"webpage_extended","title":"Google DeepMind jumps back into open source AI race with new model Gemma | VentureBeat","url":"https://venturebeat.com/ai/google-deepmind-debuts-gemma-open-models-offers-developer-alternative-to-gemini-api/#:~:text=The%20Gemma%20models%20will%20be,new%20Responsible%20Generative%20AI%20toolkit","pub_date":null,"snippet":"The Gemma models will be released with pre-trained and instruction-tuned variants, Google DeepMind said in a blog post. The model weights will be released with a permissive commercial license, as well as a new Responsible Generative AI toolkit.","attribution":"venturebeat.com","icon_type":null},{"matched_text":"\u301018\u2020L164-L173\u3011","start_idx":78925,"end_idx":78939,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=The%20prohibitive%20costs%20of%20training,models%20for%20building%20LLM%20applications","pub_date":null,"snippet":"The prohibitive costs of training and running LLMs itself was a moat that made them accessible to wealthy organizations. OpenAI used its first-mover advantage to establish itself as the baseline. GPT-3 and later ChatGPT and GPT-4 became the defacto go-to models for building LLM applications.","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u301018\u2020L179-L187\u3011","start_idx":78939,"end_idx":78953,"alt":null,"type":"webpage_extended","title":"How OpenAI is building its moat","url":"https://bdtechtalks.com/2024/01/15/how-openai-is-building-its-moat/#:~:text=While%20DeepMind%20did%20not%20open,3%E2%80%99s%20300%20billion%20tokens","pub_date":null,"snippet":"While DeepMind did not open-source Chinchilla, the training recipe triggered a new direction of research. In February Meta released Llama, a family of LLMs ranging from 7 to 65 billion parameters. Llama was trained on 1.4 trillion tokens as opposed to GPT-3\u2019s 300 billion tokens.","attribution":"bdtechtalks.com","icon_type":null},{"matched_text":"\u301022\u2020L67-L75\u3011","start_idx":79043,"end_idx":79055,"alt":null,"type":"webpage_extended","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=,the%20team%20concluded","pub_date":null,"snippet":"* They then articulated five distinctive properties of such models: broader access, greater customizability, potential for local \"inference,\" inability to rescind model access once released and weak monitoring of how a model is being used. * Any attempt to impose conditions on users of open models are \"easy for malicious actors to ignore,\" the team concluded.","attribution":"axios.com","icon_type":null},{"matched_text":"\u301022\u2020L69-L77\u3011","start_idx":79055,"end_idx":79067,"alt":null,"type":"webpage_extended","title":"What are the risks of open source AI?","url":"https://www.axios.com/2024/02/27/stanford-open-source-risks-meta#:~:text=rescind%20model%20access%20once%20released,the%20team%20concluded","pub_date":null,"snippet":"rescind model access once released and weak monitoring of how a model is being used. * Any attempt to impose conditions on users of open models are \"easy for malicious actors to ignore,\" the team concluded.","attribution":"axios.com","icon_type":null}],"timestamp_":"absolute","message_type":null,"is_async_task_result_message":true,"b1de6e2_rm":true,"async_task_id":"deepresch_67ea3806ad748191bb120f772457059e","async_task_title":"Strategic Viability of OpenAI Open-Sourcing Frontier Models and Focusing on Middleware","can_save":true},"recipient":"all","channel":"final"},"parent":"c8c8abbf-386a-452a-9cd0-f569025d5055","children":[]}}}