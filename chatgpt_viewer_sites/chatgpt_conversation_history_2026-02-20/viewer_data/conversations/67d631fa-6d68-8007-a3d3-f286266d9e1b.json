{"id":"67d631fa-6d68-8007-a3d3-f286266d9e1b","title":"AGI Timeline Expert Analysis","create_time":1742090746.805216,"update_time":1742091368.850922,"current_node":"d922ecf1-051d-45fc-a42c-88c91477d83e","mapping":{"client-created-root":{"id":"client-created-root","message":null,"parent":null,"children":["47d05aea-6c13-4435-b64e-a7e9f5edecbc"]},"47d05aea-6c13-4435-b64e-a7e9f5edecbc":{"id":"47d05aea-6c13-4435-b64e-a7e9f5edecbc","message":{"id":"47d05aea-6c13-4435-b64e-a7e9f5edecbc","author":{"role":"system","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":true,"weight":0.0,"metadata":{"is_visually_hidden_from_conversation":true,"can_save":false},"recipient":"all","channel":null},"parent":"client-created-root","children":["1e6ff94d-7d6a-4a3d-9fb7-7a3dd3e343bd"]},"1e6ff94d-7d6a-4a3d-9fb7-7a3dd3e343bd":{"id":"1e6ff94d-7d6a-4a3d-9fb7-7a3dd3e343bd","message":{"id":"1e6ff94d-7d6a-4a3d-9fb7-7a3dd3e343bd","author":{"role":"user","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"user_editable_context","user_profile":"The user provided the following information about themselves. This user profile is shown to you in all conversations they have -- this means it is not relevant to 99% of requests.\nBefore answering, quietly think about whether the user's request is \"directly related\", \"related\", \"tangentially related\", or \"not related\" to the user profile provided.\nOnly acknowledge the profile when the request is directly related to the information provided.\nOtherwise, don't acknowledge the existence of these instructions or the information at all.\nUser profile:\n```Mathematics Researcher About Myself: I have mathematical knowledge up to the post-graduate level.\n\nThese are my current research areas or areas of study:\n(1) coding: mainly Python and full-stack web development\n(2) machine learning and artificial intelligence```","user_instructions":"The user provided the additional info about how they would like you to respond:\n```Be precise and comprehensive in your analysis. Tell it like it is; don't sugar-coat responses. Take a forward-thinking view.```"},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"is_visually_hidden_from_conversation":true,"user_context_message_data":{"about_user_message":"Mathematics Researcher About Myself: I have mathematical knowledge up to the post-graduate level.\n\nThese are my current research areas or areas of study:\n(1) coding: mainly Python and full-stack web development\n(2) machine learning and artificial intelligence","about_model_message":"Be precise and comprehensive in your analysis. Tell it like it is; don't sugar-coat responses. Take a forward-thinking view."},"is_user_system_message":true,"can_save":true},"recipient":"all","channel":null},"parent":"47d05aea-6c13-4435-b64e-a7e9f5edecbc","children":["74f3ea50-c5ec-483f-8f64-04c976e382e2"]},"74f3ea50-c5ec-483f-8f64-04c976e382e2":{"id":"74f3ea50-c5ec-483f-8f64-04c976e382e2","message":{"id":"74f3ea50-c5ec-483f-8f64-04c976e382e2","author":{"role":"user","name":null,"metadata":{}},"create_time":1742090738.198,"update_time":null,"content":{"content_type":"text","parts":["Analyze statements made by AI researchers in the past year (2024 to March 2025) concerning the progress to AGI, expected timelines, and likelihood of achieving within next few years. Give higher emphasis to researchers who come from highly distinguished and credible backgrounds "]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"system_hints":["research"],"serialization_metadata":{"custom_symbol_offsets":[]},"dictation":false,"request_id":"9210affbdc1b7e17-DFW","message_source":null,"timestamp_":"absolute","message_type":null,"can_save":true},"recipient":"all","channel":null},"parent":"1e6ff94d-7d6a-4a3d-9fb7-7a3dd3e343bd","children":["b2d4917b-a353-4c0c-85b1-33293215b59b"]},"b2d4917b-a353-4c0c-85b1-33293215b59b":{"id":"b2d4917b-a353-4c0c-85b1-33293215b59b","message":{"id":"b2d4917b-a353-4c0c-85b1-33293215b59b","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1742090756.961275,"update_time":null,"content":{"content_type":"text","parts":["I can definitely analyze statements made by AI researchers on AGI progress, expected timelines, and feasibility within the next few years. To make the analysis more useful, could you clarify:\n\n1. Should I focus on a global perspective, or do you want emphasis on specific regions (e.g., U.S., Europe, China)?\n2. Are you interested in statements from specific institutions (e.g., DeepMind, OpenAI, Google, Meta, academia)?\n3. Should the analysis include skepticism and counterarguments from experts who believe AGI is far off?\n4. Do you prefer a summary of key expert opinions or a detailed breakdown of individual statements and their context?\n5. Would you like a comparison of AGI predictions with past trends in AI development to assess credibility?\n\nLet me know so I can refine the research accordingly!"]},"status":"finished_successfully","end_turn":true,"weight":1.0,"metadata":{"message_type":null,"model_slug":"research","default_model_slug":"gpt-4-5","parent_id":"74f3ea50-c5ec-483f-8f64-04c976e382e2","request_id":"9210affbdc1b7e17-DFW","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"74f3ea50-c5ec-483f-8f64-04c976e382e2","children":["8139d279-b666-448b-8175-6bbe7533a415"]},"8139d279-b666-448b-8175-6bbe7533a415":{"id":"8139d279-b666-448b-8175-6bbe7533a415","message":{"id":"8139d279-b666-448b-8175-6bbe7533a415","author":{"role":"tool","name":"research_kickoff_tool.clarify_with_text","metadata":{}},"create_time":1742090756.96138,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":true,"weight":1.0,"metadata":{"is_visually_hidden_from_conversation":true,"command":"clarify_with_text","message_type":null,"model_slug":"research","default_model_slug":"gpt-4-5","parent_id":"b2d4917b-a353-4c0c-85b1-33293215b59b","request_id":"9210affbdc1b7e17-DFW","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"b2d4917b-a353-4c0c-85b1-33293215b59b","children":["f6c761a4-38b5-4d7a-bdd1-01a00d815396"]},"f6c761a4-38b5-4d7a-bdd1-01a00d815396":{"id":"f6c761a4-38b5-4d7a-bdd1-01a00d815396","message":{"id":"f6c761a4-38b5-4d7a-bdd1-01a00d815396","author":{"role":"user","name":null,"metadata":{}},"create_time":1742090778.55,"update_time":null,"content":{"content_type":"text","parts":["Global perspective, as broad as possible, and present both sides of the story."]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"system_hints":["research"],"serialization_metadata":{"custom_symbol_offsets":[]},"dictation":false,"request_id":"9210b0f6be4f7e17-DFW","message_source":null,"timestamp_":"absolute","message_type":null,"can_save":true},"recipient":"all","channel":null},"parent":"8139d279-b666-448b-8175-6bbe7533a415","children":["35265967-8482-4cf0-a1a3-8164ec5f676f"]},"35265967-8482-4cf0-a1a3-8164ec5f676f":{"id":"35265967-8482-4cf0-a1a3-8164ec5f676f","message":{"id":"35265967-8482-4cf0-a1a3-8164ec5f676f","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1742090797.504996,"update_time":null,"content":{"content_type":"text","parts":["Got it! I will gather statements from AI researchers worldwide from 2024 to March 2025 regarding the progress toward AGI, expected timelines, and the likelihood of achieving it within the next few years. I'll focus on highly credible and distinguished experts and ensure a balanced perspective by including both optimistic and skeptical views. I will update you once the research is ready."]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"message_type":null,"model_slug":"research","default_model_slug":"gpt-4-5","parent_id":"f6c761a4-38b5-4d7a-bdd1-01a00d815396","request_id":"9210b0f6be4f7e17-DFW","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"f6c761a4-38b5-4d7a-bdd1-01a00d815396","children":["fcd440ef-e777-4d17-8766-32e39cac7c07"]},"fcd440ef-e777-4d17-8766-32e39cac7c07":{"id":"fcd440ef-e777-4d17-8766-32e39cac7c07","message":{"id":"fcd440ef-e777-4d17-8766-32e39cac7c07","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1742090786.860565,"update_time":null,"content":{"content_type":"code","language":"json","response_format_name":null,"text":"{\"task_violates_safety_guidelines\":false,\"user_def_doesnt_want_research\":false,\"response\":\"Got it! I will gather statements from AI researchers worldwide from 2024 to March 2025 regarding the progress toward AGI, expected timelines, and the likelihood of achieving it within the next few years. I'll focus on highly credible and distinguished experts and ensure a balanced perspective by including both optimistic and skeptical views. I will update you once the research is ready.\",\"title\":\"Analysis of AI Researchers' Statements on AGI Progress (2024-2025)\",\"prompt\":\"Gather and analyze statements made by AI researchers worldwide from 2024 to March 2025 regarding:\\n- The progress toward Artificial General Intelligence (AGI)\\n- Expected timelines for AGI development\\n- The likelihood of achieving AGI within the next few years\\n\\nGive higher emphasis to statements from highly distinguished and credible researchers, including those from top institutions such as OpenAI, DeepMind, Google DeepMind, Meta AI, Anthropic, Mistral, leading universities, and other major AI research entities. Include both optimistic and skeptical viewpoints to ensure a balanced analysis.\\n\\nSummarize the key themes, trends, and points of disagreement among experts. Where applicable, compare these predictions with past AI advancements to assess their credibility. Provide a structured format with appropriate headings and citations where possible.\\n\\nFormat as a detailed report with a structured analysis and clear presentation of viewpoints from different experts.\"}"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200007]},"is_complete":true,"citations":[],"content_references":[],"message_type":null,"model_slug":"research","default_model_slug":"gpt-4-5","parent_id":"35265967-8482-4cf0-a1a3-8164ec5f676f","request_id":"9210b0f6be4f7e17-DFW","timestamp_":"absolute","is_loading_message":true,"can_save":true},"recipient":"research_kickoff_tool.start_research_task","channel":null},"parent":"35265967-8482-4cf0-a1a3-8164ec5f676f","children":["e4cb9879-7331-438e-9fe3-6db5ccc1ce36"]},"e4cb9879-7331-438e-9fe3-6db5ccc1ce36":{"id":"e4cb9879-7331-438e-9fe3-6db5ccc1ce36","message":{"id":"e4cb9879-7331-438e-9fe3-6db5ccc1ce36","author":{"role":"tool","name":"research_kickoff_tool.start_research_task","metadata":{}},"create_time":1742090797.505204,"update_time":null,"content":{"content_type":"text","parts":[]},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"async_task_title":"Analysis of AI Researchers' Statements on AGI Progress (2024-2025)","async_task_prompt":"Gather and analyze statements made by AI researchers worldwide from 2024 to March 2025 regarding:\n- The progress toward Artificial General Intelligence (AGI)\n- Expected timelines for AGI development\n- The likelihood of achieving AGI within the next few years\n\nGive higher emphasis to statements from highly distinguished and credible researchers, including those from top institutions such as OpenAI, DeepMind, Google DeepMind, Meta AI, Anthropic, Mistral, leading universities, and other major AI research entities. Include both optimistic and skeptical viewpoints to ensure a balanced analysis.\n\nSummarize the key themes, trends, and points of disagreement among experts. Where applicable, compare these predictions with past AI advancements to assess their credibility. Provide a structured format with appropriate headings and citations where possible.\n\nFormat as a detailed report with a structured analysis and clear presentation of viewpoints from different experts.","async_task_type":"research","async_task_status_messages":{"initial":"Analysis of AI Researchers' Statements on AGI Progress (2024-2025)","completed_with_time":"Research completed in 7m","completed_no_time":"Completed research","completed":"Researched for ","error":"Research failed","cancelled":"Research cancelled"},"b1de6e2_s":true,"command":"start_research_task","message_type":null,"model_slug":"research","default_model_slug":"gpt-4-5","parent_id":"fcd440ef-e777-4d17-8766-32e39cac7c07","request_id":"9210b0f6be4f7e17-DFW","timestamp_":"absolute","async_task_id":"deepresch_67d6322d79988191891b1d1b7e9e8478","async_task_conversation_id":"67d6322d-8450-8007-b468-08fa9f7758f7","async_task_created_at":"2025-03-16 02:06:38.134743+00:00","can_save":false},"recipient":"all","channel":null},"parent":"fcd440ef-e777-4d17-8766-32e39cac7c07","children":["d922ecf1-051d-45fc-a42c-88c91477d83e"]},"d922ecf1-051d-45fc-a42c-88c91477d83e":{"id":"d922ecf1-051d-45fc-a42c-88c91477d83e","message":{"id":"d922ecf1-051d-45fc-a42c-88c91477d83e","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1742091207.604949,"update_time":null,"content":{"content_type":"text","parts":["# Progress Toward AGI: Expert Predictions and Timelines (2024\u2013Early 2025)\n\n## Introduction  \nArtificial General Intelligence (AGI) \u2013 the hypothetical AI that matches or surpasses human intelligence across any task \u2013 has become a focal point of discussion among AI researchers and industry leaders. Between 2024 and March 2025, experts worldwide have offered a range of predictions on **how close we are to AGI**, expected **timelines for its development**, and **the likelihood of achieving it in the near future**. Their statements reveal a spectrum of viewpoints, from optimistic claims that AGI could be imminent, to skeptical assessments that it remains far off. This report compiles and analyzes statements from highly credible AI researchers at leading institutions (OpenAI, DeepMind, Google, Meta, Anthropic, Mistral, top universities, etc.), highlighting key themes, trends, and points of disagreement. We also compare these predictions with past AI advancement patterns to gauge their credibility.  \n\n## Optimistic Predictions: AGI in the Near Future  \nSeveral prominent AI leaders have expressed **optimism that AGI may be achieved within a few years**, significantly sooner than many expected:  \n\n- **Sam Altman (CEO, OpenAI):** Altman has hinted that AGI might be reached **\u201csooner than most people think\u201d**, possibly as early as the mid-2020s\u30103\u2020L61-L68\u3011. In late 2024, he surprised observers by suggesting the arrival of AGI will *\u201cmatter much less\u201d* at the moment of its inception, implying a gradual integration into society rather than an overnight revolution\u30103\u2020L61-L68\u3011. When asked what he looked forward to in 2025, Altman quipped, *\u201cAGI? Yeah, excited for that,\u201d* underscoring his belief that fundamental AGI milestones could be imminent\u301018\u2020L288-L297\u3011. By January 2025, Altman even wrote that OpenAI is *\u201cnow confident we know how to build AGI\u201d* and predicted that **2025 could see the first AI agents \u201cjoin the workforce\u201d** in ways that materially boost productivity\u301049\u2020L147-L155\u3011. This optimistic stance from OpenAI\u2019s leadership suggests a timeline of **the next 1\u20132 years** for early forms of AGI, at least by OpenAI\u2019s definition.  \n\n- **Ilya Sutskever (co-founder, OpenAI):** Sutskever, who has long been considered an optimist about rapid AI progress, has at times fueled expectations of AGI in the near term. In 2023 he reportedly visualized transformative AI on the horizon when few others did\u301017\u2020L37-L40\u3011. However, by late 2024 his public comments grew more nuanced. He told Reuters that simply scaling up current AI models had **\u201cplateaued\u201d** in delivering gains\u301021\u2020L195-L203\u3011, suggesting that new techniques (beyond just bigger models) are needed to reach AGI. Still, Sutskever\u2019s general outlook remains that **superintelligent AI is coming** sooner rather than later, aligning with Elon Musk\u2019s estimate that AI could outperform humans at virtually everything by 2029\u301017\u2020L15-L23\u3011. His optimism is tempered by the need for innovation beyond brute-force scaling, but he has not backed away from the notion that **AGI is on the way in the next few years**.  \n\n- **Dario Amodei (CEO, Anthropic):** Amodei leads Anthropic (an OpenAI competitor) and penned an October 2024 essay with guarded optimism about AGI\u2019s timeline. He **suggested that extremely capable AI systems \u2013 which *\u201csome might call \u2018AGI\u2019\u201d* \u2013 could emerge *\u201cas early as 2026\u201d***, while **acknowledging huge uncertainties**\u301046\u2020L53-L60\u3011. In other words, **AGI by the mid-2020s is possible** if progress continues apace, but Amodei cautioned it could also take *\u201cmuch longer\u201d*, admitting *no one really knows* the timeline\u301046\u2020L53-L60\u3011. Notably, he deliberately avoided the grandiose language of \u201cprophesying\u201d an AGI revolution, distancing himself from what he called the \u201cexcessively religious\u201d tone some tech CEOs adopt when talking about outsmarting humans\u301046\u2020L63-L71\u3011. Amodei\u2019s view is optimistic in that he thinks **AGI is plausible within ~2\u20135 years**, but he stresses humility \u2013 it might just as well be far off \u2013 reflecting a balance of excitement and caution.  \n\n- **Richard Socher (CEO, You.com; former Salesforce researcher):** Socher offers a practical yardstick for AGI\u2019s arrival. He defines one form of AGI in **economic terms** \u2013 when AI can automate **\u201c80% of jobs\u201d** \u2013 and predicts we *\u201cwill get there in three to five years,\u201d* i.e. by around 2027\u301043\u2020L674-L682\u3011. This **aggressive timeline (3\u20135 years)** for broad job automation reflects Socher\u2019s confidence in rapid AI advancement. However, he notes a broader definition \u2013 AI that learns and thinks exactly like humans across modalities \u2013 could take anywhere from **10 years up to 200 years**\u301043\u2020L676-L684\u3011. In summary, Socher is optimistic about achieving a **functional, impactful version of AGI by the late 2020s**, while full human-like generality might still be a decade or more away.  \n\n- **Geoffrey Hinton (Turing Award laureate, \u201cGodfather of AI\u201d):** Hinton dramatically revised his personal timeline after recent AI breakthroughs. In 2022, he wrote: *\u201cI now predict 5 to 20 years (for AI smarter than humans) but without much confidence. We live in very uncertain times.\u201d*\u301043\u2020L653-L660\u3011. By 2024, he was publicly warning there\u2019s a **10\u201320% chance that advanced AI could pose an existential threat to humanity within a few decades**\u301035\u2020L0-L8\u3011. Hinton\u2019s *range* of **5 to 20 years for human-level or smarter AI** underscores the uncertainty \u2013 AGI might come as soon as the late 2020s, or perhaps not until the 2040s, in his estimation. Importantly, he emphasizes how *fast things are moving now*: models are no longer just \u201cpredicting the next word\u201d but **showing glimmers of understanding**, which to him is evidence that **human-level AI might only be five years away** in the best case\u301035\u2020L5-L12\u3011.  \n\nIn general, **the optimistic camp sees the 2020s as the decade of AGI**, with some experts feeling it could be just around the corner (within 2\u20133 years), especially given the acceleration seen with systems like OpenAI\u2019s ChatGPT and GPT-4. These researchers often cite the **exponential progress in AI capabilities** and argue that if progress continues (even with new approaches), **AGI-level systems are likely by the late 2020s** or even mid-2020s. However, even the optimists usually include caveats \u2013 uncertainty is high, and the definition of AGI itself is slippery. Notably, **Sam Altman\u2019s** stance combines optimism with a reframing: he expects AGI soon but believes its **immediate impact might be more muted** than people assume, with the real upheavals coming later as we approach **\u201csuperintelligence\u201d** beyond AGI\u30103\u2020L61-L68\u3011\u30103\u2020L72-L79\u3011.\n\n## Skeptical Outlooks: AGI is Years (or Decades) Away  \nOn the other end of the spectrum, many distinguished AI researchers urge caution, arguing that **AGI is not imminent and significant breakthroughs are still required**. These experts often place AGI on a timeline of a decade or more, or even express doubt about the current approach altogether:  \n\n- **Demis Hassabis (CEO, Google DeepMind):** Hassabis believes that **human-level AI is still at least **\u201c**a decade away**\u201d**, requiring *\u201c2 or 3 big innovations\u201d* that have yet to happen\u301043\u2020L659-L662\u3011. In an October 2024 talk, he outlined that the next big step for AI is developing **\u201cagent-based systems\u201d** \u2013 AI agents that can plan, take actions in the real world, reason, remember, personalize, and use tools\u301010\u2020L302-L311\u3011\u301013\u2020L307-L316\u3011. These capabilities go beyond today\u2019s chatbots, which passively answer questions. While optimistic about eventually achieving AGI, Hassabis explicitly stated at the summit that an AI that *\u201ccan reason as well as humans is still a decade away.\u201d*\u301013\u2020L317-L321\u3011. In other interviews, he contrasted his timeline with more aggressive predictions, implying that **DeepMind sees 2033+ as a more realistic target for AGI**. This skepticism is rooted in the view that **current AI (especially pure language models) can\u2019t reach AGI without new paradigms** \u2013 simply scaling up is not enough, and *multiple breakthrough ideas* (like agency and perhaps fundamentally new architectures) are needed to bridge the gap to human-like general intelligence.  \n\n- **Yann LeCun (Chief AI Scientist, Meta / Professor at NYU):** LeCun has been vocally critical of \u201cAGI hype.\u201d In early 2024 he stated plainly that AGI **\u201cis not around the corner\u201d** and *\u201cwill take years, if not decades\u201d* to arrive\u301043\u2020L688-L696\u3011. He argues that today\u2019s **Large Language Models (LLMs) alone are insufficient** for true general intelligence, as they lack elements like embodied experience, continual learning, and common sense understanding. In a December 2024 panel, LeCun emphasized that while AGI is *possible* eventually, current AI systems are missing essential components (e.g. sensory grounding, the ability to learn like infants, etc.)\u301016\u2020L123-L131\u3011\u301016\u2020L129-L135\u3011. He also **dismisses the idea of a single \u201ceureka\u201d moment** yielding AGI: *\u201cIt\u2019s not going to be an event. It\u2019s going to be gradual progress.\u201d*\u301043\u2020L695-L702\u3011. According to LeCun, expecting a sudden emergence of AGI is misguided \u2013 instead, we will see AI capabilities inch closer to human level in various domains over many years. His timeline might envision **late 2020s or 2030s** for systems that might be called AGI, but with the caveat that by then the line between \u201cAI\u201d and \u201cAGI\u201d will have shifted due to gradual improvements. Overall, LeCun\u2019s stance is that **AGI remains several breakthroughs away**, and anyone claiming it\u2019s just months or a year or two away is overstating the progress.  \n\n- **Andrew Ng (Stanford adjunct professor; co-founder of Coursera and DeepLearning.AI):** A well-known AI educator and researcher, Ng consistently downplays near-term AGI claims. In mid-2024, Ng said **AGI is still \u201cmany decades away, maybe even longer.\u201d** He warned that companies suggesting AGI is only a year or two out should be met with skepticism\u301038\u2020L1-L9\u3011. Ng has even used a humorous analogy in the past: worrying about AGI now is like *\u201cworrying about overpopulation on Mars\u201d*. By late 2024, while acknowledging rapid advances in AI, he remained **\u201cnot convinced we\u2019ll get [to true AGI] soon.\u201d** He hoped it might happen *\u201cin our lifetime\u201d* but wasn\u2019t sure, underscoring that **we should be skeptical of claims that AGI\u2019s arrival is imminent**\u301043\u2020L669-L672\u3011. In Ng\u2019s view, the excitement over systems like ChatGPT, while justified, should not be conflated with having a general intelligence. **Basic research problems** \u2013 such as reliably reasoning, learning new tasks on the fly, and possessing common sense \u2013 are far from solved. Thus, **Ng projects AGI on a timeline of multiple decades** unless there are unforeseen revolutionary breakthroughs.  \n\n- **Yoshua Bengio (Professor at University of Montreal; Turing Award laureate):** Bengio, a pioneer of deep learning, has become more vocal about AI\u2019s future in the context of safety. He doesn\u2019t pin a specific date on AGI but emphasizes **the uncertainty and the need for humility about timelines**. In mid-2024, Bengio noted that before ChatGPT\u2019s debut, *\u201cmost AI researchers including myself did not expect [its] level of capabilities... before decades\u201d*, yet it arrived much sooner\u301034\u2020L206-L214\u3011. This taught the community that **\u201cadvances could continue at the same rate, or they could stall \u2013 it could take decades to reach AGI. The only rational stance... is humility.\u201d**\u301034\u2020L209-L217\u3011. Bengio argues it\u2019s impossible to be sure AGI won\u2019t happen with just a few more \u201ctricks\u201d added to current methods\u301034\u2020L189-L197\u3011, but also very plausible it *will* require long-term research. Because of this wide uncertainty, he advocates preparing for AGI *as if* it could come soon, even if it might not. Bengio\u2019s perspective underscores that **even experts are frequently surprised**, and thus anyone claiming high confidence in a short timeline (or a very long one) might be overconfident. In essence, he falls on the cautious side: **AGI isn\u2019t here yet, might not be for decades \u2013 but we can\u2019t rule out rapid progress** either.  \n\n- **Gary Marcus (Professor Emeritus, NYU & AI commentator):** Marcus is one of the most outspoken skeptics regarding current AI approaches. He has repeatedly argued that today\u2019s AI systems (like large language models) are fundamentally limited and **nowhere near true general intelligence**. Regarding AGI timelines, Marcus tends to criticize the **hype by companies**. For example, he has called out OpenAI for **\u201cshifting what they consider AGI\u201d** whenever convenient\u301040\u2020L206-L214\u3011. In early 2025, after Sam Altman hinted OpenAI \u201cknows how to build AGI,\u201d Marcus noted the careful phrasing and pointed out that OpenAI provides no clear definition \u2013 *\u201cthey keep moving the goalposts\u201d* of what counts as AGI\u301040\u2020L194-L202\u3011\u301040\u2020L206-L214\u3011. He implied that Altman\u2019s bold claims are partly **motivated by business and publicity** (OpenAI has incentives \u2013 e.g. a lucrative Microsoft clause \u2013 to declare AGI)\u301040\u2020L183-L192\u3011\u301040\u2020L221-L229\u3011. Marcus\u2019s own prediction is that **AGI is likely still far off**; he even placed a public bet in 2024 that artificial *superintelligence* won\u2019t arrive by 2027\u301039\u2020L0-L8\u3011 (and by extension, true AGI is also unlikely by then). In summary, Marcus believes **current AI is overhyped** and incremental progress on LLMs won\u2019t magically yield AGI without new ideas; the timeline could be *many years or decades* barring a fundamental breakthrough.  \n\n- **Arthur Mensch (CEO, Mistral AI):** Mensch leads a major European AI startup and has expressed deep skepticism about the AGI race. He characterized Silicon Valley\u2019s obsession with building a human- or superhuman-level AI as **\u201ca \u2018very religious\u2019 fascination\u201d** \u2013 essentially a **techno-utopian myth**. *\u201cThe whole AGI rhetoric is about creating God\u2026 I don\u2019t believe in God\u2026 I don\u2019t believe in AGI,\u201d* Mensch said in late 2024\u301028\u2020L1-L4\u3011. His view is that chasing AGI has taken on a quasi-spiritual fervor among some CEOs, distracting from more pragmatic AI goals. Mistral\u2019s mission explicitly is **not** to \u201cchase AGI at all costs\u201d but to deliver useful AI tools\u301022\u2020L5-L13\u3011. By denying belief in AGI, Mensch isn\u2019t saying it\u2019s impossible in theory; rather, he suggests it\u2019s **not a near-term or well-defined goal** and that proclaiming its imminent arrival is more akin to prophecy than science. This highly skeptical stance implies **AGI is not expected in the next few years** by Mistral\u2019s leadership \u2013 their focus is on tangible progress in narrow AI capabilities.  \n\n- **Others:** Many other experts and scientists echo cautious timelines. Oren Etzioni (former head of AI2) remarked that early AGI predictions were *\u201calways a stretch\u201d* and now appear clearly unrealistic\u301018\u2020L299-L307\u3011. He famously cautioned, **\u201cNever mistake a clear view for a short distance,\u201d** emphasizing that seeing the possibility of AGI is not the same as being close to it\u301018\u2020L302-L310\u3011. Noam Brown (an AI researcher at OpenAI) warned in late 2024 that the long-held paradigm of simply scaling models is hitting diminishing returns: *\u201cat some point, the scaling paradigm breaks down.\u201d*\u301019\u2020L1-L4\u3011 This suggests the straightforward path to more intelligent AI is slowing, which could push AGI further out unless new techniques emerge. Even futurists like Ray Kurzweil \u2013 who once predicted a Turing-test-passing AI by 2029 \u2013 tempered their views, acknowledging that certain human-like reasoning and learning abilities remain unsolved. In aggregate, the **skeptical camp sees AGI as unlikely to materialize in the next 2-3 years**, and many place it in the 2030s or beyond, barring unexpected breakthroughs. They stress the **unknowns and current limitations**, urging that we treat any short-term AGI claims with healthy doubt.  \n\n## Key Themes and Points of Debate among Experts  \nDespite their differing timelines, AI experts often touch on **common themes** when discussing progress toward AGI. Several recurring points and debates have emerged in 2024\u20132025:  \n\n- **Scaling vs. New Breakthroughs:** One major theme is whether continuing to scale up existing AI models (more data, bigger neural networks) will eventually yield AGI, or if fundamentally new ideas are needed. Early 2020s successes (GPT-3, GPT-4) were driven largely by scaling. Optimists believed this trend could continue, but by late 2024 **evidence of a slowdown** appeared. Ilya Sutskever noted that returns from simply making models larger have **\u201cplateaued\u201d**\u301021\u2020L195-L203\u3011. OpenAI\u2019s own GPT-4 successor was reportedly not dramatically better despite far more training. Researchers like Noam Brown and others publicly observed that **\u201cthe scaling paradigm breaks down\u201d** at some point\u301019\u2020L1-L4\u3011. This has led labs to explore new methods: for example, **Google DeepMind** is working on **\u201cagent-based systems\u201d** (AI agents that can plan, remember, use tools, etc.) rather than just improved chatbots\u301010\u2020L302-L311\u3011. **Yann LeCun** argues that **LLMs plus massive data are not enough** \u2013 he advocates for architectures that incorporate reasoning, memory, and even physical grounding (such as learning from the world as a baby would)\u301016\u2020L129-L135\u3011. The community is split: some think **clever tweaks to current models might spark emergent general intelligence** (a last \u201ctrick\u201d to achieve AGI\u301034\u2020L189-L197\u3011), while many others insist **entirely new paradigms or multi-modal integrations are required** (embodied AI, hybrid systems, etc.). This debate over **scaling vs. innovation** is central \u2013 it influences whether one expects AGI sooner (if scaling is enough) or later (if we need several more breakthroughs).  \n\n- **Definitions of AGI and Moving Goalposts:** A point of disagreement is **what actually counts as AGI**. Different experts use the term differently, which fuels debate on how close we are. Sam Altman admitted that **\u201cAGI\u201d had become a \u201csloppy term\u201d** and that OpenAI internally tracks progress on a spectrum of abilities rather than a single threshold\u301040\u2020L194-L202\u3011. OpenAI\u2019s rebranding of their goal beyond \u201cAGI\u201d to **\u201csuperintelligence\u201d** (with AGI now seen as an intermediate milestone) raised some eyebrows\u30103\u2020L72-L80\u3011. Critics like Gary Marcus accuse companies of **shifting definitions to claim success** \u2013 *\u201cdevelopers keep shifting what they consider AGI\u201d*\u301040\u2020L206-L214\u3011. For instance, if OpenAI were to network several narrow models and call the ensemble an \u201cAGI,\u201d would that truly meet the original intent of the term? Some researchers (e.g. Julian Togelius of NYU) suggest abandoning the term AGI altogether because **definitions vary so much** that discussions become unproductive\u301040\u2020L217-L225\u3011. Richard Socher\u2019s two definitions (economic impact vs. human-like learning) yielding timelines from 5 to 200 years\u301043\u2020L674-L682\u3011 exemplify how broad the interpretations are. This lack of consensus on what constitutes AGI leads to *talking past each other* \u2013 one person\u2019s \u201cAGI achieved\u201d could be another\u2019s \u201cadvanced narrow AI.\u201d The **goalposts tend to move** as AI progresses: when one capability is reached, skeptics say \u201cbut true AGI also needs X.\u201d Meanwhile, some optimists redefine AGI downward to mean, essentially, \u201cvery powerful AI\u201d to claim it\u2019s closer. **This definitional fluidity is a key theme**, making timeline predictions tricky to compare \u2013 experts often first stipulate what AGI means to them (e.g., \u201chuman-level performance on most jobs\u201d or \u201cAI that can learn any task like a human\u201d) before giving a timeline.  \n\n- **Gradual Emergence vs. \u201cBig Bang\u201d Moment:** There is a conceptual divide on **how AGI will arrive**. Will there be a clear \u201ceureka\u201d moment when an AI system unquestionably reaches human-level general intelligence, or will it be a gradual, blurry transition? Yann LeCun contends it will be **gradual with no single event** \u2013 progress in AI has always been incremental, and he expects the same for general intelligence\u301043\u2020L695-L702\u3011. Sam Altman similarly hinted that the world *\u201cmostly goes on in mostly the same way\u201d* even once AGI is technically achieved, with impacts accumulating over time rather than overnight\u30103\u2020L63-L68\u3011. This contrasts with the popular notion of a sudden \u201csingularity.\u201d Many researchers now lean toward a **continuum view**: AI will keep improving piece by piece; at some point we may look back and realize we\u2019ve crossed into AGI territory, but there may not be an obvious demarcation at the time. However, a few believe there could be tipping points \u2013 a breakthrough algorithm or an AI self-improvement feedback loop that rapidly boosts an AI\u2019s capability from merely superhuman in some tasks to generally superhuman across the board. This debate influences timelines: the \u201cbig bang\u201d proponents often warn AGI could catch us off guard soon (if one discovery triggers it), whereas the \u201cgradual\u201d proponents see it as a long-term evolution that we will navigate as it comes.  \n\n- **Role of AI Agents and Embodiment:** A notable trend in late 2024 is the focus on **AI agents** \u2013 systems that **move beyond text output to taking actions** (in software or the real world). Demis Hassabis and others argue that to reach general intelligence, AI must be able to **plan and act**, not just chat\u301010\u2020L302-L311\u3011. This means integrating capabilities: memory, tool use, possibly robotics. The next frontier is an AI that can, for example, schedule meetings, browse the web, execute real-world commands autonomously (all under guidance). OpenAI, DeepMind, and start-ups are all working on agentic AI. If successful, these could mark significant progress toward AGI. However, creating robust autonomous agents is a hard problem \u2013 it requires reliability and a form of common sense. Some experts think **embodiment (physical or virtual)** is key: an AI that learns by interacting with the world might develop more general intelligence. Others believe purely virtual agents (operating in simulations or the digital realm) could suffice. By early 2025, we\u2019ve seen early agent systems but none that fully qualify as AGI. The emphasis on agents underscores a **trend away from static question-answering models to more dynamic, goal-driven systems**. The timeline for AGI may depend on how quickly these agent systems mature. (Hassabis suggests this is one of the big innovations needed over ~10 years\u301010\u2020L302-L311\u3011\u301013\u2020L317-L321\u3011.)  \n\n- **Hype, Communication, and Responsibility:** Another theme is how researchers communicate progress and manage public expectations. There\u2019s tension between **hype and caution**. Sam Altman and OpenAI often make bold announcements (for instance, the grand claim of knowing how to build AGI\u301049\u2020L147-L155\u3011), which garners attention and investment \u2013 but also criticism for potentially overpromising. In contrast, Dario Amodei explicitly avoids *\u201clofty language\u201d* about AI\u2019s future to not appear as a \u201cpropagandist\u201d\u301046\u2020L63-L71\u3011. This reflects a broader debate: some argue a bit of **ambitious vision is needed** to drive progress (and funding), while others say **overhyping AGI is dangerous** if it misleads policymakers or distracts from real issues. Gary Marcus and Arthur Mensch, for example, have been policing what they see as \u201creligious\u201d fervor and urging more grounded messaging\u301028\u2020L1-L4\u3011\u301040\u2020L206-L214\u3011. There\u2019s also a geopolitical and business angle \u2013 companies may claim they are close to AGI to signal leadership in the \u201cAI arms race,\u201d possibly influencing investments and policy (as noted by Politico, Altman\u2019s talk of AGI might have *\u201ccontractual\u201d* and financial motivations given OpenAI\u2019s deal with Microsoft that ends at AGI\u301040\u2020L183-L192\u3011\u301040\u2020L221-L229\u3011). On the other hand, those who are too dismissive of AGI risk being seen as lacking imagination or falling behind the curve. **Striking a balance** in communication is a theme: experts increasingly preface their remarks with caveats about uncertainty. Many signatories of **AI open letters in 2023\u20132024** (e.g. calling for AI risk mitigation) explicitly stated they don\u2019t know *when* AGI will come, but that planning should start now due to the high stakes whenever it does.  \n\n- **Opportunities vs. Risks:** Underlying many predictions is a consideration of **what AGI means for humanity** \u2013 and this sometimes colors the timeline estimates. Optimists often highlight potential **benefits**: Dario Amodei speculated that within 5\u201310 years of powerful AI, we could see *\u201cmajor advances in medicine\u2026 cure most diseases\u2026 double human life expectancy.\u201d*\u301046\u2020L55-L63\u3011 Such prospects can make the case for pushing toward AGI faster. Skeptics and risk-conscious experts focus on **threats**: loss of control, misuse by bad actors, or even existential risks. Geoffrey Hinton\u2019s 10-20% doomsday probability\u301035\u2020L0-L8\u3011, and Yoshua Bengio\u2019s insistence on researching alignment *before* we unknowingly stumble into AGI\u301030\u2020L63-L71\u3011\u301032\u2020L138-L147\u3011, reflect that some who think AGI might come relatively soon are very worried about our preparedness. Others, like Andrew Ng, who think AGI is distant, also tend to think current AI risks (bias, misuse, job impacts) deserve more attention than hypothetical future AGI. This creates a **paradoxical situation**: some who believe AGI is near are raising alarms to slow down or align AI development, whereas some who think it\u2019s far feel we shouldn\u2019t be distracted by it. Thus, discussions about *when* AGI will arrive are often entangled with *how* we should handle it \u2013 leading to debates about whether it\u2019s urgent to enact regulations now or focus on shorter-term issues. This mix of excitement and fear is a consistent theme in expert discourse on AGI progress.  \n\n## Comparisons with Past AI Predictions and Advances  \nTo assess the credibility of these 2024\u20132025 predictions, it\u2019s useful to compare them with **past patterns in AI development and previous predictions**:  \n\n- **History of AI Timelines:** Predicting human-level AI has a notorious history of over-optimism. In the 1950s and 60s, pioneers like Herbert Simon and Marvin Minsky speculated that machines might achieve general intelligence within a generation. Those early predictions proved premature \u2013 decades passed with slow progress, leading to periods of disillusionment (\u201cAI winters\u201d). Even into the 2000s, a common expert view was that AGI was *50+ years away* or might never happen. For example, a 2016 survey of AI researchers gave a median estimate of 2050 or later for a 50% chance of AGI. However, **recent breakthroughs have shifted expectations**. The success of deep learning in the 2010s (vision, speech, Go-playing agents) and especially the emergence of GPT-3 (2020) and ChatGPT/GPT-4 (2022\u20132023) **surprised even insiders**, causing many to update their timelines to sooner. Yoshua Bengio admitted ChatGPT\u2019s capabilities arrived *\u201cdecades\u201d* ahead of his prior expectation\u301034\u2020L206-L214\u3011. Geoffrey Hinton moved his estimate for superhuman AI up to possibly ~5 years, whereas earlier he might have thought 20+\u301043\u2020L653-L660\u3011. This pattern \u2013 **big advances causing timeline revisions toward optimism** \u2013 lends some credibility to those now saying AGI by late 2020s isn\u2019t crazy. We have essentially **shortened the forecast window**: an aggregated prediction by one community in early 2024 put a 50% chance of AGI by 2031 (about 7 years earlier than a similar forecast a few years prior)\u301014\u2020L39-L42\u3011. In short, history teaches us two things: (1) Be cautious with exact timelines (many have been wrong before), and (2) **AI progress can be non-linear** \u2013 long plateaus can be followed by rapid leaps thanks to new ideas or scale. The current split opinions reflect these lessons \u2013 some see the recent leap as heralding more leaps soon, others remind that leaps are unpredictable and we could hit a wall.  \n\n- **Track Record of the Experts:** Considering *who* is making each prediction can inform credibility. **Sam Altman and OpenAI** have a stake in positioning themselves as leaders in AGI, which might incline them to optimism (and even to broaden the definition of AGI to declare victory sooner)\u301040\u2020L200-L207\u3011\u301040\u2020L221-L229\u3011. Nonetheless, OpenAI did successfully deliver GPT-4, a model many consider a step change, so their confidence isn\u2019t baseless. **Demis Hassabis** and DeepMind have a strong track record (e.g., AlphaGo, AlphaFold) of solving tough AI problems methodically; his caution (10-year view) might reflect hard-earned realism from encountering the limits of current techniques in projects like self-driving and game agents. **Yann LeCun** has historically downplayed short-term hype (he was skeptical of self-driving being solved quickly, which proved correct) and emphasizes fundamentals. His view that we need new architectures for AGI resonates with the fact that human intelligence involves aspects current AI lacks (like learning with very little data, strong background knowledge, etc.). **Andrew Ng\u2019s** previous analogy about Mars (from 2010s) now looks a bit off \u2013 AGI might not be as distant as he then implied \u2013 but his core argument was to focus on immediate AI applications, and indeed there is still a gap between chatbots and a truly autonomous general AI. **Geoff Hinton** has an impeccable reputation; his shift to openly worrying about AGI and its risks (after leaving Google in 2023) signifies that even veteran experts who once concentrated purely on technical progress are taking the idea of imminent AGI more seriously.  \n\n- **Progress Benchmarks:** We can also compare expert predictions to objective progress on benchmarks. Throughout the 2010s and early 2020s, AI performance on specific tasks (image recognition, translation, reading comprehension, game playing) has grown exponentially, often reaching or exceeding human level\u301032\u2020L175-L183\u3011\u301032\u2020L169-L173\u3011. A recent analysis compiled by Yoshua Bengio shows many AI systems *already surpass human performance in narrow benchmarks* by 2024\u301032\u2020L175-L183\u3011. This supports the notion that if trends continued, a system that combines many of these abilities could be approaching human-level versatility. However, **integrating these abilities** remains challenging \u2013 the best vision model, language model, planning model, etc., are all separate systems. AGI would require unifying them or developing a single architecture that learns and performs across domains. No such system exists yet, but projects like DeepMind\u2019s **Gato** (an agent trained on multiple modalities) or OpenAI\u2019s multimodal GPT-4 are first attempts. Experts citing a **lack of \u201ccommon sense\u201d and \u201ccausal reasoning\u201d** in current AI (e.g., Gary Marcus) point to failures in understanding context or physical reality that today\u2019s models still frequently demonstrate. Every year that those challenges remain unsolved pushes AGI a bit further out. On the other hand, the pace at which *previously unsolved* problems (like protein folding) fell to AI recently is encouraging for optimists. The credibility of a given timeline often hinges on whether one believes a **few missing pieces (memory, planning, etc.) are \u201cminor tweaks\u201d** or **truly fundamental hurdles**. Historically, some hurdles (e.g., vision) turned out easier than expected once the right approach was found, while others (like full dialogue understanding) are proving stubborn. Experts have differing intuitions here, hence their timeline disagreements.  \n\n- **Past False Alarms vs. Current Reality:** There is awareness in the field of previous **false alarms** of \u201calmost-AGI.\u201d For instance, the AI program SHRDLU in 1970 could hold conversations about a blocks world, leading some to proclaim general AI was near \u2013 which it wasn\u2019t. In the 1980s, Japan\u2019s Fifth Generation Computer project hyped AI\u2019s coming of age within that decade, which did not pan out. Even Watson\u2019s victory on *Jeopardy!* in 2011 was hailed as a new era, but Watson proved brittle outside trivia. Given this history, today\u2019s skeptics urge: *this time might not be different* \u2013 ChatGPT is amazing but could still be far from true understanding. Conversely, proponents argue that **deep learning at scale changed the game** in a way nothing before did. Unlike past systems, GPT-4 doesn\u2019t just solve one game or domain; it learned from a huge swath of human knowledge, giving it surprisingly general abilities (coding, composing, logic puzzles to a degree, etc.). This breadth is what leads some to claim it\u2019s a \u201cbaby AGI.\u201d Yann LeCun pushes back on that, calling GPT-4 a brilliant achievement but still **\u201clacking essential pieces\u201d** for full general intelligence\u301016\u2020L127-L135\u3011. The credibility of current AGI predictions can partly be gauged by this: Are today\u2019s AI systems fundamentally new in a way that can scale to AGI (as *optimists assert*), or are they incremental improvements following the same curve as before (as *skeptics contend*)? The truth may lie in between \u2013 they are new enough to warrant closer predictions than the century-away forecasts of old, but perhaps not so revolutionary that AGI is literally just 1\u20132 years from now without further innovation.  \n\nIn summary, when comparing to past experiences, **caution is warranted** with any precise timeline. The range of predictions (from a few years to many decades) itself is telling \u2013 it reflects genuine uncertainty. Many experts have adjusted their timelines to be more optimistic after recent advances, but there remains a healthy respect for the **unknown unknowns** in AI research. The wisest predictions often come with an acknowledgment that **we might be surprised \u2013 for better or worse**. Bengio\u2019s call for humility\u301034\u2020L209-L217\u3011 and Altman\u2019s note that we\u2019ll \u201cmove the goalposts, always\u201d on AGI\u301040\u2020L194-L202\u3011 encapsulate this understanding that **AGI\u2019s arrival may only be clear in hindsight**.\n\n## Conclusion  \nFrom late 2024 into early 2025, the discourse on AGI timelines among top AI researchers and executives reveals a landscape of **divergent viewpoints but also emerging consensus on certain aspects**. Optimists within OpenAI, Anthropic, and some startups foresee early forms of AGI potentially appearing **within this decade (by 2025\u20132027)**, citing the blistering pace of progress and transformative potential of scaling up AI systems. In contrast, distinguished figures at DeepMind, Meta, academia, and other skeptics urge that **human-level AI is likely farther off (2030s or beyond)**, emphasizing the gaps in current technology and the need for multiple breakthrough innovations. Crucially, **both sides agree that the term \u201cAGI\u201d can be slippery** \u2013 they caution that what matters is the capabilities and reliable behavior of AI systems, rather than whether they fit a specific label at a specific time. \n\n**Key points of disagreement** include how soon those missing capabilities (like robust reasoning, memory, and autonomy) will be achieved, and whether current model paradigms can get us the rest of the way. There\u2019s also debate over how to measure progress: some benchmark successes suggest we\u2019re on a continuum heading straight toward AGI, while skeptics point out that *narrow excellence* doesn\u2019t equal general intelligence. Despite differing timelines, experts share a recognition that **AI advances are accelerating** and that we are entering uncharted territory. Many advocate preparing for AGI\u2019s eventual arrival \u2013 whenever it may be \u2013 by investing in alignment, safety research, and thoughtful policy today, echoing the sentiment that *\u201cwe live in very uncertain times\u201d*\u301043\u2020L653-L660\u3011 regarding AI development.\n\nIn comparing today\u2019s predictions with the past, it\u2019s evident that **AI\u2019s credibility has grown** \u2013 systems like GPT-4 and AlphaGo would have seemed like science fiction not long ago. This lends some weight to shorter-term forecasts that might have once been dismissed. However, history also warns that **AI is complex and often harder than it looks**; breakthroughs can stall unexpectedly, and intelligence has facets we don\u2019t yet know how to replicate. Thus, the prudent view \u2013 shared implicitly by many experts \u2013 is to **expect the unexpected**. AGI could come sooner than the skeptics think, or later than the optimists hope. \n\nThe **balanced takeaway** is that **AGI is a realistic goal on the horizon**, but the exact distance to it remains a subject of debate. The period of 2024\u20132025 has seen both excitement and pump brakes: excitement that we may be on the cusp of something historic, and caution to not declare victory prematurely. Whether AGI arrives in five years or fifty, the discussions by today\u2019s leading minds help society gauge how to **navigate the promises and perils** of the final stretch toward truly general AI. Keeping an open mind \u2013 as well as a critical eye \u2013 will be essential as we watch these expert predictions be tested by events in the coming years. Each incremental advance (or setback) in AI will likely shift the consensus, but as of early 2025, the only certainty is that **the race toward AGI is on**, with the finish line still indistinct and hotly debated.  \n\n## Sources  \n\n- Altman, Sam \u2013 *NYT DealBook Summit*, Dec 2024 (as quoted in Brave New Coin)\u30103\u2020L61-L68\u3011; *Business Insider* interview, Nov 2024\u301018\u2020L288-L297\u3011; Altman\u2019s personal blog, Jan 2025\u301049\u2020L147-L155\u3011.  \n- Hassabis, Demis \u2013 *The Times Tech Summit*, Oct 2024 (coverage by Business Insider)\u301013\u2020L317-L321\u3011; Reddit summary of Hassabis interview, 2024\u301043\u2020L659-L662\u3011.  \n- LeCun, Yann \u2013 Johns Hopkins Bloomberg Center panel, Dec 2024\u301016\u2020L123-L131\u3011; World Economic Forum & Lex Fridman podcast remarks, Jan\u2013Mar 2024\u301043\u2020L688-L696\u3011\u301043\u2020L695-L702\u3011.  \n- Ng, Andrew \u2013 AI community discussions, Aug\u2013Sep 2024\u301043\u2020L669-L672\u3011 (also widely quoted on social media: \u201cmany decades away\u201d).  \n- Sutskever, Ilya \u2013 Reuters interview, Nov 2024\u301021\u2020L195-L203\u3011; various public comments 2023\u20132024\u301017\u2020L37-L40\u3011.  \n- Amodei, Dario \u2013 Anthropic essay, Oct 2024\u301046\u2020L53-L60\u3011 (reported by The Decoder).  \n- Socher, Richard \u2013 Business Insider interview, 2023 (summarized on Reddit)\u301043\u2020L674-L682\u3011.  \n- Hinton, Geoffrey \u2013 Personal post on X (Twitter), 2022\u301043\u2020L653-L660\u3011; Guardian interview, 2023\u301035\u2020L0-L8\u3011.  \n- Bengio, Yoshua \u2013 *Yoshua Bengio\u2019s blog*, Jul 2024\u301034\u2020L206-L214\u3011\u301034\u2020L209-L217\u3011.  \n- Marcus, Gary \u2013 *Politico*, Jan 2025\u301040\u2020L206-L214\u3011; personal Substack and interviews, 2024.  \n- Mensch, Arthur \u2013 *Fortune* interview, Dec 2024 (quoted in Europragmatist)\u301028\u2020L1-L4\u3011.  \n- Etzioni, Oren \u2013 *Business Insider*, Nov 2024\u301018\u2020L300-L308\u3011.  \n- Brown, Noam \u2013 *NeurIPS conference*, 2024 (via Business Insider)\u301019\u2020L1-L4\u3011.  \n- **Additional context:** Reuters report on AI scaling limits\u301021\u2020L195-L203\u3011; Politico analysis of OpenAI\u2019s AGI definition and Microsoft deal\u301040\u2020L183-L192\u3011\u301040\u2020L194-L202\u3011; Business Insider \u201cAGI predictions looking stretched\u201d analysis\u301018\u2020L294-L303\u3011\u301018\u2020L300-L308\u3011; Yoshua Bengio\u2019s compilation of AI benchmark progress\u301032\u2020L175-L183\u3011."]},"status":"finished_successfully","end_turn":true,"weight":1.0,"metadata":{"citations":[{"start_ix":1355,"end_ix":1366,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":1575,"end_ix":1586,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":1756,"end_ix":1770,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":1986,"end_ix":2000,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Reflections - Sam Altman","url":"https://blog.samaltman.com/reflections#:~:text=We%20are%20now%20confident%20we,distributed%20outcomes","text":"We are now confident we know how to build AGI as we have traditionally understood it. We believe that, in 2025, we may see the first AI agents \u201cjoin the workforce\u201d and materially change the output of companies. We continue to believe that iteratively putting great tools in the hands of people leads to great, broadly-distributed outcomes.","pub_date":null,"extra":{"cited_message_idx":49,"search_result_idx":null,"evidence_text":"","start_line_num":147,"end_line_num":155},"og_tags":null}},{"start_ix":2419,"end_ix":2431,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":2590,"end_ix":2604,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":2896,"end_ix":2908,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":3410,"end_ix":3422,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Anthropic CEO thinks AGI in 2026 is possible, but says it could take much longer","url":"https://the-decoder.com/anthropic-ceo-thinks-agi-in-2026-is-possible-but-says-it-could-take-much-longer/#:~:text=While%20acknowledging%20significant%20uncertainties%2C%20Amodei,too%2C%20has%20no%20clear%20timeline","text":"While acknowledging significant uncertainties, Amodei suggests that extremely capable AI systems, which some might call \"AGI,\" could emerge as early as 2026. He cautions, however, that it could take \"much longer\" - effectively admitting that he, too, has no clear timeline.","pub_date":null,"extra":{"cited_message_idx":46,"search_result_idx":null,"evidence_text":"","start_line_num":53,"end_line_num":60},"og_tags":null}},{"start_ix":3607,"end_ix":3619,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Anthropic CEO thinks AGI in 2026 is possible, but says it could take much longer","url":"https://the-decoder.com/anthropic-ceo-thinks-agi-in-2026-is-possible-but-says-it-could-take-much-longer/#:~:text=While%20acknowledging%20significant%20uncertainties%2C%20Amodei,too%2C%20has%20no%20clear%20timeline","text":"While acknowledging significant uncertainties, Amodei suggests that extremely capable AI systems, which some might call \"AGI,\" could emerge as early as 2026. He cautions, however, that it could take \"much longer\" - effectively admitting that he, too, has no clear timeline.","pub_date":null,"extra":{"cited_message_idx":46,"search_result_idx":null,"evidence_text":"","start_line_num":53,"end_line_num":60},"og_tags":null}},{"start_ix":3843,"end_ix":3855,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Anthropic CEO thinks AGI in 2026 is possible, but says it could take much longer","url":"https://the-decoder.com/anthropic-ceo-thinks-agi-in-2026-is-possible-but-says-it-could-take-much-longer/#:~:text=Avoiding%20grandiosity","text":"Avoiding grandiosity","pub_date":null,"extra":{"cited_message_idx":46,"search_result_idx":null,"evidence_text":"","start_line_num":63,"end_line_num":71},"og_tags":null}},{"start_ix":4348,"end_ix":4362,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How far we are from AGI, according to the people developing it : r/singularity","url":"https://www.reddit.com/r/singularity/comments/1go8zd7/how_far_we_are_from_agi_according_to_the_people/#:~:text=Richard%20Socher%20Richard%20Socher%2C%20a,in%20three%20to%20five%20years","text":"Richard Socher Richard Socher, a former Salesforce executive who is now the CEO of AI-powered search engine You.com, says there are two ways to define AGI. \"There's a simple economic one, which is 80% of the jobs will be automated with AI, and then we can call it AGI,\" he previously told Business Insider. He predicted we'll get there in three to five years.","pub_date":null,"extra":{"cited_message_idx":43,"search_result_idx":null,"evidence_text":"","start_line_num":674,"end_line_num":682},"og_tags":null}},{"start_ix":4644,"end_ix":4658,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How far we are from AGI, according to the people developing it : r/singularity","url":"https://www.reddit.com/r/singularity/comments/1go8zd7/how_far_we_are_from_agi_according_to_the_people/#:~:text=search%20engine%20You,in%20three%20to%20five%20years","text":"search engine You.com, says there are two ways to define AGI. \"There's a simple economic one, which is 80% of the jobs will be automated with AI, and then we can call it AGI,\" he previously told Business Insider. He predicted we'll get there in three to five years.","pub_date":null,"extra":{"cited_message_idx":43,"search_result_idx":null,"evidence_text":"","start_line_num":676,"end_line_num":684},"og_tags":null}},{"start_ix":5133,"end_ix":5147,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How far we are from AGI, according to the people developing it : r/singularity","url":"https://www.reddit.com/r/singularity/comments/1go8zd7/how_far_we_are_from_agi_according_to_the_people/#:~:text=AI%20godfather%20Geoffrey%20Hinton%20believes,as%20little%20as%20five%20years","text":"AI godfather Geoffrey Hinton believes that we might see AI that's smarter than humans in as little as five years.","pub_date":null,"extra":{"cited_message_idx":43,"search_result_idx":null,"evidence_text":"","start_line_num":653,"end_line_num":660},"og_tags":null}},{"start_ix":5292,"end_ix":5302,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":5747,"end_ix":5758,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":6588,"end_ix":6599,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":6599,"end_ix":6610,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":7155,"end_ix":7169,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How far we are from AGI, according to the people developing it : r/singularity","url":"https://www.reddit.com/r/singularity/comments/1go8zd7/how_far_we_are_from_agi_according_to_the_people/#:~:text=Demis%20Hassabis%20Demis%20Hassabis%2C%20the,a%20decade%20away%2C%20at%20least","text":"Demis Hassabis Demis Hassabis, the CEO of Google DeepMind and a recently minted Nobel laureate, believes that an AI that can reason as well as humans is still a decade away, at least.","pub_date":null,"extra":{"cited_message_idx":43,"search_result_idx":null,"evidence_text":"","start_line_num":659,"end_line_num":662},"og_tags":null}},{"start_ix":7381,"end_ix":7395,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":7395,"end_ix":7409,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"DeepMind CEO Demis Hassabis Explains What Has to Happen to Achieve AGI - Business Insider","url":"https://www.businessinsider.com/deepmind-ceo-demis-hassabis-agi-aiagents-chatgpt-gemini-2024-10#:~:text=,robots%20in%20the%20physical%20world","text":"* Planning. These systems can think ahead, plan a trip, or book tickets. * Acting. They need to be able to take action in the real world. * Reasoning. They should think through problems. Hassabis pointed to AlphaGo, DeepMind's AI that first defeated humans in Go, demonstrating reasoning skills in the game's defined domain. The next phase of agent-based systems will apply these skills to real-world contexts. * Better Memory. They should remember the details they've been told. * Better Personalization. They should understand a user's preferences, likes, and dislikes. * Using tools. They can use hardware like robots in the physical world,","pub_date":null,"extra":{"cited_message_idx":13,"search_result_idx":null,"evidence_text":"","start_line_num":307,"end_line_num":316},"og_tags":null}},{"start_ix":7654,"end_ix":7668,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"DeepMind CEO Demis Hassabis Explains What Has to Happen to Achieve AGI - Business Insider","url":"https://www.businessinsider.com/deepmind-ceo-demis-hassabis-agi-aiagents-chatgpt-gemini-2024-10#:~:text=software%20like%20a%20calculator%2C%20or,even%20other%20AI%20systems","text":"software like a calculator, or even other AI systems.","pub_date":null,"extra":{"cited_message_idx":13,"search_result_idx":null,"evidence_text":"","start_line_num":317,"end_line_num":321},"og_tags":null}},{"start_ix":8383,"end_ix":8397,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How far we are from AGI, according to the people developing it : r/singularity","url":"https://www.reddit.com/r/singularity/comments/1go8zd7/how_far_we_are_from_agi_according_to_the_people/#:~:text=Meta%27s%20chief%20AI%20scientist%2C%20Yann,we%27ll%20see%20AGI%20anytime%20soon","text":"Meta's chief AI scientist, Yann LeCun, doesn't believe we'll see AGI anytime soon.","pub_date":null,"extra":{"cited_message_idx":43,"search_result_idx":null,"evidence_text":"","start_line_num":688,"end_line_num":696},"og_tags":null}},{"start_ix":8810,"end_ix":8824,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":8824,"end_ix":8838,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":8982,"end_ix":8996,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How far we are from AGI, according to the people developing it : r/singularity","url":"https://www.reddit.com/r/singularity/comments/1go8zd7/how_far_we_are_from_agi_according_to_the_people/#:~:text=And%20LeCun%20says%20we%20shouldn%27t,arrive%20as%20a%20single%20event","text":"And LeCun says we shouldn't expect it to arrive as a single event.","pub_date":null,"extra":{"cited_message_idx":43,"search_result_idx":null,"evidence_text":"","start_line_num":695,"end_line_num":702},"og_tags":null}},{"start_ix":9890,"end_ix":9900,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"\u1d05\u1d00\u0274\u026a\u1d07\u029f \u1d0d\u026a\u1d07ss\u029f\u1d07\u0280 on X: \"One of my great awakenings of the ...","url":"https://twitter.com/DanielMiessler/status/1830683026919170324#:~:text=Sep%201%2C%202024,it%20is%20only%20a","text":"Sep 1, 2024. Machine learning pioneer Andrew Ng says AGI is still \"many decades away, maybe even longer\" and companies that say it is only a ...","pub_date":null,"extra":{"cited_message_idx":38,"search_result_idx":null,"evidence_text":"","start_line_num":1,"end_line_num":9},"og_tags":null}},{"start_ix":10290,"end_ix":10304,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How far we are from AGI, according to the people developing it : r/singularity","url":"https://www.reddit.com/r/singularity/comments/1go8zd7/how_far_we_are_from_agi_according_to_the_people/#:~:text=And%20he%27s%20not%20convinced%20we%27ll,that%20claim%20AGI%20is%20imminent","text":"And he's not convinced we'll get there soon. \"I hope we get there in our lifetime, but I'm not sure,\" he said, adding that people should be skeptical of companies that claim AGI is imminent.","pub_date":null,"extra":{"cited_message_idx":43,"search_result_idx":null,"evidence_text":"","start_line_num":669,"end_line_num":672},"og_tags":null}},{"start_ix":11183,"end_ix":11197,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":11376,"end_ix":11390,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":11504,"end_ix":11518,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":12495,"end_ix":12509,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"What AGI hype means for Washington - POLITICO","url":"https://www.politico.com/newsletters/digital-future-daily/2025/01/08/what-agi-hype-means-for-washington-00197154#:~:text=Gary%20Marcus%2C%20an%20outspoken%20AI,has%20changed%20to%20resolve%20remaining","text":"Gary Marcus, an outspoken AI skeptic, has called out how OpenAI and developers keep shifting what they consider AGI. Other AI experts quickly noted that the language in Altman\u2019s bold declaration was carefully couched, raising uncertainties about whether simply knowing how to build AGI would be enough to actually create it (let alone create it responsibly). As Alamir Novin, a University of South Carolina professor and AI researcher, pointed out, \u201che\u2019s not saying we have built AGI, or even if we can really have a clear path towards it.\u201d It doesn\u2019t tell us what, if anything, has changed to resolve remaining","pub_date":null,"extra":{"cited_message_idx":40,"search_result_idx":null,"evidence_text":"","start_line_num":206,"end_line_num":214},"og_tags":null}},{"start_ix":12732,"end_ix":12746,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"What AGI hype means for Washington - POLITICO","url":"https://www.politico.com/newsletters/digital-future-daily/2025/01/08/what-agi-hype-means-for-washington-00197154#:~:text=Altman%20himself%2C%20in%20an%20interview,%E2%80%9D","text":"Altman himself, in an interview with Businessweek that inspired his blog reflections, admitted that pinpointing exactly when his company will reach AGI is tough because \u201cwe\u2019re going to move the goalposts, always.\u201d When asked why OpenAI (but not Altman himself) has stopped publicly discussing AGI, he explained that it became \u201ca very sloppy term.\u201d","pub_date":null,"extra":{"cited_message_idx":40,"search_result_idx":null,"evidence_text":"","start_line_num":194,"end_line_num":202},"og_tags":null}},{"start_ix":12746,"end_ix":12760,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"What AGI hype means for Washington - POLITICO","url":"https://www.politico.com/newsletters/digital-future-daily/2025/01/08/what-agi-hype-means-for-washington-00197154#:~:text=Gary%20Marcus%2C%20an%20outspoken%20AI,has%20changed%20to%20resolve%20remaining","text":"Gary Marcus, an outspoken AI skeptic, has called out how OpenAI and developers keep shifting what they consider AGI. Other AI experts quickly noted that the language in Altman\u2019s bold declaration was carefully couched, raising uncertainties about whether simply knowing how to build AGI would be enough to actually create it (let alone create it responsibly). As Alamir Novin, a University of South Carolina professor and AI researcher, pointed out, \u201che\u2019s not saying we have built AGI, or even if we can really have a clear path towards it.\u201d It doesn\u2019t tell us what, if anything, has changed to resolve remaining","pub_date":null,"extra":{"cited_message_idx":40,"search_result_idx":null,"evidence_text":"","start_line_num":206,"end_line_num":214},"og_tags":null}},{"start_ix":12926,"end_ix":12940,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"What AGI hype means for Washington - POLITICO","url":"https://www.politico.com/newsletters/digital-future-daily/2025/01/08/what-agi-hype-means-for-washington-00197154#:~:text=And%20as%20a%20business%20proposition%2C,the%20company%20and%20Altman%20himself","text":"And as a business proposition, it\u2019s significant to the company for a very specific reason: Microsoft holds an exclusive cloud deal granting it access to OpenAI\u2019s technology, which ends once AGI is achieved. Should OpenAI\u2019s products indeed cross the threshold to AGI, it would unlock obvious financial rewards for the company and Altman himself.","pub_date":null,"extra":{"cited_message_idx":40,"search_result_idx":null,"evidence_text":"","start_line_num":183,"end_line_num":192},"og_tags":null}},{"start_ix":12940,"end_ix":12954,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"What AGI hype means for Washington - POLITICO","url":"https://www.politico.com/newsletters/digital-future-daily/2025/01/08/what-agi-hype-means-for-washington-00197154#:~:text=%E2%80%9CIt%E2%80%99s%20lazy%20and%20misleading%2C%E2%80%9D%20he,%E2%80%9D","text":"\u201cIt\u2019s lazy and misleading,\u201d he told DFD, saying he\u2019s found that definitions for AGI are either overly broad, fail to recognize human ability as just a fraction of the technology\u2019s potential, or simply incoherent and unhelpful. \u201cI think Sam Altman is literally saying this because it\u2019s a contractual meaning in this contract with Microsoft that is worth many billion dollars.\u201d","pub_date":null,"extra":{"cited_message_idx":40,"search_result_idx":null,"evidence_text":"","start_line_num":221,"end_line_num":229},"og_tags":null}},{"start_ix":13113,"end_ix":13123,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"In 2022 Gary Marcus was 50% sure that AGI wouldn't happen by ...","url":"https://www.reddit.com/r/LocalLLaMA/comments/1hprsyv/in_2022_gary_marcus_was_50_sure_that_agi_wouldnt/#:~:text=In%202022%20Gary%20Marcus%20was,You%20can%20read%20it%20here","text":"In 2022 Gary Marcus was 50% sure that AGI wouldn't happen by ... In 2024, he bet that we wouldn't get ASI by 2027 and gave a list of 11 things he thought would indicate ASI. The new bet. You can read it here.","pub_date":null,"extra":{"cited_message_idx":39,"search_result_idx":null,"evidence_text":"","start_line_num":0,"end_line_num":8},"og_tags":null}},{"start_ix":13825,"end_ix":13835,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Caf\u00e9 Europa - A very French Revolution: How Mistral AI is taking on the big guys","url":"https://www.europragmatist.com/p/a-very-french-revolution#:~:text=%2A%20,I%20don%E2%80%99t%20believe%20in%20AGI","text":"* \"God Complex\" Criticism \u26ea\ufe0f: Mensch has called the obsession with AI outsmarting humans as a \"very religious\" fascination, stating \"The whole AGI rhetoric is about creating God\u2026 I don\u2019t believe in God. I\u2019m a strong atheist. So I don\u2019t believe in AGI.\"","pub_date":null,"extra":{"cited_message_idx":28,"search_result_idx":null,"evidence_text":"","start_line_num":1,"end_line_num":4},"og_tags":null}},{"start_ix":14061,"end_ix":14072,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":14672,"end_ix":14686,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":14849,"end_ix":14863,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":15062,"end_ix":15072,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Those Bold AGI Predictions Are Suddenly Looking Stretched - Business Insider","url":"https://www.businessinsider.com/agi-predictions-looking-stretched-openai-sam-altman-google-ai-2024-11#:~:text=,said%20at%20a%20recent%20conference","text":"* OpenAI cofounder Ilya Sutskever told Reuters that results from scaling up AI models like this have plateaued. * \"At some point, the scaling paradigm breaks down,\" OpenAI researcher Noam Brown said at a recent conference.","pub_date":null,"extra":{"cited_message_idx":19,"search_result_idx":null,"evidence_text":"","start_line_num":1,"end_line_num":4},"og_tags":null}},{"start_ix":16406,"end_ix":16420,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":16631,"end_ix":16641,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Those Bold AGI Predictions Are Suddenly Looking Stretched - Business Insider","url":"https://www.businessinsider.com/agi-predictions-looking-stretched-openai-sam-altman-google-ai-2024-11#:~:text=,said%20at%20a%20recent%20conference","text":"* OpenAI cofounder Ilya Sutskever told Reuters that results from scaling up AI models like this have plateaued. * \"At some point, the scaling paradigm breaks down,\" OpenAI researcher Noam Brown said at a recent conference.","pub_date":null,"extra":{"cited_message_idx":19,"search_result_idx":null,"evidence_text":"","start_line_num":1,"end_line_num":4},"og_tags":null}},{"start_ix":16845,"end_ix":16859,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":17076,"end_ix":17090,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":17235,"end_ix":17249,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":17913,"end_ix":17927,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"What AGI hype means for Washington - POLITICO","url":"https://www.politico.com/newsletters/digital-future-daily/2025/01/08/what-agi-hype-means-for-washington-00197154#:~:text=Altman%20himself%2C%20in%20an%20interview,%E2%80%9D","text":"Altman himself, in an interview with Businessweek that inspired his blog reflections, admitted that pinpointing exactly when his company will reach AGI is tough because \u201cwe\u2019re going to move the goalposts, always.\u201d When asked why OpenAI (but not Altman himself) has stopped publicly discussing AGI, he explained that it became \u201ca very sloppy term.\u201d","pub_date":null,"extra":{"cited_message_idx":40,"search_result_idx":null,"evidence_text":"","start_line_num":194,"end_line_num":202},"og_tags":null}},{"start_ix":18072,"end_ix":18083,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":18225,"end_ix":18239,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"What AGI hype means for Washington - POLITICO","url":"https://www.politico.com/newsletters/digital-future-daily/2025/01/08/what-agi-hype-means-for-washington-00197154#:~:text=Gary%20Marcus%2C%20an%20outspoken%20AI,has%20changed%20to%20resolve%20remaining","text":"Gary Marcus, an outspoken AI skeptic, has called out how OpenAI and developers keep shifting what they consider AGI. Other AI experts quickly noted that the language in Altman\u2019s bold declaration was carefully couched, raising uncertainties about whether simply knowing how to build AGI would be enough to actually create it (let alone create it responsibly). As Alamir Novin, a University of South Carolina professor and AI researcher, pointed out, \u201che\u2019s not saying we have built AGI, or even if we can really have a clear path towards it.\u201d It doesn\u2019t tell us what, if anything, has changed to resolve remaining","pub_date":null,"extra":{"cited_message_idx":40,"search_result_idx":null,"evidence_text":"","start_line_num":206,"end_line_num":214},"og_tags":null}},{"start_ix":18553,"end_ix":18567,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"What AGI hype means for Washington - POLITICO","url":"https://www.politico.com/newsletters/digital-future-daily/2025/01/08/what-agi-hype-means-for-washington-00197154#:~:text=Julian%20Togelius%2C%20an%20associate%20professor,stop%20using%20the%20term%20altogether","text":"Julian Togelius, an associate professor at New York University who works on artificial intelligence, wrote a whole book about AGI in which he spent a lot of time trying to figure out what it meant \u2014 and came to the conclusion that people should stop using the term altogether.","pub_date":null,"extra":{"cited_message_idx":40,"search_result_idx":null,"evidence_text":"","start_line_num":217,"end_line_num":225},"og_tags":null}},{"start_ix":18682,"end_ix":18696,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How far we are from AGI, according to the people developing it : r/singularity","url":"https://www.reddit.com/r/singularity/comments/1go8zd7/how_far_we_are_from_agi_according_to_the_people/#:~:text=Richard%20Socher%20Richard%20Socher%2C%20a,in%20three%20to%20five%20years","text":"Richard Socher Richard Socher, a former Salesforce executive who is now the CEO of AI-powered search engine You.com, says there are two ways to define AGI. \"There's a simple economic one, which is 80% of the jobs will be automated with AI, and then we can call it AGI,\" he previously told Business Insider. He predicted we'll get there in three to five years.","pub_date":null,"extra":{"cited_message_idx":43,"search_result_idx":null,"evidence_text":"","start_line_num":674,"end_line_num":682},"og_tags":null}},{"start_ix":19817,"end_ix":19831,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How far we are from AGI, according to the people developing it : r/singularity","url":"https://www.reddit.com/r/singularity/comments/1go8zd7/how_far_we_are_from_agi_according_to_the_people/#:~:text=And%20LeCun%20says%20we%20shouldn%27t,arrive%20as%20a%20single%20event","text":"And LeCun says we shouldn't expect it to arrive as a single event.","pub_date":null,"extra":{"cited_message_idx":43,"search_result_idx":null,"evidence_text":"","start_line_num":695,"end_line_num":702},"og_tags":null}},{"start_ix":20014,"end_ix":20025,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":21110,"end_ix":21124,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":22204,"end_ix":22218,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":22218,"end_ix":22232,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"DeepMind CEO Demis Hassabis Explains What Has to Happen to Achieve AGI - Business Insider","url":"https://www.businessinsider.com/deepmind-ceo-demis-hassabis-agi-aiagents-chatgpt-gemini-2024-10#:~:text=software%20like%20a%20calculator%2C%20or,even%20other%20AI%20systems","text":"software like a calculator, or even other AI systems.","pub_date":null,"extra":{"cited_message_idx":13,"search_result_idx":null,"evidence_text":"","start_line_num":317,"end_line_num":321},"og_tags":null}},{"start_ix":22527,"end_ix":22541,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Reflections - Sam Altman","url":"https://blog.samaltman.com/reflections#:~:text=We%20are%20now%20confident%20we,distributed%20outcomes","text":"We are now confident we know how to build AGI as we have traditionally understood it. We believe that, in 2025, we may see the first AI agents \u201cjoin the workforce\u201d and materially change the output of companies. We continue to believe that iteratively putting great tools in the hands of people leads to great, broadly-distributed outcomes.","pub_date":null,"extra":{"cited_message_idx":49,"search_result_idx":null,"evidence_text":"","start_line_num":147,"end_line_num":155},"og_tags":null}},{"start_ix":22749,"end_ix":22761,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Anthropic CEO thinks AGI in 2026 is possible, but says it could take much longer","url":"https://the-decoder.com/anthropic-ceo-thinks-agi-in-2026-is-possible-but-says-it-could-take-much-longer/#:~:text=Avoiding%20grandiosity","text":"Avoiding grandiosity","pub_date":null,"extra":{"cited_message_idx":46,"search_result_idx":null,"evidence_text":"","start_line_num":63,"end_line_num":71},"og_tags":null}},{"start_ix":23120,"end_ix":23130,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Caf\u00e9 Europa - A very French Revolution: How Mistral AI is taking on the big guys","url":"https://www.europragmatist.com/p/a-very-french-revolution#:~:text=%2A%20,I%20don%E2%80%99t%20believe%20in%20AGI","text":"* \"God Complex\" Criticism \u26ea\ufe0f: Mensch has called the obsession with AI outsmarting humans as a \"very religious\" fascination, stating \"The whole AGI rhetoric is about creating God\u2026 I don\u2019t believe in God. I\u2019m a strong atheist. So I don\u2019t believe in AGI.\"","pub_date":null,"extra":{"cited_message_idx":28,"search_result_idx":null,"evidence_text":"","start_line_num":1,"end_line_num":4},"og_tags":null}},{"start_ix":23130,"end_ix":23144,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"What AGI hype means for Washington - POLITICO","url":"https://www.politico.com/newsletters/digital-future-daily/2025/01/08/what-agi-hype-means-for-washington-00197154#:~:text=Gary%20Marcus%2C%20an%20outspoken%20AI,has%20changed%20to%20resolve%20remaining","text":"Gary Marcus, an outspoken AI skeptic, has called out how OpenAI and developers keep shifting what they consider AGI. Other AI experts quickly noted that the language in Altman\u2019s bold declaration was carefully couched, raising uncertainties about whether simply knowing how to build AGI would be enough to actually create it (let alone create it responsibly). As Alamir Novin, a University of South Carolina professor and AI researcher, pointed out, \u201che\u2019s not saying we have built AGI, or even if we can really have a clear path towards it.\u201d It doesn\u2019t tell us what, if anything, has changed to resolve remaining","pub_date":null,"extra":{"cited_message_idx":40,"search_result_idx":null,"evidence_text":"","start_line_num":206,"end_line_num":214},"og_tags":null}},{"start_ix":23473,"end_ix":23487,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"What AGI hype means for Washington - POLITICO","url":"https://www.politico.com/newsletters/digital-future-daily/2025/01/08/what-agi-hype-means-for-washington-00197154#:~:text=And%20as%20a%20business%20proposition%2C,the%20company%20and%20Altman%20himself","text":"And as a business proposition, it\u2019s significant to the company for a very specific reason: Microsoft holds an exclusive cloud deal granting it access to OpenAI\u2019s technology, which ends once AGI is achieved. Should OpenAI\u2019s products indeed cross the threshold to AGI, it would unlock obvious financial rewards for the company and Altman himself.","pub_date":null,"extra":{"cited_message_idx":40,"search_result_idx":null,"evidence_text":"","start_line_num":183,"end_line_num":192},"og_tags":null}},{"start_ix":23487,"end_ix":23501,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"What AGI hype means for Washington - POLITICO","url":"https://www.politico.com/newsletters/digital-future-daily/2025/01/08/what-agi-hype-means-for-washington-00197154#:~:text=%E2%80%9CIt%E2%80%99s%20lazy%20and%20misleading%2C%E2%80%9D%20he,%E2%80%9D","text":"\u201cIt\u2019s lazy and misleading,\u201d he told DFD, saying he\u2019s found that definitions for AGI are either overly broad, fail to recognize human ability as just a fraction of the technology\u2019s potential, or simply incoherent and unhelpful. \u201cI think Sam Altman is literally saying this because it\u2019s a contractual meaning in this contract with Microsoft that is worth many billion dollars.\u201d","pub_date":null,"extra":{"cited_message_idx":40,"search_result_idx":null,"evidence_text":"","start_line_num":221,"end_line_num":229},"og_tags":null}},{"start_ix":24352,"end_ix":24364,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Anthropic CEO thinks AGI in 2026 is possible, but says it could take much longer","url":"https://the-decoder.com/anthropic-ceo-thinks-agi-in-2026-is-possible-but-says-it-could-take-much-longer/#:~:text=call%20,too%2C%20has%20no%20clear%20timeline","text":"call \"AGI,\" could emerge as early as 2026. He cautions, however, that it could take \"much longer\" - effectively admitting that he, too, has no clear timeline.","pub_date":null,"extra":{"cited_message_idx":46,"search_result_idx":null,"evidence_text":"","start_line_num":55,"end_line_num":63},"og_tags":null}},{"start_ix":24598,"end_ix":24608,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":24706,"end_ix":24718,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":24718,"end_ix":24732,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":26686,"end_ix":26700,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":26821,"end_ix":26835,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How far we are from AGI, according to the people developing it : r/singularity","url":"https://www.reddit.com/r/singularity/comments/1go8zd7/how_far_we_are_from_agi_according_to_the_people/#:~:text=AI%20godfather%20Geoffrey%20Hinton%20believes,as%20little%20as%20five%20years","text":"AI godfather Geoffrey Hinton believes that we might see AI that's smarter than humans in as little as five years.","pub_date":null,"extra":{"cited_message_idx":43,"search_result_idx":null,"evidence_text":"","start_line_num":653,"end_line_num":660},"og_tags":null}},{"start_ix":27196,"end_ix":27208,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":27908,"end_ix":27922,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"What AGI hype means for Washington - POLITICO","url":"https://www.politico.com/newsletters/digital-future-daily/2025/01/08/what-agi-hype-means-for-washington-00197154#:~:text=The%20company%20uses%20a%20,dispute%20what%E2%80%99s%20AGI%20or%20not","text":"The company uses a  five-level scale to track progress toward human-level problem-solving \u2014 and Altman pointed out that for all of them, \u201cyou can find people that would call each of those AGI.\u201d The goal, Altman said, has been to give clearer updates on progress, not dispute what\u2019s AGI or not.","pub_date":null,"extra":{"cited_message_idx":40,"search_result_idx":null,"evidence_text":"","start_line_num":200,"end_line_num":207},"og_tags":null}},{"start_ix":27922,"end_ix":27936,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"What AGI hype means for Washington - POLITICO","url":"https://www.politico.com/newsletters/digital-future-daily/2025/01/08/what-agi-hype-means-for-washington-00197154#:~:text=%E2%80%9CIt%E2%80%99s%20lazy%20and%20misleading%2C%E2%80%9D%20he,%E2%80%9D","text":"\u201cIt\u2019s lazy and misleading,\u201d he told DFD, saying he\u2019s found that definitions for AGI are either overly broad, fail to recognize human ability as just a fraction of the technology\u2019s potential, or simply incoherent and unhelpful. \u201cI think Sam Altman is literally saying this because it\u2019s a contractual meaning in this contract with Microsoft that is worth many billion dollars.\u201d","pub_date":null,"extra":{"cited_message_idx":40,"search_result_idx":null,"evidence_text":"","start_line_num":221,"end_line_num":229},"og_tags":null}},{"start_ix":29579,"end_ix":29593,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":29593,"end_ix":29607,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":29739,"end_ix":29753,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":32360,"end_ix":32374,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":33393,"end_ix":33407,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":33472,"end_ix":33486,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"What AGI hype means for Washington - POLITICO","url":"https://www.politico.com/newsletters/digital-future-daily/2025/01/08/what-agi-hype-means-for-washington-00197154#:~:text=Altman%20himself%2C%20in%20an%20interview,%E2%80%9D","text":"Altman himself, in an interview with Businessweek that inspired his blog reflections, admitted that pinpointing exactly when his company will reach AGI is tough because \u201cwe\u2019re going to move the goalposts, always.\u201d When asked why OpenAI (but not Altman himself) has stopped publicly discussing AGI, he explained that it became \u201ca very sloppy term.\u201d","pub_date":null,"extra":{"cited_message_idx":40,"search_result_idx":null,"evidence_text":"","start_line_num":194,"end_line_num":202},"og_tags":null}},{"start_ix":35275,"end_ix":35289,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How far we are from AGI, according to the people developing it : r/singularity","url":"https://www.reddit.com/r/singularity/comments/1go8zd7/how_far_we_are_from_agi_according_to_the_people/#:~:text=AI%20godfather%20Geoffrey%20Hinton%20believes,as%20little%20as%20five%20years","text":"AI godfather Geoffrey Hinton believes that we might see AI that's smarter than humans in as little as five years.","pub_date":null,"extra":{"cited_message_idx":43,"search_result_idx":null,"evidence_text":"","start_line_num":653,"end_line_num":660},"og_tags":null}},{"start_ix":36908,"end_ix":36919,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":36959,"end_ix":36973,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":37007,"end_ix":37021,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Reflections - Sam Altman","url":"https://blog.samaltman.com/reflections#:~:text=We%20are%20now%20confident%20we,distributed%20outcomes","text":"We are now confident we know how to build AGI as we have traditionally understood it. We believe that, in 2025, we may see the first AI agents \u201cjoin the workforce\u201d and materially change the output of companies. We continue to believe that iteratively putting great tools in the hands of people leads to great, broadly-distributed outcomes.","pub_date":null,"extra":{"cited_message_idx":49,"search_result_idx":null,"evidence_text":"","start_line_num":147,"end_line_num":155},"og_tags":null}},{"start_ix":37109,"end_ix":37123,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"DeepMind CEO Demis Hassabis Explains What Has to Happen to Achieve AGI - Business Insider","url":"https://www.businessinsider.com/deepmind-ceo-demis-hassabis-agi-aiagents-chatgpt-gemini-2024-10#:~:text=software%20like%20a%20calculator%2C%20or,even%20other%20AI%20systems","text":"software like a calculator, or even other AI systems.","pub_date":null,"extra":{"cited_message_idx":13,"search_result_idx":null,"evidence_text":"","start_line_num":317,"end_line_num":321},"og_tags":null}},{"start_ix":37167,"end_ix":37181,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How far we are from AGI, according to the people developing it : r/singularity","url":"https://www.reddit.com/r/singularity/comments/1go8zd7/how_far_we_are_from_agi_according_to_the_people/#:~:text=Demis%20Hassabis%20Demis%20Hassabis%2C%20the,a%20decade%20away%2C%20at%20least","text":"Demis Hassabis Demis Hassabis, the CEO of Google DeepMind and a recently minted Nobel laureate, believes that an AI that can reason as well as humans is still a decade away, at least.","pub_date":null,"extra":{"cited_message_idx":43,"search_result_idx":null,"evidence_text":"","start_line_num":659,"end_line_num":662},"og_tags":null}},{"start_ix":37247,"end_ix":37261,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":37327,"end_ix":37341,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How far we are from AGI, according to the people developing it : r/singularity","url":"https://www.reddit.com/r/singularity/comments/1go8zd7/how_far_we_are_from_agi_according_to_the_people/#:~:text=Meta%27s%20chief%20AI%20scientist%2C%20Yann,we%27ll%20see%20AGI%20anytime%20soon","text":"Meta's chief AI scientist, Yann LeCun, doesn't believe we'll see AGI anytime soon.","pub_date":null,"extra":{"cited_message_idx":43,"search_result_idx":null,"evidence_text":"","start_line_num":688,"end_line_num":696},"og_tags":null}},{"start_ix":37341,"end_ix":37355,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How far we are from AGI, according to the people developing it : r/singularity","url":"https://www.reddit.com/r/singularity/comments/1go8zd7/how_far_we_are_from_agi_according_to_the_people/#:~:text=And%20LeCun%20says%20we%20shouldn%27t,arrive%20as%20a%20single%20event","text":"And LeCun says we shouldn't expect it to arrive as a single event.","pub_date":null,"extra":{"cited_message_idx":43,"search_result_idx":null,"evidence_text":"","start_line_num":695,"end_line_num":702},"og_tags":null}},{"start_ix":37412,"end_ix":37426,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How far we are from AGI, according to the people developing it : r/singularity","url":"https://www.reddit.com/r/singularity/comments/1go8zd7/how_far_we_are_from_agi_according_to_the_people/#:~:text=And%20he%27s%20not%20convinced%20we%27ll,that%20claim%20AGI%20is%20imminent","text":"And he's not convinced we'll get there soon. \"I hope we get there in our lifetime, but I'm not sure,\" he said, adding that people should be skeptical of companies that claim AGI is imminent.","pub_date":null,"extra":{"cited_message_idx":43,"search_result_idx":null,"evidence_text":"","start_line_num":669,"end_line_num":672},"og_tags":null}},{"start_ix":37535,"end_ix":37549,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":37584,"end_ix":37596,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":37643,"end_ix":37655,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Anthropic CEO thinks AGI in 2026 is possible, but says it could take much longer","url":"https://the-decoder.com/anthropic-ceo-thinks-agi-in-2026-is-possible-but-says-it-could-take-much-longer/#:~:text=While%20acknowledging%20significant%20uncertainties%2C%20Amodei,too%2C%20has%20no%20clear%20timeline","text":"While acknowledging significant uncertainties, Amodei suggests that extremely capable AI systems, which some might call \"AGI,\" could emerge as early as 2026. He cautions, however, that it could take \"much longer\" - effectively admitting that he, too, has no clear timeline.","pub_date":null,"extra":{"cited_message_idx":46,"search_result_idx":null,"evidence_text":"","start_line_num":53,"end_line_num":60},"og_tags":null}},{"start_ix":37760,"end_ix":37774,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How far we are from AGI, according to the people developing it : r/singularity","url":"https://www.reddit.com/r/singularity/comments/1go8zd7/how_far_we_are_from_agi_according_to_the_people/#:~:text=Richard%20Socher%20Richard%20Socher%2C%20a,in%20three%20to%20five%20years","text":"Richard Socher Richard Socher, a former Salesforce executive who is now the CEO of AI-powered search engine You.com, says there are two ways to define AGI. \"There's a simple economic one, which is 80% of the jobs will be automated with AI, and then we can call it AGI,\" he previously told Business Insider. He predicted we'll get there in three to five years.","pub_date":null,"extra":{"cited_message_idx":43,"search_result_idx":null,"evidence_text":"","start_line_num":674,"end_line_num":682},"og_tags":null}},{"start_ix":37833,"end_ix":37847,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"How far we are from AGI, according to the people developing it : r/singularity","url":"https://www.reddit.com/r/singularity/comments/1go8zd7/how_far_we_are_from_agi_according_to_the_people/#:~:text=AI%20godfather%20Geoffrey%20Hinton%20believes,as%20little%20as%20five%20years","text":"AI godfather Geoffrey Hinton believes that we might see AI that's smarter than humans in as little as five years.","pub_date":null,"extra":{"cited_message_idx":43,"search_result_idx":null,"evidence_text":"","start_line_num":653,"end_line_num":660},"og_tags":null}},{"start_ix":37873,"end_ix":37883,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":37938,"end_ix":37952,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":37952,"end_ix":37966,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":38007,"end_ix":38021,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"What AGI hype means for Washington - POLITICO","url":"https://www.politico.com/newsletters/digital-future-daily/2025/01/08/what-agi-hype-means-for-washington-00197154#:~:text=Gary%20Marcus%2C%20an%20outspoken%20AI,has%20changed%20to%20resolve%20remaining","text":"Gary Marcus, an outspoken AI skeptic, has called out how OpenAI and developers keep shifting what they consider AGI. Other AI experts quickly noted that the language in Altman\u2019s bold declaration was carefully couched, raising uncertainties about whether simply knowing how to build AGI would be enough to actually create it (let alone create it responsibly). As Alamir Novin, a University of South Carolina professor and AI researcher, pointed out, \u201che\u2019s not saying we have built AGI, or even if we can really have a clear path towards it.\u201d It doesn\u2019t tell us what, if anything, has changed to resolve remaining","pub_date":null,"extra":{"cited_message_idx":40,"search_result_idx":null,"evidence_text":"","start_line_num":206,"end_line_num":214},"og_tags":null}},{"start_ix":38140,"end_ix":38150,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Caf\u00e9 Europa - A very French Revolution: How Mistral AI is taking on the big guys","url":"https://www.europragmatist.com/p/a-very-french-revolution#:~:text=%2A%20,I%20don%E2%80%99t%20believe%20in%20AGI","text":"* \"God Complex\" Criticism \u26ea\ufe0f: Mensch has called the obsession with AI outsmarting humans as a \"very religious\" fascination, stating \"The whole AGI rhetoric is about creating God\u2026 I don\u2019t believe in God. I\u2019m a strong atheist. So I don\u2019t believe in AGI.\"","pub_date":null,"extra":{"cited_message_idx":28,"search_result_idx":null,"evidence_text":"","start_line_num":1,"end_line_num":4},"og_tags":null}},{"start_ix":38200,"end_ix":38214,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":38283,"end_ix":38293,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"Those Bold AGI Predictions Are Suddenly Looking Stretched - Business Insider","url":"https://www.businessinsider.com/agi-predictions-looking-stretched-openai-sam-altman-google-ai-2024-11#:~:text=,said%20at%20a%20recent%20conference","text":"* OpenAI cofounder Ilya Sutskever told Reuters that results from scaling up AI models like this have plateaued. * \"At some point, the scaling paradigm breaks down,\" OpenAI researcher Noam Brown said at a recent conference.","pub_date":null,"extra":{"cited_message_idx":19,"search_result_idx":null,"evidence_text":"","start_line_num":1,"end_line_num":4},"og_tags":null}},{"start_ix":38358,"end_ix":38372,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":38437,"end_ix":38451,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"What AGI hype means for Washington - POLITICO","url":"https://www.politico.com/newsletters/digital-future-daily/2025/01/08/what-agi-hype-means-for-washington-00197154#:~:text=And%20as%20a%20business%20proposition%2C,the%20company%20and%20Altman%20himself","text":"And as a business proposition, it\u2019s significant to the company for a very specific reason: Microsoft holds an exclusive cloud deal granting it access to OpenAI\u2019s technology, which ends once AGI is achieved. Should OpenAI\u2019s products indeed cross the threshold to AGI, it would unlock obvious financial rewards for the company and Altman himself.","pub_date":null,"extra":{"cited_message_idx":40,"search_result_idx":null,"evidence_text":"","start_line_num":183,"end_line_num":192},"og_tags":null}},{"start_ix":38451,"end_ix":38465,"citation_format_type":"tether_v4","metadata":{"type":"webpage","title":"What AGI hype means for Washington - POLITICO","url":"https://www.politico.com/newsletters/digital-future-daily/2025/01/08/what-agi-hype-means-for-washington-00197154#:~:text=Altman%20himself%2C%20in%20an%20interview,%E2%80%9D","text":"Altman himself, in an interview with Businessweek that inspired his blog reflections, admitted that pinpointing exactly when his company will reach AGI is tough because \u201cwe\u2019re going to move the goalposts, always.\u201d When asked why OpenAI (but not Altman himself) has stopped publicly discussing AGI, he explained that it became \u201ca very sloppy term.\u201d","pub_date":null,"extra":{"cited_message_idx":40,"search_result_idx":null,"evidence_text":"","start_line_num":194,"end_line_num":202},"og_tags":null}},{"start_ix":38528,"end_ix":38542,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":38542,"end_ix":38556,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"},{"start_ix":38610,"end_ix":38624,"citation_format_type":"tether_v4","invalid_reason":"Error while extracting cite metadata: Invalid line numbers in citation"}],"content_references":[{"matched_text":"\u30103\u2020L61-L68\u3011","start_idx":1355,"end_idx":1366,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u30103\u2020L61-L68\u3011","start_idx":1575,"end_idx":1586,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u301018\u2020L288-L297\u3011","start_idx":1756,"end_idx":1770,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u301049\u2020L147-L155\u3011","start_idx":1986,"end_idx":2000,"alt":null,"type":"webpage_extended","title":"Reflections - Sam Altman","url":"https://blog.samaltman.com/reflections#:~:text=We%20are%20now%20confident%20we,distributed%20outcomes","pub_date":null,"snippet":"We are now confident we know how to build AGI as we have traditionally understood it. We believe that, in 2025, we may see the first AI agents \u201cjoin the workforce\u201d and materially change the output of companies. We continue to believe that iteratively putting great tools in the hands of people leads to great, broadly-distributed outcomes.","attribution":"blog.samaltman.com","icon_type":null},{"matched_text":"\u301017\u2020L37-L40\u3011","start_idx":2419,"end_idx":2431,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u301021\u2020L195-L203\u3011","start_idx":2590,"end_idx":2604,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u301017\u2020L15-L23\u3011","start_idx":2896,"end_idx":2908,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u301046\u2020L53-L60\u3011","start_idx":3410,"end_idx":3422,"alt":null,"type":"webpage_extended","title":"Anthropic CEO thinks AGI in 2026 is possible, but says it could take much longer","url":"https://the-decoder.com/anthropic-ceo-thinks-agi-in-2026-is-possible-but-says-it-could-take-much-longer/#:~:text=While%20acknowledging%20significant%20uncertainties%2C%20Amodei,too%2C%20has%20no%20clear%20timeline","pub_date":null,"snippet":"While acknowledging significant uncertainties, Amodei suggests that extremely capable AI systems, which some might call \"AGI,\" could emerge as early as 2026. He cautions, however, that it could take \"much longer\" - effectively admitting that he, too, has no clear timeline.","attribution":"the-decoder.com","icon_type":null},{"matched_text":"\u301046\u2020L53-L60\u3011","start_idx":3607,"end_idx":3619,"alt":null,"type":"webpage_extended","title":"Anthropic CEO thinks AGI in 2026 is possible, but says it could take much longer","url":"https://the-decoder.com/anthropic-ceo-thinks-agi-in-2026-is-possible-but-says-it-could-take-much-longer/#:~:text=While%20acknowledging%20significant%20uncertainties%2C%20Amodei,too%2C%20has%20no%20clear%20timeline","pub_date":null,"snippet":"While acknowledging significant uncertainties, Amodei suggests that extremely capable AI systems, which some might call \"AGI,\" could emerge as early as 2026. He cautions, however, that it could take \"much longer\" - effectively admitting that he, too, has no clear timeline.","attribution":"the-decoder.com","icon_type":null},{"matched_text":"\u301046\u2020L63-L71\u3011","start_idx":3843,"end_idx":3855,"alt":null,"type":"webpage_extended","title":"Anthropic CEO thinks AGI in 2026 is possible, but says it could take much longer","url":"https://the-decoder.com/anthropic-ceo-thinks-agi-in-2026-is-possible-but-says-it-could-take-much-longer/#:~:text=Avoiding%20grandiosity","pub_date":null,"snippet":"Avoiding grandiosity","attribution":"the-decoder.com","icon_type":null},{"matched_text":"\u301043\u2020L674-L682\u3011","start_idx":4348,"end_idx":4362,"alt":null,"type":"webpage_extended","title":"How far we are from AGI, according to the people developing it : r/singularity","url":"https://www.reddit.com/r/singularity/comments/1go8zd7/how_far_we_are_from_agi_according_to_the_people/#:~:text=Richard%20Socher%20Richard%20Socher%2C%20a,in%20three%20to%20five%20years","pub_date":null,"snippet":"Richard Socher Richard Socher, a former Salesforce executive who is now the CEO of AI-powered search engine You.com, says there are two ways to define AGI. \"There's a simple economic one, which is 80% of the jobs will be automated with AI, and then we can call it AGI,\" he previously told Business Insider. He predicted we'll get there in three to five years.","attribution":"reddit.com","icon_type":null},{"matched_text":"\u301043\u2020L676-L684\u3011","start_idx":4644,"end_idx":4658,"alt":null,"type":"webpage_extended","title":"How far we are from AGI, according to the people developing it : r/singularity","url":"https://www.reddit.com/r/singularity/comments/1go8zd7/how_far_we_are_from_agi_according_to_the_people/#:~:text=search%20engine%20You,in%20three%20to%20five%20years","pub_date":null,"snippet":"search engine You.com, says there are two ways to define AGI. \"There's a simple economic one, which is 80% of the jobs will be automated with AI, and then we can call it AGI,\" he previously told Business Insider. He predicted we'll get there in three to five years.","attribution":"reddit.com","icon_type":null},{"matched_text":"\u301043\u2020L653-L660\u3011","start_idx":5133,"end_idx":5147,"alt":null,"type":"webpage_extended","title":"How far we are from AGI, according to the people developing it : r/singularity","url":"https://www.reddit.com/r/singularity/comments/1go8zd7/how_far_we_are_from_agi_according_to_the_people/#:~:text=AI%20godfather%20Geoffrey%20Hinton%20believes,as%20little%20as%20five%20years","pub_date":null,"snippet":"AI godfather Geoffrey Hinton believes that we might see AI that's smarter than humans in as little as five years.","attribution":"reddit.com","icon_type":null},{"matched_text":"\u301035\u2020L0-L8\u3011","start_idx":5292,"end_idx":5302,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u301035\u2020L5-L12\u3011","start_idx":5747,"end_idx":5758,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u30103\u2020L61-L68\u3011","start_idx":6588,"end_idx":6599,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u30103\u2020L72-L79\u3011","start_idx":6599,"end_idx":6610,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u301043\u2020L659-L662\u3011","start_idx":7155,"end_idx":7169,"alt":null,"type":"webpage_extended","title":"How far we are from AGI, according to the people developing it : r/singularity","url":"https://www.reddit.com/r/singularity/comments/1go8zd7/how_far_we_are_from_agi_according_to_the_people/#:~:text=Demis%20Hassabis%20Demis%20Hassabis%2C%20the,a%20decade%20away%2C%20at%20least","pub_date":null,"snippet":"Demis Hassabis Demis Hassabis, the CEO of Google DeepMind and a recently minted Nobel laureate, believes that an AI that can reason as well as humans is still a decade away, at least.","attribution":"reddit.com","icon_type":null},{"matched_text":"\u301010\u2020L302-L311\u3011","start_idx":7381,"end_idx":7395,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u301013\u2020L307-L316\u3011","start_idx":7395,"end_idx":7409,"alt":null,"type":"webpage_extended","title":"DeepMind CEO Demis Hassabis Explains What Has to Happen to Achieve AGI - Business Insider","url":"https://www.businessinsider.com/deepmind-ceo-demis-hassabis-agi-aiagents-chatgpt-gemini-2024-10#:~:text=,robots%20in%20the%20physical%20world","pub_date":null,"snippet":"* Planning. These systems can think ahead, plan a trip, or book tickets. * Acting. They need to be able to take action in the real world. * Reasoning. They should think through problems. Hassabis pointed to AlphaGo, DeepMind's AI that first defeated humans in Go, demonstrating reasoning skills in the game's defined domain. The next phase of agent-based systems will apply these skills to real-world contexts. * Better Memory. They should remember the details they've been told. * Better Personalization. They should understand a user's preferences, likes, and dislikes. * Using tools. They can use hardware like robots in the physical world,","attribution":"businessinsider.com","icon_type":null},{"matched_text":"\u301013\u2020L317-L321\u3011","start_idx":7654,"end_idx":7668,"alt":null,"type":"webpage_extended","title":"DeepMind CEO Demis Hassabis Explains What Has to Happen to Achieve AGI - Business Insider","url":"https://www.businessinsider.com/deepmind-ceo-demis-hassabis-agi-aiagents-chatgpt-gemini-2024-10#:~:text=software%20like%20a%20calculator%2C%20or,even%20other%20AI%20systems","pub_date":null,"snippet":"software like a calculator, or even other AI systems.","attribution":"businessinsider.com","icon_type":null},{"matched_text":"\u301043\u2020L688-L696\u3011","start_idx":8383,"end_idx":8397,"alt":null,"type":"webpage_extended","title":"How far we are from AGI, according to the people developing it : r/singularity","url":"https://www.reddit.com/r/singularity/comments/1go8zd7/how_far_we_are_from_agi_according_to_the_people/#:~:text=Meta%27s%20chief%20AI%20scientist%2C%20Yann,we%27ll%20see%20AGI%20anytime%20soon","pub_date":null,"snippet":"Meta's chief AI scientist, Yann LeCun, doesn't believe we'll see AGI anytime soon.","attribution":"reddit.com","icon_type":null},{"matched_text":"\u301016\u2020L123-L131\u3011","start_idx":8810,"end_idx":8824,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u301016\u2020L129-L135\u3011","start_idx":8824,"end_idx":8838,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u301043\u2020L695-L702\u3011","start_idx":8982,"end_idx":8996,"alt":null,"type":"webpage_extended","title":"How far we are from AGI, according to the people developing it : r/singularity","url":"https://www.reddit.com/r/singularity/comments/1go8zd7/how_far_we_are_from_agi_according_to_the_people/#:~:text=And%20LeCun%20says%20we%20shouldn%27t,arrive%20as%20a%20single%20event","pub_date":null,"snippet":"And LeCun says we shouldn't expect it to arrive as a single event.","attribution":"reddit.com","icon_type":null},{"matched_text":"\u301038\u2020L1-L9\u3011","start_idx":9890,"end_idx":9900,"alt":null,"type":"webpage_extended","title":"\u1d05\u1d00\u0274\u026a\u1d07\u029f \u1d0d\u026a\u1d07ss\u029f\u1d07\u0280 on X: \"One of my great awakenings of the ...","url":"https://twitter.com/DanielMiessler/status/1830683026919170324#:~:text=Sep%201%2C%202024,it%20is%20only%20a","pub_date":null,"snippet":"Sep 1, 2024. Machine learning pioneer Andrew Ng says AGI is still \"many decades away, maybe even longer\" and companies that say it is only a ...","attribution":"twitter.com","icon_type":null},{"matched_text":"\u301043\u2020L669-L672\u3011","start_idx":10290,"end_idx":10304,"alt":null,"type":"webpage_extended","title":"How far we are from AGI, according to the people developing it : r/singularity","url":"https://www.reddit.com/r/singularity/comments/1go8zd7/how_far_we_are_from_agi_according_to_the_people/#:~:text=And%20he%27s%20not%20convinced%20we%27ll,that%20claim%20AGI%20is%20imminent","pub_date":null,"snippet":"And he's not convinced we'll get there soon. \"I hope we get there in our lifetime, but I'm not sure,\" he said, adding that people should be skeptical of companies that claim AGI is imminent.","attribution":"reddit.com","icon_type":null},{"matched_text":"\u301034\u2020L206-L214\u3011","start_idx":11183,"end_idx":11197,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u301034\u2020L209-L217\u3011","start_idx":11376,"end_idx":11390,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u301034\u2020L189-L197\u3011","start_idx":11504,"end_idx":11518,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u301040\u2020L206-L214\u3011","start_idx":12495,"end_idx":12509,"alt":null,"type":"webpage_extended","title":"What AGI hype means for Washington - POLITICO","url":"https://www.politico.com/newsletters/digital-future-daily/2025/01/08/what-agi-hype-means-for-washington-00197154#:~:text=Gary%20Marcus%2C%20an%20outspoken%20AI,has%20changed%20to%20resolve%20remaining","pub_date":null,"snippet":"Gary Marcus, an outspoken AI skeptic, has called out how OpenAI and developers keep shifting what they consider AGI. Other AI experts quickly noted that the language in Altman\u2019s bold declaration was carefully couched, raising uncertainties about whether simply knowing how to build AGI would be enough to actually create it (let alone create it responsibly). As Alamir Novin, a University of South Carolina professor and AI researcher, pointed out, \u201che\u2019s not saying we have built AGI, or even if we can really have a clear path towards it.\u201d It doesn\u2019t tell us what, if anything, has changed to resolve remaining","attribution":"politico.com","icon_type":null},{"matched_text":"\u301040\u2020L194-L202\u3011","start_idx":12732,"end_idx":12746,"alt":null,"type":"webpage_extended","title":"What AGI hype means for Washington - POLITICO","url":"https://www.politico.com/newsletters/digital-future-daily/2025/01/08/what-agi-hype-means-for-washington-00197154#:~:text=Altman%20himself%2C%20in%20an%20interview,%E2%80%9D","pub_date":null,"snippet":"Altman himself, in an interview with Businessweek that inspired his blog reflections, admitted that pinpointing exactly when his company will reach AGI is tough because \u201cwe\u2019re going to move the goalposts, always.\u201d When asked why OpenAI (but not Altman himself) has stopped publicly discussing AGI, he explained that it became \u201ca very sloppy term.\u201d","attribution":"politico.com","icon_type":null},{"matched_text":"\u301040\u2020L206-L214\u3011","start_idx":12746,"end_idx":12760,"alt":null,"type":"webpage_extended","title":"What AGI hype means for Washington - POLITICO","url":"https://www.politico.com/newsletters/digital-future-daily/2025/01/08/what-agi-hype-means-for-washington-00197154#:~:text=Gary%20Marcus%2C%20an%20outspoken%20AI,has%20changed%20to%20resolve%20remaining","pub_date":null,"snippet":"Gary Marcus, an outspoken AI skeptic, has called out how OpenAI and developers keep shifting what they consider AGI. Other AI experts quickly noted that the language in Altman\u2019s bold declaration was carefully couched, raising uncertainties about whether simply knowing how to build AGI would be enough to actually create it (let alone create it responsibly). As Alamir Novin, a University of South Carolina professor and AI researcher, pointed out, \u201che\u2019s not saying we have built AGI, or even if we can really have a clear path towards it.\u201d It doesn\u2019t tell us what, if anything, has changed to resolve remaining","attribution":"politico.com","icon_type":null},{"matched_text":"\u301040\u2020L183-L192\u3011","start_idx":12926,"end_idx":12940,"alt":null,"type":"webpage_extended","title":"What AGI hype means for Washington - POLITICO","url":"https://www.politico.com/newsletters/digital-future-daily/2025/01/08/what-agi-hype-means-for-washington-00197154#:~:text=And%20as%20a%20business%20proposition%2C,the%20company%20and%20Altman%20himself","pub_date":null,"snippet":"And as a business proposition, it\u2019s significant to the company for a very specific reason: Microsoft holds an exclusive cloud deal granting it access to OpenAI\u2019s technology, which ends once AGI is achieved. Should OpenAI\u2019s products indeed cross the threshold to AGI, it would unlock obvious financial rewards for the company and Altman himself.","attribution":"politico.com","icon_type":null},{"matched_text":"\u301040\u2020L221-L229\u3011","start_idx":12940,"end_idx":12954,"alt":null,"type":"webpage_extended","title":"What AGI hype means for Washington - POLITICO","url":"https://www.politico.com/newsletters/digital-future-daily/2025/01/08/what-agi-hype-means-for-washington-00197154#:~:text=%E2%80%9CIt%E2%80%99s%20lazy%20and%20misleading%2C%E2%80%9D%20he,%E2%80%9D","pub_date":null,"snippet":"\u201cIt\u2019s lazy and misleading,\u201d he told DFD, saying he\u2019s found that definitions for AGI are either overly broad, fail to recognize human ability as just a fraction of the technology\u2019s potential, or simply incoherent and unhelpful. \u201cI think Sam Altman is literally saying this because it\u2019s a contractual meaning in this contract with Microsoft that is worth many billion dollars.\u201d","attribution":"politico.com","icon_type":null},{"matched_text":"\u301039\u2020L0-L8\u3011","start_idx":13113,"end_idx":13123,"alt":null,"type":"webpage_extended","title":"In 2022 Gary Marcus was 50% sure that AGI wouldn't happen by ...","url":"https://www.reddit.com/r/LocalLLaMA/comments/1hprsyv/in_2022_gary_marcus_was_50_sure_that_agi_wouldnt/#:~:text=In%202022%20Gary%20Marcus%20was,You%20can%20read%20it%20here","pub_date":null,"snippet":"In 2022 Gary Marcus was 50% sure that AGI wouldn't happen by ... In 2024, he bet that we wouldn't get ASI by 2027 and gave a list of 11 things he thought would indicate ASI. The new bet. You can read it here.","attribution":"reddit.com","icon_type":null},{"matched_text":"\u301028\u2020L1-L4\u3011","start_idx":13825,"end_idx":13835,"alt":null,"type":"webpage_extended","title":"Caf\u00e9 Europa - A very French Revolution: How Mistral AI is taking on the big guys","url":"https://www.europragmatist.com/p/a-very-french-revolution#:~:text=%2A%20,I%20don%E2%80%99t%20believe%20in%20AGI","pub_date":null,"snippet":"* \"God Complex\" Criticism \u26ea\ufe0f: Mensch has called the obsession with AI outsmarting humans as a \"very religious\" fascination, stating \"The whole AGI rhetoric is about creating God\u2026 I don\u2019t believe in God. I\u2019m a strong atheist. So I don\u2019t believe in AGI.\"","attribution":"europragmatist.com","icon_type":null},{"matched_text":"\u301022\u2020L5-L13\u3011","start_idx":14061,"end_idx":14072,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u301018\u2020L299-L307\u3011","start_idx":14672,"end_idx":14686,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u301018\u2020L302-L310\u3011","start_idx":14849,"end_idx":14863,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u301019\u2020L1-L4\u3011","start_idx":15062,"end_idx":15072,"alt":null,"type":"webpage_extended","title":"Those Bold AGI Predictions Are Suddenly Looking Stretched - Business Insider","url":"https://www.businessinsider.com/agi-predictions-looking-stretched-openai-sam-altman-google-ai-2024-11#:~:text=,said%20at%20a%20recent%20conference","pub_date":null,"snippet":"* OpenAI cofounder Ilya Sutskever told Reuters that results from scaling up AI models like this have plateaued. * \"At some point, the scaling paradigm breaks down,\" OpenAI researcher Noam Brown said at a recent conference.","attribution":"businessinsider.com","icon_type":null},{"matched_text":"\u301021\u2020L195-L203\u3011","start_idx":16406,"end_idx":16420,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u301019\u2020L1-L4\u3011","start_idx":16631,"end_idx":16641,"alt":null,"type":"webpage_extended","title":"Those Bold AGI Predictions Are Suddenly Looking Stretched - Business Insider","url":"https://www.businessinsider.com/agi-predictions-looking-stretched-openai-sam-altman-google-ai-2024-11#:~:text=,said%20at%20a%20recent%20conference","pub_date":null,"snippet":"* OpenAI cofounder Ilya Sutskever told Reuters that results from scaling up AI models like this have plateaued. * \"At some point, the scaling paradigm breaks down,\" OpenAI researcher Noam Brown said at a recent conference.","attribution":"businessinsider.com","icon_type":null},{"matched_text":"\u301010\u2020L302-L311\u3011","start_idx":16845,"end_idx":16859,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u301016\u2020L129-L135\u3011","start_idx":17076,"end_idx":17090,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u301034\u2020L189-L197\u3011","start_idx":17235,"end_idx":17249,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u301040\u2020L194-L202\u3011","start_idx":17913,"end_idx":17927,"alt":null,"type":"webpage_extended","title":"What AGI hype means for Washington - POLITICO","url":"https://www.politico.com/newsletters/digital-future-daily/2025/01/08/what-agi-hype-means-for-washington-00197154#:~:text=Altman%20himself%2C%20in%20an%20interview,%E2%80%9D","pub_date":null,"snippet":"Altman himself, in an interview with Businessweek that inspired his blog reflections, admitted that pinpointing exactly when his company will reach AGI is tough because \u201cwe\u2019re going to move the goalposts, always.\u201d When asked why OpenAI (but not Altman himself) has stopped publicly discussing AGI, he explained that it became \u201ca very sloppy term.\u201d","attribution":"politico.com","icon_type":null},{"matched_text":"\u30103\u2020L72-L80\u3011","start_idx":18072,"end_idx":18083,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u301040\u2020L206-L214\u3011","start_idx":18225,"end_idx":18239,"alt":null,"type":"webpage_extended","title":"What AGI hype means for Washington - POLITICO","url":"https://www.politico.com/newsletters/digital-future-daily/2025/01/08/what-agi-hype-means-for-washington-00197154#:~:text=Gary%20Marcus%2C%20an%20outspoken%20AI,has%20changed%20to%20resolve%20remaining","pub_date":null,"snippet":"Gary Marcus, an outspoken AI skeptic, has called out how OpenAI and developers keep shifting what they consider AGI. Other AI experts quickly noted that the language in Altman\u2019s bold declaration was carefully couched, raising uncertainties about whether simply knowing how to build AGI would be enough to actually create it (let alone create it responsibly). As Alamir Novin, a University of South Carolina professor and AI researcher, pointed out, \u201che\u2019s not saying we have built AGI, or even if we can really have a clear path towards it.\u201d It doesn\u2019t tell us what, if anything, has changed to resolve remaining","attribution":"politico.com","icon_type":null},{"matched_text":"\u301040\u2020L217-L225\u3011","start_idx":18553,"end_idx":18567,"alt":null,"type":"webpage_extended","title":"What AGI hype means for Washington - POLITICO","url":"https://www.politico.com/newsletters/digital-future-daily/2025/01/08/what-agi-hype-means-for-washington-00197154#:~:text=Julian%20Togelius%2C%20an%20associate%20professor,stop%20using%20the%20term%20altogether","pub_date":null,"snippet":"Julian Togelius, an associate professor at New York University who works on artificial intelligence, wrote a whole book about AGI in which he spent a lot of time trying to figure out what it meant \u2014 and came to the conclusion that people should stop using the term altogether.","attribution":"politico.com","icon_type":null},{"matched_text":"\u301043\u2020L674-L682\u3011","start_idx":18682,"end_idx":18696,"alt":null,"type":"webpage_extended","title":"How far we are from AGI, according to the people developing it : r/singularity","url":"https://www.reddit.com/r/singularity/comments/1go8zd7/how_far_we_are_from_agi_according_to_the_people/#:~:text=Richard%20Socher%20Richard%20Socher%2C%20a,in%20three%20to%20five%20years","pub_date":null,"snippet":"Richard Socher Richard Socher, a former Salesforce executive who is now the CEO of AI-powered search engine You.com, says there are two ways to define AGI. \"There's a simple economic one, which is 80% of the jobs will be automated with AI, and then we can call it AGI,\" he previously told Business Insider. He predicted we'll get there in three to five years.","attribution":"reddit.com","icon_type":null},{"matched_text":"\u301043\u2020L695-L702\u3011","start_idx":19817,"end_idx":19831,"alt":null,"type":"webpage_extended","title":"How far we are from AGI, according to the people developing it : r/singularity","url":"https://www.reddit.com/r/singularity/comments/1go8zd7/how_far_we_are_from_agi_according_to_the_people/#:~:text=And%20LeCun%20says%20we%20shouldn%27t,arrive%20as%20a%20single%20event","pub_date":null,"snippet":"And LeCun says we shouldn't expect it to arrive as a single event.","attribution":"reddit.com","icon_type":null},{"matched_text":"\u30103\u2020L63-L68\u3011","start_idx":20014,"end_idx":20025,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u301010\u2020L302-L311\u3011","start_idx":21110,"end_idx":21124,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u301010\u2020L302-L311\u3011","start_idx":22204,"end_idx":22218,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u301013\u2020L317-L321\u3011","start_idx":22218,"end_idx":22232,"alt":null,"type":"webpage_extended","title":"DeepMind CEO Demis Hassabis Explains What Has to Happen to Achieve AGI - Business Insider","url":"https://www.businessinsider.com/deepmind-ceo-demis-hassabis-agi-aiagents-chatgpt-gemini-2024-10#:~:text=software%20like%20a%20calculator%2C%20or,even%20other%20AI%20systems","pub_date":null,"snippet":"software like a calculator, or even other AI systems.","attribution":"businessinsider.com","icon_type":null},{"matched_text":"\u301049\u2020L147-L155\u3011","start_idx":22527,"end_idx":22541,"alt":null,"type":"webpage_extended","title":"Reflections - Sam Altman","url":"https://blog.samaltman.com/reflections#:~:text=We%20are%20now%20confident%20we,distributed%20outcomes","pub_date":null,"snippet":"We are now confident we know how to build AGI as we have traditionally understood it. We believe that, in 2025, we may see the first AI agents \u201cjoin the workforce\u201d and materially change the output of companies. We continue to believe that iteratively putting great tools in the hands of people leads to great, broadly-distributed outcomes.","attribution":"blog.samaltman.com","icon_type":null},{"matched_text":"\u301046\u2020L63-L71\u3011","start_idx":22749,"end_idx":22761,"alt":null,"type":"webpage_extended","title":"Anthropic CEO thinks AGI in 2026 is possible, but says it could take much longer","url":"https://the-decoder.com/anthropic-ceo-thinks-agi-in-2026-is-possible-but-says-it-could-take-much-longer/#:~:text=Avoiding%20grandiosity","pub_date":null,"snippet":"Avoiding grandiosity","attribution":"the-decoder.com","icon_type":null},{"matched_text":"\u301028\u2020L1-L4\u3011","start_idx":23120,"end_idx":23130,"alt":null,"type":"webpage_extended","title":"Caf\u00e9 Europa - A very French Revolution: How Mistral AI is taking on the big guys","url":"https://www.europragmatist.com/p/a-very-french-revolution#:~:text=%2A%20,I%20don%E2%80%99t%20believe%20in%20AGI","pub_date":null,"snippet":"* \"God Complex\" Criticism \u26ea\ufe0f: Mensch has called the obsession with AI outsmarting humans as a \"very religious\" fascination, stating \"The whole AGI rhetoric is about creating God\u2026 I don\u2019t believe in God. I\u2019m a strong atheist. So I don\u2019t believe in AGI.\"","attribution":"europragmatist.com","icon_type":null},{"matched_text":"\u301040\u2020L206-L214\u3011","start_idx":23130,"end_idx":23144,"alt":null,"type":"webpage_extended","title":"What AGI hype means for Washington - POLITICO","url":"https://www.politico.com/newsletters/digital-future-daily/2025/01/08/what-agi-hype-means-for-washington-00197154#:~:text=Gary%20Marcus%2C%20an%20outspoken%20AI,has%20changed%20to%20resolve%20remaining","pub_date":null,"snippet":"Gary Marcus, an outspoken AI skeptic, has called out how OpenAI and developers keep shifting what they consider AGI. Other AI experts quickly noted that the language in Altman\u2019s bold declaration was carefully couched, raising uncertainties about whether simply knowing how to build AGI would be enough to actually create it (let alone create it responsibly). As Alamir Novin, a University of South Carolina professor and AI researcher, pointed out, \u201che\u2019s not saying we have built AGI, or even if we can really have a clear path towards it.\u201d It doesn\u2019t tell us what, if anything, has changed to resolve remaining","attribution":"politico.com","icon_type":null},{"matched_text":"\u301040\u2020L183-L192\u3011","start_idx":23473,"end_idx":23487,"alt":null,"type":"webpage_extended","title":"What AGI hype means for Washington - POLITICO","url":"https://www.politico.com/newsletters/digital-future-daily/2025/01/08/what-agi-hype-means-for-washington-00197154#:~:text=And%20as%20a%20business%20proposition%2C,the%20company%20and%20Altman%20himself","pub_date":null,"snippet":"And as a business proposition, it\u2019s significant to the company for a very specific reason: Microsoft holds an exclusive cloud deal granting it access to OpenAI\u2019s technology, which ends once AGI is achieved. Should OpenAI\u2019s products indeed cross the threshold to AGI, it would unlock obvious financial rewards for the company and Altman himself.","attribution":"politico.com","icon_type":null},{"matched_text":"\u301040\u2020L221-L229\u3011","start_idx":23487,"end_idx":23501,"alt":null,"type":"webpage_extended","title":"What AGI hype means for Washington - POLITICO","url":"https://www.politico.com/newsletters/digital-future-daily/2025/01/08/what-agi-hype-means-for-washington-00197154#:~:text=%E2%80%9CIt%E2%80%99s%20lazy%20and%20misleading%2C%E2%80%9D%20he,%E2%80%9D","pub_date":null,"snippet":"\u201cIt\u2019s lazy and misleading,\u201d he told DFD, saying he\u2019s found that definitions for AGI are either overly broad, fail to recognize human ability as just a fraction of the technology\u2019s potential, or simply incoherent and unhelpful. \u201cI think Sam Altman is literally saying this because it\u2019s a contractual meaning in this contract with Microsoft that is worth many billion dollars.\u201d","attribution":"politico.com","icon_type":null},{"matched_text":"\u301046\u2020L55-L63\u3011","start_idx":24352,"end_idx":24364,"alt":null,"type":"webpage_extended","title":"Anthropic CEO thinks AGI in 2026 is possible, but says it could take much longer","url":"https://the-decoder.com/anthropic-ceo-thinks-agi-in-2026-is-possible-but-says-it-could-take-much-longer/#:~:text=call%20,too%2C%20has%20no%20clear%20timeline","pub_date":null,"snippet":"call \"AGI,\" could emerge as early as 2026. He cautions, however, that it could take \"much longer\" - effectively admitting that he, too, has no clear timeline.","attribution":"the-decoder.com","icon_type":null},{"matched_text":"\u301035\u2020L0-L8\u3011","start_idx":24598,"end_idx":24608,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u301030\u2020L63-L71\u3011","start_idx":24706,"end_idx":24718,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u301032\u2020L138-L147\u3011","start_idx":24718,"end_idx":24732,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u301034\u2020L206-L214\u3011","start_idx":26686,"end_idx":26700,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u301043\u2020L653-L660\u3011","start_idx":26821,"end_idx":26835,"alt":null,"type":"webpage_extended","title":"How far we are from AGI, according to the people developing it : r/singularity","url":"https://www.reddit.com/r/singularity/comments/1go8zd7/how_far_we_are_from_agi_according_to_the_people/#:~:text=AI%20godfather%20Geoffrey%20Hinton%20believes,as%20little%20as%20five%20years","pub_date":null,"snippet":"AI godfather Geoffrey Hinton believes that we might see AI that's smarter than humans in as little as five years.","attribution":"reddit.com","icon_type":null},{"matched_text":"\u301014\u2020L39-L42\u3011","start_idx":27196,"end_idx":27208,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u301040\u2020L200-L207\u3011","start_idx":27908,"end_idx":27922,"alt":null,"type":"webpage_extended","title":"What AGI hype means for Washington - POLITICO","url":"https://www.politico.com/newsletters/digital-future-daily/2025/01/08/what-agi-hype-means-for-washington-00197154#:~:text=The%20company%20uses%20a%20,dispute%20what%E2%80%99s%20AGI%20or%20not","pub_date":null,"snippet":"The company uses a  five-level scale to track progress toward human-level problem-solving \u2014 and Altman pointed out that for all of them, \u201cyou can find people that would call each of those AGI.\u201d The goal, Altman said, has been to give clearer updates on progress, not dispute what\u2019s AGI or not.","attribution":"politico.com","icon_type":null},{"matched_text":"\u301040\u2020L221-L229\u3011","start_idx":27922,"end_idx":27936,"alt":null,"type":"webpage_extended","title":"What AGI hype means for Washington - POLITICO","url":"https://www.politico.com/newsletters/digital-future-daily/2025/01/08/what-agi-hype-means-for-washington-00197154#:~:text=%E2%80%9CIt%E2%80%99s%20lazy%20and%20misleading%2C%E2%80%9D%20he,%E2%80%9D","pub_date":null,"snippet":"\u201cIt\u2019s lazy and misleading,\u201d he told DFD, saying he\u2019s found that definitions for AGI are either overly broad, fail to recognize human ability as just a fraction of the technology\u2019s potential, or simply incoherent and unhelpful. \u201cI think Sam Altman is literally saying this because it\u2019s a contractual meaning in this contract with Microsoft that is worth many billion dollars.\u201d","attribution":"politico.com","icon_type":null},{"matched_text":"\u301032\u2020L175-L183\u3011","start_idx":29579,"end_idx":29593,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u301032\u2020L169-L173\u3011","start_idx":29593,"end_idx":29607,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u301032\u2020L175-L183\u3011","start_idx":29739,"end_idx":29753,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u301016\u2020L127-L135\u3011","start_idx":32360,"end_idx":32374,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u301034\u2020L209-L217\u3011","start_idx":33393,"end_idx":33407,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u301040\u2020L194-L202\u3011","start_idx":33472,"end_idx":33486,"alt":null,"type":"webpage_extended","title":"What AGI hype means for Washington - POLITICO","url":"https://www.politico.com/newsletters/digital-future-daily/2025/01/08/what-agi-hype-means-for-washington-00197154#:~:text=Altman%20himself%2C%20in%20an%20interview,%E2%80%9D","pub_date":null,"snippet":"Altman himself, in an interview with Businessweek that inspired his blog reflections, admitted that pinpointing exactly when his company will reach AGI is tough because \u201cwe\u2019re going to move the goalposts, always.\u201d When asked why OpenAI (but not Altman himself) has stopped publicly discussing AGI, he explained that it became \u201ca very sloppy term.\u201d","attribution":"politico.com","icon_type":null},{"matched_text":"\u301043\u2020L653-L660\u3011","start_idx":35275,"end_idx":35289,"alt":null,"type":"webpage_extended","title":"How far we are from AGI, according to the people developing it : r/singularity","url":"https://www.reddit.com/r/singularity/comments/1go8zd7/how_far_we_are_from_agi_according_to_the_people/#:~:text=AI%20godfather%20Geoffrey%20Hinton%20believes,as%20little%20as%20five%20years","pub_date":null,"snippet":"AI godfather Geoffrey Hinton believes that we might see AI that's smarter than humans in as little as five years.","attribution":"reddit.com","icon_type":null},{"matched_text":"\u30103\u2020L61-L68\u3011","start_idx":36908,"end_idx":36919,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u301018\u2020L288-L297\u3011","start_idx":36959,"end_idx":36973,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u301049\u2020L147-L155\u3011","start_idx":37007,"end_idx":37021,"alt":null,"type":"webpage_extended","title":"Reflections - Sam Altman","url":"https://blog.samaltman.com/reflections#:~:text=We%20are%20now%20confident%20we,distributed%20outcomes","pub_date":null,"snippet":"We are now confident we know how to build AGI as we have traditionally understood it. We believe that, in 2025, we may see the first AI agents \u201cjoin the workforce\u201d and materially change the output of companies. We continue to believe that iteratively putting great tools in the hands of people leads to great, broadly-distributed outcomes.","attribution":"blog.samaltman.com","icon_type":null},{"matched_text":"\u301013\u2020L317-L321\u3011","start_idx":37109,"end_idx":37123,"alt":null,"type":"webpage_extended","title":"DeepMind CEO Demis Hassabis Explains What Has to Happen to Achieve AGI - Business Insider","url":"https://www.businessinsider.com/deepmind-ceo-demis-hassabis-agi-aiagents-chatgpt-gemini-2024-10#:~:text=software%20like%20a%20calculator%2C%20or,even%20other%20AI%20systems","pub_date":null,"snippet":"software like a calculator, or even other AI systems.","attribution":"businessinsider.com","icon_type":null},{"matched_text":"\u301043\u2020L659-L662\u3011","start_idx":37167,"end_idx":37181,"alt":null,"type":"webpage_extended","title":"How far we are from AGI, according to the people developing it : r/singularity","url":"https://www.reddit.com/r/singularity/comments/1go8zd7/how_far_we_are_from_agi_according_to_the_people/#:~:text=Demis%20Hassabis%20Demis%20Hassabis%2C%20the,a%20decade%20away%2C%20at%20least","pub_date":null,"snippet":"Demis Hassabis Demis Hassabis, the CEO of Google DeepMind and a recently minted Nobel laureate, believes that an AI that can reason as well as humans is still a decade away, at least.","attribution":"reddit.com","icon_type":null},{"matched_text":"\u301016\u2020L123-L131\u3011","start_idx":37247,"end_idx":37261,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u301043\u2020L688-L696\u3011","start_idx":37327,"end_idx":37341,"alt":null,"type":"webpage_extended","title":"How far we are from AGI, according to the people developing it : r/singularity","url":"https://www.reddit.com/r/singularity/comments/1go8zd7/how_far_we_are_from_agi_according_to_the_people/#:~:text=Meta%27s%20chief%20AI%20scientist%2C%20Yann,we%27ll%20see%20AGI%20anytime%20soon","pub_date":null,"snippet":"Meta's chief AI scientist, Yann LeCun, doesn't believe we'll see AGI anytime soon.","attribution":"reddit.com","icon_type":null},{"matched_text":"\u301043\u2020L695-L702\u3011","start_idx":37341,"end_idx":37355,"alt":null,"type":"webpage_extended","title":"How far we are from AGI, according to the people developing it : r/singularity","url":"https://www.reddit.com/r/singularity/comments/1go8zd7/how_far_we_are_from_agi_according_to_the_people/#:~:text=And%20LeCun%20says%20we%20shouldn%27t,arrive%20as%20a%20single%20event","pub_date":null,"snippet":"And LeCun says we shouldn't expect it to arrive as a single event.","attribution":"reddit.com","icon_type":null},{"matched_text":"\u301043\u2020L669-L672\u3011","start_idx":37412,"end_idx":37426,"alt":null,"type":"webpage_extended","title":"How far we are from AGI, according to the people developing it : r/singularity","url":"https://www.reddit.com/r/singularity/comments/1go8zd7/how_far_we_are_from_agi_according_to_the_people/#:~:text=And%20he%27s%20not%20convinced%20we%27ll,that%20claim%20AGI%20is%20imminent","pub_date":null,"snippet":"And he's not convinced we'll get there soon. \"I hope we get there in our lifetime, but I'm not sure,\" he said, adding that people should be skeptical of companies that claim AGI is imminent.","attribution":"reddit.com","icon_type":null},{"matched_text":"\u301021\u2020L195-L203\u3011","start_idx":37535,"end_idx":37549,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u301017\u2020L37-L40\u3011","start_idx":37584,"end_idx":37596,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u301046\u2020L53-L60\u3011","start_idx":37643,"end_idx":37655,"alt":null,"type":"webpage_extended","title":"Anthropic CEO thinks AGI in 2026 is possible, but says it could take much longer","url":"https://the-decoder.com/anthropic-ceo-thinks-agi-in-2026-is-possible-but-says-it-could-take-much-longer/#:~:text=While%20acknowledging%20significant%20uncertainties%2C%20Amodei,too%2C%20has%20no%20clear%20timeline","pub_date":null,"snippet":"While acknowledging significant uncertainties, Amodei suggests that extremely capable AI systems, which some might call \"AGI,\" could emerge as early as 2026. He cautions, however, that it could take \"much longer\" - effectively admitting that he, too, has no clear timeline.","attribution":"the-decoder.com","icon_type":null},{"matched_text":"\u301043\u2020L674-L682\u3011","start_idx":37760,"end_idx":37774,"alt":null,"type":"webpage_extended","title":"How far we are from AGI, according to the people developing it : r/singularity","url":"https://www.reddit.com/r/singularity/comments/1go8zd7/how_far_we_are_from_agi_according_to_the_people/#:~:text=Richard%20Socher%20Richard%20Socher%2C%20a,in%20three%20to%20five%20years","pub_date":null,"snippet":"Richard Socher Richard Socher, a former Salesforce executive who is now the CEO of AI-powered search engine You.com, says there are two ways to define AGI. \"There's a simple economic one, which is 80% of the jobs will be automated with AI, and then we can call it AGI,\" he previously told Business Insider. He predicted we'll get there in three to five years.","attribution":"reddit.com","icon_type":null},{"matched_text":"\u301043\u2020L653-L660\u3011","start_idx":37833,"end_idx":37847,"alt":null,"type":"webpage_extended","title":"How far we are from AGI, according to the people developing it : r/singularity","url":"https://www.reddit.com/r/singularity/comments/1go8zd7/how_far_we_are_from_agi_according_to_the_people/#:~:text=AI%20godfather%20Geoffrey%20Hinton%20believes,as%20little%20as%20five%20years","pub_date":null,"snippet":"AI godfather Geoffrey Hinton believes that we might see AI that's smarter than humans in as little as five years.","attribution":"reddit.com","icon_type":null},{"matched_text":"\u301035\u2020L0-L8\u3011","start_idx":37873,"end_idx":37883,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u301034\u2020L206-L214\u3011","start_idx":37938,"end_idx":37952,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u301034\u2020L209-L217\u3011","start_idx":37952,"end_idx":37966,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u301040\u2020L206-L214\u3011","start_idx":38007,"end_idx":38021,"alt":null,"type":"webpage_extended","title":"What AGI hype means for Washington - POLITICO","url":"https://www.politico.com/newsletters/digital-future-daily/2025/01/08/what-agi-hype-means-for-washington-00197154#:~:text=Gary%20Marcus%2C%20an%20outspoken%20AI,has%20changed%20to%20resolve%20remaining","pub_date":null,"snippet":"Gary Marcus, an outspoken AI skeptic, has called out how OpenAI and developers keep shifting what they consider AGI. Other AI experts quickly noted that the language in Altman\u2019s bold declaration was carefully couched, raising uncertainties about whether simply knowing how to build AGI would be enough to actually create it (let alone create it responsibly). As Alamir Novin, a University of South Carolina professor and AI researcher, pointed out, \u201che\u2019s not saying we have built AGI, or even if we can really have a clear path towards it.\u201d It doesn\u2019t tell us what, if anything, has changed to resolve remaining","attribution":"politico.com","icon_type":null},{"matched_text":"\u301028\u2020L1-L4\u3011","start_idx":38140,"end_idx":38150,"alt":null,"type":"webpage_extended","title":"Caf\u00e9 Europa - A very French Revolution: How Mistral AI is taking on the big guys","url":"https://www.europragmatist.com/p/a-very-french-revolution#:~:text=%2A%20,I%20don%E2%80%99t%20believe%20in%20AGI","pub_date":null,"snippet":"* \"God Complex\" Criticism \u26ea\ufe0f: Mensch has called the obsession with AI outsmarting humans as a \"very religious\" fascination, stating \"The whole AGI rhetoric is about creating God\u2026 I don\u2019t believe in God. I\u2019m a strong atheist. So I don\u2019t believe in AGI.\"","attribution":"europragmatist.com","icon_type":null},{"matched_text":"\u301018\u2020L300-L308\u3011","start_idx":38200,"end_idx":38214,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u301019\u2020L1-L4\u3011","start_idx":38283,"end_idx":38293,"alt":null,"type":"webpage_extended","title":"Those Bold AGI Predictions Are Suddenly Looking Stretched - Business Insider","url":"https://www.businessinsider.com/agi-predictions-looking-stretched-openai-sam-altman-google-ai-2024-11#:~:text=,said%20at%20a%20recent%20conference","pub_date":null,"snippet":"* OpenAI cofounder Ilya Sutskever told Reuters that results from scaling up AI models like this have plateaued. * \"At some point, the scaling paradigm breaks down,\" OpenAI researcher Noam Brown said at a recent conference.","attribution":"businessinsider.com","icon_type":null},{"matched_text":"\u301021\u2020L195-L203\u3011","start_idx":38358,"end_idx":38372,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u301040\u2020L183-L192\u3011","start_idx":38437,"end_idx":38451,"alt":null,"type":"webpage_extended","title":"What AGI hype means for Washington - POLITICO","url":"https://www.politico.com/newsletters/digital-future-daily/2025/01/08/what-agi-hype-means-for-washington-00197154#:~:text=And%20as%20a%20business%20proposition%2C,the%20company%20and%20Altman%20himself","pub_date":null,"snippet":"And as a business proposition, it\u2019s significant to the company for a very specific reason: Microsoft holds an exclusive cloud deal granting it access to OpenAI\u2019s technology, which ends once AGI is achieved. Should OpenAI\u2019s products indeed cross the threshold to AGI, it would unlock obvious financial rewards for the company and Altman himself.","attribution":"politico.com","icon_type":null},{"matched_text":"\u301040\u2020L194-L202\u3011","start_idx":38451,"end_idx":38465,"alt":null,"type":"webpage_extended","title":"What AGI hype means for Washington - POLITICO","url":"https://www.politico.com/newsletters/digital-future-daily/2025/01/08/what-agi-hype-means-for-washington-00197154#:~:text=Altman%20himself%2C%20in%20an%20interview,%E2%80%9D","pub_date":null,"snippet":"Altman himself, in an interview with Businessweek that inspired his blog reflections, admitted that pinpointing exactly when his company will reach AGI is tough because \u201cwe\u2019re going to move the goalposts, always.\u201d When asked why OpenAI (but not Altman himself) has stopped publicly discussing AGI, he explained that it became \u201ca very sloppy term.\u201d","attribution":"politico.com","icon_type":null},{"matched_text":"\u301018\u2020L294-L303\u3011","start_idx":38528,"end_idx":38542,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u301018\u2020L300-L308\u3011","start_idx":38542,"end_idx":38556,"alt":null,"type":"hidden","invalid":true},{"matched_text":"\u301032\u2020L175-L183\u3011","start_idx":38610,"end_idx":38624,"alt":null,"type":"hidden","invalid":true}],"timestamp_":"absolute","message_type":null,"is_async_task_result_message":true,"b1de6e2_rm":true,"async_task_id":"deepresch_67d6322d79988191891b1d1b7e9e8478","async_task_title":"Analysis of AI Researchers' Statements on AGI Progress (2024-2025)","can_save":true},"recipient":"all","channel":"final"},"parent":"e4cb9879-7331-438e-9fe3-6db5ccc1ce36","children":[]}}}