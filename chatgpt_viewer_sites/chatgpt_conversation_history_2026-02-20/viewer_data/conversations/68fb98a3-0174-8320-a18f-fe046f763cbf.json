{"id":"68fb98a3-0174-8320-a18f-fe046f763cbf","title":"Chip accuracy analysis","create_time":1761319077.165584,"update_time":1761319800.301078,"current_node":"d274ce01-3af5-44a5-ae75-c82bf7eb1aab","mapping":{"client-created-root":{"id":"client-created-root","message":null,"parent":null,"children":["0b0f52c2-8213-4d02-89d3-9c61a45a4896"]},"0b0f52c2-8213-4d02-89d3-9c61a45a4896":{"id":"0b0f52c2-8213-4d02-89d3-9c61a45a4896","message":{"id":"0b0f52c2-8213-4d02-89d3-9c61a45a4896","author":{"role":"system","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":true,"weight":0.0,"metadata":{"is_visually_hidden_from_conversation":true,"can_save":false},"recipient":"all","channel":null},"parent":"client-created-root","children":["8461ac03-27cd-4f8a-b178-4466d784487a"]},"8461ac03-27cd-4f8a-b178-4466d784487a":{"id":"8461ac03-27cd-4f8a-b178-4466d784487a","message":{"id":"8461ac03-27cd-4f8a-b178-4466d784487a","author":{"role":"system","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":true,"weight":0.0,"metadata":{"rebase_developer_message":true,"is_visually_hidden_from_conversation":true,"can_save":false},"recipient":"all","channel":null},"parent":"0b0f52c2-8213-4d02-89d3-9c61a45a4896","children":["606eccd3-3acb-45fd-af64-8860feace972"]},"606eccd3-3acb-45fd-af64-8860feace972":{"id":"606eccd3-3acb-45fd-af64-8860feace972","message":{"id":"606eccd3-3acb-45fd-af64-8860feace972","author":{"role":"user","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"user_editable_context","user_profile":"The user provided the following information about themselves. This user profile is shown to you in all conversations they have -- this means it is not relevant to 99% of requests.\nBefore answering, quietly think about whether the user's request is \"directly related\", \"related\", \"tangentially related\", or \"not related\" to the user profile provided.\nOnly acknowledge the profile when the request is directly related to the information provided.\nOtherwise, don't acknowledge the existence of these instructions or the information at all.\nUser profile:\n```Preferred name: E-Jay\nRole: Mathematics Researcher\nOther Information: About Myself: \nI have mathematical knowledge up to graduate level.\n\nCurrent interests:\n(1) coding: mainly Python\n(2) machine learning and artificial intelligence\n```","user_instructions":"The user provided the additional info about how they would like you to respond:\n```Be precise and comprehensive in your analysis. Don't sugar-coat responses. Be as objective as possible. Critique and question my views if necessary. Take a forward-thinking view.```"},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"is_visually_hidden_from_conversation":true,"user_context_message_data":{"about_user_message":"Preferred name: E-Jay\nRole: Mathematics Researcher\nOther Information: About Myself: \nI have mathematical knowledge up to graduate level.\n\nCurrent interests:\n(1) coding: mainly Python\n(2) machine learning and artificial intelligence\n","about_model_message":"Be precise and comprehensive in your analysis. Don't sugar-coat responses. Be as objective as possible. Critique and question my views if necessary. Take a forward-thinking view."},"is_user_system_message":true,"can_save":true},"recipient":"all","channel":null},"parent":"8461ac03-27cd-4f8a-b178-4466d784487a","children":["d068e0cb-c21c-4fc2-92c2-68cdd0d6403b"]},"d068e0cb-c21c-4fc2-92c2-68cdd0d6403b":{"id":"d068e0cb-c21c-4fc2-92c2-68cdd0d6403b","message":{"id":"d068e0cb-c21c-4fc2-92c2-68cdd0d6403b","author":{"role":"system","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"is_contextual_answers_system_message":true,"contextual_answers_message_type":"identity_prompt","is_visually_hidden_from_conversation":true,"can_save":false},"recipient":"all","channel":null},"parent":"606eccd3-3acb-45fd-af64-8860feace972","children":["6cc919cc-accf-4209-9405-b2ec1273fc76"]},"6cc919cc-accf-4209-9405-b2ec1273fc76":{"id":"6cc919cc-accf-4209-9405-b2ec1273fc76","message":{"id":"6cc919cc-accf-4209-9405-b2ec1273fc76","author":{"role":"user","name":null,"metadata":{}},"create_time":1761319073.123,"update_time":null,"content":{"content_type":"text","parts":["Analyse the veracity of this new Chinese invention. Hype or scientifically grounded? Peer reviewed yet? How promising is it?\n\n---\n\nIntroduction\r\nHost: Chinese scientists have created a superfast analog chip that can solve complex maths problems for advanced scientific tasks and artificial intelligence. According to researchers from Peking University, the device could work 1,000 times faster than top digital processors like Nvidia's graphics processing units. Here to tell us more is Post China reporter Victoria Bela. Hi, Victoria. So what do we know about this superfast analog chip?\r\n\r\nWhat We Know About the Chip\r\nVictoria Bela: The team\u2019s scalable analog device, which relies on memory chips made out of resistive materials, was designed specifically to solve matrix inversions, a complex type of mathematical problem that is widely used in different fields such as scientific computing, processing wireless communication signals, and training artificial intelligence models like neural networks. When the team applied their device to solving matrix inversion problems as well as processing wireless communication signals, they found that it actually worked better than some top-tier digital processors that are currently top-of-the-line. So, yes, it\u2019s a pretty big breakthrough.\r\n\r\nWhat Is Analog Computing?\r\nHost: So what exactly is analog computing?\r\n\r\nVictoria Bela: Digital computing, which is the dominant form of technology we use for most general tasks today, relies on binary digits\u2014zeros and ones\u2014to process information. Analog computing is a little bit different. It relies on continuous or varying physical phenomena\u2014things like voltage and mechanical motion\u2014to process information directly. You can think of it like digital computing being a standard light switch with two modes, on and off, while analog computing is like a dimmer dial where there are many different levels; it\u2019s a bit more dynamic. That gives it more flexibility, and it can be used to directly solve some of these issues. In basic forms, analog computing has existed for a very long time; in fact, it dates back to the ancient Greeks. But it has faced a lot of technical challenges, such as scalability and precision, that have really limited its applications, so digital computing became dominant for a very long time.\r\n\r\nHow It Differs from Digital Systems\r\nHost: So then how is this device different from digital systems like those from Nvidia?\r\n\r\nVictoria Bela: Unlike those top-tier digital processors\u2014GPUs from Nvidia or AMD\u2014the Peking University team\u2019s device relies on a physical phenomenon called conductance, which is essentially how easily current can flow through the memory arrays that make up the device. Instead of using binary digits\u2014ones and zeros\u2014it uses that physical phenomenon to perform calculations. The analog device already outperformed those top-tier GPUs from Nvidia and AMD, and through further improvements, such as circuitry improvements, they found that it could potentially have 100 times better energy efficiency for the same precision and potentially 1,000 times better throughput, which is the rate of data transfer or processing in a given time, for the same precision.\r\n\r\nIs Energy Efficiency the Main Advantage?\r\nHost: So is energy efficiency the most promising aspect of analog computing?\r\n\r\nVictoria Bela: Definitely. One of the main challenges that digital computing is facing as applications become more advanced is energy efficiency; it\u2019s also time consumption. This could really help overcome some of those energy issues and also deliver better precision, better accuracy, and better processing speeds. Analog computing could offer that for some of the more advanced calculations needed for simulating weather systems, driving advanced AI, and things like that.\r\n\r\nImpact on the Global Digital Landscape\r\nHost: So in that sense, how can this breakthrough change the global digital landscape?\r\n\r\nVictoria Bela: I think it could definitely enable more interesting applications in the future. A lot of people have been talking about more human-like AI, but running those systems and training those AIs takes a lot of data, a lot of calculations, a lot of processing. As we approach the physical limits of digital computing\u2014because there are limits to how much we can scale digital computing\u2014we really need something that can go beyond that. Analog computing offers that promise, but it\u2019s been bottlenecked for a very long time. Breakthroughs like these show that it has the potential to actually become a usable technology for some of these advanced applications in the future.\r\n\r\nClosing\r\nHost: Right. Sounds really promising. Victoria, thank you so much. To read more about this, you can visit scmp.com."]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"developer_mode_connector_ids":[],"selected_sources":[],"selected_github_repos":[],"serialization_metadata":{"custom_symbol_offsets":[]},"request_id":"5899ebd1-a44e-4bae-88bb-bc9587213187","message_source":null,"turn_exchange_id":"07c42b44-9afa-47a0-8171-7f40951db3b3","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"d068e0cb-c21c-4fc2-92c2-68cdd0d6403b","children":["ec08e72e-aa89-4816-af7e-8db6b48f09f4"]},"ec08e72e-aa89-4816-af7e-8db6b48f09f4":{"id":"ec08e72e-aa89-4816-af7e-8db6b48f09f4","message":{"id":"ec08e72e-aa89-4816-af7e-8db6b48f09f4","author":{"role":"system","name":null,"metadata":{}},"create_time":1761319076.9785929,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"is_contextual_answers_system_message":true,"is_visually_hidden_from_conversation":true,"command":"prompt","contextual_answers_message_type":"sources_and_filters_prompt","request_id":"5899ebd1-a44e-4bae-88bb-bc9587213187","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"max","parent_id":"6cc919cc-accf-4209-9405-b2ec1273fc76","turn_exchange_id":"07c42b44-9afa-47a0-8171-7f40951db3b3","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"6cc919cc-accf-4209-9405-b2ec1273fc76","children":["28241cf5-3906-4c31-812e-a93627eaa93f"]},"28241cf5-3906-4c31-812e-a93627eaa93f":{"id":"28241cf5-3906-4c31-812e-a93627eaa93f","message":{"id":"28241cf5-3906-4c31-812e-a93627eaa93f","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1761319077.4227965,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"request_id":"5899ebd1-a44e-4bae-88bb-bc9587213187","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"max","parent_id":"ec08e72e-aa89-4816-af7e-8db6b48f09f4","turn_exchange_id":"07c42b44-9afa-47a0-8171-7f40951db3b3","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"ec08e72e-aa89-4816-af7e-8db6b48f09f4","children":["401c2e79-5db6-4c70-acea-2fe21b4a065b"]},"401c2e79-5db6-4c70-acea-2fe21b4a065b":{"id":"401c2e79-5db6-4c70-acea-2fe21b4a065b","message":{"id":"401c2e79-5db6-4c70-acea-2fe21b4a065b","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1761319080.176901,"update_time":null,"content":{"content_type":"thoughts","thoughts":[{"summary":"Verifying claim of Chinese superfast chip","content":"I need to check the claim about a Chinese superfast analog chip from Peking University for matrix inversion using resistive memory arrays (memristor crossbars). It sounds like it's based on analog computing and memristor technology. I\u2019ll check the paper and the source to verify its details, possibly in Nature or related publications.","chunks":["I need to check the claim about a Chinese superfast analog chip from Peking University for matrix inversion using resistive memory arrays (memristor crossbars).","It sounds like it's based on analog computing and memristor technology.","I\u2019ll check the paper and the source to verify its details, possibly in Nature or related publications."],"finished":true},{"summary":"Evaluating speed claims and paper search","content":"The 1000x speed claim over GPUs sounds like it could be exaggerated and may only apply to specialized tasks with small precision limits. Analog computing struggles with noise and variability. I\u2019ll search for possible papers, like those on analog matrix-vector multiplication, focusing on recent publications from Peking University or related journals.","chunks":["The 1000x speed claim over GPUs sounds like it could be exaggerated and may only apply to specialized tasks with small precision limits.","Analog computing struggles with noise and variability.","I\u2019ll search for possible papers, like those on analog matrix-vector multiplication, focusing on recent publications from Peking University or related journals."],"finished":true},{"summary":"Evaluating claim and conducting search","content":"I\u2019ll start by searching for the SCMP article on the Peking University analog chip for matrix inversion, then look for supporting materials, such as a press release or preprint. From there, I\u2019ll assess the technical details and algorithms involved, like LU decomposition or iterative methods, and examine journal publication and metrics for credibility. I'll also check the GPU comparison.","chunks":["I\u2019ll start by searching for the SCMP article on the Peking University analog chip for matrix inversion, then look for supporting materials, such as a press release or preprint.","From there, I\u2019ll assess the technical details and algorithms involved, like LU decomposition or iterative methods, and examine journal publication and metrics for credibility.","I'll also check the GPU comparison."],"finished":true},{"summary":"Evaluating analog chip claims","content":"I need to critically assess the chip's speed claims, considering factors like ADC/DAC overhead, accuracy limits, and noise in resistive devices. There\u2019s also the potential tradeoff between precision and energy efficiency. While it might be useful for certain matrix inversion tasks, it's not yet general-purpose\u2014still more research needed.","chunks":["I need to critically assess the chip's speed claims, considering factors like ADC/DAC overhead, accuracy limits, and noise in resistive devices.","There\u2019s also the potential tradeoff between precision and energy efficiency.","While it might be useful for certain matrix inversion tasks, it's not yet general-purpose\u2014still more research needed."],"finished":true},{"summary":"Analyzing analog computing potential","content":"I\u2019ll analyze whether the claims about this new Peking University chip are backed by solid evidence and whether it truly outperforms GPUs. For that, I'll examine experimental aspects like scaling, noise, precision, and reproducibility, along with real-world AI tasks. I\u2019ll provide technical context and experiment results to support the assessment with citations and metrics.","chunks":["I\u2019ll analyze whether the claims about this new Peking University chip are backed by solid evidence and whether it truly outperforms GPUs.","For that, I'll examine experimental aspects like scaling, noise, precision, and reproducibility, along with real-world AI tasks.","I\u2019ll provide technical context and experiment results to support the assessment with citations and metrics."],"finished":true}],"source_analysis_msg_id":"60857209-83f8-4cf6-ba70-aa3b0782d501"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"is_reasoning","content_references":[],"citations":[],"classifier_response":"default","skip_reasoning_title":"Skip","request_id":"5899ebd1-a44e-4bae-88bb-bc9587213187","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"max","parent_id":"28241cf5-3906-4c31-812e-a93627eaa93f","turn_exchange_id":"07c42b44-9afa-47a0-8171-7f40951db3b3","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"28241cf5-3906-4c31-812e-a93627eaa93f","children":["7169c37b-4404-4a54-95c4-db3c4b83bf55"]},"7169c37b-4404-4a54-95c4-db3c4b83bf55":{"id":"7169c37b-4404-4a54-95c4-db3c4b83bf55","message":{"id":"7169c37b-4404-4a54-95c4-db3c4b83bf55","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1761319125.62634,"update_time":1761319125.638915,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"{\"search_query\": [{\"q\": \"Peking University analog chip matrix inversion resistive memory 1000 times faster GPU SCMP Victoria Bela\"}, {\"q\": \"superfast analog chip matrix inversion Peking University resistive memory device 1000 times faster than Nvidia\"}, {\"q\": \"matrix inversion analog chip resistive memory Peking University Nature 2025\"}, {\"q\": \"SCMP analog chip matrix inversion Victoria Bela interview Peking University 2025\"}], \"response_length\": \"short\"}"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200012]},"is_complete":true,"citations":[],"content_references":[],"reasoning_status":"is_reasoning","search_queries":[{"type":"search","q":"Peking University analog chip matrix inversion resistive memory 1000 times faster GPU SCMP Victoria Bela"},{"type":"search","q":"superfast analog chip matrix inversion Peking University resistive memory device 1000 times faster than Nvidia"},{"type":"search","q":"matrix inversion analog chip resistive memory Peking University Nature 2025"},{"type":"search","q":"SCMP analog chip matrix inversion Victoria Bela interview Peking University 2025"}],"search_display_string":"Searching the web...","searched_display_string":"Searched the web...","reasoning_title":"Searching for Peking University analog chip matrix inversion claims","classifier_response":"default","request_id":"5899ebd1-a44e-4bae-88bb-bc9587213187","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"max","parent_id":"401c2e79-5db6-4c70-acea-2fe21b4a065b","turn_exchange_id":"07c42b44-9afa-47a0-8171-7f40951db3b3","timestamp_":"absolute","can_save":true},"recipient":"web.run","channel":null},"parent":"401c2e79-5db6-4c70-acea-2fe21b4a065b","children":["c6b53081-ed00-4f63-be2d-b25f3e283a20"]},"c6b53081-ed00-4f63-be2d-b25f3e283a20":{"id":"c6b53081-ed00-4f63-be2d-b25f3e283a20","message":{"id":"c6b53081-ed00-4f63-be2d-b25f3e283a20","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1761319125.691451,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_model_queries":{"type":"search_model_queries","queries":["Peking University analog chip matrix inversion resistive memory 1000 times faster GPU SCMP Victoria Bela","superfast analog chip matrix inversion Peking University resistive memory device 1000 times faster than Nvidia","matrix inversion analog chip resistive memory Peking University Nature 2025","SCMP analog chip matrix inversion Victoria Bela interview Peking University 2025"]},"reasoning_status":"is_reasoning","reasoning_title":"Searching for Peking University analog chip matrix inversion claims","classifier_response":"default","request_id":"5899ebd1-a44e-4bae-88bb-bc9587213187","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"max","parent_id":"7169c37b-4404-4a54-95c4-db3c4b83bf55","turn_exchange_id":"07c42b44-9afa-47a0-8171-7f40951db3b3","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"7169c37b-4404-4a54-95c4-db3c4b83bf55","children":["c5925fb8-9ce3-4c18-b15c-ad94c992f866"]},"c5925fb8-9ce3-4c18-b15c-ad94c992f866":{"id":"c5925fb8-9ce3-4c18-b15c-ad94c992f866","message":{"id":"c5925fb8-9ce3-4c18-b15c-ad94c992f866","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1761319125.6896336,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_result_groups":[{"type":"search_result_group","domain":"www.scmp.com","entries":[{"type":"search_result","url":"https://www.scmp.com/news/china/science/article/3329820/chinas-analogue-ai-chip-could-work-1000-times-faster-nvidia-gpu-study","title":"China's analogue AI chip could work 1000 times faster than ...","snippet":"3 days ago \u2014 With future improvements, it could perform calculations at a processing rate 1,000 times faster than top digital processors, such as the Nvidia ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":0},"pub_date":1761058815.0,"attribution":"www.scmp.com"},{"type":"search_result","url":"https://www.scmp.com/author/victoria-bela","title":"Victoria Bela: Latest Articles, Analysis and Profile","snippet":"She holds a Master's in Public Policy from Peking University. Prior to joining SCMP in 2023, Victoria received her Bachelor's degrees in Environmental ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"www.scmp.com"}]},{"type":"search_result_group","domain":"www.nature.com","entries":[{"type":"search_result","url":"https://www.nature.com/articles/s41928-025-01477-0","title":"Precise and scalable analogue matrix equation solving ...","snippet":"by P Zuo \u00b7 2025 \u2014 Our approach uses an iterative algorithm that combines analogue low-precision matrix inversion and analogue high-precision matrix\u2013vector ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"www.nature.com"},{"type":"search_result","url":"https://www.nature.com/articles/s41586-022-04992-8","title":"A compute-in-memory chip based on resistive random- ...","snippet":"by W Wan \u00b7 2022 \u00b7 Cited by 826 \u2014 we present NeuRRAM\u2014a RRAM-based CIM chip that simultaneously delivers versatility in reconfiguring CIM cores for diverse model architectures ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":25},"pub_date":null,"attribution":"www.nature.com"}]},{"type":"search_result_group","domain":"amp.scmp.com","entries":[{"type":"search_result","url":"https://amp.scmp.com/news/china/science/article/3329820/chinas-analogue-ai-chip-could-work-1000-times-faster-nvidia-gpu-study","title":"China's analogue AI chip could work 1000 times faster than ...","snippet":"3 days ago \u2014 Chinese scientists have created a superfast analogue chip that can solve complex maths problems for advanced scientific tasks and artificial ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":2},"pub_date":1761058815.0,"attribution":"amp.scmp.com"}]},{"type":"search_result_group","domain":"www.globaltimes.cn","entries":[{"type":"search_result","url":"https://www.globaltimes.cn/page/202510/1345626.shtml","title":"Chinese researchers develop high-precision scalable ...","snippet":"Oct 14, 2025 \u2014 The chip delivers computing throughput and energy efficiency 100 to 1,000 times greater than current top digital processors (GPUs) in solving ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"www.globaltimes.cn"}]},{"type":"search_result_group","domain":"techovedas.com","entries":[{"type":"search_result","url":"https://techovedas.com/china-breaks-a-100-year-barrier-peking-university-unveils-worlds-most-precise-analog-computing-chip/","title":"Peking University Unveils World's Most Precise Analog ...","snippet":"3 days ago \u2014 The team has developed a high-precision and scalable analog matrix computing chip built on Resistive Random-Access Memory (RRAM) technology.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":6},"pub_date":1761018596.0,"attribution":"techovedas.com"}]},{"type":"search_result_group","domain":"www.extremarationews.com","entries":[{"type":"search_result","url":"https://www.extremarationews.com/post/intelligence-report-china-s-leap-in-high-precision-analog-computing-40-nm-rram-architectural-ev","title":"Intelligence Report: China's Leap in High-Precision Analog ...","snippet":"Resistive Random-Access Memory (RRAM) is the core technology chosen by the Peking University team to implement Analog Matrix Computing (AMC). RRAM is a non ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":7},"pub_date":1760475081.908,"attribution":"www.extremarationews.com"}]},{"type":"search_result_group","domain":"www.youtube.com","entries":[{"type":"search_result","url":"https://www.youtube.com/watch?v=JGJfafxjKTo","title":"Peking University team successfully developed a high ...","snippet":"Peking University team successfully developed a high-performance analog matrix computing chip. 1K views \u00b7 6 days ago #chinesenews ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"www.youtube.com"},{"type":"search_result","url":"https://www.youtube.com/watch?v=KVAmUlbLDIA","title":"Beijing Researchers Develop AI Chip Outperforming ...","snippet":"According to The China Briefing, scientists at Peking University have developed a groundbreaking analog AI chip that could be up to 1,000 ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"www.youtube.com"}]},{"type":"search_result_group","domain":"www.trendforce.com","entries":[{"type":"search_result","url":"https://www.trendforce.com/news/2025/10/21/news-chinese-scientists-developed-a-novel-chip-crossing-a-century-old-hurdle/","title":"[News] Chinese Scientists Developed a Novel Chip ...","snippet":"4 days ago \u2014 The team successfully developed a high-precision and scalable analog matrix computing chip based on resistive random-access memory (RRAM). For ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":9},"pub_date":1761035416.0,"attribution":"www.trendforce.com"}]},{"type":"search_result_group","domain":"www.techpioneer.cc","entries":[{"type":"search_result","url":"https://www.techpioneer.cc/news/2025-10-14/breakthrough-high-precision-analog-matrix-computing","title":"Breakthrough in High Precision Analog Matrix Computing | Tech ...","snippet":"Chinese scientists at Peking University have developed a high-precision analog matrix computing chip that surpasses current digital processors in efficiency ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":10},"pub_date":1760402435.0,"attribution":"www.techpioneer.cc"}]},{"type":"search_result_group","domain":"www.registrationchina.com","entries":[{"type":"search_result","url":"https://www.registrationchina.com/articles/new-chinese-chip/","title":"The Creation of the New Chinese Chip: The Era ...","snippet":"7 days ago \u2014 The Peking University study shows that the new Chinese chip can deliver hundreds to thousands of times higher throughput compared to leading ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":11},"pub_date":1760690671.0,"attribution":"www.registrationchina.com"}]},{"type":"search_result_group","domain":"en.eeworld.com.cn","entries":[{"type":"search_result","url":"https://en.eeworld.com.cn/mp/Icbank/a409025.jspx","title":"Chips developed by Chinese scientists break through century- ...","snippet":"For the first time, it brought analog computing accuracy to the same level as digital computing, while simultaneously increasing computing power and energy ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"en.eeworld.com.cn"}]},{"type":"search_result_group","domain":"www.facebook.com","entries":[{"type":"search_result","url":"https://www.facebook.com/groups/aifire.co/posts/1839791523292815/","title":"What if analogue ai chips replace traditional processors?","snippet":"It's physics. Unlike digital chips that slice reality into 0s and 1s, this new resistive memory-based system computes through continuous signals ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"www.facebook.com"},{"type":"search_result","url":"https://www.facebook.com/SunShineCNForever/posts/major-breakthrough-chinese-scientists-have-developed-the-latest-chip-overcoming-/1376681571049814/?locale=hi_IN","title":"Major breakthrough! Chinese scientists have developed ...","snippet":"Scientists in China have created a new quantum chip named Zuchongzhi 3.0 that is incredibly fast\u2014about 1 quadrillion times quicker than today's ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":20},"pub_date":null,"attribution":"www.facebook.com"},{"type":"search_result","url":"https://www.facebook.com/photo.php?fbid=10240508940050379&set=a.4240607462804&type=3","title":"a 2023 Tsinghua University study on a similar ...","snippet":"A South China Morning Post article from October 21, 2025, detailing Peking University researchers' development of a resistive memory-based ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":23},"pub_date":null,"attribution":"www.facebook.com"}]},{"type":"search_result_group","domain":"x.com","entries":[{"type":"search_result","url":"https://x.com/ExtremaRatio4/status/1978204646297805196","title":"Extrema Ratio","snippet":"Their new analog matrix solver, based on 40 nm RRAM technology, may ... #ChinaTech #AnalogComputing #RRAM #HighPrecisionAI #PekingUniversity ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"x.com"}]},{"type":"search_result_group","domain":"en.tmtpost.com","entries":[{"type":"search_result","url":"https://en.tmtpost.com/news/7721720","title":"Chinese Researchers Achieve High-Precision, Scalable ...","snippet":"Chinese scientists have developed a high-precision, scalable analog matrix computing chip based on resistive memory, creating for the first time an analog ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"en.tmtpost.com"}]},{"type":"search_result_group","domain":"www.aastocks.com","entries":[{"type":"search_result","url":"https://www.aastocks.com/en/stocks/news/aafn-con/NOW.1478978/latest-news/AAFN","title":"Report: Peking University Research Team Develops New ...","snippet":"8 hours ago \u2014 This breakthrough technology has, for the first time, increased the precision of analog computing to 24 bits fixed-point precision, with ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"www.aastocks.com"}]},{"type":"search_result_group","domain":"www.tsinghua.edu.cn","entries":[{"type":"search_result","url":"https://www.tsinghua.edu.cn/en/info/1569/12965.htm","title":"Chinese scientists create chip that can perform AI task ...","snippet":"Chinese scientists have produced a chip that is significantly faster and more energy efficient than current high-performance AI chips.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"www.tsinghua.edu.cn"}]},{"type":"search_result_group","domain":"www.researchgate.net","entries":[{"type":"search_result","url":"https://www.researchgate.net/publication/383137660_BlockAMC_Scalable_In-Memory_Analog_Matrix_Computing_for_Solving_Linear_Systems","title":"Scalable In-Memory Analog Matrix Computing for Solving Linear ...","snippet":"... The recursive blockwise inversion (RBI) algorithm aims at reducing the matrix inversion of a relatively large matrix to a smaller matrix that can fit in the ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":19},"pub_date":null,"attribution":"www.researchgate.net"}]},{"type":"search_result_group","domain":"www.linkedin.com","entries":[{"type":"search_result","url":"https://www.linkedin.com/posts/zhong-sun-91b597104_precise-and-scalable-analogue-matrix-equation-activity-7383590230920130560-_Zze","title":"Zhong Sun's Post","snippet":"Precision has been the Achilles' heel of analog computing. In our latest Nature Electronics paper, we overcome this long-standing limitation ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":21},"pub_date":null,"attribution":"www.linkedin.com"}]},{"type":"search_result_group","domain":"www.nomos-elibrary.de","entries":[{"type":"search_result","url":"https://www.nomos-elibrary.de/10.5771/9780739191804.pdf","title":"State-Society Relations and Governance in China","snippet":"This book is a collection of selected papers from an international conference titled \u201cThe State-Society Relations in the New Era: Lessons for and from. China,\u201d ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":22},"pub_date":null,"attribution":"www.nomos-elibrary.de"}]},{"type":"search_result_group","domain":"www.reddit.com","entries":[{"type":"search_result","url":"https://www.reddit.com/r/artificial/comments/17nxs0v/chinas_ai_analog_chip_claimed_to_be_3000x_faster/","title":"China's AI Analog Chip Claimed to Be 3000X Faster Than ...","snippet":"China's ACCEL chip, developed by Tsinghua University, is claimed to be 3000 times faster than Nvidia's A100 GPU and has 4000 million times higher energy ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":24},"pub_date":1699138101.309,"attribution":"www.reddit.com"}]},{"type":"search_result_group","domain":"www.explore-vc.org","entries":[{"type":"search_result","url":"https://www.explore-vc.org/en/objects.html?layout=showstar%3Aportfolio&start=20","title":"Objects","snippet":"by B Mkhonza \u2014 Dear user,. This section of our website forms the heart of the EVC project. Here you find a collection of images of objects from different 'visual cultures' ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":26},"pub_date":null,"attribution":"www.explore-vc.org"}]},{"type":"search_result_group","domain":"www.7dayadventurer.com","entries":[{"type":"search_result","url":"https://www.7dayadventurer.com/category/inter-ethnic-relations/","title":"Category Archives: Inter-ethnic relations","snippet":"Namibia in 2025 still bears the scars of its past subjugation by imperial colonial powers. Despite achieving independence in 1990, historical inequalities ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":27},"pub_date":null,"attribution":"www.7dayadventurer.com"}]},{"type":"search_result_group","domain":"interestingengineering.com","entries":[{"type":"search_result","url":"https://interestingengineering.com/innovation/chinese-gpus-surpass-nvidia","title":"China's supercomputer chips get 10 times more powerful ...","snippet":"Feb 13, 2025 \u2014 Chinese computer researchers have achieved a near-tenfold boost in performance over Nvidia-powered US supercomputers using domestically made graphics ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":28},"pub_date":null,"attribution":"interestingengineering.com"}]},{"type":"search_result_group","domain":"www.scribd.com","entries":[{"type":"search_result","url":"https://www.scribd.com/document/439535858/ANC-all-count-txt","title":"ANC All Count | PDF | Biotechnology | Life Sciences","snippet":"ANC-all-count.txt - Free download as Text File (.txt), PDF File (.pdf) or read online for free.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":29},"pub_date":null,"attribution":"www.scribd.com"}]}],"debug_sonic_thread_id":"thread_68fb98d5b8688320942a3b27d998f096","reasoning_status":"is_reasoning","reasoning_title":"Searching for Peking University analog chip matrix inversion claims","classifier_response":"default","request_id":"5899ebd1-a44e-4bae-88bb-bc9587213187","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"max","parent_id":"c6b53081-ed00-4f63-be2d-b25f3e283a20","turn_exchange_id":"07c42b44-9afa-47a0-8171-7f40951db3b3","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"c6b53081-ed00-4f63-be2d-b25f3e283a20","children":["dae3ac86-26cb-4159-a8fc-c5462710d577"]},"dae3ac86-26cb-4159-a8fc-c5462710d577":{"id":"dae3ac86-26cb-4159-a8fc-c5462710d577","message":{"id":"dae3ac86-26cb-4159-a8fc-c5462710d577","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1761319129.533304,"update_time":1761319129.539598,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"{\"open\": [{\"ref_id\": \"turn0search1\"}], \"response_length\": \"short\"}"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200012]},"is_complete":true,"citations":[],"content_references":[],"reasoning_status":"is_reasoning","reasoning_title":"Clicking Nature Electronics article link","classifier_response":"default","request_id":"5899ebd1-a44e-4bae-88bb-bc9587213187","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"max","parent_id":"c5925fb8-9ce3-4c18-b15c-ad94c992f866","turn_exchange_id":"07c42b44-9afa-47a0-8171-7f40951db3b3","timestamp_":"absolute","can_save":true},"recipient":"web.run","channel":null},"parent":"c5925fb8-9ce3-4c18-b15c-ad94c992f866","children":["9f2adb5f-4c02-4e8f-9c4b-2cc9d556472e"]},"9f2adb5f-4c02-4e8f-9c4b-2cc9d556472e":{"id":"9f2adb5f-4c02-4e8f-9c4b-2cc9d556472e","message":{"id":"9f2adb5f-4c02-4e8f-9c4b-2cc9d556472e","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1761319129.59686,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_result_groups":[{"type":"search_result_group","domain":"www.nature.com","entries":[{"type":"search_result","url":"https://www.nature.com/articles/s41928-025-01477-0","title":"Precise and scalable analogue matrix equation solving using resistive random-access memory chips | Nature Electronics","snippet":"Total lines: 691\n","ref_id":{"turn_index":1,"ref_type":"view","ref_index":0},"pub_date":null,"attribution":"www.nature.com"}]}],"debug_sonic_thread_id":"thread_68fb98d5b8688320942a3b27d998f096","reasoning_status":"is_reasoning","reasoning_title":"Clicking Nature Electronics article link","classifier_response":"default","request_id":"5899ebd1-a44e-4bae-88bb-bc9587213187","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"max","parent_id":"dae3ac86-26cb-4159-a8fc-c5462710d577","turn_exchange_id":"07c42b44-9afa-47a0-8171-7f40951db3b3","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"dae3ac86-26cb-4159-a8fc-c5462710d577","children":["905d1dac-1af8-4fd5-bdd9-ff8505a313ab"]},"905d1dac-1af8-4fd5-bdd9-ff8505a313ab":{"id":"905d1dac-1af8-4fd5-bdd9-ff8505a313ab","message":{"id":"905d1dac-1af8-4fd5-bdd9-ff8505a313ab","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1761319138.376125,"update_time":1761319138.384157,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"{\"click\": [{\"ref_id\": \"turn1view0\", \"id\": 27}], \"response_length\": \"short\"}"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200012]},"is_complete":true,"citations":[],"content_references":[],"reasoning_status":"is_reasoning","reasoning_title":"Extracting key claims and context from article","classifier_response":"default","request_id":"5899ebd1-a44e-4bae-88bb-bc9587213187","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"max","parent_id":"9f2adb5f-4c02-4e8f-9c4b-2cc9d556472e","turn_exchange_id":"07c42b44-9afa-47a0-8171-7f40951db3b3","timestamp_":"absolute","can_save":true},"recipient":"web.run","channel":null},"parent":"9f2adb5f-4c02-4e8f-9c4b-2cc9d556472e","children":["fece4725-47da-4a62-9cdc-2c8280111eda"]},"fece4725-47da-4a62-9cdc-2c8280111eda":{"id":"fece4725-47da-4a62-9cdc-2c8280111eda","message":{"id":"fece4725-47da-4a62-9cdc-2c8280111eda","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1761319138.4463341,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_result_groups":[{"type":"search_result_group","domain":"www.nature.com","entries":[{"type":"search_result","url":"https://www.nature.com/articles/s41467-024-49324-8","title":"A blueprint for precise and fault-tolerant analog neural networks | Nature Communications","snippet":"Total lines: 842\n","ref_id":{"turn_index":2,"ref_type":"view","ref_index":0},"pub_date":null,"attribution":"www.nature.com"}]}],"debug_sonic_thread_id":"thread_68fb98d5b8688320942a3b27d998f096","reasoning_status":"is_reasoning","reasoning_title":"Extracting key claims and context from article","classifier_response":"default","request_id":"5899ebd1-a44e-4bae-88bb-bc9587213187","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"max","parent_id":"905d1dac-1af8-4fd5-bdd9-ff8505a313ab","turn_exchange_id":"07c42b44-9afa-47a0-8171-7f40951db3b3","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"905d1dac-1af8-4fd5-bdd9-ff8505a313ab","children":["baf8861a-3f10-4d4c-bbf6-56d7a7e2c396"]},"baf8861a-3f10-4d4c-bbf6-56d7a7e2c396":{"id":"baf8861a-3f10-4d4c-bbf6-56d7a7e2c396","message":{"id":"baf8861a-3f10-4d4c-bbf6-56d7a7e2c396","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1761319141.805806,"update_time":1761319141.814813,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"{\"search_query\": [{\"q\": \"Nature Electronics News & Views analogue matrix equation solving resistive random-access memory 2025\"}, {\"q\": \"Peking University BlockAMC RRAM matrix inversion 24-bit fixed-point high precision Nature Electronics\"}], \"response_length\": \"short\"}"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200012]},"is_complete":true,"citations":[],"content_references":[],"reasoning_status":"is_reasoning","search_queries":[{"type":"search","q":"Nature Electronics News & Views analogue matrix equation solving resistive random-access memory 2025"},{"type":"search","q":"Peking University BlockAMC RRAM matrix inversion 24-bit fixed-point high precision Nature Electronics"}],"search_display_string":"Searching the web...","searched_display_string":"Searched the web...","reasoning_title":"Searching for analog precision commentary and news sources","classifier_response":"default","request_id":"5899ebd1-a44e-4bae-88bb-bc9587213187","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"max","parent_id":"fece4725-47da-4a62-9cdc-2c8280111eda","turn_exchange_id":"07c42b44-9afa-47a0-8171-7f40951db3b3","timestamp_":"absolute","can_save":true},"recipient":"web.run","channel":null},"parent":"fece4725-47da-4a62-9cdc-2c8280111eda","children":["947cc666-01d4-48e4-9fec-48b6d99499c4"]},"947cc666-01d4-48e4-9fec-48b6d99499c4":{"id":"947cc666-01d4-48e4-9fec-48b6d99499c4","message":{"id":"947cc666-01d4-48e4-9fec-48b6d99499c4","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1761319141.9408224,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_model_queries":{"type":"search_model_queries","queries":["Nature Electronics News & Views analogue matrix equation solving resistive random-access memory 2025","Peking University BlockAMC RRAM matrix inversion 24-bit fixed-point high precision Nature Electronics"]},"reasoning_status":"is_reasoning","reasoning_title":"Searching for analog precision commentary and news sources","classifier_response":"default","request_id":"5899ebd1-a44e-4bae-88bb-bc9587213187","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"max","parent_id":"baf8861a-3f10-4d4c-bbf6-56d7a7e2c396","turn_exchange_id":"07c42b44-9afa-47a0-8171-7f40951db3b3","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"baf8861a-3f10-4d4c-bbf6-56d7a7e2c396","children":["45bacd65-2625-4e13-80ee-6ca725466f3c"]},"45bacd65-2625-4e13-80ee-6ca725466f3c":{"id":"45bacd65-2625-4e13-80ee-6ca725466f3c","message":{"id":"45bacd65-2625-4e13-80ee-6ca725466f3c","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1761319141.9375122,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_result_groups":[{"type":"search_result_group","domain":"www.nature.com","entries":[{"type":"search_result","url":"https://www.nature.com/articles/s41928-025-01477-0","title":"Precise and scalable analogue matrix equation solving ...","snippet":"by P Zuo \u00b7 2025 \u2014 High-precision analogue MVM is achieved by bit-slicing. We validate in hardware the BlockAMC method, which solves large-scale matrix ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":0},"pub_date":null,"attribution":"www.nature.com"},{"type":"search_result","url":"https://www.nature.com/natelectron/articles?year=2025","title":"Articles in 2025 | Nature Electronics","snippet":"Precise and scalable analogue matrix equation solving using resistive random-access memory chips. An analogue matrix solver that combines low-precision matrix ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"www.nature.com"},{"type":"search_result","url":"https://www.nature.com/natelectron/","title":"Nature Electronics","snippet":"Precise and scalable analogue matrix equation solving using resistive random-access memory chips \u00b7 Score 97. Capillary flow printing of submicrometre carbon ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"www.nature.com"},{"type":"search_result","url":"https://www.nature.com/natelectron/articles?type=article&year=2025","title":"Articles in 2025 | Nature Electronics","snippet":"Precise and scalable analogue matrix equation solving using resistive random-access memory chips. An analogue matrix solver that combines low-precision matrix ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"www.nature.com"},{"type":"search_result","url":"https://www.nature.com/natelectron/research-articles?type=article&year=2025","title":"Research articles | Nature Electronics","snippet":"Precise and scalable analogue matrix equation solving using resistive random-access memory chips. An analogue matrix solver that combines low-precision matrix ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"www.nature.com"}]},{"type":"search_result_group","domain":"www.globaltimes.cn","entries":[{"type":"search_result","url":"https://www.globaltimes.cn/page/202510/1345626.shtml","title":"Chinese researchers develop high-precision scalable ...","snippet":"Oct 14, 2025 \u2014 Chinese researchers develop high-precision scalable analog matrix computing chip based on resistive memory, realizing for the first time an ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"www.globaltimes.cn"}]},{"type":"search_result_group","domain":"www.researchgate.net","entries":[{"type":"search_result","url":"https://www.researchgate.net/publication/396448715_Precise_and_scalable_analogue_matrix_equation_solving_using_resistive_random-access_memory_chips","title":"Precise and scalable analogue matrix equation solving ...","snippet":"Oct 13, 2025 \u2014 Both operations are implemented using 3-bit resistive random-access memory chips that are fabricated in a foundry. By combining these with a ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":3},"pub_date":1760313600.0,"attribution":"www.researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/scientific-contributions/Ruiqing-Xie-2303005538","title":"Ruiqing Xie's research works | Peking University and other ...","snippet":"By combining these with a block matrix algorithm, inversion problems involving 16 \u00d7 16 real-valued matrices are experimentally solved with 24-bit fixed-point ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"www.researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/scientific-contributions/Yimao-Cai-12097604","title":"Yimao Cai's research works | Peking University and other ...","snippet":"By combining these with a block matrix algorithm, inversion problems involving 16 \u00d7 16 real-valued matrices are experimentally solved with 24-bit fixed-point ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"www.researchgate.net"}]},{"type":"search_result_group","domain":"bioengineer.org","entries":[{"type":"search_result","url":"https://bioengineer.org/efficient-matrix-solving-with-resistive-ram-technology/","title":"Efficient Matrix Solving with Resistive RAM Technology","snippet":"Oct 13, 2025 \u2014 The experimental evidence is compelling: a 16\u00d716 matrix inversion problem was tackled utilizing the BlockAMC algorithm with an impressive 24-bit ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":4},"pub_date":1760362301.0,"attribution":"bioengineer.org"}]},{"type":"search_result_group","domain":"www.linkedin.com","entries":[{"type":"search_result","url":"https://www.linkedin.com/posts/zhong-sun-91b597104_precise-and-scalable-analogue-matrix-equation-activity-7383590230920130560-_Zze","title":"Zhong Sun's Post","snippet":"... matrix inversion with high-precision matrix\u2013vector multiplication, both realized on foundry-fabricated RRAM chips. We pioneered the matrix ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"www.linkedin.com"}]},{"type":"search_result_group","domain":"link.springer.com","entries":[{"type":"search_result","url":"https://link.springer.com/subjects/computer-memory-structure","title":"Computer Memory Structure - Recent articles and discoveries","snippet":"Precise and scalable analogue matrix equation solving using resistive random-access memory chips. Pushen Zuo; Qishen Wang; Zhong Sun. in Nature Electronics.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"link.springer.com"}]},{"type":"search_result_group","domain":"x.com","entries":[{"type":"search_result","url":"https://x.com/ExtremaRatio4/status/1978204646297805196","title":"Extrema Ratio","snippet":"... Peking University, and published in the international academic journal Nature Electronics. The Fact: Digital precision (24-bit/FP32) was ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"x.com"}]},{"type":"search_result_group","domain":"www.science.org","entries":[{"type":"search_result","url":"https://www.science.org/doi/10.1126/sciadv.adr6391","title":"Fully analog iteration for solving matrix equations with in- ...","snippet":"by J Li \u00b7 2025 \u00b7 Cited by 7 \u2014 This study introduces a memristive matrix equation solver that considerably accelerates solutions by performing mathematical iterations directly within an ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"www.science.org"}]},{"type":"search_result_group","domain":"arxiv.org","entries":[{"type":"search_result","url":"https://arxiv.org/pdf/2401.10042","title":"BlockAMC: Scalable In-Memory Analog Matrix Computing ...","snippet":"by L Pan \u00b7 2024 \u00b7 Cited by 6 \u2014 BlockAMC is a scalable in-memory analog matrix computing approach that partitions a large matrix into smaller ones to solve linear systems.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":14},"pub_date":1705384421.0,"attribution":"arxiv.org"}]},{"type":"search_result_group","domain":"inf.news","entries":[{"type":"search_result","url":"https://inf.news/en/tech/8ce8b4cf5e208c1918707911c67fa22e.html","title":"The end of GPU dominance, 24-bit precision, thousand ...","snippet":"6 days ago \u2014 The end of GPU dominance, 24-bit precision, thousand-fold throughput, Peking University's resistive memory chip published in Nature journal.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"inf.news"}]},{"type":"search_result_group","domain":"pmc.ncbi.nlm.nih.gov","entries":[{"type":"search_result","url":"https://pmc.ncbi.nlm.nih.gov/articles/PMC11817932/","title":"Fully analog iteration for solving matrix equations with in- ...","snippet":"by J Li \u00b7 2025 \u00b7 Cited by 7 \u2014 Memristive in-memory computing has demonstrated potential for solving matrix equations in scientific computing.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"pmc.ncbi.nlm.nih.gov"}]},{"type":"search_result_group","domain":"www.polyu.edu.hk","entries":[{"type":"search_result","url":"https://www.polyu.edu.hk/fs/docdrive/publication/20250806_Programme_Booklet.pdf","title":"AI x Science","snippet":"Aug 6, 2025 \u2014 A bit-sliced iterative refinement loop achieves full. FP32 (24-bit fixed-point) accuracy for high-precision updates. To scale up, a block-matrix.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":18},"pub_date":1754525437.0,"attribution":"www.polyu.edu.hk"}]}],"debug_sonic_thread_id":"thread_68fb98d5b8688320942a3b27d998f096","reasoning_status":"is_reasoning","reasoning_title":"Searching for analog precision commentary and news sources","classifier_response":"default","request_id":"5899ebd1-a44e-4bae-88bb-bc9587213187","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"max","parent_id":"947cc666-01d4-48e4-9fec-48b6d99499c4","turn_exchange_id":"07c42b44-9afa-47a0-8171-7f40951db3b3","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"947cc666-01d4-48e4-9fec-48b6d99499c4","children":["032ece19-0ae6-4067-b9c8-6934093acdbe"]},"032ece19-0ae6-4067-b9c8-6934093acdbe":{"id":"032ece19-0ae6-4067-b9c8-6934093acdbe","message":{"id":"032ece19-0ae6-4067-b9c8-6934093acdbe","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1761319149.9328,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_result_groups":[{"type":"search_result_group","domain":"www.nature.com","entries":[{"type":"search_result","url":"https://www.nature.com/articles/s41928-025-01477-0","title":"Precise and scalable analogue matrix equation solving using resistive random-access memory chips | Nature Electronics","snippet":"Total lines: 691\n","ref_id":{"turn_index":4,"ref_type":"view","ref_index":0},"pub_date":null,"attribution":"www.nature.com"},{"type":"search_result","url":"https://www.nature.com/articles/s41928-025-01477-0","title":"Precise and scalable analogue matrix equation solving using resistive random-access memory chips | Nature Electronics","snippet":"Total lines: 691\n","ref_id":{"turn_index":4,"ref_type":"view","ref_index":1},"pub_date":null,"attribution":"www.nature.com"},{"type":"search_result","url":"https://www.nature.com/articles/s41928-025-01477-0","title":"Precise and scalable analogue matrix equation solving using resistive random-access memory chips | Nature Electronics","snippet":"Total lines: 691\n","ref_id":{"turn_index":4,"ref_type":"view","ref_index":2},"pub_date":null,"attribution":"www.nature.com"},{"type":"search_result","url":"https://www.nature.com/articles/s41928-025-01477-0","title":"Precise and scalable analogue matrix equation solving using resistive random-access memory chips | Nature Electronics","snippet":"Total lines: 691\n","ref_id":{"turn_index":4,"ref_type":"view","ref_index":3},"pub_date":null,"attribution":"www.nature.com"},{"type":"search_result","url":"https://www.nature.com/articles/s41928-025-01477-0","title":"Precise and scalable analogue matrix equation solving using resistive random-access memory chips | Nature Electronics","snippet":"Total lines: 691\n","ref_id":{"turn_index":4,"ref_type":"view","ref_index":4},"pub_date":null,"attribution":"www.nature.com"}]}],"debug_sonic_thread_id":"thread_68fb98d5b8688320942a3b27d998f096","reasoning_status":"is_reasoning","reasoning_title":"Evaluating claims on RRAM chip performance and benchmarking","classifier_response":"default","request_id":"5899ebd1-a44e-4bae-88bb-bc9587213187","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"max","parent_id":"45bacd65-2625-4e13-80ee-6ca725466f3c","turn_exchange_id":"07c42b44-9afa-47a0-8171-7f40951db3b3","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"45bacd65-2625-4e13-80ee-6ca725466f3c","children":["9ce96992-8f00-46ea-aaac-cf40056342c4"]},"9ce96992-8f00-46ea-aaac-cf40056342c4":{"id":"9ce96992-8f00-46ea-aaac-cf40056342c4","message":{"id":"9ce96992-8f00-46ea-aaac-cf40056342c4","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1761319217.357939,"update_time":null,"content":{"content_type":"reasoning_recap","content":"Thought for 2m 18s"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"reasoning_ended","finished_duration_sec":138,"request_id":"5899ebd1-a44e-4bae-88bb-bc9587213187","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"max","parent_id":"032ece19-0ae6-4067-b9c8-6934093acdbe","turn_exchange_id":"07c42b44-9afa-47a0-8171-7f40951db3b3","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"032ece19-0ae6-4067-b9c8-6934093acdbe","children":["459b43d4-2b27-4cf0-943e-ae4115a86f31"]},"459b43d4-2b27-4cf0-943e-ae4115a86f31":{"id":"459b43d4-2b27-4cf0-943e-ae4115a86f31","message":{"id":"459b43d4-2b27-4cf0-943e-ae4115a86f31","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1761319217.227761,"update_time":1761319272.42099,"content":{"content_type":"text","parts":["Here\u2019s the short, surgical take:\n\n**Verdict:** it\u2019s *real* and **peer-reviewed** (Nature Electronics, 13 Oct 2025), but the headline \u201c1,000\u00d7 faster than Nvidia\u201d is a **projection under optimistic conditions**, not a system-level measurement. It\u2019s promising for **certain linear-algebra kernels** (matrix inversion / linear solves, e.g., MIMO detection), not a drop-in GPU replacement for general AI training. \ue200cite\ue202turn1view0\ue201\n\n---\n\n# What\u2019s actually new\n- **Paper & device.** Peking University demonstrates a *mixed-precision analogue* matrix-equation solver using **RRAM (1T1R TaOx) arrays fabricated in 40 nm CMOS**. The design couples a **low-precision analogue matrix-inverse (LP-INV)** block with **high-precision analogue MVM** via bit-slicing to iteratively refine the solution. \ue200cite\ue202turn1view0\ue201\n- **Measured results.** They **experimentally** solve **16\u00d716** real-valued matrix inversions to **24-bit fixed-point accuracy** (their proxy for FP32-class accuracy) and match FP32 digital performance on a **128\u00d78 massive-MIMO detection** task in **three iterations**. Precision improves \u2248**3 bits per iteration**. \ue200cite\ue202turn4view4\ue202turn4view3\ue201\n- **Where \u201c1000\u00d7\u201d comes from.** The paper\u2019s **benchmarking model** (not a full chip measurement) uses measured circuit timings + energy, includes DAC/ADC, normalizes GPUs to \u201cper-core,\u201d and then extrapolates performance vs. problem size. Under faster op-amp assumptions and larger on-array inversions, they project **up to ~1000\u00d7 higher throughput** and **~100\u00d7 energy efficiency** vs top GPUs/ASICs at FP32-like precision. **Key word: could.** \ue200cite\ue202turn4view2\ue201\n- **It *is* peer-reviewed.** The SCMP piece you quoted is summarizing that Nature Electronics article. \ue200cite\ue202turn0search0\ue201\n\n# What\u2019s solid vs. what\u2019s hype\n\n**Solid (demonstrated)**\n- Foundry-made **RRAM** arrays (8 conductance levels \u2248 3-bit cells) used for both the one-shot **analogue inversion** (small array) and high-precision **analogue MVM** (bit-sliced). \ue200cite\ue202turn1view0\ue201\n- **16\u00d716** inversions reaching **~10\u207b\u2077 relative error** after ~10 cycles; **MIMO detection** parity with FP32 in 3 cycles. \ue200cite\ue202turn4view3\ue201\n\n**Hype-sensitive (read the fine print)**\n- The **\u201c1,000\u00d7\u201d and \u201c100\u00d7\u201d** numbers are **modeled projections**, contingent on **faster analogue front-ends** and **larger on-array inversions** than currently demonstrated (LP-INV demo is **8\u00d78**; scaling to **32\u00d732\u201364\u00d764** requires a new tape-out). Gains also rely on how you define \u201cequivalent FLOPS\u201d for analogue hardware. \ue200cite\ue202turn4view2\ue201\n- **FP32-comparable** here means **24-bit fixed-point accuracy** via analogue bit-slicing; it does **not** equal FP32 **dynamic range**, and nothing here addresses **FP64** (often needed in scientific computing). \ue200cite\ue202turn4view3\ue201\n- **ADC/DAC overhead and precision** are a perennial constraint in analogue accelerators; energy per bit rises steeply with converter resolution. Their analysis includes converters, but broader literature flags this as the dominant cost/limit. \ue200cite\ue202turn2view0\ue201\n\n# How promising is it\u2014technically?\n**Medium-high promise for niche, linear-algebra heavy workloads; low for general-purpose AI training in the near term.**\n\n**Why promising**\n- Inversion/linear-solve kernels (e.g., **massive-MIMO detection**, certain **PDE solvers**, **second-order optimization** steps) can benefit from analogue **O(1)** on-array matrix operations combined with **iterative refinement**. Their **BlockAMC** scheme shows a credible path to scaling via block decomposition. \ue200cite\ue202turn4view4\ue201\n- Published alongside other 2025 analogue matrix-solver work (e.g., **memristive analog iteration** in *Science Advances*), indicating a **real research trend**, not a one-off. \ue200cite\ue202turn3search13\ue202turn3search17\ue201\n\n**Why to be cautious**\n- **Scalability limits**: On-array inversion beyond **8\u00d78** isn\u2019t yet demonstrated in silicon; **wire IR-drop**, **noise**, **device variability**, and **hard-wired feedback** make larger analog inversions non-trivial. The authors themselves flag this. \ue200cite\ue202turn4view2\ue201\n- **System integration**: To matter in the real world you need **monolithic integration** (LP-INV + HP-MVM + high-speed ADC/DAC + control), **software kernels**, and **robust calibration** across temperature/aging. The field knows this is hard; see broader analyses of analogue accelerators\u2019 precision/ADC bottlenecks. \ue200cite\ue202turn2view0\ue201\n- **Numerics**: Ill-conditioned matrices and **pivoting** pose challenges for fixed analogue pipelines; the paper doesn\u2019t claim universal robustness across condition numbers.\n\n# Bottom line (my call)\n- **Veracity:** **High**\u2014the core claims (16\u00d716 at 24-bit fixed-point; MIMO demo) are **supported by a peer-reviewed paper**. \ue200cite\ue202turn1view0\ue201  \n- **Hype factor:** **Moderate.** The **\u201c1000\u00d7 faster than Nvidia\u201d** line is **scenario-dependent modeling**, not an apples-to-apples, full-chip, system-level benchmark vs. H100s. Treat it as an **upper-bound** if their analogue front-ends and array sizes improve as assumed. \ue200cite\ue202turn4view2\ue201\n- **Promise:** **7/10** for **specialized linear-algebra accelerators** (wireless comms, certain scientific solves, second-order methods); **3/10** for replacing GPUs in **general AI training** any time soon.\n\n# What would convince me it\u2019s ready for prime time\n1) A **single-chip** tape-out integrating LP-INV, HP-MVM, fast **\u226510-bit** ADC/DAC, and controller;  \n2) **Head-to-head wall-clock & Joules** vs. H100/MI300 on **standardized linear-solve benchmarks** (varying condition numbers) at **fixed accuracy**;  \n3) Demonstrations beyond **16\u00d716** inversions **in hardware** (\u226532\u00d732 on-array) with quantified **drift/aging** and **temperature** robustness;  \n4) A **software runtime** (e.g., PyTorch/XLA-style kernels) exposing the solver as a **callable operator**.\n\nIf you want, I can pull specific figs/tables from the paper (e.g., the throughput/energy plots and the MIMO BER curves) and walk through the math of their mixed-precision iterative scheme and where the \u201c~3 bits per cycle\u201d comes from. \ue200cite\ue202turn4view2\ue202turn4view3\ue201\n\n**Sources:**  \n- Nature Electronics paper (open access), **13 Oct 2025**\u2014methods, measurements, and projections. \ue200cite\ue202turn1view0\ue201  \n- SCMP explainer summarizing the work and the 1,000\u00d7 claim (Victoria Bela), **21\u201322 Oct 2025**. \ue200cite\ue202turn0search2\ue201  \n- Broader analogue-compute context: ADC/DAC precision\u2013energy scaling and fault-tolerance trade-offs. \ue200cite\ue202turn2view0\ue201  \n- Parallel efforts on analogue matrix solvers (memristive iteration), 2025. \ue200cite\ue202turn3search13\ue202turn3search17\ue201\n\n"]},"status":"finished_successfully","end_turn":true,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200002]},"is_complete":true,"content_references":[{"matched_text":"\ue200cite\ue202turn1view0\ue201","start_idx":409,"end_idx":426,"safe_urls":["https://www.nature.com/articles/s41928-025-01477-0"],"refs":[],"alt":"([Nature](https://www.nature.com/articles/s41928-025-01477-0))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Precise and scalable analogue matrix equation solving using resistive random-access memory chips | Nature Electronics","url":"https://www.nature.com/articles/s41928-025-01477-0","pub_date":null,"snippet":null,"attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":1,"ref_type":"view","ref_index":0}],"hue":null,"attributions":null,"attribution":"Nature"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn1view0\ue201","start_idx":787,"end_idx":804,"safe_urls":["https://www.nature.com/articles/s41928-025-01477-0"],"refs":[],"alt":"([Nature](https://www.nature.com/articles/s41928-025-01477-0))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Precise and scalable analogue matrix equation solving using resistive random-access memory chips | Nature Electronics","url":"https://www.nature.com/articles/s41928-025-01477-0","pub_date":null,"snippet":null,"attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":1,"ref_type":"view","ref_index":0}],"hue":null,"attributions":null,"attribution":"Nature"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn4view4\ue202turn4view3\ue201","start_idx":1121,"end_idx":1149,"safe_urls":["https://www.nature.com/articles/s41928-025-01477-0"],"refs":[],"alt":"([Nature](https://www.nature.com/articles/s41928-025-01477-0))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Precise and scalable analogue matrix equation solving using resistive random-access memory chips | Nature Electronics","url":"https://www.nature.com/articles/s41928-025-01477-0","pub_date":null,"snippet":null,"attribution_segments":null,"supporting_websites":[{"title":"Precise and scalable analogue matrix equation solving using resistive random-access memory chips | Nature Electronics","url":"https://www.nature.com/articles/s41928-025-01477-0","pub_date":null,"snippet":null,"attribution":"Nature"}],"refs":[{"turn_index":4,"ref_type":"view","ref_index":4},{"turn_index":4,"ref_type":"view","ref_index":3}],"hue":null,"attributions":null,"attribution":"Nature"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn4view2\ue201","start_idx":1595,"end_idx":1612,"safe_urls":["https://www.nature.com/articles/s41928-025-01477-0"],"refs":[],"alt":"([Nature](https://www.nature.com/articles/s41928-025-01477-0))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Precise and scalable analogue matrix equation solving using resistive random-access memory chips | Nature Electronics","url":"https://www.nature.com/articles/s41928-025-01477-0","pub_date":null,"snippet":null,"attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":4,"ref_type":"view","ref_index":2}],"hue":null,"attributions":null,"attribution":"Nature"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search0\ue201","start_idx":1716,"end_idx":1735,"safe_urls":["https://www.scmp.com/news/china/science/article/3329820/chinas-analogue-ai-chip-could-work-1000-times-faster-nvidia-gpu-study?utm_source=chatgpt.com"],"refs":[],"alt":"([South China Morning Post](https://www.scmp.com/news/china/science/article/3329820/chinas-analogue-ai-chip-could-work-1000-times-faster-nvidia-gpu-study?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"China's analogue AI chip could work 1000 times faster than ...","url":"https://www.scmp.com/news/china/science/article/3329820/chinas-analogue-ai-chip-could-work-1000-times-faster-nvidia-gpu-study?utm_source=chatgpt.com","pub_date":1761058815.0,"snippet":"3 days ago \u2014 With future improvements, it could perform calculations at a processing rate 1,000 times faster than top digital processors, such as the Nvidia ...","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":0}],"hue":null,"attributions":null,"attribution":"South China Morning Post"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn1view0\ue201","start_idx":1976,"end_idx":1993,"safe_urls":["https://www.nature.com/articles/s41928-025-01477-0"],"refs":[],"alt":"([Nature](https://www.nature.com/articles/s41928-025-01477-0))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Precise and scalable analogue matrix equation solving using resistive random-access memory chips | Nature Electronics","url":"https://www.nature.com/articles/s41928-025-01477-0","pub_date":null,"snippet":null,"attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":1,"ref_type":"view","ref_index":0}],"hue":null,"attributions":null,"attribution":"Nature"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn4view3\ue201","start_idx":2118,"end_idx":2135,"safe_urls":["https://www.nature.com/articles/s41928-025-01477-0"],"refs":[],"alt":"([Nature](https://www.nature.com/articles/s41928-025-01477-0))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Precise and scalable analogue matrix equation solving using resistive random-access memory chips | Nature Electronics","url":"https://www.nature.com/articles/s41928-025-01477-0","pub_date":null,"snippet":null,"attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":4,"ref_type":"view","ref_index":3}],"hue":null,"attributions":null,"attribution":"Nature"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn4view2\ue201","start_idx":2507,"end_idx":2524,"safe_urls":["https://www.nature.com/articles/s41928-025-01477-0"],"refs":[],"alt":"([Nature](https://www.nature.com/articles/s41928-025-01477-0))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Precise and scalable analogue matrix equation solving using resistive random-access memory chips | Nature Electronics","url":"https://www.nature.com/articles/s41928-025-01477-0","pub_date":null,"snippet":null,"attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":4,"ref_type":"view","ref_index":2}],"hue":null,"attributions":null,"attribution":"Nature"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn4view3\ue201","start_idx":2738,"end_idx":2755,"safe_urls":["https://www.nature.com/articles/s41928-025-01477-0"],"refs":[],"alt":"([Nature](https://www.nature.com/articles/s41928-025-01477-0))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Precise and scalable analogue matrix equation solving using resistive random-access memory chips | Nature Electronics","url":"https://www.nature.com/articles/s41928-025-01477-0","pub_date":null,"snippet":null,"attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":4,"ref_type":"view","ref_index":3}],"hue":null,"attributions":null,"attribution":"Nature"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn2view0\ue201","start_idx":3000,"end_idx":3017,"safe_urls":["https://www.nature.com/articles/s41467-024-49324-8"],"refs":[],"alt":"([Nature](https://www.nature.com/articles/s41467-024-49324-8))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"A blueprint for precise and fault-tolerant analog neural networks | Nature Communications","url":"https://www.nature.com/articles/s41467-024-49324-8","pub_date":null,"snippet":null,"attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":2,"ref_type":"view","ref_index":0}],"hue":null,"attributions":null,"attribution":"Nature"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn4view4\ue201","start_idx":3510,"end_idx":3527,"safe_urls":["https://www.nature.com/articles/s41928-025-01477-0"],"refs":[],"alt":"([Nature](https://www.nature.com/articles/s41928-025-01477-0))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Precise and scalable analogue matrix equation solving using resistive random-access memory chips | Nature Electronics","url":"https://www.nature.com/articles/s41928-025-01477-0","pub_date":null,"snippet":null,"attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":4,"ref_type":"view","ref_index":4}],"hue":null,"attributions":null,"attribution":"Nature"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn3search13\ue202turn3search17\ue201","start_idx":3705,"end_idx":3739,"safe_urls":["https://pmc.ncbi.nlm.nih.gov/articles/PMC11817932/?utm_source=chatgpt.com","https://www.science.org/doi/10.1126/sciadv.adr6391?utm_source=chatgpt.com"],"refs":[],"alt":"([Science](https://www.science.org/doi/10.1126/sciadv.adr6391?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Fully analog iteration for solving matrix equations with in- ...","url":"https://www.science.org/doi/10.1126/sciadv.adr6391?utm_source=chatgpt.com","pub_date":null,"snippet":"by J Li \u00b7 2025 \u00b7 Cited by 7 \u2014 This study introduces a memristive matrix equation solver that considerably accelerates solutions by performing mathematical iterations directly within an ...","attribution_segments":null,"supporting_websites":[{"title":"Fully analog iteration for solving matrix equations with in- ...","url":"https://pmc.ncbi.nlm.nih.gov/articles/PMC11817932/?utm_source=chatgpt.com","pub_date":null,"snippet":"by J Li \u00b7 2025 \u00b7 Cited by 7 \u2014 Memristive in-memory computing has demonstrated potential for solving matrix equations in scientific computing.","attribution":"PMC"}],"refs":[{"turn_index":3,"ref_type":"search","ref_index":13},{"turn_index":3,"ref_type":"search","ref_index":17}],"hue":null,"attributions":null,"attribution":"Science"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn4view2\ue201","start_idx":4017,"end_idx":4034,"safe_urls":["https://www.nature.com/articles/s41928-025-01477-0"],"refs":[],"alt":"([Nature](https://www.nature.com/articles/s41928-025-01477-0))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Precise and scalable analogue matrix equation solving using resistive random-access memory chips | Nature Electronics","url":"https://www.nature.com/articles/s41928-025-01477-0","pub_date":null,"snippet":null,"attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":4,"ref_type":"view","ref_index":2}],"hue":null,"attributions":null,"attribution":"Nature"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn2view0\ue201","start_idx":4354,"end_idx":4371,"safe_urls":["https://www.nature.com/articles/s41467-024-49324-8"],"refs":[],"alt":"([Nature](https://www.nature.com/articles/s41467-024-49324-8))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"A blueprint for precise and fault-tolerant analog neural networks | Nature Communications","url":"https://www.nature.com/articles/s41467-024-49324-8","pub_date":null,"snippet":null,"attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":2,"ref_type":"view","ref_index":0}],"hue":null,"attributions":null,"attribution":"Nature"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn1view0\ue201","start_idx":4698,"end_idx":4715,"safe_urls":["https://www.nature.com/articles/s41928-025-01477-0"],"refs":[],"alt":"([Nature](https://www.nature.com/articles/s41928-025-01477-0))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Precise and scalable analogue matrix equation solving using resistive random-access memory chips | Nature Electronics","url":"https://www.nature.com/articles/s41928-025-01477-0","pub_date":null,"snippet":null,"attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":1,"ref_type":"view","ref_index":0}],"hue":null,"attributions":null,"attribution":"Nature"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn4view2\ue201","start_idx":4993,"end_idx":5010,"safe_urls":["https://www.nature.com/articles/s41928-025-01477-0"],"refs":[],"alt":"([Nature](https://www.nature.com/articles/s41928-025-01477-0))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Precise and scalable analogue matrix equation solving using resistive random-access memory chips | Nature Electronics","url":"https://www.nature.com/articles/s41928-025-01477-0","pub_date":null,"snippet":null,"attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":4,"ref_type":"view","ref_index":2}],"hue":null,"attributions":null,"attribution":"Nature"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn4view2\ue202turn4view3\ue201","start_idx":6015,"end_idx":6043,"safe_urls":["https://www.nature.com/articles/s41928-025-01477-0"],"refs":[],"alt":"([Nature](https://www.nature.com/articles/s41928-025-01477-0))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Precise and scalable analogue matrix equation solving using resistive random-access memory chips | Nature Electronics","url":"https://www.nature.com/articles/s41928-025-01477-0","pub_date":null,"snippet":null,"attribution_segments":null,"supporting_websites":[{"title":"Precise and scalable analogue matrix equation solving using resistive random-access memory chips | Nature Electronics","url":"https://www.nature.com/articles/s41928-025-01477-0","pub_date":null,"snippet":null,"attribution":"Nature"}],"refs":[{"turn_index":4,"ref_type":"view","ref_index":2},{"turn_index":4,"ref_type":"view","ref_index":3}],"hue":null,"attributions":null,"attribution":"Nature"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn1view0\ue201","start_idx":6158,"end_idx":6175,"safe_urls":["https://www.nature.com/articles/s41928-025-01477-0"],"refs":[],"alt":"([Nature](https://www.nature.com/articles/s41928-025-01477-0))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Precise and scalable analogue matrix equation solving using resistive random-access memory chips | Nature Electronics","url":"https://www.nature.com/articles/s41928-025-01477-0","pub_date":null,"snippet":null,"attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":1,"ref_type":"view","ref_index":0}],"hue":null,"attributions":null,"attribution":"Nature"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search2\ue201","start_idx":6274,"end_idx":6293,"safe_urls":["https://amp.scmp.com/news/china/science/article/3329820/chinas-analogue-ai-chip-could-work-1000-times-faster-nvidia-gpu-study?utm_source=chatgpt.com"],"refs":[],"alt":"([South China Morning Post](https://amp.scmp.com/news/china/science/article/3329820/chinas-analogue-ai-chip-could-work-1000-times-faster-nvidia-gpu-study?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"China's analogue AI chip could work 1000 times faster than ...","url":"https://amp.scmp.com/news/china/science/article/3329820/chinas-analogue-ai-chip-could-work-1000-times-faster-nvidia-gpu-study?utm_source=chatgpt.com","pub_date":1761058815.0,"snippet":"3 days ago \u2014 Chinese scientists have created a superfast analogue chip that can solve complex maths problems for advanced scientific tasks and artificial ...","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":2}],"hue":null,"attributions":null,"attribution":"South China Morning Post"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn2view0\ue201","start_idx":6397,"end_idx":6414,"safe_urls":["https://www.nature.com/articles/s41467-024-49324-8"],"refs":[],"alt":"([Nature](https://www.nature.com/articles/s41467-024-49324-8))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"A blueprint for precise and fault-tolerant analog neural networks | Nature Communications","url":"https://www.nature.com/articles/s41467-024-49324-8","pub_date":null,"snippet":null,"attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":2,"ref_type":"view","ref_index":0}],"hue":null,"attributions":null,"attribution":"Nature"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn3search13\ue202turn3search17\ue201","start_idx":6493,"end_idx":6527,"safe_urls":["https://pmc.ncbi.nlm.nih.gov/articles/PMC11817932/?utm_source=chatgpt.com","https://www.science.org/doi/10.1126/sciadv.adr6391?utm_source=chatgpt.com"],"refs":[],"alt":"([Science](https://www.science.org/doi/10.1126/sciadv.adr6391?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Fully analog iteration for solving matrix equations with in- ...","url":"https://www.science.org/doi/10.1126/sciadv.adr6391?utm_source=chatgpt.com","pub_date":null,"snippet":"by J Li \u00b7 2025 \u00b7 Cited by 7 \u2014 This study introduces a memristive matrix equation solver that considerably accelerates solutions by performing mathematical iterations directly within an ...","attribution_segments":null,"supporting_websites":[{"title":"Fully analog iteration for solving matrix equations with in- ...","url":"https://pmc.ncbi.nlm.nih.gov/articles/PMC11817932/?utm_source=chatgpt.com","pub_date":null,"snippet":"by J Li \u00b7 2025 \u00b7 Cited by 7 \u2014 Memristive in-memory computing has demonstrated potential for solving matrix equations in scientific computing.","attribution":"PMC"}],"refs":[{"turn_index":3,"ref_type":"search","ref_index":13},{"turn_index":3,"ref_type":"search","ref_index":17}],"hue":null,"attributions":null,"attribution":"Science"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":" ","start_idx":6529,"end_idx":6529,"safe_urls":[],"refs":[],"alt":"","prompt_text":null,"type":"sources_footnote","sources":[{"title":"Precise and scalable analogue matrix equation solving using resistive random-access memory chips | Nature Electronics","url":"https://www.nature.com/articles/s41928-025-01477-0","attribution":"Nature"},{"title":"China's analogue AI chip could work 1000 times faster than ...","url":"https://www.scmp.com/news/china/science/article/3329820/chinas-analogue-ai-chip-could-work-1000-times-faster-nvidia-gpu-study?utm_source=chatgpt.com","attribution":"South China Morning Post"},{"title":"Fully analog iteration for solving matrix equations with in- ...","url":"https://www.science.org/doi/10.1126/sciadv.adr6391?utm_source=chatgpt.com","attribution":"Science"},{"title":"China's analogue AI chip could work 1000 times faster than ...","url":"https://amp.scmp.com/news/china/science/article/3329820/chinas-analogue-ai-chip-could-work-1000-times-faster-nvidia-gpu-study?utm_source=chatgpt.com","attribution":"South China Morning Post"}],"has_images":false}],"safe_urls":["https://www.nature.com/articles/s41928-025-01477-0","https://www.nature.com/articles/s41928-025-01477-0","https://www.nature.com/articles/s41928-025-01477-0","https://www.nature.com/articles/s41928-025-01477-0","https://www.scmp.com/news/china/science/article/3329820/chinas-analogue-ai-chip-could-work-1000-times-faster-nvidia-gpu-study?utm_source=chatgpt.com","https://www.nature.com/articles/s41928-025-01477-0","https://www.nature.com/articles/s41928-025-01477-0","https://www.nature.com/articles/s41928-025-01477-0","https://www.nature.com/articles/s41928-025-01477-0","https://www.nature.com/articles/s41467-024-49324-8","https://www.nature.com/articles/s41928-025-01477-0","https://pmc.ncbi.nlm.nih.gov/articles/PMC11817932/?utm_source=chatgpt.com","https://www.science.org/doi/10.1126/sciadv.adr6391?utm_source=chatgpt.com","https://www.nature.com/articles/s41928-025-01477-0","https://www.nature.com/articles/s41467-024-49324-8","https://www.nature.com/articles/s41928-025-01477-0","https://www.nature.com/articles/s41928-025-01477-0","https://www.nature.com/articles/s41928-025-01477-0","https://www.nature.com/articles/s41928-025-01477-0","https://amp.scmp.com/news/china/science/article/3329820/chinas-analogue-ai-chip-could-work-1000-times-faster-nvidia-gpu-study?utm_source=chatgpt.com","https://www.nature.com/articles/s41467-024-49324-8","https://pmc.ncbi.nlm.nih.gov/articles/PMC11817932/?utm_source=chatgpt.com","https://www.science.org/doi/10.1126/sciadv.adr6391?utm_source=chatgpt.com"],"search_result_groups":[{"type":"search_result_group","domain":"nature.com","entries":[{"type":"search_result","url":"https://www.nature.com/articles/s41928-025-01477-0?utm_source=chatgpt.com","title":"Precise and scalable analogue matrix equation solving ...","snippet":"by P Zuo \u00b7 2025 \u2014 Our approach uses an iterative algorithm that combines analogue low-precision matrix inversion and analogue high-precision matrix\u2013vector ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"nature.com"},{"type":"search_result","url":"https://www.nature.com/articles/s41586-022-04992-8?utm_source=chatgpt.com","title":"A compute-in-memory chip based on resistive random- ...","snippet":"by W Wan \u00b7 2022 \u00b7 Cited by 826 \u2014 we present NeuRRAM\u2014a RRAM-based CIM chip that simultaneously delivers versatility in reconfiguring CIM cores for diverse model architectures ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":25},"pub_date":null,"attribution":"nature.com"},{"type":"search_result","url":"https://www.nature.com/natelectron/articles?year=2025&utm_source=chatgpt.com","title":"Articles in 2025 | Nature Electronics","snippet":"Precise and scalable analogue matrix equation solving using resistive random-access memory chips. An analogue matrix solver that combines low-precision matrix ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"nature.com"},{"type":"search_result","url":"https://www.nature.com/natelectron/?utm_source=chatgpt.com","title":"Nature Electronics","snippet":"Precise and scalable analogue matrix equation solving using resistive random-access memory chips \u00b7 Score 97. Capillary flow printing of submicrometre carbon ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"nature.com"},{"type":"search_result","url":"https://www.nature.com/natelectron/articles?type=article&year=2025&utm_source=chatgpt.com","title":"Articles in 2025 | Nature Electronics","snippet":"Precise and scalable analogue matrix equation solving using resistive random-access memory chips. An analogue matrix solver that combines low-precision matrix ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"nature.com"},{"type":"search_result","url":"https://www.nature.com/natelectron/research-articles?type=article&year=2025&utm_source=chatgpt.com","title":"Research articles | Nature Electronics","snippet":"Precise and scalable analogue matrix equation solving using resistive random-access memory chips. An analogue matrix solver that combines low-precision matrix ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"nature.com"}]},{"type":"search_result_group","domain":"globaltimes.cn","entries":[{"type":"search_result","url":"https://www.globaltimes.cn/page/202510/1345626.shtml?utm_source=chatgpt.com","title":"Chinese researchers develop high-precision scalable ...","snippet":"Oct 14, 2025 \u2014 The chip delivers computing throughput and energy efficiency 100 to 1,000 times greater than current top digital processors (GPUs) in solving ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"globaltimes.cn"}]},{"type":"search_result_group","domain":"researchgate.net","entries":[{"type":"search_result","url":"https://www.researchgate.net/publication/383137660_BlockAMC_Scalable_In-Memory_Analog_Matrix_Computing_for_Solving_Linear_Systems?utm_source=chatgpt.com","title":"Scalable In-Memory Analog Matrix Computing for Solving Linear ...","snippet":"... The recursive blockwise inversion (RBI) algorithm aims at reducing the matrix inversion of a relatively large matrix to a smaller matrix that can fit in the ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":19},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/396448715_Precise_and_scalable_analogue_matrix_equation_solving_using_resistive_random-access_memory_chips?utm_source=chatgpt.com","title":"Precise and scalable analogue matrix equation solving ...","snippet":"Oct 13, 2025 \u2014 Both operations are implemented using 3-bit resistive random-access memory chips that are fabricated in a foundry. By combining these with a ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/scientific-contributions/Ruiqing-Xie-2303005538?utm_source=chatgpt.com","title":"Ruiqing Xie's research works | Peking University and other ...","snippet":"By combining these with a block matrix algorithm, inversion problems involving 16 \u00d7 16 real-valued matrices are experimentally solved with 24-bit fixed-point ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/scientific-contributions/Yimao-Cai-12097604?utm_source=chatgpt.com","title":"Yimao Cai's research works | Peking University and other ...","snippet":"By combining these with a block matrix algorithm, inversion problems involving 16 \u00d7 16 real-valued matrices are experimentally solved with 24-bit fixed-point ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"researchgate.net"}]},{"type":"search_result_group","domain":"bioengineer.org","entries":[{"type":"search_result","url":"https://bioengineer.org/efficient-matrix-solving-with-resistive-ram-technology/?utm_source=chatgpt.com","title":"Efficient Matrix Solving with Resistive RAM Technology","snippet":"Oct 13, 2025 \u2014 The experimental evidence is compelling: a 16\u00d716 matrix inversion problem was tackled utilizing the BlockAMC algorithm with an impressive 24-bit ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"bioengineer.org"}]},{"type":"search_result_group","domain":"scmp.com","entries":[{"type":"search_result","url":"https://www.scmp.com/author/victoria-bela?utm_source=chatgpt.com","title":"Victoria Bela: Latest Articles, Analysis and Profile","snippet":"She holds a Master's in Public Policy from Peking University. Prior to joining SCMP in 2023, Victoria received her Bachelor's degrees in Environmental ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"scmp.com"}]},{"type":"search_result_group","domain":"techovedas.com","entries":[{"type":"search_result","url":"https://techovedas.com/china-breaks-a-100-year-barrier-peking-university-unveils-worlds-most-precise-analog-computing-chip/?utm_source=chatgpt.com","title":"Peking University Unveils World's Most Precise Analog ...","snippet":"3 days ago \u2014 The team has developed a high-precision and scalable analog matrix computing chip built on Resistive Random-Access Memory (RRAM) technology.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"techovedas.com"}]},{"type":"search_result_group","domain":"extremarationews.com","entries":[{"type":"search_result","url":"https://www.extremarationews.com/post/intelligence-report-china-s-leap-in-high-precision-analog-computing-40-nm-rram-architectural-ev?utm_source=chatgpt.com","title":"Intelligence Report: China's Leap in High-Precision Analog ...","snippet":"Resistive Random-Access Memory (RRAM) is the core technology chosen by the Peking University team to implement Analog Matrix Computing (AMC). RRAM is a non ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"extremarationews.com"}]},{"type":"search_result_group","domain":"youtube.com","entries":[{"type":"search_result","url":"https://www.youtube.com/watch?v=JGJfafxjKTo&utm_source=chatgpt.com","title":"Peking University team successfully developed a high ...","snippet":"Peking University team successfully developed a high-performance analog matrix computing chip. 1K views \u00b7 6 days ago #chinesenews ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"youtube.com"},{"type":"search_result","url":"https://www.youtube.com/watch?v=KVAmUlbLDIA&utm_source=chatgpt.com","title":"Beijing Researchers Develop AI Chip Outperforming ...","snippet":"According to The China Briefing, scientists at Peking University have developed a groundbreaking analog AI chip that could be up to 1,000 ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"youtube.com"}]},{"type":"search_result_group","domain":"trendforce.com","entries":[{"type":"search_result","url":"https://www.trendforce.com/news/2025/10/21/news-chinese-scientists-developed-a-novel-chip-crossing-a-century-old-hurdle/?utm_source=chatgpt.com","title":"[News] Chinese Scientists Developed a Novel Chip ...","snippet":"4 days ago \u2014 The team successfully developed a high-precision and scalable analog matrix computing chip based on resistive random-access memory (RRAM). For ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"trendforce.com"}]},{"type":"search_result_group","domain":"techpioneer.cc","entries":[{"type":"search_result","url":"https://www.techpioneer.cc/news/2025-10-14/breakthrough-high-precision-analog-matrix-computing?utm_source=chatgpt.com","title":"Breakthrough in High Precision Analog Matrix Computing | Tech ...","snippet":"Chinese scientists at Peking University have developed a high-precision analog matrix computing chip that surpasses current digital processors in efficiency ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"techpioneer.cc"}]},{"type":"search_result_group","domain":"registrationchina.com","entries":[{"type":"search_result","url":"https://www.registrationchina.com/articles/new-chinese-chip/?utm_source=chatgpt.com","title":"The Creation of the New Chinese Chip: The Era ...","snippet":"7 days ago \u2014 The Peking University study shows that the new Chinese chip can deliver hundreds to thousands of times higher throughput compared to leading ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"registrationchina.com"}]},{"type":"search_result_group","domain":"springer.com","entries":[{"type":"search_result","url":"https://link.springer.com/subjects/computer-memory-structure?utm_source=chatgpt.com","title":"Computer Memory Structure - Recent articles and discoveries","snippet":"Precise and scalable analogue matrix equation solving using resistive random-access memory chips. Pushen Zuo; Qishen Wang; Zhong Sun. in Nature Electronics.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"springer.com"}]},{"type":"search_result_group","domain":"eeworld.com.cn","entries":[{"type":"search_result","url":"https://en.eeworld.com.cn/mp/Icbank/a409025.jspx?utm_source=chatgpt.com","title":"Chips developed by Chinese scientists break through century- ...","snippet":"For the first time, it brought analog computing accuracy to the same level as digital computing, while simultaneously increasing computing power and energy ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"eeworld.com.cn"}]},{"type":"search_result_group","domain":"facebook.com","entries":[{"type":"search_result","url":"https://www.facebook.com/groups/aifire.co/posts/1839791523292815/?utm_source=chatgpt.com","title":"What if analogue ai chips replace traditional processors?","snippet":"It's physics. Unlike digital chips that slice reality into 0s and 1s, this new resistive memory-based system computes through continuous signals ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"facebook.com"},{"type":"search_result","url":"https://www.facebook.com/SunShineCNForever/posts/major-breakthrough-chinese-scientists-have-developed-the-latest-chip-overcoming-/1376681571049814/?locale=hi_IN&utm_source=chatgpt.com","title":"Major breakthrough! Chinese scientists have developed ...","snippet":"Scientists in China have created a new quantum chip named Zuchongzhi 3.0 that is incredibly fast\u2014about 1 quadrillion times quicker than today's ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":20},"pub_date":null,"attribution":"facebook.com"},{"type":"search_result","url":"https://www.facebook.com/photo.php?fbid=10240508940050379&set=a.4240607462804&type=3&utm_source=chatgpt.com","title":"a 2023 Tsinghua University study on a similar ...","snippet":"A South China Morning Post article from October 21, 2025, detailing Peking University researchers' development of a resistive memory-based ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":23},"pub_date":null,"attribution":"facebook.com"}]},{"type":"search_result_group","domain":"x.com","entries":[{"type":"search_result","url":"https://x.com/ExtremaRatio4/status/1978204646297805196?utm_source=chatgpt.com","title":"Extrema Ratio","snippet":"Their new analog matrix solver, based on 40 nm RRAM ... Peking University, and published in the international academic journal Nature Electronics.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"x.com"}]},{"type":"search_result_group","domain":"arxiv.org","entries":[{"type":"search_result","url":"https://arxiv.org/pdf/2401.10042?utm_source=chatgpt.com","title":"BlockAMC: Scalable In-Memory Analog Matrix Computing ...","snippet":"by L Pan \u00b7 2024 \u00b7 Cited by 6 \u2014 BlockAMC is a scalable in-memory analog matrix computing approach that partitions a large matrix into smaller ones to solve linear systems.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"arxiv.org"}]},{"type":"search_result_group","domain":"tmtpost.com","entries":[{"type":"search_result","url":"https://en.tmtpost.com/news/7721720?utm_source=chatgpt.com","title":"Chinese Researchers Achieve High-Precision, Scalable ...","snippet":"Chinese scientists have developed a high-precision, scalable analog matrix computing chip based on resistive memory, creating for the first time an analog ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"tmtpost.com"}]},{"type":"search_result_group","domain":"inf.news","entries":[{"type":"search_result","url":"https://inf.news/en/tech/8ce8b4cf5e208c1918707911c67fa22e.html?utm_source=chatgpt.com","title":"The end of GPU dominance, 24-bit precision, thousand ...","snippet":"6 days ago \u2014 The end of GPU dominance, 24-bit precision, thousand-fold throughput, Peking University's resistive memory chip published in Nature journal.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"inf.news"}]},{"type":"search_result_group","domain":"aastocks.com","entries":[{"type":"search_result","url":"https://www.aastocks.com/en/stocks/news/aafn-con/NOW.1478978/latest-news/AAFN?utm_source=chatgpt.com","title":"Report: Peking University Research Team Develops New ...","snippet":"8 hours ago \u2014 This breakthrough technology has, for the first time, increased the precision of analog computing to 24 bits fixed-point precision, with ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"aastocks.com"}]},{"type":"search_result_group","domain":"nih.gov","entries":[{"type":"search_result","url":"https://pmc.ncbi.nlm.nih.gov/articles/PMC11817932/?utm_source=chatgpt.com","title":"Fully analog iteration for solving matrix equations with in- ...","snippet":"by J Li \u00b7 2025 \u00b7 Cited by 7 \u2014 Memristive in-memory computing has demonstrated potential for solving matrix equations in scientific computing.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"nih.gov"}]},{"type":"search_result_group","domain":"tsinghua.edu.cn","entries":[{"type":"search_result","url":"https://www.tsinghua.edu.cn/en/info/1569/12965.htm?utm_source=chatgpt.com","title":"Chinese scientists create chip that can perform AI task ...","snippet":"Chinese scientists have produced a chip that is significantly faster and more energy efficient than current high-performance AI chips.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"tsinghua.edu.cn"}]},{"type":"search_result_group","domain":"polyu.edu.hk","entries":[{"type":"search_result","url":"https://www.polyu.edu.hk/fs/docdrive/publication/20250806_Programme_Booklet.pdf?utm_source=chatgpt.com","title":"AI x Science","snippet":"Aug 6, 2025 \u2014 A bit-sliced iterative refinement loop achieves full. FP32 (24-bit fixed-point) accuracy for high-precision updates. To scale up, a block-matrix.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"polyu.edu.hk"}]},{"type":"search_result_group","domain":"nomos-elibrary.de","entries":[{"type":"search_result","url":"https://www.nomos-elibrary.de/10.5771/9780739191804.pdf?utm_source=chatgpt.com","title":"State-Society Relations and Governance in China","snippet":"This book is a collection of selected papers from an international conference titled \u201cThe State-Society Relations in the New Era: Lessons for and from. China,\u201d ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":22},"pub_date":null,"attribution":"nomos-elibrary.de"}]},{"type":"search_result_group","domain":"reddit.com","entries":[{"type":"search_result","url":"https://www.reddit.com/r/artificial/comments/17nxs0v/chinas_ai_analog_chip_claimed_to_be_3000x_faster/?utm_source=chatgpt.com","title":"China's AI Analog Chip Claimed to Be 3000X Faster Than ...","snippet":"China's ACCEL chip, developed by Tsinghua University, is claimed to be 3000 times faster than Nvidia's A100 GPU and has 4000 million times higher energy ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":24},"pub_date":null,"attribution":"reddit.com"}]},{"type":"search_result_group","domain":"explore-vc.org","entries":[{"type":"search_result","url":"https://www.explore-vc.org/en/objects.html?layout=showstar%3Aportfolio&start=20&utm_source=chatgpt.com","title":"Objects","snippet":"by B Mkhonza \u2014 Dear user,. This section of our website forms the heart of the EVC project. Here you find a collection of images of objects from different 'visual cultures' ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":26},"pub_date":null,"attribution":"explore-vc.org"}]},{"type":"search_result_group","domain":"7dayadventurer.com","entries":[{"type":"search_result","url":"https://www.7dayadventurer.com/category/inter-ethnic-relations/?utm_source=chatgpt.com","title":"Category Archives: Inter-ethnic relations","snippet":"Namibia in 2025 still bears the scars of its past subjugation by imperial colonial powers. Despite achieving independence in 1990, historical inequalities ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":27},"pub_date":null,"attribution":"7dayadventurer.com"}]},{"type":"search_result_group","domain":"interestingengineering.com","entries":[{"type":"search_result","url":"https://interestingengineering.com/innovation/chinese-gpus-surpass-nvidia?utm_source=chatgpt.com","title":"China's supercomputer chips get 10 times more powerful ...","snippet":"Feb 13, 2025 \u2014 Chinese computer researchers have achieved a near-tenfold boost in performance over Nvidia-powered US supercomputers using domestically made graphics ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":28},"pub_date":null,"attribution":"interestingengineering.com"}]},{"type":"search_result_group","domain":"scribd.com","entries":[{"type":"search_result","url":"https://www.scribd.com/document/439535858/ANC-all-count-txt?utm_source=chatgpt.com","title":"ANC All Count | PDF | Biotechnology | Life Sciences","snippet":"ANC-all-count.txt - Free download as Text File (.txt), PDF File (.pdf) or read online for free.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":29},"pub_date":null,"attribution":"scribd.com"}]}],"citations":[],"request_id":"5899ebd1-a44e-4bae-88bb-bc9587213187","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"max","parent_id":"9ce96992-8f00-46ea-aaac-cf40056342c4","turn_exchange_id":"07c42b44-9afa-47a0-8171-7f40951db3b3","timestamp_":"absolute","can_save":true},"recipient":"all","channel":"final"},"parent":"9ce96992-8f00-46ea-aaac-cf40056342c4","children":["c4cb3c26-0734-4e80-9797-86b6686e41df"]},"c4cb3c26-0734-4e80-9797-86b6686e41df":{"id":"c4cb3c26-0734-4e80-9797-86b6686e41df","message":{"id":"c4cb3c26-0734-4e80-9797-86b6686e41df","author":{"role":"user","name":null,"metadata":{}},"create_time":1761319660.288,"update_time":null,"content":{"content_type":"text","parts":["If this body of research continues, extraoplate when it will begin to have a significant impact on AI training runs"]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"developer_mode_connector_ids":[],"selected_sources":[],"selected_github_repos":[],"serialization_metadata":{"custom_symbol_offsets":[]},"request_id":"e52f9de3-65ab-4b89-a495-bb780783360e","message_source":null,"turn_exchange_id":"dae60d5f-94c0-4ed0-95ae-1ca695fce69d","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"459b43d4-2b27-4cf0-943e-ae4115a86f31","children":["8d203046-f184-434a-a3cb-bf4aec17e792"]},"8d203046-f184-434a-a3cb-bf4aec17e792":{"id":"8d203046-f184-434a-a3cb-bf4aec17e792","message":{"id":"8d203046-f184-434a-a3cb-bf4aec17e792","author":{"role":"system","name":null,"metadata":{}},"create_time":1761319661.9369156,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"is_contextual_answers_system_message":true,"is_visually_hidden_from_conversation":true,"command":"prompt","contextual_answers_message_type":"sources_and_filters_prompt","request_id":"e52f9de3-65ab-4b89-a495-bb780783360e","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"max","parent_id":"c4cb3c26-0734-4e80-9797-86b6686e41df","turn_exchange_id":"dae60d5f-94c0-4ed0-95ae-1ca695fce69d","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"c4cb3c26-0734-4e80-9797-86b6686e41df","children":["30c10321-ec20-44ce-a2e7-e35add50516b"]},"30c10321-ec20-44ce-a2e7-e35add50516b":{"id":"30c10321-ec20-44ce-a2e7-e35add50516b","message":{"id":"30c10321-ec20-44ce-a2e7-e35add50516b","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1761319663.377232,"update_time":null,"content":{"content_type":"thoughts","thoughts":[{"summary":"Evaluating analog computing impact on AI","content":"I need to assess when the research into analog computing for matrix inversion and accelerators (from Peking University) will really start influencing AI training. I'll provide a grounded analysis, including timelines, assumptions, and key players like Mythic, IBM, and Rain AI. I\u2019ll focus on the advancements they're making, such as memristor-based in-memory computing and phase-change memory, factoring in energy efficiency for both training and inference.","chunks":["I need to assess when the research into analog computing for matrix inversion and accelerators (from Peking University) will really start influencing AI training.","I'll provide a grounded analysis, including timelines, assumptions, and key players like Mythic, IBM, and Rain AI.","I\u2019ll focus on the advancements they're making, such as memristor-based in-memory computing and phase-change memory, factoring in energy efficiency for both training and inference."],"finished":true},{"summary":"Assessing analog compute's effect on AI training","content":"The Peking University chip focuses on solving matrix inversions and MIMO detection, which is less common in most training that relies on matrix multiplications and first-order optimizers. Still, K-FAC uses matrix inversions. I need to assess how analog solvers could impact K-FAC adoption, training speed, and energy. I'll also validate updates on analog compute and related trends like the GPU roadmap.","chunks":["The Peking University chip focuses on solving matrix inversions and MIMO detection, which is less common in most training that relies on matrix multiplications and first-order optimizers.","Still, K-FAC uses matrix inversions.","I need to assess how analog solvers could impact K-FAC adoption, training speed, and energy.","I'll also validate updates on analog compute and related trends like the GPU roadmap."],"finished":true},{"summary":"Assessing analog computing for AI training scenarios","content":"I need to consider key factors, like ADC/DAC energy scaling, precision, memory bandwidth, and integration with frameworks (like PyTorch). Analog devices like the Peking chip claim 24-bit fixed precision, but there's a dynamic range mismatch. I'll explore optimistic, base, and pessimistic scenarios with deadlines: 2025-2027 for prototypes, and 2027-2030 for broader datacenter adoption.","chunks":["I need to consider key factors, like ADC/DAC energy scaling, precision, memory bandwidth, and integration with frameworks (like PyTorch).","Analog devices like the Peking chip claim 24-bit fixed precision, but there's a dynamic range mismatch.","I'll explore optimistic, base, and pessimistic scenarios with deadlines: 2025-2027 for prototypes, and 2027-2030 for broader datacenter adoption."],"finished":true},{"summary":"Evaluating analog MVM for transformer training","content":"In transformer model training, matrix multiplications (GEMM) dominate the workload, not inversions. Analog MVM could help with this, but GPUs are already very efficient at GEMM, and integrating analog computing might come with overhead costs. I'll need to estimate the percentage of time used for GEMMs vs other tasks and consider trends in low-precision training, including recent FP8 and 4-bit research.","chunks":["In transformer model training, matrix multiplications (GEMM) dominate the workload, not inversions.","Analog MVM could help with this, but GPUs are already very efficient at GEMM, and integrating analog computing might come with overhead costs.","I'll need to estimate the percentage of time used for GEMMs vs other tasks and consider trends in low-precision training, including recent FP8 and 4-bit research."],"finished":true}],"source_analysis_msg_id":"5166f5f7-9479-4ccb-99b5-3920b4c13b02"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"is_reasoning","content_references":[],"citations":[],"classifier_response":"default","skip_reasoning_title":"Skip","request_id":"e52f9de3-65ab-4b89-a495-bb780783360e","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"max","parent_id":"8d203046-f184-434a-a3cb-bf4aec17e792","turn_exchange_id":"dae60d5f-94c0-4ed0-95ae-1ca695fce69d","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"8d203046-f184-434a-a3cb-bf4aec17e792","children":["bb2754ae-f537-4901-a482-8b1f4c750af7"]},"bb2754ae-f537-4901-a482-8b1f4c750af7":{"id":"bb2754ae-f537-4901-a482-8b1f4c750af7","message":{"id":"bb2754ae-f537-4901-a482-8b1f4c750af7","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1761319686.032194,"update_time":1761319686.056564,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"{\"search_query\": [{\"q\": \"Nature Electronics Peking University analog matrix inversion resistive memory 2025\"}, {\"q\": \"SCMP analog chip 1000 times faster Peking University resistive memory matrix inversion 2025 Victoria Bela\"}, {\"q\": \"IBM analog AI chip phase-change memory Nature 2023 energy efficient\"}, {\"q\": \"analog in-memory computing training AI chips startups 2024 2025\"}, {\"q\": \"FP8 training NVIDIA paper 2023 2024\"}], \"response_length\": \"short\"}"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200012]},"is_complete":true,"citations":[],"content_references":[],"reasoning_status":"is_reasoning","search_queries":[{"type":"search","q":"Nature Electronics Peking University analog matrix inversion resistive memory 2025"},{"type":"search","q":"SCMP analog chip 1000 times faster Peking University resistive memory matrix inversion 2025 Victoria Bela"},{"type":"search","q":"IBM analog AI chip phase-change memory Nature 2023 energy efficient"},{"type":"search","q":"analog in-memory computing training AI chips startups 2024 2025"},{"type":"search","q":"FP8 training NVIDIA paper 2023 2024"}],"search_display_string":"Searching the web...","searched_display_string":"Searched the web...","reasoning_title":"Forecasting impact of analog computing on AI training","classifier_response":"default","request_id":"e52f9de3-65ab-4b89-a495-bb780783360e","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"max","parent_id":"30c10321-ec20-44ce-a2e7-e35add50516b","turn_exchange_id":"dae60d5f-94c0-4ed0-95ae-1ca695fce69d","timestamp_":"absolute","can_save":true},"recipient":"web.run","channel":null},"parent":"30c10321-ec20-44ce-a2e7-e35add50516b","children":["dc0ee973-4366-4f59-88e0-1d0696fc5fba"]},"dc0ee973-4366-4f59-88e0-1d0696fc5fba":{"id":"dc0ee973-4366-4f59-88e0-1d0696fc5fba","message":{"id":"dc0ee973-4366-4f59-88e0-1d0696fc5fba","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1761319686.1187901,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_model_queries":{"type":"search_model_queries","queries":["Nature Electronics Peking University analog matrix inversion resistive memory 2025","SCMP analog chip 1000 times faster Peking University resistive memory matrix inversion 2025 Victoria Bela","IBM analog AI chip phase-change memory Nature 2023 energy efficient","analog in-memory computing training AI chips startups 2024 2025","FP8 training NVIDIA paper 2023 2024"]},"reasoning_status":"is_reasoning","reasoning_title":"Forecasting impact of analog computing on AI training","classifier_response":"default","request_id":"e52f9de3-65ab-4b89-a495-bb780783360e","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"max","parent_id":"bb2754ae-f537-4901-a482-8b1f4c750af7","turn_exchange_id":"dae60d5f-94c0-4ed0-95ae-1ca695fce69d","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"bb2754ae-f537-4901-a482-8b1f4c750af7","children":["449422ee-4311-4002-9562-c1392f216868"]},"449422ee-4311-4002-9562-c1392f216868":{"id":"449422ee-4311-4002-9562-c1392f216868","message":{"id":"449422ee-4311-4002-9562-c1392f216868","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1761319686.117157,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_result_groups":[{"type":"search_result_group","domain":"www.nature.com","entries":[{"type":"search_result","url":"https://www.nature.com/articles/s41928-025-01477-0","title":"Precise and scalable analogue matrix equation solving ...","snippet":"by P Zuo \u00b7 2025 \u2014 Our approach uses an iterative algorithm that combines analogue low-precision matrix inversion and analogue high-precision matrix\u2013vector ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":0},"pub_date":null,"attribution":"www.nature.com"},{"type":"search_result","url":"https://www.nature.com/articles/s41586-023-06337-5","title":"An analog-AI chip for energy-efficient speech recognition ...","snippet":"by S Ambrogio \u00b7 2023 \u00b7 Cited by 207 \u2014 Here we present an analog-AI chip that combines 35 million phase-change memory devices across 34 tiles, massively parallel inter-tile communication and analog, ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"www.nature.com"},{"type":"search_result","url":"https://www.nature.com/articles/s41928-023-01035-6","title":"Analogue chips for energy-efficient AI","snippet":"by S Conti \u00b7 2023 \u2014 Overall, the chip has 35 million phase-change memory devices. The chip also contains digital-to-analogue input, analogue-to-digital output, ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"www.nature.com"}]},{"type":"search_result_group","domain":"amp.scmp.com","entries":[{"type":"search_result","url":"https://amp.scmp.com/news/china/science/article/3329820/chinas-analogue-ai-chip-could-work-1000-times-faster-nvidia-gpu-study","title":"China's analogue AI chip could work 1000 times faster than ...","snippet":"3 days ago \u2014 The analogue device designed by researchers from Peking University uses memory chips made of resistive materials. ... Victoria Bela.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":1},"pub_date":1761058815.0,"attribution":"amp.scmp.com"}]},{"type":"search_result_group","domain":"www.avaq.com","entries":[{"type":"search_result","url":"https://www.avaq.com/technology/top-10-ai-chip-startups-to-watch-in-2025?srsltid=AfmBOoqxP5oN9F-0EBZbP-OqpHkV9f4uCCof_7cwAX6GIPzKl3Tc-fWV","title":"Top 10 AI Chip Startups to Watch in 2025","snippet":"Sep 19, 2025 \u2014 Top 10 AI Chip Startups to Watch in 2025 \u00b7 1. Tenstorrent \u00b7 2. Mythic \u00b7 3. Groq \u00b7 4. Blumind \u00b7 5. Lightmatter \u00b7 6. Untether AI \u00b7 7. Enfabrica \u00b7 8.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"www.avaq.com"}]},{"type":"search_result_group","domain":"arxiv.org","entries":[{"type":"search_result","url":"https://arxiv.org/html/2509.22536v4","title":"InfiR2: A Comprehensive FP8 Training Recipe for ...","snippet":"7 days ago \u2014 On the hardware side, NVIDIA's Blackwell architecture (NVIDIA, 2024) fundamentally ensures FP8 training stability with the MXFP8-E4M3 format ( ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2502.05967v3","title":"\u00b5nit Scaling: Simple and Scalable FP8 LLM Training","snippet":"Jun 5, 2025 \u2014 We demonstrate a simple, scalable FP8 training method with straightforward hyperparameter transfer on large LLMs, called \u201c\u03bcnit Scaling\u201d (\u03bcS).","ref_id":{"turn_index":0,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"arxiv.org"}]},{"type":"search_result_group","domain":"www.globaltimes.cn","entries":[{"type":"search_result","url":"https://www.globaltimes.cn/page/202510/1345626.shtml","title":"Chinese researchers develop high-precision scalable ...","snippet":"Oct 14, 2025 \u2014 Chinese researchers develop high-precision scalable analog matrix computing chip based on resistive memory, realizing for the first time an ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"www.globaltimes.cn"}]},{"type":"search_result_group","domain":"www.scmp.com","entries":[{"type":"search_result","url":"https://www.scmp.com/author/victoria-bela","title":"Victoria Bela: Latest Articles, Analysis and Profile","snippet":"She holds a Master's in Public Policy from Peking University ... China's analogue AI chip could work 1,000 times faster than Nvidia GPU: study.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"www.scmp.com"}]},{"type":"search_result_group","domain":"research.ibm.com","entries":[{"type":"search_result","url":"https://research.ibm.com/blog/analog-ai-chip-inference","title":"An energy-efficient analog chip for AI inference","snippet":"Aug 10, 2023 \u2014 IBM Research's latest analog AI chip for deep learning inference. The energy-efficient chip showcases critical building blocks of a scalable mixed-signal ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":7},"pub_date":1691679600.0,"attribution":"research.ibm.com"},{"type":"search_result","url":"https://research.ibm.com/blog/analog-ai-chip-low-power","title":"New analog AI chip design uses much less power for AI tasks","snippet":"Aug 23, 2023 \u2014 IBM showed it's possible to build analog AI chips that can handle natural-language AI tasks with an estimated 14 times more energy efficiency.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":16},"pub_date":1692802800.0,"attribution":"research.ibm.com"}]},{"type":"search_result_group","domain":"research.aimultiple.com","entries":[{"type":"search_result","url":"https://research.aimultiple.com/ai-chip-makers/","title":"Top 20+ AI Chip Makers: NVIDIA & Its Competitors","snippet":"4 days ago \u2014 Based on our experience running in-depth benchmarks, we've identified the top AI hardware companies for data center workloads.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"research.aimultiple.com"}]},{"type":"search_result_group","domain":"www.researchgate.net","entries":[{"type":"search_result","url":"https://www.researchgate.net/publication/396448715_Precise_and_scalable_analogue_matrix_equation_solving_using_resistive_random-access_memory_chips","title":"Precise and scalable analogue matrix equation solving ...","snippet":"Oct 13, 2025 \u2014 Our approach uses an iterative algorithm that combines analogue low-precision matrix inversion and analogue high-precision matrix\u2013vector ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":10},"pub_date":1760313600.0,"attribution":"www.researchgate.net"}]},{"type":"search_result_group","domain":"techovedas.com","entries":[{"type":"search_result","url":"https://techovedas.com/china-breaks-a-100-year-barrier-peking-university-unveils-worlds-most-precise-analog-computing-chip/","title":"Peking University Unveils World's Most Precise Analog ...","snippet":"3 days ago \u2014 The team has developed a high-precision and scalable analog matrix computing chip built on Resistive Random-Access Memory (RRAM) technology.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":11},"pub_date":1761018596.0,"attribution":"techovedas.com"}]},{"type":"search_result_group","domain":"www.ventureradar.com","entries":[{"type":"search_result","url":"https://www.ventureradar.com/startup/analog%20ai","title":"Top analog ai start-ups","snippet":"Top start-ups for analog ai at VentureRadar with Innovation Scores, Core Health Signals and more. Including Blumind Inc., Q.ant, EnCharge AI etc.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"www.ventureradar.com"}]},{"type":"search_result_group","domain":"github.com","entries":[{"type":"search_result","url":"https://github.com/NVIDIA/TransformerEngine","title":"NVIDIA/TransformerEngine","snippet":"What's New in Transformer Engine and FP8 Training | GTC 2024 \u00b7 FP8 Training with Transformer Engine | GTC 2023 \u00b7 FP8 for Deep Learning | GTC 2023 \u00b7 Inside the ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"github.com"}]},{"type":"search_result_group","domain":"www.registrationchina.com","entries":[{"type":"search_result","url":"https://www.registrationchina.com/articles/new-chinese-chip/","title":"The Creation of the New Chinese Chip: The Era ...","snippet":"7 days ago \u2014 The Peking University study shows that the new Chinese chip can deliver hundreds to thousands of times higher throughput compared to leading ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":15},"pub_date":1760690671.0,"attribution":"www.registrationchina.com"}]},{"type":"search_result_group","domain":"www.yolegroup.com","entries":[{"type":"search_result","url":"https://www.yolegroup.com/industry-news/these-are-the-10-hottest-ai-hardware-companies-to-follow-in-2025/","title":"These are the 10 hottest AI hardware companies to follow ...","snippet":"Jan 7, 2025 \u2014 These are the 10 hottest AI hardware companies to follow in 2025 \u00b7 Tenstorrent \u00b7 Mythic \u00b7 Groq \u00b7 Blumind \u00b7 Lightmatter \u00b7 Untether AI \u00b7 Enfabrica.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"www.yolegroup.com"}]},{"type":"search_result_group","domain":"www.reuters.com","entries":[{"type":"search_result","url":"https://www.reuters.com/technology/artificial-intelligence/startup-untether-launches-ai-chips-2024-10-28/","title":"Startup Untether launches AI chips","snippet":"Startup Untether has unveiled a new artificial intelligence chip aimed at powering AI applications in diverse settings such as cars and agricultural devices. Unlike Nvidia and AMD's chips, which are primarily used for training large AI models in energy-intensive data centers, Untether's chips focus on running pre-built models efficiently, a process known as \"inference.\" The Toronto-based company anticipates that the market for inference chips will grow significantly, reaching $102 billion by 2027. Their latest chip, the 240 Slim, provides high performance with reduced energy consumption, making it suitable for autonomous vehicles, agricultural equipment, and data centers. Mercedes-Benz is already collaborating with Untether for its next-generation autonomous vehicles. Untether's chips are based on open-source RISC-V technology, competing with designs by Arm Holdings. Recent benchmark tests by MLCommons indicate strong performance of Untether's chips in relevant applications.","ref_id":{"turn_index":0,"ref_type":"news","ref_index":52},"pub_date":1730127982.0,"attribution":"www.reuters.com"},{"type":"search_result","url":"https://www.reuters.com/technology/artificial-intelligence/dutch-chipmaker-axeleraai-gets-66-million-eu-grant-2025-03-06/","title":"Dutch chipmaker AxeleraAI gets $66 million EU grant","snippet":"AxeleraAI, a Dutch company specializing in AI computer chips, has received a grant of up to 61.6 million euros ($66 million) from the European Union to develop a data center chip. This funding is part of the EU\u2019s initiative to narrow the AI competitiveness gap with the US and China by supporting local chipmakers and creating publicly accessible AI factories. AxeleraAI, based in Eindhoven, Netherlands, aims to produce a chip optimized for \"inference\" AI computing, which is essential for running large AI models. The company will use the open-source RISC-V standard for its new Titania chip, offering an alternative to Intel and Arm-dominated systems. AxeleraAI\u2019s current chip, Metis, is used in edge AI applications. Since its founding in 2021, AxeleraAI has raised $200 million from investors, including Samsung.","ref_id":{"turn_index":0,"ref_type":"news","ref_index":54},"pub_date":1741255515.0,"attribution":"www.reuters.com"}]},{"type":"search_result_group","domain":"www.tomshardware.com","entries":[{"type":"search_result","url":"https://www.tomshardware.com/pc-components/ram/new-3d-stacked-memory-tech-seeks-to-dethrone-hbm-in-ai-inference-d-matrix-claims-3dimc-will-be-10x-faster-and-10x-more-efficient","title":"New 3D-stacked memory tech seeks to dethrone HBM for AI inference - d-Matrix claims 3DIMC will be 10x faster and 10x more efficient","snippet":"Memory startup d-Matrix has introduced a new 3D Digital In-Memory Compute (3DIMC) technology that it claims outperforms High-Bandwidth Memory (HBM) by a factor of 10 in speed and efficiency for AI inference tasks. The company's latest hardware, the Pavehawk 3DIMC silicon, is undergoing lab testing and employs a novel in-memory processing design. This configuration integrates LPDDR5 memory dies and chiplets stacked through an interposer, optimized for matrix-vector computations common in transformer-based AI models.\n\nFounder and CEO Sid Sheth emphasizes that AI inference is increasingly bottlenecked by memory rather than computational capacity. d-Matrix asserts that 3DIMC addresses these limitations through vertically-stacked architecture, improving bandwidth, reducing latency, and boosting energy efficiency. The upcoming Raptor generation promises further performance gains, aiming to surpass HBM by 10x in inference speed while consuming 90% less power.\n\nThis innovation may offer a cost-effective alternative to HBM, which is produced by a few major manufacturers and faces steep price growth amid rising demand. d-Matrix\u2019s targeted approach reflects a growing trend in designing hardware specifically for distinct AI workloads, recognizing that inference and training have different performance needs.","ref_id":{"turn_index":0,"ref_type":"news","ref_index":55},"pub_date":1756980000.0,"attribution":"www.tomshardware.com"}]}],"debug_sonic_thread_id":"thread_68fb9b062bfc832c93f98a0591b36d00","reasoning_status":"is_reasoning","reasoning_title":"Forecasting impact of analog computing on AI training","classifier_response":"default","request_id":"e52f9de3-65ab-4b89-a495-bb780783360e","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"max","parent_id":"dc0ee973-4366-4f59-88e0-1d0696fc5fba","turn_exchange_id":"dae60d5f-94c0-4ed0-95ae-1ca695fce69d","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"dc0ee973-4366-4f59-88e0-1d0696fc5fba","children":["a33f17c6-11f1-4f28-bdca-fcb7c32bb892"]},"a33f17c6-11f1-4f28-bdca-fcb7c32bb892":{"id":"a33f17c6-11f1-4f28-bdca-fcb7c32bb892","message":{"id":"a33f17c6-11f1-4f28-bdca-fcb7c32bb892","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1761319693.351355,"update_time":null,"content":{"content_type":"thoughts","thoughts":[{"summary":"Researching analog compute challenges","content":"I need to gather more reliable insights on the viability and adoption of analog computing, specifically crossbars and their challenges. This includes factoring in issues like ADC energy scaling, precision limitations, signal drop, noise, and the endurance of RRAM memristors. I'll look for relevant reviews and research to guide the analysis.","chunks":["I need to gather more reliable insights on the viability and adoption of analog computing, specifically crossbars and their challenges.","This includes factoring in issues like ADC energy scaling, precision limitations, signal drop, noise, and the endurance of RRAM memristors.","I'll look for relevant reviews and research to guide the analysis."],"finished":true}],"source_analysis_msg_id":"1e965e26-333c-4d2e-9079-fddb2c689c82"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"is_reasoning","content_references":[],"citations":[],"classifier_response":"default","skip_reasoning_title":"Skip","request_id":"e52f9de3-65ab-4b89-a495-bb780783360e","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"max","parent_id":"449422ee-4311-4002-9562-c1392f216868","turn_exchange_id":"dae60d5f-94c0-4ed0-95ae-1ca695fce69d","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"449422ee-4311-4002-9562-c1392f216868","children":["af8012e8-9180-4574-9fcb-6c890a0e3582"]},"af8012e8-9180-4574-9fcb-6c890a0e3582":{"id":"af8012e8-9180-4574-9fcb-6c890a0e3582","message":{"id":"af8012e8-9180-4574-9fcb-6c890a0e3582","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1761319691.496225,"update_time":1761319691.513139,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"{\"search_query\": [{\"q\": \"analog in-memory computing challenges ADC energy scaling precision variability review 2023 2024\"}, {\"q\": \"RRAM endurance variability analog computing review 2022 2024\"}, {\"q\": \"K-FAC second-order optimizer matrix inversion AI training adoption timeline\"}], \"response_length\": \"short\"}"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"citations":[],"content_references":[],"reasoning_status":"is_reasoning","search_queries":[{"type":"search","q":"analog in-memory computing challenges ADC energy scaling precision variability review 2023 2024"},{"type":"search","q":"RRAM endurance variability analog computing review 2022 2024"},{"type":"search","q":"K-FAC second-order optimizer matrix inversion AI training adoption timeline"}],"search_display_string":"Searching the web...","searched_display_string":"Searched the web...","reasoning_title":"Searching for reviews on analog compute challenges","classifier_response":"default","request_id":"e52f9de3-65ab-4b89-a495-bb780783360e","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"max","parent_id":"a33f17c6-11f1-4f28-bdca-fcb7c32bb892","turn_exchange_id":"dae60d5f-94c0-4ed0-95ae-1ca695fce69d","timestamp_":"absolute","can_save":true},"recipient":"web.run","channel":null},"parent":"a33f17c6-11f1-4f28-bdca-fcb7c32bb892","children":["f00e6a70-e37c-4376-a0cc-185c7fd2c7b8"]},"f00e6a70-e37c-4376-a0cc-185c7fd2c7b8":{"id":"f00e6a70-e37c-4376-a0cc-185c7fd2c7b8","message":{"id":"f00e6a70-e37c-4376-a0cc-185c7fd2c7b8","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1761319691.5921454,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_model_queries":{"type":"search_model_queries","queries":["analog in-memory computing challenges ADC energy scaling precision variability review 2023 2024","RRAM endurance variability analog computing review 2022 2024","K-FAC second-order optimizer matrix inversion AI training adoption timeline"]},"reasoning_status":"is_reasoning","reasoning_title":"Searching for reviews on analog compute challenges","classifier_response":"default","request_id":"e52f9de3-65ab-4b89-a495-bb780783360e","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"max","parent_id":"af8012e8-9180-4574-9fcb-6c890a0e3582","turn_exchange_id":"dae60d5f-94c0-4ed0-95ae-1ca695fce69d","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"af8012e8-9180-4574-9fcb-6c890a0e3582","children":["ac1bba0e-510f-4e8e-a415-a4876032e6a1"]},"ac1bba0e-510f-4e8e-a415-a4876032e6a1":{"id":"ac1bba0e-510f-4e8e-a415-a4876032e6a1","message":{"id":"ac1bba0e-510f-4e8e-a415-a4876032e6a1","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1761319691.5893977,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_result_groups":[{"type":"search_result_group","domain":"www.nature.com","entries":[{"type":"search_result","url":"https://www.nature.com/articles/s43588-025-00854-1","title":"Analog in-memory computing attention mechanism for fast ...","snippet":"by N Leroux \u00b7 2025 \u00b7 Cited by 6 \u2014 Loading the KV cache for the attention mechanism is thus a major bottleneck, causing increased energy consumption and latency in large language ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":0},"pub_date":null,"attribution":"www.nature.com"},{"type":"search_result","url":"https://www.nature.com/articles/s41586-023-06337-5","title":"An analog-AI chip for energy-efficient speech recognition ...","snippet":"by S Ambrogio \u00b7 2023 \u00b7 Cited by 207 \u2014 Analog in-memory computing (analog-AI) can provide better energy efficiency by performing matrix\u2013vector multiplications in parallel on 'memory ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":24},"pub_date":null,"attribution":"www.nature.com"}]},{"type":"search_result_group","domain":"pubs.acs.org","entries":[{"type":"search_result","url":"https://pubs.acs.org/doi/10.1021/acs.chemrev.4c00845","title":"Resistive Switching Random-Access Memory (RRAM)","snippet":"by D Ielmini \u00b7 Cited by 21 \u2014 This work addresses the RRAM concept from materials, device, circuit, and application viewpoints, focusing on the physical device properties and the ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"pubs.acs.org"}]},{"type":"search_result_group","domain":"medium.com","entries":[{"type":"search_result","url":"https://medium.com/data-science/introducing-k-fac-and-its-application-for-large-scale-deep-learning-4e3f9b443414","title":"Introducing K-FAC. A Second-Order Optimization Method ...","snippet":"Kronecker-factored Approximate Curvature (K-FAC) is a second-order optimization method for deep learning proposed by James Martens and Roger Grosse of the ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":2},"pub_date":1559266152.576,"attribution":"medium.com"},{"type":"search_result","url":"https://medium.com/%40anshm18111996/comprehensive-overview-optimizers-in-machine-learning-and-ai-57a2b0fbcc79","title":"Optimizers in Machine Learning and AI: A Comprehensive ...","snippet":"Optimizers adjust model parameters to minimize a loss function. They underpin the training of NN and classical models alike.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":20},"pub_date":1744437660.328,"attribution":"medium.com"}]},{"type":"search_result_group","domain":"arxiv.org","entries":[{"type":"search_result","url":"https://arxiv.org/html/2409.19315v2","title":"Analog In-Memory Computing Attention Mechanism for ...","snippet":"Nov 25, 2024 \u2014 We present a custom self-attention in-memory computing architecture based on emerging charge-based memories called gain cells.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2409.19315v1","title":"Analog In-Memory Computing Attention Mechanism for ...","snippet":"In this work, we propose a fast and energy-efficient hardware implementation of self-attention using analog in-memory computing based on gain cell memories.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2007.00784","title":"Convolutional Neural Network Training with Distributed K- ...","snippet":"by JG Pauloski \u00b7 2020 \u00b7 Cited by 41 \u2014 We study optimization techniques such as layer-wise distribution strategies, inverse-free second-order gradient evaluation, and dynamic K-FAC ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":8},"pub_date":1593736869.0,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2504.20096v1","title":"Towards Practical Second-Order Optimizers in Deep ...","snippet":"Apr 26, 2025 \u2014 Second-order methods incorporate curvature information into the optimization process by leveraging the Hessian matrix or its approximations.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":26},"pub_date":null,"attribution":"arxiv.org"}]},{"type":"search_result_group","domain":"aihardware.mit.edu","entries":[{"type":"search_result","url":"https://aihardware.mit.edu/wp-content/uploads/2024/05/5-Aya-Amer.pdf","title":"Analog Compute-near-RRAM CNN Accelerator for ...","snippet":"May 1, 2024 \u2014 RRAM Cell output can be shared with many MAC cells. \u27a2 Reduce number of RRAM cells on chips. \u25ab RRAM Cell output independent of RRAM variations. \u27a2 ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"aihardware.mit.edu"}]},{"type":"search_result_group","domain":"openreview.net","entries":[{"type":"search_result","url":"https://openreview.net/pdf?id=HyMTkQZAb","title":"KRONECKER-FACTORED CURVATURE APPROXIMA","snippet":"by J Martens \u00b7 2018 \u00b7 Cited by 120 \u2014 Kronecker-factor Approximate Curvature (Martens & Grosse, 2015) (K-FAC) is a 2nd-order optimization method which has been shown to give state-of-the-art.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":5},"pub_date":1519317817.0,"attribution":"openreview.net"}]},{"type":"search_result_group","domain":"www.researchgate.net","entries":[{"type":"search_result","url":"https://www.researchgate.net/publication/391833689_Analog-to-Digital_Converter_Design_for_Diverse_Performance_Computing-in-Memory_Systems_A_Comprehensive_Review","title":"(PDF) Analog-to-Digital Converter Design for Diverse ...","snippet":"Aug 9, 2025 \u2014 This review presents theoretical analyses and practical case studies on the performance requirements of ADCs and their optimization methods in ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":9},"pub_date":1735689600.0,"attribution":"www.researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/379882947_Variability-aware_Design_of_RRAM-based_Analog_CAMs","title":"Variability-aware Design of RRAM-based Analog CAMs","snippet":"The results show that our designs have the capability to encode up to 4 bits of storage and achieve up to 24 intervals compared to 6 intervals for the published ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":13},"pub_date":1704067200.0,"attribution":"www.researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/386561346_Analog_In-Memory_Computing_Attention_Mechanism_for_Fast_and_Energy-Efficient_Large_Language_Models","title":"Analog In-Memory Computing Attention Mechanism for ...","snippet":"Dec 9, 2024 \u2014 Our architecture respectively reduces attention latency and energy consumption by up to two and five orders of magnitude compared to GPUs, ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":18},"pub_date":1731628800.0,"attribution":"www.researchgate.net"}]},{"type":"search_result_group","domain":"www.sciencedirect.com","entries":[{"type":"search_result","url":"https://www.sciencedirect.com/science/article/pii/S1359028624000536","title":"Prospects and challenges of electrochemical random ...","snippet":"by J Cui \u00b7 2024 \u00b7 Cited by 8 \u2014 In this review, we first examine challenges in constructing in-memory-computing accelerators and unique advantages of ECRAMs.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"www.sciencedirect.com"},{"type":"search_result","url":"https://www.sciencedirect.com/science/article/abs/pii/S2666998625002558","title":"Device and circuit perspectives for neuromorphic computing","snippet":"by RH Koo \u00b7 2025 \u2014 This review examines memory technologies, such as vertical NAND flash, and emerging options, including ferroelectric memory, resistive RAM, ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":22},"pub_date":null,"attribution":"www.sciencedirect.com"},{"type":"search_result","url":"https://www.sciencedirect.com/science/article/abs/pii/S089360802300504X","title":"A scalable second order optimizer with an adaptive trust ...","snippet":"by D Yang \u00b7 2023 \u2014 Recent research has demonstrated that K-FAC exhibits accelerated convergence in training deep neural networks compared to Stochastic Gradient Descent (SGD).","ref_id":{"turn_index":1,"ref_type":"search","ref_index":23},"pub_date":null,"attribution":"www.sciencedirect.com"}]},{"type":"search_result_group","domain":"dl.acm.org","entries":[{"type":"search_result","url":"https://dl.acm.org/doi/pdf/10.1145/3394486.3403265","title":"A Systematic Performance Analysis of Second-order ...","snippet":"by Y Ueno \u00b7 2020 \u00b7 Cited by 21 \u2014 The fact that we can reduce the training time of K-FAC to match that of SGD while also matching the Top-1 validation accuracy not only debunks.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"dl.acm.org"}]},{"type":"search_result_group","domain":"www.science.org","entries":[{"type":"search_result","url":"https://www.science.org/doi/10.1126/sciadv.ady4798","title":"Ultrahigh-precision analog computing using memory- ...","snippet":"Sep 12, 2025 \u2014 However, low precision remains a major challenge in realizing practical analog computing systems. Traditional analog systems rely on the ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"www.science.org"}]},{"type":"search_result_group","domain":"gregpauloski.com","entries":[{"type":"search_result","url":"https://gregpauloski.com/publications/pauloski2022kfac-preprint.pdf","title":"Deep Neural Network Training with Distributed K-FAC","snippet":"by JG Pauloski \u00b7 Cited by 6 \u2014 In this paper, we investigate methods for designing K-. FAC-based optimizers that reduce iterations-to-convergence and exhibit efficient scaling. We investigate ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":14},"pub_date":1673235679.0,"attribution":"gregpauloski.com"}]},{"type":"search_result_group","domain":"repository.tudelft.nl","entries":[{"type":"search_result","url":"https://repository.tudelft.nl/file/File_dfa6e78d-2bd4-4768-bf4f-e7894d569637","title":"Analysis of Conductance Variability in RRAM for Accurate ...","snippet":"by H Aziza \u00b7 2024 \u00b7 Cited by 1 \u2014 The proposed analysis revealed that conductance variability is a major concern in RRAM technology for computing. Hence, outcomes of this study are crucial for ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":16},"pub_date":1718627234.0,"attribution":"repository.tudelft.nl"}]},{"type":"search_result_group","domain":"pubs.rsc.org","entries":[{"type":"search_result","url":"https://pubs.rsc.org/en/content/articlehtml/2024/na/d4na00158c","title":"An overview of critical applications of resistive random access ...","snippet":"by F Zahoor \u00b7 2024 \u00b7 Cited by 22 \u2014 This discussion explores the physical mechanisms, device structure, performance characteristics, and applications of RRAM devices.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":19},"pub_date":null,"attribution":"pubs.rsc.org"}]},{"type":"search_result_group","domain":"pmc.ncbi.nlm.nih.gov","entries":[{"type":"search_result","url":"https://pmc.ncbi.nlm.nih.gov/articles/PMC11817932/","title":"Fully analog iteration for solving matrix equations with in- ...","snippet":"by J Li \u00b7 2025 \u00b7 Cited by 7 \u2014 However, the inherent inaccuracies of analog mechanisms create challenges in achieving high-precision solutions while maintaining low-energy ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":21},"pub_date":null,"attribution":"pmc.ncbi.nlm.nih.gov"},{"type":"search_result","url":"https://pmc.ncbi.nlm.nih.gov/articles/PMC12083524/","title":"Engineered high endurance in WO3-based resistive ...","snippet":"by Z Yuan \u00b7 2025 \u00b7 Cited by 2 \u2014 The variability not only affects the performance and endurance of individual devices but also poses challenges for large-scale integration ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":25},"pub_date":null,"attribution":"pmc.ncbi.nlm.nih.gov"}]},{"type":"search_result_group","domain":"www.mdpi.com","entries":[{"type":"search_result","url":"https://www.mdpi.com/2079-9292/14/16/3159","title":"A Survey of Analog Computing for Domain-Specific ...","snippet":"by L Belostotski \u00b7 2025 \u2014 While analog Ising machines benefit from low-power, real-time processing, they also face challenges in precision, noise robustness, and interconnection scaling.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":27},"pub_date":null,"attribution":"www.mdpi.com"}]}],"debug_sonic_thread_id":"thread_68fb9b062bfc832c93f98a0591b36d00","reasoning_status":"is_reasoning","reasoning_title":"Searching for reviews on analog compute challenges","classifier_response":"default","request_id":"e52f9de3-65ab-4b89-a495-bb780783360e","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"max","parent_id":"f00e6a70-e37c-4376-a0cc-185c7fd2c7b8","turn_exchange_id":"dae60d5f-94c0-4ed0-95ae-1ca695fce69d","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"f00e6a70-e37c-4376-a0cc-185c7fd2c7b8","children":["596e8c55-12c9-47c4-8480-cdef96849704"]},"596e8c55-12c9-47c4-8480-cdef96849704":{"id":"596e8c55-12c9-47c4-8480-cdef96849704","message":{"id":"596e8c55-12c9-47c4-8480-cdef96849704","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1761319701.174811,"update_time":null,"content":{"content_type":"thoughts","thoughts":[{"summary":"Cross-referencing analog compute sources","content":"I\u2019ve gathered sources from SCMP, IBM\u2019s 2023 analog AI chip, and reviews on RRAM challenges and ADCs. Now, I need timeline predictions and to compare with upcoming digital roadmaps, like NVIDIA's Blackwell in 2025 and Rubin in 2026-2027. I'll look into NVIDIA's announcements, especially for Rubin at GTC 2025.","chunks":["I\u2019ve gathered sources from SCMP, IBM\u2019s 2023 analog AI chip, and reviews on RRAM challenges and ADCs.","Now, I need timeline predictions and to compare with upcoming digital roadmaps, like NVIDIA's Blackwell in 2025 and Rubin in 2026-2027.","I'll look into NVIDIA's announcements, especially for Rubin at GTC 2025."],"finished":true}],"source_analysis_msg_id":"e0a19aa1-6c79-41f9-881e-ac05c5d238b7"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"is_reasoning","content_references":[],"citations":[],"classifier_response":"default","skip_reasoning_title":"Skip","request_id":"e52f9de3-65ab-4b89-a495-bb780783360e","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"max","parent_id":"ac1bba0e-510f-4e8e-a415-a4876032e6a1","turn_exchange_id":"dae60d5f-94c0-4ed0-95ae-1ca695fce69d","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"ac1bba0e-510f-4e8e-a415-a4876032e6a1","children":["55914862-d288-44c2-948f-9866dfc3f6a8"]},"55914862-d288-44c2-948f-9866dfc3f6a8":{"id":"55914862-d288-44c2-948f-9866dfc3f6a8","message":{"id":"55914862-d288-44c2-948f-9866dfc3f6a8","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1761319698.995471,"update_time":1761319699.011994,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"{\"search_query\": [{\"q\": \"NVIDIA Rubin architecture 2025 announcement GTC 2025 training FP8 tensor core throughput timeline\"}, {\"q\": \"NVIDIA Blackwell availability shipping 2025 2026 FP8 training stability TensorRT Transformer Engine\"}], \"response_length\": \"short\"}"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200012]},"is_complete":true,"citations":[],"content_references":[],"reasoning_status":"is_reasoning","search_queries":[{"type":"search","q":"NVIDIA Rubin architecture 2025 announcement GTC 2025 training FP8 tensor core throughput timeline"},{"type":"search","q":"NVIDIA Blackwell availability shipping 2025 2026 FP8 training stability TensorRT Transformer Engine"}],"search_display_string":"Searching the web...","searched_display_string":"Searched the web...","reasoning_title":"Searching for NVIDIA architecture timelines and specifications","classifier_response":"default","request_id":"e52f9de3-65ab-4b89-a495-bb780783360e","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"max","parent_id":"596e8c55-12c9-47c4-8480-cdef96849704","turn_exchange_id":"dae60d5f-94c0-4ed0-95ae-1ca695fce69d","timestamp_":"absolute","can_save":true},"recipient":"web.run","channel":null},"parent":"596e8c55-12c9-47c4-8480-cdef96849704","children":["63f245ba-c492-4449-9d1c-e7cd89b58ef1"]},"63f245ba-c492-4449-9d1c-e7cd89b58ef1":{"id":"63f245ba-c492-4449-9d1c-e7cd89b58ef1","message":{"id":"63f245ba-c492-4449-9d1c-e7cd89b58ef1","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1761319699.0769904,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_model_queries":{"type":"search_model_queries","queries":["NVIDIA Rubin architecture 2025 announcement GTC 2025 training FP8 tensor core throughput timeline","NVIDIA Blackwell availability shipping 2025 2026 FP8 training stability TensorRT Transformer Engine"]},"reasoning_status":"is_reasoning","reasoning_title":"Searching for NVIDIA architecture timelines and specifications","classifier_response":"default","request_id":"e52f9de3-65ab-4b89-a495-bb780783360e","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"max","parent_id":"55914862-d288-44c2-948f-9866dfc3f6a8","turn_exchange_id":"dae60d5f-94c0-4ed0-95ae-1ca695fce69d","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"55914862-d288-44c2-948f-9866dfc3f6a8","children":["bfdfea72-467a-4732-a51c-d643e418166c"]},"bfdfea72-467a-4732-a51c-d643e418166c":{"id":"bfdfea72-467a-4732-a51c-d643e418166c","message":{"id":"bfdfea72-467a-4732-a51c-d643e418166c","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1761319699.074193,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_result_groups":[{"type":"search_result_group","domain":"www.nvidia.com","entries":[{"type":"search_result","url":"https://www.nvidia.com/en-us/on-demand/session/gtc25-S72503/","title":"LLM Inference Performance and Optimization on NVIDIA GB200 ...","snippet":"In this session, we will dive into the GB200 NVL72 architecture and programming model, highlighting its inference performance on state-of-the-art LLM models.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":0},"pub_date":1742342400.0,"attribution":"www.nvidia.com"},{"type":"search_result","url":"https://www.nvidia.com/en-us/on-demand/session/gtc25-S72778/","title":"Stable and Scalable FP8 Deep Learning Training on Blackwell","snippet":"Learn about the new advancements in low-precision training recipes coming with Transformer Engine 2.0 for Hopper and Blackwell GPUs.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":9},"pub_date":1742428800.0,"attribution":"www.nvidia.com"},{"type":"search_result","url":"https://www.nvidia.com/en-us/on-demand/session/gtc25-s72778/","title":"Stable and Scalable FP8 Deep Learning Training on ...","snippet":"Mar 20, 2025 \u2014 Learn about the new advancements in low-precision training recipes coming with Transformer Engine 2.0 for Hopper and Blackwell GPUs.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"www.nvidia.com"}]},{"type":"search_result_group","domain":"developer.nvidia.com","entries":[{"type":"search_result","url":"https://developer.nvidia.com/blog/nvidia-blackwell-delivers-world-record-deepseek-r1-inference-performance/","title":"NVIDIA Blackwell Delivers World-Record DeepSeek-R1 Inference ...","snippet":"NVIDIA announced world-record DeepSeek-R1 inference performance at NVIDIA GTC 2025. A single NVIDIA DGX system with eight NVIDIA Blackwell ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":1},"pub_date":1742256000.0,"attribution":"developer.nvidia.com"},{"type":"search_result","url":"https://developer.nvidia.com/blog/nvidia-tensorrt-unlocks-fp4-image-generation-for-nvidia-blackwell-geforce-rtx-50-series-gpus/","title":"NVIDIA TensorRT Unlocks FP4 Image Generation for NVIDIA ...","snippet":"With FP4, Blackwell can maximize performance while maintaining usable task accuracies. FP4 also provides superior inference accuracy over INT4.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":2},"pub_date":1747180800.0,"attribution":"developer.nvidia.com"},{"type":"search_result","url":"https://developer.nvidia.com/blog/new-ai-sdks-and-tools-released-for-nvidia-blackwell-geforce-rtx-50-series-gpus/","title":"New AI SDKs and Tools Released for NVIDIA Blackwell GeForce ...","snippet":"This post details new and updated SDKs that enable developers to take full advantage of NVIDIA Blackwell GeForce RTX 50 Series GPUs.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":5},"pub_date":1738195200.0,"attribution":"developer.nvidia.com"},{"type":"search_result","url":"https://developer.nvidia.com/blog/nvidia-blackwell-delivers-massive-performance-leaps-in-mlperf-inference-v5-0/","title":"NVIDIA Blackwell Delivers Massive Performance Leaps in MLPerf ...","snippet":"MLPerf Inference v5.0 is the latest in a long-running benchmark suite that measures inference throughput across a range of different models and use cases.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":8},"pub_date":1743552000.0,"attribution":"developer.nvidia.com"},{"type":"search_result","url":"https://developer.nvidia.com/blog/delivering-1-5-m-tps-inference-on-nvidia-gb200-nvl72-nvidia-accelerates-openai-gpt-oss-models-from-cloud-to-edge/","title":"Delivering 1.5 M TPS Inference on NVIDIA GB200 NVL72, NVIDIA ...","snippet":"Deploying with TensorRT-LLM is also available using the Python API in a JupyterLab notebook on the Open AI Cookbook as an NVIDIA Launchable ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":14},"pub_date":1754433843.0,"attribution":"developer.nvidia.com"}]},{"type":"search_result_group","domain":"blogs.nvidia.com","entries":[{"type":"search_result","url":"https://blogs.nvidia.com/blog/nvidia-keynote-at-gtc-2025-ai-news-live-updates/","title":"GTC 2025 \u2013 Announcements and Live Updates","snippet":"Mar 25, 2025 \u2014 Each year will bring new GPUs, CPUs and accelerated computing advancements, including the upcoming NVIDIA Vera Rubin architecture, designed to ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":3},"pub_date":1742925605.0,"attribution":"blogs.nvidia.com"}]},{"type":"search_result_group","domain":"nvidianews.nvidia.com","entries":[{"type":"search_result","url":"https://nvidianews.nvidia.com/news/nvidia-blackwell-platform-arrives-to-power-a-new-era-of-computing","title":"NVIDIA Blackwell Platform Arrives to Power a New Era of Computing","snippet":"The GB200 NVL72 provides up to a 30x performance increase compared to the same number of NVIDIA H100 Tensor Core GPUs for LLM inference ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":4},"pub_date":1710720000.0,"attribution":"nvidianews.nvidia.com"}]},{"type":"search_result_group","domain":"s201.q4cdn.com","entries":[{"type":"search_result","url":"https://s201.q4cdn.com/141608511/files/doc_downloads/2025/03/GTC2025_Keynote.pdf","title":"GTC 2025","snippet":"Rubin Ultra. 88 Custom Arm Cores. 176 Threads. 1.8 TB/s NVLink-C2C. 1.5 PBs NVLink7. 12X. 115.2 TB/s CX9. 8X. Page 36. NVIDIA Rubin System. Vera Rubin NVLink576.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"s201.q4cdn.com"}]},{"type":"search_result_group","domain":"semianalysis.com","entries":[{"type":"search_result","url":"https://semianalysis.com/2025/05/23/amd-vs-nvidia-inference-benchmark-who-wins-performance-cost-per-million-tokens/","title":"AMD vs NVIDIA Inference Benchmark: Who Wins? - SemiAnalysis","snippet":"The MI355X will start shipping in late 2025, two quarters after B200 shipments commence. Software for the B200 and GB200 is still not fully ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":7},"pub_date":1747958400.0,"attribution":"semianalysis.com"}]},{"type":"search_result_group","domain":"github.com","entries":[{"type":"search_result","url":"https://github.com/NVIDIA/TransformerEngine","title":"NVIDIA/TransformerEngine - GitHub","snippet":"A library for accelerating Transformer models on NVIDIA GPUs, including using 8-bit floating point (FP8) precision on Hopper, Ada and Blackwell GPUs, ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/NVIDIA/TensorRT-LLM","title":"NVIDIA/TensorRT-LLM - GitHub","snippet":"TensorRT-LLM is an open-sourced library for optimizing Large Language Model (LLM) inference. It provides state-of-the-art optimizations.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/NVIDIA/TensorRT-LLM/releases","title":"Releases \u00b7 NVIDIA/TensorRT-LLM - GitHub","snippet":"TensorRT-LLM provides users with an easy-to-use Python API to define Large Language Models (LLMs) and support state-of-the-art optimizations to perform ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"github.com"}]},{"type":"search_result_group","domain":"nvidia.github.io","entries":[{"type":"search_result","url":"https://nvidia.github.io/TensorRT-LLM/0.19.0/release-notes.html","title":"Release Notes \u2014 TensorRT-LLM","snippet":"Added support for FP8 MLA on NVIDIA Hopper and Blackwell GPUs. AutoDeploy ... NVIDIA Volta GPU support is deprecated and will be removed in a future release.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"nvidia.github.io"}]},{"type":"search_result_group","domain":"intuitionlabs.ai","entries":[{"type":"search_result","url":"https://intuitionlabs.ai/articles/blackwell-vs-hopper-gpu-architecture-comparison","title":"Blackwell vs Hopper: A Deep Dive GPU Architecture Comparison","snippet":"Compared side-by-side, Blackwell offers dramatically higher AI throughput and memory capacity (e.g. ~9 petaFLOPS in FP8 vs ~4 petaFLOPS for ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":12},"pub_date":1761043129.0,"attribution":"intuitionlabs.ai"}]},{"type":"search_result_group","domain":"newsletter.semianalysis.com","entries":[{"type":"search_result","url":"https://newsletter.semianalysis.com/p/nvidia-gtc-2025-built-for-reasoning-vera-rubin-kyber-cpo-dynamo-inference-jensen-math-feynman","title":"NVIDIA GTC 2025 - Built For Reasoning, Vera Rubin ...","snippet":"Mar 18, 2025 \u2014 The next leap in inference throughput from hardware will come with the scale-up network world size expanding to 576 GPU dies in Rubin Ultra \u2013 up ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":16},"pub_date":1742350091.0,"attribution":"newsletter.semianalysis.com"}]},{"type":"search_result_group","domain":"www.tomshardware.com","entries":[{"type":"search_result","url":"https://www.tomshardware.com/tech-industry/artificial-intelligence/elon-musk-says-xai-is-targeting-50-million-h100-equivalent-ai-gpus-in-five-years-230k-gpus-including-30k-gb200s-already-reportedly-operational-for-training-grok","title":"Elon Musk says xAI is targeting 50 million 'H100 equivalent' AI GPUs in five years - 230k GPUs, including 30k GB200s already reportedly operational for training Grok","snippet":"Elon Musk announced that his AI company xAI plans to deploy the equivalent of 50 million Nvidia H100 GPUs for AI training over the next five years, targeting 50 ExaFLOPS of compute power. Although the raw number of GPUs might be lower due to improved performance in newer architectures like Blackwell, Rubin, and future Feynman Ultra chips, achieving this goal may still demand between 650,000 and 1.3 million of the most advanced GPUs. xAI currently operates 230,000 GPUs, including 30,000 Blackwell GB200 units, and is building a Colossus 2 supercluster expected to exceed one million GPUs.\n\nNvidia\u2019s annual performance enhancements, using architectures like Hopper, Blackwell, Rubin, and beyond, promise exponential efficiency and power gains. Yet, the projected energy requirement is immense\u2014up to 35 GW using H100s or about 4.7 GW with the highly-efficient Feynman chips\u2014comparable to the output of multiple nuclear power plants. This raises serious questions about power sourcing for such massive compute infrastructure. Despite these challenges, the continued exponential performance growth in AI hardware suggests that the performance goal is feasible by 2030, even if the logistics and power needs pose significant hurdles.","ref_id":{"turn_index":2,"ref_type":"news","ref_index":33},"pub_date":1753289893.0,"attribution":"www.tomshardware.com"}]},{"type":"search_result_group","domain":"www.theverge.com","entries":[{"type":"search_result","url":"https://www.theverge.com/news/631835/nvidia-blackwell-ultra-ai-chip-gb300","title":"Nvidia announces Blackwell Ultra GB300 and Vera Rubin, its next AI 'superchips'","snippet":"Nvidia has announced its new AI \"superchips,\" the Blackwell Ultra GB300 and Vera Rubin. The Blackwell Ultra GB300 is set to ship in the second half of 2025, and the Vera Rubin in the second half of 2026, with the Rubin Ultra arriving in 2027. The Blackwell Ultra boasts 20 petaflops of AI performance and an upgraded 288GB of HBM3e memory, while the Vera Rubin architecture offers substantial improvements, including 50 petaflops of FP4, and demand for immense computing power to keep up with AI advancements. A single Blackwell Ultra chip will be available in a desktop computer named the DGX Station. Nvidia aims to address the escalating need for processing power with these new releases, emphasizing their critical role in the future of computing. The company has already seen significant sales, with $11 billion worth of Blackwell chips shipped in 2025. The next architecture, named Feynman, is expected in 2028.","ref_id":{"turn_index":2,"ref_type":"news","ref_index":34},"pub_date":1742323751.0,"attribution":"www.theverge.com"}]},{"type":"search_result_group","domain":"apnews.com","entries":[{"type":"search_result","url":"https://apnews.com/article/457e9260aa2a34c1bbcc07c98b7a0555","title":"Nvidia CEO Jensen Huang unveils new Rubin AI chips at GTC 2025","snippet":"Nvidia CEO Jensen Huang unveiled the company's next-generation AI chips, Blackwell Ultra and Vera Rubin, at GTC 2025, highlighting significant advancements in AI technology. Nvidia anticipates its data center infrastructure revenue to reach $1 trillion by 2028 due to surging demand for GPUs from the top cloud service providers. Rubin AI chip will launch in late 2026, followed by Rubin Ultra in 2027. Huang emphasized that AI has evolved from perception and computer vision to generative AI and agentic AI capable of reasoning and understanding complex contexts. The next wave of AI, referred to as physical AI, encompasses robotics, which can conceptualize interactions like friction and inertia. Nvidia introduced Isaac GR00T N1, an open-source model for developing humanoid robots, and the evolving Cosmos AI model for creating synthetic training data. Nvidia\u2019s advancements aim to lower costs and improve efficiency for training AI and robotics. Additionally, Nvidia is collaborating with General Motors to integrate AI systems for self-driving cars and introduced the Halos system for autonomous driving safety. Huang concluded by announcing the Newton physics engine for robotics simulation, developed with Google DeepMind and Disney Research.","ref_id":{"turn_index":2,"ref_type":"news","ref_index":36},"pub_date":1742322920.0,"attribution":"apnews.com"}]}],"debug_sonic_thread_id":"thread_68fb9b062bfc832c93f98a0591b36d00","reasoning_status":"is_reasoning","reasoning_title":"Searching for NVIDIA architecture timelines and specifications","classifier_response":"default","request_id":"e52f9de3-65ab-4b89-a495-bb780783360e","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"max","parent_id":"63f245ba-c492-4449-9d1c-e7cd89b58ef1","turn_exchange_id":"dae60d5f-94c0-4ed0-95ae-1ca695fce69d","timestamp_":"absolute","can_save":false},"recipient":"all","channel":null},"parent":"63f245ba-c492-4449-9d1c-e7cd89b58ef1","children":["b1bb22cd-55de-4313-b367-ab76dcc943c2"]},"b1bb22cd-55de-4313-b367-ab76dcc943c2":{"id":"b1bb22cd-55de-4313-b367-ab76dcc943c2","message":{"id":"b1bb22cd-55de-4313-b367-ab76dcc943c2","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1761319709.831473,"update_time":null,"content":{"content_type":"thoughts","thoughts":[{"summary":"Forecasting analog compute adoption","content":"We have the Peking University Nature Electronics paper in hand, but I need to incorporate new citations. I'll forecast a timeline with milestones for significant impact, aiming for >10% reduction in AI training time. I'll define key thresholds like >5% of training compute using analog co-processors and set goals for 2026-2032. I'll also track critical challenges such as ADC efficiency, crossbar yields, memory, and software integration.","chunks":["We have the Peking University Nature Electronics paper in hand, but I need to incorporate new citations.","I'll forecast a timeline with milestones for significant impact, aiming for >10% reduction in AI training time.","I'll define key thresholds like >5% of training compute using analog co-processors and set goals for 2026-2032.","I'll also track critical challenges such as ADC efficiency, crossbar yields, memory, and software integration."],"finished":true},{"summary":"Analyzing analog adoption for inference and training","content":"It looks like analog adoption is more plausible for inference tasks, as IBM\u2019s analog chip has achieved success in tasks like QA and low-power inference (e.g., audio, on-device). For training, however, acceleration would likely come later. I\u2019ll calculate expected speedup using Amdahl\u2019s law, aiming for a 22% speedup in specific kernels.","chunks":["It looks like analog adoption is more plausible for inference tasks, as IBM\u2019s analog chip has achieved success in tasks like QA and low-power inference (e.g., audio, on-device).","For training, however, acceleration would likely come later.","I\u2019ll calculate expected speedup using Amdahl\u2019s law, aiming for a 22% speedup in specific kernels."],"finished":true},{"summary":"Considering analog's potential in training and timelines","content":"For general training without heavy inversion (like SGD with Adam), the speedup is minimal, around 1.05. But if analog MVM is used for GEMMs, the speedup potential increases if precision and integration improve. I'll track timeline forecasts for analog adoption, incorporating the FP8 trend and digital progress. Expect demos in 2025-2026, with prototypes in 2026-2027.","chunks":["For general training without heavy inversion (like SGD with Adam), the speedup is minimal, around 1.05.","But if analog MVM is used for GEMMs, the speedup potential increases if precision and integration improve.","I'll track timeline forecasts for analog adoption, incorporating the FP8 trend and digital progress.","Expect demos in 2025-2026, with prototypes in 2026-2027."],"finished":true},{"summary":"Considering analog's role in HPC and training","content":"For now, analog won\u2019t fit into LLM training but could serve as a co-processor (like PCIe cards) for specialized tasks such as acceleration of attention or second-order optimizers (K-FAC), offering minor speedups (5-10%). By 2028-2029, co-processor options could offer 10-25% improvements. Analog crossbar RBC could see deployment in training loops by 2030-2032, though digital (like Rubin and Feynman) will still be competitive come 2027-2028.","chunks":["For now, analog won\u2019t fit into LLM training but could serve as a co-processor (like PCIe cards) for specialized tasks such as acceleration of attention or second-order optimizers (K-FAC), offering minor speedups (5-10%).","By 2028-2029, co-processor options could offer 10-25% improvements.","Analog crossbar RBC could see deployment in training loops by 2030-2032, though digital (like Rubin and Feynman) will still be competitive come 2027-2028."],"finished":true},{"summary":"Defining analog adoption and impact","content":"For predicting the impact of analog in LLM training, we propose a threshold of 10% of training clusters utilizing analog co-processors by 2030 in an optimistic case, with 2031\u20132033 as the more likely scenario. We'll provide a scenario table and use calculations to compute possible speedup values without overpromising specific figures.","chunks":["For predicting the impact of analog in LLM training, we propose a threshold of 10% of training clusters utilizing analog co-processors by 2030 in an optimistic case, with 2031\u20132033 as the more likely scenario.","We'll provide a scenario table and use calculations to compute possible speedup values without overpromising specific figures."],"finished":true}],"source_analysis_msg_id":"365bb39f-20bd-441b-b6a4-1fa81ea40911"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"is_reasoning","content_references":[],"citations":[],"classifier_response":"default","skip_reasoning_title":"Skip","request_id":"e52f9de3-65ab-4b89-a495-bb780783360e","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"max","parent_id":"bfdfea72-467a-4732-a51c-d643e418166c","turn_exchange_id":"dae60d5f-94c0-4ed0-95ae-1ca695fce69d","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"bfdfea72-467a-4732-a51c-d643e418166c","children":["6b249b22-20e7-459e-93a7-04233e60d156"]},"6b249b22-20e7-459e-93a7-04233e60d156":{"id":"6b249b22-20e7-459e-93a7-04233e60d156","message":{"id":"6b249b22-20e7-459e-93a7-04233e60d156","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1761319731.952959,"update_time":1761319731.959288,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"# Calculate Amdahl speedup S = 1 / ((1 - p) + p / k) for various p and k\r\ndef speedup(p, k):\r\n    return 1.0 / ((1.0 - p) + p / k)\r\n\r\nps = [0.05, 0.1, 0.2, 0.5, 0.8]\r\nks = [5, 10, 30, 100, 1000]\r\nresults = {(p,k): speedup(p,k) for p in ps for k in ks}\r\nresults"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200012]},"is_complete":true,"citations":[],"content_references":[],"reasoning_status":"is_reasoning","reasoning_title":"Evaluating analog co-processor impact on AI training","classifier_response":"default","request_id":"e52f9de3-65ab-4b89-a495-bb780783360e","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"max","parent_id":"b1bb22cd-55de-4313-b367-ab76dcc943c2","turn_exchange_id":"dae60d5f-94c0-4ed0-95ae-1ca695fce69d","timestamp_":"absolute","can_save":true},"recipient":"python","channel":null},"parent":"b1bb22cd-55de-4313-b367-ab76dcc943c2","children":["4fc8bab8-01e4-44ce-b73c-16ed6363ea72"]},"4fc8bab8-01e4-44ce-b73c-16ed6363ea72":{"id":"4fc8bab8-01e4-44ce-b73c-16ed6363ea72","message":{"id":"4fc8bab8-01e4-44ce-b73c-16ed6363ea72","author":{"role":"tool","name":"python","metadata":{}},"create_time":1761319733.1674933,"update_time":1761319734.7487278,"content":{"content_type":"execution_output","text":"{(0.05, 5): 1.0416666666666667,\n (0.05, 10): 1.0471204188481675,\n (0.05, 30): 1.0507880910683012,\n (0.05, 100): 1.0520778537611783,\n (0.05, 1000): 1.052576180201042,\n (0.1, 5): 1.0869565217391304,\n (0.1, 10): 1.0989010989010988,\n (0.1, 30): 1.1070110701107012,\n (0.1, 100): 1.1098779134295227,\n (0.1, 1000): 1.1109876680368849,\n (0.2, 5): 1.1904761904761905,\n (0.2, 10): 1.2195121951219512,\n (0.2, 30): 1.2396694214876032,\n (0.2, 100): 1.2468827930174562,\n (0.2, 1000): 1.2496875781054737,\n (0.5, 5): 1.6666666666666667,\n (0.5, 10): 1.8181818181818181,\n (0.5, 30): 1.9354838709677418,\n (0.5, 100): 1.9801980198019802,\n (0.5, 1000): 1.9980019980019983,\n (0.8, 5): 2.7777777777777777,\n (0.8, 10): 3.5714285714285716,\n (0.8, 30): 4.411764705882354,\n (0.8, 100): 4.807692307692308,\n (0.8, 1000): 4.980079681274901}"},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"is_complete":true,"aggregate_result":{"status":"success","run_id":"e04eb591-9162-404b-90db-b5e1916f9cdd","start_time":1761319733.1674933,"update_time":1761319734.7487278,"code":"# Calculate Amdahl speedup S = 1 / ((1 - p) + p / k) for various p and k\r\ndef speedup(p, k):\r\n    return 1.0 / ((1.0 - p) + p / k)\r\n\r\nps = [0.05, 0.1, 0.2, 0.5, 0.8]\r\nks = [5, 10, 30, 100, 1000]\r\nresults = {(p,k): speedup(p,k) for p in ps for k in ks}\r\nresults","end_time":1761319734.7487278,"final_expression_output":"{(0.05, 5): 1.0416666666666667,\n (0.05, 10): 1.0471204188481675,\n (0.05, 30): 1.0507880910683012,\n (0.05, 100): 1.0520778537611783,\n (0.05, 1000): 1.052576180201042,\n (0.1, 5): 1.0869565217391304,\n (0.1, 10): 1.0989010989010988,\n (0.1, 30): 1.1070110701107012,\n (0.1, 100): 1.1098779134295227,\n (0.1, 1000): 1.1109876680368849,\n (0.2, 5): 1.1904761904761905,\n (0.2, 10): 1.2195121951219512,\n (0.2, 30): 1.2396694214876032,\n (0.2, 100): 1.2468827930174562,\n (0.2, 1000): 1.2496875781054737,\n (0.5, 5): 1.6666666666666667,\n (0.5, 10): 1.8181818181818181,\n (0.5, 30): 1.9354838709677418,\n (0.5, 100): 1.9801980198019802,\n (0.5, 1000): 1.9980019980019983,\n (0.8, 5): 2.7777777777777777,\n (0.8, 10): 3.5714285714285716,\n (0.8, 30): 4.411764705882354,\n (0.8, 100): 4.807692307692308,\n (0.8, 1000): 4.980079681274901}","in_kernel_exception":null,"system_exception":null,"messages":[],"jupyter_messages":[{"msg_type":"status","parent_header":{"msg_id":"023b0966-8d371ddeb47c867476c42eac_3_3","version":"5.3"},"content":{"execution_state":"busy"}},{"msg_type":"execute_input","parent_header":{"msg_id":"023b0966-8d371ddeb47c867476c42eac_3_3","version":"5.3"}},{"parent_header":{"msg_id":"023b0966-8d371ddeb47c867476c42eac_3_3","version":"5.3"},"msg_type":"execute_result","content":{"data":{"text/plain":"{(0.05, 5): 1.0416666666666667,\n (0.05, 10): 1.0471204188481675,\n (0.05, 30): 1.0507880910683012,\n (0.05, 100): 1.0520778537611783,\n (0.05, 1000): 1.052576180201042,\n (0.1, 5): 1.0869565217391304,\n (0.1, 10): 1.0989010989010988,\n (0.1, 30): 1.1070110701107012,\n (0.1, 100): 1.1098779134295227,\n (0.1, 1000): 1.1109876680368849,\n (0.2, 5): 1.1904761904761905,\n (0.2, 10): 1.2195121951219512,\n (0.2, 30): 1.2396694214876032,\n (0.2, 100): 1.2468827930174562,\n (0.2, 1000): 1.2496875781054737,\n (0.5, 5): 1.6666666666666667,\n (0.5, 10): 1.8181818181818181,\n (0.5, 30): 1.9354838709677418,\n (0.5, 100): 1.9801980198019802,\n (0.5, 1000): 1.9980019980019983,\n (0.8, 5): 2.7777777777777777,\n (0.8, 10): 3.5714285714285716,\n (0.8, 30): 4.411764705882354,\n (0.8, 100): 4.807692307692308,\n (0.8, 1000): 4.980079681274901}"}}},{"msg_type":"status","parent_header":{"msg_id":"023b0966-8d371ddeb47c867476c42eac_3_3","version":"5.3"},"content":{"execution_state":"idle"}}],"timeout_triggered":null},"reasoning_status":"is_reasoning","reasoning_title":"Evaluating analog co-processor impact on AI training","classifier_response":"default","request_id":"e52f9de3-65ab-4b89-a495-bb780783360e","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"max","parent_id":"6b249b22-20e7-459e-93a7-04233e60d156","turn_exchange_id":"dae60d5f-94c0-4ed0-95ae-1ca695fce69d","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"6b249b22-20e7-459e-93a7-04233e60d156","children":["9704865f-372b-474b-8a72-346b7e54bd4c"]},"9704865f-372b-474b-8a72-346b7e54bd4c":{"id":"9704865f-372b-474b-8a72-346b7e54bd4c","message":{"id":"9704865f-372b-474b-8a72-346b7e54bd4c","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1761319741.654799,"update_time":null,"content":{"content_type":"thoughts","thoughts":[{"summary":"Illustrating diminishing returns and energy efficiency","content":"Even with a large speedup in the accelerated part, the total speedup is around 1.25x (25%) at p=0.2, showing diminishing returns. We can present a table to illustrate this, considering both speed and energy efficiency. It\u2019s important to incorporate power cost per token and metrics like \"Joules per parameter update.\"","chunks":["Even with a large speedup in the accelerated part, the total speedup is around 1.25x (25%) at p=0.2, showing diminishing returns.","We can present a table to illustrate this, considering both speed and energy efficiency.","It\u2019s important to incorporate power cost per token and metrics like \"Joules per parameter update.\""],"finished":true},{"summary":"Exploring potential synergy and leading indicators","content":"I\u2019m thinking about proposing the use of analog units as co-processors, particularly for MIMO/per-iteration solves, like analog crossbars doing blockwise solves for K-FAC. I'll define leading indicators like demonstration of 32\u00d732 analog inversion blocks and measurable thresholds for performance, with a timeline leading up to 2025.","chunks":["I\u2019m thinking about proposing the use of analog units as co-processors, particularly for MIMO/per-iteration solves, like analog crossbars doing blockwise solves for K-FAC.","I'll define leading indicators like demonstration of 32\u00d732 analog inversion blocks and measurable thresholds for performance, with a timeline leading up to 2025."],"finished":true},{"summary":"Incorporating citations and assumptions","content":"I\u2019ll gather citations from sources like Nature Electronics 2025, IBM 2023 on analog AI, RRAM variability, and Nvidia roadmaps, among others. I\u2019ll ensure citations are placed correctly after the text and offer a bullet point list of assumptions as well, keeping the response comprehensive but balanced.","chunks":["I\u2019ll gather citations from sources like Nature Electronics 2025, IBM 2023 on analog AI, RRAM variability, and Nvidia roadmaps, among others.","I\u2019ll ensure citations are placed correctly after the text and offer a bullet point list of assumptions as well, keeping the response comprehensive but balanced."],"finished":true},{"summary":"Crafting the answer with a clear timeline","content":"I\u2019ll define the \"significant impact\" as a 10-20% reduction in training time or energy usage and adoption by leading labs. I'll lay out the timeline with optimistic, base, and pessimistic scenarios. I\u2019ll also reference FP8 training research to address improvements, considering rapid adoption of precision techniques in GPUs for better performance.","chunks":["I\u2019ll define the \"significant impact\" as a 10-20% reduction in training time or energy usage and adoption by leading labs. I'll lay out the timeline with optimistic, base, and pessimistic scenarios. I\u2019ll also reference FP8 training research to address improvements, considering rapid adoption of precision techniques in GPUs for better performance."],"finished":true}],"source_analysis_msg_id":"85ec6aab-2223-4801-8ed7-a71b8b819fc8"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"is_reasoning","content_references":[],"citations":[],"classifier_response":"default","skip_reasoning_title":"Skip","request_id":"e52f9de3-65ab-4b89-a495-bb780783360e","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"max","parent_id":"4fc8bab8-01e4-44ce-b73c-16ed6363ea72","turn_exchange_id":"dae60d5f-94c0-4ed0-95ae-1ca695fce69d","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"4fc8bab8-01e4-44ce-b73c-16ed6363ea72","children":["8fe02c84-0186-4583-a1d1-a05c29af1a72"]},"8fe02c84-0186-4583-a1d1-a05c29af1a72":{"id":"8fe02c84-0186-4583-a1d1-a05c29af1a72","message":{"id":"8fe02c84-0186-4583-a1d1-a05c29af1a72","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1761319761.465599,"update_time":null,"content":{"content_type":"reasoning_recap","content":"Thought for 1m 38s"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"reasoning_ended","finished_duration_sec":98,"request_id":"e52f9de3-65ab-4b89-a495-bb780783360e","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"max","parent_id":"9704865f-372b-474b-8a72-346b7e54bd4c","turn_exchange_id":"dae60d5f-94c0-4ed0-95ae-1ca695fce69d","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"9704865f-372b-474b-8a72-346b7e54bd4c","children":["d274ce01-3af5-44a5-ae75-c82bf7eb1aab"]},"d274ce01-3af5-44a5-ae75-c82bf7eb1aab":{"id":"d274ce01-3af5-44a5-ae75-c82bf7eb1aab","message":{"id":"d274ce01-3af5-44a5-ae75-c82bf7eb1aab","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1761319761.358835,"update_time":1761319798.535858,"content":{"content_type":"text","parts":["Short answer: not before **2028** for niche/operator-level speedups in real training loops, and **2030\u20132032** before you see **material, mainstream** impact\u2014*if* several hard engineering hurdles are cleared. The digital baseline (FP8/FP4 on NVIDIA Blackwell\u2192Rubin) is improving so quickly that the analog camp needs multiple tape-outs, robust ADC/DACs, and clean PyTorch/Triton integration to matter. \ue200cite\ue202turn0search0\ue202turn2search3\ue202turn2search1\ue202turn2search2\ue201\n\n---\n\n# How I\u2019m extrapolating\n\n## 1) What\u2019s proven vs pending\n- **Proven (on silicon, peer-reviewed):** Peking Univ. showed a *precise analogue* matrix-equation solver that combines a small **analogue inversion** block with a **high-precision analogue MVM** and iterative refinement; it hits digital-like accuracy on small problems and a MIMO detection task. That\u2019s real, but **not** a drop-in LLM trainer. \ue200cite\ue202turn0search0\ue201  \n- **Pending:** scaling on-array inversion beyond tiny blocks, high-speed/low-energy **\u226510-bit ADC/DAC**, long-term stability/variability of RRAM devices, and a **single-chip** design that can be driven by commodity frameworks at cluster scale. These are exactly where analogue compute historically stalls. Reviews still flag ADC energy and RRAM variability as dominant risks. \ue200cite\ue202turn1search9\ue202turn1search16\ue202turn1search1\ue201\n\n## 2) Moving target: digital training is getting cheaper/faster\n- Mainstream training is sliding to **FP8** (and exploring FP4 for parts of the stack) with hardened kernels in TransformerEngine/TensorRT on **Blackwell** and then **Rubin**. That shrinks analogue\u2019s *relative* advantage unless analogue arrives with production-grade precision/efficiency. \ue200cite\ue202turn0search9\ue202turn0search4\ue202turn2search9\ue202turn2search10\ue202turn2search2\ue201\n\n## 3) Where analogue could matter in training\n- **Operator-level accelerators** for linear solves (e.g., K-FAC/Kronecker-factored preconditioning, Newton-style steps) or **attention/MVM** blocks via in-memory compute. There\u2019s a credible research trend (analogue attention, fully-analogue iterations), but end-to-end *training* demonstrations are sparse. \ue200cite\ue202turn1search0\ue202turn1search3\ue202turn1search21\ue201  \n- **Amdahl reality check:** even \u201c1000\u00d7 faster\u201d on a kernel only helps if that kernel dominates runtime. If an analogue coprocessor speeds up just **20%** of your loop by **1000\u00d7**, total speedup is only **~1.25\u00d7**. If it can accelerate **80%** by **10\u00d7**, you\u2019d get **~3.6\u00d7**\u2014powerful, but that requires *most* GEMMs/attention to move onto analogue with acceptable numerics and tooling. (This is why attention/MVM offload is more impactful than exotic inverse-solvers unless second-order methods become standard.)  \n\n## 4) Plausible timeline (dated from Oct 2025)\n\n**2026\u20132027 (R&D \u2192 demo)**  \n- Tape-outs showing **\u226532\u00d732** analogue inversion blocks integrated with **10-bit+ ADC/DAC**; small **PCIe boards** with Python APIs; **research-lab** training runs that use analogue for attention or K-FAC updates. Expect **operator-level** wins on narrow model families; cluster-level gains still marginal. \ue200cite\ue202turn0search0\ue202turn1search0\ue201\n\n**2028\u20132029 (early deployment, niche impact)**  \n- First **co-processor** cards in academic/HPC sites and a few clouds for **wireless/communications**, **scientific linear solves**, or **second-order training** experiments. If analogue can own **\u226530%** of the training step (attention+some MLP MVM) at **\u226510\u00d7** speed/energy, you start to see **10\u201325%** wall-clock or energy reductions on select models. Risk: Blackwell\u2192**Rubin** cadence keeps raising the bar. \ue200cite\ue202turn2search3\ue201\n\n**2030\u20132032 (meaningful, but still domain-specific)**  \n- **Productionized** chips (monolithic analogue tiles + ADC/DAC + digital control) with **toolchain support** (PyTorch/Triton/TensorRT bridges). If reliability/calibration mature and software stacks stabilize, analogue could reach **5\u201315%** of training compute in specialized workloads, delivering **20\u201340%** energy savings and **1.2\u20132\u00d7** speedups **where algorithms are co-designed** (e.g., K-FAC-like schedules, analogue-friendly attention). Fallback if hurdles persist: analogue remains largely an **inference** or **HPC-solver** play. \ue200cite\ue202turn0search2\ue202turn0search12\ue201\n\n---\n\n# Key gating milestones to watch\n1) **Integrated silicon:** single-chip analogue solver + high-speed **\u226510-bit** ADC/DAC with measured *system* energy/throughput (not projections). \ue200cite\ue202turn1search9\ue201  \n2) **Size scaling:** on-array inversion at **\u226532\u00d732 (better 64\u00d764)** with temperature/aging drift characterization and on-chip calibration. \ue200cite\ue202turn0search0\ue201  \n3) **Software:** a **stable PyTorch extension** and kernels usable inside training loops; **MLPerf-Training** submissions that show fixed-accuracy wins vs GPUs. \ue200cite\ue202turn2search8\ue201  \n4) **Numerics:** evidence that analogue precision/dynamic-range handles **FP8-era** training stably across long schedules, or compelling **algorithmic co-design** (analogue attention, robust second-order). \ue200cite\ue202turn0search9\ue202turn1search0\ue201  \n5) **Device physics:** published RRAM variability/endurance and **converter energy** trending that make datacenter-scale calibration viable. \ue200cite\ue202turn1search16\ue202turn1search1\ue201\n\n---\n\n## Bottom line (my call)\n- **Niche/operator impact** in training: **~2028** earliest.  \n- **Visible, model-class impact** (double-digit % wall-clock/energy savings) on co-designed workloads: **2030\u20132032**.  \n- **Broad mainstream impact** across standard LLM training stacks: **>2032**, and only if analogue wins on precision, ADC energy, software, and reliability **while** outpacing Blackwell\u2192Rubin advances.  \n\nThis is a *credible* direction (the Peking Univ. paper is real and peer-reviewed), but we should treat \u201c1000\u00d7 faster than GPUs\u201d as a **modeled upper bound**, not the near-term reality of end-to-end training. \ue200cite\ue202turn0search0\ue202turn0search1\ue201"]},"status":"finished_successfully","end_turn":true,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200002]},"is_complete":true,"content_references":[{"matched_text":"\ue200cite\ue202turn0search0\ue202turn2search3\ue202turn2search1\ue202turn2search2\ue201","start_idx":401,"end_idx":459,"safe_urls":["https://blogs.nvidia.com/blog/nvidia-keynote-at-gtc-2025-ai-news-live-updates/?utm_source=chatgpt.com","https://developer.nvidia.com/blog/nvidia-blackwell-delivers-world-record-deepseek-r1-inference-performance/?utm_source=chatgpt.com","https://developer.nvidia.com/blog/nvidia-tensorrt-unlocks-fp4-image-generation-for-nvidia-blackwell-geforce-rtx-50-series-gpus/?utm_source=chatgpt.com","https://www.nature.com/articles/s41928-025-01477-0?utm_source=chatgpt.com"],"refs":[],"alt":"([Nature](https://www.nature.com/articles/s41928-025-01477-0?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Precise and scalable analogue matrix equation solving ...","url":"https://www.nature.com/articles/s41928-025-01477-0?utm_source=chatgpt.com","pub_date":null,"snippet":"by P Zuo \u00b7 2025 \u2014 Our approach uses an iterative algorithm that combines analogue low-precision matrix inversion and analogue high-precision matrix\u2013vector ...","attribution_segments":null,"supporting_websites":[{"title":"GTC 2025 \u2013 Announcements and Live Updates","url":"https://blogs.nvidia.com/blog/nvidia-keynote-at-gtc-2025-ai-news-live-updates/?utm_source=chatgpt.com","pub_date":null,"snippet":"Mar 25, 2025 \u2014 Each year will bring new GPUs, CPUs and accelerated computing advancements, including the upcoming NVIDIA Vera Rubin architecture, designed to ...","attribution":"NVIDIA Blog"},{"title":"NVIDIA Blackwell Delivers World-Record DeepSeek-R1 Inference ...","url":"https://developer.nvidia.com/blog/nvidia-blackwell-delivers-world-record-deepseek-r1-inference-performance/?utm_source=chatgpt.com","pub_date":null,"snippet":"NVIDIA announced world-record DeepSeek-R1 inference performance at NVIDIA GTC 2025. A single NVIDIA DGX system with eight NVIDIA Blackwell ...","attribution":"NVIDIA Developer"},{"title":"NVIDIA TensorRT Unlocks FP4 Image Generation for NVIDIA ...","url":"https://developer.nvidia.com/blog/nvidia-tensorrt-unlocks-fp4-image-generation-for-nvidia-blackwell-geforce-rtx-50-series-gpus/?utm_source=chatgpt.com","pub_date":null,"snippet":"With FP4, Blackwell can maximize performance while maintaining usable task accuracies. FP4 also provides superior inference accuracy over INT4.","attribution":"NVIDIA Developer"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":0},{"turn_index":2,"ref_type":"search","ref_index":3},{"turn_index":2,"ref_type":"search","ref_index":1},{"turn_index":2,"ref_type":"search","ref_index":2}],"hue":null,"attributions":null,"attribution":"Nature"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search0\ue201","start_idx":867,"end_idx":886,"safe_urls":["https://www.nature.com/articles/s41928-025-01477-0?utm_source=chatgpt.com"],"refs":[],"alt":"([Nature](https://www.nature.com/articles/s41928-025-01477-0?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Precise and scalable analogue matrix equation solving ...","url":"https://www.nature.com/articles/s41928-025-01477-0?utm_source=chatgpt.com","pub_date":null,"snippet":"by P Zuo \u00b7 2025 \u2014 Our approach uses an iterative algorithm that combines analogue low-precision matrix inversion and analogue high-precision matrix\u2013vector ...","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":0}],"hue":null,"attributions":null,"attribution":"Nature"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn1search9\ue202turn1search16\ue202turn1search1\ue201","start_idx":1265,"end_idx":1311,"safe_urls":["https://pubs.acs.org/doi/10.1021/acs.chemrev.4c00845?utm_source=chatgpt.com","https://repository.tudelft.nl/file/File_dfa6e78d-2bd4-4768-bf4f-e7894d569637?utm_source=chatgpt.com","https://www.researchgate.net/publication/391833689_Analog-to-Digital_Converter_Design_for_Diverse_Performance_Computing-in-Memory_Systems_A_Comprehensive_Review?utm_source=chatgpt.com"],"refs":[],"alt":"([ResearchGate](https://www.researchgate.net/publication/391833689_Analog-to-Digital_Converter_Design_for_Diverse_Performance_Computing-in-Memory_Systems_A_Comprehensive_Review?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"(PDF) Analog-to-Digital Converter Design for Diverse ...","url":"https://www.researchgate.net/publication/391833689_Analog-to-Digital_Converter_Design_for_Diverse_Performance_Computing-in-Memory_Systems_A_Comprehensive_Review?utm_source=chatgpt.com","pub_date":1735689600.0,"snippet":"Aug 9, 2025 \u2014 This review presents theoretical analyses and practical case studies on the performance requirements of ADCs and their optimization methods in ...","attribution_segments":null,"supporting_websites":[{"title":"Analysis of Conductance Variability in RRAM for Accurate ...","url":"https://repository.tudelft.nl/file/File_dfa6e78d-2bd4-4768-bf4f-e7894d569637?utm_source=chatgpt.com","pub_date":null,"snippet":"by H Aziza \u00b7 2024 \u00b7 Cited by 1 \u2014 The proposed analysis revealed that conductance variability is a major concern in RRAM technology for computing. Hence, outcomes of this study are crucial for ...","attribution":"TU Delft Repository"},{"title":"Resistive Switching Random-Access Memory (RRAM)","url":"https://pubs.acs.org/doi/10.1021/acs.chemrev.4c00845?utm_source=chatgpt.com","pub_date":null,"snippet":"by D Ielmini \u00b7 Cited by 21 \u2014 This work addresses the RRAM concept from materials, device, circuit, and application viewpoints, focusing on the physical device properties and the ...","attribution":"American Chemical Society Publications"}],"refs":[{"turn_index":1,"ref_type":"search","ref_index":9},{"turn_index":1,"ref_type":"search","ref_index":16},{"turn_index":1,"ref_type":"search","ref_index":1}],"hue":null,"attributions":null,"attribution":"ResearchGate"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search9\ue202turn0search4\ue202turn2search9\ue202turn2search10\ue202turn2search2\ue201","start_idx":1666,"end_idx":1738,"safe_urls":["https://arxiv.org/html/2502.05967v3?utm_source=chatgpt.com","https://arxiv.org/html/2509.22536v4?utm_source=chatgpt.com","https://developer.nvidia.com/blog/nvidia-tensorrt-unlocks-fp4-image-generation-for-nvidia-blackwell-geforce-rtx-50-series-gpus/?utm_source=chatgpt.com","https://github.com/NVIDIA/TransformerEngine?utm_source=chatgpt.com","https://www.nvidia.com/en-us/on-demand/session/gtc25-S72778/?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/html/2502.05967v3?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"\u00b5nit Scaling: Simple and Scalable FP8 LLM Training","url":"https://arxiv.org/html/2502.05967v3?utm_source=chatgpt.com","pub_date":null,"snippet":"Jun 5, 2025 \u2014 We demonstrate a simple, scalable FP8 training method with straightforward hyperparameter transfer on large LLMs, called \u201c\u03bcnit Scaling\u201d (\u03bcS).","attribution_segments":null,"supporting_websites":[{"title":"InfiR2: A Comprehensive FP8 Training Recipe for ...","url":"https://arxiv.org/html/2509.22536v4?utm_source=chatgpt.com","pub_date":null,"snippet":"7 days ago \u2014 On the hardware side, NVIDIA's Blackwell architecture (NVIDIA, 2024) fundamentally ensures FP8 training stability with the MXFP8-E4M3 format ( ...","attribution":"arXiv"},{"title":"Stable and Scalable FP8 Deep Learning Training on Blackwell","url":"https://www.nvidia.com/en-us/on-demand/session/gtc25-S72778/?utm_source=chatgpt.com","pub_date":null,"snippet":"Learn about the new advancements in low-precision training recipes coming with Transformer Engine 2.0 for Hopper and Blackwell GPUs.","attribution":"NVIDIA"},{"title":"NVIDIA/TransformerEngine - GitHub","url":"https://github.com/NVIDIA/TransformerEngine?utm_source=chatgpt.com","pub_date":null,"snippet":"A library for accelerating Transformer models on NVIDIA GPUs, including using 8-bit floating point (FP8) precision on Hopper, Ada and Blackwell GPUs, ...","attribution":"GitHub"},{"title":"NVIDIA TensorRT Unlocks FP4 Image Generation for NVIDIA ...","url":"https://developer.nvidia.com/blog/nvidia-tensorrt-unlocks-fp4-image-generation-for-nvidia-blackwell-geforce-rtx-50-series-gpus/?utm_source=chatgpt.com","pub_date":null,"snippet":"With FP4, Blackwell can maximize performance while maintaining usable task accuracies. FP4 also provides superior inference accuracy over INT4.","attribution":"NVIDIA Developer"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":9},{"turn_index":0,"ref_type":"search","ref_index":4},{"turn_index":2,"ref_type":"search","ref_index":9},{"turn_index":2,"ref_type":"search","ref_index":10},{"turn_index":2,"ref_type":"search","ref_index":2}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn1search0\ue202turn1search3\ue202turn1search21\ue201","start_idx":2094,"end_idx":2140,"safe_urls":["https://arxiv.org/html/2409.19315v2?utm_source=chatgpt.com","https://pmc.ncbi.nlm.nih.gov/articles/PMC11817932/?utm_source=chatgpt.com","https://www.nature.com/articles/s43588-025-00854-1?utm_source=chatgpt.com"],"refs":[],"alt":"([Nature](https://www.nature.com/articles/s43588-025-00854-1?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Analog in-memory computing attention mechanism for fast ...","url":"https://www.nature.com/articles/s43588-025-00854-1?utm_source=chatgpt.com","pub_date":null,"snippet":"by N Leroux \u00b7 2025 \u00b7 Cited by 6 \u2014 Loading the KV cache for the attention mechanism is thus a major bottleneck, causing increased energy consumption and latency in large language ...","attribution_segments":null,"supporting_websites":[{"title":"Analog In-Memory Computing Attention Mechanism for ...","url":"https://arxiv.org/html/2409.19315v2?utm_source=chatgpt.com","pub_date":null,"snippet":"Nov 25, 2024 \u2014 We present a custom self-attention in-memory computing architecture based on emerging charge-based memories called gain cells.","attribution":"arXiv"},{"title":"Fully analog iteration for solving matrix equations with in- ...","url":"https://pmc.ncbi.nlm.nih.gov/articles/PMC11817932/?utm_source=chatgpt.com","pub_date":null,"snippet":"by J Li \u00b7 2025 \u00b7 Cited by 7 \u2014 However, the inherent inaccuracies of analog mechanisms create challenges in achieving high-precision solutions while maintaining low-energy ...","attribution":"PMC"}],"refs":[{"turn_index":1,"ref_type":"search","ref_index":0},{"turn_index":1,"ref_type":"search","ref_index":3},{"turn_index":1,"ref_type":"search","ref_index":21}],"hue":null,"attributions":null,"attribution":"Nature"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search0\ue202turn1search0\ue201","start_idx":3046,"end_idx":3078,"safe_urls":["https://www.nature.com/articles/s41928-025-01477-0?utm_source=chatgpt.com","https://www.nature.com/articles/s43588-025-00854-1?utm_source=chatgpt.com"],"refs":[],"alt":"([Nature](https://www.nature.com/articles/s41928-025-01477-0?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Precise and scalable analogue matrix equation solving ...","url":"https://www.nature.com/articles/s41928-025-01477-0?utm_source=chatgpt.com","pub_date":null,"snippet":"by P Zuo \u00b7 2025 \u2014 Our approach uses an iterative algorithm that combines analogue low-precision matrix inversion and analogue high-precision matrix\u2013vector ...","attribution_segments":null,"supporting_websites":[{"title":"Analog in-memory computing attention mechanism for fast ...","url":"https://www.nature.com/articles/s43588-025-00854-1?utm_source=chatgpt.com","pub_date":null,"snippet":"by N Leroux \u00b7 2025 \u00b7 Cited by 6 \u2014 Loading the KV cache for the attention mechanism is thus a major bottleneck, causing increased energy consumption and latency in large language ...","attribution":"Nature"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":0},{"turn_index":1,"ref_type":"search","ref_index":0}],"hue":null,"attributions":null,"attribution":"Nature"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn2search3\ue201","start_idx":3540,"end_idx":3559,"safe_urls":["https://blogs.nvidia.com/blog/nvidia-keynote-at-gtc-2025-ai-news-live-updates/?utm_source=chatgpt.com"],"refs":[],"alt":"([NVIDIA Blog](https://blogs.nvidia.com/blog/nvidia-keynote-at-gtc-2025-ai-news-live-updates/?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"GTC 2025 \u2013 Announcements and Live Updates","url":"https://blogs.nvidia.com/blog/nvidia-keynote-at-gtc-2025-ai-news-live-updates/?utm_source=chatgpt.com","pub_date":1742925605.0,"snippet":"Mar 25, 2025 \u2014 Each year will bring new GPUs, CPUs and accelerated computing advancements, including the upcoming NVIDIA Vera Rubin architecture, designed to ...","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":2,"ref_type":"search","ref_index":3}],"hue":null,"attributions":null,"attribution":"NVIDIA Blog"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search2\ue202turn0search12\ue201","start_idx":4156,"end_idx":4189,"safe_urls":["https://www.nature.com/articles/s41586-023-06337-5?utm_source=chatgpt.com","https://www.nature.com/articles/s41928-023-01035-6?utm_source=chatgpt.com"],"refs":[],"alt":"([Nature](https://www.nature.com/articles/s41586-023-06337-5?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"An analog-AI chip for energy-efficient speech recognition ...","url":"https://www.nature.com/articles/s41586-023-06337-5?utm_source=chatgpt.com","pub_date":null,"snippet":"by S Ambrogio \u00b7 2023 \u00b7 Cited by 207 \u2014 Here we present an analog-AI chip that combines 35 million phase-change memory devices across 34 tiles, massively parallel inter-tile communication and analog, ...","attribution_segments":null,"supporting_websites":[{"title":"Analogue chips for energy-efficient AI","url":"https://www.nature.com/articles/s41928-023-01035-6?utm_source=chatgpt.com","pub_date":null,"snippet":"by S Conti \u00b7 2023 \u2014 Overall, the chip has 35 million phase-change memory devices. The chip also contains digital-to-analogue input, analogue-to-digital output, ...","attribution":"Nature"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":2},{"turn_index":0,"ref_type":"search","ref_index":12}],"hue":null,"attributions":null,"attribution":"Nature"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn1search9\ue201","start_idx":4377,"end_idx":4396,"safe_urls":["https://www.researchgate.net/publication/391833689_Analog-to-Digital_Converter_Design_for_Diverse_Performance_Computing-in-Memory_Systems_A_Comprehensive_Review?utm_source=chatgpt.com"],"refs":[],"alt":"([ResearchGate](https://www.researchgate.net/publication/391833689_Analog-to-Digital_Converter_Design_for_Diverse_Performance_Computing-in-Memory_Systems_A_Comprehensive_Review?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"(PDF) Analog-to-Digital Converter Design for Diverse ...","url":"https://www.researchgate.net/publication/391833689_Analog-to-Digital_Converter_Design_for_Diverse_Performance_Computing-in-Memory_Systems_A_Comprehensive_Review?utm_source=chatgpt.com","pub_date":1735689600.0,"snippet":"Aug 9, 2025 \u2014 This review presents theoretical analyses and practical case studies on the performance requirements of ADCs and their optimization methods in ...","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":1,"ref_type":"search","ref_index":9}],"hue":null,"attributions":null,"attribution":"ResearchGate"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search0\ue201","start_idx":4539,"end_idx":4558,"safe_urls":["https://www.nature.com/articles/s41928-025-01477-0?utm_source=chatgpt.com"],"refs":[],"alt":"([Nature](https://www.nature.com/articles/s41928-025-01477-0?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Precise and scalable analogue matrix equation solving ...","url":"https://www.nature.com/articles/s41928-025-01477-0?utm_source=chatgpt.com","pub_date":null,"snippet":"by P Zuo \u00b7 2025 \u2014 Our approach uses an iterative algorithm that combines analogue low-precision matrix inversion and analogue high-precision matrix\u2013vector ...","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":0}],"hue":null,"attributions":null,"attribution":"Nature"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn2search8\ue201","start_idx":4722,"end_idx":4741,"safe_urls":["https://developer.nvidia.com/blog/nvidia-blackwell-delivers-massive-performance-leaps-in-mlperf-inference-v5-0/?utm_source=chatgpt.com"],"refs":[],"alt":"([NVIDIA Developer](https://developer.nvidia.com/blog/nvidia-blackwell-delivers-massive-performance-leaps-in-mlperf-inference-v5-0/?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"NVIDIA Blackwell Delivers Massive Performance Leaps in MLPerf ...","url":"https://developer.nvidia.com/blog/nvidia-blackwell-delivers-massive-performance-leaps-in-mlperf-inference-v5-0/?utm_source=chatgpt.com","pub_date":1743552000.0,"snippet":"MLPerf Inference v5.0 is the latest in a long-running benchmark suite that measures inference throughput across a range of different models and use cases.","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":2,"ref_type":"search","ref_index":8}],"hue":null,"attributions":null,"attribution":"NVIDIA Developer"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search9\ue202turn1search0\ue201","start_idx":4950,"end_idx":4982,"safe_urls":["https://arxiv.org/html/2502.05967v3?utm_source=chatgpt.com","https://www.nature.com/articles/s43588-025-00854-1?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/html/2502.05967v3?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"\u00b5nit Scaling: Simple and Scalable FP8 LLM Training","url":"https://arxiv.org/html/2502.05967v3?utm_source=chatgpt.com","pub_date":null,"snippet":"Jun 5, 2025 \u2014 We demonstrate a simple, scalable FP8 training method with straightforward hyperparameter transfer on large LLMs, called \u201c\u03bcnit Scaling\u201d (\u03bcS).","attribution_segments":null,"supporting_websites":[{"title":"Analog in-memory computing attention mechanism for fast ...","url":"https://www.nature.com/articles/s43588-025-00854-1?utm_source=chatgpt.com","pub_date":null,"snippet":"by N Leroux \u00b7 2025 \u00b7 Cited by 6 \u2014 Loading the KV cache for the attention mechanism is thus a major bottleneck, causing increased energy consumption and latency in large language ...","attribution":"Nature"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":9},{"turn_index":1,"ref_type":"search","ref_index":0}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn1search16\ue202turn1search1\ue201","start_idx":5126,"end_idx":5159,"safe_urls":["https://pubs.acs.org/doi/10.1021/acs.chemrev.4c00845?utm_source=chatgpt.com","https://repository.tudelft.nl/file/File_dfa6e78d-2bd4-4768-bf4f-e7894d569637?utm_source=chatgpt.com"],"refs":[],"alt":"([TU Delft Repository](https://repository.tudelft.nl/file/File_dfa6e78d-2bd4-4768-bf4f-e7894d569637?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Analysis of Conductance Variability in RRAM for Accurate ...","url":"https://repository.tudelft.nl/file/File_dfa6e78d-2bd4-4768-bf4f-e7894d569637?utm_source=chatgpt.com","pub_date":1718627234.0,"snippet":"by H Aziza \u00b7 2024 \u00b7 Cited by 1 \u2014 The proposed analysis revealed that conductance variability is a major concern in RRAM technology for computing. Hence, outcomes of this study are crucial for ...","attribution_segments":null,"supporting_websites":[{"title":"Resistive Switching Random-Access Memory (RRAM)","url":"https://pubs.acs.org/doi/10.1021/acs.chemrev.4c00845?utm_source=chatgpt.com","pub_date":null,"snippet":"by D Ielmini \u00b7 Cited by 21 \u2014 This work addresses the RRAM concept from materials, device, circuit, and application viewpoints, focusing on the physical device properties and the ...","attribution":"American Chemical Society Publications"}],"refs":[{"turn_index":1,"ref_type":"search","ref_index":16},{"turn_index":1,"ref_type":"search","ref_index":1}],"hue":null,"attributions":null,"attribution":"TU Delft Repository"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search0\ue202turn0search1\ue201","start_idx":5787,"end_idx":5819,"safe_urls":["https://amp.scmp.com/news/china/science/article/3329820/chinas-analogue-ai-chip-could-work-1000-times-faster-nvidia-gpu-study?utm_source=chatgpt.com","https://www.nature.com/articles/s41928-025-01477-0?utm_source=chatgpt.com"],"refs":[],"alt":"([Nature](https://www.nature.com/articles/s41928-025-01477-0?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Precise and scalable analogue matrix equation solving ...","url":"https://www.nature.com/articles/s41928-025-01477-0?utm_source=chatgpt.com","pub_date":null,"snippet":"by P Zuo \u00b7 2025 \u2014 Our approach uses an iterative algorithm that combines analogue low-precision matrix inversion and analogue high-precision matrix\u2013vector ...","attribution_segments":null,"supporting_websites":[{"title":"China's analogue AI chip could work 1000 times faster than ...","url":"https://amp.scmp.com/news/china/science/article/3329820/chinas-analogue-ai-chip-could-work-1000-times-faster-nvidia-gpu-study?utm_source=chatgpt.com","pub_date":null,"snippet":"3 days ago \u2014 The analogue device designed by researchers from Peking University uses memory chips made of resistive materials. ... Victoria Bela.","attribution":"amp.scmp.com"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":0},{"turn_index":0,"ref_type":"search","ref_index":1}],"hue":null,"attributions":null,"attribution":"Nature"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":" ","start_idx":5819,"end_idx":5819,"safe_urls":[],"refs":[],"alt":"","prompt_text":null,"type":"sources_footnote","sources":[{"title":"Precise and scalable analogue matrix equation solving ...","url":"https://www.nature.com/articles/s41928-025-01477-0?utm_source=chatgpt.com","attribution":"Nature"},{"title":"(PDF) Analog-to-Digital Converter Design for Diverse ...","url":"https://www.researchgate.net/publication/391833689_Analog-to-Digital_Converter_Design_for_Diverse_Performance_Computing-in-Memory_Systems_A_Comprehensive_Review?utm_source=chatgpt.com","attribution":"ResearchGate"},{"title":"\u00b5nit Scaling: Simple and Scalable FP8 LLM Training","url":"https://arxiv.org/html/2502.05967v3?utm_source=chatgpt.com","attribution":"arXiv"},{"title":"GTC 2025 \u2013 Announcements and Live Updates","url":"https://blogs.nvidia.com/blog/nvidia-keynote-at-gtc-2025-ai-news-live-updates/?utm_source=chatgpt.com","attribution":"NVIDIA Blog"},{"title":"NVIDIA Blackwell Delivers Massive Performance Leaps in MLPerf ...","url":"https://developer.nvidia.com/blog/nvidia-blackwell-delivers-massive-performance-leaps-in-mlperf-inference-v5-0/?utm_source=chatgpt.com","attribution":"NVIDIA Developer"},{"title":"Analysis of Conductance Variability in RRAM for Accurate ...","url":"https://repository.tudelft.nl/file/File_dfa6e78d-2bd4-4768-bf4f-e7894d569637?utm_source=chatgpt.com","attribution":"TU Delft Repository"}],"has_images":false}],"safe_urls":["https://blogs.nvidia.com/blog/nvidia-keynote-at-gtc-2025-ai-news-live-updates/?utm_source=chatgpt.com","https://developer.nvidia.com/blog/nvidia-blackwell-delivers-world-record-deepseek-r1-inference-performance/?utm_source=chatgpt.com","https://developer.nvidia.com/blog/nvidia-tensorrt-unlocks-fp4-image-generation-for-nvidia-blackwell-geforce-rtx-50-series-gpus/?utm_source=chatgpt.com","https://www.nature.com/articles/s41928-025-01477-0?utm_source=chatgpt.com","https://www.nature.com/articles/s41928-025-01477-0?utm_source=chatgpt.com","https://pubs.acs.org/doi/10.1021/acs.chemrev.4c00845?utm_source=chatgpt.com","https://repository.tudelft.nl/file/File_dfa6e78d-2bd4-4768-bf4f-e7894d569637?utm_source=chatgpt.com","https://www.researchgate.net/publication/391833689_Analog-to-Digital_Converter_Design_for_Diverse_Performance_Computing-in-Memory_Systems_A_Comprehensive_Review?utm_source=chatgpt.com","https://arxiv.org/html/2502.05967v3?utm_source=chatgpt.com","https://arxiv.org/html/2509.22536v4?utm_source=chatgpt.com","https://developer.nvidia.com/blog/nvidia-tensorrt-unlocks-fp4-image-generation-for-nvidia-blackwell-geforce-rtx-50-series-gpus/?utm_source=chatgpt.com","https://github.com/NVIDIA/TransformerEngine?utm_source=chatgpt.com","https://www.nvidia.com/en-us/on-demand/session/gtc25-S72778/?utm_source=chatgpt.com","https://arxiv.org/html/2409.19315v2?utm_source=chatgpt.com","https://pmc.ncbi.nlm.nih.gov/articles/PMC11817932/?utm_source=chatgpt.com","https://www.nature.com/articles/s43588-025-00854-1?utm_source=chatgpt.com","https://www.nature.com/articles/s41928-025-01477-0?utm_source=chatgpt.com","https://www.nature.com/articles/s43588-025-00854-1?utm_source=chatgpt.com","https://blogs.nvidia.com/blog/nvidia-keynote-at-gtc-2025-ai-news-live-updates/?utm_source=chatgpt.com","https://www.nature.com/articles/s41586-023-06337-5?utm_source=chatgpt.com","https://www.nature.com/articles/s41928-023-01035-6?utm_source=chatgpt.com","https://www.researchgate.net/publication/391833689_Analog-to-Digital_Converter_Design_for_Diverse_Performance_Computing-in-Memory_Systems_A_Comprehensive_Review?utm_source=chatgpt.com","https://www.nature.com/articles/s41928-025-01477-0?utm_source=chatgpt.com","https://developer.nvidia.com/blog/nvidia-blackwell-delivers-massive-performance-leaps-in-mlperf-inference-v5-0/?utm_source=chatgpt.com","https://arxiv.org/html/2502.05967v3?utm_source=chatgpt.com","https://www.nature.com/articles/s43588-025-00854-1?utm_source=chatgpt.com","https://pubs.acs.org/doi/10.1021/acs.chemrev.4c00845?utm_source=chatgpt.com","https://repository.tudelft.nl/file/File_dfa6e78d-2bd4-4768-bf4f-e7894d569637?utm_source=chatgpt.com","https://amp.scmp.com/news/china/science/article/3329820/chinas-analogue-ai-chip-could-work-1000-times-faster-nvidia-gpu-study?utm_source=chatgpt.com","https://www.nature.com/articles/s41928-025-01477-0?utm_source=chatgpt.com"],"search_result_groups":[{"type":"search_result_group","domain":"nvidia.com","entries":[{"type":"search_result","url":"https://developer.nvidia.com/blog/floating-point-8-an-introduction-to-efficient-lower-precision-ai-training/?utm_source=chatgpt.com","title":"Floating-Point 8: An Introduction to Efficient, Lower ...","snippet":"Jun 4, 2025 \u2014 A key enabler of FP8 training's speed and efficiency is the inclusion of dedicated FP8 Tensor Cores within the NVIDIA H100 architecture.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":23},"pub_date":null,"attribution":"nvidia.com"},{"type":"search_result","url":"https://developer.nvidia.com/blog/faster-training-throughput-in-fp8-precision-with-nvidia-nemo/?utm_source=chatgpt.com","title":"Faster Training Throughput in FP8 Precision with NVIDIA ...","snippet":"Sep 23, 2025 \u2014 We'll compare the leading FP8 scaling recipes side by side, using real benchmarks on NVIDIA H100 and NVIDIA DGX B200 GPUs. We rigorously ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":32},"pub_date":null,"attribution":"nvidia.com"},{"type":"search_result","url":"https://www.nvidia.com/en-us/on-demand/session/gtc25-S72503/?utm_source=chatgpt.com","title":"LLM Inference Performance and Optimization on NVIDIA GB200 ...","snippet":"In this session, we will dive into the GB200 NVL72 architecture and programming model, highlighting its inference performance on state-of-the-art LLM models.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":0},"pub_date":1742342400.0,"attribution":"nvidia.com"},{"type":"search_result","url":"https://developer.nvidia.com/blog/nvidia-blackwell-delivers-world-record-deepseek-r1-inference-performance/?utm_source=chatgpt.com","title":"NVIDIA Blackwell Delivers World-Record DeepSeek-R1 Inference ...","snippet":"NVIDIA announced world-record DeepSeek-R1 inference performance at NVIDIA GTC 2025. A single NVIDIA DGX system with eight NVIDIA Blackwell ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":1},"pub_date":1742256000.0,"attribution":"nvidia.com"},{"type":"search_result","url":"https://developer.nvidia.com/blog/nvidia-tensorrt-unlocks-fp4-image-generation-for-nvidia-blackwell-geforce-rtx-50-series-gpus/?utm_source=chatgpt.com","title":"NVIDIA TensorRT Unlocks FP4 Image Generation for NVIDIA ...","snippet":"With FP4, Blackwell can maximize performance while maintaining usable task accuracies. FP4 also provides superior inference accuracy over INT4.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":2},"pub_date":1747180800.0,"attribution":"nvidia.com"},{"type":"search_result","url":"https://nvidianews.nvidia.com/news/nvidia-blackwell-platform-arrives-to-power-a-new-era-of-computing?utm_source=chatgpt.com","title":"NVIDIA Blackwell Platform Arrives to Power a New Era of Computing","snippet":"The GB200 NVL72 provides up to a 30x performance increase compared to the same number of NVIDIA H100 Tensor Core GPUs for LLM inference ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":4},"pub_date":1710720000.0,"attribution":"nvidia.com"},{"type":"search_result","url":"https://developer.nvidia.com/blog/new-ai-sdks-and-tools-released-for-nvidia-blackwell-geforce-rtx-50-series-gpus/?utm_source=chatgpt.com","title":"New AI SDKs and Tools Released for NVIDIA Blackwell GeForce ...","snippet":"This post details new and updated SDKs that enable developers to take full advantage of NVIDIA Blackwell GeForce RTX 50 Series GPUs.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":5},"pub_date":1738195200.0,"attribution":"nvidia.com"},{"type":"search_result","url":"https://www.nvidia.com/en-us/on-demand/session/gtc25-S72778/?utm_source=chatgpt.com","title":"Stable and Scalable FP8 Deep Learning Training on Blackwell","snippet":"Learn about the new advancements in low-precision training recipes coming with Transformer Engine 2.0 for Hopper and Blackwell GPUs.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":9},"pub_date":1742428800.0,"attribution":"nvidia.com"},{"type":"search_result","url":"https://www.nvidia.com/en-us/on-demand/session/gtc25-s72778/?utm_source=chatgpt.com","title":"Stable and Scalable FP8 Deep Learning Training on ...","snippet":"Mar 20, 2025 \u2014 Learn about the new advancements in low-precision training recipes coming with Transformer Engine 2.0 for Hopper and Blackwell GPUs.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"nvidia.com"},{"type":"search_result","url":"https://developer.nvidia.com/blog/delivering-1-5-m-tps-inference-on-nvidia-gb200-nvl72-nvidia-accelerates-openai-gpt-oss-models-from-cloud-to-edge/?utm_source=chatgpt.com","title":"Delivering 1.5 M TPS Inference on NVIDIA GB200 NVL72, NVIDIA ...","snippet":"Deploying with TensorRT-LLM is also available using the Python API in a JupyterLab notebook on the Open AI Cookbook as an NVIDIA Launchable ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":14},"pub_date":1754433843.0,"attribution":"nvidia.com"},{"type":"search_result","url":"https://developer.nvidia.com/blog/blackwell-breaks-the-1000-tps-user-barrier-with-metas-llama-4-maverick/?utm_source=chatgpt.com","title":"Blackwell Breaks the 1,000 TPS/User Barrier With Meta's Llama 4 ...","snippet":"A single NVIDIA DGX B200 node with eight NVIDIA Blackwell GPUs can achieve over 1,000 tokens per second (TPS) per user on the 400-billion- ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":20},"pub_date":1747872000.0,"attribution":"nvidia.com"},{"type":"search_result","url":"https://images.nvidia.com/aem-dam/Solutions/geforce/blackwell/nvidia-rtx-blackwell-gpu-architecture.pdf?utm_source=chatgpt.com","title":"[PDF] NVIDIA RTX BLACKWELL GPU ARCHITECTURE","snippet":"GPU performance and image quality has been continually improving, even with Moore's Law coming to an end, by using neural rendering techniques.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":24},"pub_date":null,"attribution":"nvidia.com"},{"type":"search_result","url":"https://www.nvidia.com/en-us/on-demand/session/gtc25-s72503/?playlistId=playList-6f3417a3-e18d-429c-8d9c-8201d6db459c&utm_source=chatgpt.com","title":"LLM Inference Performance and Optimization on NVIDIA GB200 ...","snippet":"In this session, we will dive into the GB200 NVL72 architecture and programming model, highlighting its inference performance on state-of-the-art LLM model.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":28},"pub_date":null,"attribution":"nvidia.com"}]},{"type":"search_result_group","domain":"scmp.com","entries":[{"type":"search_result","url":"https://amp.scmp.com/news/china/science/article/3329820/chinas-analogue-ai-chip-could-work-1000-times-faster-nvidia-gpu-study?utm_source=chatgpt.com","title":"China's analogue AI chip could work 1000 times faster than ...","snippet":"3 days ago \u2014 The analogue device designed by researchers from Peking University uses memory chips made of resistive materials. ... Victoria Bela.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"scmp.com"},{"type":"search_result","url":"https://www.scmp.com/author/victoria-bela?utm_source=chatgpt.com","title":"Victoria Bela: Latest Articles, Analysis and Profile","snippet":"She holds a Master's in Public Policy from Peking University ... China's analogue AI chip could work 1,000 times faster than Nvidia GPU: study.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"scmp.com"}]},{"type":"search_result_group","domain":"acs.org","entries":[{"type":"search_result","url":"https://pubs.acs.org/doi/10.1021/acs.chemrev.4c00845?utm_source=chatgpt.com","title":"Resistive Switching Random-Access Memory (RRAM)","snippet":"by D Ielmini \u00b7 Cited by 21 \u2014 This work addresses the RRAM concept from materials, device, circuit, and application viewpoints, focusing on the physical device properties and the ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"acs.org"}]},{"type":"search_result_group","domain":"medium.com","entries":[{"type":"search_result","url":"https://medium.com/data-science/introducing-k-fac-and-its-application-for-large-scale-deep-learning-4e3f9b443414?utm_source=chatgpt.com","title":"Introducing K-FAC. A Second-Order Optimization Method ...","snippet":"Kronecker-factored Approximate Curvature (K-FAC) is a second-order optimization method for deep learning proposed by James Martens and Roger Grosse of the ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://medium.com/%40anshm18111996/comprehensive-overview-optimizers-in-machine-learning-and-ai-57a2b0fbcc79?utm_source=chatgpt.com","title":"Optimizers in Machine Learning and AI: A Comprehensive ...","snippet":"Optimizers adjust model parameters to minimize a loss function. They underpin the training of NN and classical models alike.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":20},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://medium.com/%40mosorr/ai-unleashed-inside-nvidias-game-changing-gtc-2025-breakthroughs-and-the-future-of-intelligent-ffad9714666e?utm_source=chatgpt.com","title":"AI Unleashed: Inside NVIDIA's Game-Changing GTC 2025 ...","snippet":"This report provides a detailed breakdown of everything announced \u2014 from advanced AI/ML tools and software platforms to the latest hardware ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":25},"pub_date":null,"attribution":"medium.com"}]},{"type":"search_result_group","domain":"avaq.com","entries":[{"type":"search_result","url":"https://www.avaq.com/technology/top-10-ai-chip-startups-to-watch-in-2025?srsltid=AfmBOoqxP5oN9F-0EBZbP-OqpHkV9f4uCCof_7cwAX6GIPzKl3Tc-fWV&utm_source=chatgpt.com","title":"Top 10 AI Chip Startups to Watch in 2025","snippet":"Sep 19, 2025 \u2014 Top 10 AI Chip Startups to Watch in 2025 \u00b7 1. Tenstorrent \u00b7 2. Mythic \u00b7 3. Groq \u00b7 4. Blumind \u00b7 5. Lightmatter \u00b7 6. Untether AI \u00b7 7. Enfabrica \u00b7 8.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"avaq.com"}]},{"type":"search_result_group","domain":"arxiv.org","entries":[{"type":"search_result","url":"https://arxiv.org/html/2509.22536v4?utm_source=chatgpt.com","title":"InfiR2: A Comprehensive FP8 Training Recipe for ...","snippet":"7 days ago \u2014 On the hardware side, NVIDIA's Blackwell architecture (NVIDIA, 2024) fundamentally ensures FP8 training stability with the MXFP8-E4M3 format ( ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2409.19315v2?utm_source=chatgpt.com","title":"Analog In-Memory Computing Attention Mechanism for ...","snippet":"Nov 25, 2024 \u2014 We present a custom self-attention in-memory computing architecture based on emerging charge-based memories called gain cells.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2409.19315v1?utm_source=chatgpt.com","title":"Analog In-Memory Computing Attention Mechanism for ...","snippet":"In this work, we propose a fast and energy-efficient hardware implementation of self-attention using analog in-memory computing based on gain cell memories.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2007.00784?utm_source=chatgpt.com","title":"Convolutional Neural Network Training with Distributed K- ...","snippet":"by JG Pauloski \u00b7 2020 \u00b7 Cited by 41 \u2014 We study optimization techniques such as layer-wise distribution strategies, inverse-free second-order gradient evaluation, and dynamic K-FAC ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2504.20096v1?utm_source=chatgpt.com","title":"Towards Practical Second-Order Optimizers in Deep ...","snippet":"Apr 26, 2025 \u2014 Second-order methods incorporate curvature information into the optimization process by leveraging the Hessian matrix or its approximations.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":26},"pub_date":null,"attribution":"arxiv.org"}]},{"type":"search_result_group","domain":"mit.edu","entries":[{"type":"search_result","url":"https://aihardware.mit.edu/wp-content/uploads/2024/05/5-Aya-Amer.pdf?utm_source=chatgpt.com","title":"Analog Compute-near-RRAM CNN Accelerator for ...","snippet":"May 1, 2024 \u2014 RRAM Cell output can be shared with many MAC cells. \u27a2 Reduce number of RRAM cells on chips. \u25ab RRAM Cell output independent of RRAM variations. \u27a2 ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"mit.edu"}]},{"type":"search_result_group","domain":"globaltimes.cn","entries":[{"type":"search_result","url":"https://www.globaltimes.cn/page/202510/1345626.shtml?utm_source=chatgpt.com","title":"Chinese researchers develop high-precision scalable ...","snippet":"Oct 14, 2025 \u2014 Chinese researchers develop high-precision scalable analog matrix computing chip based on resistive memory, realizing for the first time an ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"globaltimes.cn"}]},{"type":"search_result_group","domain":"openreview.net","entries":[{"type":"search_result","url":"https://openreview.net/forum?id=XfKSDgqIRj&noteId=eFPV0riaT1&utm_source=chatgpt.com","title":"COAT: Compressing Optimizer states and Activations for...","snippet":"Dec 15, 2024 \u2014 This paper introduces COAT, an FP8 training framework that improves memory efficiency and training speed for large-scale models while ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":40},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/pdf?id=HyMTkQZAb&utm_source=chatgpt.com","title":"KRONECKER-FACTORED CURVATURE APPROXIMA","snippet":"by J Martens \u00b7 2018 \u00b7 Cited by 120 \u2014 Kronecker-factor Approximate Curvature (Martens & Grosse, 2015) (K-FAC) is a 2nd-order optimization method which has been shown to give state-of-the-art.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"openreview.net"}]},{"type":"search_result_group","domain":"q4cdn.com","entries":[{"type":"search_result","url":"https://s201.q4cdn.com/141608511/files/doc_downloads/2025/03/GTC2025_Keynote.pdf?utm_source=chatgpt.com","title":"GTC 2025","snippet":"Rubin Ultra. 88 Custom Arm Cores. 176 Threads. 1.8 TB/s NVLink-C2C. 1.5 PBs NVLink7. 12X. 115.2 TB/s CX9. 8X. Page 36. NVIDIA Rubin System. Vera Rubin NVLink576.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"q4cdn.com"}]},{"type":"search_result_group","domain":"ibm.com","entries":[{"type":"search_result","url":"https://research.ibm.com/blog/analog-ai-chip-inference?utm_source=chatgpt.com","title":"An energy-efficient analog chip for AI inference","snippet":"Aug 10, 2023 \u2014 IBM Research's latest analog AI chip for deep learning inference. The energy-efficient chip showcases critical building blocks of a scalable mixed-signal ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"ibm.com"},{"type":"search_result","url":"https://research.ibm.com/blog/analog-ai-chip-low-power?utm_source=chatgpt.com","title":"New analog AI chip design uses much less power for AI tasks","snippet":"Aug 23, 2023 \u2014 IBM showed it's possible to build analog AI chips that can handle natural-language AI tasks with an estimated 14 times more energy efficiency.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"ibm.com"}]},{"type":"search_result_group","domain":"semianalysis.com","entries":[{"type":"search_result","url":"https://semianalysis.com/2025/05/23/amd-vs-nvidia-inference-benchmark-who-wins-performance-cost-per-million-tokens/?utm_source=chatgpt.com","title":"AMD vs NVIDIA Inference Benchmark: Who Wins? - SemiAnalysis","snippet":"The MI355X will start shipping in late 2025, two quarters after B200 shipments commence. Software for the B200 and GB200 is still not fully ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":7},"pub_date":1747958400.0,"attribution":"semianalysis.com"},{"type":"search_result","url":"https://newsletter.semianalysis.com/p/nvidia-gtc-2025-built-for-reasoning-vera-rubin-kyber-cpo-dynamo-inference-jensen-math-feynman?utm_source=chatgpt.com","title":"NVIDIA GTC 2025 - Built For Reasoning, Vera Rubin ...","snippet":"Mar 18, 2025 \u2014 The next leap in inference throughput from hardware will come with the scale-up network world size expanding to 576 GPU dies in Rubin Ultra \u2013 up ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"semianalysis.com"}]},{"type":"search_result_group","domain":"aimultiple.com","entries":[{"type":"search_result","url":"https://research.aimultiple.com/ai-chip-makers/?utm_source=chatgpt.com","title":"Top 20+ AI Chip Makers: NVIDIA & Its Competitors","snippet":"4 days ago \u2014 Based on our experience running in-depth benchmarks, we've identified the top AI hardware companies for data center workloads.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"aimultiple.com"}]},{"type":"search_result_group","domain":"researchgate.net","entries":[{"type":"search_result","url":"https://www.researchgate.net/publication/396448715_Precise_and_scalable_analogue_matrix_equation_solving_using_resistive_random-access_memory_chips?utm_source=chatgpt.com","title":"Precise and scalable analogue matrix equation solving ...","snippet":"Oct 13, 2025 \u2014 Our approach uses an iterative algorithm that combines analogue low-precision matrix inversion and analogue high-precision matrix\u2013vector ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/370996359_Smaller_Faster_Lower-Power_Analog_RRAM_Matrix_Computing_Circuits_Without_Performance_Compromise?utm_source=chatgpt.com","title":"(PDF) Smaller, Faster, Lower-Power Analog RRAM Matrix ...","snippet":"PDF | p>Recently, the analog matrix computing (AMC) concept has been proposed for fast, efficient matrix operations, by configuring global feedback.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":41},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/379882947_Variability-aware_Design_of_RRAM-based_Analog_CAMs?utm_source=chatgpt.com","title":"Variability-aware Design of RRAM-based Analog CAMs","snippet":"The results show that our designs have the capability to encode up to 4 bits of storage and achieve up to 24 intervals compared to 6 intervals for the published ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/386561346_Analog_In-Memory_Computing_Attention_Mechanism_for_Fast_and_Energy-Efficient_Large_Language_Models?utm_source=chatgpt.com","title":"Analog In-Memory Computing Attention Mechanism for ...","snippet":"Dec 9, 2024 \u2014 Our architecture respectively reduces attention latency and energy consumption by up to two and five orders of magnitude compared to GPUs, ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"researchgate.net"}]},{"type":"search_result_group","domain":"sciencedirect.com","entries":[{"type":"search_result","url":"https://www.sciencedirect.com/science/article/pii/S1359028624000536?utm_source=chatgpt.com","title":"Prospects and challenges of electrochemical random ...","snippet":"by J Cui \u00b7 2024 \u00b7 Cited by 8 \u2014 In this review, we first examine challenges in constructing in-memory-computing accelerators and unique advantages of ECRAMs.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"sciencedirect.com"},{"type":"search_result","url":"https://www.sciencedirect.com/science/article/abs/pii/S2666998625002558?utm_source=chatgpt.com","title":"Device and circuit perspectives for neuromorphic computing","snippet":"by RH Koo \u00b7 2025 \u2014 This review examines memory technologies, such as vertical NAND flash, and emerging options, including ferroelectric memory, resistive RAM, ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":22},"pub_date":null,"attribution":"sciencedirect.com"},{"type":"search_result","url":"https://www.sciencedirect.com/science/article/abs/pii/S089360802300504X?utm_source=chatgpt.com","title":"A scalable second order optimizer with an adaptive trust ...","snippet":"by D Yang \u00b7 2023 \u2014 Recent research has demonstrated that K-FAC exhibits accelerated convergence in training deep neural networks compared to Stochastic Gradient Descent (SGD).","ref_id":{"turn_index":1,"ref_type":"search","ref_index":23},"pub_date":null,"attribution":"sciencedirect.com"}]},{"type":"search_result_group","domain":"techovedas.com","entries":[{"type":"search_result","url":"https://techovedas.com/china-breaks-a-100-year-barrier-peking-university-unveils-worlds-most-precise-analog-computing-chip/?utm_source=chatgpt.com","title":"Peking University Unveils World's Most Precise Analog ...","snippet":"3 days ago \u2014 The team has developed a high-precision and scalable analog matrix computing chip built on Resistive Random-Access Memory (RRAM) technology.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"techovedas.com"}]},{"type":"search_result_group","domain":"acm.org","entries":[{"type":"search_result","url":"https://dl.acm.org/doi/pdf/10.1145/3394486.3403265?utm_source=chatgpt.com","title":"A Systematic Performance Analysis of Second-order ...","snippet":"by Y Ueno \u00b7 2020 \u00b7 Cited by 21 \u2014 The fact that we can reduce the training time of K-FAC to match that of SGD while also matching the Top-1 validation accuracy not only debunks.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"acm.org"}]},{"type":"search_result_group","domain":"nvidia.github.io","entries":[{"type":"search_result","url":"https://nvidia.github.io/TensorRT-LLM/0.19.0/release-notes.html?utm_source=chatgpt.com","title":"Release Notes \u2014 TensorRT-LLM","snippet":"Added support for FP8 MLA on NVIDIA Hopper and Blackwell GPUs. AutoDeploy ... NVIDIA Volta GPU support is deprecated and will be removed in a future release.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"nvidia.github.io"}]},{"type":"search_result_group","domain":"nature.com","entries":[{"type":"search_result","url":"https://www.nature.com/articles/s41928-023-01035-6?utm_source=chatgpt.com","title":"Analogue chips for energy-efficient AI","snippet":"by S Conti \u00b7 2023 \u2014 Overall, the chip has 35 million phase-change memory devices. The chip also contains digital-to-analogue input, analogue-to-digital output, ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"nature.com"},{"type":"search_result","url":"https://www.nature.com/articles/s41586-022-04992-8?utm_source=chatgpt.com","title":"A compute-in-memory chip based on resistive random- ...","snippet":"by W Wan \u00b7 2022 \u00b7 Cited by 826 \u2014 we present NeuRRAM\u2014a RRAM-based CIM chip that simultaneously delivers versatility in reconfiguring CIM cores for diverse model architectures ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":36},"pub_date":null,"attribution":"nature.com"}]},{"type":"search_result_group","domain":"science.org","entries":[{"type":"search_result","url":"https://www.science.org/doi/10.1126/sciadv.ady4798?utm_source=chatgpt.com","title":"Ultrahigh-precision analog computing using memory- ...","snippet":"Sep 12, 2025 \u2014 However, low precision remains a major challenge in realizing practical analog computing systems. Traditional analog systems rely on the ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"science.org"}]},{"type":"search_result_group","domain":"intuitionlabs.ai","entries":[{"type":"search_result","url":"https://intuitionlabs.ai/articles/blackwell-vs-hopper-gpu-architecture-comparison?utm_source=chatgpt.com","title":"Blackwell vs Hopper: A Deep Dive GPU Architecture Comparison","snippet":"Compared side-by-side, Blackwell offers dramatically higher AI throughput and memory capacity (e.g. ~9 petaFLOPS in FP8 vs ~4 petaFLOPS for ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":12},"pub_date":1761043129.0,"attribution":"intuitionlabs.ai"}]},{"type":"search_result_group","domain":"ventureradar.com","entries":[{"type":"search_result","url":"https://www.ventureradar.com/startup/analog%20ai?utm_source=chatgpt.com","title":"Top analog ai start-ups","snippet":"Top start-ups for analog ai at VentureRadar with Innovation Scores, Core Health Signals and more. Including Blumind Inc., Q.ant, EnCharge AI etc.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"ventureradar.com"}]},{"type":"search_result_group","domain":"github.com","entries":[{"type":"search_result","url":"https://github.com/NVIDIA/TransformerEngine?utm_source=chatgpt.com","title":"NVIDIA/TransformerEngine","snippet":"What's New in Transformer Engine and FP8 Training | GTC 2024 \u00b7 FP8 Training with Transformer Engine | GTC 2023 \u00b7 FP8 for Deep Learning | GTC 2023 \u00b7 Inside the ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/NVIDIA/TensorRT-LLM?utm_source=chatgpt.com","title":"NVIDIA/TensorRT-LLM - GitHub","snippet":"TensorRT-LLM is an open-sourced library for optimizing Large Language Model (LLM) inference. It provides state-of-the-art optimizations.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/NVIDIA/TensorRT-LLM/releases?utm_source=chatgpt.com","title":"Releases \u00b7 NVIDIA/TensorRT-LLM - GitHub","snippet":"TensorRT-LLM provides users with an easy-to-use Python API to define Large Language Models (LLMs) and support state-of-the-art optimizations to perform ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"github.com"}]},{"type":"search_result_group","domain":"gregpauloski.com","entries":[{"type":"search_result","url":"https://gregpauloski.com/publications/pauloski2022kfac-preprint.pdf?utm_source=chatgpt.com","title":"Deep Neural Network Training with Distributed K-FAC","snippet":"by JG Pauloski \u00b7 Cited by 6 \u2014 In this paper, we investigate methods for designing K-. FAC-based optimizers that reduce iterations-to-convergence and exhibit efficient scaling. We investigate ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"gregpauloski.com"}]},{"type":"search_result_group","domain":"registrationchina.com","entries":[{"type":"search_result","url":"https://www.registrationchina.com/articles/new-chinese-chip/?utm_source=chatgpt.com","title":"The Creation of the New Chinese Chip: The Era ...","snippet":"7 days ago \u2014 The Peking University study shows that the new Chinese chip can deliver hundreds to thousands of times higher throughput compared to leading ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"registrationchina.com"}]},{"type":"search_result_group","domain":"yolegroup.com","entries":[{"type":"search_result","url":"https://www.yolegroup.com/industry-news/these-are-the-10-hottest-ai-hardware-companies-to-follow-in-2025/?utm_source=chatgpt.com","title":"These are the 10 hottest AI hardware companies to follow ...","snippet":"Jan 7, 2025 \u2014 These are the 10 hottest AI hardware companies to follow in 2025 \u00b7 Tenstorrent \u00b7 Mythic \u00b7 Groq \u00b7 Blumind \u00b7 Lightmatter \u00b7 Untether AI \u00b7 Enfabrica.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"yolegroup.com"}]},{"type":"search_result_group","domain":"huggingface.co","entries":[{"type":"search_result","url":"https://huggingface.co/papers/2310.18313?utm_source=chatgpt.com","title":"Paper page - FP8-LM: Training FP8 Large Language Models","snippet":"Oct 30, 2023 \u2014 The paper introduces a new FP8 framework for training LLMs, reducing memory usage by 42% and increasing speed by 64% compared to BF16.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"huggingface.co"}]},{"type":"search_result_group","domain":"bizon-tech.com","entries":[{"type":"search_result","url":"https://bizon-tech.com/blog/gtc-2025-highlights?srsltid=AfmBOoqFIaCe30QTnvwQi3t9SI8FMw-qSdFTXojwO1CZ6aqFEF7RxOSO&utm_source=chatgpt.com","title":"Nvidia GTC 2025 Highlights - Bizon-tech","snippet":"Mar 28, 2025 \u2014 Higher Tensor Core throughput and precision scaling. Enhanced multi-instance GPU features to isolate concurrent workloads.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"bizon-tech.com"}]},{"type":"search_result_group","domain":"rsc.org","entries":[{"type":"search_result","url":"https://pubs.rsc.org/en/content/articlehtml/2024/na/d4na00158c?utm_source=chatgpt.com","title":"An overview of critical applications of resistive random access ...","snippet":"by F Zahoor \u00b7 2024 \u00b7 Cited by 22 \u2014 This discussion explores the physical mechanisms, device structure, performance characteristics, and applications of RRAM devices.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":19},"pub_date":null,"attribution":"rsc.org"}]},{"type":"search_result_group","domain":"trendforce.com","entries":[{"type":"search_result","url":"https://www.trendforce.com/news/2025/10/21/news-chinese-scientists-developed-a-novel-chip-crossing-a-century-old-hurdle/?utm_source=chatgpt.com","title":"[News] Chinese Scientists Developed a Novel Chip ...","snippet":"4 days ago \u2014 The team successfully developed a high-precision and scalable analog matrix computing chip based on resistive random-access memory (RRAM). For ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":20},"pub_date":null,"attribution":"trendforce.com"}]},{"type":"search_result_group","domain":"eenewseurope.com","entries":[{"type":"search_result","url":"https://www.eenewseurope.com/en/ibm-analog-ai-chip-uses-phase-change-memory/?utm_source=chatgpt.com","title":"IBM analog AI chip uses phase-change memory .. ...","snippet":"Aug 14, 2023 \u2014 IBM Research has developed a multicore compute in memory analog chip for machine learning using phase-change memory (PCM) to reduce the power consumption.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":21},"pub_date":null,"attribution":"eenewseurope.com"}]},{"type":"search_result_group","domain":"nih.gov","entries":[{"type":"search_result","url":"https://pmc.ncbi.nlm.nih.gov/articles/PMC11817932/?utm_source=chatgpt.com","title":"Fully analog iteration for solving matrix equations with in- ...","snippet":"by J Li \u00b7 2025 \u00b7 Cited by 7 \u2014 However, the inherent inaccuracies of analog mechanisms create challenges in achieving high-precision solutions while maintaining low-energy ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":21},"pub_date":null,"attribution":"nih.gov"},{"type":"search_result","url":"https://pmc.ncbi.nlm.nih.gov/articles/PMC12083524/?utm_source=chatgpt.com","title":"Engineered high endurance in WO3-based resistive ...","snippet":"by Z Yuan \u00b7 2025 \u00b7 Cited by 2 \u2014 The variability not only affects the performance and endurance of individual devices but also poses challenges for large-scale integration ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":25},"pub_date":null,"attribution":"nih.gov"}]},{"type":"search_result_group","domain":"datacenterfrontier.com","entries":[{"type":"search_result","url":"https://www.datacenterfrontier.com/machine-learning/article/55279633/nvidia-gtc-2025-unveils-revolutionary-chips-systems-and-optical-networking-for-hyperscale-ai-data-centers?utm_source=chatgpt.com","title":"NVIDIA GTC 2025 Unveils Revolutionary Chips, Systems ...","snippet":"Apr 8, 2025 \u2014 NVIDIA's GTC 2025 spotlighted a sweeping upgrade to its AI infrastructure stack, unveiling new CPU and GPU architectures built for extreme ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":21},"pub_date":null,"attribution":"datacenterfrontier.com"}]},{"type":"search_result_group","domain":"nextbigfuture.com","entries":[{"type":"search_result","url":"https://www.nextbigfuture.com/2025/09/analog-in-memory-computing-attention-mechanism-for-fast-and-energy-efficient-large-language-models.html?utm_source=chatgpt.com","title":"Analog in-memory Computing Attention Mechanism for ...","snippet":"Sep 29, 2025 \u2014 Their chips integrate memory and computation to cut energy/latency costs, outperforming GPUs in edge AI scenarios. A January 2025 IBM Research ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":22},"pub_date":null,"attribution":"nextbigfuture.com"},{"type":"search_result","url":"https://www.nextbigfuture.com/2023/09/ibm-researchs-new-prototype-ai-chip-with-14-times-energy-efficiency.html?utm_source=chatgpt.com","title":"IBM Research's New Prototype AI Chip With 14 Times ...","snippet":"Sep 25, 2023 \u2014 IBM showed it's possible to build analog AI chips that can handle natural-language AI tasks with an estimated 14 times more energy ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":43},"pub_date":null,"attribution":"nextbigfuture.com"}]},{"type":"search_result_group","domain":"reddit.com","entries":[{"type":"search_result","url":"https://www.reddit.com/r/NVDA_Stock/comments/1g6yj8s/nvidia_to_ship_150k200k_blackwell_gb200_ai/?utm_source=chatgpt.com","title":"NVIDIA To Ship 150K-200K Blackwell GB200 AI Servers In Q4 2024 ...","snippet":"NVIDIA To Ship 150K-200K Blackwell GB200 AI Servers In Q4 2024 Alone & 500-550K Units In Q1 2025. News. NVIDIA To Ship 150K-200K Blackwell GB200 ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":22},"pub_date":1729296000.0,"attribution":"reddit.com"}]},{"type":"search_result_group","domain":"ts2.tech","entries":[{"type":"search_result","url":"https://ts2.tech/en/nvidia-blackwell-b200-vs-amd-mi350-vs-google-tpu-v6e-2025s-ultimate-ai-accelerator-showdown/?utm_source=chatgpt.com","title":"NVIDIA Blackwell B200 vs AMD MI350 vs Google TPU v6e","snippet":"AMD touts 35\u00d7 inference gain over MI300 and says MI355X beats B200 by 20\u201330% in some LLM inference tasks smbom.com. Google's TPU v6e, with INT8 ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":23},"pub_date":1754373723.0,"attribution":"ts2.tech"}]},{"type":"search_result_group","domain":"tmtpost.com","entries":[{"type":"search_result","url":"https://en.tmtpost.com/news/7721720?utm_source=chatgpt.com","title":"Chinese Researchers Achieve High-Precision, Scalable ...","snippet":"Chinese scientists have developed a high-precision, scalable analog matrix computing chip based on resistive memory, creating for the first time an analog ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":24},"pub_date":null,"attribution":"tmtpost.com"}]},{"type":"search_result_group","domain":"ieee.org","entries":[{"type":"search_result","url":"https://spectrum.ieee.org/analog-ai-ibm?utm_source=chatgpt.com","title":"IBM'S AI Chip May Find Use in Generative AI","snippet":"Aug 25, 2023 \u2014 Previous simulations from IBM suggested that analog AI could prove 40 to 140 times as energy efficient as the best GPUs for AI applications.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":25},"pub_date":null,"attribution":"ieee.org"}]},{"type":"search_result_group","domain":"omnius.so","entries":[{"type":"search_result","url":"https://www.omnius.so/blog/leading-us-ai-startups?utm_source=chatgpt.com","title":"Top AI Startups in the US to Watch in 2025 [Extended List]","snippet":"Oct 13, 2025 \u2014 EnCharge AI builds analog in-memory computing chips for edge AI, integrating computation and memory on a single chip for high performance and ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":26},"pub_date":null,"attribution":"omnius.so"}]},{"type":"search_result_group","domain":"crn.com","entries":[{"type":"search_result","url":"https://www.crn.com/news/ai/2025/10-big-nvidia-gtc-2025-announcements-blackwell-ultra-rubin-ultra-dgx-spark-and-more?utm_source=chatgpt.com","title":"10 Big Nvidia GTC 2025 Announcements: Blackwell Ultra, Rubin ...","snippet":"... GB200 NVL72 that started shipping a few months ago. ... Dynamo support the PyTorch, SGLand, Nvidia TensorRT-LLM and vLLM software libraries.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":26},"pub_date":1742515200.0,"attribution":"crn.com"}]},{"type":"search_result_group","domain":"iclr.cc","entries":[{"type":"search_result","url":"https://proceedings.iclr.cc/paper_files/paper/2025/file/6ac807c9b296964409b277369e55621a-Paper-Conference.pdf?utm_source=chatgpt.com","title":"COAT: COMPRESSING OPTIMIZER STATES AND ...","snippet":"by H Xi \u00b7 Cited by 12 \u2014 Compared to BF16, FP8 training has the potential to (1) double the speed and (2) halve the memory footprint. To achieve practical speedup,. Transformer Engine ( ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":27},"pub_date":null,"attribution":"iclr.cc"}]},{"type":"search_result_group","domain":"mdpi.com","entries":[{"type":"search_result","url":"https://www.mdpi.com/2079-9292/14/16/3159?utm_source=chatgpt.com","title":"A Survey of Analog Computing for Domain-Specific ...","snippet":"by L Belostotski \u00b7 2025 \u2014 While analog Ising machines benefit from low-power, real-time processing, they also face challenges in precision, noise robustness, and interconnection scaling.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":27},"pub_date":null,"attribution":"mdpi.com"}]},{"type":"search_result_group","domain":"storagereview.com","entries":[{"type":"search_result","url":"https://www.storagereview.com/news/nvidias-gtc-2025-highlights-blackwell-gpus-dgx-systems-and-ai-q-framework?utm_source=chatgpt.com","title":"NVIDIA's GTC 2025 Highlights: Blackwell GPUs, DGX ...","snippet":"Mar 18, 2025 \u2014 FP8 Tensor Core, 3958 TFLOPS (~4 PFLOPS), 3958 TFLOPS (~4 PFLOPS), 7 ... Rubin Ultra GPUs aim to double Vera Rubin's performance, delivering an ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":27},"pub_date":null,"attribution":"storagereview.com"}]},{"type":"search_result_group","domain":"x.com","entries":[{"type":"search_result","url":"https://x.com/ExtremaRatio4/status/1978204646297805196?utm_source=chatgpt.com","title":"Extrema Ratio","snippet":"Their new analog matrix solver, based on 40 nm RRAM ... Peking University, and published in the international academic journal Nature Electronics.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":28},"pub_date":null,"attribution":"x.com"}]},{"type":"search_result_group","domain":"springer.com","entries":[{"type":"search_result","url":"https://link.springer.com/article/10.1007/s11432-023-3990-4?utm_source=chatgpt.com","title":"Smaller, faster, lower-power analog RRAM matrix ...","snippet":"by Y Luo \u00b7 2025 \u00b7 Cited by 5 \u2014 Smaller, faster, lower-power analog RRAM matrix computing circuits without performance compromise. Research Paper; Published: 14 January 2025.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":28},"pub_date":null,"attribution":"springer.com"}]},{"type":"search_result_group","domain":"youtube.com","entries":[{"type":"search_result","url":"https://www.youtube.com/watch?v=KVAmUlbLDIA&utm_source=chatgpt.com","title":"Beijing Researchers Develop AI Chip Outperforming ...","snippet":"According to The China Briefing, scientists at Peking University have developed a groundbreaking analog AI chip that could be up to 1,000 ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":29},"pub_date":null,"attribution":"youtube.com"},{"type":"search_result","url":"https://www.youtube.com/watch?v=JGJfafxjKTo&utm_source=chatgpt.com","title":"Peking University team successfully developed a high ...","snippet":"Peking University team successfully developed a high-performance analog matrix computing chip. 1K views \u00b7 6 days ago #chinesenews ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":37},"pub_date":null,"attribution":"youtube.com"}]},{"type":"search_result_group","domain":"thecvf.com","entries":[{"type":"search_result","url":"https://openaccess.thecvf.com/content_CVPR_2019/papers/Osawa_Large-Scale_Distributed_Second-Order_Optimization_Using_Kronecker-Factored_Approximate_Curvature_for_Deep_CVPR_2019_paper.pdf?utm_source=chatgpt.com","title":"Large-Scale Distributed Second-Order Optimization Using ...","snippet":"by K Osawa \u00b7 2019 \u00b7 Cited by 123 \u2014 In doing so, we are able to reduce the over- head of K-FAC. We were able to train ResNet-50 on ImageNet in 10 minutes to a top-1 accuracy of 74.9% using 1,024 ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":29},"pub_date":null,"attribution":"thecvf.com"}]},{"type":"search_result_group","domain":"runpod.io","entries":[{"type":"search_result","url":"https://www.runpod.io/articles/guides/nvidia-dgx-b200?utm_source=chatgpt.com","title":"Everything You Need to Know About the Nvidia DGX B200 GPU","snippet":"In Blackwell's case, the FP4 capability can effectively double the inference throughput compared to FP8. Nvidia quotes up to 144 PFLOPS of FP4 ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":29},"pub_date":1746662400.0,"attribution":"runpod.io"}]},{"type":"search_result_group","domain":"repec.org","entries":[{"type":"search_result","url":"https://ideas.repec.org/a/nat/nature/v620y2023i7975d10.1038_s41586-023-06337-5.html?utm_source=chatgpt.com","title":"An analog-AI chip for energy-efficient speech recognition an","snippet":"by S Ambrogio \u00b7 2023 \u00b7 Cited by 207 \u2014 Here we present an analog-AI chip that combines 35 million phase-change memory devices across 34 tiles, massively parallel inter-tile communication and analog, .....","ref_id":{"turn_index":0,"ref_type":"search","ref_index":30},"pub_date":null,"attribution":"repec.org"}]},{"type":"search_result_group","domain":"oracle.com","entries":[{"type":"search_result","url":"https://www.oracle.com/news/announcement/oracle-and-nvidia-to-deliver-sovereign-ai-worldwide-2024-03-18/?utm_source=chatgpt.com","title":"Oracle and NVIDIA to Deliver Sovereign AI Worldwide","snippet":"GB200 delivers up to 30X faster real-time large language model (LLM) inference, 25X lower TCO, and requires 25X less energy compared to the ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":30},"pub_date":1710720000.0,"attribution":"oracle.com"}]},{"type":"search_result_group","domain":"tdk.com","entries":[{"type":"search_result","url":"https://www.tdk.com/en/featured_stories/entry_083-analog-reservoir-computing-AI-chip.html?utm_source=chatgpt.com","title":"Staying Ahead of Human Motion: Analog Reservoir AI Chip ...","snippet":"Oct 7, 2025 \u2014 Jointly with Hokkaido University, TDK has developed a prototype analog reservoir AI chip designed for edge applications. At CEATEC 2025, to be ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":31},"pub_date":null,"attribution":"tdk.com"}]},{"type":"search_result_group","domain":"exxactcorp.com","entries":[{"type":"search_result","url":"https://www.exxactcorp.com/blog/news/nvidia-gtc-2025-keynote-recap?utm_source=chatgpt.com","title":"NVIDIA GTC 2025 Keynote Recap | Exxact Blgo","snippet":"Mar 19, 2025 \u2014 Rubin Ultra NVL576 will be a revolutionary AI factory. Rubin Ultra is expected to deliver 14x the performance of Blackwell Ultra, adopting the ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":31},"pub_date":null,"attribution":"exxactcorp.com"}]},{"type":"search_result_group","domain":"springernature.com","entries":[{"type":"search_result","url":"https://communities.springernature.com/posts/analogue-in-memory-computing-coming-of-age?utm_source=chatgpt.com","title":"Analogue in-memory computing coming of age","snippet":"Aug 10, 2023 \u2014 IBM introduces the IBM HERMES project chip: a fully integrated in-memory compute chip comprising 64 analogue in-memory computing cores.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":33},"pub_date":null,"attribution":"springernature.com"}]},{"type":"search_result_group","domain":"chroniclejournal.com","entries":[{"type":"search_result","url":"https://markets.chroniclejournal.com/chroniclejournal/article/tokenring-2025-10-15-beyond-the-gpu-specialized-ai-chips-ignite-a-new-era-of-innovation?utm_source=chatgpt.com","title":"Beyond the GPU: Specialized AI Chips Ignite a New Era of ...","snippet":"Oct 15, 2025 \u2014 The global AI chip market, valued at $44.9 billion in 2024, is projected to reach $460.9 billion by 2034, growing at a CAGR of 27.6% from 2025 ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":34},"pub_date":null,"attribution":"chroniclejournal.com"}]},{"type":"search_result_group","domain":"continuumlabs.ai","entries":[{"type":"search_result","url":"https://training.continuumlabs.ai/training/the-fine-tuning-process/hyperparameters/fp8-formats-for-deep-learning?utm_source=chatgpt.com","title":"FP8 Formats for Deep Learning","snippet":"Jun 1, 2024 \u2014 The paper presents a comprehensive study of the proposed FP8 format for deep learning training and inference. The authors demonstrate that FP8 ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":35},"pub_date":null,"attribution":"continuumlabs.ai"}]},{"type":"search_result_group","domain":"arstechnica.com","entries":[{"type":"search_result","url":"https://arstechnica.com/science/2023/08/ibm-team-builds-low-power-analog-ai-processor/?utm_source=chatgpt.com","title":"IBM team builds low-power analog AI processor","snippet":"Aug 23, 2023 \u2014 Phase-change memory has been under development for a while. It offers the persistence of flash memory but with performance that's much closer to ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":38},"pub_date":null,"attribution":"arstechnica.com"}]},{"type":"search_result_group","domain":"fanaticalfuturist.com","entries":[{"type":"search_result","url":"https://www.fanaticalfuturist.com/2025/03/low-energy-analogue-ai-chips-gets-a-100-million-boost-from-darpa/?utm_source=chatgpt.com","title":"Low energy Analogue AI chips gets a $100 Million boost from ...","snippet":"Mar 31, 2025 \u2014 A young DARPA-backed startup with a fresh spin on a low-power computer chip has raised over $100 million in a Series B funding round.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":39},"pub_date":null,"attribution":"fanaticalfuturist.com"}]},{"type":"search_result_group","domain":"facebook.com","entries":[{"type":"search_result","url":"https://www.facebook.com/scmp/posts/discover-how-this-new-chip-technology-breakthrough-could-reshape-the-future-of-s/1034415565401162/?utm_source=chatgpt.com","title":"Discover how this new chip technology breakthrough could ...","snippet":"Mar 18, 2025 \u2014 Discover how this new chip technology breakthrough could reshape the future of science and innovation.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":42},"pub_date":null,"attribution":"facebook.com"}]},{"type":"search_result_group","domain":"semiengineering.com","entries":[{"type":"search_result","url":"https://semiengineering.com/startup-funding-q3-2025/?utm_source=chatgpt.com","title":"Chip Industry Startup Funding: Q3 2025","snippet":"Oct 6, 2025 \u2014 The third quarter of 2025 was dominated by massive rounds for companies developing AI chips and quantum computers. Over $2.5 billion went to ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":44},"pub_date":null,"attribution":"semiengineering.com"}]}],"citations":[],"request_id":"e52f9de3-65ab-4b89-a495-bb780783360e","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","thinking_effort":"max","parent_id":"8fe02c84-0186-4583-a1d1-a05c29af1a72","turn_exchange_id":"dae60d5f-94c0-4ed0-95ae-1ca695fce69d","timestamp_":"absolute","can_save":true},"recipient":"all","channel":"final"},"parent":"8fe02c84-0186-4583-a1d1-a05c29af1a72","children":[]}}}