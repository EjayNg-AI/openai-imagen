{"id":"68fbb8fb-588c-8322-ba98-6722eebad23b","title":"General intelligence frameworks","create_time":1761327356.402874,"update_time":1761327768.464574,"current_node":"b1faa487-92a8-4a83-9e0f-f13b684f613a","mapping":{"client-created-root":{"id":"client-created-root","message":null,"parent":null,"children":["97509a0b-b025-4dd9-b144-32264989b322"]},"97509a0b-b025-4dd9-b144-32264989b322":{"id":"97509a0b-b025-4dd9-b144-32264989b322","message":{"id":"97509a0b-b025-4dd9-b144-32264989b322","author":{"role":"system","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":true,"weight":0.0,"metadata":{"is_visually_hidden_from_conversation":true,"can_save":false},"recipient":"all","channel":null},"parent":"client-created-root","children":["cb13e0d6-8b1d-4f9c-ad62-eb3655eba7ac"]},"cb13e0d6-8b1d-4f9c-ad62-eb3655eba7ac":{"id":"cb13e0d6-8b1d-4f9c-ad62-eb3655eba7ac","message":{"id":"cb13e0d6-8b1d-4f9c-ad62-eb3655eba7ac","author":{"role":"system","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":true,"weight":0.0,"metadata":{"rebase_developer_message":true,"is_visually_hidden_from_conversation":true,"can_save":false},"recipient":"all","channel":null},"parent":"97509a0b-b025-4dd9-b144-32264989b322","children":["0054c507-b320-443b-aded-7385ffa3c267"]},"0054c507-b320-443b-aded-7385ffa3c267":{"id":"0054c507-b320-443b-aded-7385ffa3c267","message":{"id":"0054c507-b320-443b-aded-7385ffa3c267","author":{"role":"user","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"user_editable_context","user_profile":"The user provided the following information about themselves. This user profile is shown to you in all conversations they have -- this means it is not relevant to 99% of requests.\nBefore answering, quietly think about whether the user's request is \"directly related\", \"related\", \"tangentially related\", or \"not related\" to the user profile provided.\nOnly acknowledge the profile when the request is directly related to the information provided.\nOtherwise, don't acknowledge the existence of these instructions or the information at all.\nUser profile:\n```Preferred name: E-Jay\nRole: Mathematics Researcher\nOther Information: About Myself: \nI have mathematical knowledge up to graduate level.\n\nCurrent interests:\n(1) coding: mainly Python\n(2) machine learning and artificial intelligence\n```","user_instructions":"The user provided the additional info about how they would like you to respond:\n```Be precise and comprehensive in your analysis. Don't sugar-coat responses. Be as objective as possible. Critique and question my views if necessary. Take a forward-thinking view.```"},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"is_visually_hidden_from_conversation":true,"user_context_message_data":{"about_user_message":"Preferred name: E-Jay\nRole: Mathematics Researcher\nOther Information: About Myself: \nI have mathematical knowledge up to graduate level.\n\nCurrent interests:\n(1) coding: mainly Python\n(2) machine learning and artificial intelligence\n","about_model_message":"Be precise and comprehensive in your analysis. Don't sugar-coat responses. Be as objective as possible. Critique and question my views if necessary. Take a forward-thinking view."},"is_user_system_message":true,"can_save":true},"recipient":"all","channel":null},"parent":"cb13e0d6-8b1d-4f9c-ad62-eb3655eba7ac","children":["e6ef7b30-90d0-4da4-932d-e5b514296d2d"]},"e6ef7b30-90d0-4da4-932d-e5b514296d2d":{"id":"e6ef7b30-90d0-4da4-932d-e5b514296d2d","message":{"id":"e6ef7b30-90d0-4da4-932d-e5b514296d2d","author":{"role":"user","name":null,"metadata":{}},"create_time":1761327354.365,"update_time":null,"content":{"content_type":"text","parts":["Current LLMs use language synthesis as the foundation on which all token prediction, reasoning, and agentic behavior is developed. But language synthesis is but one framework for developing global, general intelligence. I want you to explore what other methods to general intelligence can there can, beyond the bedrock of language synthesis, and if a new paradigm might be needed for us to develop true, general intelligence that has the capacity to expand to include all human domains of understanding and cognition."]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"developer_mode_connector_ids":[],"selected_sources":[],"selected_github_repos":[],"serialization_metadata":{"custom_symbol_offsets":[]},"request_id":"24940b34-6c48-4a35-b691-56b19a558b4b","message_source":null,"turn_exchange_id":"85f2c976-89c7-4488-a243-12c129cba59f","timestamp_":"absolute","can_save":true},"recipient":"all","channel":null},"parent":"0054c507-b320-443b-aded-7385ffa3c267","children":["b9b74983-cc20-4a40-b1bb-093fd4158822"]},"b9b74983-cc20-4a40-b1bb-093fd4158822":{"id":"b9b74983-cc20-4a40-b1bb-093fd4158822","message":{"id":"b9b74983-cc20-4a40-b1bb-093fd4158822","author":{"role":"tool","name":"a8km123","metadata":{}},"create_time":1761327357.027541,"update_time":null,"content":{"content_type":"text","parts":["\n\n**Evaluating conceptual frameworks**\n\nI\u2019m dissecting how to respond to a research essay on alternative AGI foundations, analyzing recent developments and conceptual frameworks.\n\n**Evaluating alternative paradigms**\n\nI'm mapping out various frameworks and benchmarks for non-linguistic AGI foundations, including world models, evolutionary computation, memory retrieval systems, and advanced cognitive architectures.\n\n**Narrowing the focus**\n\nI\u2019m honing in on five key sources: MuZero for model-based planning, DreamerV3 for world modeling, JEPA for predictive architecture, Causal representation learning for causality, and ARC for intelligence measures.\n\n**Weighing options**  \nConsidering the inclusion of \"RT-2\" and its relevance to vision-language-action models. Searching for further insights.\n\n**Assessing news stability**\n\nI\u2019m thinking about using news to highlight robotics, but need to ensure stability. Hm, considering The Verge or Reuters could work well. Also, I\u2019ll weave in \"Active Inference\" from Friston, 2010 or 2019.\n\n**Identifying potential options**\n\nI'm thinking about incorporating various machine learning and reinforcement learning concepts, like energy-based models, TD-MPC2, active learning, and self-organization, into our discussions.\n\n**Mapping intelligence dimensions**\n\nI\u2019m identifying general intelligence axes like representation, learning, embodiment, memory, reasoning, agency, sociality, and grounding, while suggesting a dual-fuel architecture for language synthesis.\n\n**Mapping out benchmarks**\n\nI\u2019m focusing on practical tasks and multi-agent environments. Setting near-term goals to integrate tasks, benchmark evaluation metrics, and assess progress. This approach ensures alignment with research objectives.\n\n**Highlighting up-to-date sources**\n\nI'm gathering relevant news sources on DeepMind robotics, ensuring they align with recent developments and are concise. This makes the essay more informative and current."]},"status":"finished_successfully","end_turn":null,"weight":0.0,"metadata":{"finished_text":"Reasoned for 6m 46s","initial_text":"Reasoning","summarization_headline":"Request for GPT-5 Pro","async_source":"bon-user-BCJOyZGunEUKDxRwBvjpnlad-24940b34-6c48-4a35-b691-56b19a558b4b","parent_id":"e6ef7b30-90d0-4da4-932d-e5b514296d2d","poll_on_websocket_inactivity_ms":30000,"poll_freshness_max_mins":30,"poll_interval_ms":10000,"request_id":"24940b34-6c48-4a35-b691-56b19a558b4b","message_type":"next","model_slug":"gpt-5-pro","default_model_slug":"gpt-5-pro","turn_exchange_id":"85f2c976-89c7-4488-a243-12c129cba59f","timestamp_":"absolute","finished_duration_sec":406,"pro_skipped":false,"can_save":true},"recipient":"all","channel":null},"parent":"e6ef7b30-90d0-4da4-932d-e5b514296d2d","children":["b1faa487-92a8-4a83-9e0f-f13b684f613a"]},"b1faa487-92a8-4a83-9e0f-f13b684f613a":{"id":"b1faa487-92a8-4a83-9e0f-f13b684f613a","message":{"id":"b1faa487-92a8-4a83-9e0f-f13b684f613a","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1761327763.767075,"update_time":1761327576.917131,"content":{"content_type":"text","parts":["Below is a concrete map of **non\u2011linguistic** foundations for general intelligence, why today\u2019s language\u2011first approach will likely stall on some axes, and what a post\u2011language architecture could look like. I\u2019ll critique the \u201clanguage synthesis as bedrock\u201d premise where warranted, then propose a research program with falsifiable milestones.\n\n---\n\n## 0) What \u201clanguage\u2011as\u2011bedrock\u201d gives us\u2014and where it stalls\n\n**Strengths.** Large language models (LLMs) compress an enormous amount of *cultural* regularities into a single, trainable prior. This gives:\n- Broad knowledge and analogical reach across domains.\n- Cheap compositional interfaces (tokens) that make tool use, program synthesis and coordination natural.\n- Impressive \u201cin\u2011context learning\u201d that approximates few\u2011shot Bayesian updating.\n\n**Critical gaps.**\n1. **Grounding and causality.** Tokens correlate with the world but do not *bind* to entities, dynamics, or interventions. This makes out\u2011of\u2011distribution (OOD) generalization and causal reasoning brittle.  \n2. **Long\u2011horizon credit assignment.** Pure next\u2011token training provides weak signals for closed\u2011loop control, multi\u2011step planning, and non\u2011linguistic skill acquisition.  \n3. **Physical and temporal coherence.** LLMs lack an internal physics engine; \u201creasoning\u201d is often retrospective explanation, not predictive control.  \n4. **Semantics vs. syntax.** Without external semantics (sensors, actuators, experiments), token coherence can diverge from truth (hallucinations).  \n5. **Sample efficiency for action.** Transferring a language prior into robust control is nontrivial; direct sensorimotor learning is often more efficient.\n\n**Bottom line:** language is a powerful **interface and cultural prior**, but a weak **substrate** for mastery of perception, action, and causal abstraction. We need other foundations.\n\n---\n\n## 1) Alternative bedrocks for general intelligence\n\n### A. **World models** (simulation\u2011based inference and planning)\nTrain a model to predict **how the world evolves** under actions, then plan in imagination. This is an old idea in control, but modern generative video/3D models and latent dynamics make it practical.\n\n- **Latent model\u2011based RL**: DreamerV3 learns compact latent dynamics and plans by \u201cimagining\u201d trajectories, mastering >150 tasks with a single configuration\u2014evidence that **simulation in latent space** is a scalable substrate for skill acquisition. \ue200cite\ue202turn0search6\ue201  \n- **Actionable world simulators**: DeepMind\u2019s **Genie** line turns images or prompts into **playable environments**\u2014not just video, but **controllable** dynamics for agents and humans. This is a substrate for open\u2011ended skill learning without labeled data. \ue200cite\ue202turn0search0\ue201  \n- **High\u2011fidelity physical priors**: OpenAI\u2019s **Sora** program frames video generators explicitly as **world simulators**, pushing consistency, duration, and controllability\u2014raw material for training models that reason about physics and affordances. \ue200cite\ue202turn0search1\ue202turn0search8\ue201\n\n> **Why this matters:** A *predictive simulator + planner* supplies grounding, counterfactual reasoning (\u201cwhat if I do X?\u201d), and long\u2011horizon credit assignment\u2014gaps that language\u2011only training cannot close.\n\n---\n\n### B. **Sensorimotor grounding and VLA (Vision\u2011Language\u2011Action)**\nFuse vision (or multisensory perception), language, and **actions** in one policy. Language becomes an auxiliary *instruction* channel, not the representational core.\n\n- **RT\u20112** showed that web\u2011scale vision\u2011language knowledge can be distilled into **robotic action policies**, enabling zero\u2011shot generalization to new tasks described in words. This is grounded competence, not token prediction. \ue200cite\ue202turn0search2\ue202turn0search9\ue201\n\n> **Why this matters:** Policies that *act* must encode affordances, 3D geometry, and temporal constraints. They learn invariants that purely linguistic models don\u2019t need to learn.\n\n---\n\n### C. **Causal representation learning (CRL)**\nReplace correlational features with **variables and mechanisms** that support intervention and OOD transfer.\n\n- The CRL program (Sch\u00f6lkopf et\u202fal.) argues that discovering **latent causal variables** is essential to robust generalization; recent work explores identifiability under multiple environments and interventions. Empirically, CRL is still hard\u2014but it\u2019s the right set of questions. \ue200cite\ue202turn1search1\ue202turn1search7\ue201\n\n> **Why this matters:** General intelligence must ask \u201cwhat *caused* this and what *would happen if*\u2026?\u201d Causality gives you counterfactuals, safety analysis, and principled exploration.\n\n---\n\n### D. **Program synthesis + neuro\u2011symbolic reasoning**\nUse neural models to propose **discrete programs/proofs**, then **verify** or **search** symbolically. This converts stochastic guesses into certifiable solutions and enables exact generalization on algorithmic structure.\n\n- **AlphaGeometry/AlphaProof** style systems solve Olympiad\u2011level math by synthesizing and verifying proof steps at scale, a template for rigor in other domains (planning, code, regulation). \ue200cite\ue202turn0search3\ue202turn0search10\ue201\n\n> **Why this matters:** For mathematics, software, law, and safety\u2011critical engineering, *truth conditions* matter; verification plugs a key hole left by probabilistic models.\n\n---\n\n### E. **Energy\u2011based & predictive learning beyond next\u2011token**\nTrain to **predict in representation space** rather than reconstruct tokens or pixels.\n\n- **I\u2011JEPA** (LeCun et\u202fal.) predicts **latent** targets instead of raw pixels, encouraging semantic abstraction and reducing spurious shortcuts\u2014an alternative to token\u2011level losses as the organizing principle. \ue200cite\ue202turn0search4\ue201  \n- **Active Inference / Free\u2011Energy**: a unifying lens for perception\u2011action loops as **Bayesian control** minimizing expected surprise; useful for principled exploration and uncertainty handling in embodied agents. \ue200cite\ue202turn0search5\ue202turn0search12\ue201\n\n> **Why this matters:** Language modeling is a *surface* objective; JEPA\u2011style or free\u2011energy objectives seek **state variables** and **controls** that matter for survival and task achievement.\n\n---\n\n### F. **Open\u2011endedness and discovery engines**\nDesign learners that **generate their own curricula** and seek *diverse, high\u2011value* artifacts.\n\n- **GFlowNets** sample compositional objects proportional to a reward (e.g., molecules, hypotheses), bridging RL and generative modeling and encouraging *diversity* over single optimum. This is closer to scientific discovery than maximum\u2011likelihood training is. \ue200cite\ue202turn1search8\ue201\n\n> **Why this matters:** A general intelligence cannot be confined to matching a fixed distribution; it must **seek**, invent, and cover multiple solution modes.\n\n---\n\n## 2) A post\u2011language architecture: language as an I/O layer, not the core\n\nHere\u2019s a concrete stack that makes **simulation, causality, and action** the substrate, with language as an interface:\n\n1. **Multimodal Perceptual Backbone**  \n   Self\u2011supervised JEPA\u2011style encoders over video, audio, proprioception, tactile streams to learn **object\u2011centric**, **3D**, and **temporal** representations. (I\u2011JEPA rationale.) \ue200cite\ue202turn0search4\ue201\n\n2. **Action\u2011Conditioned World Model**  \n   A latent dynamics model trained on real + simulated rollouts; learns **state transitions and affordances**. Use *Dreamer\u2011style imagination* for planning, and distill advances from **Sora/Genie** to increase fidelity, consistency, and controllability. \ue200cite\ue202turn0search6\ue202turn0search1\ue202turn0search0\ue201\n\n3. **Causal Layer**  \n   Discover latent variables and mechanisms across tasks/environments; maintain **structural causal models** (SCMs) for counterfactual queries and OOD transfer. Integrate interventional data via active experimentation policies. \ue200cite\ue202turn1search1\ue202turn1search7\ue201\n\n4. **Executive & Planning**  \n   - **Model\u2011predictive control** over the world model for short\u2011horizon robustness.  \n   - **Symbolic program/plan synthesis** with **verification** for long\u2011horizon reliability (proofs, code, formal specs). Use neural proposals + search + checkers (AlphaGeometry template). \ue200cite\ue202turn0search3\ue201\n\n5. **Memory & Knowledge**  \n   - **Episodic**: compressed rollouts and outcomes (for credit assignment and RCA).  \n   - **Semantic/Graph**: entities, relations, learned invariants, and mechanistic facts.  \n   - **Procedural**: skills with preconditions/effects, abstracted from policies.\n\n6. **Motivation & Uncertainty**  \n   - Intrinsic objectives: **information gain / empowerment / free energy** to drive open\u2011ended exploration and reduce epistemic uncertainty. \ue200cite\ue202turn0search5\ue201  \n   - **Risk\u2011aware control** (distributional value functions, constraints).\n\n7. **Language Module (outer loop)**  \n   - Serves as *instruction*, *explanation*, *social coordination*, and *tool API*.  \n   - Trains against **the agent\u2019s own traces** (plans, proofs, experiments) to make language reflect **grounded internal states**, not just web text.\n\n> **Key inversion:** The system *acts, perceives, and models* first; **then** it talks about what it knows. Language supervises interfaces, not the ontology.\n\n---\n\n## 3) Training regime (scalable & testable)\n\n1. **Stage I \u2014 World pretraining**  \n   - Train the perceptual backbone + world model on massive video/embodied logs; include synthetic, controllable, and counterfactual data (Genie\u2011style) for breadth. \ue200cite\ue202turn0search0\ue201  \n   - Add *temporal contrastive/JEPA losses* to push object/dynamics abstraction. \ue200cite\ue202turn0search4\ue201\n\n2. **Stage II \u2014 Interventional data & CRL**  \n   - Run **active experiments** in sim and on real platforms (robots, simulators).  \n   - Estimate SCMs; evaluate via OOD interventions and invariance tests. \ue200cite\ue202turn1search1\ue201\n\n3. **Stage III \u2014 Skill acquisition via imagination**  \n   - Dreamer\u2011style latent planning to learn reusable skills; distill to policies.  \n   - Curriculum generated by **open\u2011ended environment generators** (Genie): always new tasks, forever. \ue200cite\ue202turn0search6\ue202turn0search0\ue201\n\n4. **Stage IV \u2014 Neuro\u2011symbolic hardening**  \n   - For math, software, safety: train proposal networks to output **programs/proofs**; verify and backprop signals from checkers. (AlphaGeometry pattern.) \ue200cite\ue202turn0search3\ue201\n\n5. **Stage V \u2014 Language alignment**  \n   - Learn to *explain* internal beliefs/plans; penalize divergences between verbal claims and **rollout\u2011verified** outcomes (truth\u2011anchored RL).\n\n---\n\n## 4) Evaluation: beyond benchmarks that reward eloquence\n\nDesign tests that measure **grounded competence** and **transfer**, not eloquence:\n\n- **Physical reasoning**: Predict and control in novel physics puzzles; score by rollout accuracy and energy constraint satisfaction.  \n- **Interventional OOD**: Change causal mechanisms at test time; measure adaptation without fine\u2011tuning (CRL stress test). \ue200cite\ue202turn1search1\ue201  \n- **Long\u2011horizon tasks**: Real robot sequences (dozens to hundreds of steps), with sparse rewards; measure success under latency and partial observability (VLA\u2011style). \ue200cite\ue202turn0search2\ue201  \n- **Verified problem solving**: Percentage of solutions **formally verified** (proofs, compilable & correct programs, safety constraints satisfied). (AlphaGeometry template.) \ue200cite\ue202turn0search3\ue201  \n- **Open\u2011ended discovery**: Diversity and quality of artifacts found per unit compute (GFlowNet\u2011style metrics), not just top\u20111 reward. \ue200cite\ue202turn1search8\ue201\n\n---\n\n## 5) Safety and alignment advantages of a post\u2011language core\n\n- **Truth anchoring.** Tethering language to **simulation outcomes, sensors, and verifiers** reduces hallucination and rhetorical overreach.  \n- **Counterfactual safety analysis.** SCMs make \u201cwhat if I don\u2019t?\u201d or \u201cwhat if the actuator fails?\u201d queries explicit and auditable. \ue200cite\ue202turn1search1\ue201  \n- **Bias/coverage control.** Open\u2011ended generators + causal objectives can systematically explore edge cases missing in web corpora (a known issue for video models trained on human media). \ue200cite\ue202turn0news78\ue201\n\n---\n\n## 6) Counterpoints to your premise (and mine)\n\n- **Language is not just surface form.** Token prediction over *integrated, multimodal corpora* (vision, audio, code) already absorbs some physics and tool use. The question is whether this scales to **control\u2011relevant** abstractions without explicit action modeling. Evidence suggests **partial**, not sufficient.  \n- **Emergence vs. engineering.** One might hope that enough multimodal pretraining yields causality, planning, and agency \u201cfor free.\u201d Empirically, adding **action, interventions, and verification** yields large jumps in reliability and transfer\u2014suggesting we need to **engineer** these inductive biases explicitly. (Dreamer/RT\u20112/AlphaGeometry evidence.) \ue200cite\ue202turn0search6\ue202turn0search2\ue202turn0search3\ue201  \n- **CRL is not solved.** Recent empirical probes show CRL methods often fail on real systems unless assumptions are met. This doesn\u2019t invalidate the goal; it indicates where to invest (identifiability conditions, richer interventions). \ue200cite\ue202turn1search7\ue201\n\n---\n\n## 7) A concrete, testable \u201cpost\u2011language AGI\u201d minimal core\n\n1. **JEPA\u2011style perceptual encoder + Dreamer\u2011class latent dynamics** (world model). \ue200cite\ue202turn0search4\ue202turn0search6\ue201  \n2. **Hybrid planner**: MPC for short horizons; *neuro\u2011symbolic* program synthesis + verification for long horizons. \ue200cite\ue202turn0search3\ue201  \n3. **SCM layer** with active experiment design for causal updates. \ue200cite\ue202turn1search1\ue201  \n4. **VLA policy heads** distilled from imagined trajectories and real rollouts. \ue200cite\ue202turn0search2\ue201  \n5. **Language I/O** trained to *describe* internal beliefs, ask for information, and generate experiments\u2014not to be the world model.\n\n**Milestones (each falsifiable):**\n- **M1:** Zero\u2011shot control transfer across robot morphologies with only a few minutes of adaptation (tests causality + dynamics abstraction). (RT\u20112\u2011style tasks but morphology\u2011shifty.) \ue200cite\ue202turn0search2\ue201  \n- **M2:** OOD interventions: swap friction/coefficient maps at test time; maintain control with limited trials. (CRL payoff.) \ue200cite\ue202turn1search1\ue201  \n- **M3:** Verified solving of multi\u2011step software and math tasks with **formal certificates**; language explanations match verified plans. (AlphaGeometry pattern generalized.) \ue200cite\ue202turn0search3\ue201  \n- **M4:** Open\u2011ended discovery: diverse, high\u2011scoring artifacts in a scientific domain using GFlowNet\u2011like diversity objectives. \ue200cite\ue202turn1search8\ue201\n\n---\n\n## 8) What to build now (practical recipe)\n\n- **Data:** unify large\u2011scale video (including egocentric), proprioception, tactile streams, and robot logs; generate **controllable synthetic worlds** (Genie\u2011class) to ensure coverage of rare dynamics. \ue200cite\ue202turn0search0\ue201  \n- **Objectives:** blend JEPA\u2011style latent prediction, dynamics modeling, risk\u2011sensitive control, and exploration bonuses derived from free\u2011energy / information gain. \ue200cite\ue202turn0search4\ue202turn0search5\ue201  \n- **Toolchain:** integrate SMT/ATP provers, compilers, and simulators into the inner loop; train proposal models *to satisfy verifiers*. (AlphaGeometry template.) \ue200cite\ue202turn0search3\ue201  \n- **Governance & eval:** require *simulation\u2011backed* claims in high\u2011risk domains; measure **regret under causal shifts**, not just benchmark scores.\n\n---\n\n## 9) Bottom line\n\n- **Yes, a new paradigm is needed:** swap **language as bedrock** for **world modeling + causality + action** as the substrate, with language relegated to interface, coordination, and explanation.  \n- **Why this can scale:** these ingredients supply grounding, counterfactuals, and reliable long\u2011horizon behavior\u2014things token prediction cannot guarantee.  \n- **What success looks like:** agents that (i) learn skills by **imagining** and **experimenting**, (ii) adapt under interventions, (iii) produce **verifiable artifacts**, and (iv) use language to *ask*, *explain*, and *coordinate*, not to improvise reality.\n\nIf you want, I can sketch a more formal version (state space, loss decomposition, identifiability assumptions) or propose a concrete experimental suite aligned to your math background (e.g., program\u2011synthesis tasks with proof certificates and causal shifts)."]},"status":"finished_successfully","end_turn":true,"weight":1.0,"metadata":{"content_references":[{"matched_text":"\ue200cite\ue202turn0search6\ue201","start_idx":2417,"end_idx":2436,"safe_urls":["https://arxiv.org/abs/2301.04104?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2301.04104?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Mastering Diverse Domains through World Models","url":"https://arxiv.org/abs/2301.04104?utm_source=chatgpt.com","pub_date":null,"snippet":"by D Hafner \u00b7 2023 \u00b7 Cited by 932 \u2014 We present DreamerV3, a general algorithm that outperforms specialized methods across over 150 diverse tasks, with a single configuration.","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":6}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search0\ue201","start_idx":2696,"end_idx":2715,"safe_urls":["https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/?utm_source=chatgpt.com"],"refs":[],"alt":"([Google DeepMind](https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Genie 2: A large-scale foundation world model","url":"https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/?utm_source=chatgpt.com","pub_date":null,"snippet":"Dec 4, 2024 \u2014 A foundation world model capable of generating an endless variety of action-controllable, playable 3D environments for training and evaluating embodied agents.","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":0}],"hue":null,"attributions":null,"attribution":"Google DeepMind"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search1\ue202turn0search8\ue201","start_idx":2968,"end_idx":3000,"safe_urls":["https://openai.com/index/sora-2/?utm_source=chatgpt.com","https://openai.com/index/video-generation-models-as-world-simulators/?utm_source=chatgpt.com"],"refs":[],"alt":"([OpenAI](https://openai.com/index/video-generation-models-as-world-simulators/?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Video generation models as world simulators","url":"https://openai.com/index/video-generation-models-as-world-simulators/?utm_source=chatgpt.com","pub_date":null,"snippet":"Feb 15, 2024 \u2014 Sora is a generalist model of visual data\u2014it can generate videos and images spanning diverse durations, aspect ratios and resolutions, up to a ...","attribution_segments":null,"supporting_websites":[{"title":"Sora 2 is here","url":"https://openai.com/index/sora-2/?utm_source=chatgpt.com","pub_date":null,"snippet":"Sep 30, 2025 \u2014 Today we're releasing Sora 2, our flagship video and audio generation model. The original Sora model\u2060 from February 2024 was in many ways the ...","attribution":"OpenAI"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":1},{"turn_index":0,"ref_type":"search","ref_index":8}],"hue":null,"attributions":null,"attribution":"OpenAI"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search2\ue202turn0search9\ue201","start_idx":3678,"end_idx":3710,"safe_urls":["https://deepmind.google/discover/blog/rt-2-new-model-translates-vision-and-language-into-action/?utm_source=chatgpt.com","https://robotics-transformer2.github.io/?utm_source=chatgpt.com"],"refs":[],"alt":"([Google DeepMind](https://deepmind.google/discover/blog/rt-2-new-model-translates-vision-and-language-into-action/?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"RT-2: New model translates vision and language into action","url":"https://deepmind.google/discover/blog/rt-2-new-model-translates-vision-and-language-into-action/?utm_source=chatgpt.com","pub_date":null,"snippet":"Jul 28, 2023 \u2014 RT-2 is a novel vision-language-action (VLA) model that learns from both web and robotics data, and translates this knowledge into generalised instructions for ...See more","attribution_segments":null,"supporting_websites":[{"title":"RT-2: Vision-Language-Action Models","url":"https://robotics-transformer2.github.io/?utm_source=chatgpt.com","pub_date":null,"snippet":"We study how vision-language models trained on Internet-scale data can be incorporated directly into end-to-end robotic control to boost generalization.See more","attribution":"robotics-transformer2.github.io"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":2},{"turn_index":0,"ref_type":"search","ref_index":9}],"hue":null,"attributions":null,"attribution":"Google DeepMind"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn1search1\ue202turn1search7\ue201","start_idx":4337,"end_idx":4369,"safe_urls":["https://arxiv.org/abs/2102.11107?utm_source=chatgpt.com","https://arxiv.org/pdf/2402.05052?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2102.11107?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Towards Causal Representation Learning","url":"https://arxiv.org/abs/2102.11107?utm_source=chatgpt.com","pub_date":1614007617,"snippet":"","attribution_segments":null,"supporting_websites":[{"title":"Causal Representation Learning from Multiple Distributions","url":"https://arxiv.org/pdf/2402.05052?utm_source=chatgpt.com","pub_date":null,"snippet":"by K Zhang \u00b7 2024 \u00b7 Cited by 46 \u2014 This has been recently known as causal representation learning (Sch\u00f6lkopf et al., 2021). It is worth noting that identifying only the latent causal variables ...","attribution":"arXiv"}],"refs":[{"turn_index":1,"ref_type":"search","ref_index":1},{"turn_index":1,"ref_type":"search","ref_index":7}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search3\ue202turn0search10\ue201","start_idx":5033,"end_idx":5066,"safe_urls":["https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/?utm_source=chatgpt.com","https://www.nature.com/articles/s41586-023-06747-5?utm_source=chatgpt.com"],"refs":[],"alt":"([Nature](https://www.nature.com/articles/s41586-023-06747-5?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Solving olympiad geometry without human demonstrations","url":"https://www.nature.com/articles/s41586-023-06747-5?utm_source=chatgpt.com","pub_date":null,"snippet":"by TH Trinh \u00b7 2024 \u00b7 Cited by 707 \u2014 We propose AlphaGeometry, a theorem prover for Euclidean plane geometry that sidesteps the need for human demonstrations by synthesizing millions of theorems ...","attribution_segments":null,"supporting_websites":[{"title":"AI achieves silver-medal standard solving International ...","url":"https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/?utm_source=chatgpt.com","pub_date":null,"snippet":"Jul 25, 2024 \u2014 AlphaGeometry 2 proved the geometry problem, while the two combinatorics problems remained unsolved. See our system's IMO 2024 solutions.","attribution":"Google DeepMind"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":3},{"turn_index":0,"ref_type":"search","ref_index":10}],"hue":null,"attributions":null,"attribution":"Nature"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search4\ue201","start_idx":5612,"end_idx":5631,"safe_urls":["https://ai.meta.com/blog/yann-lecun-ai-model-i-jepa/?utm_source=chatgpt.com"],"refs":[],"alt":"([Meta AI](https://ai.meta.com/blog/yann-lecun-ai-model-i-jepa/?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"I-JEPA: The first AI model based on Yann LeCun's vision ...","url":"https://ai.meta.com/blog/yann-lecun-ai-model-i-jepa/?utm_source=chatgpt.com","pub_date":null,"snippet":"Jun 13, 2023 \u2014 Our paper on I-JEPA will be presented at CVPR 2023 next week, and we're also open-sourcing the training code and model checkpoints today.","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":4}],"hue":null,"attributions":null,"attribution":"Meta AI"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search5\ue202turn0search12\ue201","start_idx":5849,"end_idx":5882,"safe_urls":["https://direct.mit.edu/neco/article/36/5/963/119791/An-Overview-of-the-Free-Energy-Principle-and?utm_source=chatgpt.com","https://www.sciencedirect.com/science/article/pii/S037015732300203X?utm_source=chatgpt.com"],"refs":[],"alt":"([MIT Press Direct](https://direct.mit.edu/neco/article/36/5/963/119791/An-Overview-of-the-Free-Energy-Principle-and?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"An Overview of the Free Energy Principle and Related ...","url":"https://direct.mit.edu/neco/article/36/5/963/119791/An-Overview-of-the-Free-Energy-Principle-and?utm_source=chatgpt.com","pub_date":null,"snippet":"Apr 23, 2024 \u2014 The free energy principle states that the human brain operates as a Bayesian inference machine, implementing perception through Bayesian ...See more","attribution_segments":null,"supporting_websites":[{"title":"The free energy principle made simpler but not too simple","url":"https://www.sciencedirect.com/science/article/pii/S037015732300203X?utm_source=chatgpt.com","pub_date":null,"snippet":"by K Friston \u00b7 2023 \u00b7 Cited by 178 \u2014 This paper provides a concise description of the free energy principle, starting from a formulation of random dynamical systems in terms of ...See more","attribution":"ScienceDirect"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":5},{"turn_index":0,"ref_type":"search","ref_index":12}],"hue":null,"attributions":null,"attribution":"MIT Press Direct"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn1search8\ue201","start_idx":6491,"end_idx":6510,"safe_urls":["https://jmlr.org/papers/volume24/22-0364/22-0364.pdf?utm_source=chatgpt.com"],"refs":[],"alt":"([Journal of Machine Learning Research](https://jmlr.org/papers/volume24/22-0364/22-0364.pdf?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"GFlowNet Foundations","url":"https://jmlr.org/papers/volume24/22-0364/22-0364.pdf?utm_source=chatgpt.com","pub_date":1689002413,"snippet":"by Y Bengio \u00b7 2023 \u00b7 Cited by 349 \u2014 This paper extends the theory of the original GFlowNet construction (Bengio et al.,. 2021) in several directions, including a new local training objective ...","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":1,"ref_type":"search","ref_index":8}],"hue":null,"attributions":null,"attribution":"Journal of Machine Learning Research"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search4\ue201","start_idx":7096,"end_idx":7115,"safe_urls":["https://ai.meta.com/blog/yann-lecun-ai-model-i-jepa/?utm_source=chatgpt.com"],"refs":[],"alt":"([Meta AI](https://ai.meta.com/blog/yann-lecun-ai-model-i-jepa/?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"I-JEPA: The first AI model based on Yann LeCun's vision ...","url":"https://ai.meta.com/blog/yann-lecun-ai-model-i-jepa/?utm_source=chatgpt.com","pub_date":null,"snippet":"Jun 13, 2023 \u2014 Our paper on I-JEPA will be presented at CVPR 2023 next week, and we're also open-sourcing the training code and model checkpoints today.","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":4}],"hue":null,"attributions":null,"attribution":"Meta AI"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search6\ue202turn0search1\ue202turn0search0\ue201","start_idx":7411,"end_idx":7456,"safe_urls":["https://arxiv.org/abs/2301.04104?utm_source=chatgpt.com","https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/?utm_source=chatgpt.com","https://openai.com/index/video-generation-models-as-world-simulators/?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2301.04104?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Mastering Diverse Domains through World Models","url":"https://arxiv.org/abs/2301.04104?utm_source=chatgpt.com","pub_date":null,"snippet":"by D Hafner \u00b7 2023 \u00b7 Cited by 932 \u2014 We present DreamerV3, a general algorithm that outperforms specialized methods across over 150 diverse tasks, with a single configuration.","attribution_segments":null,"supporting_websites":[{"title":"Video generation models as world simulators","url":"https://openai.com/index/video-generation-models-as-world-simulators/?utm_source=chatgpt.com","pub_date":null,"snippet":"Feb 15, 2024 \u2014 Sora is a generalist model of visual data\u2014it can generate videos and images spanning diverse durations, aspect ratios and resolutions, up to a ...","attribution":"OpenAI"},{"title":"Genie 2: A large-scale foundation world model","url":"https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/?utm_source=chatgpt.com","pub_date":null,"snippet":"Dec 4, 2024 \u2014 A foundation world model capable of generating an endless variety of action-controllable, playable 3D environments for training and evaluating embodied agents.","attribution":"Google DeepMind"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":6},{"turn_index":0,"ref_type":"search","ref_index":1},{"turn_index":0,"ref_type":"search","ref_index":0}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn1search1\ue202turn1search7\ue201","start_idx":7708,"end_idx":7740,"safe_urls":["https://arxiv.org/abs/2102.11107?utm_source=chatgpt.com","https://arxiv.org/pdf/2402.05052?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2102.11107?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Towards Causal Representation Learning","url":"https://arxiv.org/abs/2102.11107?utm_source=chatgpt.com","pub_date":1614007617,"snippet":"","attribution_segments":null,"supporting_websites":[{"title":"Causal Representation Learning from Multiple Distributions","url":"https://arxiv.org/pdf/2402.05052?utm_source=chatgpt.com","pub_date":null,"snippet":"by K Zhang \u00b7 2024 \u00b7 Cited by 46 \u2014 This has been recently known as causal representation learning (Sch\u00f6lkopf et al., 2021). It is worth noting that identifying only the latent causal variables ...","attribution":"arXiv"}],"refs":[{"turn_index":1,"ref_type":"search","ref_index":1},{"turn_index":1,"ref_type":"search","ref_index":7}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search3\ue201","start_idx":8048,"end_idx":8067,"safe_urls":["https://www.nature.com/articles/s41586-023-06747-5?utm_source=chatgpt.com"],"refs":[],"alt":"([Nature](https://www.nature.com/articles/s41586-023-06747-5?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Solving olympiad geometry without human demonstrations","url":"https://www.nature.com/articles/s41586-023-06747-5?utm_source=chatgpt.com","pub_date":null,"snippet":"by TH Trinh \u00b7 2024 \u00b7 Cited by 707 \u2014 We propose AlphaGeometry, a theorem prover for Euclidean plane geometry that sidesteps the need for human demonstrations by synthesizing millions of theorems ...","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":3}],"hue":null,"attributions":null,"attribution":"Nature"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search5\ue201","start_idx":8534,"end_idx":8553,"safe_urls":["https://direct.mit.edu/neco/article/36/5/963/119791/An-Overview-of-the-Free-Energy-Principle-and?utm_source=chatgpt.com"],"refs":[],"alt":"([MIT Press Direct](https://direct.mit.edu/neco/article/36/5/963/119791/An-Overview-of-the-Free-Energy-Principle-and?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"An Overview of the Free Energy Principle and Related ...","url":"https://direct.mit.edu/neco/article/36/5/963/119791/An-Overview-of-the-Free-Energy-Principle-and?utm_source=chatgpt.com","pub_date":null,"snippet":"Apr 23, 2024 \u2014 The free energy principle states that the human brain operates as a Bayesian inference machine, implementing perception through Bayesian ...See more","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":5}],"hue":null,"attributions":null,"attribution":"MIT Press Direct"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search0\ue201","start_idx":9318,"end_idx":9337,"safe_urls":["https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/?utm_source=chatgpt.com"],"refs":[],"alt":"([Google DeepMind](https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Genie 2: A large-scale foundation world model","url":"https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/?utm_source=chatgpt.com","pub_date":null,"snippet":"Dec 4, 2024 \u2014 A foundation world model capable of generating an endless variety of action-controllable, playable 3D environments for training and evaluating embodied agents.","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":0}],"hue":null,"attributions":null,"attribution":"Google DeepMind"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search4\ue201","start_idx":9421,"end_idx":9440,"safe_urls":["https://ai.meta.com/blog/yann-lecun-ai-model-i-jepa/?utm_source=chatgpt.com"],"refs":[],"alt":"([Meta AI](https://ai.meta.com/blog/yann-lecun-ai-model-i-jepa/?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"I-JEPA: The first AI model based on Yann LeCun's vision ...","url":"https://ai.meta.com/blog/yann-lecun-ai-model-i-jepa/?utm_source=chatgpt.com","pub_date":null,"snippet":"Jun 13, 2023 \u2014 Our paper on I-JEPA will be presented at CVPR 2023 next week, and we're also open-sourcing the training code and model checkpoints today.","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":4}],"hue":null,"attributions":null,"attribution":"Meta AI"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn1search1\ue201","start_idx":9646,"end_idx":9665,"safe_urls":["https://arxiv.org/abs/2102.11107?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2102.11107?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Towards Causal Representation Learning","url":"https://arxiv.org/abs/2102.11107?utm_source=chatgpt.com","pub_date":1614007617,"snippet":"","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":1,"ref_type":"search","ref_index":1}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search6\ue202turn0search0\ue201","start_idx":9909,"end_idx":9941,"safe_urls":["https://arxiv.org/abs/2301.04104?utm_source=chatgpt.com","https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2301.04104?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Mastering Diverse Domains through World Models","url":"https://arxiv.org/abs/2301.04104?utm_source=chatgpt.com","pub_date":null,"snippet":"by D Hafner \u00b7 2023 \u00b7 Cited by 932 \u2014 We present DreamerV3, a general algorithm that outperforms specialized methods across over 150 diverse tasks, with a single configuration.","attribution_segments":null,"supporting_websites":[{"title":"Genie 2: A large-scale foundation world model","url":"https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/?utm_source=chatgpt.com","pub_date":null,"snippet":"Dec 4, 2024 \u2014 A foundation world model capable of generating an endless variety of action-controllable, playable 3D environments for training and evaluating embodied agents.","attribution":"Google DeepMind"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":6},{"turn_index":0,"ref_type":"search","ref_index":0}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search3\ue201","start_idx":10144,"end_idx":10163,"safe_urls":["https://www.nature.com/articles/s41586-023-06747-5?utm_source=chatgpt.com"],"refs":[],"alt":"([Nature](https://www.nature.com/articles/s41586-023-06747-5?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Solving olympiad geometry without human demonstrations","url":"https://www.nature.com/articles/s41586-023-06747-5?utm_source=chatgpt.com","pub_date":null,"snippet":"by TH Trinh \u00b7 2024 \u00b7 Cited by 707 \u2014 We propose AlphaGeometry, a theorem prover for Euclidean plane geometry that sidesteps the need for human demonstrations by synthesizing millions of theorems ...","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":3}],"hue":null,"attributions":null,"attribution":"Nature"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn1search1\ue201","start_idx":10757,"end_idx":10776,"safe_urls":["https://arxiv.org/abs/2102.11107?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2102.11107?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Towards Causal Representation Learning","url":"https://arxiv.org/abs/2102.11107?utm_source=chatgpt.com","pub_date":1614007617,"snippet":"","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":1,"ref_type":"search","ref_index":1}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search2\ue201","start_idx":10947,"end_idx":10966,"safe_urls":["https://deepmind.google/discover/blog/rt-2-new-model-translates-vision-and-language-into-action/?utm_source=chatgpt.com"],"refs":[],"alt":"([Google DeepMind](https://deepmind.google/discover/blog/rt-2-new-model-translates-vision-and-language-into-action/?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"RT-2: New model translates vision and language into action","url":"https://deepmind.google/discover/blog/rt-2-new-model-translates-vision-and-language-into-action/?utm_source=chatgpt.com","pub_date":null,"snippet":"Jul 28, 2023 \u2014 RT-2 is a novel vision-language-action (VLA) model that learns from both web and robotics data, and translates this knowledge into generalised instructions for ...See more","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":2}],"hue":null,"attributions":null,"attribution":"Google DeepMind"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search3\ue201","start_idx":11144,"end_idx":11163,"safe_urls":["https://www.nature.com/articles/s41586-023-06747-5?utm_source=chatgpt.com"],"refs":[],"alt":"([Nature](https://www.nature.com/articles/s41586-023-06747-5?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Solving olympiad geometry without human demonstrations","url":"https://www.nature.com/articles/s41586-023-06747-5?utm_source=chatgpt.com","pub_date":null,"snippet":"by TH Trinh \u00b7 2024 \u00b7 Cited by 707 \u2014 We propose AlphaGeometry, a theorem prover for Euclidean plane geometry that sidesteps the need for human demonstrations by synthesizing millions of theorems ...","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":3}],"hue":null,"attributions":null,"attribution":"Nature"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn1search8\ue201","start_idx":11301,"end_idx":11320,"safe_urls":["https://jmlr.org/papers/volume24/22-0364/22-0364.pdf?utm_source=chatgpt.com"],"refs":[],"alt":"([Journal of Machine Learning Research](https://jmlr.org/papers/volume24/22-0364/22-0364.pdf?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"GFlowNet Foundations","url":"https://jmlr.org/papers/volume24/22-0364/22-0364.pdf?utm_source=chatgpt.com","pub_date":1689002413,"snippet":"by Y Bengio \u00b7 2023 \u00b7 Cited by 349 \u2014 This paper extends the theory of the original GFlowNet construction (Bengio et al.,. 2021) in several directions, including a new local training objective ...","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":1,"ref_type":"search","ref_index":8}],"hue":null,"attributions":null,"attribution":"Journal of Machine Learning Research"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn1search1\ue201","start_idx":11665,"end_idx":11684,"safe_urls":["https://arxiv.org/abs/2102.11107?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2102.11107?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Towards Causal Representation Learning","url":"https://arxiv.org/abs/2102.11107?utm_source=chatgpt.com","pub_date":1614007617,"snippet":"","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":1,"ref_type":"search","ref_index":1}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0news78\ue201","start_idx":11876,"end_idx":11894,"safe_urls":["https://www.wired.com/story/openai-sora-video-generator-bias?utm_source=chatgpt.com"],"refs":[],"alt":"([WIRED](https://www.wired.com/story/openai-sora-video-generator-bias?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"OpenAI's Sora Is Plagued by Sexist, Racist, and Ableist Biases","url":"https://www.wired.com/story/openai-sora-video-generator-bias?utm_source=chatgpt.com","pub_date":1742724000,"snippet":"OpenAI's video generation tool, Sora, perpetuates sexist, racist, and ableist biases, despite advancements in image quality. A WIRED investigation of 250 AI-generated videos found stereotypical job roles and physical appearances. Pilots, CEOs, and professors are depicted as men, while women are shown as flight attendants, receptionists, and childcare workers. Disabled people are portrayed as wheelchair users, and fat people are seldom shown running. Sora struggles with diverse racial presentations and often defaults to portraying attractive and physically fit individuals. Although OpenAI acknowledges these biases and has teams dedicated to reducing them, the tool still produces uniform and stereotypical outputs, reflecting and amplifying existing social biases. Researchers suggest the need for more diverse training data and societal risk assessments in AI development to address these issues effectively.","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"news","ref_index":78}],"hue":null,"attributions":null,"attribution":"WIRED"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search6\ue202turn0search2\ue202turn0search3\ue201","start_idx":12620,"end_idx":12665,"safe_urls":["https://arxiv.org/abs/2301.04104?utm_source=chatgpt.com","https://deepmind.google/discover/blog/rt-2-new-model-translates-vision-and-language-into-action/?utm_source=chatgpt.com","https://www.nature.com/articles/s41586-023-06747-5?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2301.04104?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Mastering Diverse Domains through World Models","url":"https://arxiv.org/abs/2301.04104?utm_source=chatgpt.com","pub_date":null,"snippet":"by D Hafner \u00b7 2023 \u00b7 Cited by 932 \u2014 We present DreamerV3, a general algorithm that outperforms specialized methods across over 150 diverse tasks, with a single configuration.","attribution_segments":null,"supporting_websites":[{"title":"RT-2: New model translates vision and language into action","url":"https://deepmind.google/discover/blog/rt-2-new-model-translates-vision-and-language-into-action/?utm_source=chatgpt.com","pub_date":null,"snippet":"Jul 28, 2023 \u2014 RT-2 is a novel vision-language-action (VLA) model that learns from both web and robotics data, and translates this knowledge into generalised instructions for ...See more","attribution":"Google DeepMind"},{"title":"Solving olympiad geometry without human demonstrations","url":"https://www.nature.com/articles/s41586-023-06747-5?utm_source=chatgpt.com","pub_date":null,"snippet":"by TH Trinh \u00b7 2024 \u00b7 Cited by 707 \u2014 We propose AlphaGeometry, a theorem prover for Euclidean plane geometry that sidesteps the need for human demonstrations by synthesizing millions of theorems ...","attribution":"Nature"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":6},{"turn_index":0,"ref_type":"search","ref_index":2},{"turn_index":0,"ref_type":"search","ref_index":3}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn1search7\ue201","start_idx":12904,"end_idx":12923,"safe_urls":["https://arxiv.org/pdf/2402.05052?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/pdf/2402.05052?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Causal Representation Learning from Multiple Distributions","url":"https://arxiv.org/pdf/2402.05052?utm_source=chatgpt.com","pub_date":1723509191,"snippet":"by K Zhang \u00b7 2024 \u00b7 Cited by 46 \u2014 This has been recently known as causal representation learning (Sch\u00f6lkopf et al., 2021). It is worth noting that identifying only the latent causal variables ...","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":1,"ref_type":"search","ref_index":7}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search4\ue202turn0search6\ue201","start_idx":13075,"end_idx":13107,"safe_urls":["https://ai.meta.com/blog/yann-lecun-ai-model-i-jepa/?utm_source=chatgpt.com","https://arxiv.org/abs/2301.04104?utm_source=chatgpt.com"],"refs":[],"alt":"([Meta AI](https://ai.meta.com/blog/yann-lecun-ai-model-i-jepa/?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"I-JEPA: The first AI model based on Yann LeCun's vision ...","url":"https://ai.meta.com/blog/yann-lecun-ai-model-i-jepa/?utm_source=chatgpt.com","pub_date":null,"snippet":"Jun 13, 2023 \u2014 Our paper on I-JEPA will be presented at CVPR 2023 next week, and we're also open-sourcing the training code and model checkpoints today.","attribution_segments":null,"supporting_websites":[{"title":"Mastering Diverse Domains through World Models","url":"https://arxiv.org/abs/2301.04104?utm_source=chatgpt.com","pub_date":null,"snippet":"by D Hafner \u00b7 2023 \u00b7 Cited by 932 \u2014 We present DreamerV3, a general algorithm that outperforms specialized methods across over 150 diverse tasks, with a single configuration.","attribution":"arXiv"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":4},{"turn_index":0,"ref_type":"search","ref_index":6}],"hue":null,"attributions":null,"attribution":"Meta AI"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search3\ue201","start_idx":13226,"end_idx":13245,"safe_urls":["https://www.nature.com/articles/s41586-023-06747-5?utm_source=chatgpt.com"],"refs":[],"alt":"([Nature](https://www.nature.com/articles/s41586-023-06747-5?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Solving olympiad geometry without human demonstrations","url":"https://www.nature.com/articles/s41586-023-06747-5?utm_source=chatgpt.com","pub_date":null,"snippet":"by TH Trinh \u00b7 2024 \u00b7 Cited by 707 \u2014 We propose AlphaGeometry, a theorem prover for Euclidean plane geometry that sidesteps the need for human demonstrations by synthesizing millions of theorems ...","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":3}],"hue":null,"attributions":null,"attribution":"Nature"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn1search1\ue201","start_idx":13315,"end_idx":13334,"safe_urls":["https://arxiv.org/abs/2102.11107?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2102.11107?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Towards Causal Representation Learning","url":"https://arxiv.org/abs/2102.11107?utm_source=chatgpt.com","pub_date":1614007617,"snippet":"","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":1,"ref_type":"search","ref_index":1}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search2\ue201","start_idx":13417,"end_idx":13436,"safe_urls":["https://deepmind.google/discover/blog/rt-2-new-model-translates-vision-and-language-into-action/?utm_source=chatgpt.com"],"refs":[],"alt":"([Google DeepMind](https://deepmind.google/discover/blog/rt-2-new-model-translates-vision-and-language-into-action/?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"RT-2: New model translates vision and language into action","url":"https://deepmind.google/discover/blog/rt-2-new-model-translates-vision-and-language-into-action/?utm_source=chatgpt.com","pub_date":null,"snippet":"Jul 28, 2023 \u2014 RT-2 is a novel vision-language-action (VLA) model that learns from both web and robotics data, and translates this knowledge into generalised instructions for ...See more","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":2}],"hue":null,"attributions":null,"attribution":"Google DeepMind"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search2\ue201","start_idx":13793,"end_idx":13812,"safe_urls":["https://deepmind.google/discover/blog/rt-2-new-model-translates-vision-and-language-into-action/?utm_source=chatgpt.com"],"refs":[],"alt":"([Google DeepMind](https://deepmind.google/discover/blog/rt-2-new-model-translates-vision-and-language-into-action/?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"RT-2: New model translates vision and language into action","url":"https://deepmind.google/discover/blog/rt-2-new-model-translates-vision-and-language-into-action/?utm_source=chatgpt.com","pub_date":null,"snippet":"Jul 28, 2023 \u2014 RT-2 is a novel vision-language-action (VLA) model that learns from both web and robotics data, and translates this knowledge into generalised instructions for ...See more","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":2}],"hue":null,"attributions":null,"attribution":"Google DeepMind"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn1search1\ue201","start_idx":13941,"end_idx":13960,"safe_urls":["https://arxiv.org/abs/2102.11107?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2102.11107?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Towards Causal Representation Learning","url":"https://arxiv.org/abs/2102.11107?utm_source=chatgpt.com","pub_date":1614007617,"snippet":"","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":1,"ref_type":"search","ref_index":1}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search3\ue201","start_idx":14139,"end_idx":14158,"safe_urls":["https://www.nature.com/articles/s41586-023-06747-5?utm_source=chatgpt.com"],"refs":[],"alt":"([Nature](https://www.nature.com/articles/s41586-023-06747-5?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Solving olympiad geometry without human demonstrations","url":"https://www.nature.com/articles/s41586-023-06747-5?utm_source=chatgpt.com","pub_date":null,"snippet":"by TH Trinh \u00b7 2024 \u00b7 Cited by 707 \u2014 We propose AlphaGeometry, a theorem prover for Euclidean plane geometry that sidesteps the need for human demonstrations by synthesizing millions of theorems ...","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":3}],"hue":null,"attributions":null,"attribution":"Nature"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn1search8\ue201","start_idx":14290,"end_idx":14309,"safe_urls":["https://jmlr.org/papers/volume24/22-0364/22-0364.pdf?utm_source=chatgpt.com"],"refs":[],"alt":"([Journal of Machine Learning Research](https://jmlr.org/papers/volume24/22-0364/22-0364.pdf?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"GFlowNet Foundations","url":"https://jmlr.org/papers/volume24/22-0364/22-0364.pdf?utm_source=chatgpt.com","pub_date":1689002413,"snippet":"by Y Bengio \u00b7 2023 \u00b7 Cited by 349 \u2014 This paper extends the theory of the original GFlowNet construction (Bengio et al.,. 2021) in several directions, including a new local training objective ...","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":1,"ref_type":"search","ref_index":8}],"hue":null,"attributions":null,"attribution":"Journal of Machine Learning Research"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search0\ue201","start_idx":14563,"end_idx":14582,"safe_urls":["https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/?utm_source=chatgpt.com"],"refs":[],"alt":"([Google DeepMind](https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Genie 2: A large-scale foundation world model","url":"https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/?utm_source=chatgpt.com","pub_date":null,"snippet":"Dec 4, 2024 \u2014 A foundation world model capable of generating an endless variety of action-controllable, playable 3D environments for training and evaluating embodied agents.","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":0}],"hue":null,"attributions":null,"attribution":"Google DeepMind"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search4\ue202turn0search5\ue201","start_idx":14751,"end_idx":14783,"safe_urls":["https://ai.meta.com/blog/yann-lecun-ai-model-i-jepa/?utm_source=chatgpt.com","https://direct.mit.edu/neco/article/36/5/963/119791/An-Overview-of-the-Free-Energy-Principle-and?utm_source=chatgpt.com"],"refs":[],"alt":"([Meta AI](https://ai.meta.com/blog/yann-lecun-ai-model-i-jepa/?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"I-JEPA: The first AI model based on Yann LeCun's vision ...","url":"https://ai.meta.com/blog/yann-lecun-ai-model-i-jepa/?utm_source=chatgpt.com","pub_date":null,"snippet":"Jun 13, 2023 \u2014 Our paper on I-JEPA will be presented at CVPR 2023 next week, and we're also open-sourcing the training code and model checkpoints today.","attribution_segments":null,"supporting_websites":[{"title":"An Overview of the Free Energy Principle and Related ...","url":"https://direct.mit.edu/neco/article/36/5/963/119791/An-Overview-of-the-Free-Energy-Principle-and?utm_source=chatgpt.com","pub_date":null,"snippet":"Apr 23, 2024 \u2014 The free energy principle states that the human brain operates as a Bayesian inference machine, implementing perception through Bayesian ...See more","attribution":"MIT Press Direct"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":4},{"turn_index":0,"ref_type":"search","ref_index":5}],"hue":null,"attributions":null,"attribution":"Meta AI"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search3\ue201","start_idx":14949,"end_idx":14968,"safe_urls":["https://www.nature.com/articles/s41586-023-06747-5?utm_source=chatgpt.com"],"refs":[],"alt":"([Nature](https://www.nature.com/articles/s41586-023-06747-5?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Solving olympiad geometry without human demonstrations","url":"https://www.nature.com/articles/s41586-023-06747-5?utm_source=chatgpt.com","pub_date":null,"snippet":"by TH Trinh \u00b7 2024 \u00b7 Cited by 707 \u2014 We propose AlphaGeometry, a theorem prover for Euclidean plane geometry that sidesteps the need for human demonstrations by synthesizing millions of theorems ...","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":3}],"hue":null,"attributions":null,"attribution":"Nature"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":" ","start_idx":16020,"end_idx":16020,"safe_urls":[],"refs":[],"alt":"","prompt_text":null,"type":"sources_footnote","sources":[{"title":"Mastering Diverse Domains through World Models","url":"https://arxiv.org/abs/2301.04104?utm_source=chatgpt.com","attribution":"arXiv"},{"title":"Genie 2: A large-scale foundation world model","url":"https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/?utm_source=chatgpt.com","attribution":"Google DeepMind"},{"title":"Video generation models as world simulators","url":"https://openai.com/index/video-generation-models-as-world-simulators/?utm_source=chatgpt.com","attribution":"OpenAI"},{"title":"Solving olympiad geometry without human demonstrations","url":"https://www.nature.com/articles/s41586-023-06747-5?utm_source=chatgpt.com","attribution":"Nature"},{"title":"I-JEPA: The first AI model based on Yann LeCun's vision ...","url":"https://ai.meta.com/blog/yann-lecun-ai-model-i-jepa/?utm_source=chatgpt.com","attribution":"Meta AI"},{"title":"An Overview of the Free Energy Principle and Related ...","url":"https://direct.mit.edu/neco/article/36/5/963/119791/An-Overview-of-the-Free-Energy-Principle-and?utm_source=chatgpt.com","attribution":"MIT Press Direct"},{"title":"GFlowNet Foundations","url":"https://jmlr.org/papers/volume24/22-0364/22-0364.pdf?utm_source=chatgpt.com","attribution":"Journal of Machine Learning Research"},{"title":"OpenAI's Sora Is Plagued by Sexist, Racist, and Ableist Biases","url":"https://www.wired.com/story/openai-sora-video-generator-bias?utm_source=chatgpt.com","attribution":"WIRED"}],"has_images":false}],"safe_urls":["https://arxiv.org/abs/2301.04104?utm_source=chatgpt.com","https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/?utm_source=chatgpt.com","https://openai.com/index/sora-2/?utm_source=chatgpt.com","https://openai.com/index/video-generation-models-as-world-simulators/?utm_source=chatgpt.com","https://deepmind.google/discover/blog/rt-2-new-model-translates-vision-and-language-into-action/?utm_source=chatgpt.com","https://robotics-transformer2.github.io/?utm_source=chatgpt.com","https://arxiv.org/abs/2102.11107?utm_source=chatgpt.com","https://arxiv.org/pdf/2402.05052?utm_source=chatgpt.com","https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/?utm_source=chatgpt.com","https://www.nature.com/articles/s41586-023-06747-5?utm_source=chatgpt.com","https://ai.meta.com/blog/yann-lecun-ai-model-i-jepa/?utm_source=chatgpt.com","https://direct.mit.edu/neco/article/36/5/963/119791/An-Overview-of-the-Free-Energy-Principle-and?utm_source=chatgpt.com","https://www.sciencedirect.com/science/article/pii/S037015732300203X?utm_source=chatgpt.com","https://jmlr.org/papers/volume24/22-0364/22-0364.pdf?utm_source=chatgpt.com","https://ai.meta.com/blog/yann-lecun-ai-model-i-jepa/?utm_source=chatgpt.com","https://arxiv.org/abs/2301.04104?utm_source=chatgpt.com","https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/?utm_source=chatgpt.com","https://openai.com/index/video-generation-models-as-world-simulators/?utm_source=chatgpt.com","https://arxiv.org/abs/2102.11107?utm_source=chatgpt.com","https://arxiv.org/pdf/2402.05052?utm_source=chatgpt.com","https://www.nature.com/articles/s41586-023-06747-5?utm_source=chatgpt.com","https://direct.mit.edu/neco/article/36/5/963/119791/An-Overview-of-the-Free-Energy-Principle-and?utm_source=chatgpt.com","https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/?utm_source=chatgpt.com","https://ai.meta.com/blog/yann-lecun-ai-model-i-jepa/?utm_source=chatgpt.com","https://arxiv.org/abs/2102.11107?utm_source=chatgpt.com","https://arxiv.org/abs/2301.04104?utm_source=chatgpt.com","https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/?utm_source=chatgpt.com","https://www.nature.com/articles/s41586-023-06747-5?utm_source=chatgpt.com","https://arxiv.org/abs/2102.11107?utm_source=chatgpt.com","https://deepmind.google/discover/blog/rt-2-new-model-translates-vision-and-language-into-action/?utm_source=chatgpt.com","https://www.nature.com/articles/s41586-023-06747-5?utm_source=chatgpt.com","https://jmlr.org/papers/volume24/22-0364/22-0364.pdf?utm_source=chatgpt.com","https://arxiv.org/abs/2102.11107?utm_source=chatgpt.com","https://www.wired.com/story/openai-sora-video-generator-bias?utm_source=chatgpt.com","https://arxiv.org/abs/2301.04104?utm_source=chatgpt.com","https://deepmind.google/discover/blog/rt-2-new-model-translates-vision-and-language-into-action/?utm_source=chatgpt.com","https://www.nature.com/articles/s41586-023-06747-5?utm_source=chatgpt.com","https://arxiv.org/pdf/2402.05052?utm_source=chatgpt.com","https://ai.meta.com/blog/yann-lecun-ai-model-i-jepa/?utm_source=chatgpt.com","https://arxiv.org/abs/2301.04104?utm_source=chatgpt.com","https://www.nature.com/articles/s41586-023-06747-5?utm_source=chatgpt.com","https://arxiv.org/abs/2102.11107?utm_source=chatgpt.com","https://deepmind.google/discover/blog/rt-2-new-model-translates-vision-and-language-into-action/?utm_source=chatgpt.com","https://deepmind.google/discover/blog/rt-2-new-model-translates-vision-and-language-into-action/?utm_source=chatgpt.com","https://arxiv.org/abs/2102.11107?utm_source=chatgpt.com","https://www.nature.com/articles/s41586-023-06747-5?utm_source=chatgpt.com","https://jmlr.org/papers/volume24/22-0364/22-0364.pdf?utm_source=chatgpt.com","https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/?utm_source=chatgpt.com","https://ai.meta.com/blog/yann-lecun-ai-model-i-jepa/?utm_source=chatgpt.com","https://direct.mit.edu/neco/article/36/5/963/119791/An-Overview-of-the-Free-Energy-Principle-and?utm_source=chatgpt.com","https://www.nature.com/articles/s41586-023-06747-5?utm_source=chatgpt.com"],"search_result_groups":[{"type":"search_result_group","domain":"arxiv.org","entries":[{"type":"search_result","url":"https://arxiv.org/pdf/2301.04104?utm_source=chatgpt.com","title":"Mastering Diverse Domains through World Models","snippet":"by D Hafner \u00b7 2023 \u00b7 Cited by 932 \u2014 We present DreamerV3, a general algorithm that outperforms specialized methods across over 150 diverse tasks, with a single configuration.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2307.15818?utm_source=chatgpt.com","title":"RT-2: Vision-Language-Action Models Transfer Web ...","snippet":"by A Brohan \u00b7 2023 \u00b7 Cited by 2008 \u2014 RT-2 uses vision-language models trained on web data to boost robotic control, enabling semantic reasoning and improved generalization.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2502.03544v1?utm_source=chatgpt.com","title":"Gold-medalist Performance in Solving Olympiad Geometry ...","snippet":"Feb 5, 2025 \u2014 We present AlphaGeometry2, a significantly improved version of AlphaGeometry introduced in Trinh et al. (2024) , which has now surpassed an average gold ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":65},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2402.05309v1?utm_source=chatgpt.com","title":"1 Introduction","snippet":"Generative Flow Networks (GFlowNets, or GFNs) have emerged as a generative modelling framework for learning unnormalized probability mass functions of discrete ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":77},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2402.02186v2?utm_source=chatgpt.com","title":"Evolution guided generative flow networks","snippet":"Jun 13, 2025 \u2014 We propose Evolution guided generative flow networks (EGFN), a simple and powerful augmentation to the GFlowNets training using Evolutionary algorithms (EA).","ref_id":{"turn_index":1,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2102.11107?utm_source=chatgpt.com","title":"Towards Causal Representation Learning","snippet":"by B Sch\u00f6lkopf \u00b7 2021 \u00b7 Cited by 1870 \u2014 In the present paper, we review fundamental concepts of causal inference and relate them to crucial open problems of machine learning, including ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2301.12594?utm_source=chatgpt.com","title":"arXiv:2301.12594v2 [cs.LG] 25 May 2023","snippet":"by S Lahlou \u00b7 2023 \u00b7 Cited by 114 \u2014 Generative flow networks (GFlowNets) are amor- tized variational inference algorithms that are trained to sample from unnormalized target distri ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2409.02772?utm_source=chatgpt.com","title":"unifying causal representation learning with","snippet":"by D Yao \u00b7 2024 \u00b7 Cited by 14 \u2014 Overall, this paper clarifies the role of causal assumptions in the discovery of causal variables and shifts the focus to preserving data ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2310.03419?utm_source=chatgpt.com","title":"Pre-Training and Fine-Tuning Generative Flow Networks","snippet":"by L Pan \u00b7 2023 \u00b7 Cited by 21 \u2014 We introduce a novel approach for reward-free pre-training of GFlowNets. By framing the training as a self-supervised problem, we propose an outcome- ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2502.20099v1?utm_source=chatgpt.com","title":"Sanity Checking Causal Representation Learning on a ...","snippet":"Feb 27, 2025 \u2014 We evaluate methods for causal representation learning (CRL) on a simple, real-world system where these methods are expected to work.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"arxiv.org"}]},{"type":"search_result_group","domain":"semanticscholar.org","entries":[{"type":"search_result","url":"https://www.semanticscholar.org/paper/Towards-Causal-Representation-Learning-Scholkopf-Locatello/8f566001453bc6be0a935bf69ffd90d9db3af32b?utm_source=chatgpt.com","title":"[PDF] Towards Causal Representation Learning","snippet":"Towards Causal Representation Learning \u00b7 B. Scholkopf, Francesco Locatello, +4 authors. Yoshua Bengio \u00b7 Published in arXiv.org 22 February 2021 \u00b7 Computer Science, ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"semanticscholar.org"}]},{"type":"search_result_group","domain":"mlr.press","entries":[{"type":"search_result","url":"https://proceedings.mlr.press/v229/zitkovich23a/zitkovich23a.pdf?utm_source=chatgpt.com","title":"RT-2: Vision-Language-Action Models Transfer Web ...","snippet":"Google DeepMind \u2217. Abstract: We study how vision-language models trained on Internet-scale data can be incorporated directly into end-to-end robotic control ...See more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":47},"pub_date":null,"attribution":"mlr.press"},{"type":"search_result","url":"https://proceedings.mlr.press/v202/shen23a/shen23a.pdf?utm_source=chatgpt.com","title":"Towards Understanding and Improving GFlowNet Training","snippet":"by MW Shen \u00b7 2023 \u00b7 Cited by 73 \u2014 A Generative Flow Network (GFlowNet) learns a genera- tive policy for constructing an object by taking a sequence of actions (see (Bengio et al., 2021b) for a ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"mlr.press"}]},{"type":"search_result_group","domain":"deepmind.google","entries":[{"type":"search_result","url":"https://deepmind.google/discover/blog/genie-3-a-new-frontier-for-world-models/?utm_source=chatgpt.com","title":"Genie 3: A new frontier for world models","snippet":"Aug 5, 2025 \u2014 Today we are announcing Genie 3, a general purpose world model that can generate an unprecedented diversity of interactive environments.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"deepmind.google"},{"type":"search_result","url":"https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/?utm_source=chatgpt.com","title":"AI achieves silver-medal standard solving International ...","snippet":"Jul 25, 2024 \u2014 AlphaGeometry 2 proved the geometry problem, while the two combinatorics problems remained unsolved. See our system's IMO 2024 solutions.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"deepmind.google"},{"type":"search_result","url":"https://deepmind.google/discover/blog/alphageometry-an-olympiad-level-ai-system-for-geometry/?utm_source=chatgpt.com","title":"AlphaGeometry: An Olympiad-level AI system for geometry","snippet":"Jan 17, 2024 \u2014 In a paper published today in Nature, we introduce AlphaGeometry, an AI system that solves complex geometry problems at a level approaching ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":25},"pub_date":null,"attribution":"deepmind.google"},{"type":"search_result","url":"https://deepmind.google/discover/blog/shaping-the-future-of-advanced-robotics/?utm_source=chatgpt.com","title":"Shaping the future of advanced robotics","snippet":"Jan 4, 2024 \u2014 Robotic Transformer 2 (RT-2) is a novel vision-language-action (VLA) model that learns from both web and robotics data, and translates this ...See more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":39},"pub_date":null,"attribution":"deepmind.google"}]},{"type":"search_result_group","domain":"openai.com","entries":[{"type":"search_result","url":"https://openai.com/index/sora-2/?utm_source=chatgpt.com","title":"Sora 2 is here","snippet":"Sep 30, 2025 \u2014 Today we're releasing Sora 2, our flagship video and audio generation model. The original Sora model\u2060 from February 2024 was in many ways the ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"openai.com"},{"type":"search_result","url":"https://openai.com/index/sora/?utm_source=chatgpt.com","title":"Sora: Creating video from text","snippet":"Feb 15, 2025 \u2014 Introducing Sora, our text-to-video model. Sora can generate videos up to a minute long while maintaining visual quality and adherence to the user's prompt.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":22},"pub_date":null,"attribution":"openai.com"},{"type":"search_result","url":"https://openai.com/index/sora-is-here/?utm_source=chatgpt.com","title":"Sora is here","snippet":"Dec 9, 2024 \u2014 We introduced Sora, our model that can create realistic videos from text, and shared our initial research progress on world simulation.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":54},"pub_date":null,"attribution":"openai.com"}]},{"type":"search_result_group","domain":"robotics-transformer2.github.io","entries":[{"type":"search_result","url":"https://robotics-transformer2.github.io/?utm_source=chatgpt.com","title":"RT-2: Vision-Language-Action Models","snippet":"We study how vision-language models trained on Internet-scale data can be incorporated directly into end-to-end robotic control to boost generalization.See more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"robotics-transformer2.github.io"}]},{"type":"search_result_group","domain":"medium.com","entries":[{"type":"search_result","url":"https://malcolmlett.medium.com/critical-review-of-lecuns-introductory-jepa-paper-fabe5783134e?utm_source=chatgpt.com","title":"Critical review of LeCun's Introductory JEPA paper | Medium","snippet":"He outlines his theory for the basis of the next revolution in AI and introduces the Joint Embedding Predictive Architecture (JEPA) model architecture.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://granthbrennermd.medium.com/active-inference-therapy-a-first-principles-framework-for-psychotherapeutic-intervention-afd946b985b0?utm_source=chatgpt.com","title":"Active Inference Therapy: A First-Principles Framework for ...","snippet":"This paper introduces Active Inference Therapy (AIT), a novel psychotherapeutic framework grounded in the free energy principle and active inference theory.See more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":19},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://medium.com/ai-simplified-in-plain-english/genie-3-a-new-frontier-in-interactive-ai-world-models-89a9be32c0ae?utm_source=chatgpt.com","title":"Genie 3: A New Frontier in Interactive AI World Models","snippet":"At its core, Genie 3 is a general-purpose world model designed to create interactive 3D worlds from simple text prompts. Unlike static image or ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":21},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://medium.com/%40sanderink.ursina/jepa-a-family-of-predictive-architectures-for-human-like-ai-ae9b55e92dc7?utm_source=chatgpt.com","title":"JEPA: A Family of Predictive Architectures for Human-Like AI","snippet":"Joint Embedding Predictive Architectures (JEPA) in 2022: models that learn by predicting high-level embeddings of unseen parts of their input, rather than raw ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":50},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://medium.com/%40LawrencewleKnight/how-vision-language-action-models-are-revolutionizing-robotic-control-a627bbc0c249?utm_source=chatgpt.com","title":"How Vision-Language-Action Models are Revolutionizing ...","snippet":"The research paper introduces the RT-2 model, which is an instantiation of a VLA model. RT-2 uses as its base, Google's VLMs PaLI-X and PALM-E, ...See more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":63},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://medium.com/%40types24digital/deepminds-genie-2-revolutionizing-interactive-3d-world-generation-3dba75b4d86b?utm_source=chatgpt.com","title":"DeepMind's Genie 2: Revolutionizing Interactive 3D World ...","snippet":": The model can transform real-world images into immersive, interactive environments, enabling new levels of creativity and simulation fidelity.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":69},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://medium.com/%40seofai77/openai-sora-the-revolutionary-ai-model-generating-realistic-videos-from-text-6a7f8e6252f5?utm_source=chatgpt.com","title":"OpenAI Sora: The Revolutionary AI Model Generating ...","snippet":"OpenAI Sora is a groundbreaking new AI model that can generate remarkably realistic and imaginative videos directly from text descriptions.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":70},"pub_date":null,"attribution":"medium.com"}]},{"type":"search_result_group","domain":"reddit.com","entries":[{"type":"search_result","url":"https://www.reddit.com/r/math/comments/19fg9rx/some_perspective_on_alphageometry/?utm_source=chatgpt.com","title":"Some perspective on AlphaGeometry : r/math","snippet":"Researchers at DeepMind had created an AI system that solves IMO geometry problems at a level close to that of IMO gold medalists.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":41},"pub_date":null,"attribution":"reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/computervision/comments/14conzp/ijepa_the_first_ai_model_based_on_yann_lecuns/?utm_source=chatgpt.com","title":"I-JEPA: The first AI model based on Yann LeCun's vision ...","snippet":"This paper demonstrates an approach for learning highly semantic image representations without relying on hand-crafted data-augmentations.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":42},"pub_date":null,"attribution":"reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/singularity/comments/15cs38b/google_deepmind_presents_rt2_the_first/?utm_source=chatgpt.com","title":"Google Deepmind presents RT-2, the first vision-language- ...","snippet":"Their research paper is on the first VLA (vision-language-action) Model RT-2 (see paper), a multi-modal algorithm which tokenizes robotic inputs ...See more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":55},"pub_date":null,"attribution":"reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/reinforcementlearning/comments/108t325/dreamv3_mastering_diverse_domains_through_world/?utm_source=chatgpt.com","title":"Mastering Diverse Domains through World Models\", Hafner ...","snippet":"DreamerV3 builds upon the DreamerV2 algorithm27. This section describes the main changes that we applied in order to master a wide range of domains with fixed ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":75},"pub_date":null,"attribution":"reddit.com"},{"type":"search_result","url":"https://www.reddit.com/r/MachineLearning/comments/nyvgqk/r_towards_causal_representation_learning/?utm_source=chatgpt.com","title":"[R] Towards Causal Representation Learning","snippet":"In the present paper, we review fundamental concepts of causal inference and relate them to crucial open problems of machine learning, including transfer and ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"reddit.com"}]},{"type":"search_result_group","domain":"sciencedirect.com","entries":[{"type":"search_result","url":"https://www.sciencedirect.com/science/article/pii/S037015732300203X?utm_source=chatgpt.com","title":"The free energy principle made simpler but not too simple","snippet":"by K Friston \u00b7 2023 \u00b7 Cited by 178 \u2014 This paper provides a concise description of the free energy principle, starting from a formulation of random dynamical systems in terms of ...See more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"sciencedirect.com"},{"type":"search_result","url":"https://www.sciencedirect.com/science/article/pii/S0149763425002970?utm_source=chatgpt.com","title":"A beautiful loop: An active inference theory of consciousness","snippet":"by R Laukkonen \u00b7 2025 \u00b7 Cited by 9 \u2014 Active inference provides a straightforward solution to \u2014 or description of \u2014 how organisms construct a reality model apt for their lived world (Friston, 2006, ......","ref_id":{"turn_index":0,"ref_type":"search","ref_index":43},"pub_date":null,"attribution":"sciencedirect.com"}]},{"type":"search_result_group","domain":"substack.com","entries":[{"type":"search_result","url":"https://neuropurrfectai.substack.com/p/alphageometry-deepminds-mathematical?utm_source=chatgpt.com","title":"How AI Learned to Paint with Geometric Proofs","snippet":"But in 2024, Google DeepMind's AlphaGeometry had made a major breakthrough, achieving near-gold-medal performance on International Mathematical ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":73},"pub_date":null,"attribution":"substack.com"},{"type":"search_result","url":"https://gonzoml.substack.com/p/gflownets?utm_source=chatgpt.com","title":"GFlowNets - by Grigory Sapunov - Gonzo ML","snippet":"GFlowNets, or Generative Flow Networks, a work co-authored by Yoshua Bengio, which he speaks very highly of and considers an important new direction in ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"substack.com"}]},{"type":"search_result_group","domain":"openreview.net","entries":[{"type":"search_result","url":"https://openreview.net/forum?id=lpOC6s4BcM&utm_source=chatgpt.com","title":"Invariance & Causal Representation Learning: Prospects ...","snippet":"by S Bing \u00b7 Cited by 5 \u2014 In this work, we explore this invariance principle as a candidate assumption to achieve identifiability of causal representations.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"openreview.net"}]},{"type":"search_result_group","domain":"imagine.art","entries":[{"type":"search_result","url":"https://www.imagine.art/blogs/google-genie-3-overview?utm_source=chatgpt.com","title":"Google's Genie 3: The Future of AI-Generated Interactive ...","snippet":"Aug 20, 2025 \u2014 This new model can generate interactive, 3D environments from simple text prompts, bringing digital worlds to life in ways that were once the ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"imagine.art"}]},{"type":"search_result_group","domain":"neurips.cc","entries":[{"type":"search_result","url":"https://proceedings.neurips.cc/paper_files/paper/2023/file/27571b74d6cd650b8eb6cf1837953ae8-Paper-Conference.pdf?utm_source=chatgpt.com","title":"Solving Graph Combinatorial Optimization Problems with ...","snippet":"by D Zhang \u00b7 2023 \u00b7 Cited by 108 \u2014 Generative flow networks, or GFlowNets, are variational inference algorithms that treat sampling from a target probability distribution as a sequential decision ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"neurips.cc"}]},{"type":"search_result_group","domain":"yenchenlin.github.io","entries":[{"type":"search_result","url":"https://yenchenlin.github.io/blog/2025/01/08/video-generation-models-explosion-2024/?utm_source=chatgpt.com","title":"Video Generation Models Explosion 2024","snippet":"Jan 8, 2025 \u2014 Video generation models exploded onto the scene in 2024, sparked by the release of Sora from OpenAI. This blog post is my way of keeping track of the progress ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"yenchenlin.github.io"}]},{"type":"search_result_group","domain":"acm.org","entries":[{"type":"search_result","url":"https://dl.acm.org/doi/10.1145/3762179?utm_source=chatgpt.com","title":"Deep Causal Learning: Representation, Discovery and ...","snippet":"by Z Deng \u00b7 2025 \u00b7 Cited by 16 \u2014 In this article, we comprehensively review how deep learning can contribute to causal learning by tackling traditional challenges across ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"acm.org"},{"type":"search_result","url":"https://dl.acm.org/doi/10.5555/3618408.3619689?utm_source=chatgpt.com","title":"Towards understanding and improving GFlowNet training","snippet":"by MW Shen \u00b7 2023 \u00b7 Cited by 73 \u2014 Generative flow networks (GFlowNets) are a family of algorithms that learn a generative policy to sample discrete objects x with non-negative reward R(x).","ref_id":{"turn_index":1,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"acm.org"}]},{"type":"search_result_group","domain":"nature.com","entries":[{"type":"search_result","url":"https://www.nature.com/articles/d41586-024-02441-2?utm_source=chatgpt.com","title":"DeepMind hits milestone in solving maths problems \u2014 AI's ...","snippet":"Jul 25, 2024 \u2014 In their latest effort, the researchers used AlphaGeometry 2 to solve a geometry problem in under 20 seconds. The AI tool is an improved and ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"nature.com"}]},{"type":"search_result_group","domain":"torus.ai","entries":[{"type":"search_result","url":"https://blogs.torus.ai/self-supervised-learning-from-images-with-a-joint-embedding-predictive-architecture-the-latest-paper-from-yann-lecuns-team-at-meta/?utm_source=chatgpt.com","title":"\u201cSelf-Supervised Learning from Images with a Joint- ...","snippet":"Jul 11, 2023 \u2014 I-JEPA is a novel generative method, where the model learns to reconstruct the masked patch of an input image, but instead of a pixel-by-pixel reconstruction.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"torus.ai"}]},{"type":"search_result_group","domain":"rsc.org","entries":[{"type":"search_result","url":"https://pubs.rsc.org/en/content/articlehtml/2023/dd/d3dd00002h?utm_source=chatgpt.com","title":"GFlowNets for AI-driven scientific discovery - RSC Publishing","snippet":"by M Jain \u00b7 2023 \u00b7 Cited by 82 \u2014 A new probabilistic machine learning framework called GFlowNets, which can be applied in the modeling, hypotheses generation and experimental design stages.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"rsc.org"}]},{"type":"search_result_group","domain":"ethz.ch","entries":[{"type":"search_result","url":"https://www.research-collection.ethz.ch/bitstream/handle/20.500.11850/484234/09363924.pdf?sequence=3&utm_source=chatgpt.com","title":"Toward Causal Representation Learning - Research Collection","snippet":"by B Sch\u00f6lkopf \u00b7 2021 \u00b7 Cited by 1837 \u2014 This article reviews fundamental concepts of causal inference and relates them to crucial open problems of machine learning, including transfer learning and ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":19},"pub_date":null,"attribution":"ethz.ch"}]},{"type":"search_result_group","domain":"danijar.com","entries":[{"type":"search_result","url":"https://danijar.com/project/dreamerv3/?utm_source=chatgpt.com","title":"Mastering Diverse Control Tasks through World Models","snippet":"Here we present the third generation of Dreamer, a general algorithm that outperforms specialized methods across over 150 diverse tasks, with a single ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":20},"pub_date":null,"attribution":"danijar.com"}]},{"type":"search_result_group","domain":"blog.google","entries":[{"type":"search_result","url":"https://blog.google/technology/ai/google-deepmind-rt2-robotics-vla-model/?utm_source=chatgpt.com","title":"Speaking robot: Our new AI model translates vision and ...","snippet":"Jul 28, 2023 \u2014 RT-2, our new vision-language-action model, helps robots more easily understand and perform actions \u2014 in both familiar and new situations ...See more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":23},"pub_date":null,"attribution":"blog.google"}]},{"type":"search_result_group","domain":"yoshuabengio.org","entries":[{"type":"search_result","url":"https://yoshuabengio.org/2022/03/05/generative-flow-networks/?utm_source=chatgpt.com","title":"Generative Flow Networks - Yoshua Bengio -","snippet":"Mar 5, 2022 \u2014 We call them GFlowNets, for Generative Flow Networks. They live somewhere at the intersection of reinforcement learning, deep generative models and energy- ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":24},"pub_date":null,"attribution":"yoshuabengio.org"}]},{"type":"search_result_group","domain":"oxen.ai","entries":[{"type":"search_result","url":"https://ghost.oxen.ai/arxiv-dives-i-jepa/?utm_source=chatgpt.com","title":"ArXiv Dives: I-JEPA","snippet":"Mar 26, 2024 \u2014 This paper demonstrates an approach for learning highly semantic image representations without relying on hand-crafted data-augmentations.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":26},"pub_date":null,"attribution":"oxen.ai"}]},{"type":"search_result_group","domain":"researchgate.net","entries":[{"type":"search_result","url":"https://www.researchgate.net/publication/359572945_Active_Inference_The_Free_Energy_Principle_in_Mind_Brain_and_Behavior?utm_source=chatgpt.com","title":"Active Inference: The Free Energy Principle in Mind, Brain, ...","snippet":"Active inference is a \u201cfirst principles\u201d approach to understanding behavior and the brain, framed in terms of a single imperative to minimize free energy. The ...See more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":27},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/367019841_Mastering_Diverse_Domains_through_World_Models?utm_source=chatgpt.com","title":"(PDF) Mastering Diverse Domains through World Models","snippet":"10 Jan 2023 \u2014 Recent work in model-based RL have shown that scaling the world model achieves significant improvements (Hafner et al., 2023; Hansen et al., ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":28},"pub_date":null,"attribution":"researchgate.net"}]},{"type":"search_result_group","domain":"marketingaiinstitute.com","entries":[{"type":"search_result","url":"https://www.marketingaiinstitute.com/blog/google-genie-3?utm_source=chatgpt.com","title":"Google DeepMind's Genie 3 Could Be the Virtual World ...","snippet":"Aug 12, 2025 \u2014 Google just pulled back the curtain on Genie 3, a photorealistic \u201cworld model\u201d that can conjure interactive environments straight from a text","ref_id":{"turn_index":0,"ref_type":"search","ref_index":29},"pub_date":null,"attribution":"marketingaiinstitute.com"}]},{"type":"search_result_group","domain":"duality.ai","entries":[{"type":"search_result","url":"https://www.duality.ai/blog/sora?utm_source=chatgpt.com","title":"Can SORA's Visually Amazing Videos Train Other ...","snippet":"Mar 7, 2024 \u2014 The video examples generated by SORA, recently showcased by OpenAI, are varied; impressive in their visual fidelity; and temporally coherent.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":30},"pub_date":null,"attribution":"duality.ai"}]},{"type":"search_result_group","domain":"github.com","entries":[{"type":"search_result","url":"https://github.com/kyegomez/RT-2?utm_source=chatgpt.com","title":"GitHub - kyegomez/RT-2","snippet":"RT-2 stands at the intersection of vision, language, and action, delivering unmatched capabilities and significant benefits for the world of robotics.See more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":31},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/zdhNarsil/Awesome-GFlowNets?utm_source=chatgpt.com","title":"zdhNarsil/Awesome-GFlowNets","snippet":"Moksh Jain, et al. The GFlowNet Tutorial [high level introduction] Yoshua Bengio. GFlowNet Tutorial [PRACTICAL colab notebook] Emmanuel Bengio. Paper.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":32},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/google-deepmind/alphageometry?utm_source=chatgpt.com","title":"google-deepmind/alphageometry","snippet":"This repository contains the code necessary to reproduce DDAR and AlphaGeometry, the two geometry theorem provers introduced in the Nature 2024 paper.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":57},"pub_date":null,"attribution":"github.com"}]},{"type":"search_result_group","domain":"facebook.com","entries":[{"type":"search_result","url":"https://www.facebook.com/groups/DeepNetGroup/posts/2119344128458458/?utm_source=chatgpt.com","title":"**AlphaGeometry: An Olympiad-level AI system for geometry","snippet":"We propose AlphaGeometry, a theorem prover for Euclidean plane geometry that sidesteps the need for human demonstrations by synthesizing ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":33},"pub_date":null,"attribution":"facebook.com"}]},{"type":"search_result_group","domain":"encord.com","entries":[{"type":"search_result","url":"https://encord.com/blog/i-jepa-explained/?utm_source=chatgpt.com","title":"Meta AI's I-JEPA Explained","snippet":"Jun 14, 2023 \u2014 Image-based Joint Embedding Predictive Architecture (I-JEPA) is a non-generative approach for self-supervised learning from images. This aims to ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":34},"pub_date":null,"attribution":"encord.com"}]},{"type":"search_result_group","domain":"frontiersin.org","entries":[{"type":"search_result","url":"https://www.frontiersin.org/journals/neurorobotics/articles/10.3389/fnbot.2022.844773/full?utm_source=chatgpt.com","title":"The Problem of Meaning: The Free Energy Principle and ...","snippet":"by J Kiverstein \u00b7 2022 \u00b7 Cited by 48 \u2014 Active inference describes the process of selecting actions that minimize free energy over time. Could active inference models based on the FEP be used to ...See...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":35},"pub_date":null,"attribution":"frontiersin.org"}]},{"type":"search_result_group","domain":"vitalab.github.io","entries":[{"type":"search_result","url":"https://vitalab.github.io/article/2023/01/19/DreamerV3.html?utm_source=chatgpt.com","title":"DreamerV3: Mastering Diverse Domains through World Models","snippet":"19 Jan 2023 \u2014 Model-based reinforcement learning is a type of RL where the agent will not only learn a policy, but also a world model which the agent can use to plan ahead.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":36},"pub_date":null,"attribution":"vitalab.github.io"}]},{"type":"search_result_group","domain":"analyticsvidhya.com","entries":[{"type":"search_result","url":"https://www.analyticsvidhya.com/blog/2024/12/genie-2/?utm_source=chatgpt.com","title":"Genie 2: The Next-Generation Foundation Model for 3D ...","snippet":"May 9, 2025 \u2014 Genie 2 is a groundbreaking generative AI model that creates dynamic 3D action-controllable worlds from simple image prompts.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":37},"pub_date":null,"attribution":"analyticsvidhya.com"}]},{"type":"search_result_group","domain":"viso.ai","entries":[{"type":"search_result","url":"https://viso.ai/deep-learning/openai-sora/?utm_source=chatgpt.com","title":"OpenAI Sora: Transform Text to Video Seamlessly","snippet":"Mar 12, 2024 \u2014 Sora is a text-to-video artificial intelligence model developed by OpenAI that can create realistic and imaginative scenes from text instructions.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":38},"pub_date":null,"attribution":"viso.ai"}]},{"type":"search_result_group","domain":"notion.site","entries":[{"type":"search_result","url":"https://milayb.notion.site/The-GFlowNet-Tutorial-95434ef0e2d94c24aab90e69b30be9b3?utm_source=chatgpt.com","title":"The GFlowNet Tutorial","snippet":"A GFlowNet is a trained stochastic policy or generative model, trained such that it samples objects x x x\ufeff through a sequence of constructive steps, with ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":40},"pub_date":null,"attribution":"notion.site"}]},{"type":"search_result_group","domain":"google.com","entries":[{"type":"search_result","url":"https://scholar.google.com/citations?hl=en&user=VINmGpYAAAAJ&utm_source=chatgpt.com","title":"Danijar Hafner","snippet":"Mastering Diverse Domains through World Models. D Hafner, J Pasukonis, J Ba, T Lillicrap. arXiv preprint arXiv:2301.04104, 2023. 990, 2023 ; Planning to Explore ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":44},"pub_date":null,"attribution":"google.com"}]},{"type":"search_result_group","domain":"skywork.ai","entries":[{"type":"search_result","url":"https://skywork.ai/skypage/en/Genie%203%3A%20My%20Deep%20Dive%20into%20Google%E2%80%99s%20Real-Time%20AI%20World%20Builder/1975582077712658432?utm_source=chatgpt.com","title":"Genie 3: My Deep Dive into Google's Real-Time AI World ...","snippet":"Oct 10, 2025 \u2014 Genie 3 is a general-purpose \"world model\" from Google DeepMind that generates interactive, navigable 3D environments from text prompts in real- ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":45},"pub_date":null,"attribution":"skywork.ai"}]},{"type":"search_result_group","domain":"aimagazine.com","entries":[{"type":"search_result","url":"https://aimagazine.com/news/openais-sora-2-redefining-safe-physics-driven-video-ai?utm_source=chatgpt.com","title":"OpenAI's Sora 2: Redefining Safe, Physics\u2011Driven Video AI","snippet":"Oct 1, 2025 \u2014 \u201cThe Sora team has been focused on training models with more advanced world simulation capabilities,\u201d the team writes in an OpenAI blog post.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":46},"pub_date":null,"attribution":"aimagazine.com"}]},{"type":"search_result_group","domain":"danmackinlay.name","entries":[{"type":"search_result","url":"https://danmackinlay.name/notebook/nn_gflow?utm_source=chatgpt.com","title":"Generative flow nets - Dan MacKinlay","snippet":"Bengio, Emmanuel, Jain, Korablyov, et al. 2021. \u201cFlow Network Based Generative Models for Non-Iterative Diverse Candidate Generation.\u201d In ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":48},"pub_date":null,"attribution":"danmackinlay.name"}]},{"type":"search_result_group","domain":"lesswrong.com","entries":[{"type":"search_result","url":"https://www.lesswrong.com/posts/GGLpjugLQv6TupQgS/alphageometry-an-olympiad-level-ai-system-for-geometry?utm_source=chatgpt.com","title":"AlphaGeometry: An Olympiad-level AI system for geometry","snippet":"Jan 17, 2024 \u2014 In a paper published today in Nature, we introduce AlphaGeometry, an AI system that solves complex geometry problems at a level approaching ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":49},"pub_date":null,"attribution":"lesswrong.com"}]},{"type":"search_result_group","domain":"oup.com","entries":[{"type":"search_result","url":"https://academic.oup.com/nc/article/2025/1/niaf009/8117684?utm_source=chatgpt.com","title":"How do inner screens enable imaginative experience ...","snippet":"by C Fields \u00b7 2025 \u00b7 Cited by 5 \u2014 This paper examines the constraints that the free-energy principle (FEP) places on possible model of consciousness, particularly models of attentional control ...See...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":51},"pub_date":null,"attribution":"oup.com"}]},{"type":"search_result_group","domain":"umass.edu","entries":[{"type":"search_result","url":"https://rlj.cs.umass.edu/2024/papers/RLJ_RLC_2024_167.pdf?utm_source=chatgpt.com","title":"Learning Contextual World Models Aids Zero-Shot ...","snippet":"by S Prasanna \u00b7 Cited by 13 \u2014 We now discuss how we incorporate context into the Dreamer (v3) (Hafner et al., 2023) algorithm. We first introduce our novel approach to contextual dreaming ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":52},"pub_date":null,"attribution":"umass.edu"}]},{"type":"search_result_group","domain":"bdtechtalks.com","entries":[{"type":"search_result","url":"https://bdtechtalks.com/2025/08/07/deepmind-genie-3/?utm_source=chatgpt.com","title":"The promise and limitations of DeepMind's Genie 3","snippet":"Aug 7, 2025 \u2014 Google DeepMind has announced Genie 3, a general-purpose world model capable of generating interactive, navigable environments from a text ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":53},"pub_date":null,"attribution":"bdtechtalks.com"}]},{"type":"search_result_group","domain":"umontreal.ca","entries":[{"type":"search_result","url":"https://www.iro.umontreal.ca/~slacoste/teaching/ift6269/A24/notes/lecture23_slides.pdf?utm_source=chatgpt.com","title":"An Introduction to Generative Flow Networks","snippet":"Emmanuel Bengio, et al. NeurIPS 2021. \u25cb [Structure Learning with GFlowNets] Bayesian Structure Learning with \u00b7 Generative Flow Networks. Tristan Deleu, et al.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":56},"pub_date":null,"attribution":"umontreal.ca"}]},{"type":"search_result_group","domain":"meta.com","entries":[{"type":"search_result","url":"https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/?utm_source=chatgpt.com","title":"V-JEPA: The next step toward advanced machine ...","snippet":"Feb 15, 2024 \u2014 V-JEPA is a non-generative model that learns by predicting missing or masked parts of a video in an abstract representation space.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":58},"pub_date":null,"attribution":"meta.com"}]},{"type":"search_result_group","domain":"goodreads.com","entries":[{"type":"search_result","url":"https://www.goodreads.com/book/show/58275959?utm_source=chatgpt.com","title":"Active Inference: The Free Energy Principle in Mind, Brain, ...","snippet":"This book offers the first comprehensive treatment of active inference, covering theory, applications, and cognitive domains.See more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":59},"pub_date":null,"attribution":"goodreads.com"}]},{"type":"search_result_group","domain":"scholaris.ca","entries":[{"type":"search_result","url":"https://utoronto.scholaris.ca/bitstreams/8a278445-a1ce-4a53-9275-4f1a0c6739b9/download?utm_source=chatgpt.com","title":"Embodied Intelligence Through World Models","snippet":"by D Hafner \u00b7 2024 \u00b7 Cited by 1 \u2014 World models help humans predict outcomes. This thesis focuses on equipping computers with algorithms to learn these models from unstructured inputs for ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":60},"pub_date":null,"attribution":"scholaris.ca"}]},{"type":"search_result_group","domain":"pregrad.in","entries":[{"type":"search_result","url":"https://blog.pregrad.in/google-deepmind-launches-genie-3-google-ai-model/?utm_source=chatgpt.com","title":"Google AI Model Which Can Create Realistic Worlds","snippet":"Aug 7, 2025 \u2014 This model not just generates images or videos, it creates playable worlds where agents and users can walk, look around, interact and even ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":61},"pub_date":null,"attribution":"pregrad.in"}]},{"type":"search_result_group","domain":"xunhuang.me","entries":[{"type":"search_result","url":"https://www.xunhuang.me/blogs/world_model.html?utm_source=chatgpt.com","title":"Towards Video World Models","snippet":"Jul 11, 2025 \u2014 Exploring the path from video generation to true video world models through causality, interactivity, persistence, real-time responsiveness, ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":62},"pub_date":null,"attribution":"xunhuang.me"}]},{"type":"search_result_group","domain":"itnext.io","entries":[{"type":"search_result","url":"https://itnext.io/i-jepa-self-supervised-learning-from-images-with-a-joint-embedding-predictive-architecture-e896c73e011a?utm_source=chatgpt.com","title":"I-JEPA: Self-Supervised Learning from Images with a Joint ...","snippet":"Aug 11, 2023 \u2014 This paper from Meta proposes a self-supervised technique which tries to learn highly semantic image features without relying on hand-crafted augmentations.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":66},"pub_date":null,"attribution":"itnext.io"}]},{"type":"search_result_group","domain":"springer.com","entries":[{"type":"search_result","url":"https://link.springer.com/article/10.1007/s10539-022-09864-z?utm_source=chatgpt.com","title":"Free energy: a user's guide | Biology & Philosophy","snippet":"by SF Mann \u00b7 2022 \u00b7 Cited by 23 \u2014 Active inference, whose most famous tenet is the free energy principle, purports to unify explanations in biology and cognitive science ...See more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":67},"pub_date":null,"attribution":"springer.com"}]},{"type":"search_result_group","domain":"ws-dl.blogspot.com","entries":[{"type":"search_result","url":"https://ws-dl.blogspot.com/2023/08/2023-08-11-paper-summary-mastering.html?utm_source=chatgpt.com","title":"2023-08-11: Paper Summary: \"Mastering Diverse Domains ...","snippet":"11 Aug 2023 \u2014 To address these issues, Hafner et al. have developed DreamerV3, a general and scalable algorithm that outperforms specialized algorithms by ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":68},"pub_date":null,"attribution":"ws-dl.blogspot.com"}]},{"type":"search_result_group","domain":"wikipedia.org","entries":[{"type":"search_result","url":"https://en.wikipedia.org/wiki/Vision-language-action_model?utm_source=chatgpt.com","title":"Vision-language-action model","snippet":"The concept was pioneered in July 2023 by Google DeepMind with RT-2, a VLM adapted for end-to-end manipulation tasks, capable of unifying perception, reasoning ...See more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":71},"pub_date":null,"attribution":"wikipedia.org"}]},{"type":"search_result_group","domain":"rohitbandaru.github.io","entries":[{"type":"search_result","url":"https://rohitbandaru.github.io/blog/JEPA-Deep-Dive/?utm_source=chatgpt.com","title":"Deep Dive into Yann LeCun's JEPA - Rohit Bandaru","snippet":"Jul 31, 2024 \u2014 This blog post will dive deep into Yann's vision for AI, the JEPA architecture, current research, and energy based models.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":74},"pub_date":null,"attribution":"rohitbandaru.github.io"}]},{"type":"search_result_group","domain":"neuroai.science","entries":[{"type":"search_result","url":"https://www.neuroai.science/p/gflownets-sampling-on-sets-and-graphs?utm_source=chatgpt.com","title":"Gflownets: sampling on sets & graphs - The NeuroAI archive","snippet":"Nov 13, 2023 \u2014 Gflownets, short for generative flow network, are a class of algorithms for sampling from a probability distribution.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":76},"pub_date":null,"attribution":"neuroai.science"}]}],"citations":[],"request_id":"wfr_019a174aa1157f22922d445953a10293","message_type":"next","model_slug":"gpt-5-pro","default_model_slug":"gpt-5-pro","parent_id":"b9b74983-cc20-4a40-b1bb-093fd4158822","timestamp_":"absolute","can_save":true},"recipient":"all","channel":"final"},"parent":"b9b74983-cc20-4a40-b1bb-093fd4158822","children":[]}}}