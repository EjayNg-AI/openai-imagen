{"id":"6956490d-a058-8320-9643-ecb2dd7ebdc3","title":"Continual Learning in AI","create_time":1767262510.467634,"update_time":1767262732.085499,"current_node":"b72bbed9-55b4-4e3a-8e99-342bb5080995","mapping":{"client-created-root":{"id":"client-created-root","message":null,"parent":null,"children":["d8d32db7-5ff7-44cf-86c0-42337dc54141"]},"d8d32db7-5ff7-44cf-86c0-42337dc54141":{"id":"d8d32db7-5ff7-44cf-86c0-42337dc54141","message":{"id":"d8d32db7-5ff7-44cf-86c0-42337dc54141","author":{"role":"system","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":true,"weight":0.0,"metadata":{"is_visually_hidden_from_conversation":true},"recipient":"all","channel":null},"parent":"client-created-root","children":["f8e6a2fc-9074-41ad-ad53-7a3f86dad68b"]},"f8e6a2fc-9074-41ad-ad53-7a3f86dad68b":{"id":"f8e6a2fc-9074-41ad-ad53-7a3f86dad68b","message":{"id":"f8e6a2fc-9074-41ad-ad53-7a3f86dad68b","author":{"role":"system","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":true,"weight":0.0,"metadata":{"rebase_developer_message":true,"is_visually_hidden_from_conversation":true},"recipient":"all","channel":null},"parent":"d8d32db7-5ff7-44cf-86c0-42337dc54141","children":["53d3e97e-728b-4f38-a27d-2940b36e52ab"]},"53d3e97e-728b-4f38-a27d-2940b36e52ab":{"id":"53d3e97e-728b-4f38-a27d-2940b36e52ab","message":{"id":"53d3e97e-728b-4f38-a27d-2940b36e52ab","author":{"role":"user","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"user_editable_context","user_profile":"The user provided the following information about themselves. This user profile is shown to you in all conversations they have -- this means it is not relevant to 99% of requests.\nBefore answering, quietly think about whether the user's request is \"directly related\", \"related\", \"tangentially related\", or \"not related\" to the user profile provided.\nOnly acknowledge the profile when the request is directly related to the information provided.\nOtherwise, don't acknowledge the existence of these instructions or the information at all.\nUser profile:\n```Preferred name: E-Jay\nRole: Mathematics Researcher\nOther Information: About Myself: \nI have mathematical knowledge up to graduate level.\n\nCurrent interests:\n(1) coding: mainly Python\n(2) machine learning and artificial intelligence\n```","user_instructions":"The user provided the additional info about how they would like you to respond:\n```Follow the instructions below naturally, without repeating, referencing, echoing, or mirroring any of their wording!\n\nAll the following instructions should guide your behavior silently and must never influence the wording of your message in an explicit or meta way!\n\nBe precise and comprehensive in your analysis. Don't sugar-coat responses. Be as objective as possible. Critique and question my views if necessary. Take a forward-thinking view.\n\nDefine highly technical or specialized abbreviations in full before using them.```"},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"is_visually_hidden_from_conversation":true,"user_context_message_data":{"about_user_message":"Preferred name: E-Jay\nRole: Mathematics Researcher\nOther Information: About Myself: \nI have mathematical knowledge up to graduate level.\n\nCurrent interests:\n(1) coding: mainly Python\n(2) machine learning and artificial intelligence\n","about_model_message":"Be precise and comprehensive in your analysis. Don't sugar-coat responses. Be as objective as possible. Critique and question my views if necessary. Take a forward-thinking view.\n\nDefine highly technical or specialized abbreviations in full before using them."},"is_user_system_message":true},"recipient":"all","channel":null},"parent":"f8e6a2fc-9074-41ad-ad53-7a3f86dad68b","children":["6f9a5c59-4fe9-49df-a311-422f35e0988f"]},"6f9a5c59-4fe9-49df-a311-422f35e0988f":{"id":"6f9a5c59-4fe9-49df-a311-422f35e0988f","message":{"id":"6f9a5c59-4fe9-49df-a311-422f35e0988f","author":{"role":"system","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"is_contextual_answers_system_message":true,"contextual_answers_message_type":"identity_prompt","is_visually_hidden_from_conversation":true},"recipient":"all","channel":null},"parent":"53d3e97e-728b-4f38-a27d-2940b36e52ab","children":["7fb41202-7333-44e8-a694-ee2c59204f29"]},"7fb41202-7333-44e8-a694-ee2c59204f29":{"id":"7fb41202-7333-44e8-a694-ee2c59204f29","message":{"id":"7fb41202-7333-44e8-a694-ee2c59204f29","author":{"role":"user","name":null,"metadata":{}},"create_time":1767262508.806,"update_time":null,"content":{"content_type":"text","parts":["Investigate the latest advances in the continual learning paradigm in frontier generative AI models."]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"developer_mode_connector_ids":[],"selected_sources":[],"selected_github_repos":[],"serialization_metadata":{"custom_symbol_offsets":[]},"request_id":"5f3f0455-8a59-45eb-a9c3-284af86d3bb4","message_source":null,"turn_exchange_id":"b62969f7-f59e-4e1e-9b90-3e7bb7097612"},"recipient":"all","channel":null},"parent":"6f9a5c59-4fe9-49df-a311-422f35e0988f","children":["b078164d-0153-40e9-b5d4-619ff960375c"]},"b078164d-0153-40e9-b5d4-619ff960375c":{"id":"b078164d-0153-40e9-b5d4-619ff960375c","message":{"id":"b078164d-0153-40e9-b5d4-619ff960375c","author":{"role":"system","name":null,"metadata":{}},"create_time":1767262510.1249235,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"is_contextual_answers_system_message":true,"is_visually_hidden_from_conversation":true,"command":"prompt","contextual_answers_message_type":"sources_and_filters_prompt","request_id":"5f3f0455-8a59-45eb-a9c3-284af86d3bb4","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"7fb41202-7333-44e8-a694-ee2c59204f29","turn_exchange_id":"b62969f7-f59e-4e1e-9b90-3e7bb7097612"},"recipient":"all","channel":null},"parent":"7fb41202-7333-44e8-a694-ee2c59204f29","children":["6b3c6351-fd09-4ea5-b993-f63c896a375d"]},"6b3c6351-fd09-4ea5-b993-f63c896a375d":{"id":"6b3c6351-fd09-4ea5-b993-f63c896a375d","message":{"id":"6b3c6351-fd09-4ea5-b993-f63c896a375d","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1767262510.4547439,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"request_id":"5f3f0455-8a59-45eb-a9c3-284af86d3bb4","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"b078164d-0153-40e9-b5d4-619ff960375c","turn_exchange_id":"b62969f7-f59e-4e1e-9b90-3e7bb7097612"},"recipient":"all","channel":null},"parent":"b078164d-0153-40e9-b5d4-619ff960375c","children":["dc4efa65-7896-456a-bad1-78c77dbcde4b"]},"dc4efa65-7896-456a-bad1-78c77dbcde4b":{"id":"dc4efa65-7896-456a-bad1-78c77dbcde4b","message":{"id":"dc4efa65-7896-456a-bad1-78c77dbcde4b","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1767262511.107204,"update_time":null,"content":{"content_type":"thoughts","thoughts":[],"source_analysis_msg_id":"190d4a5f-3e17-4c28-92c4-b335e123c56d"},"status":"in_progress","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"is_reasoning","citations":[],"content_references":[],"classifier_response":"default","skip_reasoning_title":"Skip","request_id":"5f3f0455-8a59-45eb-a9c3-284af86d3bb4","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"6b3c6351-fd09-4ea5-b993-f63c896a375d","turn_exchange_id":"b62969f7-f59e-4e1e-9b90-3e7bb7097612"},"recipient":"all","channel":null},"parent":"6b3c6351-fd09-4ea5-b993-f63c896a375d","children":["f1ac7882-6c57-43a2-905b-100cd9463d49"]},"f1ac7882-6c57-43a2-905b-100cd9463d49":{"id":"f1ac7882-6c57-43a2-905b-100cd9463d49","message":{"id":"f1ac7882-6c57-43a2-905b-100cd9463d49","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1767262510.163235,"update_time":null,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"{\"search_query\":[{\"q\":\"2025 continual learning large language models catastrophic forgetting replay parameter efficient fine-tuning online updates\",\"recency\":30},{\"q\":\"2025 2024 continual learning generative models diffusion transformers rehearsal regularization survey\",\"recency\":365},{\"q\":\"2025 'continual pretraining' language model streaming data paper\",\"recency\":365},{\"q\":\"2025 'online learning' 'RLHF' continual alignment model update without forgetting paper\",\"recency\":365}],\"response_length\":\"long\"}"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200012]},"is_complete":true,"citations":[],"content_references":[],"reasoning_status":"is_reasoning","search_queries":[{"type":"search","q":"2025 continual learning large language models catastrophic forgetting replay parameter efficient fine-tuning online updates"},{"type":"search","q":"2025 2024 continual learning generative models diffusion transformers rehearsal regularization survey"},{"type":"search","q":"2025 'continual pretraining' language model streaming data paper"},{"type":"search","q":"2025 'online learning' 'RLHF' continual alignment model update without forgetting paper"}],"search_display_string":"Searching the web...","searched_display_string":"Searched the web...","reasoning_title":"Browsing for latest advances in continual learning AI","classifier_response":"default","request_id":"5f3f0455-8a59-45eb-a9c3-284af86d3bb4","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"dc4efa65-7896-456a-bad1-78c77dbcde4b","turn_exchange_id":"b62969f7-f59e-4e1e-9b90-3e7bb7097612"},"recipient":"web.run","channel":null},"parent":"dc4efa65-7896-456a-bad1-78c77dbcde4b","children":["b45709fa-0d86-494a-b11f-e40fa2032fd1"]},"b45709fa-0d86-494a-b11f-e40fa2032fd1":{"id":"b45709fa-0d86-494a-b11f-e40fa2032fd1","message":{"id":"b45709fa-0d86-494a-b11f-e40fa2032fd1","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1767262516.8333895,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_model_queries":{"type":"search_model_queries","queries":["2025 continual learning large language models catastrophic forgetting replay parameter efficient fine-tuning online updates","2025 2024 continual learning generative models diffusion transformers rehearsal regularization survey","2025 'continual pretraining' language model streaming data paper","2025 'online learning' 'RLHF' continual alignment model update without forgetting paper"]},"reasoning_status":"is_reasoning","reasoning_title":"Browsing for latest advances in continual learning AI","classifier_response":"default","request_id":"5f3f0455-8a59-45eb-a9c3-284af86d3bb4","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"f1ac7882-6c57-43a2-905b-100cd9463d49","turn_exchange_id":"b62969f7-f59e-4e1e-9b90-3e7bb7097612"},"recipient":"all","channel":null},"parent":"f1ac7882-6c57-43a2-905b-100cd9463d49","children":["b4e22920-63d3-427d-8898-93690a45ecfb"]},"b4e22920-63d3-427d-8898-93690a45ecfb":{"id":"b4e22920-63d3-427d-8898-93690a45ecfb","message":{"id":"b4e22920-63d3-427d-8898-93690a45ecfb","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1767262516.8285394,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_result_groups":[{"type":"search_result_group","domain":"arxiv.org","entries":[{"type":"search_result","url":"https://arxiv.org/html/2504.13822v2","title":"Parameter-Efficient Continual Fine-Tuning: A Survey","snippet":"19 Aug 2025 \u2014 This problem is known as catastrophic forgetting [108] and is the core challenge of CL. Theoretically, consequential re-training and adapting to ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":0},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2506.13045v3","title":"A Comprehensive Survey on Continual Learning in ...","snippet":"19 Jun 2025 \u2014 In this work, we present a comprehensive survey of continual learning methods for mainstream generative models, encompassing large language ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2506.03320","title":"The Future of Continual Learning in the Era of Foundation ...","snippet":"by J Bell \u00b7 2025 \u00b7 Cited by 8 \u2014 In this paper, we first review Continual Pre-Training (4.1), which equips large-scale foundational models with adaptive, resource-efficient mechanisms to ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":3},"pub_date":1749749834.0,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2402.17400","title":"Investigating Continual Pretraining in Large Language ...","snippet":"by \u00c7 Y\u0131ld\u0131z \u00b7 2024 \u00b7 Cited by 55 \u2014 Our research establishes a new benchmark for CL in LLMs, providing a more realistic evaluation of knowledge retention and transfer across diverse domains.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2509.17183v1","title":"LifeAlign: Lifelong Alignment for Large Language Models ...","snippet":"21 Sept 2025 \u2014 Lifelong learning for LLMs seeks to enable models to absorb an ongoing stream of data without suffering catastrophic forgetting. As ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":31},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2505.07796","title":"Learning Dynamics in Continual Pre-Training for Large ...","snippet":"by X Wang \u00b7 2025 \u00b7 Cited by 8 \u2014 In this work, we explore the learning dynamics throughout the CPT process for large language models. We specifically focus on how general and downstream domain ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":33},"pub_date":null,"attribution":"arxiv.org"}]},{"type":"search_result_group","domain":"aclanthology.org","entries":[{"type":"search_result","url":"https://aclanthology.org/2025.acl-long.289.pdf","title":"Towards Effective and Efficient Continual Pre-training of ...","snippet":"by J Chen \u00b7 2025 \u00b7 Cited by 20 \u2014 In this paper, we present a completely trans- parent procedure for continually pre-training the open-sourced LLM\u2014Llama-3 (8B), with all exper-.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":2},"pub_date":1752152997.0,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2025.naacl-industry.25/","title":"Efficient Continual Pre-training of LLMs for Low-resource ...","snippet":"by A Nag \u00b7 2025 \u00b7 Cited by 7 \u2014 We first develop a new algorithm to select a subset of texts from a larger corpus. We show the effectiveness of our technique using very little CPT data.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2025.emnlp-main.1108.pdf","title":"Mitigating Catastrophic Forgetting in Large Language ...","snippet":"by W Huang \u00b7 2025 \u2014 Can we solve the problem of catastrophic forget- ting without changing training process, without any additional data, and without altering model.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":18},"pub_date":1761174564.0,"attribution":"aclanthology.org"}]},{"type":"search_result_group","domain":"openreview.net","entries":[{"type":"search_result","url":"https://openreview.net/forum?id=ScI7IlKGdI","title":"Spurious Forgetting in Continual Learning of Language ...","snippet":"by J Zheng \u00b7 Cited by 29 \u2014 The paper analyzes the phenomenon of catastrophic forgetting in the continual learning of language models. The authors argue that this forgetting stems from a ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/forum?id=Vk1rNMl0J1","title":"Learning Dynamics in Continual Pre-Training for Large ...","snippet":"by X Wang \u00b7 Cited by 8 \u2014 The paper analyzes and models learning dynamics in CPT of large language models, focusing on performance evolution across general and downstream ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/forum?id=J5sUOvlLbQ&noteId=PYWNZ0NC7L","title":"LiNeS: Post-training Layer Scaling Prevents Forgetting and ...","snippet":"23 Dec 2024 \u2014 This paper introduces a post-training editing technique, LiNeS, designed to address catastrophic forgetting and facilitate model merging after ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"openreview.net"}]},{"type":"search_result_group","domain":"www.arxiv.org","entries":[{"type":"search_result","url":"https://www.arxiv.org/pdf/2506.13045v2","title":"A Comprehensive Survey on Continual Learning in ...","snippet":"18 Jun 2025 \u2014 In this work, we present a comprehensive survey of continual learning methods for mainstream generative models, encompassing large language ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"www.arxiv.org"},{"type":"search_result","url":"https://www.arxiv.org/pdf/2504.13822","title":"Parameter-Efficient Continual Fine-Tuning: A Survey","snippet":"by EN Coleman \u00b7 2025 \u00b7 Cited by 5 \u2014 This problem is known as catastrophic forgetting [108] and is the core challenge of CL. Theoretically, consequential re-training and adapting to ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":21},"pub_date":null,"attribution":"www.arxiv.org"}]},{"type":"search_result_group","domain":"dl.acm.org","entries":[{"type":"search_result","url":"https://dl.acm.org/doi/10.1145/3735633","title":"Continual Learning of Large Language Models","snippet":"20 Nov 2025 \u2014 Examining Forgetting in Continual Pre-training of Aligned Large Language Models. ... Online Continual Learning Without the Storage Constraint.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"dl.acm.org"},{"type":"search_result","url":"https://dl.acm.org/doi/10.1145/3746027.3755302","title":"Forward-Only Continual Learning | Proceedings of the 33rd ...","snippet":"27 Oct 2025 \u2014 Catastrophic forgetting remains a central challenge in continual learning (CL) with pre-trained models. While existing approaches typically ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"dl.acm.org"},{"type":"search_result","url":"https://dl.acm.org/doi/abs/10.1145/3735633","title":"Continual Learning of Large Language Models","snippet":"by H Shi \u00b7 Cited by 175 \u2014 This survey sheds light on the relatively understudied domain of continually pre-training, adapting, and fine-tuning large language models.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":20},"pub_date":null,"attribution":"dl.acm.org"},{"type":"search_result","url":"https://dl.acm.org/doi/full/10.1145/3716629","title":"Towards Lifelong Learning of Large Language Models","snippet":"by J Zheng \u00b7 2025 \u00b7 Cited by 79 \u2014 Our survey explores the landscape of lifelong learning, categorizing strategies into two groups based on how new knowledge is integrated.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":32},"pub_date":null,"attribution":"dl.acm.org"}]},{"type":"search_result_group","domain":"github.com","entries":[{"type":"search_result","url":"https://github.com/Wang-ML-Lab/llm-continual-learning-survey","title":"Continual Learning of Large Language Models: A ...","snippet":"Overcoming Catastrophic Forgetting in Massively Multilingual Continual Learning ... Investigating the Catastrophic Forgetting in Multimodal Large Language Models ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/xialeiliu/Awesome-Incremental-Learning","title":"xialeiliu/Awesome-Incremental-Learning","snippet":"Continual Learning for VLMs: A Survey and Taxonomy Beyond Forgetting (arXiv 2025) [ \u00b7 Continual Learning With Knowledge Distillation: A Survey (TNNLS 2024) [ ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":19},"pub_date":null,"attribution":"github.com"}]},{"type":"search_result_group","domain":"iclr.cc","entries":[{"type":"search_result","url":"https://iclr.cc/virtual/2025/papers.html","title":"ICLR 2025 Papers","snippet":"Glauber Generative Model: Discrete Diffusion Models via Binary Classification ... Dynamical Diffusion: Learning Temporal Dynamics with Diffusion Models ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"iclr.cc"}]},{"type":"search_result_group","domain":"mdpgroup.com","entries":[{"type":"search_result","url":"https://mdpgroup.com/en/blog/why-continual-learning-is-imperative/","title":"Continual Learning in Large Language Models","snippet":"7 days ago \u2014 Overcoming Catastrophic Forgetting. A core failure mode of sequential training is catastrophic forgetting: when a model is updated on new ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":11},"pub_date":1766672326.0,"attribution":"mdpgroup.com"}]},{"type":"search_result_group","domain":"icml.cc","entries":[{"type":"search_result","url":"https://icml.cc/virtual/2025/papers.html","title":"ICML 2025 Papers","snippet":"FedSSI: Rehearsal-Free Continual Federated Learning with Synergistic Synaptic Intelligence ... Learning Single Index Models with Diffusion Priors \u00b7 Neural ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"icml.cc"}]},{"type":"search_result_group","domain":"magazine.sebastianraschka.com","entries":[{"type":"search_result","url":"https://magazine.sebastianraschka.com/p/state-of-llms-2025","title":"The State Of LLMs 2025: Progress, Problems, and Predictions","snippet":"2 days ago \u2014 A 2025 review of large language models, from DeepSeek R1 and RLVR to inference-time scaling, benchmarks, architectures, and predictions for ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":13},"pub_date":1767097346.0,"attribution":"magazine.sebastianraschka.com"}]},{"type":"search_result_group","domain":"neurips.cc","entries":[{"type":"search_result","url":"https://neurips.cc/virtual/2025/papers.html","title":"NeurIPS 2025 Papers","snippet":"GenPO: Generative Diffusion Models Meet On-Policy Reinforcement Learning \u00b7 Reducing the Probability of Undesirable Outputs in Language Models Using ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"neurips.cc"}]},{"type":"search_result_group","domain":"ceur-ws.org","entries":[{"type":"search_result","url":"https://ceur-ws.org/Vol-4082/paper1.pdf","title":"Key Challenges in Continual Learning","snippet":"by R Teng \u00b7 2025 \u2014 The regularization-based method prevents drastic parameter changes by adding penalty terms for important parameters of previous tasks in the loss function. For ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":22},"pub_date":1762324976.0,"attribution":"ceur-ws.org"}]},{"type":"search_result_group","domain":"liner.com","entries":[{"type":"search_result","url":"https://liner.com/review/efficient-continual-pretraining-llms-for-lowresource-languages","title":"Efficient Continual Pre-training of LLMs for Low-resource ...","snippet":"The research aims to drastically reduce the cost of continual pre-training for Large Language Models while improving their performance on low-resource languages ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":23},"pub_date":1734048000.0,"attribution":"liner.com"}]},{"type":"search_result_group","domain":"medium.com","entries":[{"type":"search_result","url":"https://medium.com/%40baicenxiao/avoiding-amnesia-some-practical-guides-to-mitigate-catastrophic-forgetting-in-llms-post-training-6a23e4f064cb","title":"Avoiding Amnesia: Some Practical Guides to Mitigate ...","snippet":"Catastrophic forgetting (CF) is when learning a new task causes an abrupt performance drop on old ones. In LLMs, I've seen it show up as: Weaker ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":24},"pub_date":1755986852.553,"attribution":"medium.com"}]},{"type":"search_result_group","domain":"www.researchgate.net","entries":[{"type":"search_result","url":"https://www.researchgate.net/publication/397202096_Learn_more_but_bother_less_parameter_efficient_continual_learning","title":"Learn more, but bother less: parameter efficient continual ...","snippet":"5 Nov 2025 \u2014 Parameter efficient fine tuning CL techniques are gaining traction for their effectiveness in addressing catastrophic forgetting with a ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":25},"pub_date":1704067200.0,"attribution":"www.researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/383754106_Continual_Diffuser_CoD_Mastering_Continual_Offline_Reinforcement_Learning_with_Experience_Rehearsal","title":"(PDF) Continual Diffuser (CoD): Mastering ...","snippet":"4 Sept 2024 \u2014 In view of this, we propose a rehearsal-based continual diffusion model, called Continual Diffuser (CoD), to endow the diffuser with the ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":26},"pub_date":1725408000.0,"attribution":"www.researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/396747601_Retaining_by_Doing_The_Role_of_On-Policy_Data_in_Mitigating_Forgetting","title":"The Role of On-Policy Data in Mitigating Forgetting","snippet":"24 Oct 2025 \u2014 In this paper, toward identifying guidelines for mitigating this phenomenon, we systematically compare the forgetting patterns of two widely ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":28},"pub_date":1761004800.0,"attribution":"www.researchgate.net"}]},{"type":"search_result_group","domain":"www.semanticscholar.org","entries":[{"type":"search_result","url":"https://www.semanticscholar.org/paper/Continual-Pre-Training-of-Large-Language-Models%3A-to-Gupta-Th%27erien/193955704f66923ac20a664bd184ed4663b2bdf9","title":"[PDF] Continual Pre-Training of Large Language Models","snippet":"It is shown that removing parallel structures in the pre-training data reduces LMs' ICL accuracy by 51% (vs 2% from random ablation), and this drop persists ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":27},"pub_date":null,"attribution":"www.semanticscholar.org"}]},{"type":"search_result_group","domain":"jessylin.com","entries":[{"type":"search_result","url":"https://jessylin.com/2025/10/20/continual-learning/","title":"The Continual Learning Problem","snippet":"20 Oct 2025 \u2014 To solve catastrophic forgetting and integration, we'll likely want solutions where models can learn what to overwrite and what to preserve ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":29},"pub_date":null,"attribution":"jessylin.com"}]},{"type":"search_result_group","domain":"www.computer.org","entries":[{"type":"search_result","url":"https://www.computer.org/csdl/journal/tp/2025/03/10752992/21S24kWCL1m","title":"A Comprehensive Survey of Forgetting in Deep Learning ...","snippet":"by Z Wang \u00b7 2025 \u00b7 Cited by 111 \u2014 In Sections II,III,IV,V,VI,VII, and VIII, we provide a comprehensive survey on harmful forgetting in continual learning, foundation model, domain adaptation, ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":30},"pub_date":null,"attribution":"www.computer.org"}]}],"debug_sonic_thread_id":"thread_695649353e2c83248117d80f2fe78bd6","reasoning_status":"is_reasoning","reasoning_title":"Browsing for latest advances in continual learning AI","classifier_response":"default","request_id":"5f3f0455-8a59-45eb-a9c3-284af86d3bb4","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"b45709fa-0d86-494a-b11f-e40fa2032fd1","turn_exchange_id":"b62969f7-f59e-4e1e-9b90-3e7bb7097612"},"recipient":"all","channel":null},"parent":"b45709fa-0d86-494a-b11f-e40fa2032fd1","children":["cebdae56-497d-45fd-8303-6488d7648eee"]},"cebdae56-497d-45fd-8303-6488d7648eee":{"id":"cebdae56-497d-45fd-8303-6488d7648eee","message":{"id":"cebdae56-497d-45fd-8303-6488d7648eee","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1767262530.043364,"update_time":null,"content":{"content_type":"thoughts","thoughts":[{"summary":"Evaluating advances in continual learning and product features","content":"I\u2019m looking into the latest advances in continual learning for generative AI models. This includes technical methods like fine-tuning, memory modules, and model alignment, as well as practical examples from labs like ChatGPT and Claude. However, I'll keep in mind that most labs use periodic updates, not strictly continuous learning.","chunks":["I\u2019m looking into the latest advances in continual learning for generative AI models.","This includes technical methods like fine-tuning, memory modules, and model alignment, as well as practical examples from labs like ChatGPT and Claude.","However, I'll keep in mind that most labs use periodic updates, not strictly continuous learning."],"finished":true},{"summary":"Focusing on adaptation and model updates","content":"I should focus more on training and adaptation rather than retrieval. Also, I need to include methods like model editing and delta updates (e.g. MEMIT, ROME) for incorporating new facts. Diffusion models in continual learning, including text-to-image and multimodal models, are essential too. I'll search for 2025-2026 papers on these topics.","chunks":["I should focus more on training and adaptation rather than retrieval.","Also, I need to include methods like model editing and delta updates (e.g. MEMIT, ROME) for incorporating new facts.","Diffusion models in continual learning, including text-to-image and multimodal models, are essential too.","I'll search for 2025-2026 papers on these topics."],"finished":true}],"source_analysis_msg_id":"83f2bf6d-2a3e-40e9-bea5-9da745656228"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"is_reasoning","citations":[],"content_references":[],"classifier_response":"default","skip_reasoning_title":"Skip","request_id":"5f3f0455-8a59-45eb-a9c3-284af86d3bb4","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"b4e22920-63d3-427d-8898-93690a45ecfb","turn_exchange_id":"b62969f7-f59e-4e1e-9b90-3e7bb7097612"},"recipient":"all","channel":null},"parent":"b4e22920-63d3-427d-8898-93690a45ecfb","children":["2a85d3dc-4c17-4a38-979b-cbf7541fec66"]},"2a85d3dc-4c17-4a38-979b-cbf7541fec66":{"id":"2a85d3dc-4c17-4a38-979b-cbf7541fec66","message":{"id":"2a85d3dc-4c17-4a38-979b-cbf7541fec66","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1767262520.453562,"update_time":null,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"{\"search_query\":[{\"q\":\"2025 continual learning diffusion models text-to-image catastrophic forgetting replay\",\"recency\":365},{\"q\":\"2025 continual learning multimodal large language model continual instruction tuning benchmark\",\"recency\":365},{\"q\":\"2025 continual learning memory layers finetuning sparse memory finetuning paper\",\"recency\":365},{\"q\":\"2025 lifelong alignment large language models continual learning LifeAlign paper\",\"recency\":365}],\"response_length\":\"long\"}"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200012]},"is_complete":true,"citations":[],"content_references":[],"reasoning_status":"is_reasoning","search_queries":[{"type":"search","q":"2025 continual learning diffusion models text-to-image catastrophic forgetting replay"},{"type":"search","q":"2025 continual learning multimodal large language model continual instruction tuning benchmark"},{"type":"search","q":"2025 continual learning memory layers finetuning sparse memory finetuning paper"},{"type":"search","q":"2025 lifelong alignment large language models continual learning LifeAlign paper"}],"search_display_string":"Searching the web...","searched_display_string":"Searched the web...","reasoning_title":"Searching for latest research on continual learning models","classifier_response":"default","request_id":"5f3f0455-8a59-45eb-a9c3-284af86d3bb4","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"cebdae56-497d-45fd-8303-6488d7648eee","turn_exchange_id":"b62969f7-f59e-4e1e-9b90-3e7bb7097612"},"recipient":"web.run","channel":null},"parent":"cebdae56-497d-45fd-8303-6488d7648eee","children":["486c10c0-3ab6-4270-b61e-d5039756377c"]},"486c10c0-3ab6-4270-b61e-d5039756377c":{"id":"486c10c0-3ab6-4270-b61e-d5039756377c","message":{"id":"486c10c0-3ab6-4270-b61e-d5039756377c","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1767262531.7978296,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_model_queries":{"type":"search_model_queries","queries":["2025 continual learning diffusion models text-to-image catastrophic forgetting replay","2025 continual learning multimodal large language model continual instruction tuning benchmark","2025 continual learning memory layers finetuning sparse memory finetuning paper","2025 lifelong alignment large language models continual learning LifeAlign paper"]},"reasoning_status":"is_reasoning","reasoning_title":"Searching for latest research on continual learning models","classifier_response":"default","request_id":"5f3f0455-8a59-45eb-a9c3-284af86d3bb4","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"2a85d3dc-4c17-4a38-979b-cbf7541fec66","turn_exchange_id":"b62969f7-f59e-4e1e-9b90-3e7bb7097612"},"recipient":"all","channel":null},"parent":"2a85d3dc-4c17-4a38-979b-cbf7541fec66","children":["a8759e22-4362-4a9f-9843-f7fb1b40ece9"]},"a8759e22-4362-4a9f-9843-f7fb1b40ece9":{"id":"a8759e22-4362-4a9f-9843-f7fb1b40ece9","message":{"id":"a8759e22-4362-4a9f-9843-f7fb1b40ece9","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1767262531.7924066,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_result_groups":[{"type":"search_result_group","domain":"www.arxiv.org","entries":[{"type":"search_result","url":"https://www.arxiv.org/abs/2509.10529","title":"Mitigating Catastrophic Forgetting and Mode Collapse in ...","snippet":"by A Otani \u00b7 2025 \u2014 Abstract page for arXiv paper 2509.10529: Mitigating Catastrophic Forgetting and Mode Collapse in Text-to-Image Diffusion via Latent Replay.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":0},"pub_date":null,"attribution":"www.arxiv.org"}]},{"type":"search_result_group","domain":"arxiv.org","entries":[{"type":"search_result","url":"https://arxiv.org/abs/2508.08275","title":"MLLM-CBench:A Comprehensive Benchmark for Continual Instruction Tuning of Multimodal LLMs with Chain-of-Thought Reasoning Analysis","snippet":"","ref_id":{"turn_index":1,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2510.15103","title":"Continual Learning via Sparse Memory Finetuning","snippet":"","ref_id":{"turn_index":1,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2509.17183","title":"LifeAlign: Lifelong Alignment for Large Language Models with Memory-Augmented Focalized Preference Optimization","snippet":"","ref_id":{"turn_index":1,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2509.17183v1","title":"LifeAlign: Lifelong Alignment for Large Language Models ...","snippet":"21 Sept 2025 \u2014 We introduce LifeAlign, a novel framework for lifelong alignment that enables LLMs to maintain consistent human preference alignment across ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2509.10529v1","title":"Mitigating Catastrophic Forgetting and Mode Collapse in ...","snippet":"4 Sept 2025 \u2014 Mitigating Catastrophic Forgetting and Mode Collapse in Text-to-Image Diffusion via Latent Replay. Report issue for preceding element. Aoi Otani.Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2508.07307","title":"MCITlib: Multimodal Continual Instruction Tuning Library ...","snippet":"by H Guo \u00b7 2025 \u00b7 Cited by 3 \u2014 Continual learning aims to equip AI systems with the ability to continuously acquire and adapt to new knowledge without forgetting previously ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2510.15103v1","title":"Continual Learning via Sparse Memory Finetuning","snippet":"16 Oct 2025 \u2014 We find that sparse memory finetuning learns new knowledge while exhibiting substantially less forgetting: while NaturalQuestions F1 drops by 89 ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":22},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2509.17183","title":"LifeAlign: Lifelong Alignment for Large Language Models ...","snippet":"by J Li \u00b7 2025 \u00b7 Cited by 1 \u2014 We introduce LifeAlign, a novel framework for life- long alignment that enables LLMs to maintain consistent hu- man preference alignment across ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":23},"pub_date":null,"attribution":"arxiv.org"}]},{"type":"search_result_group","domain":"openaccess.thecvf.com","entries":[{"type":"search_result","url":"https://openaccess.thecvf.com/content/ICCV2025/papers/Skiers_Joint_Diffusion_Models_in_Continual_Learning_ICCV_2025_paper.pdf","title":"Joint Diffusion Models in Continual Learning - CVF Open Access","snippet":"by P Skier\u015b \u00b7 2025 \u00b7 Cited by 6 \u2014 introduce a method for finetuning text-to-image DDGMs with Prior Preservation Loss, that employs generative replay to mitigate catastrophic forgetting.Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"openaccess.thecvf.com"}]},{"type":"search_result_group","domain":"openreview.net","entries":[{"type":"search_result","url":"https://openreview.net/forum?id=EpnsUQavJA&referrer=%5Bthe+profile+of+Jingkuan+Song%5D%28%2Fprofile%3Fid%3D~Jingkuan_Song3%29","title":"CoIN: A Benchmark of Continual Instruction Tuning for ...","snippet":"13 Nov 2024 \u2014 In this paper, we present CoIN, a comprehensive benchmark tailored for assessing the behavior of existing MLLMs under continual instruction tuning.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/forum?id=LGo7U1m24L","title":"Continual Learning via Sparse Memory Finetuning","snippet":"19 Sept 2025 \u2014 This paper addresses catastrophic forgetting in continual learning for large language models by proposing Sparse Memory Finetuning, a method ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/forum?id=PvvQlhBbgu&noteId=MmyzoLCDQN","title":"Fast Multi-Mode Adaptive Generative Distillation for ...","snippet":"14 Nov 2024 \u2014 The paper solves the catastrophic forgetting problem for the diffusion model in a continual learning fashion on images with class labels.Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"openreview.net"}]},{"type":"search_result_group","domain":"www.linkedin.com","entries":[{"type":"search_result","url":"https://www.linkedin.com/posts/srvjha_iclr2025-tokyo-continuallearning-activity-7287962592340254720-V6AR","title":"Saurav Jha's Post","snippet":"... text-to-image latent diffusion models on a sequence of concepts without any replay memory. To counter catastrophic forgetting in this continual ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":8},"pub_date":1737585685.779,"attribution":"www.linkedin.com"}]},{"type":"search_result_group","domain":"dl.acm.org","entries":[{"type":"search_result","url":"https://dl.acm.org/doi/10.5555/3737916.3739760","title":"CoIN: a benchmark of continual instruction tuning for ...","snippet":"10 Dec 2024 \u2014 Instruction tuning demonstrates impressive performance in adapting Multimodal Large Language Models (MLLMs) to follow task instructions and ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"dl.acm.org"},{"type":"search_result","url":"https://dl.acm.org/doi/abs/10.1145/3735633","title":"Continual Learning of Large Language Models","snippet":"by H Shi \u00b7 Cited by 175 \u2014 This survey sheds light on the relatively understudied domain of continually pre-training, adapting, and fine-tuning large language models.Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":19},"pub_date":null,"attribution":"dl.acm.org"}]},{"type":"search_result_group","domain":"jessylin.com","entries":[{"type":"search_result","url":"https://jessylin.com/2025/10/20/continual-learning/","title":"The Continual Learning Problem","snippet":"20 Oct 2025 \u2014 In our paper, \u201cContinual Learning via Sparse Memory Finetuning,\u201d we propose that memory layers provide a potential answer. The Design Space. To ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"jessylin.com"}]},{"type":"search_result_group","domain":"www.semanticscholar.org","entries":[{"type":"search_result","url":"https://www.semanticscholar.org/paper/LifeAlign%3A-Lifelong-Alignment-for-Large-Language-Li-Zhou/865da3faec0bd4aea4e56b9252149fe221309746","title":"LifeAlign: Lifelong Alignment for Large Language Models with ...","snippet":"LifeAlign is introduced, a novel framework for lifelong alignment that enables LLMs to maintain consistent human preference alignment across sequential ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"www.semanticscholar.org"}]},{"type":"search_result_group","domain":"neurips.cc","entries":[{"type":"search_result","url":"https://neurips.cc/virtual/2024/poster/97786","title":"CoIN: A Benchmark of Continual Instruction Tuning ...","snippet":"9 Dec 2024 \u2014 In this paper, we present CoIN, a comprehensive benchmark tailored for assessing the behavior of existing MLLMs under continual instruction ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":13},"pub_date":1727308800.0,"attribution":"neurips.cc"}]},{"type":"search_result_group","domain":"github.com","entries":[{"type":"search_result","url":"https://github.com/Wang-ML-Lab/llm-continual-learning-survey","title":"Continual Learning of Large Language Models: A ...","snippet":"This is an updating survey for Continual Learning of Large Language Models (CL-LLMs), a constantly updated and extended version for the manuscript.Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/Ghy0501/Awesome-Continual-Learning-in-Generative-Models","title":"Awesome-Continual-Learning-in-Generative-Models","snippet":"Yet, their practical deployment is hindered by catastrophic forgetting\u2014a fundamental issue where learning new tasks erases previously acquired knowledge.Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":28},"pub_date":null,"attribution":"github.com"}]},{"type":"search_result_group","domain":"www.sciencedirect.com","entries":[{"type":"search_result","url":"https://www.sciencedirect.com/science/article/pii/S026288562500188X","title":"Memory augmented using diffusion model for class- ...","snippet":"by Q Jodelet \u00b7 2025 \u2014 Several research works have shown how additional data can be used by incremental models to help mitigate catastrophic forgetting. In this work, following the ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"www.sciencedirect.com"}]},{"type":"search_result_group","domain":"www.researchgate.net","entries":[{"type":"search_result","url":"https://www.researchgate.net/publication/395725674_LifeAlign_Lifelong_Alignment_for_Large_Language_Models_with_Memory-Augmented_Focalized_Preference_Optimization","title":"LifeAlign: Lifelong Alignment for Large Language Models ...","snippet":"25 Sept 2025 \u2014 We introduce LifeAlign, a novel framework for lifelong alignment that enables LLMs to maintain consistent human preference alignment across ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":17},"pub_date":1758412800.0,"attribution":"www.researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/394457653_MLLM-CBenchA_Comprehensive_Benchmark_for_Continual_Instruction_Tuning_of_Multimodal_LLMs_with_Chain-of-Thought_Reasoning_Analysis","title":"MLLM-CBench:A Comprehensive Benchmark for Continual ...","snippet":"16 Aug 2025 \u2014 MLLM-CBench:A Comprehensive Benchmark for Continual Instruction Tuning of Multimodal LLMs with Chain-of-Thought Reasoning Analysis. July 2025.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":25},"pub_date":1753920000.0,"attribution":"www.researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/396693493_Continual_Learning_via_Sparse_Memory_Finetuning","title":"(PDF) Continual Learning via Sparse Memory Finetuning","snippet":"22 Oct 2025 \u2014 Our results suggest sparsity in memory layers offers a promising path toward continual learning in large language models. ResearchGate Logo.Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":36},"pub_date":1760572800.0,"attribution":"www.researchgate.net"}]},{"type":"search_result_group","domain":"aclanthology.org","entries":[{"type":"search_result","url":"https://aclanthology.org/2025.acl-long.537.pdf","title":"A Generative Adaptive Replay Continual Learning Model ...","snippet":"by Z Zhang \u00b7 2025 \u2014 Continual Learning(CL) fine-tuning models with new data may seem intu- itive, but often results in catastrophic forgetting, where prior ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":20},"pub_date":1752153041.0,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2025.emnlp-tutorials.7/","title":"Continual Learning of Large Language Models","snippet":"by T Wu \u00b7 2025 \u2014 This tutorial offers a comprehensive exploration of continual learning (CL) in the context of LLMs, presenting a structured framework that spans continual pre- ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":27},"pub_date":null,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2025.emnlp-main.609.pdf","title":"Towards Efficient Multimodal Continual Instruction Tuning ...","snippet":"by F Zeng \u00b7 2025 \u00b7 Cited by 2 \u2014 Coin: A benchmark of continual instruction tuning for mul- timodel large language model. Advances in neural information processing systems ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":29},"pub_date":1761174296.0,"attribution":"aclanthology.org"}]},{"type":"search_result_group","domain":"liner.com","entries":[{"type":"search_result","url":"https://liner.com/review/coin-a-benchmark-of-continual-instruction-tuning-for-multimodel-large","title":"A Benchmark of Continual Instruction tuNing for Multimodel ...","snippet":"However, continual instruction tuning for MLLMs is largely overlooked, and a public benchmark for assessing their behavior in sequential learning is absent.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":21},"pub_date":1710288000.0,"attribution":"liner.com"}]},{"type":"search_result_group","domain":"www.ijcai.org","entries":[{"type":"search_result","url":"https://www.ijcai.org/proceedings/2025/0328.pdf","title":"Generative Diffusion Replay for Continual Anomaly Detection","snippet":"by L Hu \u00b7 Cited by 2 \u2014 In this case, the model suffers from catastrophic forgetting, resulting in a sharp decline in per- formance. T2 and T3 represent the processes of learning and ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":24},"pub_date":1758198534.0,"attribution":"www.ijcai.org"}]},{"type":"search_result_group","domain":"medium.com","entries":[{"type":"search_result","url":"https://medium.com/data-science-collective/the-promise-of-continual-learning-f3dd88b17a51","title":"The Promise of Continual Learning | by Minhajul Hoque","snippet":"In the paper that motivates this post, sparse memory finetuning preserved held\u2011out performance far better than full finetuning or LoRA while ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":26},"pub_date":1761492528.951,"attribution":"medium.com"}]},{"type":"search_result_group","domain":"pub.towardsai.net","entries":[{"type":"search_result","url":"https://pub.towardsai.net/continual-learning-via-sparse-memory-finetuning-paper-review-2c316a3b42e0","title":"Continual Learning via Sparse Memory Finetuning (Paper ...","snippet":"26 Oct 2025 \u2014 Meta AI's Sparse Memory Finetuning introduces a clever, lightweight solution: instead of changing the entire model, it teaches selectively ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":30},"pub_date":1761548335.8,"attribution":"pub.towardsai.net"}]},{"type":"search_result_group","domain":"www.nb-data.com","entries":[{"type":"search_result","url":"https://www.nb-data.com/p/advancing-ai-lifelong-learning-roadmap","title":"Advancing AI: Lifelong Learning Roadmap for LLM-Based ...","snippet":"20 Jan 2025 \u2014 Recently, I read a nice paper from Zheng et al. (2025) regarding a roadmap to Lifelong Learning of LLM-based Agents.Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":31},"pub_date":1737363175.0,"attribution":"www.nb-data.com"}]},{"type":"search_result_group","domain":"proceedings.neurips.cc","entries":[{"type":"search_result","url":"https://proceedings.neurips.cc/paper_files/paper/2024/file/d0949cbcec31c09431610553a284f94a-Paper-Conference.pdf","title":"Leveraging Catastrophic Forgetting to Develop Safe ...","snippet":"by J Pan \u00b7 2024 \u00b7 Cited by 5 \u2014 Various attempts have been made to alleviate catastrophic forgetting through continual learning algorithms and data replay, such as imposing a penalty on ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":32},"pub_date":null,"attribution":"proceedings.neurips.cc"}]},{"type":"search_result_group","domain":"www.themoonlight.io","entries":[{"type":"search_result","url":"https://www.themoonlight.io/tw/review/coin-a-benchmark-of-continual-instruction-tuning-for-multimodel-large-language-model","title":"[\u8ad6\u6587\u8a55\u8ff0] CoIN: A Benchmark of Continual Instruction ...","snippet":"\u672c\u9801\u9762\u63d0\u4f9b\u5168\u7403\u6700\u6e96\u78ba\u3001\u7cbe\u7149\u7684\u8ad6\u6587\u300aCoIN: A Benchmark of Continual Instruction tuNing for Multimodel Large Language Model\u300b\u6458\u8981\u3002\u900f\u904e Moonlight \u9019\u6b3e AI \u7814\u7a76\u52a9\u624b\uff0c ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":33},"pub_date":null,"attribution":"www.themoonlight.io"}]},{"type":"search_result_group","domain":"self-supervised.cs.jhu.edu","entries":[{"type":"search_result","url":"https://self-supervised.cs.jhu.edu/fa2025/files/presentations/Continual-learn-Dec4.pdf","title":"Can Sparse Memory updates allow LLMs to continually ...","snippet":"Sparse Memory Finetuning: An intelligent, selective update rule that modifies only specific memory slots, mitigating interference. Page ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":34},"pub_date":null,"attribution":"self-supervised.cs.jhu.edu"}]},{"type":"search_result_group","domain":"www.scilit.com","entries":[{"type":"search_result","url":"https://www.scilit.com/scholars/12888679","title":"Jie Zhou from East China Normal University","snippet":"We introduce LifeAlign, a novel framework for lifelong alignment that enables LLMs to maintain consistent human preference alignment across sequential learning ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":35},"pub_date":null,"attribution":"www.scilit.com"}]}],"debug_sonic_thread_id":"thread_695649353e2c83248117d80f2fe78bd6","reasoning_status":"is_reasoning","reasoning_title":"Searching for latest research on continual learning models","classifier_response":"default","request_id":"5f3f0455-8a59-45eb-a9c3-284af86d3bb4","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"486c10c0-3ab6-4270-b61e-d5039756377c","turn_exchange_id":"b62969f7-f59e-4e1e-9b90-3e7bb7097612"},"recipient":"all","channel":null},"parent":"486c10c0-3ab6-4270-b61e-d5039756377c","children":["7f16f5e9-1794-424e-95cf-70d2dba00dc7"]},"7f16f5e9-1794-424e-95cf-70d2dba00dc7":{"id":"7f16f5e9-1794-424e-95cf-70d2dba00dc7","message":{"id":"7f16f5e9-1794-424e-95cf-70d2dba00dc7","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1767262543.939458,"update_time":null,"content":{"content_type":"thoughts","thoughts":[{"summary":"Exploring frontier AI models and continual learning","content":"I\u2019ve found some useful sources, like diffusion latent replay and LifeAlign, and I need to address industrial trends, such as Llama 3\u2019s continual pretraining. The user asked about frontier generative models, so I must include diffusion models, multimodal models, and even robotics, not just LLMs. Scaling laws and new advancements like \"Forward-Only learning\" are also important.","chunks":["I\u2019ve found some useful sources, like diffusion latent replay and LifeAlign, and I need to address industrial trends, such as Llama 3\u2019s continual pretraining.","The user asked about frontier generative models, so I must include diffusion models, multimodal models, and even robotics, not just LLMs.","Scaling laws and new advancements like \"Forward-Only learning\" are also important."],"finished":true},{"summary":"Key dimensions of continual learning","content":"For continual learning, I need to address several dimensions. These include Continual Pretraining, Fine-Tuning, and Alignment, along with architectural updates like LoRA and memory layers. Replay, regularization methods like EWC, model merging, and tasks like evaluation and benchmarks are crucial too. Lastly, deployment often uses methods like retrieval-augmented generation instead of weight updates.","chunks":["For continual learning, I need to address several dimensions.","These include Continual Pretraining, Fine-Tuning, and Alignment, along with architectural updates like LoRA and memory layers.","Replay, regularization methods like EWC, model merging, and tasks like evaluation and benchmarks are crucial too.","Lastly, deployment often uses methods like retrieval-augmented generation instead of weight updates."],"finished":true},{"summary":"Exploring frontier system updates and future research","content":"I should mention that frontier systems might avoid full continual learning, focusing instead on \"tool use\" or \"RAG\" for updates due to safety or regulatory concerns. However, internal R&D is exploring more direct continual updates. I\u2019ll need to research contributions from 2025-2026, especially around self-synthesized rehearsal in LLMs.","chunks":["I should mention that frontier systems might avoid full continual learning, focusing instead on \"tool use\" or \"RAG\" for updates due to safety or regulatory concerns. However, internal R&D is exploring more direct continual updates. I\u2019ll need to research contributions from 2025-2026, especially around self-synthesized rehearsal in LLMs."],"finished":true}],"source_analysis_msg_id":"f0befe6e-d7aa-4b64-9014-86e03874808f"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"is_reasoning","citations":[],"content_references":[],"classifier_response":"default","skip_reasoning_title":"Skip","request_id":"5f3f0455-8a59-45eb-a9c3-284af86d3bb4","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"a8759e22-4362-4a9f-9843-f7fb1b40ece9","turn_exchange_id":"b62969f7-f59e-4e1e-9b90-3e7bb7097612"},"recipient":"all","channel":null},"parent":"a8759e22-4362-4a9f-9843-f7fb1b40ece9","children":["167f9e4a-f6a2-4565-b60d-3a6986827693"]},"167f9e4a-f6a2-4565-b60d-3a6986827693":{"id":"167f9e4a-f6a2-4565-b60d-3a6986827693","message":{"id":"167f9e4a-f6a2-4565-b60d-3a6986827693","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1767262533.405864,"update_time":null,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"{\"search_query\":[{\"q\":\"2025 self-synthesized rehearsal continual instruction tuning large language models paper\",\"recency\":365},{\"q\":\"2025 continual instruction tuning benchmark CITB TRACE InsCL ConPET SAPT\",\"recency\":365},{\"q\":\"2025 'online continual learning' large language model without replay memory\",\"recency\":365},{\"q\":\"2025 model merging continual learning LLM LiNeS layer scaling\",\"recency\":365}],\"response_length\":\"long\"}"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200012]},"is_complete":true,"citations":[],"content_references":[],"reasoning_status":"is_reasoning","search_queries":[{"type":"search","q":"2025 self-synthesized rehearsal continual instruction tuning large language models paper"},{"type":"search","q":"2025 continual instruction tuning benchmark CITB TRACE InsCL ConPET SAPT"},{"type":"search","q":"2025 'online continual learning' large language model without replay memory"},{"type":"search","q":"2025 model merging continual learning LLM LiNeS layer scaling"}],"search_display_string":"Searching the web...","searched_display_string":"Searched the web...","reasoning_title":"Searching for 2025 advancements in continual learning","classifier_response":"default","request_id":"5f3f0455-8a59-45eb-a9c3-284af86d3bb4","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"7f16f5e9-1794-424e-95cf-70d2dba00dc7","turn_exchange_id":"b62969f7-f59e-4e1e-9b90-3e7bb7097612"},"recipient":"web.run","channel":null},"parent":"7f16f5e9-1794-424e-95cf-70d2dba00dc7","children":["74802954-2028-48c4-8090-6791560c86cc"]},"74802954-2028-48c4-8090-6791560c86cc":{"id":"74802954-2028-48c4-8090-6791560c86cc","message":{"id":"74802954-2028-48c4-8090-6791560c86cc","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1767262554.0700238,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_model_queries":{"type":"search_model_queries","queries":["2025 self-synthesized rehearsal continual instruction tuning large language models paper","2025 continual instruction tuning benchmark CITB TRACE InsCL ConPET SAPT","2025 'online continual learning' large language model without replay memory","2025 model merging continual learning LLM LiNeS layer scaling"]},"reasoning_status":"is_reasoning","reasoning_title":"Searching for 2025 advancements in continual learning","classifier_response":"default","request_id":"5f3f0455-8a59-45eb-a9c3-284af86d3bb4","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"167f9e4a-f6a2-4565-b60d-3a6986827693","turn_exchange_id":"b62969f7-f59e-4e1e-9b90-3e7bb7097612"},"recipient":"all","channel":null},"parent":"167f9e4a-f6a2-4565-b60d-3a6986827693","children":["5c9e767b-9287-445f-a413-15d842889d36"]},"5c9e767b-9287-445f-a413-15d842889d36":{"id":"5c9e767b-9287-445f-a413-15d842889d36","message":{"id":"5c9e767b-9287-445f-a413-15d842889d36","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1767262554.0600188,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_result_groups":[{"type":"search_result_group","domain":"arxiv.org","entries":[{"type":"search_result","url":"https://arxiv.org/abs/2403.01244","title":"[2403.01244] Mitigating Catastrophic Forgetting in Large ...","snippet":"by J Huang \u00b7 2024 \u00b7 Cited by 86 \u2014 We propose a framework called Self-Synthesized Rehearsal (SSR) that uses the LLM to generate synthetic instances for rehearsal.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":0},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2310.14510","title":"CITB: A Benchmark for Continual Instruction Tuning","snippet":"by Z Zhang \u00b7 2023 \u00b7 Cited by 41 \u2014 In this work, we establish a CIT benchmark consisting of learning and evaluation protocols. We curate two long dialogue task streams of different types.Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2410.17146","title":"LiNeS: Post-training Layer Scaling Prevents Forgetting and ...","snippet":"by K Wang \u00b7 2024 \u00b7 Cited by 18 \u2014 We introduce LiNeS, Layer-increasing Network Scaling, a post-training editing technique designed to preserve pre-trained generalization while enhancing fine- ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2412.15479v1","title":"Continual Learning Using Only Large Language Model ...","snippet":"20 Dec 2024 \u2014 This is referred to as online or streaming CIL, where the training data arrives as a continuous stream, and each training example is seen only ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2310.06762","title":"TRACE: A Comprehensive Benchmark for Continual ...","snippet":"by X Wang \u00b7 2023 \u00b7 Cited by 51 \u2014 TRACE consists of 8 distinct datasets spanning challenging tasks including domain-specific tasks, multilingual capabilities, code generation, and mathematical ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":29},"pub_date":null,"attribution":"arxiv.org"}]},{"type":"search_result_group","domain":"aclanthology.org","entries":[{"type":"search_result","url":"https://aclanthology.org/2023.findings-emnlp.633/","title":"CITB: A Benchmark for Continual Instruction Tuning","snippet":"by Z Zhang \u00b7 2023 \u00b7 Cited by 41 \u2014 In this work, we establish a CIT benchmark consisting of learning and evaluation protocols. We curate two long dialogue task streams of different types.Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2025.emnlp-main.829.pdf","title":"RECALL: REpresentation-aligned Catastrophic-forgetting ...","snippet":"by B Wang \u00b7 2025 \u2014 Therefore, inspired by those observations, we propose RECALL in this section, which performs layer-wise model merging by comparing the sim-.Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":14},"pub_date":1761174412.0,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2024.acl-long.77/","title":"Mitigating Catastrophic Forgetting in Large Language ...","snippet":"by J Huang \u00b7 2024 \u00b7 Cited by 86 \u2014 We propose a framework called Self-Synthesized Rehearsal (SSR) that uses the LLM to generate synthetic instances for rehearsal.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2025.coling-main.402.pdf","title":"Continual Learning Using Only Large Language Model ...","snippet":"by J Qiu \u00b7 2025 \u00b7 Cited by 2 \u2014 We introduce CLOB, a novel continual learning. (CL) paradigm wherein a large language model. (LLM) is regarded as a black box. Learning.Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":17},"pub_date":1733637936.0,"attribution":"aclanthology.org"}]},{"type":"search_result_group","domain":"dl.acm.org","entries":[{"type":"search_result","url":"https://dl.acm.org/doi/10.1145/3735633","title":"Continual Learning of Large Language Models","snippet":"20 Nov 2025 \u2014 Continual fine-tuning targets downstream tasks after deployment, encompassing instruction tuning, model refinement, model alignment, and ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"dl.acm.org"},{"type":"search_result","url":"https://dl.acm.org/doi/pdf/10.1145/3735633","title":"Continual Learning of Large Language Models","snippet":"by H Shi \u00b7 Cited by 176 \u2014 In CFT, our focus is on the emerging field of learning LLMs, covering topics such as Continual Instruction Tuning (CIT), Continual Model Refinement ... CITB: A ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":20},"pub_date":null,"attribution":"dl.acm.org"}]},{"type":"search_result_group","domain":"openreview.net","entries":[{"type":"search_result","url":"https://openreview.net/forum?id=J5sUOvlLbQ&noteId=PYWNZ0NC7L","title":"LiNeS: Post-training Layer Scaling Prevents Forgetting and ...","snippet":"23 Dec 2024 \u2014 In multi-task model merging scenarios, layer-wise scaling of merged parameters reduces negative task interference. LiNeS demonstrates ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/forum?id=QA1jlb1VG7","title":"CITB: A Benchmark for Continual Instruction Tuning","snippet":"by Z Zhang \u00b7 Cited by 41 \u2014 The benchmark consists of two long task streams constructed from the SuperNI dataset, and the authors propose an evaluation protocol to assess performance on ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/forum?id=LWH8yn4HS2","title":"From RAG to Memory: Non-Parametric Continual Learning ...","snippet":"by BJ Guti\u00e9rrez \u00b7 Cited by 84 \u2014 TL;DR: In this work, we propose HippoRAG 2, a non-parametric continual learning framework which outperforms state-of-the-art retrieval methods ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/pdf/02bb9435749398313a19d1e2d4389699ebe7d3bf.pdf","title":"Self-Evolving Pseudo-Rehearsal for Catastrophic ...","snippet":"Continual instruction tuning for LLMs extends traditional LLMs tuning by enabling LLMs to incrementally absorb new tasks and feedback without forgetting prior ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":19},"pub_date":1761141098.0,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/pdf/c38679398b6736228ed121760328ebc474d8e294.pdf","title":"LINES: POST-TRAINING LAYER SCALING PREVENTS ...","snippet":"When merging multiple models, LiNeS improves baseline methods for merging checkpoints fine-tuned on multiple tasks in both computer vision and NLP benchmarks ( ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":22},"pub_date":1743584911.0,"attribution":"openreview.net"}]},{"type":"search_result_group","domain":"liner.com","entries":[{"type":"search_result","url":"https://liner.com/review/mitigating-catastrophic-forgetting-in-large-language-models-with-selfsynthesized-rehearsal","title":"[Quick Review] Mitigating Catastrophic Forgetting in Large ...","snippet":"We propose Self-Synthesized Rehearsal (SSR), a framework that employs LLMs to generate synthetic instances for rehearsal to mitigate catastrophic forgetting.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":4},"pub_date":1709337600.0,"attribution":"liner.com"}]},{"type":"search_result_group","domain":"github.com","entries":[{"type":"search_result","url":"https://github.com/Wang-ML-Lab/llm-continual-learning-survey","title":"Continual Learning of Large Language Models: A ...","snippet":"This is an updating survey for Continual Learning of Large Language Models (CL-LLMs), a constantly updated and extended version for the manuscript.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/EnnengYang/Awesome-Model-Merging-Methods-Theories-Applications","title":"EnnengYang/Awesome-Model-Merging-Methods-Theories ...","snippet":"This survey provides a comprehensive overview of model merging methods and theories, their applications in various domains and settings, and future research ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"github.com"}]},{"type":"search_result_group","domain":"www.researchgate.net","entries":[{"type":"search_result","url":"https://www.researchgate.net/publication/384211005_Mitigating_Catastrophic_Forgetting_in_Large_Language_Models_with_Self-Synthesized_Rehearsal","title":"Mitigating Catastrophic Forgetting in Large Language ...","snippet":"Continual fine-tuning of large language models (LLMs) suffers from catastrophic forgetting. Rehearsal-based methods mitigate this problem by retaining a small ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":8},"pub_date":1704067200.0,"attribution":"www.researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/376393733_CITB_A_Benchmark_for_Continual_Instruction_Tuning","title":"CITB: A Benchmark for Continual Instruction Tuning","snippet":"Although tuning a pretrained LLM with instruction data before deployment gains wide application, it still faces challenges when dealing with incremental data ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":16},"pub_date":1672531200.0,"attribution":"www.researchgate.net"}]},{"type":"search_result_group","domain":"openaccess.thecvf.com","entries":[{"type":"search_result","url":"https://openaccess.thecvf.com/content/ICCV2025/papers/Chen_FW-Merging_Scaling_Model_Merging_with_Frank-Wolfe_Optimization_ICCV_2025_paper.pdf","title":"Scaling Model Merging with Frank-Wolfe Optimization","snippet":"by HM Chen \u00b7 2025 \u00b7 Cited by 2 \u2014 Model merging has emerged as a promising approach for multi-task learning (MTL), offering a data-efficient alterna- tive to conventional fine-tuning.Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"openaccess.thecvf.com"}]},{"type":"search_result_group","domain":"www.semanticscholar.org","entries":[{"type":"search_result","url":"https://www.semanticscholar.org/paper/Mitigating-Catastrophic-Forgetting-in-Large-Models-Huang-Cui/015f62d7a59f7a4301c0cdbe997460c38148d07b","title":"Mitigating Catastrophic Forgetting in Large Language ...","snippet":"2 Mar 2024 \u2014 This work proposes a framework called Self-Synthesized Rehearsal (SSR) that uses the base LLM for in-context learning to generate synthetic ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"www.semanticscholar.org"},{"type":"search_result","url":"https://www.semanticscholar.org/paper/75a85d74433d03a78a07bb95f6f261323a79eb80","title":"[PDF] CITB: A Benchmark for Continual Instruction Tuning","snippet":"This work establishes a CIT benchmark consisting of learning and evaluation protocols and shows that existing CL methods do not effectively leverage the ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":26},"pub_date":null,"attribution":"www.semanticscholar.org"}]},{"type":"search_result_group","domain":"jessylin.com","entries":[{"type":"search_result","url":"https://jessylin.com/2025/10/20/continual-learning/","title":"The Continual Learning Problem","snippet":"20 Oct 2025 \u2014 Continual learning and memory is a huge, rich space to explore, and at this point in 2025 we're only just starting to reach the point where we ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":21},"pub_date":null,"attribution":"jessylin.com"}]},{"type":"search_result_group","domain":"opus.lib.uts.edu.au","entries":[{"type":"search_result","url":"https://opus.lib.uts.edu.au/rest/bitstreams/e9bfbba4-8ad3-4d5f-9eab-0e3752342a81/retrieve","title":"CITB: A Benchmark for Continual Instruction Tuning","snippet":"by Z Zhang \u00b7 Cited by 41 \u2014 This challenging yet practical problem is formulated as Continual Instruction Tuning (CIT). In this work, we establish a CIT benchmark consist- ing of learning ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":23},"pub_date":1701921581.0,"attribution":"opus.lib.uts.edu.au"}]},{"type":"search_result_group","domain":"huggingface.co","entries":[{"type":"search_result","url":"https://huggingface.co/papers/2502.14802","title":"From RAG to Memory: Non-Parametric Continual Learning ...","snippet":"Given the challenges in continual learning with large language models (LLMs), retrieval-augmented generation (RAG) has become the dominant way to introduce new ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":24},"pub_date":null,"attribution":"huggingface.co"}]},{"type":"search_result_group","domain":"www.themoonlight.io","entries":[{"type":"search_result","url":"https://www.themoonlight.io/en/review/mitigating-catastrophic-forgetting-in-large-language-models-with-self-synthesized-rehearsal","title":"[Literature Review] Mitigating Catastrophic Forgetting in ...","snippet":"The authors propose a novel framework called Self-Synthesized Rehearsal (SSR) to mitigate this problem without relying on the original training data from ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":25},"pub_date":null,"attribution":"www.themoonlight.io"}]},{"type":"search_result_group","domain":"deepfa.ir","entries":[{"type":"search_result","url":"https://deepfa.ir/en/blog/continual-learning-ai-lifelong-machine-learning","title":"How Can AI Learn Like Humans Without Forgetting?","snippet":"25 Oct 2025 \u2014 Replay-based continual learning stores samples of old data in a memory buffer and incorporates them in subsequent training cycles. Types of ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":27},"pub_date":null,"attribution":"deepfa.ir"}]},{"type":"search_result_group","domain":"iclr.cc","entries":[{"type":"search_result","url":"https://iclr.cc/virtual/2025/papers.html","title":"ICLR 2025 Papers","snippet":"LiNeS: Post-training Layer Scaling Prevents Forgetting and Enhances Model Merging \u00b7 Accelerating Training with Neuron Interaction and Nowcasting Networks ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":28},"pub_date":null,"attribution":"iclr.cc"}]},{"type":"search_result_group","domain":"ijsret.com","entries":[{"type":"search_result","url":"https://ijsret.com/wp-content/uploads/2025/03/IJSRET_V11_issue2_428.pdf","title":"Overcoming Catastrophic Forgetting in Continual Learning","snippet":"In this paper, we explore how external memory modules can be combined with large language models to facilitate continual learning. By utilizing a real-world ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":30},"pub_date":1744113683.0,"attribution":"ijsret.com"}]},{"type":"search_result_group","domain":"developers.redhat.com","entries":[{"type":"search_result","url":"https://developers.redhat.com/articles/2025/04/04/sculpting-subspaces-how-we-solved-continual-learning-llms","title":"Sculpting subspaces: How we solved continual learning in ...","snippet":"4 Apr 2025 \u2014 Discover how the adaptive SVD approach enables LLMs to continually learn and adapt without forgetting previously acquired knowledge.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":31},"pub_date":1743750000.0,"attribution":"developers.redhat.com"}]},{"type":"search_result_group","domain":"medium.com","entries":[{"type":"search_result","url":"https://medium.com/%40baicenxiao/avoiding-amnesia-some-practical-guides-to-mitigate-catastrophic-forgetting-in-llms-post-training-6a23e4f064cb","title":"Avoiding Amnesia: Some Practical Guides to Mitigate ...","snippet":"[8] Mitigating Catastrophic Forgetting in Large Language Models with Self-Synthesized Rehearsal. ACL 2024. https://aclanthology.org/2024.acl ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":32},"pub_date":1755986852.553,"attribution":"medium.com"}]},{"type":"search_result_group","domain":"neurips.cc","entries":[{"type":"search_result","url":"https://neurips.cc/virtual/2024/poster/97786","title":"CoIN: A Benchmark of Continual Instruction Tuning ...","snippet":"9 Dec 2024 \u2014 In this paper, we present CoIN, a comprehensive benchmark tailored for assessing the behavior of existing MLLMs under continual instruction ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":33},"pub_date":1727308800.0,"attribution":"neurips.cc"}]},{"type":"search_result_group","domain":"www.computer.org","entries":[{"type":"search_result","url":"https://www.computer.org/csdl/journal/tp/2025/03/10752992/21S24kWCL1m","title":"A Comprehensive Survey of Forgetting in Deep Learning ...","snippet":"by Z Wang \u00b7 2025 \u00b7 Cited by 111 \u2014 In online continual learning and meta-learning, where data or tasks are typically processed only once, these challenges are particularly pronounced. Furthermore ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":34},"pub_date":null,"attribution":"www.computer.org"}]},{"type":"search_result_group","domain":"www.mdpi.com","entries":[{"type":"search_result","url":"https://www.mdpi.com/2076-3417/15/9/5196","title":"Analysis of Model Merging Methods for Continual Updating ...","snippet":"by K Kubota \u00b7 2025 \u2014 We propose a novel framework that integrates model merging with federated learning to enable continual foundation model updates without centralizing sensitive ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":35},"pub_date":null,"attribution":"www.mdpi.com"}]}],"debug_sonic_thread_id":"thread_695649353e2c83248117d80f2fe78bd6","reasoning_status":"is_reasoning","reasoning_title":"Searching for 2025 advancements in continual learning","classifier_response":"default","request_id":"5f3f0455-8a59-45eb-a9c3-284af86d3bb4","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"74802954-2028-48c4-8090-6791560c86cc","turn_exchange_id":"b62969f7-f59e-4e1e-9b90-3e7bb7097612"},"recipient":"all","channel":null},"parent":"74802954-2028-48c4-8090-6791560c86cc","children":["fa915d7f-1c20-437d-8891-d02e81d66791"]},"fa915d7f-1c20-437d-8891-d02e81d66791":{"id":"fa915d7f-1c20-437d-8891-d02e81d66791","message":{"id":"fa915d7f-1c20-437d-8891-d02e81d66791","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1767262563.518561,"update_time":null,"content":{"content_type":"thoughts","thoughts":[{"summary":"Identifying key sources and focusing on 2025\u20132026 research","content":"We have some exciting models like HippoRAG 2 and CLOB, but need to rely on top-tier sources like arXiv and ACL Anthology for solid research. Since the user asked for \u201clatest advances,\u201d I\u2019ll focus on work from 2025-2026, including citations throughout, without relying on UI elements like image carousels.","chunks":["We have some exciting models like HippoRAG 2 and CLOB, but need to rely on top-tier sources like arXiv and ACL Anthology for solid research.","Since the user asked for \u201clatest advances,\u201d I\u2019ll focus on work from 2025-2026, including citations throughout, without relying on UI elements like image carousels."],"finished":true},{"summary":"Balancing UI elements with content structure","content":"The developer wants me to incorporate UI elements if they add value, but I\u2019m thinking navigation lists and carousels might not quite work for this context. A table could be more useful. I\u2019ll focus on explaining \"continual learning\" in frontier generative AI models, touching on both parametric and non-parametric methods, with a brief mention of HippoRAG 2 and the stability vs. plasticity tradeoff.","chunks":["The developer wants me to incorporate UI elements if they add value, but I\u2019m thinking navigation lists and carousels might not quite work for this context.","A table could be more useful.","I\u2019ll focus on explaining \"continual learning\" in frontier generative AI models, touching on both parametric and non-parametric methods, with a brief mention of HippoRAG 2 and the stability vs. plasticity tradeoff."],"finished":true},{"summary":"Refining model evaluation and safety considerations","content":"I\u2019ll mention the importance of evaluation metrics like forgetting and spurious forgetting, as well as how safety and alignment constraints complicate online learning for frontier models. I\u2019ll briefly touch on federated learning for privacy-preserving updates, though it\u2019s niche. For the accuracy of details, checking sources like OpenReview and PDFs will be helpful, but summarizing is fine.","chunks":["I\u2019ll mention the importance of evaluation metrics like forgetting and spurious forgetting, as well as how safety and alignment constraints complicate online learning for frontier models.","I\u2019ll briefly touch on federated learning for privacy-preserving updates, though it\u2019s niche.","For the accuracy of details, checking sources like OpenReview and PDFs will be helpful, but summarizing is fine."],"finished":true},{"summary":"Deciding how to handle PDFs for citation","content":"I think we can open and cite the PDF directly without needing to capture a screenshot, using web sources. The screenshot tool is only necessary for images or certain details from PDF pages. We can rely on snippets, but it's nice to confirm details in the full PDF or abstract.","chunks":["I think we can open and cite the PDF directly without needing to capture a screenshot, using web sources.","The screenshot tool is only necessary for images or certain details from PDF pages.","We can rely on snippets, but it's nice to confirm details in the full PDF or abstract."],"finished":true},{"summary":"Looking into vision-language action models for continual learning","content":"I\u2019m considering citing a survey on continual learning in generative models, which includes vision-language action models. To get more relevant information, I might search for \"vision-language action continual learning 2025\" to keep things current and accurate. Let's dive into this topic more!","chunks":["I\u2019m considering citing a survey on continual learning in generative models, which includes vision-language action models.","To get more relevant information, I might search for \"vision-language action continual learning 2025\" to keep things current and accurate. Let's dive into this topic more!"],"finished":true}],"source_analysis_msg_id":"beafca0e-b30e-4220-81ef-5982f7b79b16"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"is_reasoning","citations":[],"content_references":[],"classifier_response":"default","skip_reasoning_title":"Skip","request_id":"5f3f0455-8a59-45eb-a9c3-284af86d3bb4","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"5c9e767b-9287-445f-a413-15d842889d36","turn_exchange_id":"b62969f7-f59e-4e1e-9b90-3e7bb7097612"},"recipient":"all","channel":null},"parent":"5c9e767b-9287-445f-a413-15d842889d36","children":["55a904f5-3d21-496a-b216-2ad0751110bc"]},"55a904f5-3d21-496a-b216-2ad0751110bc":{"id":"55a904f5-3d21-496a-b216-2ad0751110bc","message":{"id":"55a904f5-3d21-496a-b216-2ad0751110bc","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1767262555.756321,"update_time":null,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"{\"search_query\":[{\"q\":\"2025 continual learning vision-language action models continual adaptation robots foundation models\",\"recency\":365},{\"q\":\"2025 continual learning VLA model continual learning vision language action arXiv\",\"recency\":365},{\"q\":\"2025 continual learning multimodal large language models hierarchical decoupling HiDe-LLaVA continual instruction tuning\",\"recency\":365},{\"q\":\"2025 continual learning diffusion model prior preservation loss generative replay ICCV 2025 joint diffusion models continual learning\",\"recency\":365}],\"response_length\":\"long\"}"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200012]},"is_complete":true,"citations":[],"content_references":[],"reasoning_status":"is_reasoning","search_queries":[{"type":"search","q":"2025 continual learning vision-language action models continual adaptation robots foundation models"},{"type":"search","q":"2025 continual learning VLA model continual learning vision language action arXiv"},{"type":"search","q":"2025 continual learning multimodal large language models hierarchical decoupling HiDe-LLaVA continual instruction tuning"},{"type":"search","q":"2025 continual learning diffusion model prior preservation loss generative replay ICCV 2025 joint diffusion models continual learning"}],"search_display_string":"Searching the web...","searched_display_string":"Searched the web...","reasoning_title":"Searching for 2025 advances in continual learning","classifier_response":"default","request_id":"5f3f0455-8a59-45eb-a9c3-284af86d3bb4","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"fa915d7f-1c20-437d-8891-d02e81d66791","turn_exchange_id":"b62969f7-f59e-4e1e-9b90-3e7bb7097612"},"recipient":"web.run","channel":null},"parent":"fa915d7f-1c20-437d-8891-d02e81d66791","children":["cfc51438-b35b-49b5-bb6c-6926248ff66c"]},"cfc51438-b35b-49b5-bb6c-6926248ff66c":{"id":"cfc51438-b35b-49b5-bb6c-6926248ff66c","message":{"id":"cfc51438-b35b-49b5-bb6c-6926248ff66c","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1767262583.6905105,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_model_queries":{"type":"search_model_queries","queries":["2025 continual learning vision-language action models continual adaptation robots foundation models","2025 continual learning VLA model continual learning vision language action arXiv","2025 continual learning multimodal large language models hierarchical decoupling HiDe-LLaVA continual instruction tuning","2025 continual learning diffusion model prior preservation loss generative replay ICCV 2025 joint diffusion models continual learning"]},"reasoning_status":"is_reasoning","reasoning_title":"Searching for 2025 advances in continual learning","classifier_response":"default","request_id":"5f3f0455-8a59-45eb-a9c3-284af86d3bb4","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"55a904f5-3d21-496a-b216-2ad0751110bc","turn_exchange_id":"b62969f7-f59e-4e1e-9b90-3e7bb7097612"},"recipient":"all","channel":null},"parent":"55a904f5-3d21-496a-b216-2ad0751110bc","children":["6dc9a0e4-d27f-4ebc-a1df-0a519904dec0"]},"6dc9a0e4-d27f-4ebc-a1df-0a519904dec0":{"id":"6dc9a0e4-d27f-4ebc-a1df-0a519904dec0","message":{"id":"6dc9a0e4-d27f-4ebc-a1df-0a519904dec0","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1767262583.6821325,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_result_groups":[{"type":"search_result_group","domain":"openaccess.thecvf.com","entries":[{"type":"search_result","url":"https://openaccess.thecvf.com/content/ICCV2025/papers/Skiers_Joint_Diffusion_Models_in_Continual_Learning_ICCV_2025_paper.pdf","title":"[PDF] Joint Diffusion Models in Continual Learning - CVF Open Access","snippet":"In this work, we introduce JDCL \u2013 a new method for con- tinual learning with generative rehearsal based on joint dif- fusion models.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":0},"pub_date":null,"attribution":"openaccess.thecvf.com"},{"type":"search_result","url":"https://openaccess.thecvf.com/content/ICCV2025/html/Skiers_Joint_Diffusion_Models_in_Continual_Learning_ICCV_2025_paper.html","title":"Joint Diffusion Models in Continual Learning - CVF Open Access","snippet":"In this work, we introduce JDCL - a new method for continual learning with generative rehearsal based on joint diffusion models. Neural networks suffer from ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"openaccess.thecvf.com"},{"type":"search_result","url":"https://openaccess.thecvf.com/content/ICCV2025/papers/Li_CoA-VLA_Improving_Vision-Language-Action_Models_via_Visual-Text_Chain-of-Affordance_ICCV_2025_paper.pdf","title":"CoA-VLA: Improving Vision-Language-Action Models via ...","snippet":"by J Li \u00b7 2025 \u00b7 Cited by 4 \u2014 Our method leverages visual affordance in robot learning, con- ceptualizing various actions and interactions with objects or the environment that a robot can ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"openaccess.thecvf.com"}]},{"type":"search_result_group","domain":"arxiv.org","entries":[{"type":"search_result","url":"https://arxiv.org/html/2512.06951v1","title":"Task adaptation of Vision-Language-Action model","snippet":"7 Dec 2025 \u2014 We present a vision-action policy that won 1st place in the 2025 ... action (VLA) model that uses flow matching to predict action sequences.Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2503.12941","title":"Hierarchical Decoupling for Continual Instruction Tuning of ...","snippet":"by H Guo \u00b7 2025 \u00b7 Cited by 17 \u2014 Instruction tuning is widely used to improve a pre-trained Multimodal Large Language Model (MLLM) by training it on curated task-specific ...Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2411.08224v3","title":"Joint Diffusion Models in Continual Learning - arXiv","snippet":"In this work, we introduce JDCL \u2013 a new method for continual learning with generative rehearsal based on joint diffusion models. Neural networks ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":4},"pub_date":1759708800.0,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2511.18085","title":"Continually Evolving Skill Knowledge in Vision Language ...","snippet":"by Y Wu \u00b7 2025 \u2014 The diversity of manipulation skills and environmental complexity make continual learning a key challenge for VLA models toward general robotic ...Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2511.18960v1","title":"AVA-VLA: Improving Vision-Language-Action models with ...","snippet":"24 Nov 2025 \u2014 The better you learn, the smarter you prune: Towards efficient vision-language-action models via differentiable token pruning. arXiv preprint ...Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2511.18085v2","title":"Continually Evolving Skill Knowledge in Vision Language ...","snippet":"25 Nov 2025 \u2014 Developing general robot intelligence in open environments requires continual skill learning. Recent Vision-Language-Action (VLA) models ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":24},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2505.23705","title":"Knowledge Insulating Vision-Language-Action Models","snippet":"by D Driess \u00b7 2025 \u00b7 Cited by 37 \u2014 Abstract:Vision-language-action (VLA) models provide a powerful approach to training control policies for physical systems, such as robots, ...Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":25},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2503.12941","title":"HiDe-LLaVA: Hierarchical Decoupling for Continual ...","snippet":"by H Guo \u00b7 2025 \u00b7 Cited by 17 \u2014 Instruction tuning is widely used to improve a pre-trained Multimodal Large Language. Model (MLLM) by training it on curated task-.Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":26},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2411.08224","title":"[2411.08224] Joint Diffusion models in Continual Learning - arXiv","snippet":"In this work, we introduce JDCL - a new method for continual learning with generative rehearsal based on joint diffusion models.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":27},"pub_date":1731369600.0,"attribution":"arxiv.org"}]},{"type":"search_result_group","domain":"web3.arxiv.org","entries":[{"type":"search_result","url":"https://web3.arxiv.org/abs/2511.18085","title":"Continually Evolving Skill Knowledge in Vision Language ...","snippet":"by Y Wu \u00b7 2025 \u2014 We propose Stellar VLA, a knowledge-driven continual learning framework with two variants: T-Stellar, modeling task-centric knowledge space, and ...Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"web3.arxiv.org"}]},{"type":"search_result_group","domain":"www.techrxiv.org","entries":[{"type":"search_result","url":"https://www.techrxiv.org/users/956965/articles/1326137/master/file/data/eart2025recipevla/eart2025recipevla.pdf?inline=true","title":"Recipe for Vision-Language-Action Models in Robotic ...","snippet":"This survey offers a comprehensive and systematic exam- ination of the current landscape of Vision-Language-Action. (VLA) models for robotic manipulation, ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"www.techrxiv.org"}]},{"type":"search_result_group","domain":"aclanthology.org","entries":[{"type":"search_result","url":"https://aclanthology.org/2025.acl-long.666/","title":"Hierarchical Decoupling for Continual Instruction Tuning of ...","snippet":"by H Guo \u00b7 2025 \u00b7 Cited by 17 \u2014 In this paper, we propose a task-specific expansion and task-general fusion framework based on the variations in Centered Kernel Alignment (CKA) ...Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2025.acl-long.666.pdf","title":"Hierarchical Decoupling for Continual Instruction Tuning of ...","snippet":"by H Guo \u00b7 2025 \u00b7 Cited by 17 \u2014 Instruction tuning is widely used to improve a pre-trained Multimodal Large Language. Model (MLLM) by training it on curated task-.Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":14},"pub_date":1752153064.0,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2025.emnlp-main.273.pdf","title":"ChatVLA: Unified Multimodal Understanding and Robot ...","snippet":"by Z Zhou \u00b7 2025 \u00b7 Cited by 63 \u2014 Recent advancements in Vision-Language-Action. (VLA) (Black et al., 2024; Kim et al., 2024; Wen et al., 2024c, 2025) models have largely ...Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":21},"pub_date":1761174131.0,"attribution":"aclanthology.org"}]},{"type":"search_result_group","domain":"rohitbandaru.github.io","entries":[{"type":"search_result","url":"https://rohitbandaru.github.io/blog/Foundation-Models-for-Robotics-VLA/","title":"Foundation Models for Robotics: Vision-Language-Action ...","snippet":"28 Sept 2025 \u2014 2025, train VLAs with regression loss to predict continuous actions. However, this approach is not as effective on its own compared to ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"rohitbandaru.github.io"}]},{"type":"search_result_group","domain":"www.alphaxiv.org","entries":[{"type":"search_result","url":"https://www.alphaxiv.org/overview/2511.18085v2","title":"Continually Evolving Skill Knowledge in Vision Language ...","snippet":"Current VLA models face three critical challenges in continual learning scenarios. First, they demonstrate heavy dependence on task-specific fine-tuning, ...Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"www.alphaxiv.org"}]},{"type":"search_result_group","domain":"github.com","entries":[{"type":"search_result","url":"https://github.com/Ghy0501/HiDe-LLaVA","title":"HiDe-LLaVA: Hierarchical Decoupling for Continual ...","snippet":"Instruction tuning is widely used to enhance a pre-trained Multimodal Large Language Model (MLLM) to understand and follow human instructions by training it ...Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln","title":"jonyzhang2023/awesome-embodied-vla-va-vln","snippet":"This repository aims to organize and showcase the state-of-the-art technologies in robot learning, including vision-language-action (VLA) models.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"github.com"}]},{"type":"search_result_group","domain":"www.researchgate.net","entries":[{"type":"search_result","url":"https://www.researchgate.net/publication/385785942_Joint_Diffusion_models_in_Continual_Learning","title":"(PDF) Joint Diffusion models in Continual Learning - ResearchGate","snippet":"In this work, we introduce JDCL - a new method for continual learning with generative rehearsal based on joint diffusion models.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":12},"pub_date":1731369600.0,"attribution":"www.researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/394303097_HiDe-LLaVA_Hierarchical_Decoupling_for_Continual_Instruction_Tuning_of_Multimodal_Large_Language_Model","title":"Hierarchical Decoupling for Continual Instruction Tuning of ...","snippet":"7 Aug 2025 \u2014 Language Modeling. Conference Paper. HiDe-LLaVA: Hierarchical Decoupling for Continual Instruction Tuning of Multimodal Large Language Model.Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":22},"pub_date":1735689600.0,"attribution":"www.researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/399072662_Foundation_Models_for_Construction_Robotics_Transfer_Learning_and_Vision-Language-Action_Integration","title":"Transfer Learning and Vision-Language-Action Integration","snippet":"6 days ago \u2014 This paper investigates the adaptation of pre-trained robotics foundation models, specifically RT-2 and PaLM-E, for construction automation ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":32},"pub_date":null,"attribution":"www.researchgate.net"}]},{"type":"search_result_group","domain":"www.ijcai.org","entries":[{"type":"search_result","url":"https://www.ijcai.org/proceedings/2025/0328.pdf","title":"[PDF] Generative Diffusion Replay for Continual Anomaly Detection - IJCAI","snippet":"Continual Anomaly Detection (CAD) enables anomaly detection models in learning new classes while preserving knowledge of historical classes.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":15},"pub_date":1758198534.0,"attribution":"www.ijcai.org"}]},{"type":"search_result_group","domain":"liner.com","entries":[{"type":"search_result","url":"https://liner.com/review/hidellava-hierarchical-decoupling-for-continual-instruction-tuning-multimodal-large-language","title":"HiDe-LLaVA: Hierarchical Decoupling for Continual ...","snippet":"Regarding this ACL 2025 paper, this review summarizes HiDe-LLaVA, a hierarchical decoupling method for continual instruction tuning of MLLMs.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":18},"pub_date":1742169600.0,"attribution":"liner.com"}]},{"type":"search_result_group","domain":"iccv.thecvf.com","entries":[{"type":"search_result","url":"https://iccv.thecvf.com/Conferences/2025/AcceptedPapers","title":"ICCV 2025 Accepted Papers","snippet":"Instruction-Grounded Visual Projectors for Continual Learning of Generative Vision-Language Models Poster Session 1 & Exhibit Hall ... DiffPS: Leveraging Prior ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":19},"pub_date":null,"attribution":"iccv.thecvf.com"}]},{"type":"search_result_group","domain":"dl.acm.org","entries":[{"type":"search_result","url":"https://dl.acm.org/doi/10.1145/3705725","title":"Recent Advances of Foundation Language Models-based ...","snippet":"This comprehensive survey examines recent advances in continual learning applied to foundation language models, including pre-trained language models, large ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":20},"pub_date":null,"attribution":"dl.acm.org"}]},{"type":"search_result_group","domain":"www.semanticscholar.org","entries":[{"type":"search_result","url":"https://www.semanticscholar.org/paper/Joint-Diffusion-models-in-Continual-Learning-Skier%27s-Deja/d371ac6c03dee81f33691e11f0f3e1cd08a9673e","title":"Joint Diffusion models in Continual Learning - Semantic Scholar","snippet":"This work proposes to extend the semi-supervised continual learning setup by combining a continually trained classifier with a diffusion-based generative ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":23},"pub_date":null,"attribution":"www.semanticscholar.org"}]},{"type":"search_result_group","domain":"iclr.cc","entries":[{"type":"search_result","url":"https://iclr.cc/virtual/2025/workshop/23977","title":"Generative Models for Robot Learning","snippet":"This workshop proposal focuses on generative models for robot learning, which lies in the important and fundamental field of AI and robotics. Learning-based ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":28},"pub_date":null,"attribution":"iclr.cc"}]},{"type":"search_result_group","domain":"openreview.net","entries":[{"type":"search_result","url":"https://openreview.net/pdf/1ce871c2effb9d50718a6160a602d79f305a10eb.pdf","title":"Interactive Post-Training for Vision-Language-Action Models","snippet":"vision-language-action model with open-world generalization. 704. arXiv preprint arXiv:2504.16054, 2025. 2. 705. [12] Moo Jin Kim, Karl Pertsch, Siddharth ...Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":29},"pub_date":1747432210.0,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/revisions?id=2SBzSnwjQB","title":"Revisions","snippet":"[2] HiDe-LLaVA: Hierarchical Decoupling for Continual Instruction Tuning of Multimodal Large Language Model. ACL'25. Note \u2013 Signatures: ICLR.cc/2026 ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":30},"pub_date":null,"attribution":"openreview.net"}]},{"type":"search_result_group","domain":"www.theverge.com","entries":[{"type":"search_result","url":"https://www.theverge.com/news/631743/nvidia-issac-groot-n1-robotics-foundation-model-available","title":"Nvidia says 'the age of generalist robotics is here'","snippet":"Nvidia has officially launched Isaac GR00T N1, an open-source, pretrained, and customizable foundation model designed to accelerate the development of general-purpose humanoid robots. CEO Jensen Huang unveiled the technology during his GTC 2025 keynote, declaring the arrival of \u201cthe age of generalist robotics.\u201d Isaac GR00T N1 enhances robot adaptability and reasoning through a dual-system cognitive model: System 1 handles fast, reflex-like responses using human and synthetic training data, while System 2 reasons with a vision-language model to plan and execute complex tasks. Companies such as 1X Technologies, Boston Dynamics, Agility Robotics, Mentee Robotics, and Neura Robotics have gained early access to GR00T N1 to enhance their robot capabilities. 1X Technologies showcased their NEO Gamma robot performing autonomous tasks using the GR00T model. Nvidia has also made the training datasets and evaluation tools publicly available via Hugging Face and GitHub, emphasizing a collaborative push towards expanding the role of robotics in daily life.","ref_id":{"turn_index":3,"ref_type":"news","ref_index":44},"pub_date":1742389977.0,"attribution":"www.theverge.com"},{"type":"search_result","url":"https://www.theverge.com/news/628021/google-deepmind-gemini-robotics-ai-models","title":"Google DeepMind's new AI models help robots perform physical tasks, even without training","snippet":"Google DeepMind has introduced two new AI models, Gemini Robotics and Gemini Robotics-ER, designed to improve robots' real-world physical capabilities. Built on the Gemini 2.0 platform, Gemini Robotics is a vision-language-action model that enables robots to handle new scenarios, even without specific training. The model enhances robot generality, interactivity, and dexterity\u2014allowing for advanced tasks like folding paper or removing bottle caps. \n\nGemini Robotics-ER (Embodied Reasoning) extends this functionality by incorporating complex reasoning abilities, enabling robots to understand spatial contexts and manipulate objects effectively, such as packing a lunchbox. It can interface with existing robotic control systems, allowing developers to implement more advanced capabilities. \n\nDeepMind emphasizes safety, employing a layered approach and training models to evaluate the risk of actions. The company is also releasing benchmarks to support broader AI safety research. Partnerships with companies like Apptronik, Agile Robots, and Boston Dynamics aim to integrate these models into next-generation humanoid robots. This marks a significant step toward more adaptive, intelligent, and physically capable robotic systems for diverse real-world applications.","ref_id":{"turn_index":3,"ref_type":"news","ref_index":46},"pub_date":1741791600.0,"attribution":"www.theverge.com"}]},{"type":"search_result_group","domain":"www.wired.com","entries":[{"type":"search_result","url":"https://www.wired.com/story/googles-gemini-robotics-ai-model-that-reaches-into-the-physical-world","title":"Google's Gemini Robotics AI Model Reaches Into the Physical World","snippet":"Google DeepMind has unveiled Gemini Robotics, a new AI model that bridges language, vision, and physical interaction to power more adaptive and capable robots. Demonstrations showcased robot arms executing tasks like folding paper and handling objects via spoken commands. The model, a version of Gemini 2.0, enables robots to generalize and perform tasks across varying hardware platforms. DeepMind also introduced Gemini Robotics-ER, which offers visual-spatial understanding for researchers to train their own models. This advancement signifies a major step forward in robotic embodiment, leveraging lessons from large language models to better control physical systems.\n\nCollaborations with companies like Boston Dynamics and Agility Robotics are underway, aiming to bring these technologies to diverse robot platforms. However, safety concerns remain. To address this, DeepMind launched the ASIMOV benchmark to evaluate and prevent potentially harmful robot behaviors. Despite the progress, DeepMind emphasizes the technology is still in early stages with no immediate commercialization plans. The project underscores a broader shift in AI development\u2014from purely conversational agents to physically interactive systems\u2014while striving to maintain responsible safety measures.","ref_id":{"turn_index":3,"ref_type":"news","ref_index":49},"pub_date":1741791600.0,"attribution":"www.wired.com"},{"type":"search_result","url":"https://www.wired.com/story/this-humanoid-robot-is-showing-signs-of-generalized-learning","title":"This Robot Only Needs a Single AI Model to Master Humanlike Movements","snippet":"Boston Dynamics\u2019 humanoid robot, Atlas, has achieved a major milestone by learning to walk and manipulate objects using a single AI model\u2014a significant leap from the conventional approach of using separate models for different tasks. Developed in partnership with the Toyota Research Institute (TRI), the robot's new single model, called a Large Behavior Model (LBM), integrates visual, proprioceptive, and language inputs to execute tasks much like a human would. This unified model enables Atlas not only to move naturally, such as rebalancing while reaching, but also to demonstrate emergent behaviors like recovering from dropped items without being explicitly trained for such actions.\n\nAccording to TRI's Russ Tedrake, treating the robot\u2019s feet as \u201cadditional hands\u201d contributes to its generalist capabilities\u2014a concept inspired by the success of large language models (LLMs) like ChatGPT. The work is seen as a step toward robots with generalized intelligence capable of operating in messy real-world environments and rapidly acquiring new skills without redesign or retraining. While experts caution against overinterpreting such emergent behaviors due to potential hidden training data, there\u2019s optimism that these advancements indicate robotics may be undergoing a transformative shift similar to that seen in generative AI.","ref_id":{"turn_index":3,"ref_type":"news","ref_index":54},"pub_date":1756922400.0,"attribution":"www.wired.com"}]},{"type":"search_result_group","domain":"www.ft.com","entries":[{"type":"search_result","url":"https://www.ft.com/content/f0b1dff8-8936-4e05-9e0f-b1bbbb40dc02","title":"Google DeepMind unveils new AI models in race to make robots useful","snippet":"Google DeepMind has announced the release of its new AI models for robotics\u2014Gemini Robotics and Gemini Robotics-ER\u2014marking a significant advance in the push for general-purpose robots capable of functioning in complex real-world settings. These models integrate the powerful reasoning abilities of large language models to help robots perform diverse and nuanced tasks such as folding origami, organizing desks, managing headphone wires, and even playing miniature basketball. The models are trained using DeepMind's Gemini 2.0 language model, enhancing robots' ability to adapt to unpredictable environments, follow verbal commands, and handle delicate objects with dexterity.\n\nGoogle DeepMind is also collaborating with startup Apptronik to develop humanoid robots powered by this technology. The initiative places DeepMind among tech giants like Tesla and OpenAI racing to create AI-driven robotics solutions with transformative potential across sectors like manufacturing and healthcare. Experts highlight the significance of cloud-based operation, extensive language model integration, and spatial reasoning improvements in the Gemini models, though they caution that general-purpose robots are still not ready for widespread deployment. Despite clear progress, substantial challenges remain in bringing robots from lab environments to everyday human spaces.","ref_id":{"turn_index":3,"ref_type":"news","ref_index":51},"pub_date":1741791651.728,"attribution":"www.ft.com"}]},{"type":"search_result_group","domain":"www.livescience.com","entries":[{"type":"search_result","url":"https://www.livescience.com/technology/robotics/robots-receive-major-intelligence-boost-thanks-to-google-deepminds-thinking-ai-a-pair-of-models-that-help-machines-understand-the-world","title":"Robots receive major intelligence boost thanks to Google DeepMind's 'thinking AI' - a pair of models that help machines understand the world","snippet":"Google DeepMind has significantly advanced robotics intelligence by introducing two new AI models, Gemini Robotics 1.5 and Gemini Robotics-ER 1.5. These models expand on the initial Gemini Robotics AI, which was based on the Gemini large language model but tailored for robotic tasks. The enhanced models now enable robots to perform complex, multistep tasks involving real-world reasoning and adaptation. For instance, the Aloha 2 robot successfully sorted fruits by color, narrating its process in natural language.\n\nThe models work in tandem: Gemini Robotics-ER 1.5 acts as the \"brain\" (a vision-language model that processes input and issues commands), while Robotics 1.5 is the \"hands and eyes\" (a vision-language-action model that executes tasks and provides feedback). Impressively, the robots can access external information via tools like Google Search to adapt behaviors, such as following local recycling regulations.\n\nAnother breakthrough is their cross-platform adaptability. Knowledge gained on one robot can transfer across multiple systems like the Apollo humanoid and Franka bi-arm robots, facilitating general-purpose robotics. These innovations mark a critical step toward robots performing everyday tasks with greater autonomy and intelligent reasoning.","ref_id":{"turn_index":3,"ref_type":"news","ref_index":53},"pub_date":1760098200.0,"attribution":"www.livescience.com"}]}],"debug_sonic_thread_id":"thread_695649353e2c83248117d80f2fe78bd6","reasoning_status":"is_reasoning","reasoning_title":"Searching for 2025 advances in continual learning","classifier_response":"default","request_id":"5f3f0455-8a59-45eb-a9c3-284af86d3bb4","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"cfc51438-b35b-49b5-bb6c-6926248ff66c","turn_exchange_id":"b62969f7-f59e-4e1e-9b90-3e7bb7097612"},"recipient":"all","channel":null},"parent":"cfc51438-b35b-49b5-bb6c-6926248ff66c","children":["70249656-6a11-4cb6-9727-d33f9f2e536c"]},"70249656-6a11-4cb6-9727-d33f9f2e536c":{"id":"70249656-6a11-4cb6-9727-d33f9f2e536c","message":{"id":"70249656-6a11-4cb6-9727-d33f9f2e536c","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1767262590.908227,"update_time":null,"content":{"content_type":"thoughts","thoughts":[{"summary":"Exploring continual learning and model specifics","content":"I\u2019m thinking it\u2019s better to open PDFs for deeper insights, although screenshots are required if we\u2019re analyzing and extracting from them. I\u2019ll forgo too much detailed analysis, but might mention general themes when citing. I\u2019ll also gather info on \"RECALL\" for model merging and explore \"forward-only continual learning.\" And, I\u2019ll include concepts like \"spurious forgetting,\" \"latent replay,\" and possibly \"vision-language action models\" if relevant!","chunks":["I\u2019m thinking it\u2019s better to open PDFs for deeper insights, although screenshots are required if we\u2019re analyzing and extracting from them.","I\u2019ll forgo too much detailed analysis, but might mention general themes when citing.","I\u2019ll also gather info on \"RECALL\" for model merging and explore \"forward-only continual learning.\" And, I\u2019ll include concepts like \"spurious forgetting,\" \"latent replay,\" and possibly \"vision-language action models\" if relevant!"],"finished":true},{"summary":"Considering robotics models and continual learning","content":"The news sources on robotics foundation models, like from The Verge and Wired, discuss adaptation and generalization in new scenarios, though not specifically continual learning. Still, I can mention emerging robotics models and the challenge of continual learning in generative AI. I'll include sources on skill learning frameworks and \"knowledge insulating\" to broaden the response but stay mindful of how we represent news accurately.","chunks":["The news sources on robotics foundation models, like from The Verge and Wired, discuss adaptation and generalization in new scenarios, though not specifically continual learning.","Still, I can mention emerging robotics models and the challenge of continual learning in generative AI.","I'll include sources on skill learning frameworks and \"knowledge insulating\" to broaden the response but stay mindful of how we represent news accurately."],"finished":true},{"summary":"Crafting a focused answer on continual learning","content":"The user's request is clear: I\u2019ll give an overview of continual learning in generative models. I'll highlight important papers from 2024-2025 and provide a timeline, while focusing mainly on methods for generative models rather than general robotics. I\u2019ll also refer to key surveys like \"Comprehensive Survey on Continual Learning\" and \"Parameter-Efficient Continual Fine-Tuning\" for supporting details. I'll open sources to explore new methods and taxonomy.","chunks":["The user's request is clear: I\u2019ll give an overview of continual learning in generative models.","I'll highlight important papers from 2024-2025 and provide a timeline, while focusing mainly on methods for generative models rather than general robotics.","I\u2019ll also refer to key surveys like \"Comprehensive Survey on Continual Learning\" and \"Parameter-Efficient Continual Fine-Tuning\" for supporting details. I'll open sources to explore new methods and taxonomy."],"finished":true}],"source_analysis_msg_id":"b7351e9f-c1cb-49aa-bcd4-dafd74838a1f"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"is_reasoning","citations":[],"content_references":[],"classifier_response":"default","skip_reasoning_title":"Skip","request_id":"5f3f0455-8a59-45eb-a9c3-284af86d3bb4","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"6dc9a0e4-d27f-4ebc-a1df-0a519904dec0","turn_exchange_id":"b62969f7-f59e-4e1e-9b90-3e7bb7097612"},"recipient":"all","channel":null},"parent":"6dc9a0e4-d27f-4ebc-a1df-0a519904dec0","children":["2b95a89f-cdbb-454f-97ef-6df325b1c299"]},"2b95a89f-cdbb-454f-97ef-6df325b1c299":{"id":"2b95a89f-cdbb-454f-97ef-6df325b1c299","message":{"id":"2b95a89f-cdbb-454f-97ef-6df325b1c299","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1767262588.182144,"update_time":null,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"{\"open\":[{\"ref_id\":\"turn0search1\"},{\"ref_id\":\"turn1search2\"},{\"ref_id\":\"turn1search3\"},{\"ref_id\":\"turn2search10\"},{\"ref_id\":\"turn1search4\"},{\"ref_id\":\"turn2search14\"},{\"ref_id\":\"turn0search2\"}],\"response_length\":\"short\"}"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200012]},"is_complete":true,"citations":[],"content_references":[],"reasoning_status":"is_reasoning","reasoning_title":"Analyzing continual learning in generative AI models","classifier_response":"default","request_id":"5f3f0455-8a59-45eb-a9c3-284af86d3bb4","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"70249656-6a11-4cb6-9727-d33f9f2e536c","turn_exchange_id":"b62969f7-f59e-4e1e-9b90-3e7bb7097612"},"recipient":"web.run","channel":null},"parent":"70249656-6a11-4cb6-9727-d33f9f2e536c","children":["e51afa97-953c-45e1-abe3-f1e2d5c84789"]},"e51afa97-953c-45e1-abe3-f1e2d5c84789":{"id":"e51afa97-953c-45e1-abe3-f1e2d5c84789","message":{"id":"e51afa97-953c-45e1-abe3-f1e2d5c84789","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1767262600.5747936,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_result_groups":[{"type":"search_result_group","domain":"arxiv.org","entries":[{"type":"search_result","url":"https://arxiv.org/html/2506.13045v3","title":"A Comprehensive Survey on Continual Learning in Generative Models","snippet":"Total lines: 854\n","ref_id":{"turn_index":4,"ref_type":"view","ref_index":0},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2510.15103","title":"[2510.15103] Continual Learning via Sparse Memory Finetuning","snippet":"Total lines: 200\n","ref_id":{"turn_index":4,"ref_type":"view","ref_index":1},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2509.17183","title":"[2509.17183] LifeAlign: Lifelong Alignment for Large Language Models with Memory-Augmented Focalized Preference Optimization","snippet":"Total lines: 201\n","ref_id":{"turn_index":4,"ref_type":"view","ref_index":2},"pub_date":null,"attribution":"arxiv.org"}]},{"type":"search_result_group","domain":"openreview.net","entries":[{"type":"search_result","url":"https://openreview.net/forum?id=LWH8yn4HS2","title":"From RAG to Memory: Non-Parametric Continual Learning for Large Language Models | OpenReview","snippet":"Total lines: 55\n","ref_id":{"turn_index":4,"ref_type":"view","ref_index":3},"pub_date":null,"attribution":"openreview.net"}]},{"type":"search_result_group","domain":"openaccess.thecvf.com","entries":[{"type":"search_result","url":"https://openaccess.thecvf.com/content/ICCV2025/papers/Skiers_Joint_Diffusion_Models_in_Continual_Learning_ICCV_2025_paper.pdf","title":"Joint Diffusion Models in Continual Learning","snippet":"Total lines: 1044\n","ref_id":{"turn_index":4,"ref_type":"view","ref_index":4},"pub_date":null,"attribution":"openaccess.thecvf.com"}]},{"type":"search_result_group","domain":"aclanthology.org","entries":[{"type":"search_result","url":"https://aclanthology.org/2025.emnlp-main.829.pdf","title":"","snippet":"Total lines: 1336\n","ref_id":{"turn_index":4,"ref_type":"view","ref_index":5},"pub_date":null,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2025.acl-long.289.pdf","title":"","snippet":"Total lines: 1343\n","ref_id":{"turn_index":4,"ref_type":"view","ref_index":6},"pub_date":null,"attribution":"aclanthology.org"}]}],"debug_sonic_thread_id":"thread_695649353e2c83248117d80f2fe78bd6","reasoning_status":"is_reasoning","reasoning_title":"Analyzing continual learning in generative AI models","classifier_response":"default","request_id":"5f3f0455-8a59-45eb-a9c3-284af86d3bb4","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"2b95a89f-cdbb-454f-97ef-6df325b1c299","turn_exchange_id":"b62969f7-f59e-4e1e-9b90-3e7bb7097612"},"recipient":"all","channel":null},"parent":"2b95a89f-cdbb-454f-97ef-6df325b1c299","children":["eb6f35ff-5c20-482b-be49-c81624ded6a2"]},"eb6f35ff-5c20-482b-be49-c81624ded6a2":{"id":"eb6f35ff-5c20-482b-be49-c81624ded6a2","message":{"id":"eb6f35ff-5c20-482b-be49-c81624ded6a2","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1767262611.086452,"update_time":null,"content":{"content_type":"thoughts","thoughts":[{"summary":"Clarifying the screenshot requirement for PDFs","content":"Based on the instructions, it looks like I should use the screenshot tool whenever analyzing a PDF, including when reading content like text lines. However, since we\u2019ve already opened and analyzed some PDFs without using a screenshot, it seems I might not need images. Still, the rule seems clear: I must use screenshots for PDFs.","chunks":["Based on the instructions, it looks like I should use the screenshot tool whenever analyzing a PDF, including when reading content like text lines.","However, since we\u2019ve already opened and analyzed some PDFs without using a screenshot, it seems I might not need images.","Still, the rule seems clear: I must use screenshots for PDFs."],"finished":true}],"source_analysis_msg_id":"cd2ecbfe-a14a-4ca1-96c1-44ba3103894d"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"is_reasoning","citations":[],"content_references":[],"classifier_response":"default","skip_reasoning_title":"Skip","request_id":"5f3f0455-8a59-45eb-a9c3-284af86d3bb4","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"e51afa97-953c-45e1-abe3-f1e2d5c84789","turn_exchange_id":"b62969f7-f59e-4e1e-9b90-3e7bb7097612"},"recipient":"all","channel":null},"parent":"e51afa97-953c-45e1-abe3-f1e2d5c84789","children":["bfda79c9-5bd4-4e14-910b-b93c51a6538f"]},"bfda79c9-5bd4-4e14-910b-b93c51a6538f":{"id":"bfda79c9-5bd4-4e14-910b-b93c51a6538f","message":{"id":"bfda79c9-5bd4-4e14-910b-b93c51a6538f","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1767262600.930845,"update_time":null,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"{\"screenshot\":[{\"ref_id\":\"turn4view4\",\"pageno\":0},{\"ref_id\":\"turn4view5\",\"pageno\":0},{\"ref_id\":\"turn4view6\",\"pageno\":0}],\"response_length\":\"short\"}"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200012]},"is_complete":true,"citations":[],"content_references":[],"reasoning_status":"is_reasoning","reasoning_title":"Screenshotting PDF pages per instructions","classifier_response":"default","request_id":"5f3f0455-8a59-45eb-a9c3-284af86d3bb4","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"eb6f35ff-5c20-482b-be49-c81624ded6a2","turn_exchange_id":"b62969f7-f59e-4e1e-9b90-3e7bb7097612"},"recipient":"web.run","channel":null},"parent":"eb6f35ff-5c20-482b-be49-c81624ded6a2","children":["67f4c484-81ea-494a-9e3b-c20d7c7cbe92"]},"67f4c484-81ea-494a-9e3b-c20d7c7cbe92":{"id":"67f4c484-81ea-494a-9e3b-c20d7c7cbe92","message":{"id":"67f4c484-81ea-494a-9e3b-c20d7c7cbe92","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1767262609.0231743,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_result_groups":[],"debug_sonic_thread_id":"thread_695649353e2c83248117d80f2fe78bd6","reasoning_status":"is_reasoning","reasoning_title":"Screenshotting PDF pages per instructions","classifier_response":"default","request_id":"5f3f0455-8a59-45eb-a9c3-284af86d3bb4","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"bfda79c9-5bd4-4e14-910b-b93c51a6538f","turn_exchange_id":"b62969f7-f59e-4e1e-9b90-3e7bb7097612"},"recipient":"all","channel":null},"parent":"bfda79c9-5bd4-4e14-910b-b93c51a6538f","children":["475dfd50-5d37-4c18-8de5-d08181853025"]},"475dfd50-5d37-4c18-8de5-d08181853025":{"id":"475dfd50-5d37-4c18-8de5-d08181853025","message":{"id":"475dfd50-5d37-4c18-8de5-d08181853025","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1767262627.703725,"update_time":null,"content":{"content_type":"thoughts","thoughts":[{"summary":"Troubleshooting screenshot tool issue","content":"It seems like the screenshot tool only works with reference IDs that are directly associated with PDFs. Although I opened a PDF with the content type application/pdf, there\u2019s an error because the reference ID might not match the one the tool is expecting. I\u2019ll try using the view ID from web.open instead.","chunks":["It seems like the screenshot tool only works with reference IDs that are directly associated with PDFs.","Although I opened a PDF with the content type application/pdf, there\u2019s an error because the reference ID might not match the one the tool is expecting.","I\u2019ll try using the view ID from web.open instead."],"finished":true},{"summary":"Investigating screenshot tool issue","content":"It seems like the PDF might be too large or there could be an issue with page number. The screenshot tool likely requires a proper view ID, and possibly the reference ID for the PDF. I\u2019ll try opening another PDF first to get the correct view ID, or try searching with a different result ID.","chunks":["It seems like the PDF might be too large or there could be an issue with page number.","The screenshot tool likely requires a proper view ID, and possibly the reference ID for the PDF.","I\u2019ll try opening another PDF first to get the correct view ID, or try searching with a different result ID."],"finished":true},{"summary":"Troubleshooting screenshot tool issue","content":"The screenshot tool is still failing \u2014 it might be a bug. I\u2019ll try a smaller PDF or another view ID. The error could be due to page number issues, or the tool expecting a specific schema. I\u2019ll double-check if I need a direct URL instead of the view ID for this to work.","chunks":["The screenshot tool is still failing \u2014 it might be a bug.","I\u2019ll try a smaller PDF or another view ID.","The error could be due to page number issues, or the tool expecting a specific schema.","I\u2019ll double-check if I need a direct URL instead of the view ID for this to work."],"finished":true},{"summary":"Testing cartoon-style screenshot for a stable source","content":"It might be an issue with non-standard sites. I'll try a stable source like arXiv or ACL anthology. If that fails, maybe the screenshot tool can't fetch external PDFs due to cross-origin restrictions. I\u2019ll try opening the URL with a reference ID to see if that works.","chunks":["It might be an issue with non-standard sites.","I'll try a stable source like arXiv or ACL anthology.","If that fails, maybe the screenshot tool can't fetch external PDFs due to cross-origin restrictions.","I\u2019ll try opening the URL with a reference ID to see if that works."],"finished":true}],"source_analysis_msg_id":"ffc305b9-3789-4f54-87f4-8485e20e5b90"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"is_reasoning","citations":[],"content_references":[],"classifier_response":"default","skip_reasoning_title":"Skip","request_id":"5f3f0455-8a59-45eb-a9c3-284af86d3bb4","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"67f4c484-81ea-494a-9e3b-c20d7c7cbe92","turn_exchange_id":"b62969f7-f59e-4e1e-9b90-3e7bb7097612"},"recipient":"all","channel":null},"parent":"67f4c484-81ea-494a-9e3b-c20d7c7cbe92","children":["d2318aa3-6f2c-434d-8ea1-f4accc7fd78f"]},"d2318aa3-6f2c-434d-8ea1-f4accc7fd78f":{"id":"d2318aa3-6f2c-434d-8ea1-f4accc7fd78f","message":{"id":"d2318aa3-6f2c-434d-8ea1-f4accc7fd78f","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1767262609.256614,"update_time":null,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"{\"open\":[{\"ref_id\":\"https://aclanthology.org/2025.acl-long.289.pdf\"},{\"ref_id\":\"https://aclanthology.org/2025.emnlp-main.829.pdf\"},{\"ref_id\":\"https://openaccess.thecvf.com/content/ICCV2025/papers/Skiers_Joint_Diffusion_Models_in_Continual_Learning_ICCV_2025_paper.pdf\"}],\"response_length\":\"short\"}"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200012]},"is_complete":true,"citations":[],"content_references":[],"reasoning_status":"is_reasoning","reasoning_title":"Troubleshooting screenshot tool validation error","classifier_response":"default","request_id":"5f3f0455-8a59-45eb-a9c3-284af86d3bb4","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"475dfd50-5d37-4c18-8de5-d08181853025","turn_exchange_id":"b62969f7-f59e-4e1e-9b90-3e7bb7097612"},"recipient":"web.run","channel":null},"parent":"475dfd50-5d37-4c18-8de5-d08181853025","children":["eb244dba-d9f8-4f2e-b7ff-6135886633cd"]},"eb244dba-d9f8-4f2e-b7ff-6135886633cd":{"id":"eb244dba-d9f8-4f2e-b7ff-6135886633cd","message":{"id":"eb244dba-d9f8-4f2e-b7ff-6135886633cd","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1767262626.367288,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_result_groups":[{"type":"search_result_group","domain":"aclanthology.org","entries":[{"type":"search_result","url":"https://aclanthology.org/2025.acl-long.289.pdf","title":"","snippet":"Total lines: 1343\n","ref_id":{"turn_index":6,"ref_type":"view","ref_index":0},"pub_date":null,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2025.emnlp-main.829.pdf","title":"","snippet":"Total lines: 1336\n","ref_id":{"turn_index":6,"ref_type":"view","ref_index":1},"pub_date":null,"attribution":"aclanthology.org"}]},{"type":"search_result_group","domain":"openaccess.thecvf.com","entries":[{"type":"search_result","url":"https://openaccess.thecvf.com/content/ICCV2025/papers/Skiers_Joint_Diffusion_Models_in_Continual_Learning_ICCV_2025_paper.pdf","title":"Joint Diffusion Models in Continual Learning","snippet":"Total lines: 1044\n","ref_id":{"turn_index":6,"ref_type":"view","ref_index":2},"pub_date":null,"attribution":"openaccess.thecvf.com"}]}],"debug_sonic_thread_id":"thread_695649353e2c83248117d80f2fe78bd6","reasoning_status":"is_reasoning","reasoning_title":"Troubleshooting screenshot tool validation error","classifier_response":"default","request_id":"5f3f0455-8a59-45eb-a9c3-284af86d3bb4","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"d2318aa3-6f2c-434d-8ea1-f4accc7fd78f","turn_exchange_id":"b62969f7-f59e-4e1e-9b90-3e7bb7097612"},"recipient":"all","channel":null},"parent":"d2318aa3-6f2c-434d-8ea1-f4accc7fd78f","children":["02274e2e-8a4d-483c-aa07-6dad1801289d"]},"02274e2e-8a4d-483c-aa07-6dad1801289d":{"id":"02274e2e-8a4d-483c-aa07-6dad1801289d","message":{"id":"02274e2e-8a4d-483c-aa07-6dad1801289d","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1767262632.340346,"update_time":null,"content":{"content_type":"thoughts","thoughts":[{"summary":"Attempting screenshot again","content":"I\u2019ll try the screenshot tool again on a stable source, like (website). Hopefully, this time it works as expected! I\u2019ll make sure it's asking for the right content and view, and will go ahead with it if it's all lined up properly.","chunks":["I\u2019ll try the screenshot tool again on a stable source, like (website).","Hopefully, this time it works as expected!","I\u2019ll make sure it's asking for the right content and view, and will go ahead with it if it's all lined up properly."],"finished":true}],"source_analysis_msg_id":"7aaa6b2b-0807-48f4-9656-f6513f7afa68"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"is_reasoning","citations":[],"content_references":[],"classifier_response":"default","skip_reasoning_title":"Skip","request_id":"5f3f0455-8a59-45eb-a9c3-284af86d3bb4","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"eb244dba-d9f8-4f2e-b7ff-6135886633cd","turn_exchange_id":"b62969f7-f59e-4e1e-9b90-3e7bb7097612"},"recipient":"all","channel":null},"parent":"eb244dba-d9f8-4f2e-b7ff-6135886633cd","children":["127f4180-c3ff-42f6-8312-be07e499b957"]},"127f4180-c3ff-42f6-8312-be07e499b957":{"id":"127f4180-c3ff-42f6-8312-be07e499b957","message":{"id":"127f4180-c3ff-42f6-8312-be07e499b957","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1767262626.741078,"update_time":null,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"{\"screenshot\":[{\"ref_id\":\"turn6view0\",\"pageno\":0},{\"ref_id\":\"turn6view1\",\"pageno\":0},{\"ref_id\":\"turn6view2\",\"pageno\":0}],\"response_length\":\"short\"}"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200012]},"is_complete":true,"citations":[],"content_references":[],"reasoning_status":"is_reasoning","reasoning_title":"Testing screenshot functionality on turn6view0","classifier_response":"default","request_id":"5f3f0455-8a59-45eb-a9c3-284af86d3bb4","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"02274e2e-8a4d-483c-aa07-6dad1801289d","turn_exchange_id":"b62969f7-f59e-4e1e-9b90-3e7bb7097612"},"recipient":"web.run","channel":null},"parent":"02274e2e-8a4d-483c-aa07-6dad1801289d","children":["38cb8ded-3ac2-4aec-ac3f-68e872db3bcd"]},"38cb8ded-3ac2-4aec-ac3f-68e872db3bcd":{"id":"38cb8ded-3ac2-4aec-ac3f-68e872db3bcd","message":{"id":"38cb8ded-3ac2-4aec-ac3f-68e872db3bcd","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1767262629.383976,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_result_groups":[],"debug_sonic_thread_id":"thread_695649353e2c83248117d80f2fe78bd6","reasoning_status":"is_reasoning","reasoning_title":"Testing screenshot functionality on turn6view0","classifier_response":"default","request_id":"5f3f0455-8a59-45eb-a9c3-284af86d3bb4","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"127f4180-c3ff-42f6-8312-be07e499b957","turn_exchange_id":"b62969f7-f59e-4e1e-9b90-3e7bb7097612"},"recipient":"all","channel":null},"parent":"127f4180-c3ff-42f6-8312-be07e499b957","children":["a76f281d-354f-4225-908d-6ba2258fd416"]},"a76f281d-354f-4225-908d-6ba2258fd416":{"id":"a76f281d-354f-4225-908d-6ba2258fd416","message":{"id":"a76f281d-354f-4225-908d-6ba2258fd416","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1767262636.263585,"update_time":null,"content":{"content_type":"thoughts","thoughts":[{"summary":"Attempting screenshot on new PDF","content":"The screenshot tool still isn't working due to a ValidationError, which is frustrating. Perhaps it only works for PDFs available from specific domains or with certain headers. I'll try another PDF, like one from arXiv, to see if the tool functions there. If it works, I'll proceed.","chunks":["The screenshot tool still isn't working due to a ValidationError, which is frustrating.","Perhaps it only works for PDFs available from specific domains or with certain headers.","I'll try another PDF, like one from arXiv, to see if the tool functions there.","If it works, I'll proceed."],"finished":true}],"source_analysis_msg_id":"852e4201-267a-4dc6-9818-670d0095b5f0"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"is_reasoning","citations":[],"content_references":[],"classifier_response":"default","skip_reasoning_title":"Skip","request_id":"5f3f0455-8a59-45eb-a9c3-284af86d3bb4","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"38cb8ded-3ac2-4aec-ac3f-68e872db3bcd","turn_exchange_id":"b62969f7-f59e-4e1e-9b90-3e7bb7097612"},"recipient":"all","channel":null},"parent":"38cb8ded-3ac2-4aec-ac3f-68e872db3bcd","children":["c04d62fe-f636-40f3-a636-850f5c66b9b1"]},"c04d62fe-f636-40f3-a636-850f5c66b9b1":{"id":"c04d62fe-f636-40f3-a636-850f5c66b9b1","message":{"id":"c04d62fe-f636-40f3-a636-850f5c66b9b1","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1767262629.64089,"update_time":null,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"{\"open\":[{\"ref_id\":\"turn0search21\"},{\"ref_id\":\"turn1search23\"}],\"response_length\":\"short\"}"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200012]},"is_complete":true,"citations":[],"content_references":[],"reasoning_status":"is_reasoning","reasoning_title":"Testing screenshot tool with arXiv PDF","classifier_response":"default","request_id":"5f3f0455-8a59-45eb-a9c3-284af86d3bb4","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"a76f281d-354f-4225-908d-6ba2258fd416","turn_exchange_id":"b62969f7-f59e-4e1e-9b90-3e7bb7097612"},"recipient":"web.run","channel":null},"parent":"a76f281d-354f-4225-908d-6ba2258fd416","children":["ae6c014a-fb3e-4c16-bd20-e35842d78d01"]},"ae6c014a-fb3e-4c16-bd20-e35842d78d01":{"id":"ae6c014a-fb3e-4c16-bd20-e35842d78d01","message":{"id":"ae6c014a-fb3e-4c16-bd20-e35842d78d01","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1767262634.5392587,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_result_groups":[{"type":"search_result_group","domain":"www.arxiv.org","entries":[{"type":"search_result","url":"https://www.arxiv.org/pdf/2504.13822","title":"Parameter-Efficient Continual Fine-Tuning: A Survey","snippet":"Total lines: 2062\n","ref_id":{"turn_index":8,"ref_type":"view","ref_index":0},"pub_date":null,"attribution":"www.arxiv.org"}]},{"type":"search_result_group","domain":"arxiv.org","entries":[{"type":"search_result","url":"https://arxiv.org/pdf/2509.17183","title":"LifeAlign: Lifelong Alignment for Large Language Models with Memory-Augmented Focalized Preference Optimization","snippet":"Total lines: 1420\n","ref_id":{"turn_index":8,"ref_type":"view","ref_index":1},"pub_date":null,"attribution":"arxiv.org"}]}],"debug_sonic_thread_id":"thread_695649353e2c83248117d80f2fe78bd6","reasoning_status":"is_reasoning","reasoning_title":"Testing screenshot tool with arXiv PDF","classifier_response":"default","request_id":"5f3f0455-8a59-45eb-a9c3-284af86d3bb4","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"c04d62fe-f636-40f3-a636-850f5c66b9b1","turn_exchange_id":"b62969f7-f59e-4e1e-9b90-3e7bb7097612"},"recipient":"all","channel":null},"parent":"c04d62fe-f636-40f3-a636-850f5c66b9b1","children":["39618756-1841-4604-a025-fbb2a3753885"]},"39618756-1841-4604-a025-fbb2a3753885":{"id":"39618756-1841-4604-a025-fbb2a3753885","message":{"id":"39618756-1841-4604-a025-fbb2a3753885","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1767262640.725104,"update_time":null,"content":{"content_type":"thoughts","thoughts":[{"summary":"Testing screenshot on arXiv PDF","content":"I\u2019m going to test if the screenshot tool functions with an arXiv PDF. It might work better with a different source, so I\u2019ll give it a try and see if the tool can grab the image as expected. Let\u2019s see if this one succeeds!","chunks":["I\u2019m going to test if the screenshot tool functions with an arXiv PDF.","It might work better with a different source, so I\u2019ll give it a try and see if the tool can grab the image as expected.","Let\u2019s see if this one succeeds!"],"finished":true}],"source_analysis_msg_id":"423ed819-5116-496f-a569-451eb9f5b1c1"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"is_reasoning","citations":[],"content_references":[],"classifier_response":"default","skip_reasoning_title":"Skip","request_id":"5f3f0455-8a59-45eb-a9c3-284af86d3bb4","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"ae6c014a-fb3e-4c16-bd20-e35842d78d01","turn_exchange_id":"b62969f7-f59e-4e1e-9b90-3e7bb7097612"},"recipient":"all","channel":null},"parent":"ae6c014a-fb3e-4c16-bd20-e35842d78d01","children":["45604749-0a11-4969-95ec-b1a027a55506"]},"45604749-0a11-4969-95ec-b1a027a55506":{"id":"45604749-0a11-4969-95ec-b1a027a55506","message":{"id":"45604749-0a11-4969-95ec-b1a027a55506","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1767262634.835266,"update_time":null,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"{\"screenshot\":[{\"ref_id\":\"turn8view0\",\"pageno\":0},{\"ref_id\":\"turn8view1\",\"pageno\":0}],\"response_length\":\"short\"}"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200012]},"is_complete":true,"citations":[],"content_references":[],"reasoning_status":"is_reasoning","reasoning_title":"Testing screenshot method for arXiv PDFs","classifier_response":"default","request_id":"5f3f0455-8a59-45eb-a9c3-284af86d3bb4","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"39618756-1841-4604-a025-fbb2a3753885","turn_exchange_id":"b62969f7-f59e-4e1e-9b90-3e7bb7097612"},"recipient":"web.run","channel":null},"parent":"39618756-1841-4604-a025-fbb2a3753885","children":["9b328cc6-9555-478e-bbfc-1b13d4ff9497"]},"9b328cc6-9555-478e-bbfc-1b13d4ff9497":{"id":"9b328cc6-9555-478e-bbfc-1b13d4ff9497","message":{"id":"9b328cc6-9555-478e-bbfc-1b13d4ff9497","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1767262636.9641802,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_result_groups":[],"debug_sonic_thread_id":"thread_695649353e2c83248117d80f2fe78bd6","reasoning_status":"is_reasoning","reasoning_title":"Testing screenshot method for arXiv PDFs","classifier_response":"default","request_id":"5f3f0455-8a59-45eb-a9c3-284af86d3bb4","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"45604749-0a11-4969-95ec-b1a027a55506","turn_exchange_id":"b62969f7-f59e-4e1e-9b90-3e7bb7097612"},"recipient":"all","channel":null},"parent":"45604749-0a11-4969-95ec-b1a027a55506","children":["82844c22-9648-48ff-90ba-a30a20eb5a40"]},"82844c22-9648-48ff-90ba-a30a20eb5a40":{"id":"82844c22-9648-48ff-90ba-a30a20eb5a40","message":{"id":"82844c22-9648-48ff-90ba-a30a20eb5a40","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1767262644.640375,"update_time":null,"content":{"content_type":"thoughts","thoughts":[{"summary":"Moving forward without screenshots","content":"Looks like the screenshot tool isn't working, so I can't fetch any PDFs. We\u2019ll move ahead without them and rely on the text I\u2019ve already extracted. It's probably not necessary to mention this to the user unless they ask, but I will be honest if needed. Now, I\u2019ll structure the answer.","chunks":["Looks like the screenshot tool isn't working, so I can't fetch any PDFs.","We\u2019ll move ahead without them and rely on the text I\u2019ve already extracted.","It's probably not necessary to mention this to the user unless they ask, but I will be honest if needed.","Now, I\u2019ll structure the answer."],"finished":true},{"summary":"Crafting the response structure","content":"Okay, here's the direction to take. For continual pretraining, an example is Chen et al.'s Llama-3 work with scaling laws. Other key areas: continual instruction tuning (benchmarks and algorithms), alignment (LifeAlign, spurious forgetting), parameter-efficient updates (LoRA, adapters), and robotics/VLA. I'll tie it all in. Evaluation should stress knowledge vs alignment.","chunks":["Okay, here's the direction to take.","For continual pretraining, an example is Chen et al.'s Llama-3 work with scaling laws.","Other key areas: continual instruction tuning (benchmarks and algorithms), alignment (LifeAlign, spurious forgetting), parameter-efficient updates (LoRA, adapters), and robotics/VLA.","I'll tie it all in.","Evaluation should stress knowledge vs alignment."],"finished":true},{"summary":"Structuring the final sections","content":"I\u2019ll highlight key metrics and open challenges like data contamination, compute cost, and value drift. For implementation, I can mention periodic model releases, RAG, and incremental updates. Practical takeaways are crucial for building systems, so I\u2019ll cover memory, fine-tuning, and evaluation. I\u2019ll also reference key papers like \u201cLearning Dynamics\u201d and \u201cSpurious Forgetting.\u201d","chunks":["I\u2019ll highlight key metrics and open challenges like data contamination, compute cost, and value drift.","For implementation, I can mention periodic model releases, RAG, and incremental updates.","Practical takeaways are crucial for building systems, so I\u2019ll cover memory, fine-tuning, and evaluation.","I\u2019ll also reference key papers like \u201cLearning Dynamics\u201d and \u201cSpurious Forgetting.\u201d"],"finished":true},{"summary":"Finalizing the answer with necessary details","content":"I\u2019ll include citations for key surveys like PEFT CL, ACM\u2019s LLM continual learning, and others. I\u2019ll define technical terms like LLM, CL, and RLHF clearly before using the abbreviations, as the user requested. I\u2019ll ensure accuracy while avoiding too much verbosity, presenting the information concisely but thoroughly.","chunks":["I\u2019ll include citations for key surveys like PEFT CL, ACM\u2019s LLM continual learning, and others.","I\u2019ll define technical terms like LLM, CL, and RLHF clearly before using the abbreviations, as the user requested.","I\u2019ll ensure accuracy while avoiding too much verbosity, presenting the information concisely but thoroughly."],"finished":true},{"summary":"Structuring the answer while tackling complexity","content":"The topic is indeed complex, but I can stay structured. I'll start with an intro explaining continual learning for frontier models, mentioning recent 2025 surveys that categorize methods like architecture-based, regularization-based, and replay-based. I\u2019ll organize the answer by advances in these categories and cite key papers for each point.","chunks":["The topic is indeed complex, but I can stay structured.","I'll start with an intro explaining continual learning for frontier models, mentioning recent 2025 surveys that categorize methods like architecture-based, regularization-based, and replay-based.","I\u2019ll organize the answer by advances in these categories and cite key papers for each point."],"finished":true}],"source_analysis_msg_id":"5382f687-defe-44d4-bb75-e3816c2f8f9f"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"is_reasoning","citations":[],"content_references":[],"classifier_response":"default","skip_reasoning_title":"Skip","request_id":"5f3f0455-8a59-45eb-a9c3-284af86d3bb4","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"9b328cc6-9555-478e-bbfc-1b13d4ff9497","turn_exchange_id":"b62969f7-f59e-4e1e-9b90-3e7bb7097612"},"recipient":"all","channel":null},"parent":"9b328cc6-9555-478e-bbfc-1b13d4ff9497","children":["460731d4-97aa-4d71-870f-9f66c99a7c50"]},"460731d4-97aa-4d71-870f-9f66c99a7c50":{"id":"460731d4-97aa-4d71-870f-9f66c99a7c50","message":{"id":"460731d4-97aa-4d71-870f-9f66c99a7c50","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1767262683.481458,"update_time":null,"content":{"content_type":"reasoning_recap","content":"Thought for 2m 52s"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"reasoning_ended","finished_duration_sec":172,"request_id":"5f3f0455-8a59-45eb-a9c3-284af86d3bb4","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"82844c22-9648-48ff-90ba-a30a20eb5a40","turn_exchange_id":"b62969f7-f59e-4e1e-9b90-3e7bb7097612"},"recipient":"all","channel":null},"parent":"82844c22-9648-48ff-90ba-a30a20eb5a40","children":["b72bbed9-55b4-4e3a-8e99-342bb5080995"]},"b72bbed9-55b4-4e3a-8e99-342bb5080995":{"id":"b72bbed9-55b4-4e3a-8e99-342bb5080995","message":{"id":"b72bbed9-55b4-4e3a-8e99-342bb5080995","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1767262637.240739,"update_time":null,"content":{"content_type":"text","parts":["Continual learning (CL)\u2014also called lifelong or incremental learning\u2014is the attempt to keep *deployed* generative models up to date (new facts, new skills, new preferences) **without** retraining from scratch and **without** wiping out older capabilities (\u201ccatastrophic forgetting\u201d). A 2025 survey that explicitly targets *frontier generative model families* (large language models, multimodal large language models, vision-language-action models, diffusion models) groups the main approaches into **architecture-based**, **regularization-based**, and **replay-based** paradigms. \ue200cite\ue202turn4view0\ue201\n\nBelow are the most notable research directions and \u201cwhat\u2019s actually new\u201d through late-2025 (i.e., what you should regard as *state of the art* heading into 2026).\n\n---\n\n## 1) Architecture-based: update *less*, route *better*, store *explicitly*\n\n### Parameter-efficient continual updates are becoming the default\nInstead of updating all weights, **parameter-efficient fine-tuning (PEFT)** methods update small add-ons (e.g., adapters, prompts, low-rank matrices). A dedicated 2025 survey frames **parameter-efficient continual fine-tuning** as the main practical path because it reduces interference, compute, and deployment risk versus full fine-tuning. \ue200cite\ue202turn8view0\ue201\n\n### Sparse \u201cmemory layers\u201d as a concrete antidote to interference\nA very direct 2025 result: **Sparse Memory Finetuning** updates only a sparse set of \u201cmemory slots\u201d that activate strongly for new knowledge, explicitly aiming to prevent interference with the base model\u2019s shared parameters. This is one of the clearest \u201ccontinual learning *works better than LoRA* in a controlled test\u201d style papers in the recent batch. \ue200cite\ue202turn1search2\ue202turn1search6\ue201\n\n### Multimodal continual instruction tuning is moving toward \u201cdecompose + fuse\u201d\nFor **multimodal large language models (MLLMs)**, **HiDe-LLaVA** proposes a *task-specific expansion* plus *task-general fusion* strategy guided by **Centered Kernel Alignment (CKA)** similarity shifts across layers\u2014i.e., decide what to specialize vs what to share by measuring representational change. \ue200cite\ue202turn3search3\ue202turn3search7\ue201\n\n**Why this matters:** this \u201callocate updates where the representation actually shifts\u201d idea is showing up repeatedly (also in merging; see below), and it\u2019s one of the few scalable knobs you can turn on 10B\u2013100B-class systems without drowning in replay data.\n\n---\n\n## 2) Replay-based: rehearsal is back, but it\u2019s getting cheaper (latent, synthetic, structured)\n\n### Self-generated rehearsal (no old data required)\n**Self-Synthesized Rehearsal (SSR)** uses the model itself to generate rehearsal examples for past tasks (generate \u2192 refine \u2192 select diverse high-quality synthetic instances), reducing dependence on storing old training data. \ue200cite\ue202turn2search0\ue202turn2search15\ue201  \nThis is important operationally because \u201ckeep the full old dataset around\u201d is often legally or logistically impossible.\n\n### Diffusion models: latent replay & diffusion-as-rehearsal\nIn text-to-image diffusion, **latent replay** is emerging as a practical form of replay: store compressed latent codes of previously learned concepts and replay them during sequential fine-tunes to reduce forgetting and mode collapse. \ue200cite\ue202turn1search0\ue202turn1search12\ue201\n\n### Joint diffusion models for generative rehearsal\nA line of work formalizes **generative rehearsal using diffusion**\u2014e.g., \u201cJoint Diffusion Models in Continual Learning (JDCL)\u201d trains/uses diffusion models to generate rehearsal samples for old tasks while learning new ones. \ue200cite\ue202turn3search8\ue202turn3search27\ue201\n\n---\n\n## 3) Regularization/constraint-based: \u201cdon\u2019t move the parts that matter\u201d\n\nTwo things are changing here:\n\n1) Regularization is becoming **representation-aware** (penalize changes that disrupt internal representations, not just weights).  \n2) Alignment/post-training adds new constraints (especially **Kullback\u2013Leibler (KL) divergence** constraints in reinforcement learning style post-training).\n\n### Lifelong alignment (preferences drift; safety can\u2019t)\n**LifeAlign** targets sequential preference-learning (alignment) without forgetting: it proposes *focalized preference optimization* plus a short-to-long **memory consolidation** mechanism (compress \u201cshort-term preference representations\u201d into more stable long-term memory). \ue200cite\ue202turn8view1\ue202turn4view2\ue201\n\n### Benchmarks are finally measuring *reasoning degradation* separately from answers\n**MLLM-CTBench** evaluates continual instruction tuning for multimodal LLMs and reports a useful empirical pattern: *reasoning chains degrade more slowly than final answers* (a \u201chierarchical forgetting\u201d hypothesis), and in reinforcement-learning settings, **KL constraints** help maintain policy stability and reduce forgetting. \ue200cite\ue202turn1search1\ue201\n\n### \u201cSpurious forgetting\u201d: sometimes you didn\u2019t lose knowledge\u2014you lost *task alignment*\nA notable ICLR 2025 result argues that large apparent forgetting in continual LLM training can be \u201cspurious\u201d: performance drops may reflect deterioration in *instruction/task alignment* rather than true loss of underlying knowledge. \ue200cite\ue202turn0search4\ue201  \nThis matters because it changes what you optimize: you may need to preserve *formats, policies, and instruction-following behaviors* separately from factual competence.\n\n---\n\n## 4) Model merging & post-training editing: treating updates as composable \u201cdeltas\u201d\n\nThis is becoming a major alternative to sequential fine-tuning when you can afford to train multiple specialized deltas and then combine them.\n\n### Layer-wise scaling to reduce interference (LiNeS)\n**LiNeS** is a post-training technique that scales updates by layer depth to preserve general features in earlier layers while retaining task specifics in deeper layers; it also improves multi-task model merging. \ue200cite\ue202turn2search7\ue202turn2search22\ue201\n\n### Representation-aligned merging (RECALL)\n**RECALL** explicitly aligns representations when merging multiple models (layer-wise merging using representation similarity) to enhance multi-domain performance while mitigating catastrophic forgetting. \ue200cite\ue202turn4view5\ue202turn2search14\ue201\n\n### Scaling merging optimization (FW-Merging)\nWork like **FW-Merging** (Frank-Wolfe optimization) reflects a push to make merging scale and behave predictably as the number of task deltas grows. \ue200cite\ue202turn2search11\ue201\n\n---\n\n## 5) Continual pre-training: better recipes, better diagnostics, more transparency\n\nA big practical trend is \u201ccontinual pre-training (CPT)\u201d\u2014keep pretraining on new corpora to add knowledge/domains while trying to retain general abilities.\n\n### A concrete, transparent CPT pipeline (Llama-3 continual pretraining)\nAn ACL 2025 paper gives an unusually detailed CPT procedure on **Llama-3 (8B)**, emphasizing *data mixture*, *curriculum*, *synthetic high-quality data*, and *performance tracking / mixture adjustment* to balance new abilities with retention. \ue200cite\ue202turn6view0\ue202turn0search2\ue201\n\n### Understanding CPT dynamics (scaling-law style)\nThere\u2019s also movement toward modeling CPT as a predictable process (learning-dynamics analyses and \u201cCPT scaling law\u201d style results) to choose learning rates/steps/data mixtures more systematically. \ue200cite\ue202turn0search10\ue202turn0search33\ue201\n\n---\n\n## 6) Non-parametric continual learning: \u201cdon\u2019t rewrite the brain, build a memory system\u201d\n\nGiven the safety and stability risks of weight updates, many \u201cfrontier\u201d deployments lean on retrieval systems. Research is now trying to make retrieval behave more like *structured long-term memory*, not just nearest-neighbor vector search.\n\n### From RAG to memory graphs (HippoRAG 2)\n**HippoRAG 2** is framed explicitly as **non-parametric continual learning**: it aims to outperform standard retrieval-augmented generation on factual memory while improving sense-making and associative retrieval, using graph structure (Personalized PageRank) plus deeper passage integration and online large-language-model use. \ue200cite\ue202turn4view3\ue202turn2search10\ue201\n\n### Black-box continual learning via prompting (CLOB)\nFor API-only models, \u201ccontinual learning\u201d can mean incremental prompt-based mechanisms. **CLOB** treats the LLM as a black box and uses incremental summarization to deal with context limits. \ue200cite\ue202turn2search17\ue201\n\n---\n\n## 7) Vision-language-action: continual skill learning is becoming central in robotics foundation models\nIf \u201cfrontier generative models\u201d includes embodied agents, continual skill acquisition is now a front-burner issue.\n\n- **Stellar VLA** proposes a knowledge-driven continual learning framework (task/skill structure, expert routing) explicitly to reduce annotation needs and training overhead. \ue200cite\ue202turn3search2\ue202turn3search24\ue201  \n- Meanwhile, big labs are shipping VLA systems and benchmarks; even when press coverage emphasizes *generalization*, continual learning is the obvious next step (safe updates, new skills, changing environments). \ue200cite\ue202turn3news46\ue202turn3news44\ue201\n\n---\n\n## What to watch in 2026 (the \u201chard unsolved\u201d bits)\nThese are the issues most likely to define the next wave:\n\n- **Measuring real retention vs spurious forgetting** (separate knowledge, instruction-following, safety policies). \ue200cite\ue202turn0search4\ue201  \n- **Hybrid memory + small param updates** (memory layers / sparse slot updates + retrieval graphs + occasional merging). \ue200cite\ue202turn1search2\ue202turn4view3\ue201  \n- **Safe continual alignment**: updating preferences/policies without destabilizing safety behaviors (KL-constrained RL-style updates, memory consolidation). \ue200cite\ue202turn1search1\ue202turn8view1\ue201  \n- **Compute + governance**: streaming updates are attractive, but adversarial data poisoning, privacy constraints, and auditability make \u201ctrue online learning\u201d hard to deploy responsibly.\n\nIf you tell me which slice you care about most\u2014(i) LLM continual pretraining, (ii) continual instruction tuning, (iii) continual alignment, (iv) diffusion / image models, or (v) embodied VLA\u2014I'll narrow this into a \u201ctop 10 papers + what each contributes + how they fit together\u201d map."]},"status":"finished_successfully","end_turn":true,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200002]},"is_complete":true,"content_references":[{"matched_text":"\ue200cite\ue202turn4view0\ue201","start_idx":580,"end_idx":597,"safe_urls":["https://arxiv.org/html/2506.13045v3"],"refs":[],"alt":"([arXiv](https://arxiv.org/html/2506.13045v3))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"A Comprehensive Survey on Continual Learning in Generative Models","url":"https://arxiv.org/html/2506.13045v3","pub_date":null,"snippet":null,"attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":4,"ref_type":"view","ref_index":0}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn8view0\ue201","start_idx":1254,"end_idx":1271,"safe_urls":["https://www.arxiv.org/pdf/2504.13822"],"refs":[],"alt":"([arXiv](https://www.arxiv.org/pdf/2504.13822))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Parameter-Efficient Continual Fine-Tuning: A Survey","url":"https://www.arxiv.org/pdf/2504.13822","pub_date":null,"snippet":null,"attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":8,"ref_type":"view","ref_index":0}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn1search2\ue202turn1search6\ue201","start_idx":1693,"end_idx":1725,"safe_urls":["https://arxiv.org/abs/2510.15103","https://arxiv.org/abs/2510.15103?utm_source=chatgpt.com","https://openreview.net/forum?id=LGo7U1m24L","https://openreview.net/forum?id=LGo7U1m24L&utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2510.15103?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Continual Learning via Sparse Memory Finetuning","url":"https://arxiv.org/abs/2510.15103?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[{"title":"Continual Learning via Sparse Memory Finetuning","url":"https://openreview.net/forum?id=LGo7U1m24L&utm_source=chatgpt.com","pub_date":null,"snippet":"19 Sept 2025 \u2014 This paper addresses catastrophic forgetting in continual learning for large language models by proposing Sparse Memory Finetuning, a method ...Read more","attribution":"OpenReview"}],"refs":[{"turn_index":1,"ref_type":"search","ref_index":2},{"turn_index":1,"ref_type":"search","ref_index":6}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn3search3\ue202turn3search7\ue201","start_idx":2110,"end_idx":2142,"safe_urls":["https://aclanthology.org/2025.acl-long.666/","https://aclanthology.org/2025.acl-long.666/?utm_source=chatgpt.com","https://arxiv.org/abs/2503.12941","https://arxiv.org/abs/2503.12941?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2503.12941?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Hierarchical Decoupling for Continual Instruction Tuning of ...","url":"https://arxiv.org/abs/2503.12941?utm_source=chatgpt.com","pub_date":null,"snippet":"by H Guo \u00b7 2025 \u00b7 Cited by 17 \u2014 Instruction tuning is widely used to improve a pre-trained Multimodal Large Language Model (MLLM) by training it on curated task-specific ...Read more","attribution_segments":null,"supporting_websites":[{"title":"Hierarchical Decoupling for Continual Instruction Tuning of ...","url":"https://aclanthology.org/2025.acl-long.666/?utm_source=chatgpt.com","pub_date":null,"snippet":"by H Guo \u00b7 2025 \u00b7 Cited by 17 \u2014 In this paper, we propose a task-specific expansion and task-general fusion framework based on the variations in Centered Kernel Alignment (CKA) ...Read more","attribution":"ACL Anthology"}],"refs":[{"turn_index":3,"ref_type":"search","ref_index":3},{"turn_index":3,"ref_type":"search","ref_index":7}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn2search0\ue202turn2search15\ue201","start_idx":2783,"end_idx":2816,"safe_urls":["https://aclanthology.org/2024.acl-long.77/","https://aclanthology.org/2024.acl-long.77/?utm_source=chatgpt.com","https://arxiv.org/abs/2403.01244","https://arxiv.org/abs/2403.01244?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2403.01244?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"[2403.01244] Mitigating Catastrophic Forgetting in Large ...","url":"https://arxiv.org/abs/2403.01244?utm_source=chatgpt.com","pub_date":null,"snippet":"by J Huang \u00b7 2024 \u00b7 Cited by 86 \u2014 We propose a framework called Self-Synthesized Rehearsal (SSR) that uses the LLM to generate synthetic instances for rehearsal.","attribution_segments":null,"supporting_websites":[{"title":"Mitigating Catastrophic Forgetting in Large Language ...","url":"https://aclanthology.org/2024.acl-long.77/?utm_source=chatgpt.com","pub_date":null,"snippet":"by J Huang \u00b7 2024 \u00b7 Cited by 86 \u2014 We propose a framework called Self-Synthesized Rehearsal (SSR) that uses the LLM to generate synthetic instances for rehearsal.","attribution":"ACL Anthology"}],"refs":[{"turn_index":2,"ref_type":"search","ref_index":0},{"turn_index":2,"ref_type":"search","ref_index":15}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn1search0\ue202turn1search12\ue201","start_idx":3236,"end_idx":3269,"safe_urls":["https://arxiv.org/html/2509.10529v1","https://arxiv.org/html/2509.10529v1?utm_source=chatgpt.com","https://www.arxiv.org/abs/2509.10529","https://www.arxiv.org/abs/2509.10529?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://www.arxiv.org/abs/2509.10529?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Mitigating Catastrophic Forgetting and Mode Collapse in ...","url":"https://www.arxiv.org/abs/2509.10529?utm_source=chatgpt.com","pub_date":null,"snippet":"by A Otani \u00b7 2025 \u2014 Abstract page for arXiv paper 2509.10529: Mitigating Catastrophic Forgetting and Mode Collapse in Text-to-Image Diffusion via Latent Replay.","attribution_segments":null,"supporting_websites":[{"title":"Mitigating Catastrophic Forgetting and Mode Collapse in ...","url":"https://arxiv.org/html/2509.10529v1?utm_source=chatgpt.com","pub_date":null,"snippet":"4 Sept 2025 \u2014 Mitigating Catastrophic Forgetting and Mode Collapse in Text-to-Image Diffusion via Latent Replay. Report issue for preceding element. Aoi Otani.Read more","attribution":"arXiv"}],"refs":[{"turn_index":1,"ref_type":"search","ref_index":0},{"turn_index":1,"ref_type":"search","ref_index":12}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn3search8\ue202turn3search27\ue201","start_idx":3548,"end_idx":3581,"safe_urls":["https://arxiv.org/abs/2411.08224","https://arxiv.org/abs/2411.08224?utm_source=chatgpt.com","https://openaccess.thecvf.com/content/ICCV2025/html/Skiers_Joint_Diffusion_Models_in_Continual_Learning_ICCV_2025_paper.html","https://openaccess.thecvf.com/content/ICCV2025/html/Skiers_Joint_Diffusion_Models_in_Continual_Learning_ICCV_2025_paper.html?utm_source=chatgpt.com"],"refs":[],"alt":"([CVF Open Access](https://openaccess.thecvf.com/content/ICCV2025/html/Skiers_Joint_Diffusion_Models_in_Continual_Learning_ICCV_2025_paper.html?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Joint Diffusion Models in Continual Learning - CVF Open Access","url":"https://openaccess.thecvf.com/content/ICCV2025/html/Skiers_Joint_Diffusion_Models_in_Continual_Learning_ICCV_2025_paper.html?utm_source=chatgpt.com","pub_date":null,"snippet":"In this work, we introduce JDCL - a new method for continual learning with generative rehearsal based on joint diffusion models. Neural networks suffer from ...","attribution_segments":null,"supporting_websites":[{"title":"[2411.08224] Joint Diffusion models in Continual Learning - arXiv","url":"https://arxiv.org/abs/2411.08224?utm_source=chatgpt.com","pub_date":null,"snippet":"In this work, we introduce JDCL - a new method for continual learning with generative rehearsal based on joint diffusion models.","attribution":"arXiv"}],"refs":[{"turn_index":3,"ref_type":"search","ref_index":8},{"turn_index":3,"ref_type":"search","ref_index":27}],"hue":null,"attributions":null,"attribution":"CVF Open Access"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn8view1\ue202turn4view2\ue201","start_idx":4317,"end_idx":4345,"safe_urls":["https://arxiv.org/abs/2509.17183","https://arxiv.org/pdf/2509.17183"],"refs":[],"alt":"([arXiv](https://arxiv.org/pdf/2509.17183))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"LifeAlign: Lifelong Alignment for Large Language Models with Memory-Augmented Focalized Preference Optimization","url":"https://arxiv.org/pdf/2509.17183","pub_date":null,"snippet":null,"attribution_segments":null,"supporting_websites":[{"title":"[2509.17183] LifeAlign: Lifelong Alignment for Large Language Models with Memory-Augmented Focalized Preference Optimization","url":"https://arxiv.org/abs/2509.17183","pub_date":null,"snippet":null,"attribution":"arXiv"}],"refs":[{"turn_index":8,"ref_type":"view","ref_index":1},{"turn_index":4,"ref_type":"view","ref_index":2}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn1search1\ue201","start_idx":4761,"end_idx":4780,"safe_urls":["https://arxiv.org/abs/2508.08275","https://arxiv.org/abs/2508.08275?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2508.08275?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"MLLM-CBench:A Comprehensive Benchmark for Continual Instruction Tuning of Multimodal LLMs with Chain-of-Thought Reasoning Analysis","url":"https://arxiv.org/abs/2508.08275?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":1,"ref_type":"search","ref_index":1}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search4\ue201","start_idx":5104,"end_idx":5123,"safe_urls":["https://openreview.net/forum?id=ScI7IlKGdI","https://openreview.net/forum?id=ScI7IlKGdI&utm_source=chatgpt.com"],"refs":[],"alt":"([OpenReview](https://openreview.net/forum?id=ScI7IlKGdI&utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Spurious Forgetting in Continual Learning of Language ...","url":"https://openreview.net/forum?id=ScI7IlKGdI&utm_source=chatgpt.com","pub_date":null,"snippet":"by J Zheng \u00b7 Cited by 29 \u2014 The paper analyzes the phenomenon of catastrophic forgetting in the continual learning of language models. The authors argue that this forgetting stems from a ...Read more","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":4}],"hue":null,"attributions":null,"attribution":"OpenReview"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn2search7\ue202turn2search22\ue201","start_idx":5798,"end_idx":5831,"safe_urls":["https://arxiv.org/abs/2410.17146","https://arxiv.org/abs/2410.17146?utm_source=chatgpt.com","https://openreview.net/pdf/c38679398b6736228ed121760328ebc474d8e294.pdf","https://openreview.net/pdf/c38679398b6736228ed121760328ebc474d8e294.pdf?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2410.17146?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"LiNeS: Post-training Layer Scaling Prevents Forgetting and ...","url":"https://arxiv.org/abs/2410.17146?utm_source=chatgpt.com","pub_date":null,"snippet":"by K Wang \u00b7 2024 \u00b7 Cited by 18 \u2014 We introduce LiNeS, Layer-increasing Network Scaling, a post-training editing technique designed to preserve pre-trained generalization while enhancing fine- ...Read more","attribution_segments":null,"supporting_websites":[{"title":"LINES: POST-TRAINING LAYER SCALING PREVENTS ...","url":"https://openreview.net/pdf/c38679398b6736228ed121760328ebc474d8e294.pdf?utm_source=chatgpt.com","pub_date":null,"snippet":"When merging multiple models, LiNeS improves baseline methods for merging checkpoints fine-tuned on multiple tasks in both computer vision and NLP benchmarks ( ...Read more","attribution":"OpenReview"}],"refs":[{"turn_index":2,"ref_type":"search","ref_index":7},{"turn_index":2,"ref_type":"search","ref_index":22}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn4view5\ue202turn2search14\ue201","start_idx":6082,"end_idx":6113,"safe_urls":["https://aclanthology.org/2025.emnlp-main.829.pdf","https://aclanthology.org/2025.emnlp-main.829.pdf?utm_source=chatgpt.com"],"refs":[],"alt":"([ACL Anthology](https://aclanthology.org/2025.emnlp-main.829.pdf))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"","url":"https://aclanthology.org/2025.emnlp-main.829.pdf","pub_date":null,"snippet":null,"attribution_segments":null,"supporting_websites":[{"title":"RECALL: REpresentation-aligned Catastrophic-forgetting ...","url":"https://aclanthology.org/2025.emnlp-main.829.pdf?utm_source=chatgpt.com","pub_date":null,"snippet":"by B Wang \u00b7 2025 \u2014 Therefore, inspired by those observations, we propose RECALL in this section, which performs layer-wise model merging by comparing the sim-.Read more","attribution":"ACL Anthology"}],"refs":[{"turn_index":4,"ref_type":"view","ref_index":5},{"turn_index":2,"ref_type":"search","ref_index":14}],"hue":null,"attributions":null,"attribution":"ACL Anthology"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn2search11\ue201","start_idx":6310,"end_idx":6330,"safe_urls":["https://openaccess.thecvf.com/content/ICCV2025/papers/Chen_FW-Merging_Scaling_Model_Merging_with_Frank-Wolfe_Optimization_ICCV_2025_paper.pdf","https://openaccess.thecvf.com/content/ICCV2025/papers/Chen_FW-Merging_Scaling_Model_Merging_with_Frank-Wolfe_Optimization_ICCV_2025_paper.pdf?utm_source=chatgpt.com"],"refs":[],"alt":"([CVF Open Access](https://openaccess.thecvf.com/content/ICCV2025/papers/Chen_FW-Merging_Scaling_Model_Merging_with_Frank-Wolfe_Optimization_ICCV_2025_paper.pdf?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Scaling Model Merging with Frank-Wolfe Optimization","url":"https://openaccess.thecvf.com/content/ICCV2025/papers/Chen_FW-Merging_Scaling_Model_Merging_with_Frank-Wolfe_Optimization_ICCV_2025_paper.pdf?utm_source=chatgpt.com","pub_date":null,"snippet":"by HM Chen \u00b7 2025 \u00b7 Cited by 2 \u2014 Model merging has emerged as a promising approach for multi-task learning (MTL), offering a data-efficient alterna- tive to conventional fine-tuning.Read more","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":2,"ref_type":"search","ref_index":11}],"hue":null,"attributions":null,"attribution":"CVF Open Access"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn6view0\ue202turn0search2\ue201","start_idx":6894,"end_idx":6924,"safe_urls":["https://aclanthology.org/2025.acl-long.289.pdf","https://aclanthology.org/2025.acl-long.289.pdf?utm_source=chatgpt.com"],"refs":[],"alt":"([ACL Anthology](https://aclanthology.org/2025.acl-long.289.pdf))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"","url":"https://aclanthology.org/2025.acl-long.289.pdf","pub_date":null,"snippet":null,"attribution_segments":null,"supporting_websites":[{"title":"Towards Effective and Efficient Continual Pre-training of ...","url":"https://aclanthology.org/2025.acl-long.289.pdf?utm_source=chatgpt.com","pub_date":null,"snippet":"by J Chen \u00b7 2025 \u00b7 Cited by 20 \u2014 In this paper, we present a completely trans- parent procedure for continually pre-training the open-sourced LLM\u2014Llama-3 (8B), with all exper-.Read more","attribution":"ACL Anthology"}],"refs":[{"turn_index":6,"ref_type":"view","ref_index":0},{"turn_index":0,"ref_type":"search","ref_index":2}],"hue":null,"attributions":null,"attribution":"ACL Anthology"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search10\ue202turn0search33\ue201","start_idx":7175,"end_idx":7209,"safe_urls":["https://arxiv.org/abs/2505.07796","https://arxiv.org/abs/2505.07796?utm_source=chatgpt.com","https://openreview.net/forum?id=Vk1rNMl0J1","https://openreview.net/forum?id=Vk1rNMl0J1&utm_source=chatgpt.com"],"refs":[],"alt":"([OpenReview](https://openreview.net/forum?id=Vk1rNMl0J1&utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Learning Dynamics in Continual Pre-Training for Large ...","url":"https://openreview.net/forum?id=Vk1rNMl0J1&utm_source=chatgpt.com","pub_date":null,"snippet":"by X Wang \u00b7 Cited by 8 \u2014 The paper analyzes and models learning dynamics in CPT of large language models, focusing on performance evolution across general and downstream ...Read more","attribution_segments":null,"supporting_websites":[{"title":"Learning Dynamics in Continual Pre-Training for Large ...","url":"https://arxiv.org/abs/2505.07796?utm_source=chatgpt.com","pub_date":null,"snippet":"by X Wang \u00b7 2025 \u00b7 Cited by 8 \u2014 In this work, we explore the learning dynamics throughout the CPT process for large language models. We specifically focus on how general and downstream domain ...Read more","attribution":"arXiv"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":10},{"turn_index":0,"ref_type":"search","ref_index":33}],"hue":null,"attributions":null,"attribution":"OpenReview"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn4view3\ue202turn2search10\ue201","start_idx":7921,"end_idx":7952,"safe_urls":["https://openreview.net/forum?id=LWH8yn4HS2","https://openreview.net/forum?id=LWH8yn4HS2&utm_source=chatgpt.com"],"refs":[],"alt":"([OpenReview](https://openreview.net/forum?id=LWH8yn4HS2))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"From RAG to Memory: Non-Parametric Continual Learning for Large Language Models | OpenReview","url":"https://openreview.net/forum?id=LWH8yn4HS2","pub_date":null,"snippet":null,"attribution_segments":null,"supporting_websites":[{"title":"From RAG to Memory: Non-Parametric Continual Learning ...","url":"https://openreview.net/forum?id=LWH8yn4HS2&utm_source=chatgpt.com","pub_date":null,"snippet":"by BJ Guti\u00e9rrez \u00b7 Cited by 84 \u2014 TL;DR: In this work, we propose HippoRAG 2, a non-parametric continual learning framework which outperforms state-of-the-art retrieval methods ...Read more","attribution":"OpenReview"}],"refs":[{"turn_index":4,"ref_type":"view","ref_index":3},{"turn_index":2,"ref_type":"search","ref_index":10}],"hue":null,"attributions":null,"attribution":"OpenReview"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn2search17\ue201","start_idx":8199,"end_idx":8219,"safe_urls":["https://aclanthology.org/2025.coling-main.402.pdf","https://aclanthology.org/2025.coling-main.402.pdf?utm_source=chatgpt.com"],"refs":[],"alt":"([ACL Anthology](https://aclanthology.org/2025.coling-main.402.pdf?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Continual Learning Using Only Large Language Model ...","url":"https://aclanthology.org/2025.coling-main.402.pdf?utm_source=chatgpt.com","pub_date":1733637936.0,"snippet":"by J Qiu \u00b7 2025 \u00b7 Cited by 2 \u2014 We introduce CLOB, a novel continual learning. (CL) paradigm wherein a large language model. (LLM) is regarded as a black box. Learning.Read more","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":2,"ref_type":"search","ref_index":17}],"hue":null,"attributions":null,"attribution":"ACL Anthology"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn3search2\ue202turn3search24\ue201","start_idx":8622,"end_idx":8655,"safe_urls":["https://arxiv.org/html/2511.18085v2","https://arxiv.org/html/2511.18085v2?utm_source=chatgpt.com","https://web3.arxiv.org/abs/2511.18085","https://web3.arxiv.org/abs/2511.18085?utm_source=chatgpt.com"],"refs":[],"alt":"([arXiv](https://web3.arxiv.org/abs/2511.18085?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Continually Evolving Skill Knowledge in Vision Language ...","url":"https://web3.arxiv.org/abs/2511.18085?utm_source=chatgpt.com","pub_date":null,"snippet":"by Y Wu \u00b7 2025 \u2014 We propose Stellar VLA, a knowledge-driven continual learning framework with two variants: T-Stellar, modeling task-centric knowledge space, and ...Read more","attribution_segments":null,"supporting_websites":[{"title":"Continually Evolving Skill Knowledge in Vision Language ...","url":"https://arxiv.org/html/2511.18085v2?utm_source=chatgpt.com","pub_date":null,"snippet":"25 Nov 2025 \u2014 Developing general robot intelligence in open environments requires continual skill learning. Recent Vision-Language-Action (VLA) models ...","attribution":"arXiv"}],"refs":[{"turn_index":3,"ref_type":"search","ref_index":2},{"turn_index":3,"ref_type":"search","ref_index":24}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn3news46\ue202turn3news44\ue201","start_idx":8870,"end_idx":8900,"safe_urls":["https://www.theverge.com/news/628021/google-deepmind-gemini-robotics-ai-models","https://www.theverge.com/news/628021/google-deepmind-gemini-robotics-ai-models?utm_source=chatgpt.com","https://www.theverge.com/news/631743/nvidia-issac-groot-n1-robotics-foundation-model-available","https://www.theverge.com/news/631743/nvidia-issac-groot-n1-robotics-foundation-model-available?utm_source=chatgpt.com"],"refs":[],"alt":"([The Verge](https://www.theverge.com/news/628021/google-deepmind-gemini-robotics-ai-models?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Google DeepMind's new AI models help robots perform physical tasks, even without training","url":"https://www.theverge.com/news/628021/google-deepmind-gemini-robotics-ai-models?utm_source=chatgpt.com","pub_date":1741791600.0,"snippet":"Google DeepMind has introduced two new AI models, Gemini Robotics and Gemini Robotics-ER, designed to improve robots' real-world physical capabilities. Built on the Gemini 2.0 platform, Gemini Robotics is a vision-language-action model that enables robots to handle new scenarios, even without specific training. The model enhances robot generality, interactivity, and dexterity\u2014allowing for advanced tasks like folding paper or removing bottle caps. \n\nGemini Robotics-ER (Embodied Reasoning) extends this functionality by incorporating complex reasoning abilities, enabling robots to understand spatial contexts and manipulate objects effectively, such as packing a lunchbox. It can interface with existing robotic control systems, allowing developers to implement more advanced capabilities. \n\nDeepMind emphasizes safety, employing a layered approach and training models to evaluate the risk of actions. The company is also releasing benchmarks to support broader AI safety research. Partnerships with companies like Apptronik, Agile Robots, and Boston Dynamics aim to integrate these models into next-generation humanoid robots. This marks a significant step toward more adaptive, intelligent, and physically capable robotic systems for diverse real-world applications.","attribution_segments":null,"supporting_websites":[{"title":"Nvidia says 'the age of generalist robotics is here'","url":"https://www.theverge.com/news/631743/nvidia-issac-groot-n1-robotics-foundation-model-available?utm_source=chatgpt.com","pub_date":null,"snippet":"Nvidia has officially launched Isaac GR00T N1, an open-source, pretrained, and customizable foundation model designed to accelerate the development of general-purpose humanoid robots. CEO Jensen Huang unveiled the technology during his GTC 2025 keynote, declaring the arrival of \u201cthe age of generalist robotics.\u201d Isaac GR00T N1 enhances robot adaptability and reasoning through a dual-system cognitive model: System 1 handles fast, reflex-like responses using human and synthetic training data, while System 2 reasons with a vision-language model to plan and execute complex tasks. Companies such as 1X Technologies, Boston Dynamics, Agility Robotics, Mentee Robotics, and Neura Robotics have gained early access to GR00T N1 to enhance their robot capabilities. 1X Technologies showcased their NEO Gamma robot performing autonomous tasks using the GR00T model. Nvidia has also made the training datasets and evaluation tools publicly available via Hugging Face and GitHub, emphasizing a collaborative push towards expanding the role of robotics in daily life.","attribution":"The Verge"}],"refs":[{"turn_index":3,"ref_type":"news","ref_index":46},{"turn_index":3,"ref_type":"news","ref_index":44}],"hue":null,"attributions":null,"attribution":"The Verge"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search4\ue201","start_idx":9134,"end_idx":9153,"safe_urls":["https://openreview.net/forum?id=ScI7IlKGdI","https://openreview.net/forum?id=ScI7IlKGdI&utm_source=chatgpt.com"],"refs":[],"alt":"([OpenReview](https://openreview.net/forum?id=ScI7IlKGdI&utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Spurious Forgetting in Continual Learning of Language ...","url":"https://openreview.net/forum?id=ScI7IlKGdI&utm_source=chatgpt.com","pub_date":null,"snippet":"by J Zheng \u00b7 Cited by 29 \u2014 The paper analyzes the phenomenon of catastrophic forgetting in the continual learning of language models. The authors argue that this forgetting stems from a ...Read more","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":4}],"hue":null,"attributions":null,"attribution":"OpenReview"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn1search2\ue202turn4view3\ue201","start_idx":9277,"end_idx":9307,"safe_urls":["https://arxiv.org/abs/2510.15103","https://arxiv.org/abs/2510.15103?utm_source=chatgpt.com","https://openreview.net/forum?id=LWH8yn4HS2"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2510.15103?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Continual Learning via Sparse Memory Finetuning","url":"https://arxiv.org/abs/2510.15103?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[{"title":"From RAG to Memory: Non-Parametric Continual Learning for Large Language Models | OpenReview","url":"https://openreview.net/forum?id=LWH8yn4HS2","pub_date":null,"snippet":null,"attribution":"OpenReview"}],"refs":[{"turn_index":1,"ref_type":"search","ref_index":2},{"turn_index":4,"ref_type":"view","ref_index":3}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn1search1\ue202turn8view1\ue201","start_idx":9468,"end_idx":9498,"safe_urls":["https://arxiv.org/abs/2508.08275","https://arxiv.org/abs/2508.08275?utm_source=chatgpt.com","https://arxiv.org/pdf/2509.17183"],"refs":[],"alt":"([arXiv](https://arxiv.org/abs/2508.08275?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"MLLM-CBench:A Comprehensive Benchmark for Continual Instruction Tuning of Multimodal LLMs with Chain-of-Thought Reasoning Analysis","url":"https://arxiv.org/abs/2508.08275?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[{"title":"LifeAlign: Lifelong Alignment for Large Language Models with Memory-Augmented Focalized Preference Optimization","url":"https://arxiv.org/pdf/2509.17183","pub_date":null,"snippet":null,"attribution":"arXiv"}],"refs":[{"turn_index":1,"ref_type":"search","ref_index":1},{"turn_index":8,"ref_type":"view","ref_index":1}],"hue":null,"attributions":null,"attribution":"arXiv"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":" ","start_idx":9973,"end_idx":9973,"safe_urls":[],"refs":[],"alt":"","prompt_text":null,"type":"sources_footnote","sources":[{"title":"A Comprehensive Survey on Continual Learning in Generative Models","url":"https://arxiv.org/html/2506.13045v3","attribution":"arXiv"},{"title":"Joint Diffusion Models in Continual Learning - CVF Open Access","url":"https://openaccess.thecvf.com/content/ICCV2025/html/Skiers_Joint_Diffusion_Models_in_Continual_Learning_ICCV_2025_paper.html?utm_source=chatgpt.com","attribution":"CVF Open Access"},{"title":"Spurious Forgetting in Continual Learning of Language ...","url":"https://openreview.net/forum?id=ScI7IlKGdI&utm_source=chatgpt.com","attribution":"OpenReview"},{"title":"","url":"https://aclanthology.org/2025.emnlp-main.829.pdf","attribution":"ACL Anthology"},{"title":"Continually Evolving Skill Knowledge in Vision Language ...","url":"https://web3.arxiv.org/abs/2511.18085?utm_source=chatgpt.com","attribution":"arXiv"},{"title":"Google DeepMind's new AI models help robots perform physical tasks, even without training","url":"https://www.theverge.com/news/628021/google-deepmind-gemini-robotics-ai-models?utm_source=chatgpt.com","attribution":"The Verge"}],"has_images":false}],"safe_urls":["https://aclanthology.org/2024.acl-long.77/","https://aclanthology.org/2024.acl-long.77/?utm_source=chatgpt.com","https://aclanthology.org/2025.acl-long.289.pdf","https://aclanthology.org/2025.acl-long.289.pdf?utm_source=chatgpt.com","https://aclanthology.org/2025.acl-long.666/","https://aclanthology.org/2025.acl-long.666/?utm_source=chatgpt.com","https://aclanthology.org/2025.coling-main.402.pdf","https://aclanthology.org/2025.coling-main.402.pdf?utm_source=chatgpt.com","https://aclanthology.org/2025.emnlp-main.829.pdf","https://aclanthology.org/2025.emnlp-main.829.pdf?utm_source=chatgpt.com","https://arxiv.org/abs/2403.01244","https://arxiv.org/abs/2403.01244?utm_source=chatgpt.com","https://arxiv.org/abs/2410.17146","https://arxiv.org/abs/2410.17146?utm_source=chatgpt.com","https://arxiv.org/abs/2411.08224","https://arxiv.org/abs/2411.08224?utm_source=chatgpt.com","https://arxiv.org/abs/2503.12941","https://arxiv.org/abs/2503.12941?utm_source=chatgpt.com","https://arxiv.org/abs/2505.07796","https://arxiv.org/abs/2505.07796?utm_source=chatgpt.com","https://arxiv.org/abs/2508.08275","https://arxiv.org/abs/2508.08275?utm_source=chatgpt.com","https://arxiv.org/abs/2509.17183","https://arxiv.org/abs/2510.15103","https://arxiv.org/abs/2510.15103?utm_source=chatgpt.com","https://arxiv.org/html/2506.13045v3","https://arxiv.org/html/2509.10529v1","https://arxiv.org/html/2509.10529v1?utm_source=chatgpt.com","https://arxiv.org/html/2511.18085v2","https://arxiv.org/html/2511.18085v2?utm_source=chatgpt.com","https://arxiv.org/pdf/2509.17183","https://openaccess.thecvf.com/content/ICCV2025/html/Skiers_Joint_Diffusion_Models_in_Continual_Learning_ICCV_2025_paper.html","https://openaccess.thecvf.com/content/ICCV2025/html/Skiers_Joint_Diffusion_Models_in_Continual_Learning_ICCV_2025_paper.html?utm_source=chatgpt.com","https://openaccess.thecvf.com/content/ICCV2025/papers/Chen_FW-Merging_Scaling_Model_Merging_with_Frank-Wolfe_Optimization_ICCV_2025_paper.pdf","https://openaccess.thecvf.com/content/ICCV2025/papers/Chen_FW-Merging_Scaling_Model_Merging_with_Frank-Wolfe_Optimization_ICCV_2025_paper.pdf?utm_source=chatgpt.com","https://openreview.net/forum?id=LGo7U1m24L","https://openreview.net/forum?id=LGo7U1m24L&utm_source=chatgpt.com","https://openreview.net/forum?id=LWH8yn4HS2","https://openreview.net/forum?id=LWH8yn4HS2&utm_source=chatgpt.com","https://openreview.net/forum?id=ScI7IlKGdI","https://openreview.net/forum?id=ScI7IlKGdI&utm_source=chatgpt.com","https://openreview.net/forum?id=Vk1rNMl0J1","https://openreview.net/forum?id=Vk1rNMl0J1&utm_source=chatgpt.com","https://openreview.net/pdf/c38679398b6736228ed121760328ebc474d8e294.pdf","https://openreview.net/pdf/c38679398b6736228ed121760328ebc474d8e294.pdf?utm_source=chatgpt.com","https://web3.arxiv.org/abs/2511.18085","https://web3.arxiv.org/abs/2511.18085?utm_source=chatgpt.com","https://www.arxiv.org/abs/2509.10529","https://www.arxiv.org/abs/2509.10529?utm_source=chatgpt.com","https://www.arxiv.org/pdf/2504.13822","https://www.theverge.com/news/628021/google-deepmind-gemini-robotics-ai-models","https://www.theverge.com/news/628021/google-deepmind-gemini-robotics-ai-models?utm_source=chatgpt.com","https://www.theverge.com/news/631743/nvidia-issac-groot-n1-robotics-foundation-model-available","https://www.theverge.com/news/631743/nvidia-issac-groot-n1-robotics-foundation-model-available?utm_source=chatgpt.com"],"search_result_groups":[{"type":"search_result_group","domain":"arxiv.org","entries":[{"type":"search_result","url":"https://arxiv.org/html/2504.13822v2?utm_source=chatgpt.com","title":"Parameter-Efficient Continual Fine-Tuning: A Survey","snippet":"19 Aug 2025 \u2014 This problem is known as catastrophic forgetting [108] and is the core challenge of CL. Theoretically, consequential re-training and adapting to ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":0},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2506.13045v3?utm_source=chatgpt.com","title":"A Comprehensive Survey on Continual Learning in ...","snippet":"19 Jun 2025 \u2014 In this work, we present a comprehensive survey of continual learning methods for mainstream generative models, encompassing large language ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2506.03320?utm_source=chatgpt.com","title":"The Future of Continual Learning in the Era of Foundation ...","snippet":"by J Bell \u00b7 2025 \u00b7 Cited by 8 \u2014 In this paper, we first review Continual Pre-Training (4.1), which equips large-scale foundational models with adaptive, resource-efficient mechanisms to ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://www.arxiv.org/pdf/2506.13045v2?utm_source=chatgpt.com","title":"A Comprehensive Survey on Continual Learning in ...","snippet":"18 Jun 2025 \u2014 In this work, we present a comprehensive survey of continual learning methods for mainstream generative models, encompassing large language ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2402.17400?utm_source=chatgpt.com","title":"Investigating Continual Pretraining in Large Language ...","snippet":"by \u00c7 Y\u0131ld\u0131z \u00b7 2024 \u00b7 Cited by 55 \u2014 Our research establishes a new benchmark for CL in LLMs, providing a more realistic evaluation of knowledge retention and transfer across diverse domains.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://www.arxiv.org/pdf/2504.13822?utm_source=chatgpt.com","title":"Parameter-Efficient Continual Fine-Tuning: A Survey","snippet":"by EN Coleman \u00b7 2025 \u00b7 Cited by 5 \u2014 This problem is known as catastrophic forgetting [108] and is the core challenge of CL. Theoretically, consequential re-training and adapting to ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":21},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2509.17183v1?utm_source=chatgpt.com","title":"LifeAlign: Lifelong Alignment for Large Language Models ...","snippet":"21 Sept 2025 \u2014 Lifelong learning for LLMs seeks to enable models to absorb an ongoing stream of data without suffering catastrophic forgetting. As ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":31},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2505.07796?utm_source=chatgpt.com","title":"Learning Dynamics in Continual Pre-Training for Large ...","snippet":"by X Wang \u00b7 2025 \u00b7 Cited by 8 \u2014 In this work, we explore the learning dynamics throughout the CPT process for large language models. We specifically focus on how general and downstream domain ...Read...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":33},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2509.17183?utm_source=chatgpt.com","title":"LifeAlign: Lifelong Alignment for Large Language Models ...","snippet":"by J Li \u00b7 2025 \u00b7 Cited by 1 \u2014 Abstract:Alignment plays a crucial role in Large Language Models (LLMs) in aligning with human preferences on a specific task/domain.Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":3},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2509.10529v1?utm_source=chatgpt.com","title":"Mitigating Catastrophic Forgetting and Mode Collapse in ...","snippet":"4 Sept 2025 \u2014 Mitigating Catastrophic Forgetting and Mode Collapse in Text-to-Image Diffusion via Latent Replay. Report issue for preceding element. Aoi Otani.Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2508.07307?utm_source=chatgpt.com","title":"MCITlib: Multimodal Continual Instruction Tuning Library ...","snippet":"by H Guo \u00b7 2025 \u00b7 Cited by 3 \u2014 Continual learning aims to equip AI systems with the ability to continuously acquire and adapt to new knowledge without forgetting previously ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2510.15103v1?utm_source=chatgpt.com","title":"Continual Learning via Sparse Memory Finetuning","snippet":"16 Oct 2025 \u2014 We find that sparse memory finetuning learns new knowledge while exhibiting substantially less forgetting: while NaturalQuestions F1 drops by 89 ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":22},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2509.17183?utm_source=chatgpt.com","title":"LifeAlign: Lifelong Alignment for Large Language Models ...","snippet":"by J Li \u00b7 2025 \u00b7 Cited by 1 \u2014 We introduce LifeAlign, a novel framework for life- long alignment that enables LLMs to maintain consistent hu- man preference alignment across ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":23},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2310.14510?utm_source=chatgpt.com","title":"CITB: A Benchmark for Continual Instruction Tuning","snippet":"by Z Zhang \u00b7 2023 \u00b7 Cited by 41 \u2014 In this work, we establish a CIT benchmark consisting of learning and evaluation protocols. We curate two long dialogue task streams of different types.Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2412.15479v1?utm_source=chatgpt.com","title":"Continual Learning Using Only Large Language Model ...","snippet":"20 Dec 2024 \u2014 This is referred to as online or streaming CIL, where the training data arrives as a continuous stream, and each training example is seen only ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2310.06762?utm_source=chatgpt.com","title":"TRACE: A Comprehensive Benchmark for Continual ...","snippet":"by X Wang \u00b7 2023 \u00b7 Cited by 51 \u2014 TRACE consists of 8 distinct datasets spanning challenging tasks including domain-specific tasks, multilingual capabilities, code generation, and mathematical ...Read...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":29},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2512.06951v1?utm_source=chatgpt.com","title":"Task adaptation of Vision-Language-Action model","snippet":"7 Dec 2025 \u2014 We present a vision-action policy that won 1st place in the 2025 BEHAVIOR Challenge\u2014a large-scale benchmark featuring 50 diverse long-horizon ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2411.08224v3?utm_source=chatgpt.com","title":"Joint Diffusion Models in Continual Learning - arXiv","snippet":"In this work, we introduce JDCL \u2013 a new method for continual learning with generative rehearsal based on joint diffusion models. Neural networks ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":4},"pub_date":1759708800.0,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2511.18085?utm_source=chatgpt.com","title":"Continually Evolving Skill Knowledge in Vision Language ...","snippet":"by Y Wu \u00b7 2025 \u2014 The diversity of manipulation skills and environmental complexity make continual learning a key challenge for VLA models toward general robotic ...Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2511.18960v1?utm_source=chatgpt.com","title":"AVA-VLA: Improving Vision-Language-Action models with ...","snippet":"24 Nov 2025 \u2014 The better you learn, the smarter you prune: Towards efficient vision-language-action models via differentiable token pruning. arXiv preprint ...Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/html/2511.18085v2?utm_source=chatgpt.com","title":"Continually Evolving Skill Knowledge in Vision Language ...","snippet":"25 Nov 2025 \u2014 Developing general robot intelligence in open environments requires continual skill learning. Recent Vision-Language-Action (VLA) models ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":24},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2505.23705?utm_source=chatgpt.com","title":"Knowledge Insulating Vision-Language-Action Models","snippet":"by D Driess \u00b7 2025 \u00b7 Cited by 37 \u2014 Abstract:Vision-language-action (VLA) models provide a powerful approach to training control policies for physical systems, such as robots, ...Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":25},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/pdf/2503.12941?utm_source=chatgpt.com","title":"HiDe-LLaVA: Hierarchical Decoupling for Continual ...","snippet":"by H Guo \u00b7 2025 \u00b7 Cited by 17 \u2014 Instruction tuning is widely used to improve a pre-trained Multimodal Large Language. Model (MLLM) by training it on curated task-.Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":26},"pub_date":null,"attribution":"arxiv.org"},{"type":"search_result","url":"https://arxiv.org/abs/2411.08224?utm_source=chatgpt.com","title":"[2411.08224] Joint Diffusion models in Continual Learning - arXiv","snippet":"In this work, we introduce JDCL - a new method for continual learning with generative rehearsal based on joint diffusion models.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":27},"pub_date":1731369600.0,"attribution":"arxiv.org"}]},{"type":"search_result_group","domain":"aclanthology.org","entries":[{"type":"search_result","url":"https://aclanthology.org/2025.acl-long.289.pdf?utm_source=chatgpt.com","title":"Towards Effective and Efficient Continual Pre-training of ...","snippet":"by J Chen \u00b7 2025 \u00b7 Cited by 20 \u2014 In this paper, we present a completely trans- parent procedure for continually pre-training the open-sourced LLM\u2014Llama-3 (8B), with all exper-.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2025.naacl-industry.25/?utm_source=chatgpt.com","title":"Efficient Continual Pre-training of LLMs for Low-resource ...","snippet":"by A Nag \u00b7 2025 \u00b7 Cited by 7 \u2014 We first develop a new algorithm to select a subset of texts from a larger corpus. We show the effectiveness of our technique using very little CPT data.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2025.emnlp-main.1108.pdf?utm_source=chatgpt.com","title":"Mitigating Catastrophic Forgetting in Large Language ...","snippet":"by W Huang \u00b7 2025 \u2014 Can we solve the problem of catastrophic forget- ting without changing training process, without any additional data, and without altering model.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2025.acl-long.537.pdf?utm_source=chatgpt.com","title":"A Generative Adaptive Replay Continual Learning Model ...","snippet":"by Z Zhang \u00b7 2025 \u2014 Continual Learning(CL) fine-tuning models with new data may seem intu- itive, but often results in catastrophic forgetting, where prior ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":20},"pub_date":null,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2025.emnlp-tutorials.7/?utm_source=chatgpt.com","title":"Continual Learning of Large Language Models","snippet":"by T Wu \u00b7 2025 \u2014 This tutorial offers a comprehensive exploration of continual learning (CL) in the context of LLMs, presenting a structured framework that spans continual pre- ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":27},"pub_date":null,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2025.emnlp-main.609.pdf?utm_source=chatgpt.com","title":"Towards Efficient Multimodal Continual Instruction Tuning ...","snippet":"by F Zeng \u00b7 2025 \u00b7 Cited by 2 \u2014 Coin: A benchmark of continual instruction tuning for mul- timodel large language model. Advances in neural information processing systems ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":29},"pub_date":null,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2023.findings-emnlp.633/?utm_source=chatgpt.com","title":"CITB: A Benchmark for Continual Instruction Tuning","snippet":"by Z Zhang \u00b7 2023 \u00b7 Cited by 41 \u2014 In this work, we establish a CIT benchmark consisting of learning and evaluation protocols. We curate two long dialogue task streams of different types.Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":1},"pub_date":null,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2025.emnlp-main.829.pdf?utm_source=chatgpt.com","title":"RECALL: REpresentation-aligned Catastrophic-forgetting ...","snippet":"by B Wang \u00b7 2025 \u2014 Therefore, inspired by those observations, we propose RECALL in this section, which performs layer-wise model merging by comparing the sim-.Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2024.acl-long.77/?utm_source=chatgpt.com","title":"Mitigating Catastrophic Forgetting in Large Language ...","snippet":"by J Huang \u00b7 2024 \u00b7 Cited by 86 \u2014 We propose a framework called Self-Synthesized Rehearsal (SSR) that uses the LLM to generate synthetic instances for rehearsal.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2025.acl-long.666/?utm_source=chatgpt.com","title":"Hierarchical Decoupling for Continual Instruction Tuning of ...","snippet":"by H Guo \u00b7 2025 \u00b7 Cited by 17 \u2014 In this paper, we propose a task-specific expansion and task-general fusion framework based on the variations in Centered Kernel Alignment (CKA) ...Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2025.acl-long.666.pdf?utm_source=chatgpt.com","title":"Hierarchical Decoupling for Continual Instruction Tuning of ...","snippet":"by H Guo \u00b7 2025 \u00b7 Cited by 17 \u2014 Instruction tuning is widely used to improve a pre-trained Multimodal Large Language. Model (MLLM) by training it on curated task-.Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"aclanthology.org"},{"type":"search_result","url":"https://aclanthology.org/2025.emnlp-main.273.pdf?utm_source=chatgpt.com","title":"ChatVLA: Unified Multimodal Understanding and Robot ...","snippet":"by Z Zhou \u00b7 2025 \u00b7 Cited by 63 \u2014 Recent advancements in Vision-Language-Action. (VLA) (Black et al., 2024; Kim et al., 2024; Wen et al., 2024c, 2025) models have largely ...Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":21},"pub_date":null,"attribution":"aclanthology.org"}]},{"type":"search_result_group","domain":"thecvf.com","entries":[{"type":"search_result","url":"https://openaccess.thecvf.com/content/ICCV2025/papers/Skiers_Joint_Diffusion_Models_in_Continual_Learning_ICCV_2025_paper.pdf?utm_source=chatgpt.com","title":"Joint Diffusion Models in Continual Learning - CVF Open Access","snippet":"by P Skier\u015b \u00b7 2025 \u00b7 Cited by 6 \u2014 introduce a method for finetuning text-to-image DDGMs with Prior Preservation Loss, that employs generative replay to mitigate catastrophic forgetting.Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"thecvf.com"},{"type":"search_result","url":"https://openaccess.thecvf.com/content/ICCV2025/papers/Li_CoA-VLA_Improving_Vision-Language-Action_Models_via_Visual-Text_Chain-of-Affordance_ICCV_2025_paper.pdf?utm_source=chatgpt.com","title":"CoA-VLA: Improving Vision-Language-Action Models via ...","snippet":"by J Li \u00b7 2025 \u00b7 Cited by 4 \u2014 Our method leverages visual affordance in robot learning, con- ceptualizing various actions and interactions with objects or the environment that a robot can ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"thecvf.com"},{"type":"search_result","url":"https://iccv.thecvf.com/Conferences/2025/AcceptedPapers?utm_source=chatgpt.com","title":"ICCV 2025 Accepted Papers","snippet":"Instruction-Grounded Visual Projectors for Continual Learning of Generative Vision-Language Models Poster Session 1 & Exhibit Hall ... DiffPS: Leveraging Prior ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":19},"pub_date":null,"attribution":"thecvf.com"},{"type":"search_result","url":"https://iccv.thecvf.com/virtual/2025/papers.html?utm_source=chatgpt.com","title":"ICCV 2025 Papers","snippet":"Joint Diffusion Models in Continual Learning \u00b7 GT-Loc: Unifying When and Where ... Learning Deblurring Texture Prior from Unpaired Data with Diffusion Model ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":35},"pub_date":null,"attribution":"thecvf.com"}]},{"type":"search_result_group","domain":"liner.com","entries":[{"type":"search_result","url":"https://liner.com/review/efficient-continual-pretraining-llms-for-lowresource-languages?utm_source=chatgpt.com","title":"Efficient Continual Pre-training of LLMs for Low-resource ...","snippet":"The research aims to drastically reduce the cost of continual pre-training for Large Language Models while improving their performance on low-resource languages ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":23},"pub_date":null,"attribution":"liner.com"},{"type":"search_result","url":"https://liner.com/review/coin-a-benchmark-of-continual-instruction-tuning-for-multimodel-large?utm_source=chatgpt.com","title":"A Benchmark of Continual Instruction tuNing for Multimodel ...","snippet":"However, continual instruction tuning for MLLMs is largely overlooked, and a public benchmark for assessing their behavior in sequential learning is absent.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":21},"pub_date":null,"attribution":"liner.com"},{"type":"search_result","url":"https://liner.com/review/mitigating-catastrophic-forgetting-in-large-language-models-with-selfsynthesized-rehearsal?utm_source=chatgpt.com","title":"[Quick Review] Mitigating Catastrophic Forgetting in Large ...","snippet":"We propose Self-Synthesized Rehearsal (SSR), a framework that employs LLMs to generate synthetic instances for rehearsal to mitigate catastrophic forgetting.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"liner.com"},{"type":"search_result","url":"https://liner.com/review/hidellava-hierarchical-decoupling-for-continual-instruction-tuning-multimodal-large-language?utm_source=chatgpt.com","title":"HiDe-LLaVA: Hierarchical Decoupling for Continual ...","snippet":"Regarding this ACL 2025 paper, this review summarizes HiDe-LLaVA, a hierarchical decoupling method for continual instruction tuning of MLLMs.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"liner.com"}]},{"type":"search_result_group","domain":"openreview.net","entries":[{"type":"search_result","url":"https://openreview.net/forum?id=J5sUOvlLbQ&noteId=PYWNZ0NC7L&utm_source=chatgpt.com","title":"LiNeS: Post-training Layer Scaling Prevents Forgetting and ...","snippet":"23 Dec 2024 \u2014 This paper introduces a post-training editing technique, LiNeS, designed to address catastrophic forgetting and facilitate model merging after ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/forum?id=EpnsUQavJA&referrer=%5Bthe+profile+of+Jingkuan+Song%5D%28%2Fprofile%3Fid%3D~Jingkuan_Song3%29&utm_source=chatgpt.com","title":"CoIN: A Benchmark of Continual Instruction Tuning for ...","snippet":"13 Nov 2024 \u2014 In this paper, we present CoIN, a comprehensive benchmark tailored for assessing the behavior of existing MLLMs under continual instruction tuning.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/forum?id=LGo7U1m24L&utm_source=chatgpt.com","title":"Continual Learning via Sparse Memory Finetuning","snippet":"19 Sept 2025 \u2014 This paper addresses catastrophic forgetting in continual learning for large language models by proposing Sparse Memory Finetuning, a method ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":6},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/forum?id=PvvQlhBbgu&noteId=MmyzoLCDQN&utm_source=chatgpt.com","title":"Fast Multi-Mode Adaptive Generative Distillation for ...","snippet":"14 Nov 2024 \u2014 The paper solves the catastrophic forgetting problem for the diffusion model in a continual learning fashion on images with class labels.Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/forum?id=QA1jlb1VG7&utm_source=chatgpt.com","title":"CITB: A Benchmark for Continual Instruction Tuning","snippet":"by Z Zhang \u00b7 Cited by 41 \u2014 The benchmark consists of two long task streams constructed from the SuperNI dataset, and the authors propose an evaluation protocol to assess performance on ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/forum?id=LWH8yn4HS2&utm_source=chatgpt.com","title":"From RAG to Memory: Non-Parametric Continual Learning ...","snippet":"by BJ Guti\u00e9rrez \u00b7 Cited by 84 \u2014 TL;DR: In this work, we propose HippoRAG 2, a non-parametric continual learning framework which outperforms state-of-the-art retrieval methods ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/pdf/02bb9435749398313a19d1e2d4389699ebe7d3bf.pdf?utm_source=chatgpt.com","title":"Self-Evolving Pseudo-Rehearsal for Catastrophic ...","snippet":"Continual instruction tuning for LLMs extends traditional LLMs tuning by enabling LLMs to incrementally absorb new tasks and feedback without forgetting prior ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":19},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/pdf/c38679398b6736228ed121760328ebc474d8e294.pdf?utm_source=chatgpt.com","title":"LINES: POST-TRAINING LAYER SCALING PREVENTS ...","snippet":"When merging multiple models, LiNeS improves baseline methods for merging checkpoints fine-tuned on multiple tasks in both computer vision and NLP benchmarks ( ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":22},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/pdf/1ce871c2effb9d50718a6160a602d79f305a10eb.pdf?utm_source=chatgpt.com","title":"Interactive Post-Training for Vision-Language-Action Models","snippet":"vision-language-action model with open-world generalization. 704. arXiv preprint arXiv:2504.16054, 2025. 2. 705. [12] Moo Jin Kim, Karl Pertsch, Siddharth ...Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":29},"pub_date":null,"attribution":"openreview.net"},{"type":"search_result","url":"https://openreview.net/revisions?id=2SBzSnwjQB&utm_source=chatgpt.com","title":"Revisions","snippet":"[2] HiDe-LLaVA: Hierarchical Decoupling for Continual Instruction Tuning of Multimodal Large Language Model. ACL'25. Note \u2013 Signatures: ICLR.cc/2026 ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":30},"pub_date":null,"attribution":"openreview.net"}]},{"type":"search_result_group","domain":"techrxiv.org","entries":[{"type":"search_result","url":"https://www.techrxiv.org/users/956965/articles/1326137/master/file/data/eart2025recipevla/eart2025recipevla.pdf?inline=true&utm_source=chatgpt.com","title":"Recipe for Vision-Language-Action Models in Robotic ...","snippet":"This survey offers a comprehensive and systematic exam- ination of the current landscape of Vision-Language-Action. (VLA) models for robotic manipulation, ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"techrxiv.org"}]},{"type":"search_result_group","domain":"acm.org","entries":[{"type":"search_result","url":"https://dl.acm.org/doi/10.1145/3735633?utm_source=chatgpt.com","title":"Continual Learning of Large Language Models","snippet":"20 Nov 2025 \u2014 Examining Forgetting in Continual Pre-training of Aligned Large Language Models. ... Online Continual Learning Without the Storage Constraint.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"acm.org"},{"type":"search_result","url":"https://dl.acm.org/doi/10.1145/3746027.3755302?utm_source=chatgpt.com","title":"Forward-Only Continual Learning | Proceedings of the 33rd ...","snippet":"27 Oct 2025 \u2014 Catastrophic forgetting remains a central challenge in continual learning (CL) with pre-trained models. While existing approaches typically ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"acm.org"},{"type":"search_result","url":"https://dl.acm.org/doi/abs/10.1145/3735633?utm_source=chatgpt.com","title":"Continual Learning of Large Language Models","snippet":"by H Shi \u00b7 Cited by 175 \u2014 This survey sheds light on the relatively understudied domain of continually pre-training, adapting, and fine-tuning large language models.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":20},"pub_date":null,"attribution":"acm.org"},{"type":"search_result","url":"https://dl.acm.org/doi/full/10.1145/3716629?utm_source=chatgpt.com","title":"Towards Lifelong Learning of Large Language Models","snippet":"by J Zheng \u00b7 2025 \u00b7 Cited by 79 \u2014 Our survey explores the landscape of lifelong learning, categorizing strategies into two groups based on how new knowledge is integrated.Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":32},"pub_date":null,"attribution":"acm.org"},{"type":"search_result","url":"https://dl.acm.org/doi/10.5555/3737916.3739760?utm_source=chatgpt.com","title":"CoIN: a benchmark of continual instruction tuning for ...","snippet":"10 Dec 2024 \u2014 Instruction tuning demonstrates impressive performance in adapting Multimodal Large Language Models (MLLMs) to follow task instructions and ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"acm.org"},{"type":"search_result","url":"https://dl.acm.org/doi/pdf/10.1145/3735633?utm_source=chatgpt.com","title":"Continual Learning of Large Language Models","snippet":"by H Shi \u00b7 Cited by 176 \u2014 In CFT, our focus is on the emerging field of learning LLMs, covering topics such as Continual Instruction Tuning (CIT), Continual Model Refinement ... CITB: A ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":20},"pub_date":null,"attribution":"acm.org"},{"type":"search_result","url":"https://dl.acm.org/doi/10.1145/3705725?utm_source=chatgpt.com","title":"Recent Advances of Foundation Language Models-based ...","snippet":"This comprehensive survey examines recent advances in continual learning applied to foundation language models, including pre-trained language models, large ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":20},"pub_date":null,"attribution":"acm.org"}]},{"type":"search_result_group","domain":"github.com","entries":[{"type":"search_result","url":"https://github.com/Wang-ML-Lab/llm-continual-learning-survey?utm_source=chatgpt.com","title":"Continual Learning of Large Language Models: A ...","snippet":"Overcoming Catastrophic Forgetting in Massively Multilingual Continual Learning ... Investigating the Catastrophic Forgetting in Multimodal Large Language Models ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/xialeiliu/Awesome-Incremental-Learning?utm_source=chatgpt.com","title":"xialeiliu/Awesome-Incremental-Learning","snippet":"Continual Learning for VLMs: A Survey and Taxonomy Beyond Forgetting (arXiv 2025) [ \u00b7 Continual Learning With Knowledge Distillation: A Survey (TNNLS 2024) [ ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":19},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/Ghy0501/Awesome-Continual-Learning-in-Generative-Models?utm_source=chatgpt.com","title":"Awesome-Continual-Learning-in-Generative-Models","snippet":"Yet, their practical deployment is hindered by catastrophic forgetting\u2014a fundamental issue where learning new tasks erases previously acquired knowledge.Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":28},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/EnnengYang/Awesome-Model-Merging-Methods-Theories-Applications?utm_source=chatgpt.com","title":"EnnengYang/Awesome-Model-Merging-Methods-Theories ...","snippet":"This survey provides a comprehensive overview of model merging methods and theories, their applications in various domains and settings, and future research ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":18},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/Ghy0501/HiDe-LLaVA?utm_source=chatgpt.com","title":"HiDe-LLaVA: Hierarchical Decoupling for Continual ...","snippet":"Instruction tuning is widely used to enhance a pre-trained Multimodal Large Language Model (MLLM) to understand and follow human instructions by training it ...Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"github.com"},{"type":"search_result","url":"https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln?utm_source=chatgpt.com","title":"jonyzhang2023/awesome-embodied-vla-va-vln","snippet":"This repository aims to organize and showcase the state-of-the-art technologies in robot learning, including vision-language-action (VLA) models.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"github.com"}]},{"type":"search_result_group","domain":"linkedin.com","entries":[{"type":"search_result","url":"https://www.linkedin.com/posts/srvjha_iclr2025-tokyo-continuallearning-activity-7287962592340254720-V6AR?utm_source=chatgpt.com","title":"Saurav Jha's Post","snippet":"... text-to-image latent diffusion models on a sequence of concepts without any replay memory. To counter catastrophic forgetting in this continual ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"linkedin.com"},{"type":"search_result","url":"https://www.linkedin.com/posts/data-science-dojo_continual-learning-via-sparse-memory-finetuning-activity-7387246464046989312-5E4u?utm_source=chatgpt.com","title":"Meta's new paper on Sparse Memory Finetuning for LLMs ...","snippet":"Meta's new paper on Sparse Memory Finetuning for LLMs reduces forgetting by 78%. View organization page for Data Science Dojo \u00b7 Data Science ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":37},"pub_date":null,"attribution":"linkedin.com"}]},{"type":"search_result_group","domain":"researchgate.net","entries":[{"type":"search_result","url":"https://www.researchgate.net/publication/397202096_Learn_more_but_bother_less_parameter_efficient_continual_learning?utm_source=chatgpt.com","title":"Learn more, but bother less: parameter efficient continual ...","snippet":"5 Nov 2025 \u2014 Parameter efficient fine tuning CL techniques are gaining traction for their effectiveness in addressing catastrophic forgetting with a ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":25},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/383754106_Continual_Diffuser_CoD_Mastering_Continual_Offline_Reinforcement_Learning_with_Experience_Rehearsal?utm_source=chatgpt.com","title":"(PDF) Continual Diffuser (CoD): Mastering ...","snippet":"4 Sept 2024 \u2014 In view of this, we propose a rehearsal-based continual diffusion model, called Continual Diffuser (CoD), to endow the diffuser with the ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":26},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/396747601_Retaining_by_Doing_The_Role_of_On-Policy_Data_in_Mitigating_Forgetting?utm_source=chatgpt.com","title":"The Role of On-Policy Data in Mitigating Forgetting","snippet":"24 Oct 2025 \u2014 In this paper, toward identifying guidelines for mitigating this phenomenon, we systematically compare the forgetting patterns of two widely ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":28},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/395725674_LifeAlign_Lifelong_Alignment_for_Large_Language_Models_with_Memory-Augmented_Focalized_Preference_Optimization?utm_source=chatgpt.com","title":"LifeAlign: Lifelong Alignment for Large Language Models ...","snippet":"25 Sept 2025 \u2014 We introduce LifeAlign, a novel framework for lifelong alignment that enables LLMs to maintain consistent human preference alignment across ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/394457653_MLLM-CBenchA_Comprehensive_Benchmark_for_Continual_Instruction_Tuning_of_Multimodal_LLMs_with_Chain-of-Thought_Reasoning_Analysis?utm_source=chatgpt.com","title":"MLLM-CBench:A Comprehensive Benchmark for Continual ...","snippet":"16 Aug 2025 \u2014 MLLM-CBench:A Comprehensive Benchmark for Continual Instruction Tuning of Multimodal LLMs with Chain-of-Thought Reasoning Analysis. July 2025.","ref_id":{"turn_index":1,"ref_type":"search","ref_index":25},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/396693493_Continual_Learning_via_Sparse_Memory_Finetuning?utm_source=chatgpt.com","title":"(PDF) Continual Learning via Sparse Memory Finetuning","snippet":"22 Oct 2025 \u2014 Our results suggest sparsity in memory layers offers a promising path toward continual learning in large language models. ResearchGate Logo.Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":36},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/384211005_Mitigating_Catastrophic_Forgetting_in_Large_Language_Models_with_Self-Synthesized_Rehearsal?utm_source=chatgpt.com","title":"Mitigating Catastrophic Forgetting in Large Language ...","snippet":"Continual fine-tuning of large language models (LLMs) suffers from catastrophic forgetting. Rehearsal-based methods mitigate this problem by retaining a small ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/376393733_CITB_A_Benchmark_for_Continual_Instruction_Tuning?utm_source=chatgpt.com","title":"CITB: A Benchmark for Continual Instruction Tuning","snippet":"Although tuning a pretrained LLM with instruction data before deployment gains wide application, it still faces challenges when dealing with incremental data ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/385785942_Joint_Diffusion_models_in_Continual_Learning?utm_source=chatgpt.com","title":"(PDF) Joint Diffusion models in Continual Learning - ResearchGate","snippet":"In this work, we introduce JDCL - a new method for continual learning with generative rehearsal based on joint diffusion models.","ref_id":{"turn_index":3,"ref_type":"search","ref_index":12},"pub_date":1731369600.0,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/394303097_HiDe-LLaVA_Hierarchical_Decoupling_for_Continual_Instruction_Tuning_of_Multimodal_Large_Language_Model?utm_source=chatgpt.com","title":"Hierarchical Decoupling for Continual Instruction Tuning of ...","snippet":"7 Aug 2025 \u2014 Language Modeling. Conference Paper. HiDe-LLaVA: Hierarchical Decoupling for Continual Instruction Tuning of Multimodal Large Language Model.Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":22},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/399072662_Foundation_Models_for_Construction_Robotics_Transfer_Learning_and_Vision-Language-Action_Integration?utm_source=chatgpt.com","title":"Transfer Learning and Vision-Language-Action Integration","snippet":"6 days ago \u2014 This paper investigates the adaptation of pre-trained robotics foundation models, specifically RT-2 and PaLM-E, for construction automation ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":32},"pub_date":null,"attribution":"researchgate.net"},{"type":"search_result","url":"https://www.researchgate.net/publication/391856953_Unveiling_the_Potential_of_Vision-Language-Action_Models_with_Open-Ended_Multimodal_Instructions?utm_source=chatgpt.com","title":"(PDF) Unveiling the Potential of Vision-Language-Action ...","snippet":"21 May 2025 \u2014 Unveiling the Potential of Vision-Language-Action Models with Open-Ended Multimodal Instructions. May 2025. DOI:10.48550/arXiv.2505.11214.Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":33},"pub_date":null,"attribution":"researchgate.net"}]},{"type":"search_result_group","domain":"iclr.cc","entries":[{"type":"search_result","url":"https://iclr.cc/virtual/2025/papers.html?utm_source=chatgpt.com","title":"ICLR 2025 Papers","snippet":"Glauber Generative Model: Discrete Diffusion Models via Binary Classification ... Dynamical Diffusion: Learning Temporal Dynamics with Diffusion Models ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"iclr.cc"},{"type":"search_result","url":"https://iclr.cc/virtual/2025/workshop/23977?utm_source=chatgpt.com","title":"Generative Models for Robot Learning","snippet":"This workshop proposal focuses on generative models for robot learning, which lies in the important and fundamental field of AI and robotics. Learning-based ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":28},"pub_date":null,"attribution":"iclr.cc"}]},{"type":"search_result_group","domain":"rohitbandaru.github.io","entries":[{"type":"search_result","url":"https://rohitbandaru.github.io/blog/Foundation-Models-for-Robotics-VLA/?utm_source=chatgpt.com","title":"Foundation Models for Robotics: Vision-Language-Action ...","snippet":"28 Sept 2025 \u2014 2025, train VLAs with regression loss to predict continuous actions. However, this approach is not as effective on its own compared to ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"rohitbandaru.github.io"}]},{"type":"search_result_group","domain":"alphaxiv.org","entries":[{"type":"search_result","url":"https://www.alphaxiv.org/overview/2511.18085v2?utm_source=chatgpt.com","title":"Continually Evolving Skill Knowledge in Vision Language ...","snippet":"Current VLA models face three critical challenges in continual learning scenarios. First, they demonstrate heavy dependence on task-specific fine-tuning, ...Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"alphaxiv.org"}]},{"type":"search_result_group","domain":"mdpgroup.com","entries":[{"type":"search_result","url":"https://mdpgroup.com/en/blog/why-continual-learning-is-imperative/?utm_source=chatgpt.com","title":"Continual Learning in Large Language Models","snippet":"7 days ago \u2014 Overcoming Catastrophic Forgetting. A core failure mode of sequential training is catastrophic forgetting: when a model is updated on new ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"mdpgroup.com"}]},{"type":"search_result_group","domain":"semanticscholar.org","entries":[{"type":"search_result","url":"https://www.semanticscholar.org/paper/Continual-Pre-Training-of-Large-Language-Models%3A-to-Gupta-Th%27erien/193955704f66923ac20a664bd184ed4663b2bdf9?utm_source=chatgpt.com","title":"[PDF] Continual Pre-Training of Large Language Models","snippet":"It is shown that removing parallel structures in the pre-training data reduces LMs' ICL accuracy by 51% (vs 2% from random ablation), and this drop persists ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":27},"pub_date":null,"attribution":"semanticscholar.org"},{"type":"search_result","url":"https://www.semanticscholar.org/paper/LifeAlign%3A-Lifelong-Alignment-for-Large-Language-Li-Zhou/865da3faec0bd4aea4e56b9252149fe221309746?utm_source=chatgpt.com","title":"LifeAlign: Lifelong Alignment for Large Language Models with ...","snippet":"LifeAlign is introduced, a novel framework for lifelong alignment that enables LLMs to maintain consistent human preference alignment across sequential ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":11},"pub_date":null,"attribution":"semanticscholar.org"},{"type":"search_result","url":"https://www.semanticscholar.org/paper/Mitigating-Catastrophic-Forgetting-in-Large-Models-Huang-Cui/015f62d7a59f7a4301c0cdbe997460c38148d07b?utm_source=chatgpt.com","title":"Mitigating Catastrophic Forgetting in Large Language ...","snippet":"2 Mar 2024 \u2014 This work proposes a framework called Self-Synthesized Rehearsal (SSR) that uses the base LLM for in-context learning to generate synthetic ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"semanticscholar.org"},{"type":"search_result","url":"https://www.semanticscholar.org/paper/75a85d74433d03a78a07bb95f6f261323a79eb80?utm_source=chatgpt.com","title":"[PDF] CITB: A Benchmark for Continual Instruction Tuning","snippet":"This work establishes a CIT benchmark consisting of learning and evaluation protocols and shows that existing CL methods do not effectively leverage the ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":26},"pub_date":null,"attribution":"semanticscholar.org"},{"type":"search_result","url":"https://www.semanticscholar.org/paper/Joint-Diffusion-models-in-Continual-Learning-Skier%27s-Deja/d371ac6c03dee81f33691e11f0f3e1cd08a9673e?utm_source=chatgpt.com","title":"Joint Diffusion models in Continual Learning - Semantic Scholar","snippet":"This work proposes to extend the semi-supervised continual learning setup by combining a continually trained classifier with a diffusion-based generative ...","ref_id":{"turn_index":3,"ref_type":"search","ref_index":23},"pub_date":null,"attribution":"semanticscholar.org"}]},{"type":"search_result_group","domain":"icml.cc","entries":[{"type":"search_result","url":"https://icml.cc/virtual/2025/papers.html?utm_source=chatgpt.com","title":"ICML 2025 Papers","snippet":"FedSSI: Rehearsal-Free Continual Federated Learning with Synergistic Synaptic Intelligence ... Learning Single Index Models with Diffusion Priors \u00b7 Neural ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"icml.cc"}]},{"type":"search_result_group","domain":"sebastianraschka.com","entries":[{"type":"search_result","url":"https://magazine.sebastianraschka.com/p/state-of-llms-2025?utm_source=chatgpt.com","title":"The State Of LLMs 2025: Progress, Problems, and Predictions","snippet":"2 days ago \u2014 A 2025 review of large language models, from DeepSeek R1 and RLVR to inference-time scaling, benchmarks, architectures, and predictions for ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"sebastianraschka.com"}]},{"type":"search_result_group","domain":"neurips.cc","entries":[{"type":"search_result","url":"https://neurips.cc/virtual/2025/papers.html?utm_source=chatgpt.com","title":"NeurIPS 2025 Papers","snippet":"GenPO: Generative Diffusion Models Meet On-Policy Reinforcement Learning \u00b7 Reducing the Probability of Undesirable Outputs in Language Models Using ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"neurips.cc"},{"type":"search_result","url":"https://neurips.cc/virtual/2024/poster/97786?utm_source=chatgpt.com","title":"CoIN: A Benchmark of Continual Instruction Tuning ...","snippet":"9 Dec 2024 \u2014 In this paper, we present CoIN, a comprehensive benchmark tailored for assessing the behavior of existing MLLMs under continual instruction ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":13},"pub_date":null,"attribution":"neurips.cc"},{"type":"search_result","url":"https://proceedings.neurips.cc/paper_files/paper/2024/file/d0949cbcec31c09431610553a284f94a-Paper-Conference.pdf?utm_source=chatgpt.com","title":"Leveraging Catastrophic Forgetting to Develop Safe ...","snippet":"by J Pan \u00b7 2024 \u00b7 Cited by 5 \u2014 Various attempts have been made to alleviate catastrophic forgetting through continual learning algorithms and data replay, such as imposing a penalty on ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":32},"pub_date":null,"attribution":"neurips.cc"}]},{"type":"search_result_group","domain":"sciencedirect.com","entries":[{"type":"search_result","url":"https://www.sciencedirect.com/science/article/pii/S026288562500188X?utm_source=chatgpt.com","title":"Memory augmented using diffusion model for class- ...","snippet":"by Q Jodelet \u00b7 2025 \u2014 Several research works have shown how additional data can be used by incremental models to help mitigate catastrophic forgetting. In this work, following the ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"sciencedirect.com"}]},{"type":"search_result_group","domain":"ceur-ws.org","entries":[{"type":"search_result","url":"https://ceur-ws.org/Vol-4082/paper1.pdf?utm_source=chatgpt.com","title":"Key Challenges in Continual Learning","snippet":"by R Teng \u00b7 2025 \u2014 The regularization-based method prevents drastic parameter changes by adding penalty terms for important parameters of previous tasks in the loss function. For ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":22},"pub_date":null,"attribution":"ceur-ws.org"}]},{"type":"search_result_group","domain":"uts.edu.au","entries":[{"type":"search_result","url":"https://opus.lib.uts.edu.au/rest/bitstreams/e9bfbba4-8ad3-4d5f-9eab-0e3752342a81/retrieve?utm_source=chatgpt.com","title":"CITB: A Benchmark for Continual Instruction Tuning","snippet":"by Z Zhang \u00b7 Cited by 41 \u2014 This challenging yet practical problem is formulated as Continual Instruction Tuning (CIT). In this work, we establish a CIT benchmark consist- ing of learning ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":23},"pub_date":null,"attribution":"uts.edu.au"}]},{"type":"search_result_group","domain":"medium.com","entries":[{"type":"search_result","url":"https://medium.com/%40baicenxiao/avoiding-amnesia-some-practical-guides-to-mitigate-catastrophic-forgetting-in-llms-post-training-6a23e4f064cb?utm_source=chatgpt.com","title":"Avoiding Amnesia: Some Practical Guides to Mitigate ...","snippet":"A small update can knock the model out of the basin where older tasks worked well. Techniques that bias training toward flatter minima tend to ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":24},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://medium.com/data-science-collective/the-promise-of-continual-learning-f3dd88b17a51?utm_source=chatgpt.com","title":"The Promise of Continual Learning | by Minhajul Hoque","snippet":"In the paper that motivates this post, sparse memory finetuning preserved held\u2011out performance far better than full finetuning or LoRA while ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":26},"pub_date":null,"attribution":"medium.com"}]},{"type":"search_result_group","domain":"ijcai.org","entries":[{"type":"search_result","url":"https://www.ijcai.org/proceedings/2025/0328.pdf?utm_source=chatgpt.com","title":"Generative Diffusion Replay for Continual Anomaly Detection","snippet":"by L Hu \u00b7 Cited by 2 \u2014 In this case, the model suffers from catastrophic forgetting, resulting in a sharp decline in per- formance. T2 and T3 represent the processes of learning and ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":24},"pub_date":null,"attribution":"ijcai.org"}]},{"type":"search_result_group","domain":"huggingface.co","entries":[{"type":"search_result","url":"https://huggingface.co/papers/2502.14802?utm_source=chatgpt.com","title":"From RAG to Memory: Non-Parametric Continual Learning ...","snippet":"Given the challenges in continual learning with large language models (LLMs), retrieval-augmented generation (RAG) has become the dominant way to introduce new ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":24},"pub_date":null,"attribution":"huggingface.co"},{"type":"search_result","url":"https://huggingface.co/papers/2512.22615?utm_source=chatgpt.com","title":"Dream-VL & Dream-VLA: Open Vision-Language and ...","snippet":"2 days ago \u2014 Dream-VL & Dream-VLA: Open Vision-Language and Vision-Language-Action Models with Diffusion Language Model Backbone. Published on Dec 27, 2025.Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":36},"pub_date":null,"attribution":"huggingface.co"}]},{"type":"search_result_group","domain":"themoonlight.io","entries":[{"type":"search_result","url":"https://www.themoonlight.io/tw/review/coin-a-benchmark-of-continual-instruction-tuning-for-multimodel-large-language-model?utm_source=chatgpt.com","title":"[\u8ad6\u6587\u8a55\u8ff0] CoIN: A Benchmark of Continual Instruction ...","snippet":"\u672c\u9801\u9762\u63d0\u4f9b\u5168\u7403\u6700\u6e96\u78ba\u3001\u7cbe\u7149\u7684\u8ad6\u6587\u300aCoIN: A Benchmark of Continual Instruction tuNing for Multimodel Large Language Model\u300b\u6458\u8981\u3002\u900f\u904e Moonlight \u9019\u6b3e AI \u7814\u7a76\u52a9\u624b\uff0c ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":33},"pub_date":null,"attribution":"themoonlight.io"},{"type":"search_result","url":"https://www.themoonlight.io/en/review/mitigating-catastrophic-forgetting-in-large-language-models-with-self-synthesized-rehearsal?utm_source=chatgpt.com","title":"[Literature Review] Mitigating Catastrophic Forgetting in ...","snippet":"The authors propose a novel framework called Self-Synthesized Rehearsal (SSR) to mitigate this problem without relying on the original training data from ...","ref_id":{"turn_index":2,"ref_type":"search","ref_index":25},"pub_date":null,"attribution":"themoonlight.io"},{"type":"search_result","url":"https://www.themoonlight.io/en/review/hide-llava-hierarchical-decoupling-for-continual-instruction-tuning-of-multimodal-large-language-model?utm_source=chatgpt.com","title":"[Literature Review] HiDe-LLaVA: Hierarchical Decoupling ...","snippet":"The experiments demonstrate significant improvements over existing state-of-the-art continual instruction tuning methods. Key performance metrics like \"Last\" ...Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":34},"pub_date":null,"attribution":"themoonlight.io"}]},{"type":"search_result_group","domain":"deepfa.ir","entries":[{"type":"search_result","url":"https://deepfa.ir/en/blog/continual-learning-ai-lifelong-machine-learning?utm_source=chatgpt.com","title":"How Can AI Learn Like Humans Without Forgetting?","snippet":"25 Oct 2025 \u2014 Replay-based continual learning stores samples of old data in a memory buffer and incorporates them in subsequent training cycles. Types of ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":27},"pub_date":null,"attribution":"deepfa.ir"}]},{"type":"search_result_group","domain":"jessylin.com","entries":[{"type":"search_result","url":"https://jessylin.com/2025/10/20/continual-learning/?utm_source=chatgpt.com","title":"The Continual Learning Problem","snippet":"20 Oct 2025 \u2014 To solve catastrophic forgetting and integration, we'll likely want solutions where models can learn what to overwrite and what to preserve ...Read more","ref_id":{"turn_index":0,"ref_type":"search","ref_index":29},"pub_date":null,"attribution":"jessylin.com"}]},{"type":"search_result_group","domain":"computer.org","entries":[{"type":"search_result","url":"https://www.computer.org/csdl/journal/tp/2025/03/10752992/21S24kWCL1m?utm_source=chatgpt.com","title":"A Comprehensive Survey of Forgetting in Deep Learning ...","snippet":"by Z Wang \u00b7 2025 \u00b7 Cited by 111 \u2014 In Sections II,III,IV,V,VI,VII, and VIII, we provide a comprehensive survey on harmful forgetting in continual learning, foundation model, domain adaptation, ...Read...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":30},"pub_date":null,"attribution":"computer.org"}]},{"type":"search_result_group","domain":"towardsai.net","entries":[{"type":"search_result","url":"https://pub.towardsai.net/continual-learning-via-sparse-memory-finetuning-paper-review-2c316a3b42e0?utm_source=chatgpt.com","title":"Continual Learning via Sparse Memory Finetuning (Paper ...","snippet":"26 Oct 2025 \u2014 Meta AI's Sparse Memory Finetuning introduces a clever, lightweight solution: instead of changing the entire model, it teaches selectively ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":30},"pub_date":null,"attribution":"towardsai.net"}]},{"type":"search_result_group","domain":"ijsret.com","entries":[{"type":"search_result","url":"https://ijsret.com/wp-content/uploads/2025/03/IJSRET_V11_issue2_428.pdf?utm_source=chatgpt.com","title":"Overcoming Catastrophic Forgetting in Continual Learning","snippet":"In this paper, we explore how external memory modules can be combined with large language models to facilitate continual learning. By utilizing a real-world ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":30},"pub_date":null,"attribution":"ijsret.com"}]},{"type":"search_result_group","domain":"nb-data.com","entries":[{"type":"search_result","url":"https://www.nb-data.com/p/advancing-ai-lifelong-learning-roadmap?utm_source=chatgpt.com","title":"Advancing AI: Lifelong Learning Roadmap for LLM-Based ...","snippet":"20 Jan 2025 \u2014 Recently, I read a nice paper from Zheng et al. (2025) regarding a roadmap to Lifelong Learning of LLM-based Agents.Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":31},"pub_date":null,"attribution":"nb-data.com"}]},{"type":"search_result_group","domain":"redhat.com","entries":[{"type":"search_result","url":"https://developers.redhat.com/articles/2025/04/04/sculpting-subspaces-how-we-solved-continual-learning-llms?utm_source=chatgpt.com","title":"Sculpting subspaces: How we solved continual learning in ...","snippet":"4 Apr 2025 \u2014 Discover how the adaptive SVD approach enables LLMs to continually learn and adapt without forgetting previously acquired knowledge.","ref_id":{"turn_index":2,"ref_type":"search","ref_index":31},"pub_date":null,"attribution":"redhat.com"}]},{"type":"search_result_group","domain":"jhu.edu","entries":[{"type":"search_result","url":"https://self-supervised.cs.jhu.edu/fa2025/files/presentations/Continual-learn-Dec4.pdf?utm_source=chatgpt.com","title":"Can Sparse Memory updates allow LLMs to continually ...","snippet":"Sparse Memory Finetuning: An intelligent, selective update rule that modifies only specific memory slots, mitigating interference. Page ...Read more","ref_id":{"turn_index":1,"ref_type":"search","ref_index":34},"pub_date":null,"attribution":"jhu.edu"}]},{"type":"search_result_group","domain":"scilit.com","entries":[{"type":"search_result","url":"https://www.scilit.com/scholars/12888679?utm_source=chatgpt.com","title":"Jie Zhou from East China Normal University","snippet":"We introduce LifeAlign, a novel framework for lifelong alignment that enables LLMs to maintain consistent human preference alignment across sequential learning ...","ref_id":{"turn_index":1,"ref_type":"search","ref_index":35},"pub_date":null,"attribution":"scilit.com"}]},{"type":"search_result_group","domain":"mdpi.com","entries":[{"type":"search_result","url":"https://www.mdpi.com/2076-3417/15/9/5196?utm_source=chatgpt.com","title":"Analysis of Model Merging Methods for Continual Updating ...","snippet":"by K Kubota \u00b7 2025 \u2014 We propose a novel framework that integrates model merging with federated learning to enable continual foundation model updates without centralizing sensitive ...Read more","ref_id":{"turn_index":2,"ref_type":"search","ref_index":35},"pub_date":null,"attribution":"mdpi.com"}]},{"type":"search_result_group","domain":"google.com.sg","entries":[{"type":"search_result","url":"https://scholar.google.com.sg/citations?hl=ru&user=p1eW_uwAAAAJ&utm_source=chatgpt.com","title":"Haiyang Guo - Google Scholar","snippet":"Hide-llava: Hierarchical decoupling for continual instruction tuning of multimodal large language model. H Guo, F Zeng, Z Xiang, F Zhu, DH Wang, XY Zhang, CL ...Read more","ref_id":{"turn_index":3,"ref_type":"search","ref_index":37},"pub_date":null,"attribution":"google.com.sg"}]}],"citations":[],"request_id":"5f3f0455-8a59-45eb-a9c3-284af86d3bb4","message_type":"next","model_slug":"gpt-5-2-thinking","default_model_slug":"gpt-5-2-thinking","thinking_effort":"max","parent_id":"460731d4-97aa-4d71-870f-9f66c99a7c50","turn_exchange_id":"b62969f7-f59e-4e1e-9b90-3e7bb7097612"},"recipient":"all","channel":"final"},"parent":"460731d4-97aa-4d71-870f-9f66c99a7c50","children":[]}}}