{"id":"6899fa26-0d40-8331-9523-0d68a1bafb57","title":"AI and future responsibilities","create_time":1754921616.206008,"update_time":1754928220.439095,"current_node":"67ca84d7-e1fc-4c1e-add0-981852834837","mapping":{"client-created-root":{"id":"client-created-root","message":null,"parent":null,"children":["ba0a1bab-68f3-4a62-8af0-29881722dacc"]},"ba0a1bab-68f3-4a62-8af0-29881722dacc":{"id":"ba0a1bab-68f3-4a62-8af0-29881722dacc","message":{"id":"ba0a1bab-68f3-4a62-8af0-29881722dacc","author":{"role":"system","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":true,"weight":0.0,"metadata":{"is_visually_hidden_from_conversation":true},"recipient":"all","channel":null},"parent":"client-created-root","children":["aa651662-b10b-4a1d-927b-907c8b627472"]},"aa651662-b10b-4a1d-927b-907c8b627472":{"id":"aa651662-b10b-4a1d-927b-907c8b627472","message":{"id":"aa651662-b10b-4a1d-927b-907c8b627472","author":{"role":"system","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":true,"weight":0.0,"metadata":{"rebase_developer_message":true,"is_visually_hidden_from_conversation":true},"recipient":"all","channel":null},"parent":"ba0a1bab-68f3-4a62-8af0-29881722dacc","children":["c3e5de70-2eed-43fb-ac24-1fe709e77f38"]},"c3e5de70-2eed-43fb-ac24-1fe709e77f38":{"id":"c3e5de70-2eed-43fb-ac24-1fe709e77f38","message":{"id":"c3e5de70-2eed-43fb-ac24-1fe709e77f38","author":{"role":"user","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"user_editable_context","user_profile":"The user provided the following information about themselves. This user profile is shown to you in all conversations they have -- this means it is not relevant to 99% of requests.\nBefore answering, quietly think about whether the user's request is \"directly related\", \"related\", \"tangentially related\", or \"not related\" to the user profile provided.\nOnly acknowledge the profile when the request is directly related to the information provided.\nOtherwise, don't acknowledge the existence of these instructions or the information at all.\nUser profile:\n```Preferred name: E-Jay\nRole: Mathematics Researcher\nOther Information: About Myself: \nI have mathematical knowledge up to graduate level.\n\nCurrent interests:\n(1) coding: mainly Python and full-stack web development\n(2) machine learning and artificial intelligence\n(3) Model categories, stable infinity categories\n(4) Quantum field theory and general relativity.\n```","user_instructions":"The user provided the additional info about how they would like you to respond:\n```Be precise and comprehensive in your analysis. Don't sugar-coat responses. Be as objective as possible. Critique and question my views if necessary. Take a forward-thinking view.```"},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"is_visually_hidden_from_conversation":true,"user_context_message_data":{"about_user_message":"Preferred name: E-Jay\nRole: Mathematics Researcher\nOther Information: About Myself: \nI have mathematical knowledge up to graduate level.\n\nCurrent interests:\n(1) coding: mainly Python and full-stack web development\n(2) machine learning and artificial intelligence\n(3) Model categories, stable infinity categories\n(4) Quantum field theory and general relativity.\n","about_model_message":"Be precise and comprehensive in your analysis. Don't sugar-coat responses. Be as objective as possible. Critique and question my views if necessary. Take a forward-thinking view."},"is_user_system_message":true},"recipient":"all","channel":null},"parent":"aa651662-b10b-4a1d-927b-907c8b627472","children":["dbf99df2-8dc0-4dfc-b812-5eaf0f105db7"]},"dbf99df2-8dc0-4dfc-b812-5eaf0f105db7":{"id":"dbf99df2-8dc0-4dfc-b812-5eaf0f105db7","message":{"id":"dbf99df2-8dc0-4dfc-b812-5eaf0f105db7","author":{"role":"system","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"is_contextual_answers_system_message":true,"contextual_answers_message_type":"identity_prompt","is_visually_hidden_from_conversation":true},"recipient":"all","channel":null},"parent":"c3e5de70-2eed-43fb-ac24-1fe709e77f38","children":["b1a7076f-d1a2-437e-8c0c-fcdf829856b8"]},"b1a7076f-d1a2-437e-8c0c-fcdf829856b8":{"id":"b1a7076f-d1a2-437e-8c0c-fcdf829856b8","message":{"id":"b1a7076f-d1a2-437e-8c0c-fcdf829856b8","author":{"role":"user","name":null,"metadata":{}},"create_time":1754921615.205,"update_time":null,"content":{"content_type":"text","parts":["There is a growing idea promulgating amongst AI optimists that in the future, no one will need to study the hard stuff - robotics, engineering, math, physics, coding, etc because self-improving AI will handle all high-level cognitive tasks and orchestrate all automation in society, I obviously disagree and have some strong counterpoints. But I want to hear your unfiltered take first"]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"selected_sources":[],"selected_github_repos":[],"serialization_metadata":{"custom_symbol_offsets":[]},"request_id":"96d8559ecb41c51a-SIN","message_source":null,"timestamp_":"absolute"},"recipient":"all","channel":null},"parent":"dbf99df2-8dc0-4dfc-b812-5eaf0f105db7","children":["26690c2b-8dd8-4438-adac-423dbba81e58"]},"26690c2b-8dd8-4438-adac-423dbba81e58":{"id":"26690c2b-8dd8-4438-adac-423dbba81e58","message":{"id":"26690c2b-8dd8-4438-adac-423dbba81e58","author":{"role":"system","name":null,"metadata":{}},"create_time":1754921615.859327,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"is_contextual_answers_system_message":true,"is_visually_hidden_from_conversation":true,"command":"prompt","contextual_answers_message_type":"sources_and_filters_prompt","request_id":"96d8559ecb41c51a-SIN","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","parent_id":"b1a7076f-d1a2-437e-8c0c-fcdf829856b8","timestamp_":"absolute"},"recipient":"all","channel":null},"parent":"b1a7076f-d1a2-437e-8c0c-fcdf829856b8","children":["e6c275c8-909d-4e7e-8c40-6647e607d732"]},"e6c275c8-909d-4e7e-8c40-6647e607d732":{"id":"e6c275c8-909d-4e7e-8c40-6647e607d732","message":{"id":"e6c275c8-909d-4e7e-8c40-6647e607d732","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1754921615.8593915,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"request_id":"96d8559ecb41c51a-SIN","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","parent_id":"26690c2b-8dd8-4438-adac-423dbba81e58","timestamp_":"absolute"},"recipient":"all","channel":null},"parent":"26690c2b-8dd8-4438-adac-423dbba81e58","children":["cca9daae-49ad-4b5d-a27f-13fc2d36afbb"]},"cca9daae-49ad-4b5d-a27f-13fc2d36afbb":{"id":"cca9daae-49ad-4b5d-a27f-13fc2d36afbb","message":{"id":"cca9daae-49ad-4b5d-a27f-13fc2d36afbb","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1754921616.60095,"update_time":null,"content":{"content_type":"thoughts","thoughts":[{"summary":"Analyzing E-Jay's claim on AI supplanting hard disciplines","content":"I don\u2019t need to browse for this\u2014I'll focus on pure analysis. The claim that future self-improving AI eliminates the need for studying hard disciplines is provocative. It's important to address the potential societal implications directly and clearly, without unnecessary flamboyance. Let's provide thoughtful critique and remain high-level with analysis.","chunks":[],"finished":true},{"summary":"Arguments for continuing study despite AI advancements","content":"Even with powerful AI, there are still reasons to study. We need to consider areas like alignment, verification, and interpretability to ensure ethical deployment. There are also practical issues like sociotechnical factors, model collapse, and security. I need to address contingency planning\u2014AI may not reach full self-improvement due to limitations, and human roles will remain essential for oversight and reliability.","chunks":[],"finished":true},{"summary":"Human expertise remains essential","content":"Even as AI advances, human expertise is crucial for tasks like formalizing goals, shaping priors, and problem decomposition. Critical areas like interpretability, judgment, and abductive reasoning require human input. If expertise fades, we risk societal fragility and the concentration of power in those controlling AI. I can propose futures: full automation, tool AI, mixed-critical, and regress risks. We've also got counterarguments to consider, but I'll present those seamlessly as continuous prose.","chunks":[],"finished":true},{"summary":"Maintaining human expertise","content":"We should avoid excessive flattery and focus on being direct here. While optimists may be partly correct\u2014if we achieve scalable AI alignment, robust robotics, and energy abundance\u2014studying still matters. We need human knowledge for autonomy, agency, and resilience. Practically, it's essential for model failure, geopolitics, and supply disruptions. Let\u2019s propose targeted metrics like a \"critical path knowledge floor\" and specific roles like \u201cred-teamers\u201d or \u201cmodel auditors\u201d to maintain a secure knowledge base.","chunks":[],"finished":true}],"source_analysis_msg_id":"f06643bf-f56f-481a-9958-f2186c5621e1"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"is_reasoning","citations":[],"content_references":[],"classifier_response":"default","skip_reasoning_title":"Get a quick answer","request_id":"96d8559ecb41c51a-SIN","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","parent_id":"e6c275c8-909d-4e7e-8c40-6647e607d732","timestamp_":"absolute"},"recipient":"all","channel":null},"parent":"e6c275c8-909d-4e7e-8c40-6647e607d732","children":["ce8e9ee2-6402-49ee-a385-4116b2fd6d9e"]},"ce8e9ee2-6402-49ee-a385-4116b2fd6d9e":{"id":"ce8e9ee2-6402-49ee-a385-4116b2fd6d9e","message":{"id":"ce8e9ee2-6402-49ee-a385-4116b2fd6d9e","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1754921667.228392,"update_time":null,"content":{"content_type":"reasoning_recap","content":"Thought for 50s"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"reasoning_ended","finished_duration_sec":50,"request_id":"96d8559ecb41c51a-SIN","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","parent_id":"cca9daae-49ad-4b5d-a27f-13fc2d36afbb","timestamp_":"absolute"},"recipient":"all","channel":null},"parent":"cca9daae-49ad-4b5d-a27f-13fc2d36afbb","children":["c93ca5bf-85ea-4456-825a-0cc2d9ee3179"]},"c93ca5bf-85ea-4456-825a-0cc2d9ee3179":{"id":"c93ca5bf-85ea-4456-825a-0cc2d9ee3179","message":{"id":"c93ca5bf-85ea-4456-825a-0cc2d9ee3179","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1754921615.859122,"update_time":null,"content":{"content_type":"text","parts":["Here\u2019s my blunt take.\n\nThe claim that \u201cno one will need to study the hard stuff because self-improving AI will handle it\u201d confuses automation of *tasks* with automation of *responsibility*. Even under very aggressive AI progress, societies that stop producing people who can think in robotics, math, physics, and systems engineering will become brittle, manipulable, and unsafe. They\u2019ll also innovate less. The optimist story only works under a stacked set of assumptions\u2014near-perfect reliability, scalable alignment, abundant energy and hardware, robust autonomy in the physical world, and stable institutions\u2014that rarely co-occur in real systems.\n\nStart with feasibility. Self-improvement is not magic; it\u2019s constrained by compute, data, energy, experiment cycles, and the cost of testing in the real world. In software you can iterate fast; in embodied systems you pay \u201creality tax\u201d: friction, variance, wear, latency, safety gating, regulation, and liability. That\u2019s before you confront adversaries. Autonomous systems in open environments face distribution shift and strategic manipulation, where even tiny failure probabilities are unacceptable at scale. When stakes are high\u2014bioprocess control, grid stability, aviation, nuclear, financial plumbing\u2014you don\u2019t retire the humans who understand the substrate; you change their job from \u201cprimary operator\u201d to \u201cverifier, auditor, and incident commander.\u201d Those roles still require deep technical literacy.\n\nNow alignment and specification. Powerful models don\u2019t remove the need to know what to build or why. They push it *upstream* into problem framing, objective design, constraint setting, and multi-objective trade-offs (safety, fairness, cost, latency, interpretability). You can\u2019t meaningfully specify, monitor, or contest an AI system\u2019s behavior in a domain you don\u2019t understand. If a model proposes a new control law for a fusion reactor or a proof that collapses a complexity class, who detects a subtle objective mismatch or a hidden regularity assumption? Domain expertise is precisely how we avoid Goodhart traps and \u201cworks in sim\u201d failures.\n\nVerification doesn\u2019t disappear either. We\u2019ll use formal methods, property testing, fault injection, and mechanized proof assistants more widely. But those tools live on the same hard disciplines: logic, probability, optimization, control, numerical analysis, programming languages, and systems. Model-generated artifacts still need model-*independent* checks. An epistemic monoculture where the only way to verify a model\u2019s output is \u201cask a bigger model\u201d is a single point of failure.\n\nThere\u2019s also a sovereignty and resilience angle. If only a small priesthood can build and audit the core AIs, power centralizes. A nation (or company) that atrophies its STEM base becomes dependent on whoever controls the models, fabs, data, and energy. Shocks\u2014export controls, supply chain breaks, cyber incidents\u2014then propagate. Broad technical education is not just about employment; it\u2019s strategic redundancy.\n\nTacit knowledge matters more than optimists admit. Plenty of engineering is craft: how to design experiments that *actually* isolate a variable; where real-world tolerances break a beautiful abstraction; how to make a robot survive dust, heat, and miscalibration; which numerical scheme will behave under stiff dynamics on imperfect hardware. Much of this is learned in the doing, not in text. You can compress and transmit it with AI, but you still need humans who can absorb, contest, and extend it.\n\nInnovation dynamics also argue against \u201cno study needed.\u201d Models are astonishing pattern synthesizers across existing knowledge. But the frontier moves through anomaly hunting, reframing, and committing to ideas before they\u2019re obviously profitable or even legible to current systems. Human taste and risk appetite still select problem portfolios, fund experiments, and decide which divergences from the prior are worth chasing. AI will expand the search; humans will choose where to dig.\n\nWhere could the optimists be partially right? Coding as currently practiced will continue to commoditize; a lot of routine proof search, derivations, and experiment design will be \u201ccopilot-first.\u201d Many people will *need* less domain depth to be productive. But this is an argument for *raising the floor* with AI, not *lowering the ceiling* of human capability. You still want a significant fraction of the population trained to expert level in foundational disciplines, because that\u2019s the layer that defines constraints, audits systems, handles tail events, and pushes the frontier when the tools plateau.\n\nA more realistic end-state is layered autonomy with human technical roles shifting rather than disappearing:\n\n1) Architecture and specification. Translating societal goals and domain constraints into machine-checkable specs. Requires deep domain math/physics/CS.  \n2) Mechanized science and engineering. Running AI-designed pipelines, but with humans owning experiment topology, safety envelopes, and go/no-go gates.  \n3) Assurance. Formal verification, adversarial testing, provenance, reproducibility, and incident response.  \n4) Governance engineering. Designing incentive-compatible deployment regimes, market rules, and safety cases that bind model use in critical infrastructure.  \n5) Frontier research. When models saturate current data or run into physical/algorithmic limits, humans reframe the problem and invent new primitives.\n\nEducation should adapt, not vanish. Less time on syntactic grind; more on semantics and systems: control and robustness, probabilistic reasoning, causal inference, mechanism design, computability/complexity, optimization under constraints, and HIL (hardware-in-the-loop) thinking. Teach people to *drive* and *doubt* advanced tools: build a spec; force it through a proof assistant; simulate; push to hardware; red-team; write the post-mortem. That is still \u201chard stuff,\u201d just with better leverage.\n\nMy forecast, stated plainly: Over the next 10\u201315 years, the premium on deep math/CS/engineering will *rise*, not fall, because capable AI increases the scope and hazard surface of what we attempt. Beyond that horizon, if alignment, reliability, and abundant energy all hold, the *median* person can rely more on AI to do sophisticated work. But the societal *need* for human experts does not go to zero unless you are willing to accept opaque governance, concentrated power, and catastrophic-tail risk without independent recourse. If we teach fewer people the hard stuff, we won\u2019t need it less\u2014we\u2019ll just notice failures later and have fewer levers to fix them.\n\nSo no, we shouldn\u2019t stop studying. We should study differently: aim for conceptual mastery, systems literacy, and the ability to specify, verify, and govern powerful machine collaborators. That\u2019s how you get the upside of self-improving AI without forfeiting agency or safety."]},"status":"finished_successfully","end_turn":true,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200002]},"is_complete":true,"citations":[],"content_references":[],"request_id":"96d8559ecb41c51a-SIN","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","parent_id":"ce8e9ee2-6402-49ee-a385-4116b2fd6d9e","timestamp_":"absolute"},"recipient":"all","channel":"final"},"parent":"ce8e9ee2-6402-49ee-a385-4116b2fd6d9e","children":["157e8e1d-b1b0-4482-a462-3bfb8b3c0393"]},"157e8e1d-b1b0-4482-a462-3bfb8b3c0393":{"id":"157e8e1d-b1b0-4482-a462-3bfb8b3c0393","message":{"id":"157e8e1d-b1b0-4482-a462-3bfb8b3c0393","author":{"role":"user","name":null,"metadata":{}},"create_time":1754924218.397,"update_time":null,"content":{"content_type":"text","parts":["That was a comprehensive, sharply articulated take. Now, examine the transcript of the following podcast and provide relevant commentary in light of your discussion above.\n\n---\n\n# Post\u2011Labor Economics, Part 1: The Rise of Automation \u2014 A Conversation with David Shapiro\n\n## Introduction and Series Overview\n\n**Host (Dali Petrovich):**  \nWell, good morning, good afternoon, or good evening, ladies and gentlemen. Welcome\u2014or welcome back, as the case might be. My name is Dali Petrovich, your host for these Tectonic Conversations. Today, I'm thrilled to be joined by my friend and colleague, David Shapiro. Dave, thank you very much for your time.\n\n**Guest (David Shapiro):**  \nThanks for having me back.\n\n**Host (Dali):**  \nThank you, David. What we wanted to do is create a series of live webcast episodes to explore the topic of post\u2011labor economics in more detail. Knowing that David has just completed writing the manuscript of his new book called The Great Decoupling, we thought it would be great to follow the structure of that book, which delves deeply into the topic of post\u2011labor economics. Over the next couple of months we\u2019re going to organize and deliver six episodes like this, focusing on each one of the six parts of this master volume\u2014The Great Decoupling. This session today, the first in the series, will focus on Part One, which is The Rise of Automation. But because this is the first episode, we\u2019re going to start with the big picture, and I\u2019m going to ask David to explain, for someone hearing the concept of post\u2011labor economics for the first time, what it is, why it\u2019s important, and why someone who is not an economist should think about it, learn about it, and get involved. Dave, over to you.\n\n## Defining Post\u2011Labor Economics\n\n**Guest (David):**  \nYeah, great first question. The simplest definition of post\u2011labor economics that I use is: we are seeing an ongoing decoupling of economic productivity from human labor inputs. In simpler terms, GDP goes up, wages go down. We\u2019ve actually seen this trend pretty much since the 1950s, and it\u2019s only continuing to accelerate due to additional layers of automation.\n\nNow, the book I\u2019ve just completed\u2014it needs a little polishing and refinement\u2014but it asks and answers two fundamental questions. One is: how do we make ends meet if our jobs get automated away? It doesn\u2019t have to be 100% of jobs; it could be 40%, 50, 60, 80%. But imagine if we had an unemployment level of 40% rather than the 4.5% we have today. The second question is: how do we keep society balanced if labor loses that much power, because labor is part of our social contract today. That is post\u2011labor economics at a very, very high level.\n\n## Today\u2019s Structure\n\n**Host (Dali):**  \nExcellent. Here\u2019s how we\u2019re going to structure today\u2019s episode: we\u2019ll go through some very basic questions for people being introduced to this topic for the first time. Then, in the next part, we\u2019ll go through the seven chapters of Part One of the book. And we\u2019ll reserve more expert\u2011level questions for the end. Is that fair?\n\n**Guest (David):**  \nYep. Let\u2019s do it.\n\n## Why This Time Is Different\n\n**Host (Dali):**  \nOne of the basic premises of post\u2011labor economics is that, yes, we\u2019re going through industrial revolutions, we\u2019re inventing and deploying technology, but this time things are going to be different. Can you reflect on why you feel that\u2019s the case, and how societies in the past handled major technological disruptions?\n\n**Guest (David):**  \nYeah. In a word, this time is different because we\u2019re working toward what Sam Altman called \u201cintelligence too cheap to meter,\u201d or, in more objective terms, cognitive hyperabundance. That sounds like a mouthful, but basically we\u2019re presently in a knowledge\u2011work or service\u2011based economy, and what we\u2019re working on automating right now\u2014with artificial intelligence like LLMs and other kinds of AI\u2014is automating away the need for human cognitive labor. It\u2019s going to be better, faster, cheaper, and safer than humans. In many cases it already is. There was a news report the other day that said 40% of Americans trust AI chatbots for medical advice. That has ramped up far faster than many would have predicted, and those AIs are only going to get better from here.\n\nThat\u2019s the key difference. Automation in the past was not general\u2011purpose and was not as flexible as humans are. Remember, the same chatbots that can write code are also able to diagnose medical conditions, help you plan to build a house, replace consultants and writers, and so on. It\u2019s the perfect general\u2011purpose technology, and it\u2019s only continuing to improve. That\u2019s what\u2019s different this time around compared to previous industrial revolutions.\n\n## Creative Destruction Then vs. Now\n\n**Host (Dali):**  \nIn previous industrial revolutions, what we know has happened is creative destruction: old industries wither and go away, but new industries emerge, and people displaced in old industries\u2014the theory goes\u2014find their happiness in those new industries. The post\u2011labor economics framework suggests this might not be the case this time around. Can you explain that?\n\n**Guest (David):**  \nYes. Creative destruction is a term coined by Joseph Schumpeter in 1923, characterizing the paradigm shifts of prior industrial revolutions. We ended up with far fewer farmers and weavers, but entirely new industries emerged\u2014steam engines and diesel engines required mechanics, factory line workers, and all kinds of jobs that didn\u2019t exist before. Likewise today we have cloud engineers\u2014that\u2019s what I used to do\u2014and YouTubers. Those are jobs you couldn\u2019t have described to someone in 1900; there were too many layers of technology between what they knew and what we have now. Even in the 1960s and \u201970s, only the most forward\u2011thinking sci\u2011fi predicted the internet\u2019s impact, and even then it under\u2011predicted or missed a lot\u2014some things predicted blogs but not Twitter. You can guess a few decades ahead but not a century.\n\nSo yes, technology knocks out the old and brings in the new, creating entire sectors you can\u2019t predict far in advance. The assumption is that this pattern always leads to more jobs. We\u2019ll talk about why that\u2019s not necessarily the case in a little bit.\n\n**Host (Dali):**  \nThat\u2019s interesting, because when I speak with people who haven\u2019t spent the time we have exploring this, they say, \u201cDon\u2019t worry\u2014new jobs we can\u2019t even imagine will be created, and that will save the day.\u201d I look forward to that exploration; for me that was an aha moment when I understood the math and the calculation there.\n\n## Early Evidence of Displacement\n\n**Host (Dali):**  \nWe already know that automation continuously displaces work. That\u2019s been happening throughout history and it\u2019s happening today. If I asked you to share examples of the types of jobs that automation today is already replacing\u2014things people might not be thinking of\u2014what would you cite?\n\n**Guest (David):**  \nTwo of the most public examples we\u2019re seeing, both in data and through anecdotes, are, first, copywriters. One of the primary use cases of chatbots today is to write\u2014everything from emails to marketing copy, fiction, and non\u2011fiction. Second, call centers\u2014customer service or marketing. The combination of realistic human voices and speech\u2011to\u2011text/text\u2011to\u2011speech, combined with these general\u2011purpose cognitive engines, allows you to replace most of your call\u2011center staff either with one\u2011to\u2011one digital callers or by moving your customers to chatbots, which is the native format of these AIs.\n\nLooking at the data, there\u2019s also been a huge number of layoffs this year. Depending on who you ask, there are about 80,000 to 100,000 layoffs just in the tech sector alone due to AI. However, when you look at changes in, for instance, payrolls versus corporate income, you can probably find evidence that there are even more layoffs, including overseas workers and contractors. Up to half a million people this year alone, in America alone, have potentially been laid off either directly due to AI or due to downstream impacts of AI being integrated into Fortune 500 companies. So, there\u2019s quite a bit going on here, and it\u2019s not always obvious yet exactly how big the impact is.\n\n**Host (Dali):**  \nI watched your YouTube video on how you derived that half\u2011a\u2011million displacement figure. For posterity, we are recording this in August 2025, so that\u2019s the effect of the first seven months of this year. The impact is real, and I think a lot of people either explicitly or intuitively feel that something different is going on here. That\u2019s why more people are paying attention to this conversation.\n\n## Part One Overview: The Rise of Automation\n\n**Host (Dali):**  \nLet\u2019s unpack the actual book and start with Part One, The Rise of Automation. This part is broken into seven components, and we\u2019ll delve into each to build the story. David, what is Part One intended to do? What are the key messages? Then let\u2019s start with the epochal shifts.\n\n**Guest (David):**  \nIf you\u2019re going to talk about post\u2011labor economics, the first ingredient you need is to demonstrate that automation will be sufficient to displace human labor. That\u2019s the fundamental purpose of this first part of the book: to show the history of automation. We start with the printing press and move forward to artificial intelligence today. That\u2019s 500 years of history. The reason we need to do this is to show that automation is not just a chatbot; automation comprises many technologies, and there\u2019s a class they fit under\u2014general\u2011purpose technologies.\n\nYou might say, \u201cAI is a narrow kind of automation\u2014it can\u2019t do everything.\u201d Sure. But as a general\u2011purpose technology, you will continue discovering uses for it for many years, the same way we\u2019re still figuring out new uses for the wheel, electricity, and the internet\u2014other than fire, which you could argue we discovered rather than invented. The long arc of this part demonstrates that automation is on the rise and has been on the rise, and it teaches readers how to grasp what it means to reach a saturation point of automation, ultimately reaching cognitive hyperabundance\u2014intelligence too cheap to meter. You really need to understand that\u2019s the chief economic bottleneck we\u2019re currently eliminating.\n\n## Epochal Shifts and Normalcy Bias\n\n**Host (Dali):**  \nGreat setup. Let\u2019s start unpacking the story. Section one is \u201cEpochal Shifts.\u201d\n\n**Guest (David):**  \nMany people are anchored in what\u2019s called normalcy bias. We have a cognitive preference to understand the world as we see it today and assume it\u2019s not really going to change. Even when we live through changes, our brains tend to assume the new normal is permanent.\n\nThis section goes through the long history from agrarian farmers, the invention of the printing press, getting rid of monarchies, and then up through the first, second, and third industrial revolutions, to show that in the last 500 years we have lived through no fewer than three or four full socioeconomic and sociopolitical paradigm shifts. Politics changed, economics changed, society changed, due primarily to technology. Technology was a forcing function. People are right to point out technology alone does not guarantee a better future; you need policy, institutions, and thoughtful implementation. At the same time, we can learn a lot by comparing states or regions keen to adopt and integrate innovations versus those that were resistant.\n\nOne chief example is Tsarist Russia. They had little incentive to industrialize, so they didn\u2019t. The aristocracy ignored it and kept their peasants as things were until Russia fell from one of the most powerful empires in Europe to one of the weakest in basically a century because they failed to industrialize. That\u2019s a historical lesson: you do need to embrace these disruptors and innovations, even if they come with the cost of creative destruction.\n\n**Host (Dali):**  \nYou can almost contrast that with what we have now\u2014global competition unfolding between the United States and China on the AI front. That\u2019s a lesson learned. Now we see a fearless competition between the U.S. and China, each trying to out\u2011compete the other and maximize the positive impact for their populations.\n\n## Better, Faster, Cheaper, Safer\u2014and the Four Human Capabilities\n\n**Host (Dali):**  \nSection two is \u201cBetter, Faster, Cheaper, Safer.\u201d It\u2019s here that you mention two four\u2011word concepts that light up light bulbs for people: better, faster, cheaper, safer\u2014and human capabilities. Please explain.\n\n**Guest (David):**  \n\u201cBetter, faster, cheaper, safer\u201d is a term I coined in the very early days, before I even had the name \u201cpost\u2011labor economics.\u201d I was trying to understand the condition under which labor substitution actually occurs. The model I came up with is simple: once a machine option\u2014or capital more broadly\u2014provides the same outcome a human can provide, and it crosses those four thresholds\u2014and it often doesn\u2019t need to cross all four; two or three will usually do\u2014if it\u2019s better, faster, cheaper, and safer than a human, a company, government, or military will generally choose the machine option. Humans are perishable\u2014not that we die, but you can\u2019t put a human on a shelf. Humans aren\u2019t shelf\u2011stable; you can\u2019t amortize us on the books. A machine, however, you can. Once machines cross those thresholds, substitution becomes inevitable.\n\nThen there\u2019s the supply side. On the labor demand side you say, \u201cI want tasks done; I don\u2019t care by who or what.\u201d On the labor supply side you ask, \u201cWhat is it that humans supply to the economy that\u2019s economically valuable?\u201d There are four basic food groups: strength, dexterity, cognition, and empathy.\n\nStrength we started automating away during the first, second, and third industrial revolutions with coal, steam, electric motors, and batteries. Human strength hasn\u2019t been a major bottleneck for a long time. As you pointed out in an earlier episode, we even replaced it with beasts of burden before the industrial revolution. We ended up with thermodynamic abundance\u2014abundance of heat energy\u2014to create mechanical energy. Strength has not been an economic bottleneck for a long time. We have gigantic dump trucks and cranes. All you need to do is push buttons.\n\nDexterity is fine motor control\u2014the ability to assemble circuit boards, make fine stitches, perform surgery. Machines have encroached there with industrial robots, but usually in very controlled environments. However, as robots become more sophisticated\u2014surgical robots are getting better and more autonomous\u2014Neuralink was able to install brain implants, which is a very delicate surgery, at superhuman levels in a fully automated surgery. Other surgical robots recently fully performed a gallbladder removal\u2014no humans involved whatsoever. The dexterity is increasing quickly. Look at the coordination and dexterity of robots like Tesla\u2019s Optimus; there are dozens of those coming to market. We\u2019re in the middle of seeing dexterity be automated away. It\u2019s slower than cognition because the real world has friction, but it\u2019s not a safe harbor forever.\n\nCognition is creativity, problem\u2011solving, planning\u2014writing code, being a CEO, or being a foreman on a construction site where you have to solve problems dynamically. We\u2019re already seeing AI models\u2014like the GPT\u20115 that was just released the day before we\u2019re recording this episode\u2014surpassing humans on many cognitive tasks: planning, coding, medical diagnosis, and more. Cognition isn\u2019t going to be a differentiating factor for human labor arbitrage before too long. It\u2019s not that humans are getting dumber; it\u2019s that machines will be so much smarter, cheaper, and faster that it won\u2019t be reasonable to have a human if and when the AIs can replace that task.\n\nThe last bastion is empathy\u2014the root of communication, trust, authenticity. Chatbots are encroaching there too; people use them for companionship and therapy. However, many humans have a durable preference for other humans. Live performances: you\u2019d probably be less excited to see a basketball game played by robots. Likewise, computers have been better than humans at chess for more than a decade, but you still prefer to see real humans playing each other. So while this is the last bastion of durable demand for human labor, it\u2019s not absorbing enough of the labor refugees\u2014people trying to escape losing their jobs to AI or machines. It\u2019s growing\u2014personal coaches, yoga instructors\u2014but not as fast as the layoffs are growing.\n\n**Host (Dali):**  \nIn other words, we bring strength, cognition, dexterity, and empathy. And whenever technologies can do those faster, better, cheaper, or safer\u2014or some combination thereof\u2014the likely scenario is displacement of work. That\u2019s clear. Now we have to figure out how to deal with the transition that\u2019s upon us, in the most effective and efficient way. Many people are betting the creative part of creative destruction will create work to absorb those labor refugees. The big question is whether that will really happen. We\u2019ll discuss that in future episodes.\n\n## The Fourth Industrial Revolution\n\n**Host (Dali):**  \nThis leads us to the Fourth Industrial Revolution. What are its characteristics?\n\n**Guest (David):**  \nThe term was coined by Klaus Schwab of the World Economic Forum in 2016. In the past, each industrial revolution was characterized by the confluence of a handful of technologies\u2014steam power and mechanical engineering; later, electricity, and so on. What we\u2019re seeing in the Fourth Industrial Revolution is the confluence of numerous technologies. It\u2019s not just AI; it\u2019s also biotech, quantum computing, nuclear fusion, solar energy, photonic computing\u2014all coalescing around the same time. They also create a positive feedback loop: the better AI gets, the more it helps every other technology.\n\nI personally characterize AI as the keystone technology of the Fourth Industrial Revolution. It\u2019s very power\u2011hungry, drawing demand for more solar, more nuclear plants, fusion plants eventually\u2014those are knock\u2011on effects. AI is also driving more medical advancements. And geopolitically, as you mentioned, there\u2019s a contest between the U.S. and China. Acceleration isn\u2019t just compounding returns; it\u2019s the de facto geopolitical optimal strategy\u2014a contest around technology.\n\nThere\u2019s also a darker side. Every previous industrial revolution came with huge amounts of social disruption\u2014jobs, economic changes, robber barons during the third industrial revolution, steel and oil tycoons consolidating monopolies, the rise of factories, child labor, dangerous working conditions with no recourse. When you have all\u2011encompassing changes, it can get messy. That\u2019s the motivation for writing this book: how best can we navigate these choppy waters.\n\n**Host (Dali):**  \nThe big difference now is that information technology was the grandmother that gave birth to daughter technologies, and now there are granddaughter technologies that touch everything\u2014from space tech to robotics to biology, chemistry, and physics. It\u2019s proliferation everywhere\u2014what you call \u201cthe spread in all directions,\u201d right?\n\n## Spread in All Directions\n\n**Guest (David):**  \nYes. When you look at the impact of these technologies, there are two primary terms: spillover effects\u2014knock\u2011on effects, some predictable, some not\u2014and network effects, where a technology passes the threshold of usefulness and gets integrated everywhere. Take radio waves: when radio was first invented by Nikola Tesla more than a century ago, people asked what it was good for. It was good for one\u2011way communication. You don\u2019t necessarily realize that Wi\u2011Fi, Bluetooth, 5G\u2014all fundamentally the same class of technology\u2014become more useful over time as the tech becomes more sophisticated. Digital broadcast TV, Starlink\u2014these are all downstream of the original progenitor technology.\n\nStep back and don\u2019t just look at chatbots, which are downstream of computers and the internet. Look at all the impacts of AI and machine learning. AI has infiltrated literally every sector of the economy\u2014from construction to law to healthcare to the military and government. Uptake has been much faster than any previous technology. It\u2019s spreading like wildfire. Just looking at ChatGPT\u2014which already has 700 million daily users even though it\u2019s only three years old\u2014that\u2019s spreading like wildfire. And beyond chatbots, computer vision, speech\u2011to\u2011text, image generators\u2014these are being implemented everywhere.\n\nA key characteristic of general\u2011purpose technologies is that they improve internally. Early radios were analog, then digital, then carrying video, then encryption, and so on. AI, in all its categories, is continuously improving. We\u2019re getting more spillover effects. When NASA developed microwave tech, we found communications uses and kitchen uses. As utility goes up and price goes down, sectors that didn\u2019t have a use for a technology suddenly find uses. Electricity is a good example: initially it was expensive and mostly ran big motors, lights, and fans near local coal\u2011burning powerhouses. As we produced more electricity for cheaper, we found more uses. People are familiar with Jevons\u2019 paradox: the more you create of something, the more uses you find for it because it gets more useful, cheaper, and more abundant. In this case, the base technology improves and downstream technologies multiply. Spread in all directions\u2014it\u2019s a tsunami that has already hit us; we just didn\u2019t realize it at first.\n\n**Host (Dali):**  \nHere\u2019s an observation. You talk about better, faster, cheaper, safer. Right now, faster and cheaper\u2014check. Better is the question, and safer is a big question. But the \u201cbetter\u201d gap is shrinking quickly, and in many fields it\u2019s already checked. We now have de facto cheaper and unquestionably faster, not necessarily better everywhere but getting better very quickly. Safety is still an angst\u2014privacy, data handling, control. I\u2019d project the \u201cbetter\u201d gap will shrink across most endeavors, and the safety gap will also eventually shrink. Then we\u2019re facing a very unknown circumstance\u2014hence your work preparing society to understand the dynamics causing this. Unlike many futurists, your work includes solutions. I can\u2019t wait to get to that episode.\n\n## The Luddite Fallacy Revisited\n\n**Host (Dali):**  \nAfter you set the stage so powerfully, many people will say, \u201cDon\u2019t be alarmist. It will work out fine\u2014new industries will emerge.\u201d The Luddite fallacy. Can you explain what that is?\n\n**Guest (David):**  \nThe Luddite fallacy is the age\u2011old idea that technology will destroy jobs and the jobs are gone forever. That was the argument of the Luddites who sabotaged equipment during the early industrial revolutions. I couldn\u2019t propose this framework without addressing this fear, because I\u2019m essentially saying the \u201cfallacy\u201d is true: we will eliminate the need or demand for human labor\u2014at least a significant portion\u2014such that a non\u2011trivial segment of the population, 40% or more in my view, will not have a way to make money as we understand it today through a wage\u2011labor contract.\n\nTo make that argument, look at the truism that\u2019s emerged: \u201ctechnology always creates new jobs.\u201d Technology destroys jobs, and it doesn\u2019t necessarily create new ones, with a few exceptions when it enables new platforms. What technology really does is deflationary\u2014it makes goods and services cheaper. That liberates more capital\u2014therefore more time and labor\u2014to do other things. Farming is the primary example. In 1800, 75% to 90% of Americans were farmers because farming was so inefficient you could only produce a few surplus calories per hour. With the first, second, and third industrial revolutions, farming became more efficient\u201440% of Americans were farmers by 1900, and today it\u2019s 2%. That freed a tremendous amount of time and energy to do other things\u2014go to school, harness electricity, invent radios.\n\nHowever, none of that says new jobs are automatic. There is no economic law that says new jobs are entailed by deflationary pressure. Everyone agrees technology is deflationary\u2014that\u2019s why we do it. But there\u2019s no intrinsic demand for the new goods and services to be rendered by humans. Unless there\u2019s durable, intrinsic demand for a human doing the job, eventually you\u2019ll ask, \u201cWhy have a human do it?\u201d Massage therapists\u2014there are robotic massage machines some people really like. Concierge, butlers\u2014many would prefer a robot. Eliminate everything without an intrinsic human component and there are very few jobs left.\n\nWe\u2019ve gone through three primary workforce paradigms. First was the agricultural revolution\u2014most people were farmers. Next was manufacturing\u2014using dexterity to create goods or render services\u2014now on its way out in advanced economies. Now we\u2019re in a knowledge\u2011based economy\u2014predicated on human cognition. If cognition is about to be subsumed by machines, the next paradigm is an attention\u2011based or meaning/experience\u2011based economy, grounded in authenticity and empathy. You want to see your favorite band on stage, not a hologram; you want to see humans play sports or do comedy. However, we probably won\u2019t need that many comedians, athletes, or chess players. Human attention is scarce\u2014people only spend six to eight hours paying attention beyond themselves and their homes per day. With attention as the primary scarcity, we won\u2019t be able to demand that much human labor. The math doesn\u2019t work.\n\nMy gut instinct, after looking at this for years, is we\u2019ll have an employment rate of about 20% in the future\u2014meaning for everyone who wants a job, only about one in five will find one. Time horizon maybe the next 20 years.\n\n**Host (Dali):**  \nImportant to say: that 20% would be jobs\u2014employment\u2014people getting monthly paychecks. You\u2019re not excluding entrepreneurs or gig workers, right?\n\n**Guest (David):**  \nI\u2019d include a lot of gig and solopreneur work in that\u2014content creators, for instance. And the numbers are abysmal. The average YouTube channel makes less than $100 a month. The average creator on OnlyFans makes less than $200 a month\u2014nowhere near enough to live on. Many writers and comedians are starving artists who need to work coffee\u2011shop jobs while pursuing their dreams. There\u2019s no evidence we can absorb displaced labor there at today\u2019s level.\n\nOne caveat is Baumol\u2019s cost disease. When you have inelastic, low\u2011productivity tasks that scale poorly, the price tends to go up faster as the rest of the economy grows because demand shifts there. Education and healthcare are the two primary examples over the last two decades: the cost of university has gone up because you can\u2019t copy\u2011paste professors\u2014though AI may change that\u2014and it takes a long time to produce doctors, so healthcare costs have also risen precipitously. Some other job categories might see increased demand\u2014live musicians, comedians, writers, YouTubers\u2014particularly if people aren\u2019t working and have more time to allocate attention. But even so, we\u2019re not seeing those jobs absorb enough labor refugees by a wide margin.\n\n**Host (Dali):**  \nAnd in the attention economy, there\u2019s only so much attention each person has to allocate per day.\n\n## Audience Q&A: Are \u201cBetter, Faster, Cheaper, Safer\u201d Orthogonal?\n\n**Host (Dali):**  \nBefore we move on, Richard in the audience asks: are these four\u2014better, faster, cheaper, safer\u2014in some sense orthogonal and therefore independent of each other?\n\n**Guest (David):**  \nSometimes, but not always. There can be overlap. Take internal combustion engines. You look at the cost to build, maintain, and fuel the engine, and at its power output. As that technology improves, it becomes better, faster, and cheaper in one go. It doesn\u2019t necessarily become safer; in fact, it becomes less safe the more power you have, so you need other systems\u2014crash prevention, seat belts, airbags\u2014to make it safer. Safety is often the most orthogonal to the others.\n\nIn AI, safety is often a requirement. When a military contract specifies a device or software must do X, Y, and Z exactly right, and if you hit the kill switch it turns off immediately, safety is a feature, not just a side benefit. Likewise with humanoid robots: one primary way to get adoption is to ensure they\u2019re safe around children and dogs. If a 25\u2011kilogram robot falls and starts flailing wildly, that\u2019s a lawsuit. In some cases, safety is intrinsic, not orthogonal. So the qualified answer is: sometimes they\u2019re orthogonal, sometimes not. You can find counterexamples both ways.\n\n## Is There a Ceiling? How Smart Can It Get?\n\n**Host (Dali):**  \nWe\u2019ve established that automation, especially when it hits better/faster/cheaper/safer, displaces work. You\u2019ve described the general\u2011purpose nature of technology and how it proliferates. Is there a ceiling? How smart can it get?\n\n**Guest (David):**  \nConsider Moore\u2019s Law\u2014really an observation\u2014that for roughly the last century the cost of computation per operation has gone down exponentially, starting with mechanical relays up through vacuum tubes and now transistors. That trend has shown no sign of slowing down. One primary bottleneck to reach the AI we have today was compute cost. Some of the deep neural networks\u2014the progenitor work that led to transformers\u2014were invented decades ago. The math and theory were there, but computers weren\u2019t big or fast enough and didn\u2019t have enough memory. When I first got into deep learning around 2009, I did a back\u2011of\u2011the\u2011napkin calculation: when will a typical server be able to run something about brain\u2011size? I came to roughly the same conclusion Ray Kurzweil did: about now\u20142025 to 2027\u2014for humanlike computers. I was lucky my math was good, but I was looking at the same facts and trends as everyone else.\n\nWhat\u2019s the maximum intelligence or density we can get to? One example we have is the human brain. It runs on about 20 watts of energy and is, as best as we can figure, at least a million times more efficient than the best supercomputers today. Every time we come up with a new class of supercomputer, the human brain still appears about a million times more efficient, partly because we discover more about how the brain computes. That\u2019s why I say \u201cat least\u201d a million times. That\u2019s several orders of magnitude beyond where Moore\u2019s Law will take us in 10 to 20 years.\n\nPhysics has already produced human brains. There\u2019s also Landauer\u2019s limit\u2014the least amount of energy required to perform a computation. Human brains are about a million to a billion times less efficient than Landauer\u2019s limit, meaning we could hypothetically create computers in the future that are trillions to quadrillions of times more efficient than today, in terms of processing power per watt. From a physics perspective, there\u2019s no functional limit anywhere near the near\u2011term horizon. We can expect Moore\u2019s Law and equivalent derivatives to continue for several decades. In about 40 to 50 years, your smartwatch will be able to run the smartest AI we have today. You could run GPT\u20115 on your Garmin, version 80, if Garmin is still around.\n\n**Host (Dali):**  \nThis technically means we\u2019re heading into\u2014or maybe as of yesterday we\u2019re already in\u2014a cognitive hyperabundance reality.\n\n**Guest (David):**  \nYes, and it\u2019s only going to get cheaper. General\u2011purpose technologies tend to get cheaper and better over time. And it\u2019s not just getting better at the one thing you built it to do. If it\u2019s a general\u2011purpose technology like AI that has cognition, it starts being able to do entirely new classes of things as it expands. Electricity is analogous: initially it powered telegraphs and lights, then radio waves, then electric motors, and now countless other things. As these general\u2011purpose technologies advance, they don\u2019t just get better at the first thing; they proliferate very quickly. That\u2019s what we\u2019re seeing with AI.\n\n**Host (Dali):**  \nWe\u2019re on the cusp of self\u2011improvement of AI systems. And as we learned earlier this week with OpenAI making their open\u2011weights model available freely to anyone on earth, we now technically have the potential for every person to have access to\u2014well, I won\u2019t call it superintelligence\u2014but a PhD\u2011level friend in their pocket on any topic. That\u2019s shocking. And this is day two. This continues exponentially. I think we can say cognitive hyperabundance is upon us.\n\n## Audience Q&A: Diffusion to Developing Nations and \u201cReverse Brain Drain\u201d\n\n**Host (Dali):**  \nThat concludes Part One\u2014The Rise of Automation. Let\u2019s take a few expert\u2011level questions. We\u2019re recording this in August 2025.\n\n**Audience (Pranchu):**  \nDo you think that as the Fourth Industrial Revolution diffuses over the decade from the Western world to the developing world, there will be a massive reverse brain drain through labor refugees?\n\n**Host (Dali):**  \nI\u2019m going to assume you mean labor refugees from more developed nations into the developing world. How would you react to that?\n\n**Guest (David):**  \nGreat question. The early evidence is not intuitive\u2014until you explain it. One first\u2011order effect is that some of the jobs being lost are offshore workers. Anecdotally, we\u2019re seeing remote workers in India, Thailand, Vietnam, Ukraine, Russia being replaced first because it\u2019s easier to let go of contractors overseas, and native American, English\u2011speaking workers are using the latest AI tools to replace their coworkers. That doesn\u2019t get reported as a layoff\u2014it\u2019s an OPEX line item that gets removed. So we\u2019re seeing not a brain drain but almost a demarcation; it\u2019s not even reshoring. It\u2019s just getting rid of the job globally.\n\nThe other thing is that AI is getting so cheap it raises the floor quickly. Chatbots are still diffusing, but medical image analyzers, for example, are being deployed fastest in places like rural India. If you don\u2019t have a doctor in a village but you have an internet connection, you functionally have a doctor. Developing nations can adopt quickly because the price point is low, and it has an outsized impact. I\u2019ve worked with a lot of educators. The first\u2011world problem of AI in education is, \u201cHow do we grade?\u201d In the developing world, they say, \u201cThis is the best thing ever\u2014it\u2019s helping us learn and filling gaps.\u201d That\u2019s the leapfrog effect we\u2019ve observed many times\u2014developing nations go from mud roads to satellite internet in one generation. The pattern is repeating with AI.\n\n**Host (Dali):**  \nIt feels like every nation will need to bootstrap itself into this. Those at the forefront will dominate and win, and those behind need to mobilize quickly, invest in infrastructure, and bootstrap their people to come up with innovations and ideas. More independent nations entering the competition?\n\n**Guest (David):**  \nI think there are certainly people working toward that. Emad Mostaque\u2014formerly of Stability AI\u2014is working on democratizing AI globally. That\u2019s also one reason OpenAI released GPT\u2011OSS, their open\u2011source version, and why China releases so many open\u2011source models. It\u2019s not necessarily pure benevolence\u2014though many do have a good mission\u2014it\u2019s also to make sure developing nations start using their technology now, even before they can afford the high\u2011end stuff.\n\nOpen source is only about six months behind the frontier models. China has demonstrated repeatedly that within a few weeks of OpenAI releasing a new model, they can duplicate it\u2014sometimes by theft, sometimes not. One of the most interesting things about this technology is that it is intrinsically democratic. It\u2019s the most portable technology we\u2019ve ever seen. A file of a few gigabytes\u2014or even a few hundred megabytes\u2014is intelligence you can run on a phone. We\u2019ve never seen a technology this disruptive also be this portable\u2014copy a few files, and if you have a powerful enough computer, you can run it.\n\n**Host (Dali):**  \nPeople describe AI as the modern equivalent of electricity. I\u2019d go a step further\u2014after what happened this week, I\u2019d say we\u2019re entering a time where AI will be like air. It\u2019ll be everywhere, untethered across the world. Everyone who has access to a very affordable local device will have access to superintelligence in their pocket. That\u2019s a game changer like we\u2019ve never had.\n\n## Superstar Firms and Capital Intensification\n\n**Host (Dali):**  \nA couple more expert\u2011level questions. One is the emergence of superstar firms. Many have heard we may see a solopreneur\u2014a one\u2011person billion\u2011dollar business. Highlights we already know: Instagram had 13 employees and 30 million users; WhatsApp had 55 employees and served 450 million users. That demonstrates digital scalability. How do these superstar models alter the economic power structures compared to traditional labor\u2011intensive industries?\n\n**Guest (David):**  \nWhat you\u2019re seeing is capital intensification\u2014capital becomes more valuable than labor. The \u201cMagnificent Seven\u201d stocks are all tech companies. The biggest companies in the \u201940s, \u201950s, and \u201960s were companies like Coca\u2011Cola and GM\u2014brand companies with huge workforce footprints, anchored in the physical world with heavy materials and machines and lots of people to operate them. You couldn\u2019t scale them the way you can now, where a few dozen or a few hundred employees can reach most of the planet. Even OpenAI probably has a couple thousand employees now, but they have a billion users. That would not have been possible before.\n\nThis is exactly what you expect to see with the rise of automation: fewer man\u2011hours, larger impact. But it necessitates that we renegotiate capital intensification because it leads to capital concentration\u2014the people who own those businesses own the lion\u2019s share of everything productive. The World Economic Forum has for a few years had the mantra that everything is moving toward a rentier economy, where everything is a subscription\u2014\u201cyou will own nothing and be happy.\u201d That\u2019s the opposite of what we need. We need to broaden ownership. Otherwise, people won\u2019t have jobs or income, and they won\u2019t be able to pay for the goods and services that are getting cheaper. That\u2019s what superstar firms are telling us. It\u2019s a clue to the future.\n\n## Not Communism\u2014Capitalism 2.0\n\n**Host (Dali):**  \nThis is important to mention. The post\u2011labor economics model you\u2019re proposing is not communism. I\u2019d call it Capitalism 2.0\u2014moving from labor arbitrage as the primary source of income to ownership rights of the population as the source of income. We\u2019re not pitching, \u201cStay in bed, the government will keep you alive.\u201d We\u2019re saying we have an opportunity to reimagine capitalism differently and get everybody to participate as co\u2011owners of the assets. I\u2019m sure you get criticism from people who don\u2019t delve deeper and say, \u201cThis is socialism, communism, Marxism.\u201d\n\n**Guest (David):**  \nWe want the opposite of central management and central ownership. There is an asterisk: within post\u2011labor economics I do advocate for universal basic income, universal basic services, and some sovereign wealth funds\u2014which is technically a socialized, though not fully socialist, mechanism\u2014where the state owns some assets and uses that wealth to help prop up citizens. But that should not be the mainstay of the economy. The mainstay should be market\u2011based and property\u2011based. In that respect, we\u2019re not making dramatic changes. It\u2019s a matter of ensuring people can participate in Capitalism 2.0\u2014what some call hyper\u2011capitalism. If labor goes away as a meaningful way of getting money, then everything is capital. That\u2019s the nature of capital intensification.\n\n## The Zero\u2011Employee Firm\n\n**Host (Dali):**  \nOn superstar firms: full automation implies lights\u2011out factories. We already have lights\u2011out factories, but the ultimate optimal number of employees for a firm is technically zero. I wouldn\u2019t be surprised to see existing billion\u2011dollar companies end up down to the owner\u2014that\u2019s it.\n\n**Guest (David):**  \nWhen you look at why companies hire employees, they hire because they have to\u2014either for regulatory reasons or because they need the person to get the job done. If you ultimately erode and eliminate the need for every employee at every level, you can fire more and more people. We\u2019re seeing the beginning of that\u2014Microsoft, IBM, Google, and others are letting go not only of entry\u2011level people but some middle management as well, because they\u2019re finding more efficiencies. The fewer people you have to manage, the fewer managers you need.\n\nWe haven\u2019t even seen the next wave yet: humanoid robots. Once they amortize to about one to three dollars per hour, they\u2019ll work tirelessly, won\u2019t require insurance, won\u2019t quit, and will just need spare parts and batteries. They\u2019ll be smarter than your average worker as well. Before too long, there will be very few moats around human labor.\n\n**Host (Dali):**  \nAnd in an open free\u2011market economy where every firm competes for survival and prosperity, that model absolutely guarantees that outcome. That\u2019s why we need to talk about policy interventions\u2014ownership and so on\u2014before this natural outcome plays out and we end up with double\u2011digit unemployment comparable to the 1920s and \u201930s.\n\n## Policy: Measurement First\n\n**Host (Dali):**  \nMany current economic policies are built on the assumption of near full employment as the norm, with governments treating 4%\u20137% as the good range. From a policy design standpoint, what are the most urgent updates needed to reflect a reality where human labor might no longer be the primary driver of productivity?\n\n**Guest (David):**  \nThe absolute first step for any policymaker at any level is measuring the difference. Fortunately, many are starting to measure this decoupling\u2014looking at economic performance indexes and other data. For instance, the rise of discouraged workers and marginally attached workers is up sharply this year, as is youth unemployment. We don\u2019t yet have a good dashboard or metric to really capture this. The data can be misleading\u2014gig work hides a lot of underemployment or people not reaching their potential. The first policy change, anywhere, is to work on better measurements so we understand who\u2019s being impacted, where, and at what rate. I\u2019ve got a few ideas, but they\u2019re not battle\u2011tested yet. Any policy intervention should start with making sure we know what\u2019s happening on the ground.\n\n**Host (Dali):**  \nFor those following us, this video will be available on both the Tectonic Conversations channel and David\u2019s channel. I invite you to register for the forthcoming episodes\u2014the link is in the description.\n\n## Possible Futures: Worst Case and Best Case\n\n**Host (Dali):**  \nFinal question: possible futures. You\u2019re projecting some pretty spectacular numbers\u2014that within the next decades we might live with a billion humanoid robots among us performing physical tasks, while cognition has long since been automated. What are the possible scenarios? Best case? Worst case?\n\n**Guest (David):**  \nLet\u2019s start with the worst case so we can end on a high note. Worst case: society and government fail to adapt, and we end up with a runaway freight train of capital concentration and capital intensification. We get what science fiction calls \u201chigh\u2011tech, low\u2011life.\u201d Technology continues to improve, but you\u2019ll own nothing and you won\u2019t be happy\u2014you\u2019ll have no leverage and very little income. People will scrape by on gig work or government handouts. One version is more corporate oligarchy or hegemony\u2014multinational conglomerates owning everything. But the entire economy suffers because, without consumption, companies have no one to sell to. You end up in a lose\u2011lose scenario where the state, the people, and corporations all lose power because the economy stalls. Putting it gently, that could lead to protests, riots, even civil war. People tolerate hardship, but not hardship and powerlessness for prolonged periods. Eventually the calculus becomes: it\u2019s better to turn violent and tear the system down and rebuild it.\n\nBest case: we come up with the right measurements and implement the correct interventions, and we implement reforms vigorously as they become means\u2011tested\u2014not just at the national level, but international, regional/state, and city levels. Then we could end up in a situation where very few people work, and those who work do so because they want to\u2014because it\u2019s something they want to do, not because they\u2019re compelled. People will be free, with enough capital to pursue their dreams\u2014be a sculptor, hike the Appalachian Trail, be a tour guide\u2014whatever it is. Entrepreneurs will be competing against superintelligence\u2014so good luck in 15 years; you\u2019ll have to be sharp\u2014but if you want to do it, go for it.\n\nThat level of individual liberty and social mobility is what we should aim for. It won\u2019t be equal in outcome, but everyone should have the same floor\u2014the same bootstrapping capital to meet basic needs, to ensure they\u2019re not at risk of homelessness or hunger, and that they have healthcare. There should also be ways for everyone to participate in market\u2011based Capitalism 2.0. If you want to build wealth, you won\u2019t need to, but you can. The last thing we want is a system where nobody has economic agency, regardless of how hard\u2011working or smart they are.\n\n**Host (Dali):**  \nWe\u2019re at a junction, and it\u2019s up to us to decide. Do we move toward the Star Trek, solar\u2011punk, beautiful future\u2014the age of abundance\u2014where people still have economic agency and can deploy it to better themselves, their families, and their communities? Or do we not and drift into an Elysium\u2011style dystopia? This is the task of our generation. It\u2019s probably the most important task in front of humanity, because it impacts all of us regardless of where we were born. We should reach out across the globe and connect with people who have the right mindset, who understand both the risk and the opportunity. This is why we\u2019re doing this. David, thank you so much. For the audience, please subscribe to David\u2019s channel and to Tectonic Conversations, and register for the future episodes. Thank you for your attention.\n\n**Guest (David):**  \nThank you so much. Take care. Bye\u2011bye."]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"selected_sources":[],"selected_github_repos":[],"serialization_metadata":{"custom_symbol_offsets":[]},"request_id":"96d8952cde5a3ffa-SIN","message_source":null,"timestamp_":"absolute"},"recipient":"all","channel":null},"parent":"c93ca5bf-85ea-4456-825a-0cc2d9ee3179","children":["fecf11d3-b711-4849-8b9b-8d3ffb738841"]},"fecf11d3-b711-4849-8b9b-8d3ffb738841":{"id":"fecf11d3-b711-4849-8b9b-8d3ffb738841","message":{"id":"fecf11d3-b711-4849-8b9b-8d3ffb738841","author":{"role":"system","name":null,"metadata":{}},"create_time":1754924218.657001,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"is_contextual_answers_system_message":true,"is_visually_hidden_from_conversation":true,"command":"prompt","contextual_answers_message_type":"sources_and_filters_prompt","request_id":"96d8952cde5a3ffa-SIN","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","parent_id":"157e8e1d-b1b0-4482-a462-3bfb8b3c0393","timestamp_":"absolute"},"recipient":"all","channel":null},"parent":"157e8e1d-b1b0-4482-a462-3bfb8b3c0393","children":["5cb59247-fe58-408b-a568-34ff92e18921"]},"5cb59247-fe58-408b-a568-34ff92e18921":{"id":"5cb59247-fe58-408b-a568-34ff92e18921","message":{"id":"5cb59247-fe58-408b-a568-34ff92e18921","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1754924220.311548,"update_time":null,"content":{"content_type":"thoughts","thoughts":[{"summary":"Analyzing the user's request","content":"The user wants a detailed commentary on a podcast about post-labor economics, connecting it to our earlier discussion on the importance of studying challenging topics and human expertise. I'll aim for a professional, deep analysis with rigorous critique, in a clear, precise tone. There's no need for up-to-date info or external searches.","chunks":[],"finished":true},{"summary":"Proceeding with analysis","content":"Since the user provided a transcript, I don\u2019t need to look up external facts. While claims like \"GPT-5 released\" or \"AI layoffs\" could be challenged, I don\u2019t have to verify them unless directly asked. It\u2019s enough to critique the claims for unsubstantiated statements without needing to browse or cite outside sources.","chunks":[],"finished":true},{"summary":"Structuring the critique","content":"I\u2019ll raise concerns about claims needing empirical validation and suggest metrics. It's important to link the points to our earlier views: like automation vs. responsibility, human capabilities, and the risks of overreliance on AI. I'll challenge certain assumptions and offer critical frameworks for evaluating and ensuring safety in emerging technologies, proposing near-term policy and research efforts to retain human expertise.","chunks":[],"finished":true},{"summary":"Structuring the commentary","content":"I\u2019ll organize the commentary into professional, continuous prose while keeping the structure clear with distinct sections: Assessment of premises, agreement points, tensions, missing elements, policy, education, research, and actionable takeaways. The user prefers detailed analysis without excessive verbosity or bullet points, so I'll ensure the tone remains clear, precise, and focused.","chunks":[],"finished":true}],"source_analysis_msg_id":"56c54382-c79a-4050-b145-5ca03b892b71"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"is_reasoning","citations":[],"content_references":[],"classifier_response":"default","skip_reasoning_title":"Get a quick answer","request_id":"96d8952cde5a3ffa-SIN","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","parent_id":"fecf11d3-b711-4849-8b9b-8d3ffb738841","timestamp_":"absolute"},"recipient":"all","channel":null},"parent":"fecf11d3-b711-4849-8b9b-8d3ffb738841","children":["13e6498c-410b-4be9-81cd-440ef9aa40d3"]},"13e6498c-410b-4be9-81cd-440ef9aa40d3":{"id":"13e6498c-410b-4be9-81cd-440ef9aa40d3","message":{"id":"13e6498c-410b-4be9-81cd-440ef9aa40d3","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1754924273.215858,"update_time":null,"content":{"content_type":"reasoning_recap","content":"Thought for 52s"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"reasoning_ended","finished_duration_sec":52,"request_id":"96d8952cde5a3ffa-SIN","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","parent_id":"5cb59247-fe58-408b-a568-34ff92e18921","timestamp_":"absolute"},"recipient":"all","channel":null},"parent":"5cb59247-fe58-408b-a568-34ff92e18921","children":["67ca84d7-e1fc-4c1e-add0-981852834837"]},"67ca84d7-e1fc-4c1e-add0-981852834837":{"id":"67ca84d7-e1fc-4c1e-add0-981852834837","message":{"id":"67ca84d7-e1fc-4c1e-add0-981852834837","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1754924218.681059,"update_time":null,"content":{"content_type":"text","parts":["Below is a critical reading of the episode through the lens of the earlier argument: automation can eat tasks, but it cannot\u2014and must not\u2014replace human responsibility for specification, verification, governance, and frontier reframing. I\u2019ll keep close to what\u2019s said in the transcript, flag places where the reasoning is strong, where it overreaches, and what\u2019s missing if we want this discussion to inform real decisions.\n\n# What the episode gets right\n\nThe \u201cbetter/faster/cheaper/safer\u201d framing is a useful operational rule for when substitution happens, and pairing it with the four human \u201cinputs\u201d\u2014strength, dexterity, cognition, empathy\u2014helps non-experts reason about displacement channels. It also correctly situates AI as a general-purpose technology with spillovers and network effects; diffusion really does create second- and third-order uses that are hard to foresee ex ante. The link to capital intensification and superstar firms is, directionally, also right: if marginal cognition approaches zero cost, output per head can rise while headcount falls, and ownership of the capital stack becomes more determinative of income than hours worked.\n\nFinally, the insistence on **measurement first** is the best policy instinct in the conversation. Right now our dashboards hide underemployment, discourage workers, and quality-adjusted output. If we\u2019re about to renegotiate the social contract, we need new leading indicators rather than after-the-fact anecdotes.\n\n# Where the argument overreaches\n\n**\u201cIntelligence too cheap to meter\u201d is a claim about *cost and reliability*, not just speed and quality.** The episode often treats \u201ccheaper and faster\u201d as sufficient. In critical domains the gating variable is *assured reliability under distribution shift*. If a model writes 1,000 perfect scripts and one that silently corrupts a safety interlock, the expected cost of that tail dwarfs savings. Without assurance, \u201ctoo cheap to meter\u201d can be *too risky to deploy*. You can\u2019t retire human expertise until you can make\u2014and *audit*\u2014systematic guarantees, not benchmark demos.\n\n**Task success \u2260 function automation.** The transcript blurs one-off task competence (\u201cmodel X outperforms on planning/coding/diagnosis\u201d) with the ability to own a *function* end-to-end. Owning a function requires specification, exception handling, red-teaming, incident response, liability modeling, and change management across messy socio-technical interfaces. That is precisely where deep domain knowledge lives, and where, in practice, deployment fails if humans stop studying the substrate.\n\n**Dexterity timelines are still bottlenecked by the \u201creality tax.\u201d** The episode treats humanoid dexterity as an inexorable, near-term wave. Progress is real, but throughput in uncontrolled environments continues to be limited by sensing under occlusion, contact-rich manipulation, latency, safety envelopes around humans, verification of control stacks, and plain wear-and-tear. Calling this out isn\u2019t luddism; it\u2019s a reminder that embodied autonomy scales slower than software, so labor market forecasts must reflect that asymmetry.\n\n**The 20% employment prediction is asserted, not demonstrated.** It may prove right, but the chain of reasoning needs a model: assumed adoption curves by sector, quality-adjusted price declines, ODD (operational design domain) expansion rates for robotics, regulatory lags, and attention-economy income concentration parameters. Without those, we\u2019re extrapolating from salient anecdotes.\n\n**\u201cOpen models democratize intelligence\u201d understates power concentrations.** Portability of weights helps, but the durable moats\u2014cutting-edge compute, energy, fab capacity, data pipelines, evaluation/assurance infrastructure, system integration into regulated domains\u2014remain capital-intensive and geopolitically chokepointed. That interacts directly with the episode\u2019s own worry about capital concentration.\n\n# What\u2019s missing if we\u2019re serious about deployment\n\n**Assurance as a first-class economic activity.** If automation is to be \u201csafer,\u201d who proves it? We need explicit safety cases, formal interfaces between natural language specs and machine-checkable properties, property-based testing at system scale, adversarial evaluation markets, provenance and bill-of-materials for models, and cross-model redundancy to avoid epistemic monocultures (\u201cthe only way to check a model is with a bigger model\u201d). None of this appears in the episode, yet it determines whether substitution is economically rational outside of low-stakes domains.\n\n**Governance engineering.** Beyond \u201cCapitalism 2.0,\u201d we need deployable mechanisms: regulated autonomy levels by domain (analogous to SAE levels in AVs), mandatory incident reporting with near-miss taxonomies, compute-for-safety carve-outs, and insurance-linked safety standards that price residual risk. Otherwise \u201cbetter/faster/cheaper\u201d will outcompete \u201csafer\u201d in the wild.\n\n**Sovereignty and resilience.** A nation that outsources STEM mastery because \u201cAI can do it\u201d becomes strategically dependent on the owners of fabs, energy, and frontier models. The transcript hints at US\u2013China competition but doesn\u2019t follow through to the policy conclusion: broad technical education is a resilience asset, not merely a labor-market instrument.\n\n# Reframing specific claims in light of \u201cdon\u2019t stop studying the hard stuff\u201d\n\nWhen the guest says cognition will soon cease to differentiate human labor, take that as a *floor effect*: AI raises average competence, compressing the bottom and middle of the distribution. The ceiling\u2014architecture, specification, verification, mechanism design, control under constraints\u2014remains scarce and becomes more valuable because it gates the safe use of the tools. That directly contradicts the meme that fewer people should study math/CS/engineering; it implies the opposite. The roles shift: from doing all the calculations by hand to making them legible to proof assistants; from writing every control loop to writing contracts that restrict what any loop may do; from manual QA to building falsification harnesses and incident-command drills. None of that is \u201ceasy mode.\u201d\n\nLikewise, the \u201cempathy enclave\u201d is under-analyzed. Demand for human authenticity is real but thin if we think in occupational codes. The thicker case is *trust brokerage*: humans who can interrogate, contest, and certify model-mediated outputs for institutions and the public. That still requires technical depth; it isn\u2019t mere \u201cbedside manner.\u201d\n\n# A crisper measurement and research agenda\n\nIf policymakers should start with measurement, measure the right things:\n\n\u2013 **Quality-adjusted labor displacement** by task family, with explicit error-tolerance thresholds; a task that can be automated at 95% accuracy may still be net negative if its allowed error is 0.1%.  \n\u2013 **Autonomy Readiness Levels (ARL)** per sector: a ladder from \u201ccopilot\u201d to \u201cclosed-loop with human veto\u201d to \u201clights-out,\u201d each with required evidence types (formal proofs, stress tests, field trials, post-deployment monitoring).  \n\u2013 **Assurance spend as share of capex/opex** for AI-enabled lines of business; if it\u2019s near zero, you\u2019re almost certainly externalizing risk.  \n\u2013 **Diversification indices** for model provenance in critical systems to avoid monoculture failure.  \n\u2013 **STEM capacity indicators** tied to sovereignty: number of professionals capable of reading/authoring formal specs, control proofs, and safety cases per million people.\n\nAcademically, fund the plumbing: spec languages that bind natural-language requirements to formal properties; scalable falsification methods for learned controllers; multi-model adjudication protocols; and HIL (hardware-in-the-loop) testbeds that quantify \u201creality tax.\u201d\n\n# Policy that actually complements the thesis\n\n\u201cCapitalism 2.0\u201d needs more than universal income and public wealth funds. If the goal is agency without brittle dependence:\n\n\u2013 **Widen ownership of the *means of assurance*.** Subsidize community testbeds, public model-eval infrastructures, and open safety tooling so independent auditors can contest corporate claims.  \n\u2013 **Education pivot** toward systems literacy: control and robustness, probabilistic reasoning, formal verification, safety case writing, and incident command for AI-enabled systems. That\u2019s not less \u201chard stuff,\u201d it\u2019s harder\u2014and more valuable.  \n\u2013 **Compute as a regulated utility** for safety-relevant evaluation (not training) to reduce the advantage of firms that starve third-party auditors.  \n\u2013 **Mandatory transparency artifacts**: model cards with legally relevant claims, training data provenance summaries, change logs, and structured post-mortems.\n\n# Scenario hygiene\n\nThe worst-case \u201chigh-tech, low-life\u201d and best-case \u201cabundance with agency\u201d are useful bookends, but planning lives in the middle. Expect heterogeneity by domain: fast cognitive substitution in software and back-office work; slower, staircase-like substitution in embodied services; stubborn human bottlenecks in governance and assurance. Expect local reversals when a high-profile incident resets public tolerance. Expect \u201ccapability cliffs\u201d where modest gains in reliability unlock large swaths of automation, followed by long plateaus. Those features argue for keeping\u2014and upskilling\u2014the human technical base through the whole arc.\n\n# Bottom line\n\nThe episode is right about the direction of travel and right to force the distributional question now, not later. But the claim that cognition will soon be so abundant that human expertise becomes optional misses where value (and risk) concentrates in an automated society: specification, verification, control, and governance. Those are not automatable away without first being *understood*. If we stop training people in robotics, engineering, math, physics, and computing because \u201cthe models can,\u201d we will not need the hard stuff less\u2014we will only notice failures later, have fewer levers to correct them, and be more dependent on whoever owns the stack.\n\nStudy the hard stuff. Then aim it where the future actually needs you: architecting, constraining, and assuring the machines we\u2019re about to trust with everything."]},"status":"finished_successfully","end_turn":true,"weight":1.0,"metadata":{"citations":[],"content_references":[],"request_id":"96d8952cde5a3ffa-SIN","message_type":"next","model_slug":"gpt-5-thinking","default_model_slug":"gpt-5-thinking","parent_id":"13e6498c-410b-4be9-81cd-440ef9aa40d3","timestamp_":"absolute"},"recipient":"all","channel":"final"},"parent":"13e6498c-410b-4be9-81cd-440ef9aa40d3","children":[]}}}