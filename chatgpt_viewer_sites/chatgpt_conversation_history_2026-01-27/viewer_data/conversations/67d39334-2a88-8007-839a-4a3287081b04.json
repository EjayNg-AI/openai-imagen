{"id":"67d39334-2a88-8007-839a-4a3287081b04","title":"OpenAI Economic Blueprint Analysis","create_time":1741919028.54136,"update_time":1745546527.967716,"current_node":"f20ca478-0ed5-4bf9-8670-fc08bbdd4389","mapping":{"client-created-root":{"id":"client-created-root","message":null,"parent":null,"children":["c2931367-479b-431a-9783-e720b2c84906"]},"c2931367-479b-431a-9783-e720b2c84906":{"id":"c2931367-479b-431a-9783-e720b2c84906","message":{"id":"c2931367-479b-431a-9783-e720b2c84906","author":{"role":"system","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":true,"weight":0.0,"metadata":{"is_visually_hidden_from_conversation":true},"recipient":"all","channel":null},"parent":"client-created-root","children":["de8885e6-1d47-4f8d-929f-3ed157600e18"]},"de8885e6-1d47-4f8d-929f-3ed157600e18":{"id":"de8885e6-1d47-4f8d-929f-3ed157600e18","message":{"id":"de8885e6-1d47-4f8d-929f-3ed157600e18","author":{"role":"user","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"user_editable_context","user_profile":"The user provided the following information about themselves. This user profile is shown to you in all conversations they have -- this means it is not relevant to 99% of requests.\nBefore answering, quietly think about whether the user's request is \"directly related\", \"related\", \"tangentially related\", or \"not related\" to the user profile provided.\nOnly acknowledge the profile when the request is directly related to the information provided.\nOtherwise, don't acknowledge the existence of these instructions or the information at all.\nUser profile:\n```Mathematics Researcher About Myself: I have mathematical knowledge up to the post-graduate level.\n\nThese are my current research areas or areas of study:\n(1) coding: mainly Python and full-stack web development\n(2) machine learning and artificial intelligence```","user_instructions":"The user provided the additional info about how they would like you to respond:\n```Be precise and comprehensive in your analysis. Tell it like it is; don't sugar-coat responses. Take a forward-thinking view.```"},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"is_visually_hidden_from_conversation":true,"user_context_message_data":{"about_user_message":"Mathematics Researcher About Myself: I have mathematical knowledge up to the post-graduate level.\n\nThese are my current research areas or areas of study:\n(1) coding: mainly Python and full-stack web development\n(2) machine learning and artificial intelligence","about_model_message":"Be precise and comprehensive in your analysis. Tell it like it is; don't sugar-coat responses. Take a forward-thinking view."},"is_user_system_message":true},"recipient":"all","channel":null},"parent":"c2931367-479b-431a-9783-e720b2c84906","children":["54afc2d4-bfaa-426b-b34d-3b2096d401d2"]},"54afc2d4-bfaa-426b-b34d-3b2096d401d2":{"id":"54afc2d4-bfaa-426b-b34d-3b2096d401d2","message":{"id":"54afc2d4-bfaa-426b-b34d-3b2096d401d2","author":{"role":"user","name":null,"metadata":{}},"create_time":1741919027.993,"update_time":null,"content":{"content_type":"text","parts":["Please analyze and give your comments on the attached document published by OpenAI"]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"attachments":[{"id":"file-Kd7m1wytPgwgg7PG4DRMhk","size":1129861,"name":"openai-us-economicblueprint-feb-2025-edu-update.pdf","mime_type":"application/pdf","file_token_size":5968}],"serialization_metadata":{"custom_symbol_offsets":[]},"dictation":false,"request_id":"92004fa4de08835c-ATL","message_source":null,"timestamp_":"absolute","message_type":null},"recipient":"all","channel":null},"parent":"de8885e6-1d47-4f8d-929f-3ed157600e18","children":["de812106-77f5-4444-8ec1-e86533b6f30b"]},"de812106-77f5-4444-8ec1-e86533b6f30b":{"id":"de812106-77f5-4444-8ec1-e86533b6f30b","message":{"id":"de812106-77f5-4444-8ec1-e86533b6f30b","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1741919040.612013,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"message_type":null,"model_slug":"gpt-4-5","default_model_slug":"gpt-4-5","parent_id":"54afc2d4-bfaa-426b-b34d-3b2096d401d2","request_id":"92004fa4de08835c-ATL","timestamp_":"absolute"},"recipient":"all","channel":null},"parent":"54afc2d4-bfaa-426b-b34d-3b2096d401d2","children":["d38cda72-0a1b-424b-a8fe-5b689064e01c"]},"d38cda72-0a1b-424b-a8fe-5b689064e01c":{"id":"d38cda72-0a1b-424b-a8fe-5b689064e01c","message":{"id":"d38cda72-0a1b-424b-a8fe-5b689064e01c","author":{"role":"tool","name":"myfiles_browser","metadata":{}},"create_time":1741919040.612183,"update_time":null,"content":{"content_type":"tether_browsing_display","result":"","summary":"","assets":null,"tether_id":null},"status":"finished_successfully","end_turn":null,"weight":0.0,"metadata":{"command":"spinner","status":"running","message_type":null,"model_slug":"gpt-4-5","default_model_slug":"gpt-4-5","parent_id":"de812106-77f5-4444-8ec1-e86533b6f30b","request_id":"92004fa4de08835c-ATL","timestamp_":"absolute"},"recipient":"all","channel":null},"parent":"de812106-77f5-4444-8ec1-e86533b6f30b","children":["83276077-d1a1-4933-8786-a9f8097cf950"]},"83276077-d1a1-4933-8786-a9f8097cf950":{"id":"83276077-d1a1-4933-8786-a9f8097cf950","message":{"id":"83276077-d1a1-4933-8786-a9f8097cf950","author":{"role":"tool","name":"myfiles_browser","metadata":{}},"create_time":1741919040.612297,"update_time":null,"content":{"content_type":"tether_quote","url":"file-Kd7m1wytPgwgg7PG4DRMhk","domain":"openai-us-economicblueprint-feb-2025-edu-update.pdf","text":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOpenAI's US Economic Blueprint | Feb 2025 Edu Update\n\n\n \n\n \n \n\n \n \n \n \n \n \n \n \n \n \n \n \n\nAI in America   OpenAI's Economic Blueprint \nFebruary 2025 Update: Advancing AI Education \n\n \n\n\n\n \n\nForeword \n\n \n \n \nOpenAI\u02bcs mission is to ensure that artificial intelligence benefits everyone. To us, that means \nbuilding AI that helps people solve hard problems because by helping with the hard problems, \nAI can benefit the most people possible \u2013 through better healthcare and education, more \nscientific discoveries, better public policies and services, and improved productivity. We\u02bcre off \nto a strong start, creating freely available intelligence being used by more than 300 million \npeople around the world, including 3 million developers, to ideate, discover, and innovate \nbeyond what we\u02bcre currently capable of doing on our own. Already, our tools are being used to: \n \n\n \n\n \n\nSpeed up \ndevelopment \nof life-saving \nmedical \ntreatments \n\n \n\nAccelerate \nscientific \nresearch by \nUS National \nLaboratories \n\n \n\nHelp \nteachers \ncreate \npersonalized \nlesson plans, \nspend more \ntime with \nstudents, \nand safely \nadopt AI in \nthe \nclassroom  \n\n \n\nProtect US \nmilitary \npersonnel \nagainst \nunmanned \ndrone \nattacks   \n\n \n\nUnlock new \nforms of \ncreativity for \nartists and \nincrease \naccessibility \nof artistic \nproduction \n\n \n\nMake state \nand local \ngovernments \nmore \nefficient  \n\n \n \nWe believe America needs to act now to maximize AI\u02bcs possibilities while minimizing its harms. \nAI is too powerful a technology to be led and shaped by autocrats, but that is the growing risk \nwe face, while the economic opportunity AI presents is too compelling to forfeit. Shared \nprosperity is as near and measurable as the new jobs and growth to come from building the \nneeded infrastructure. Soon, as our CEO Sam Altman has written, AI will help our children do \nthings we can\u02bct. Not far off is a future in which everyone\u02bcs lives can be better than anyone\u02bcs life \nis now.  \n \nWith such prosperity in sight, we want to work with policymakers to ensure that AI\u02bcs benefits \nare shared responsibly and equitably. The enclosed framework champions the \nentrepreneurship and individual freedoms at the heart of the American innovation ecosystem. \n\n2 \n \n\nhttps://openai.com/index/moderna/\nhttps://openai.com/index/moderna/\nhttps://www.osti.gov/servlets/purl/2479365\nhttps://www.osti.gov/servlets/purl/2479365\nhttps://www.osti.gov/servlets/purl/2479365\nhttps://sharemylesson.com/webinars/aftopenai-professional-learning-series\nhttps://sharemylesson.com/webinars/aftopenai-professional-learning-series\nhttps://www.youtube.com/watch?v=Ia3CPhVkUtg\nhttps://www.youtube.com/watch?v=Ia3CPhVkUtg\nhttps://www.anduril.com/article/anduril-partners-with-openai-to-advance-u-s-artificial-intelligence-leadership-and-protect-u-s/\nhttps://www.anduril.com/article/anduril-partners-with-openai-to-advance-u-s-artificial-intelligence-leadership-and-protect-u-s/\nhttps://www.anduril.com/article/anduril-partners-with-openai-to-advance-u-s-artificial-intelligence-leadership-and-protect-u-s/\nhttps://www.anduril.com/article/anduril-partners-with-openai-to-advance-u-s-artificial-intelligence-leadership-and-protect-u-s/\nhttps://openai.com/sora/\nhttps://openai.com/sora/\nhttps://openai.com/sora/\nhttps://tribecafilm.com/press-center/festival/press-releases/tribeca-festival-and-open-ai-announce-sora-shorts\nhttps://tribecafilm.com/press-center/festival/press-releases/tribeca-festival-and-open-ai-announce-sora-shorts\nhttps://www.pa.gov/agencies/oa/newsroom/agreement-innovateus-to-train-responsible-generative-artificial-.html\nhttps://www.pa.gov/agencies/oa/newsroom/agreement-innovateus-to-train-responsible-generative-artificial-.html\nhttps://cdn.openai.com/global-affairs/openai-infra-economics-10.09.24.pdf\nhttps://ia.samaltman.com/\n\n\n \n\nIf done right, the developers who are AI\u02bcs Main Street will thrive along with companies of all \nsizes, and the broad economic benefits of the technology will catalyze a reindustrialization \nacross the country. \n \nAmerica has faced such moments before, and we know how to think big, build big and act big. \n \nAutomobiles weren\u02bct invented here\u2014they were invented in Europe. Early proponents \nenvisioned the car transforming how people lived and worked. Supply chains and customer \nbases could be expanded and diversified. \n \nBut in the United Kingdom, where some of the earliest cars were introduced, the new industry\u02bcs \ngrowth was stunted by regulation. The 1865 Red Flag Act required a flag bearer to walk ahead \nof any car to warn others on the road and wave the car aside in favor of horse-drawn \ntransport. How could a person walk in front of a car without getting run over? Because of \nanother requirement: that cars move no faster than 4 miles per hour. \n \nAmerica, meanwhile, took a very different approach to the car, merging private-sector vision \nand innovation with public-sector enlightenment to unlock the new technology and its \neconomic\u2014and ultimately, with World War I looming\u2014national security benefits.  \n \nThe country became the heart of the world\u02bcs auto industry, mass-producing affordable cars \nwith the help of local, state and federal officials who saw the industry\u02bcs potential. Public safety \nconcerns over horse-drawn vehicles on crowded city streets prompted local officials to \nsupport the switch to cars\u2014not make cars yield to horses. The country\u02bcs size prompted states \nto invest in better roads. And the federal government cleared the way to scale transport by car \nwith a national\u2014rather than state-by-state\u2014highway system.  \n \nToday, while some countries sideline AI and its economic potential, the US government can \npave the road for its AI industry to: \n\n \n \n \n \n\nContinue the country\u02bcs  \nglobal leadership  \n\nin innovation while \n protecting national  \n\nsecurity \n\n Make sure we \nget it right \n\non AI access \nand benefits \nfrom the start \n\n Maximize the  \neconomic opportunity  \nof AI for communities \n\nacross the country \n\n \n \n \n \n\n3 \n \n\n\n\n \n\nAnd just as drivers are expected to stick to clear, common-sense standards that help keep the \nactual roads safe, developers and users have a responsibility to follow clear, common-sense \nstandards that keep the AI roads safe. Straightforward, predictable rules that safeguard the \npublic while helping innovators thrive can encourage investment, competition, and greater \nfreedom for everyone. \n \nFor our part, OpenAI is committed to working with US policymakers on how AI can best serve \nboth the national interest and the public good, stewarding our own technology along those \nlines, and globally championing AI that is built on a foundation of the democratic values the US \nhas always stood for.  \n \nWe believe in America because America believes in innovation. This is why our CEO will be \nkicking off this work with a gathering in Washington, DC on January 30 to preview the state of \nAI advancement and how it can drive economic growth. And this is why that event will kick off \nour Innovating for America initiative to engage states across the country to help ensure that \nwe\u02bcre bringing AI\u02bcs economic benefits to Americans from all walks of life.  \n \nThis country always succeeds when it bets on its ecosystem of builders and entrepreneurs. \nThis Blueprint, a living document we\u02bcll update as we learn from our work to help solve people\u02bcs \nhard problems, lays out a relationship we believe we can build on with government here at \nhome and as a place to begin with allies around the world.  \n \n \nChris Lehane \nVice President, Global Affairs \n \n\n \n\n4 \n \n\n\n\n \n\nWhere We Stand \n\n \n \n \nThe enclosed policy proposals reflect OpenAI\u02bcs position that: \n \n\n\u25cf We believe in America because America believes in innovation.  \n \n\n\u25cf Chips, data, energy and talent are the keys to winning on AI\u2014and this is a race \nAmerica can and must win.  \n \n\n\u25cf With an estimated $175 billion sitting in global funds awaiting investment in AI projects, \nif the US doesn\u02bct attract those funds, they will flow to China-backed \nprojects\u2014strengthening the Chinese Communist Party\u02bcs global influence. \n \n\n\u25cf Rules and regulations for the development and use of AI should be based on the \ndemocratic values the country has always stood for\u2014what we think of as \u201cdemocratic \nAI.\u02ee  \n \n\n\u25cf As for any industry, we need common-sense rules of the road that safeguard the \npublic while helping innovators thrive by encouraging investment, competition, and \ngreater freedom for everyone\u2014and to best achieve this, these rules should apply \nnationwide.  \n\n \n\n5 \n \n\n\n\n \n\n \n\nCompetitiveness and Security \n\n \n \n \nWe believe that making sure AI benefits the most people possible means enabling AI through \ncommon-sense rules aimed at protecting people from actual harms, and building democratic AI \nshaped by the values the US has always stood for, including:  \n \n\n\u25cf A free market promoting free and fair competition that drives innovation \n \n\n\u25cf Freedom for developers and users to work with and direct our tools as they see fit, in \nexchange for following clear, common-sense standards that help keep AI safe for \neveryone, and being held accountable when they don\u02bct \n \n\n\u25cf Preventing government use of AI tools to amass power and control their citizens, or to \nthreaten or coerce other states \n\n \nTo us, this means that in the same way the federal government helped clear the way for the \nnascent automobile industry to grow, including by preempting a state-by-state tangle of roads \nand rules, it should clear the way for the AI industry\u02bcs development of frontier models to best \nensure that they promote US economic and national security. \n \nTo be clear, by \u201cfrontier models,\u02ee  we are referring to the most state-of-the-art large language \nmodels that lead on capability benchmarks. Responsibly exporting these models to our allies \nand partners will help them stand up their own AI ecosystems, including their own developer \ncommunities innovating with AI and distributing its benefits, while also building AI on US \ntechnology, not technology funded by the Chinese Communist Party \ue081CCP\ue082.  \n \n \n \n \n\n \n\n6 \n \n\n\n\n \n\nThe US strategy for frontier model security should prioritize national competitiveness, model \nsafeguards and national security. Led by the federal government in consultation with industry, \nthis strategy should:  \n \n\n \n\n \n\nDevelop best practices for \ndeployment to better protect \nagainst the risks of criminal, \nterrorist, and state-sponsored \nmisuse and industrial \nespionage; and streamline \nindustry engagement with \nnational security departments \nand agencies  \n\n \n\nDevelop export policies that \nlet the industry securely \nshare frontier models with US \nallies and partner nations to \nstrengthen their economies \nand especially their \ndeveloper communities, and \npreserve a vibrant and \ninnovative open-source \ncommunity. At the same time, \nlimit the export of frontier \nmodels to adversary nations \nthat may be more likely to \nmisuse the technology or \nco-opt the IP \n\n \n\nDevelop alternatives to the \ngrowing patchwork of state \nand international regulations \nthat risk hindering American \ncompetitiveness, such as by \nhaving the federal \ngovernment leading the \ndevelopment of national \nsecurity evaluations at home, \nand establishing a US-led \ninternational coalition that \nworks toward shared safety \nstandards abroad \n\n \n \nAt OpenAI, we\u02bcve already taken steps toward such a strategy, including by developing our own \nsector-leading Preparedness Framework; having red team experts pressure-test our frontier \nmodels for national security risks (for example, by evaluating a model\u02bcs capability to create \nnovel cyber threats); using tailored safeguards to mitigate risks; stewarding adoption of our \nmodels by US-allied and partner countries; partnering with leading names in defense such as \nLos Alamos National Laboratory, the Air Force Research Laboratory, and Anduril; and being \ntransparent with the public about our safeguards and deployment practices.  \n\n \n \n \n \n \n \n \n \n \n \n\n7 \n \n\n\n\n \n\n \nSolutions: \nThe US always succeeds when it bets on its ecosystem of innovators and entrepreneurs. To \nhelp US AI companies develop and deploy frontier models securely and with the needed \nsafeguards, the federal government should:  \n \nAs appropriate, share national security-related information and resources that it alone \nmaintains\u2014such as briefings on security threats to the industry and high-level results of \ntesting US and non-US AI models\u2014with US AI companies pursuing advanced research.  \n \nThen, incentivize AI companies to deploy their products widely, including to allied and partner \nnations and to support US government agencies. \n \nThe federal government\u02bcs approach to frontier model safety and security should streamline \nrequirements, reduce bureaucratic obstacles to government-industry collaboration, and \nincentivize companies to support US competitiveness. For instance, the government could: \n\n \nSupport the development of standards and safeguards, ensure that such standards are \nrecognized and respected by other nations and international bodies on behalf of the US \nprivate sector, and support direct work with US government agencies and offices. \n \nShare its unique expertise with AI companies, including information about how to secure their \nIP against industrial security threats and mitigate potential cyber, chemical, biological, \nradiological and nuclear \ue081CBRN\ue082 and other risks that are heightened by increasingly powerful \nmodels. \n \nHelp companies access secure infrastructure, such as classified computing clusters, to \nevaluate model security risks and safeguards. \n \nPromote transparency consistent with competitiveness by the US and like-minded nations \nthrough protecting trade secrets, promoting market competition, and ensuring broad and \naffordable AI access by carefully choosing disclosure requirements across the AI life cycle. \n \nStreamline its support for the industry by creating a defined, voluntary pathway for companies \nthat develop large language models to work with government to define model evaluations, test \nmodels, and exchange information to support the companies\u02bc safeguards. The US government \ncan uniquely mobilize and coordinate experts, especially those with access to classified threat \nintelligence, to work directly with frontier labs on national security-related evaluations and \nmitigations. In return, these companies would receive preemption from state-by-state \nregulations on the types of risks that the same national security agencies would handle.  \n \n\n8 \n \n\n\n\n \n\nEmpower the public sector to quickly and securely adopt AI tools to ensure pathways to \nadoption for start-ups and smaller firms, save taxpayers money, improve the efficiency of \noperations, and deliver better public services.  \n \nAnd to further coordinate and collaborate with the federal government, AI builders could:  \n \nForm a consortium that identifies best practices for working with the national security \ncommunity, including to prioritize security-based requests of the government (such as access \nto compute) and to streamline efforts to responsibly integrate AI in ways consistent with US \nand company policies. As AI systems become increasingly more capable, deeper partnership \nbetween government and industry will both improve the security of those systems and \nenhance the US government\u02bcs access to cutting-edge talent and capabilities.    \n \nHelp develop training programs to cultivate the next generation of AI talent in the US, \nespecially in areas of the country that have not benefited from previous waves of innovation, \nto establish pools of skilled talent for both the public and private sectors. \n\n \n\n9 \n \n\n\n\n \n\n \n\nRules of the Road \n\n \n \n \nWe believe that the more US-led development of AI becomes, the more widely it will be \ndeployed, the more trusted it will become, and the more people will benefit\u2014in turn creating a \nflywheel of growing prosperity and appreciation for democratic values like the freedom to \nresponsibly direct and work with AI tools, and a free market, with the appropriate safeguards, in \nwhich all manner of AI companies and entrepreneurs can compete. \n \nTo us, this means getting AI access and benefits right from the start\u2014what we think of as \ngetting the rules of the road right so the benefits can be fully realized. AI is not social \nmedia\u2014it\u02bcs an infrastructure technology that is leading us into what our CEO Sam Altman has \ncalled the Intelligence Age. With AI, our children will be able to do things we can\u02bct, and \neventually everyone\u02bcs lives can be better than anyone\u02bcs life is now. But we have work to do to \nget there. Government and the AI industry need to learn from the past and lay the proper rules \nso that when accessing AI tools and products, users can feel confident that:  \n \n\n \n\n \n\nTheir children will be \nprotected from potential \nharms \n\n \n\nThey will know where \ncontent comes from \n\n \n\nThey will be able to \npersonalize the AI tools  \nthey use \n\n \nWhile the federal government should lead on AI-related matters of national security, the states \nhave a vital role to play when it comes to maximizing AI\u02bcs benefits from the start. They can fill \ntheir historical role as laboratories for democracy by supporting experimentation with AI, \nincluding by start-ups and smaller AI firms, to identify ways to solve people\u02bcs daily hard \nproblems in areas like education and healthcare. They can support their government workers \nand developer communities experimenting with AI to identify ways to improve the lives of their \n\n10 \n \n\nhttps://ia.samaltman.com/\n\n\n \n\ntaxpayers. At the same time, this work would boost states\u02bc own local AI \necosystems\u2014especially new generations of AI-enabled developers who are the next Main \nStreet\u2014and competitiveness. \n \nAnd for the users of AI, from developers to the private sector and the public, access comes \nwith responsibility for following the rules so that everyone can proceed with certainty on the AI \nroads. The industry is building and deploying AI, but developers and users are the ones behind \nthe wheel.  \n \n\n \nSolutions: \nWe know that for AI to benefit everyone, even as we\u02bcre building AI to help people solve hard \nproblems, we have to build understanding of the technology and confidence in the safeguards \naround how it intersects with their daily lives.  \n \nOn child safety, AI companies and developers should:  \n \n\n\u25cf Encourage policy solutions that prevent the creation and distribution of AI-generated \nchild sexual abuse material/child sexual exploitation material \ue081CSAM/CSEM\ue082 \n \n\n\u25cf Incorporate CSAM/CSEM protections throughout the AI development life cycle \n \n\n\u25cf Take steps to prevent downstream developers from using their models to generate \nCSAM/CSEM \n \n\n\u25cf Promote conditions that support robust and lasting partnerships among AI companies \nand law enforcement \n\n \nOn knowing where content comes from, which is important for building trust and empowering \nusers, those building with AI, from large companies to start-ups to developers and \nentrepreneurs, should:  \n \n\n\u25cf Apply provenance data to all AI-generated audio-visual content \n \n\n\u25cf Use common provenance standards such as those developed by the Coalition for \nContent Provenance and Authenticity \ue081C2PA\ue082 \n \n\n\u25cf For large companies, given their broader reach, develop and report publicly on \nprogress toward more advanced provenance methods \n\n \n \n \n \n\n11 \n \n\n\n\n \n\n \n \nOn preferences: \n \n\n\u25cf People should be empowered to personalize their AI tools, including through controls \non how their personal data is used \n \n\n\u25cf Government and industry should work together to scale AI literacy through robust \nfunding for pilot programs, school district technology budgets and professional \ndevelopment trainings that help people understand how to choose their own \npreferences to personalize their tools \n \n\n\u25cf In exchange for having so much freedom, users should be responsible for impacts of \nhow they work and create with AI. Common-sense rules for AI that are aimed at \nprotecting from actual harms can only provide that protection if they apply to those \nusing the technology as well as those building it \n\n \nAt OpenAI, we\u02bcve already taken steps to adopt emerging rules of the road, including by \nestablishing robust child safety measures, and engaging with the National Center for Missing \nand Exploited Children, law enforcement, and other government stakeholders on child \nprotection issues and enhancements to reporting mechanisms. We\u02bcre also developing and \ndeploying ways to help users know where AI-generated audio or visual content comes from, \nincluding robust provenance methods, and we provide tools that help people personalize their \nChatGPT experience within broad, reasonable limits, and control how their data is used. \n \n\n \n\n12 \n \n\nhttps://openai.com/index/child-safety-adopting-sbd-principles/\nhttps://help.openai.com/en/articles/8096356-custom-instructions-for-chatgpt\nhttps://help.openai.com/en/articles/7730893-data-controls-faq\nhttps://openai.com/index/new-ways-to-manage-your-data-in-chatgpt/\n\n\n \n\n \n\nInfrastructure as Destiny \n \n \n \nWe believe that building enough infrastructure is not just vital for ensuring that AI around the \nworld is based on US rather than China-based technology\u2014it\u02bcs an unmissable opportunity to \ncatalyze a reindustrialization of the US. Successful nations turn resources into competitive \nadvantages. In the AI era, chips, data, energy and talent are the resources that will underpin \ncontinued US leadership, and as with the mass production of the automobile, marshalling these \nresources will create widespread economic opportunity and reinforce our global \ncompetitiveness. \n \nTo us, this means seizing the moment and building the infrastructure needed to produce \nenough energy and chips to drive down the cost of compute and make it abundant. In turn, this \nwill create tens of thousands of skilled-trade jobs, boost local economies through spending \nand indirect job creation, and modernize our energy grid in the near term\u2014 ultimately \nsupporting the kind of breakthroughs and innovations that drive lasting economic growth.  \n \nIt also means assuring AI developers that AI models will have the ability to learn from publicly \navailable information, and making more such information available through competition policy \nand public sector investment.  \n \nToday, demand for compute and energy far outstrips the available supply, while an estimated \n$175 billion in global funds is waiting to be invested in AI infrastructure. If the US doesn't move \nfast to channel these resources into projects that support democratic AI ecosystems around \nthe world, the funds will flow to projects backed and shaped by the CCP. \n \nLikewise, other actors, including developers in other countries, make no effort to respect or \nengage with the owners of IP rights. If the US and like-minded nations don\u02bct address this \nimbalance through sensible measures that help advance AI for the long-term, the same content \nwill still be used for AI training elsewhere, but for the benefit of other economies.  \n \n \n \n\n13 \n \n\nhttps://cdn.openai.com/global-affairs/openai-infra-economics-10.09.24.pdf\n\n\n \n\n \nSolutions: \nWe need a foundational strategy to ensure that investment in infrastructure benefits the most \npeople possible and maximizes access to AI. This includes policies and initiatives that \nencourage rather than stifle developers; support a thriving AI-ready workforce and ecosystems \nof labs, start-ups and larger companies; and secure America\u02bcs leadership on AI into the future, \nsuch as:  \n \nEnsuring that AI has the ability to learn from universal, publicly available information, just like \nhumans do, while also protecting creators from unauthorized digital replicas.  \n \nDigitizing government data currently in analog form. A lot of government data is in the public \ndomain. Making it more accessible or machine-readable could help US AI developers of all \nsizes, especially those working in fields where vital data is disproportionately \ngovernment-held. In exchange, developers using this data could work with government to \nunlock new insights that help it develop better public policies.  \n \nA Compact for AI among US allies and partner nations that streamlines access to capital and \nsupply chains in ways that support AI infrastructure and a robust AI ecosystem. Participating \ncountries would also agree to some common security standards. Over time, this collaboration \ncould expand to a global network of US allies and partners that would compete with the \nPeople\u02bcs Republic of China\u02bcs AI infrastructure alliances while also strengthening security \nthrough shared standards. \n \nAI Economic Zones, created by local, state and the federal government together with industry, \nthat significantly speed up the permitting processes for building AI infrastructure like new solar \narrays, wind farms and nuclear reactors.  \n \nCreation of AI research labs and workforces aligned with key local industries by requiring AI \ncompanies to provide meaningful amounts of compute to public universities to equitably scale \nthe training of a homegrown AI-skilled workforce. For example, Kansas could establish a hub \ndedicated to applying AI in agriculture; Texas or Pennsylvania could develop centers focused \non integrating AI into power production and grid resilience.  \n \nA nationwide AI education strategy\u2014rooted in local communities in partnership with American \ncompanies\u2014to help our current workforce and students become AI-ready, bolster the \neconomy, and secure America\u02bcs continued leadership on innovation. Maintaining US leadership \nin AI means ensuring we have an experienced, trained professional workforce working across \nthe AI supply chain, including construction worker management, HVAC technicians and \nelectricians. Government should ensure this training is accessible and affordable, such as by: \n \n \n\n14 \n \n\n\n\n \n\n\u25cf At the federal level, expand 529 savings plans to cover more AI supply chain-related \ntraining programs \u2013 including for construction, HVAC technicians, electricians, as well as \nAI researchers and developers \u2013 by amending Section 529 of the Internal Revenue Code \nor broadening the SECURE Act\u02bcs provisions.  \n \n\n\u25cf At the federal or state level, incentivize AI supply chain companies to work with a \nbackbone organization to understand the workforce needs of AI supply chain \ncompanies, develop a pipeline of training programs that help companies meet those \nneeds, and coordinate with labor unions, community colleges, and trade associations \nto build and operate that training pipeline. \n \n\n\u25cf At the state and local level, streamlining school procurement of AI tools and resources \nto make it faster and easier to incorporate AI into curricula and increase AI literacy for \nboth students and teachers. \n\n \nInvestment in national research infrastructure that would give scientists, innovators, and \neducators access to the compute and data necessary to accelerate and democratize scientific \nprogress, such as through funding a National AI Research Resource. \n \nLeading on the next generation of energy technology, including sustainable sources such as \nfission, fusion, and other promising technologies to support our existing energy capacity. A \nsufficient energy supply is critical to sustaining American leadership on AI. \n \nDramatically increased federal spending on power and data transmission and streamlined \napproval for new lines. That would be accompanied by the creation of a National AI \nInfrastructure Highway to connect those regional power and communication grids in the \ninterest of national economic competitiveness and security. \n \nFederal backstops for high-value AI public works that illustrate the model of federal spending \nin support of industry growth and both industry and users adhering to its rules. Since private \nmarkets alone may not be enough to pay for the massive amount of needed AI infrastructure, \nthe US government can provide offtake purchase commitments and credit enhancements to \nencourage infrastructure investment. The resulting infrastructure, such as the new energy \nsources needed to power AI data centers, would be considered strategic national assets.  \n\n \n \n\n \n\nOpenAI\u02bcs Economic Blueprint is a living document which we\u02bcll update as \nwe learn from our work with the US government to be thoughtful \nstewards of our technology and ensure that our tools help people solve \nhard problems to benefit the most people possible. \n\n \n \n\n15 \n \n\n\n\n \n\n \n \n\n \n \n\n \n\n \n\n \n\n \n\n \n\n \nCover image created with DALL.E \n\n \n \n\n16 \n \n\n\n\tForeword \n\tWhere We Stand \n\tCompetitiveness and Security \n\tRules of the Road \n\tInfrastructure as Destiny \n\n","title":"openai-us-economicblueprint-feb-2025-edu-update.pdf","tether_id":null},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"command":"context_stuff","is_visually_hidden_from_conversation":false,"message_type":null,"model_slug":"gpt-4-5","default_model_slug":"gpt-4-5","parent_id":"d38cda72-0a1b-424b-a8fe-5b689064e01c","request_id":"92004fa4de08835c-ATL","timestamp_":"absolute"},"recipient":"all","channel":null},"parent":"d38cda72-0a1b-424b-a8fe-5b689064e01c","children":["3fc66d74-1d44-4d68-b047-e9344eb64772"]},"3fc66d74-1d44-4d68-b047-e9344eb64772":{"id":"3fc66d74-1d44-4d68-b047-e9344eb64772","message":{"id":"3fc66d74-1d44-4d68-b047-e9344eb64772","author":{"role":"tool","name":"myfiles_browser","metadata":{}},"create_time":1741919040.612398,"update_time":null,"content":{"content_type":"text","parts":["All the files uploaded by the user have been fully loaded. Searching won't provide additional information."]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"is_visually_hidden_from_conversation":false,"message_type":null,"model_slug":"gpt-4-5","default_model_slug":"gpt-4-5","parent_id":"83276077-d1a1-4933-8786-a9f8097cf950","request_id":"92004fa4de08835c-ATL","timestamp_":"absolute"},"recipient":"all","channel":null},"parent":"83276077-d1a1-4933-8786-a9f8097cf950","children":["f20ca478-0ed5-4bf9-8670-fc08bbdd4389"]},"f20ca478-0ed5-4bf9-8670-fc08bbdd4389":{"id":"f20ca478-0ed5-4bf9-8670-fc08bbdd4389","message":{"id":"f20ca478-0ed5-4bf9-8670-fc08bbdd4389","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1741919028.794795,"update_time":null,"content":{"content_type":"text","parts":["Here's a precise and comprehensive analysis of OpenAI's **\"US Economic Blueprint | February 2025 Education Update\"**.\n\n---\n\n### Overview of the Document\nOpenAI's document outlines their vision for leveraging artificial intelligence to enhance education, economic growth, national security, and global competitiveness for the United States. It emphasizes the strategic integration of AI across various sectors and advocates for governmental involvement to promote responsible and equitable AI deployment.\n\n### Key Themes and Comments\n\n#### 1. Mission Alignment and Vision Clarity\nThe document clearly aligns with OpenAI's stated mission: **\"ensuring that artificial intelligence benefits everyone.\"** It demonstrates coherence with the broader goal of utilizing AI to solve complex societal challenges, including education, healthcare, scientific research, public policy, and military protection.\n\n**Analysis:**  \n- The commitment to broad public benefit and democratic values is commendable, reflecting strategic foresight about the necessity of coupling technological innovation with social responsibility.\n- Emphasis on education as a priority reflects awareness of the transformative potential AI holds for social mobility and economic growth.\n\n---\n\n### Strategic Elements\n\n#### 1. AI and US Competitiveness\nThe document positions AI as critical for maintaining global leadership, highlighting potential threats from autocratic control (notably China-backed AI initiatives). It strongly advocates a clear, coordinated federal approach to AI deployment, avoiding fragmented state-by-state regulations.\n\n**Analysis:**\n- This stance is pragmatic given the risks of regulatory fragmentation. The analogy with the early automotive industry effectively underscores the critical need for unified, supportive regulation that encourages innovation.\n- The document implicitly acknowledges the geopolitical dimensions of AI, explicitly mentioning China as an adversarial competitor, aiming to rally bipartisan political support around maintaining U.S. leadership in AI.\n\n### Key Recommendations:\n1. **Frontier Model Security**:\n   - Advocates stringent safety measures for frontier models to guard against misuse.\n   - Encourages collaboration between AI companies and national security agencies.\n   - Supports responsible international cooperation, with measured export controls for state-of-the-art models.\n\n**Analysis:**\n- This is a responsible and forward-thinking approach that balances innovation and security. The proposal to limit technology transfer to adversarial nations while promoting exports to allied nations is geopolitically astute.\n\n---\n\n###  Strategic Focus Areas Identified by OpenAI\n\n#### 1. Infrastructure Development  \n- Advocates for significant investment in AI-related infrastructure (energy, chips, computing resources).\n- Highlights the need to expand energy infrastructure (solar, wind, nuclear, fusion, fission) to sustain AI development.\n- Supports creating a \"National AI Research Resource\" to democratize access to compute and data.\n\n**Analysis:**\n- Recognition of infrastructure as a foundational component of AI-driven economic competitiveness is insightful.\n- The recommended federal backstops and infrastructure spending could effectively drive national competitiveness.\n\n#### 2. Education and Workforce Training\n- Emphasizes equitable, accessible AI training for a broad spectrum of job roles, not just high-level technical talent.\n- Proposes governmental incentives for AI companies to engage with educational institutions to foster an AI-skilled workforce.\n\n**Analysis:**\n- The emphasis on training across the AI ecosystem, from electricians to software developers, underscores a comprehensive and inclusive vision that could drive long-term economic and social stability.\n- Highlighting traditionally underserved regions can democratize the benefits of AI, reducing regional inequality.\n\n#### 3. Common-Sense Regulation\n- Calls for nationwide, predictable regulations that balance innovation with safety.\n- Advocates transparency, proven safeguards against misuse, and standards for the responsible use of AI-generated content, including provenance tracking and protection against child exploitation.\n\n**Analysis:**\n- OpenAI\u2019s commitment to transparency and regulation of AI-generated content through standardized provenance data (e.g., C2PA) is highly positive, especially given current public concerns around misinformation and digital authenticity.\n\n---\n\n### Potential Concerns and Critiques:\n- **Implementation Risks:** Despite clarity on high-level vision, the document lacks explicit implementation details and timelines, which could result in ambiguity or delays in actionable policy outcomes.\n- **Market Concentration:** Encouragement of a centralized federal regulatory framework, though efficient, could inadvertently favor large corporations with established infrastructure and resources, risking potential monopolization.\n- **Security vs. Openness:** The tension between secure model deployment and the preservation of an open-source community is noted but not deeply explored. More explicit policy guidance on protecting open-source innovation from overly restrictive export controls would be beneficial.\n\n---\n\n### Recommendations for Improvement:\n\n1. **Clarify Implementation Strategies:**  \n   - Include more detailed action plans, metrics, and clear milestones to operationalize proposed policies.\n\n2. **Balancing Regulation with Innovation:**  \n- Address more clearly how smaller firms and start-ups will be supported within the regulatory framework to prevent excessive market centralization and foster genuine innovation competition.\n\n3. **Data and Privacy Protection:**  \n- Explicitly integrate privacy protection and ethical considerations about data usage into policy frameworks to reassure users and regulators amid growing privacy concerns.\n\n4. **Global Coordination:**  \n- Provide more explicit recommendations for international collaboration, beyond export controls, especially concerning harmonizing global AI standards and practices among allies to counteract international regulatory fragmentation effectively.\n\n---\n\n### Conclusion\nOverall, OpenAI's \"Economic Blueprint\" presents a comprehensive, clear-eyed strategy focused on harnessing AI's potential responsibly, aiming for widespread economic and social benefits. Its core strengths lie in its clarity of vision, commitment to democratic values, and practical analogies to past US technological leadership.\n\nHowever, effectiveness will hinge on precise policy execution, balancing centralized regulation with healthy market competition, and protecting against unintended economic and social risks. OpenAI's recommendations, if implemented carefully, could indeed position the US advantageously in the global AI landscape while minimizing potential harms associated with the technology.\n\n---  \n*Reference: OpenAI US Economic Blueprint, February 2025 Education Update\u30106\u2020source\u3011.*"]},"status":"finished_successfully","end_turn":true,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200002]},"is_complete":true,"citations":[{"start_ix":6982,"end_ix":6992,"citation_format_type":"tether_og","metadata":{"type":"file","name":"openai-us-economicblueprint-feb-2025-edu-update.pdf","id":"file-Kd7m1wytPgwgg7PG4DRMhk","source":"my_files","text":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOpenAI's US Economic Blueprint | Feb 2025 Edu Update\n\n\n \n\n \n \n\n \n \n \n \n \n \n \n \n \n \n \n \n\nAI in America   OpenAI's Economic Blueprint \nFebruary 2025 Update: Advancing AI Education \n\n \n\n\n\n \n\nForeword \n\n \n \n \nOpenAI\u02bcs mission is to ensure that artificial intelligence benefits everyone. To us, that means \nbuilding AI that helps people solve hard problems because by helping with the hard problems, \nAI can benefit the most people possible \u2013 through better healthcare and education, more \nscientific discoveries, better public policies and services, and improved productivity. We\u02bcre off \nto a strong start, creating freely available intelligence being used by more than 300 million \npeople around the world, including 3 million developers, to ideate, discover, and innovate \nbeyond what we\u02bcre currently capable of doing on our own. Already, our tools are being used to: \n \n\n \n\n \n\nSpeed up \ndevelopment \nof life-saving \nmedical \ntreatments \n\n \n\nAccelerate \nscientific \nresearch by \nUS National \nLaboratories \n\n \n\nHelp \nteachers \ncreate \npersonalized \nlesson plans, \nspend more \ntime with \nstudents, \nand safely \nadopt AI in \nthe \nclassroom  \n\n \n\nProtect US \nmilitary \npersonnel \nagainst \nunmanned \ndrone \nattacks   \n\n \n\nUnlock new \nforms of \ncreativity for \nartists and \nincrease \naccessibility \nof artistic \nproduction \n\n \n\nMake state \nand local \ngovernments \nmore \nefficient  \n\n \n \nWe believe America needs to act now to maximize AI\u02bcs possibilities while minimizing its harms. \nAI is too powerful a technology to be led and shaped by autocrats, but that is the growing risk \nwe face, while the economic opportunity AI presents is too compelling to forfeit. Shared \nprosperity is as near and measurable as the new jobs and growth to come from building the \nneeded infrastructure. Soon, as our CEO Sam Altman has written, AI will help our children do \nthings we can\u02bct. Not far off is a future in which everyone\u02bcs lives can be better than anyone\u02bcs life \nis now.  \n \nWith such prosperity in sight, we want to work with policymakers to ensure that AI\u02bcs benefits \nare shared responsibly and equitably. The enclosed framework champions the \nentrepreneurship and individual freedoms at the heart of the American innovation ecosystem. \n\n2 \n \n\nhttps://openai.com/index/moderna/\nhttps://openai.com/index/moderna/\nhttps://www.osti.gov/servlets/purl/2479365\nhttps://www.osti.gov/servlets/purl/2479365\nhttps://www.osti.gov/servlets/purl/2479365\nhttps://sharemylesson.com/webinars/aftopenai-professional-learning-series\nhttps://sharemylesson.com/webinars/aftopenai-professional-learning-series\nhttps://www.youtube.com/watch?v=Ia3CPhVkUtg\nhttps://www.youtube.com/watch?v=Ia3CPhVkUtg\nhttps://www.anduril.com/article/anduril-partners-with-openai-to-advance-u-s-artificial-intelligence-leadership-and-protect-u-s/\nhttps://www.anduril.com/article/anduril-partners-with-openai-to-advance-u-s-artificial-intelligence-leadership-and-protect-u-s/\nhttps://www.anduril.com/article/anduril-partners-with-openai-to-advance-u-s-artificial-intelligence-leadership-and-protect-u-s/\nhttps://www.anduril.com/article/anduril-partners-with-openai-to-advance-u-s-artificial-intelligence-leadership-and-protect-u-s/\nhttps://openai.com/sora/\nhttps://openai.com/sora/\nhttps://openai.com/sora/\nhttps://tribecafilm.com/press-center/festival/press-releases/tribeca-festival-and-open-ai-announce-sora-shorts\nhttps://tribecafilm.com/press-center/festival/press-releases/tribeca-festival-and-open-ai-announce-sora-shorts\nhttps://www.pa.gov/agencies/oa/newsroom/agreement-innovateus-to-train-responsible-generative-artificial-.html\nhttps://www.pa.gov/agencies/oa/newsroom/agreement-innovateus-to-train-responsible-generative-artificial-.html\nhttps://cdn.openai.com/global-affairs/openai-infra-economics-10.09.24.pdf\nhttps://ia.samaltman.com/\n\n\n \n\nIf done right, the developers who are AI\u02bcs Main Street will thrive along with companies of all \nsizes, and the broad economic benefits of the technology will catalyze a reindustrialization \nacross the country. \n \nAmerica has faced such moments before, and we know how to think big, build big and act big. \n \nAutomobiles weren\u02bct invented here\u2014they were invented in Europe. Early proponents \nenvisioned the car transforming how people lived and worked. Supply chains and customer \nbases could be expanded and diversified. \n \nBut in the United Kingdom, where some of the earliest cars were introduced, the new industry\u02bcs \ngrowth was stunted by regulation. The 1865 Red Flag Act required a flag bearer to walk ahead \nof any car to warn others on the road and wave the car aside in favor of horse-drawn \ntransport. How could a person walk in front of a car without getting run over? Because of \nanother requirement: that cars move no faster than 4 miles per hour. \n \nAmerica, meanwhile, took a very different approach to the car, merging private-sector vision \nand innovation with public-sector enlightenment to unlock the new technology and its \neconomic\u2014and ultimately, with World War I looming\u2014national security benefits.  \n \nThe country became the heart of the world\u02bcs auto industry, mass-producing affordable cars \nwith the help of local, state and federal officials who saw the industry\u02bcs potential. Public safety \nconcerns over horse-drawn vehicles on crowded city streets prompted local officials to \nsupport the switch to cars\u2014not make cars yield to horses. The country\u02bcs size prompted states \nto invest in better roads. And the federal government cleared the way to scale transport by car \nwith a national\u2014rather than state-by-state\u2014highway system.  \n \nToday, while some countries sideline AI and its economic potential, the US government can \npave the road for its AI industry to: \n\n \n \n \n \n\nContinue the country\u02bcs  \nglobal leadership  \n\nin innovation while \n protecting national  \n\nsecurity \n\n Make sure we \nget it right \n\non AI access \nand benefits \nfrom the start \n\n Maximize the  \neconomic opportunity  \nof AI for communities \n\nacross the country \n\n \n \n \n \n\n3 \n \n\n\n\n \n\nAnd just as drivers are expected to stick to clear, common-sense standards that help keep the \nactual roads safe, developers and users have a responsibility to follow clear, common-sense \nstandards that keep the AI roads safe. Straightforward, predictable rules that safeguard the \npublic while helping innovators thrive can encourage investment, competition, and greater \nfreedom for everyone. \n \nFor our part, OpenAI is committed to working with US policymakers on how AI can best serve \nboth the national interest and the public good, stewarding our own technology along those \nlines, and globally championing AI that is built on a foundation of the democratic values the US \nhas always stood for.  \n \nWe believe in America because America believes in innovation. This is why our CEO will be \nkicking off this work with a gathering in Washington, DC on January 30 to preview the state of \nAI advancement and how it can drive economic growth. And this is why that event will kick off \nour Innovating for America initiative to engage states across the country to help ensure that \nwe\u02bcre bringing AI\u02bcs economic benefits to Americans from all walks of life.  \n \nThis country always succeeds when it bets on its ecosystem of builders and entrepreneurs. \nThis Blueprint, a living document we\u02bcll update as we learn from our work to help solve people\u02bcs \nhard problems, lays out a relationship we believe we can build on with government here at \nhome and as a place to begin with allies around the world.  \n \n \nChris Lehane \nVice President, Global Affairs \n \n\n \n\n4 \n \n\n\n\n \n\nWhere We Stand \n\n \n \n \nThe enclosed policy proposals reflect OpenAI\u02bcs position that: \n \n\n\u25cf We believe in America because America believes in innovation.  \n \n\n\u25cf Chips, data, energy and talent are the keys to winning on AI\u2014and this is a race \nAmerica can and must win.  \n \n\n\u25cf With an estimated $175 billion sitting in global funds awaiting investment in AI projects, \nif the US doesn\u02bct attract those funds, they will flow to China-backed \nprojects\u2014strengthening the Chinese Communist Party\u02bcs global influence. \n \n\n\u25cf Rules and regulations for the development and use of AI should be based on the \ndemocratic values the country has always stood for\u2014what we think of as \u201cdemocratic \nAI.\u02ee  \n \n\n\u25cf As for any industry, we need common-sense rules of the road that safeguard the \npublic while helping innovators thrive by encouraging investment, competition, and \ngreater freedom for everyone\u2014and to best achieve this, these rules should apply \nnationwide.  \n\n \n\n5 \n \n\n\n\n \n\n \n\nCompetitiveness and Security \n\n \n \n \nWe believe that making sure AI benefits the most people possible means enabling AI through \ncommon-sense rules aimed at protecting people from actual harms, and building democratic AI \nshaped by the values the US has always stood for, including:  \n \n\n\u25cf A free market promoting free and fair competition that drives innovation \n \n\n\u25cf Freedom for developers and users to work with and direct our tools as they see fit, in \nexchange for following clear, common-sense standards that help keep AI safe for \neveryone, and being held accountable when they don\u02bct \n \n\n\u25cf Preventing government use of AI tools to amass power and control their citizens, or to \nthreaten or coerce other states \n\n \nTo us, this means that in the same way the federal government helped clear the way for the \nnascent automobile industry to grow, including by preempting a state-by-state tangle of roads \nand rules, it should clear the way for the AI industry\u02bcs development of frontier models to best \nensure that they promote US economic and national security. \n \nTo be clear, by \u201cfrontier models,\u02ee  we are referring to the most state-of-the-art large language \nmodels that lead on capability benchmarks. Responsibly exporting these models to our allies \nand partners will help them stand up their own AI ecosystems, including their own developer \ncommunities innovating with AI and distributing its benefits, while also building AI on US \ntechnology, not technology funded by the Chinese Communist Party \ue081CCP\ue082.  \n \n \n \n \n\n \n\n6 \n \n\n\n\n \n\nThe US strategy for frontier model security should prioritize national competitiveness, model \nsafeguards and national security. Led by the federal government in consultation with industry, \nthis strategy should:  \n \n\n \n\n \n\nDevelop best practices for \ndeployment to better protect \nagainst the risks of criminal, \nterrorist, and state-sponsored \nmisuse and industrial \nespionage; and streamline \nindustry engagement with \nnational security departments \nand agencies  \n\n \n\nDevelop export policies that \nlet the industry securely \nshare frontier models with US \nallies and partner nations to \nstrengthen their economies \nand especially their \ndeveloper communities, and \npreserve a vibrant and \ninnovative open-source \ncommunity. At the same time, \nlimit the export of frontier \nmodels to adversary nations \nthat may be more likely to \nmisuse the technology or \nco-opt the IP \n\n \n\nDevelop alternatives to the \ngrowing patchwork of state \nand international regulations \nthat risk hindering American \ncompetitiveness, such as by \nhaving the federal \ngovernment leading the \ndevelopment of national \nsecurity evaluations at home, \nand establishing a US-led \ninternational coalition that \nworks toward shared safety \nstandards abroad \n\n \n \nAt OpenAI, we\u02bcve already taken steps toward such a strategy, including by developing our own \nsector-leading Preparedness Framework; having red team experts pressure-test our frontier \nmodels for national security risks (for example, by evaluating a model\u02bcs capability to create \nnovel cyber threats); using tailored safeguards to mitigate risks; stewarding adoption of our \nmodels by US-allied and partner countries; partnering with leading names in defense such as \nLos Alamos National Laboratory, the Air Force Research Laboratory, and Anduril; and being \ntransparent with the public about our safeguards and deployment practices.  \n\n \n \n \n \n \n \n \n \n \n \n\n7 \n \n\n\n\n \n\n \nSolutions: \nThe US always succeeds when it bets on its ecosystem of innovators and entrepreneurs. To \nhelp US AI companies develop and deploy frontier models securely and with the needed \nsafeguards, the federal government should:  \n \nAs appropriate, share national security-related information and resources that it alone \nmaintains\u2014such as briefings on security threats to the industry and high-level results of \ntesting US and non-US AI models\u2014with US AI companies pursuing advanced research.  \n \nThen, incentivize AI companies to deploy their products widely, including to allied and partner \nnations and to support US government agencies. \n \nThe federal government\u02bcs approach to frontier model safety and security should streamline \nrequirements, reduce bureaucratic obstacles to government-industry collaboration, and \nincentivize companies to support US competitiveness. For instance, the government could: \n\n \nSupport the development of standards and safeguards, ensure that such standards are \nrecognized and respected by other nations and international bodies on behalf of the US \nprivate sector, and support direct work with US government agencies and offices. \n \nShare its unique expertise with AI companies, including information about how to secure their \nIP against industrial security threats and mitigate potential cyber, chemical, biological, \nradiological and nuclear \ue081CBRN\ue082 and other risks that are heightened by increasingly powerful \nmodels. \n \nHelp companies access secure infrastructure, such as classified computing clusters, to \nevaluate model security risks and safeguards. \n \nPromote transparency consistent with competitiveness by the US and like-minded nations \nthrough protecting trade secrets, promoting market competition, and ensuring broad and \naffordable AI access by carefully choosing disclosure requirements across the AI life cycle. \n \nStreamline its support for the industry by creating a defined, voluntary pathway for companies \nthat develop large language models to work with government to define model evaluations, test \nmodels, and exchange information to support the companies\u02bc safeguards. The US government \ncan uniquely mobilize and coordinate experts, especially those with access to classified threat \nintelligence, to work directly with frontier labs on national security-related evaluations and \nmitigations. In return, these companies would receive preemption from state-by-state \nregulations on the types of risks that the same national security agencies would handle.  \n \n\n8 \n \n\n\n\n \n\nEmpower the public sector to quickly and securely adopt AI tools to ensure pathways to \nadoption for start-ups and smaller firms, save taxpayers money, improve the efficiency of \noperations, and deliver better public services.  \n \nAnd to further coordinate and collaborate with the federal government, AI builders could:  \n \nForm a consortium that identifies best practices for working with the national security \ncommunity, including to prioritize security-based requests of the government (such as access \nto compute) and to streamline efforts to responsibly integrate AI in ways consistent with US \nand company policies. As AI systems become increasingly more capable, deeper partnership \nbetween government and industry will both improve the security of those systems and \nenhance the US government\u02bcs access to cutting-edge talent and capabilities.    \n \nHelp develop training programs to cultivate the next generation of AI talent in the US, \nespecially in areas of the country that have not benefited from previous waves of innovation, \nto establish pools of skilled talent for both the public and private sectors. \n\n \n\n9 \n \n\n\n\n \n\n \n\nRules of the Road \n\n \n \n \nWe believe that the more US-led development of AI becomes, the more widely it will be \ndeployed, the more trusted it will become, and the more people will benefit\u2014in turn creating a \nflywheel of growing prosperity and appreciation for democratic values like the freedom to \nresponsibly direct and work with AI tools, and a free market, with the appropriate safeguards, in \nwhich all manner of AI companies and entrepreneurs can compete. \n \nTo us, this means getting AI access and benefits right from the start\u2014what we think of as \ngetting the rules of the road right so the benefits can be fully realized. AI is not social \nmedia\u2014it\u02bcs an infrastructure technology that is leading us into what our CEO Sam Altman has \ncalled the Intelligence Age. With AI, our children will be able to do things we can\u02bct, and \neventually everyone\u02bcs lives can be better than anyone\u02bcs life is now. But we have work to do to \nget there. Government and the AI industry need to learn from the past and lay the proper rules \nso that when accessing AI tools and products, users can feel confident that:  \n \n\n \n\n \n\nTheir children will be \nprotected from potential \nharms \n\n \n\nThey will know where \ncontent comes from \n\n \n\nThey will be able to \npersonalize the AI tools  \nthey use \n\n \nWhile the federal government should lead on AI-related matters of national security, the states \nhave a vital role to play when it comes to maximizing AI\u02bcs benefits from the start. They can fill \ntheir historical role as laboratories for democracy by supporting experimentation with AI, \nincluding by start-ups and smaller AI firms, to identify ways to solve people\u02bcs daily hard \nproblems in areas like education and healthcare. They can support their government workers \nand developer communities experimenting with AI to identify ways to improve the lives of their \n\n10 \n \n\nhttps://ia.samaltman.com/\n\n\n \n\ntaxpayers. At the same time, this work would boost states\u02bc own local AI \necosystems\u2014especially new generations of AI-enabled developers who are the next Main \nStreet\u2014and competitiveness. \n \nAnd for the users of AI, from developers to the private sector and the public, access comes \nwith responsibility for following the rules so that everyone can proceed with certainty on the AI \nroads. The industry is building and deploying AI, but developers and users are the ones behind \nthe wheel.  \n \n\n \nSolutions: \nWe know that for AI to benefit everyone, even as we\u02bcre building AI to help people solve hard \nproblems, we have to build understanding of the technology and confidence in the safeguards \naround how it intersects with their daily lives.  \n \nOn child safety, AI companies and developers should:  \n \n\n\u25cf Encourage policy solutions that prevent the creation and distribution of AI-generated \nchild sexual abuse material/child sexual exploitation material \ue081CSAM/CSEM\ue082 \n \n\n\u25cf Incorporate CSAM/CSEM protections throughout the AI development life cycle \n \n\n\u25cf Take steps to prevent downstream developers from using their models to generate \nCSAM/CSEM \n \n\n\u25cf Promote conditions that support robust and lasting partnerships among AI companies \nand law enforcement \n\n \nOn knowing where content comes from, which is important for building trust and empowering \nusers, those building with AI, from large companies to start-ups to developers and \nentrepreneurs, should:  \n \n\n\u25cf Apply provenance data to all AI-generated audio-visual content \n \n\n\u25cf Use common provenance standards such as those developed by the Coalition for \nContent Provenance and Authenticity \ue081C2PA\ue082 \n \n\n\u25cf For large companies, given their broader reach, develop and report publicly on \nprogress toward more advanced provenance methods \n\n \n \n \n \n\n11 \n \n\n\n\n \n\n \n \nOn preferences: \n \n\n\u25cf People should be empowered to personalize their AI tools, including through controls \non how their personal data is used \n \n\n\u25cf Government and industry should work together to scale AI literacy through robust \nfunding for pilot programs, school district technology budgets and professional \ndevelopment trainings that help people understand how to choose their own \npreferences to personalize their tools \n \n\n\u25cf In exchange for having so much freedom, users should be responsible for impacts of \nhow they work and create with AI. Common-sense rules for AI that are aimed at \nprotecting from actual harms can only provide that protection if they apply to those \nusing the technology as well as those building it \n\n \nAt OpenAI, we\u02bcve already taken steps to adopt emerging rules of the road, including by \nestablishing robust child safety measures, and engaging with the National Center for Missing \nand Exploited Children, law enforcement, and other government stakeholders on child \nprotection issues and enhancements to reporting mechanisms. We\u02bcre also developing and \ndeploying ways to help users know where AI-generated audio or visual content comes from, \nincluding robust provenance methods, and we provide tools that help people personalize their \nChatGPT experience within broad, reasonable limits, and control how their data is used. \n \n\n \n\n12 \n \n\nhttps://openai.com/index/child-safety-adopting-sbd-principles/\nhttps://help.openai.com/en/articles/8096356-custom-instructions-for-chatgpt\nhttps://help.openai.com/en/articles/7730893-data-controls-faq\nhttps://openai.com/index/new-ways-to-manage-your-data-in-chatgpt/\n\n\n \n\n \n\nInfrastructure as Destiny \n \n \n \nWe believe that building enough infrastructure is not just vital for ensuring that AI around the \nworld is based on US rather than China-based technology\u2014it\u02bcs an unmissable opportunity to \ncatalyze a reindustrialization of the US. Successful nations turn resources into competitive \nadvantages. In the AI era, chips, data, energy and talent are the resources that will underpin \ncontinued US leadership, and as with the mass production of the automobile, marshalling these \nresources will create widespread economic opportunity and reinforce our global \ncompetitiveness. \n \nTo us, this means seizing the moment and building the infrastructure needed to produce \nenough energy and chips to drive down the cost of compute and make it abundant. In turn, this \nwill create tens of thousands of skilled-trade jobs, boost local economies through spending \nand indirect job creation, and modernize our energy grid in the near term\u2014 ultimately \nsupporting the kind of breakthroughs and innovations that drive lasting economic growth.  \n \nIt also means assuring AI developers that AI models will have the ability to learn from publicly \navailable information, and making more such information available through competition policy \nand public sector investment.  \n \nToday, demand for compute and energy far outstrips the available supply, while an estimated \n$175 billion in global funds is waiting to be invested in AI infrastructure. If the US doesn't move \nfast to channel these resources into projects that support democratic AI ecosystems around \nthe world, the funds will flow to projects backed and shaped by the CCP. \n \nLikewise, other actors, including developers in other countries, make no effort to respect or \nengage with the owners of IP rights. If the US and like-minded nations don\u02bct address this \nimbalance through sensible measures that help advance AI for the long-term, the same content \nwill still be used for AI training elsewhere, but for the benefit of other economies.  \n \n \n \n\n13 \n \n\nhttps://cdn.openai.com/global-affairs/openai-infra-economics-10.09.24.pdf\n\n\n \n\n \nSolutions: \nWe need a foundational strategy to ensure that investment in infrastructure benefits the most \npeople possible and maximizes access to AI. This includes policies and initiatives that \nencourage rather than stifle developers; support a thriving AI-ready workforce and ecosystems \nof labs, start-ups and larger companies; and secure America\u02bcs leadership on AI into the future, \nsuch as:  \n \nEnsuring that AI has the ability to learn from universal, publicly available information, just like \nhumans do, while also protecting creators from unauthorized digital replicas.  \n \nDigitizing government data currently in analog form. A lot of government data is in the public \ndomain. Making it more accessible or machine-readable could help US AI developers of all \nsizes, especially those working in fields where vital data is disproportionately \ngovernment-held. In exchange, developers using this data could work with government to \nunlock new insights that help it develop better public policies.  \n \nA Compact for AI among US allies and partner nations that streamlines access to capital and \nsupply chains in ways that support AI infrastructure and a robust AI ecosystem. Participating \ncountries would also agree to some common security standards. Over time, this collaboration \ncould expand to a global network of US allies and partners that would compete with the \nPeople\u02bcs Republic of China\u02bcs AI infrastructure alliances while also strengthening security \nthrough shared standards. \n \nAI Economic Zones, created by local, state and the federal government together with industry, \nthat significantly speed up the permitting processes for building AI infrastructure like new solar \narrays, wind farms and nuclear reactors.  \n \nCreation of AI research labs and workforces aligned with key local industries by requiring AI \ncompanies to provide meaningful amounts of compute to public universities to equitably scale \nthe training of a homegrown AI-skilled workforce. For example, Kansas could establish a hub \ndedicated to applying AI in agriculture; Texas or Pennsylvania could develop centers focused \non integrating AI into power production and grid resilience.  \n \nA nationwide AI education strategy\u2014rooted in local communities in partnership with American \ncompanies\u2014to help our current workforce and students become AI-ready, bolster the \neconomy, and secure America\u02bcs continued leadership on innovation. Maintaining US leadership \nin AI means ensuring we have an experienced, trained professional workforce working across \nthe AI supply chain, including construction worker management, HVAC technicians and \nelectricians. Government should ensure this training is accessible and affordable, such as by: \n \n \n\n14 \n \n\n\n\n \n\n\u25cf At the federal level, expand 529 savings plans to cover more AI supply chain-related \ntraining programs \u2013 including for construction, HVAC technicians, electricians, as well as \nAI researchers and developers \u2013 by amending Section 529 of the Internal Revenue Code \nor broadening the SECURE Act\u02bcs provisions.  \n \n\n\u25cf At the federal or state level, incentivize AI supply chain companies to work with a \nbackbone organization to understand the workforce needs of AI supply chain \ncompanies, develop a pipeline of training programs that help companies meet those \nneeds, and coordinate with labor unions, community colleges, and trade associations \nto build and operate that training pipeline. \n \n\n\u25cf At the state and local level, streamlining school procurement of AI tools and resources \nto make it faster and easier to incorporate AI into curricula and increase AI literacy for \nboth students and teachers. \n\n \nInvestment in national research infrastructure that would give scientists, innovators, and \neducators access to the compute and data necessary to accelerate and democratize scientific \nprogress, such as through funding a National AI Research Resource. \n \nLeading on the next generation of energy technology, including sustainable sources such as \nfission, fusion, and other promising technologies to support our existing energy capacity. A \nsufficient energy supply is critical to sustaining American leadership on AI. \n \nDramatically increased federal spending on power and data transmission and streamlined \napproval for new lines. That would be accompanied by the creation of a National AI \nInfrastructure Highway to connect those regional power and communication grids in the \ninterest of national economic competitiveness and security. \n \nFederal backstops for high-value AI public works that illustrate the model of federal spending \nin support of industry growth and both industry and users adhering to its rules. Since private \nmarkets alone may not be enough to pay for the massive amount of needed AI infrastructure, \nthe US government can provide offtake purchase commitments and credit enhancements to \nencourage infrastructure investment. The resulting infrastructure, such as the new energy \nsources needed to power AI data centers, would be considered strategic national assets.  \n\n \n \n\n \n\nOpenAI\u02bcs Economic Blueprint is a living document which we\u02bcll update as \nwe learn from our work with the US government to be thoughtful \nstewards of our technology and ensure that our tools help people solve \nhard problems to benefit the most people possible. \n\n \n \n\n15 \n \n\n\n\n \n\n \n \n\n \n \n\n \n\n \n\n \n\n \n\n \n\n \nCover image created with DALL.E \n\n \n \n\n16 \n \n\n\n\tForeword \n\tWhere We Stand \n\tCompetitiveness and Security \n\tRules of the Road \n\tInfrastructure as Destiny \n\n","extra":{"cited_message_idx":6,"search_result_idx":null,"evidence_text":"source","cloud_doc_url":null}}}],"content_references":[{"matched_text":"\u30106\u2020source\u3011","start_idx":6982,"end_idx":6992,"alt":null,"type":"file","name":"openai-us-economicblueprint-feb-2025-edu-update.pdf","id":"file-Kd7m1wytPgwgg7PG4DRMhk","source":"my_files","snippet":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOpenAI's US Economic Blueprint | Feb 2025 Edu Update\n\n\n \n\n \n \n\n \n \n \n \n \n \n \n \n \n \n \n \n\nAI in America   OpenAI's Economic Blueprint \nFebruary 2025 Update: Advancing AI Education \n\n \n\n\n\n \n\nForeword \n\n \n \n \nOpenAI\u02bcs mission is to ensure that artificial intelligence benefits everyone. To us, that means \nbuilding AI that helps people solve hard problems because by helping with the hard problems, \nAI can benefit the most people possible \u2013 through better healthcare and education, more \nscientific discoveries, better public policies and services, and improved productivity. We\u02bcre off \nto a strong start, creating freely available intelligence being used by more than 300 million \npeople around the world, including 3 million developers, to ideate, discover, and innovate \nbeyond what we\u02bcre currently capable of doing on our own. Already, our tools are being used to: \n \n\n \n\n \n\nSpeed up \ndevelopment \nof life-saving \nmedical \ntreatments \n\n \n\nAccelerate \nscientific \nresearch by \nUS National \nLaboratories \n\n \n\nHelp \nteachers \ncreate \npersonalized \nlesson plans, \nspend more \ntime with \nstudents, \nand safely \nadopt AI in \nthe \nclassroom  \n\n \n\nProtect US \nmilitary \npersonnel \nagainst \nunmanned \ndrone \nattacks   \n\n \n\nUnlock new \nforms of \ncreativity for \nartists and \nincrease \naccessibility \nof artistic \nproduction \n\n \n\nMake state \nand local \ngovernments \nmore \nefficient  \n\n \n \nWe believe America needs to act now to maximize AI\u02bcs possibilities while minimizing its harms. \nAI is too powerful a technology to be led and shaped by autocrats, but that is the growing risk \nwe face, while the economic opportunity AI presents is too compelling to forfeit. Shared \nprosperity is as near and measurable as the new jobs and growth to come from building the \nneeded infrastructure. Soon, as our CEO Sam Altman has written, AI will help our children do \nthings we can\u02bct. Not far off is a future in which everyone\u02bcs lives can be better than anyone\u02bcs life \nis now.  \n \nWith such prosperity in sight, we want to work with policymakers to ensure that AI\u02bcs benefits \nare shared responsibly and equitably. The enclosed framework champions the \nentrepreneurship and individual freedoms at the heart of the American innovation ecosystem. \n\n2 \n \n\nhttps://openai.com/index/moderna/\nhttps://openai.com/index/moderna/\nhttps://www.osti.gov/servlets/purl/2479365\nhttps://www.osti.gov/servlets/purl/2479365\nhttps://www.osti.gov/servlets/purl/2479365\nhttps://sharemylesson.com/webinars/aftopenai-professional-learning-series\nhttps://sharemylesson.com/webinars/aftopenai-professional-learning-series\nhttps://www.youtube.com/watch?v=Ia3CPhVkUtg\nhttps://www.youtube.com/watch?v=Ia3CPhVkUtg\nhttps://www.anduril.com/article/anduril-partners-with-openai-to-advance-u-s-artificial-intelligence-leadership-and-protect-u-s/\nhttps://www.anduril.com/article/anduril-partners-with-openai-to-advance-u-s-artificial-intelligence-leadership-and-protect-u-s/\nhttps://www.anduril.com/article/anduril-partners-with-openai-to-advance-u-s-artificial-intelligence-leadership-and-protect-u-s/\nhttps://www.anduril.com/article/anduril-partners-with-openai-to-advance-u-s-artificial-intelligence-leadership-and-protect-u-s/\nhttps://openai.com/sora/\nhttps://openai.com/sora/\nhttps://openai.com/sora/\nhttps://tribecafilm.com/press-center/festival/press-releases/tribeca-festival-and-open-ai-announce-sora-shorts\nhttps://tribecafilm.com/press-center/festival/press-releases/tribeca-festival-and-open-ai-announce-sora-shorts\nhttps://www.pa.gov/agencies/oa/newsroom/agreement-innovateus-to-train-responsible-generative-artificial-.html\nhttps://www.pa.gov/agencies/oa/newsroom/agreement-innovateus-to-train-responsible-generative-artificial-.html\nhttps://cdn.openai.com/global-affairs/openai-infra-economics-10.09.24.pdf\nhttps://ia.samaltman.com/\n\n\n \n\nIf done right, the developers who are AI\u02bcs Main Street will thrive along with companies of all \nsizes, and the broad economic benefits of the technology will catalyze a reindustrialization \nacross the country. \n \nAmerica has faced such moments before, and we know how to think big, build big and act big. \n \nAutomobiles weren\u02bct invented here\u2014they were invented in Europe. Early proponents \nenvisioned the car transforming how people lived and worked. Supply chains and customer \nbases could be expanded and diversified. \n \nBut in the United Kingdom, where some of the earliest cars were introduced, the new industry\u02bcs \ngrowth was stunted by regulation. The 1865 Red Flag Act required a flag bearer to walk ahead \nof any car to warn others on the road and wave the car aside in favor of horse-drawn \ntransport. How could a person walk in front of a car without getting run over? Because of \nanother requirement: that cars move no faster than 4 miles per hour. \n \nAmerica, meanwhile, took a very different approach to the car, merging private-sector vision \nand innovation with public-sector enlightenment to unlock the new technology and its \neconomic\u2014and ultimately, with World War I looming\u2014national security benefits.  \n \nThe country became the heart of the world\u02bcs auto industry, mass-producing affordable cars \nwith the help of local, state and federal officials who saw the industry\u02bcs potential. Public safety \nconcerns over horse-drawn vehicles on crowded city streets prompted local officials to \nsupport the switch to cars\u2014not make cars yield to horses. The country\u02bcs size prompted states \nto invest in better roads. And the federal government cleared the way to scale transport by car \nwith a national\u2014rather than state-by-state\u2014highway system.  \n \nToday, while some countries sideline AI and its economic potential, the US government can \npave the road for its AI industry to: \n\n \n \n \n \n\nContinue the country\u02bcs  \nglobal leadership  \n\nin innovation while \n protecting national  \n\nsecurity \n\n Make sure we \nget it right \n\non AI access \nand benefits \nfrom the start \n\n Maximize the  \neconomic opportunity  \nof AI for communities \n\nacross the country \n\n \n \n \n \n\n3 \n \n\n\n\n \n\nAnd just as drivers are expected to stick to clear, common-sense standards that help keep the \nactual roads safe, developers and users have a responsibility to follow clear, common-sense \nstandards that keep the AI roads safe. Straightforward, predictable rules that safeguard the \npublic while helping innovators thrive can encourage investment, competition, and greater \nfreedom for everyone. \n \nFor our part, OpenAI is committed to working with US policymakers on how AI can best serve \nboth the national interest and the public good, stewarding our own technology along those \nlines, and globally championing AI that is built on a foundation of the democratic values the US \nhas always stood for.  \n \nWe believe in America because America believes in innovation. This is why our CEO will be \nkicking off this work with a gathering in Washington, DC on January 30 to preview the state of \nAI advancement and how it can drive economic growth. And this is why that event will kick off \nour Innovating for America initiative to engage states across the country to help ensure that \nwe\u02bcre bringing AI\u02bcs economic benefits to Americans from all walks of life.  \n \nThis country always succeeds when it bets on its ecosystem of builders and entrepreneurs. \nThis Blueprint, a living document we\u02bcll update as we learn from our work to help solve people\u02bcs \nhard problems, lays out a relationship we believe we can build on with government here at \nhome and as a place to begin with allies around the world.  \n \n \nChris Lehane \nVice President, Global Affairs \n \n\n \n\n4 \n \n\n\n\n \n\nWhere We Stand \n\n \n \n \nThe enclosed policy proposals reflect OpenAI\u02bcs position that: \n \n\n\u25cf We believe in America because America believes in innovation.  \n \n\n\u25cf Chips, data, energy and talent are the keys to winning on AI\u2014and this is a race \nAmerica can and must win.  \n \n\n\u25cf With an estimated $175 billion sitting in global funds awaiting investment in AI projects, \nif the US doesn\u02bct attract those funds, they will flow to China-backed \nprojects\u2014strengthening the Chinese Communist Party\u02bcs global influence. \n \n\n\u25cf Rules and regulations for the development and use of AI should be based on the \ndemocratic values the country has always stood for\u2014what we think of as \u201cdemocratic \nAI.\u02ee  \n \n\n\u25cf As for any industry, we need common-sense rules of the road that safeguard the \npublic while helping innovators thrive by encouraging investment, competition, and \ngreater freedom for everyone\u2014and to best achieve this, these rules should apply \nnationwide.  \n\n \n\n5 \n \n\n\n\n \n\n \n\nCompetitiveness and Security \n\n \n \n \nWe believe that making sure AI benefits the most people possible means enabling AI through \ncommon-sense rules aimed at protecting people from actual harms, and building democratic AI \nshaped by the values the US has always stood for, including:  \n \n\n\u25cf A free market promoting free and fair competition that drives innovation \n \n\n\u25cf Freedom for developers and users to work with and direct our tools as they see fit, in \nexchange for following clear, common-sense standards that help keep AI safe for \neveryone, and being held accountable when they don\u02bct \n \n\n\u25cf Preventing government use of AI tools to amass power and control their citizens, or to \nthreaten or coerce other states \n\n \nTo us, this means that in the same way the federal government helped clear the way for the \nnascent automobile industry to grow, including by preempting a state-by-state tangle of roads \nand rules, it should clear the way for the AI industry\u02bcs development of frontier models to best \nensure that they promote US economic and national security. \n \nTo be clear, by \u201cfrontier models,\u02ee  we are referring to the most state-of-the-art large language \nmodels that lead on capability benchmarks. Responsibly exporting these models to our allies \nand partners will help them stand up their own AI ecosystems, including their own developer \ncommunities innovating with AI and distributing its benefits, while also building AI on US \ntechnology, not technology funded by the Chinese Communist Party \ue081CCP\ue082.  \n \n \n \n \n\n \n\n6 \n \n\n\n\n \n\nThe US strategy for frontier model security should prioritize national competitiveness, model \nsafeguards and national security. Led by the federal government in consultation with industry, \nthis strategy should:  \n \n\n \n\n \n\nDevelop best practices for \ndeployment to better protect \nagainst the risks of criminal, \nterrorist, and state-sponsored \nmisuse and industrial \nespionage; and streamline \nindustry engagement with \nnational security departments \nand agencies  \n\n \n\nDevelop export policies that \nlet the industry securely \nshare frontier models with US \nallies and partner nations to \nstrengthen their economies \nand especially their \ndeveloper communities, and \npreserve a vibrant and \ninnovative open-source \ncommunity. At the same time, \nlimit the export of frontier \nmodels to adversary nations \nthat may be more likely to \nmisuse the technology or \nco-opt the IP \n\n \n\nDevelop alternatives to the \ngrowing patchwork of state \nand international regulations \nthat risk hindering American \ncompetitiveness, such as by \nhaving the federal \ngovernment leading the \ndevelopment of national \nsecurity evaluations at home, \nand establishing a US-led \ninternational coalition that \nworks toward shared safety \nstandards abroad \n\n \n \nAt OpenAI, we\u02bcve already taken steps toward such a strategy, including by developing our own \nsector-leading Preparedness Framework; having red team experts pressure-test our frontier \nmodels for national security risks (for example, by evaluating a model\u02bcs capability to create \nnovel cyber threats); using tailored safeguards to mitigate risks; stewarding adoption of our \nmodels by US-allied and partner countries; partnering with leading names in defense such as \nLos Alamos National Laboratory, the Air Force Research Laboratory, and Anduril; and being \ntransparent with the public about our safeguards and deployment practices.  \n\n \n \n \n \n \n \n \n \n \n \n\n7 \n \n\n\n\n \n\n \nSolutions: \nThe US always succeeds when it bets on its ecosystem of innovators and entrepreneurs. To \nhelp US AI companies develop and deploy frontier models securely and with the needed \nsafeguards, the federal government should:  \n \nAs appropriate, share national security-related information and resources that it alone \nmaintains\u2014such as briefings on security threats to the industry and high-level results of \ntesting US and non-US AI models\u2014with US AI companies pursuing advanced research.  \n \nThen, incentivize AI companies to deploy their products widely, including to allied and partner \nnations and to support US government agencies. \n \nThe federal government\u02bcs approach to frontier model safety and security should streamline \nrequirements, reduce bureaucratic obstacles to government-industry collaboration, and \nincentivize companies to support US competitiveness. For instance, the government could: \n\n \nSupport the development of standards and safeguards, ensure that such standards are \nrecognized and respected by other nations and international bodies on behalf of the US \nprivate sector, and support direct work with US government agencies and offices. \n \nShare its unique expertise with AI companies, including information about how to secure their \nIP against industrial security threats and mitigate potential cyber, chemical, biological, \nradiological and nuclear \ue081CBRN\ue082 and other risks that are heightened by increasingly powerful \nmodels. \n \nHelp companies access secure infrastructure, such as classified computing clusters, to \nevaluate model security risks and safeguards. \n \nPromote transparency consistent with competitiveness by the US and like-minded nations \nthrough protecting trade secrets, promoting market competition, and ensuring broad and \naffordable AI access by carefully choosing disclosure requirements across the AI life cycle. \n \nStreamline its support for the industry by creating a defined, voluntary pathway for companies \nthat develop large language models to work with government to define model evaluations, test \nmodels, and exchange information to support the companies\u02bc safeguards. The US government \ncan uniquely mobilize and coordinate experts, especially those with access to classified threat \nintelligence, to work directly with frontier labs on national security-related evaluations and \nmitigations. In return, these companies would receive preemption from state-by-state \nregulations on the types of risks that the same national security agencies would handle.  \n \n\n8 \n \n\n\n\n \n\nEmpower the public sector to quickly and securely adopt AI tools to ensure pathways to \nadoption for start-ups and smaller firms, save taxpayers money, improve the efficiency of \noperations, and deliver better public services.  \n \nAnd to further coordinate and collaborate with the federal government, AI builders could:  \n \nForm a consortium that identifies best practices for working with the national security \ncommunity, including to prioritize security-based requests of the government (such as access \nto compute) and to streamline efforts to responsibly integrate AI in ways consistent with US \nand company policies. As AI systems become increasingly more capable, deeper partnership \nbetween government and industry will both improve the security of those systems and \nenhance the US government\u02bcs access to cutting-edge talent and capabilities.    \n \nHelp develop training programs to cultivate the next generation of AI talent in the US, \nespecially in areas of the country that have not benefited from previous waves of innovation, \nto establish pools of skilled talent for both the public and private sectors. \n\n \n\n9 \n \n\n\n\n \n\n \n\nRules of the Road \n\n \n \n \nWe believe that the more US-led development of AI becomes, the more widely it will be \ndeployed, the more trusted it will become, and the more people will benefit\u2014in turn creating a \nflywheel of growing prosperity and appreciation for democratic values like the freedom to \nresponsibly direct and work with AI tools, and a free market, with the appropriate safeguards, in \nwhich all manner of AI companies and entrepreneurs can compete. \n \nTo us, this means getting AI access and benefits right from the start\u2014what we think of as \ngetting the rules of the road right so the benefits can be fully realized. AI is not social \nmedia\u2014it\u02bcs an infrastructure technology that is leading us into what our CEO Sam Altman has \ncalled the Intelligence Age. With AI, our children will be able to do things we can\u02bct, and \neventually everyone\u02bcs lives can be better than anyone\u02bcs life is now. But we have work to do to \nget there. Government and the AI industry need to learn from the past and lay the proper rules \nso that when accessing AI tools and products, users can feel confident that:  \n \n\n \n\n \n\nTheir children will be \nprotected from potential \nharms \n\n \n\nThey will know where \ncontent comes from \n\n \n\nThey will be able to \npersonalize the AI tools  \nthey use \n\n \nWhile the federal government should lead on AI-related matters of national security, the states \nhave a vital role to play when it comes to maximizing AI\u02bcs benefits from the start. They can fill \ntheir historical role as laboratories for democracy by supporting experimentation with AI, \nincluding by start-ups and smaller AI firms, to identify ways to solve people\u02bcs daily hard \nproblems in areas like education and healthcare. They can support their government workers \nand developer communities experimenting with AI to identify ways to improve the lives of their \n\n10 \n \n\nhttps://ia.samaltman.com/\n\n\n \n\ntaxpayers. At the same time, this work would boost states\u02bc own local AI \necosystems\u2014especially new generations of AI-enabled developers who are the next Main \nStreet\u2014and competitiveness. \n \nAnd for the users of AI, from developers to the private sector and the public, access comes \nwith responsibility for following the rules so that everyone can proceed with certainty on the AI \nroads. The industry is building and deploying AI, but developers and users are the ones behind \nthe wheel.  \n \n\n \nSolutions: \nWe know that for AI to benefit everyone, even as we\u02bcre building AI to help people solve hard \nproblems, we have to build understanding of the technology and confidence in the safeguards \naround how it intersects with their daily lives.  \n \nOn child safety, AI companies and developers should:  \n \n\n\u25cf Encourage policy solutions that prevent the creation and distribution of AI-generated \nchild sexual abuse material/child sexual exploitation material \ue081CSAM/CSEM\ue082 \n \n\n\u25cf Incorporate CSAM/CSEM protections throughout the AI development life cycle \n \n\n\u25cf Take steps to prevent downstream developers from using their models to generate \nCSAM/CSEM \n \n\n\u25cf Promote conditions that support robust and lasting partnerships among AI companies \nand law enforcement \n\n \nOn knowing where content comes from, which is important for building trust and empowering \nusers, those building with AI, from large companies to start-ups to developers and \nentrepreneurs, should:  \n \n\n\u25cf Apply provenance data to all AI-generated audio-visual content \n \n\n\u25cf Use common provenance standards such as those developed by the Coalition for \nContent Provenance and Authenticity \ue081C2PA\ue082 \n \n\n\u25cf For large companies, given their broader reach, develop and report publicly on \nprogress toward more advanced provenance methods \n\n \n \n \n \n\n11 \n \n\n\n\n \n\n \n \nOn preferences: \n \n\n\u25cf People should be empowered to personalize their AI tools, including through controls \non how their personal data is used \n \n\n\u25cf Government and industry should work together to scale AI literacy through robust \nfunding for pilot programs, school district technology budgets and professional \ndevelopment trainings that help people understand how to choose their own \npreferences to personalize their tools \n \n\n\u25cf In exchange for having so much freedom, users should be responsible for impacts of \nhow they work and create with AI. Common-sense rules for AI that are aimed at \nprotecting from actual harms can only provide that protection if they apply to those \nusing the technology as well as those building it \n\n \nAt OpenAI, we\u02bcve already taken steps to adopt emerging rules of the road, including by \nestablishing robust child safety measures, and engaging with the National Center for Missing \nand Exploited Children, law enforcement, and other government stakeholders on child \nprotection issues and enhancements to reporting mechanisms. We\u02bcre also developing and \ndeploying ways to help users know where AI-generated audio or visual content comes from, \nincluding robust provenance methods, and we provide tools that help people personalize their \nChatGPT experience within broad, reasonable limits, and control how their data is used. \n \n\n \n\n12 \n \n\nhttps://openai.com/index/child-safety-adopting-sbd-principles/\nhttps://help.openai.com/en/articles/8096356-custom-instructions-for-chatgpt\nhttps://help.openai.com/en/articles/7730893-data-controls-faq\nhttps://openai.com/index/new-ways-to-manage-your-data-in-chatgpt/\n\n\n \n\n \n\nInfrastructure as Destiny \n \n \n \nWe believe that building enough infrastructure is not just vital for ensuring that AI around the \nworld is based on US rather than China-based technology\u2014it\u02bcs an unmissable opportunity to \ncatalyze a reindustrialization of the US. Successful nations turn resources into competitive \nadvantages. In the AI era, chips, data, energy and talent are the resources that will underpin \ncontinued US leadership, and as with the mass production of the automobile, marshalling these \nresources will create widespread economic opportunity and reinforce our global \ncompetitiveness. \n \nTo us, this means seizing the moment and building the infrastructure needed to produce \nenough energy and chips to drive down the cost of compute and make it abundant. In turn, this \nwill create tens of thousands of skilled-trade jobs, boost local economies through spending \nand indirect job creation, and modernize our energy grid in the near term\u2014 ultimately \nsupporting the kind of breakthroughs and innovations that drive lasting economic growth.  \n \nIt also means assuring AI developers that AI models will have the ability to learn from publicly \navailable information, and making more such information available through competition policy \nand public sector investment.  \n \nToday, demand for compute and energy far outstrips the available supply, while an estimated \n$175 billion in global funds is waiting to be invested in AI infrastructure. If the US doesn't move \nfast to channel these resources into projects that support democratic AI ecosystems around \nthe world, the funds will flow to projects backed and shaped by the CCP. \n \nLikewise, other actors, including developers in other countries, make no effort to respect or \nengage with the owners of IP rights. If the US and like-minded nations don\u02bct address this \nimbalance through sensible measures that help advance AI for the long-term, the same content \nwill still be used for AI training elsewhere, but for the benefit of other economies.  \n \n \n \n\n13 \n \n\nhttps://cdn.openai.com/global-affairs/openai-infra-economics-10.09.24.pdf\n\n\n \n\n \nSolutions: \nWe need a foundational strategy to ensure that investment in infrastructure benefits the most \npeople possible and maximizes access to AI. This includes policies and initiatives that \nencourage rather than stifle developers; support a thriving AI-ready workforce and ecosystems \nof labs, start-ups and larger companies; and secure America\u02bcs leadership on AI into the future, \nsuch as:  \n \nEnsuring that AI has the ability to learn from universal, publicly available information, just like \nhumans do, while also protecting creators from unauthorized digital replicas.  \n \nDigitizing government data currently in analog form. A lot of government data is in the public \ndomain. Making it more accessible or machine-readable could help US AI developers of all \nsizes, especially those working in fields where vital data is disproportionately \ngovernment-held. In exchange, developers using this data could work with government to \nunlock new insights that help it develop better public policies.  \n \nA Compact for AI among US allies and partner nations that streamlines access to capital and \nsupply chains in ways that support AI infrastructure and a robust AI ecosystem. Participating \ncountries would also agree to some common security standards. Over time, this collaboration \ncould expand to a global network of US allies and partners that would compete with the \nPeople\u02bcs Republic of China\u02bcs AI infrastructure alliances while also strengthening security \nthrough shared standards. \n \nAI Economic Zones, created by local, state and the federal government together with industry, \nthat significantly speed up the permitting processes for building AI infrastructure like new solar \narrays, wind farms and nuclear reactors.  \n \nCreation of AI research labs and workforces aligned with key local industries by requiring AI \ncompanies to provide meaningful amounts of compute to public universities to equitably scale \nthe training of a homegrown AI-skilled workforce. For example, Kansas could establish a hub \ndedicated to applying AI in agriculture; Texas or Pennsylvania could develop centers focused \non integrating AI into power production and grid resilience.  \n \nA nationwide AI education strategy\u2014rooted in local communities in partnership with American \ncompanies\u2014to help our current workforce and students become AI-ready, bolster the \neconomy, and secure America\u02bcs continued leadership on innovation. Maintaining US leadership \nin AI means ensuring we have an experienced, trained professional workforce working across \nthe AI supply chain, including construction worker management, HVAC technicians and \nelectricians. Government should ensure this training is accessible and affordable, such as by: \n \n \n\n14 \n \n\n\n\n \n\n\u25cf At the federal level, expand 529 savings plans to cover more AI supply chain-related \ntraining programs \u2013 including for construction, HVAC technicians, electricians, as well as \nAI researchers and developers \u2013 by amending Section 529 of the Internal Revenue Code \nor broadening the SECURE Act\u02bcs provisions.  \n \n\n\u25cf At the federal or state level, incentivize AI supply chain companies to work with a \nbackbone organization to understand the workforce needs of AI supply chain \ncompanies, develop a pipeline of training programs that help companies meet those \nneeds, and coordinate with labor unions, community colleges, and trade associations \nto build and operate that training pipeline. \n \n\n\u25cf At the state and local level, streamlining school procurement of AI tools and resources \nto make it faster and easier to incorporate AI into curricula and increase AI literacy for \nboth students and teachers. \n\n \nInvestment in national research infrastructure that would give scientists, innovators, and \neducators access to the compute and data necessary to accelerate and democratize scientific \nprogress, such as through funding a National AI Research Resource. \n \nLeading on the next generation of energy technology, including sustainable sources such as \nfission, fusion, and other promising technologies to support our existing energy capacity. A \nsufficient energy supply is critical to sustaining American leadership on AI. \n \nDramatically increased federal spending on power and data transmission and streamlined \napproval for new lines. That would be accompanied by the creation of a National AI \nInfrastructure Highway to connect those regional power and communication grids in the \ninterest of national economic competitiveness and security. \n \nFederal backstops for high-value AI public works that illustrate the model of federal spending \nin support of industry growth and both industry and users adhering to its rules. Since private \nmarkets alone may not be enough to pay for the massive amount of needed AI infrastructure, \nthe US government can provide offtake purchase commitments and credit enhancements to \nencourage infrastructure investment. The resulting infrastructure, such as the new energy \nsources needed to power AI data centers, would be considered strategic national assets.  \n\n \n \n\n \n\nOpenAI\u02bcs Economic Blueprint is a living document which we\u02bcll update as \nwe learn from our work with the US government to be thoughtful \nstewards of our technology and ensure that our tools help people solve \nhard problems to benefit the most people possible. \n\n \n \n\n15 \n \n\n\n\n \n\n \n \n\n \n \n\n \n\n \n\n \n\n \n\n \n\n \nCover image created with DALL.E \n\n \n \n\n16 \n \n\n\n\tForeword \n\tWhere We Stand \n\tCompetitiveness and Security \n\tRules of the Road \n\tInfrastructure as Destiny \n\n","cloud_doc_url":null}],"message_type":null,"model_slug":"gpt-4-5","default_model_slug":"gpt-4-5","parent_id":"3fc66d74-1d44-4d68-b047-e9344eb64772","request_id":"92004fa4de08835c-ATL","timestamp_":"absolute"},"recipient":"all","channel":null},"parent":"3fc66d74-1d44-4d68-b047-e9344eb64772","children":[]}}}