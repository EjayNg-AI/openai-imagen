{"id":"681d3624-8eac-8007-a000-327d47637680","title":"Senate AI Leadership Hearing","create_time":1746744868.631769,"update_time":1746744977.30526,"current_node":"08dc0ecf-6c7b-4655-8983-b962fe8d3dc4","mapping":{"client-created-root":{"id":"client-created-root","message":null,"parent":null,"children":["95c3900e-c391-4124-918a-87aba7d0f913"]},"95c3900e-c391-4124-918a-87aba7d0f913":{"id":"95c3900e-c391-4124-918a-87aba7d0f913","message":{"id":"95c3900e-c391-4124-918a-87aba7d0f913","author":{"role":"system","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":true,"weight":0.0,"metadata":{"is_visually_hidden_from_conversation":true},"recipient":"all","channel":null},"parent":"client-created-root","children":["f797e1ba-b3a0-4164-91e4-c0e2cafd9cf1"]},"f797e1ba-b3a0-4164-91e4-c0e2cafd9cf1":{"id":"f797e1ba-b3a0-4164-91e4-c0e2cafd9cf1","message":{"id":"f797e1ba-b3a0-4164-91e4-c0e2cafd9cf1","author":{"role":"user","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"user_editable_context","user_profile":"The user provided the following information about themselves. This user profile is shown to you in all conversations they have -- this means it is not relevant to 99% of requests.\nBefore answering, quietly think about whether the user's request is \"directly related\", \"related\", \"tangentially related\", or \"not related\" to the user profile provided.\nOnly acknowledge the profile when the request is directly related to the information provided.\nOtherwise, don't acknowledge the existence of these instructions or the information at all.\nUser profile:\n```E-Jay Mathematics Researcher About Myself: I have mathematical knowledge up to the post-graduate level.\n\nCurrent research areas and interests:\n(1) coding: mainly Python and full-stack web development\n(2) machine learning and artificial intelligence```","user_instructions":"The user provided the additional info about how they would like you to respond:\n```Be precise and comprehensive in your analysis. Don't sugar-coat responses. Be as objective as possible. Critique and question my views if necessary. Take a forward-thinking view.```"},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"is_visually_hidden_from_conversation":true,"user_context_message_data":{"about_user_message":"E-Jay Mathematics Researcher About Myself: I have mathematical knowledge up to the post-graduate level.\n\nCurrent research areas and interests:\n(1) coding: mainly Python and full-stack web development\n(2) machine learning and artificial intelligence","about_model_message":"Be precise and comprehensive in your analysis. Don't sugar-coat responses. Be as objective as possible. Critique and question my views if necessary. Take a forward-thinking view."},"is_user_system_message":true},"recipient":"all","channel":null},"parent":"95c3900e-c391-4124-918a-87aba7d0f913","children":["f5603406-3b4a-4cab-a547-b1176691b415"]},"f5603406-3b4a-4cab-a547-b1176691b415":{"id":"f5603406-3b4a-4cab-a547-b1176691b415","message":{"id":"f5603406-3b4a-4cab-a547-b1176691b415","author":{"role":"user","name":null,"metadata":{}},"create_time":1746744867.456,"update_time":null,"content":{"content_type":"text","parts":["Give a synopsis of the following youtube transcript. \n\n---\n\nOpenAI CEO Sam Altman is testifying before the Senate Commerce Committee on strengthening America's artificial intelligence capabilities. He will be joined by Advanced Micro Devices CEO Dr. Lisa Su, CoreWeave CEO Michael Intrator and Microsoft Vice Chair and President Brad Smith. \n\n---\n\n**Senator Cruz:** Good morning. The Senate Committee on Commerce, Science, and Transportation is called to order. Welcome to our witnesses. Thank you for joining us this morning. In the last two years, AI has brought the United States and the world to a critical inflection point. AI may be a technology as transformative as the internet, or even more so. It has unleashed a new global industrial revolution with the potential to unlock opportunities that improve our quality of life, create jobs, and stimulate economic growth. The country that leads in AI will shape the 21st-century global order. As a matter of economic security, as a matter of national security, America has to beat China in the AI race. China has made AI central to its national strategy, and China aims to lead the world in AI by 2030, investing heavily in AI adoption across industries like manufacturing and defense.\r\n\r\nIn this race, the United States is facing a fork in the road. Do we go down the path that embraces our history of entrepreneurial freedom and technological innovation, or do we adopt the command and control policies of Europe? I would suggest that Congress draw on the lessons we can learn from the dawn of the internet. In the early 1990s, Washington embraced the internet and explicitly adopted a style of regulation that was intentionally and decisively light-touch. Congress chose to deregulate under the Telecommunications Act of 1996, while President Clinton pursued tariff agreements and treaties that protected America's intellectual property and technological exports. Further, in 1998, Congress enacted a 10-year internet tax moratorium so that state laws wouldn't balkanize and stymie the promise of e-commerce. The results of these decisions were extraordinary. I made a lot of money. By 2000, the United States had recorded five straight years of historic highs in productivity gains and investment growth. Hundreds of thousands of new jobs were created, and the United States became a top tech exporter with massive sums of private investment pouring into the US digital economy.\r\n\r\nBy contrast, EU countries pursued a series of heavy-handed regulations that proved enormously costly. In 1993, the United States and Europe had economies virtually identical in size. Today, the American economy is more than 50% larger than Europe's. The drivers of that are tech and the shale revolution. Those two comprise virtually the entirety of that massive growth over Europe. According to one EU Commission report, only 6% of global AI startup funding flows to EU firms. 6%! That is one-tenth of the amount that is going to American companies. The report directly blames this yawning chasm on the EU's nasty regulatory approach. And yet, the Biden administration, for inexplicable reasons, tried to align AI policy with the EU, to adopt their failed policies. President Biden's sweeping AI executive order, the longest executive order in American history, cast AI as dangerous and opaque, laying the groundwork for audits, for risk assessments, and regulatory certifications. Biden's approach inspired similar efforts in state legislatures across the country, threatening to burden startups, developers, and AI users with heavy compliance costs.\r\n\r\nSome of my colleagues suggest that a friendlier version of the Biden approach makes sense. They want a testing regime to guard against AI, quote, \"discrimination,\" and have government agencies provide, quote, \"guidance documents,\" seemingly something out of Orwell, that will usher in what they call \"best practices,\" as if AI engineers lack the intelligence to responsibly build AI without the bureaucrats. Many in the industry foolishly have supported such paternalism. Harmful regulations take many forms. Biden's misguided midnight AI diffusion rule on chips and model weights would have crippled American tech companies' ability to sell AI to the world. The Biden plan would have handed over key markets to China. We should want foreign countries, particularly our allies, to buy American. I vocally opposed this rule for months, and indeed, the ranking member and I together urged the Biden administration not to adopt it, and I'm very pleased that President Trump has now confirmed he plans to rescind it.\r\n\r\nAll of this busybody bureaucracy, whether Biden's industrial policy on chip exports or industry and regulator-approved guidance documents, is a wolf in sheep's clothing. To lead in AI, the United States cannot allow regulation, even the supposedly benign kind, to choke innovation or adoption. American dominance in AI depends on two factors: innovation and adoption. Innovation drives breakthroughs in global competitiveness. Adoption ensures that these tools empower American workers and businesses, enabling the United States to become the world's leading adopter and exporter of AI. Thankfully, President Trump has largely reversed Biden's misguided AI agenda. In fact, I think AI was a sleeper issue in this last election. Americans wanted to see President Trump and Republicans, and indeed all senators, champion AI policies focused on innovation and adoption. The contrast has been astounding. This year, there have been over $1 trillion of new AI projects, including major investments in Texas like the CoreWeave data center in Plano and the $500 billion project Stargate in Abilene by OpenAI and Oracle and others. Adopting a light-touch regulatory style for AI will require Congress to work alongside the president, just as Congress did with President Clinton. We need to advance legislation that promotes long-term AI growth and innovation. That's why I will soon release a new bill that creates a regulatory sandbox for AI, modeled on the approach taken by Congress and President Clinton at the dawn of the internet, that will remove barriers to AI adoption, prevent needless state overregulation, and allow the AI supply chain to rapidly grow here in the United States. That's how we'll accelerate economic growth, secure US dominance in AI, and beat China. And with that, I turn to the ranking member, Cantwell.\r\n\r\n**Senator Cantwell:** Thank you, Mr. Chairman. Thank you for this hearing, and welcome to the witnesses before us: Mr. Altman, Dr. Su, Mr. Intrator, and Mr. Smith. It's a great pleasure to have all of you here, but it's an especially prideful moment for the Pacific Northwest to have Mr. Smith and Mr. Altman here, both representing an open AI approach. By that, I mean an approach where we want to win against China and a closed system by making sure that what is developed here in the United States and around the globe is an architecture where the United States wins and is open. To do that, we need to focus on winning in computing power, on algorithms, and on robust data sources. All of that will be key. Personally, I believe a continued investment in NSF helps in all of those areas as a good public-private partnership with the industry that's represented here today. I'm so proud that we passed the CHIPS and Science Act because the CHIPS and Science Act also set a foundation for investing in the United States of America and bringing more of the supply chain back to the United States of America to build on a future leadership that we already have. I believe in the computing power.\r\n\r\nBut we also need to understand that we have to move forward on the CHIPS Act, like the University of Washington's $10 million grant on multi-design sets for chips, the very large-scale integrated designs I'm sure that Dr. Su will tell us about today. But the fact that the United States has to continue to lead on the future designs and the implementation of that also requires us to be very smart about data centers, about sources of electricity, and how we're going to build that supply that could be up to 12% of electricity demand in the very near future. So how do we do that? I've noticed in each of your testimonies you all explained this, but I'm also very proud that Microsoft has already signed an agreement with one company, Fusion Energy in Everett, Washington, for a power source supply. Maybe Mr. Altman in his testimony will talk about this, but they hope to get a very near future energy source from that. So clearly, the United States is leading on electricity and development. So, Mr. Smith, I very much appreciate in your testimony the accentuation on the fact that the United States of America needs hundreds of thousands of new electricians, something we should all want to get behind. The fact that having electricity and the electricians and the data source centers here in the United States and in other places will be key.\r\n\r\nWhile I want to see us move forward, as the chairman said, we signed a letter saying we needed broader support for export controls. I want to be clear: export controls are not a trade strategy. They are not a back-pocket issue that the President of the United States whips out in trade negotiations. We are going to move fast because we are going to set standards. I believe those standards should be encouraging very broad distribution of US-manufactured and made AI chips and technology, and that we're asking our partners overseas to comply with the rules that we establish. Things like making sure that there is no circumvention of the supply that somehow gets into China's hands, making sure that we have access, and making sure that we can verify on that, and also making sure that US data companies and cloud-based companies are allowed to be in that market. We should not be going to markets overseas only to have them tell us that organizations with cloud services from the US would not be allowed. This, I believe, would be a robust initiative on getting US AI chips and US AI open systems dominated around the globe.\r\n\r\nWhy do we need to move fast? We need to move fast because if we don't, we are looking at another Huawei, another instance where the United States is behind and also saying we should tear out this system that now we don't like for lots of reasons and backdoor policies. So, I'm all for winning. That is why we passed the CHIPS and Science Act. I'm all for winning, and that is why we have passed seven bills out of this committee last year that kind of got stuck in the lame duck. I think the chairman of the committee wasn't ready to move forward in negotiations with the House and Senate on those seven bills. But those bills, a bill between myself and Senator Young on the Institute for Standards, NIST standards, which I think we still need to do; my colleague and I, Moran, on education and scholarships, small business; and the bill by my colleague here, Senators Klobuchar and Thune, which was also related to the NIST standards. So we had an opportunity a year ago to move fast; we didn't do it. So let's do this now. Let's get together and figure this out. The faster the United States moves now, I like this great Paul Romer quote, which was about \"collaboration is the next phase of innovation.\" If we don't collaborate here, if we throw down on politics instead of getting the policy right, we won't move fast. Let's allow these people to do what they do best, and let's make sure the United States has the right policies in place so that our open AI standard wins the day. Thank you, Mr. Chairman.\r\n\r\n**Senator Cruz:** Thank you. I'd now like to introduce our witnesses for today. Each of our witnesses and their companies represent critical parts of the AI infrastructure, hardware, and software supply chain. Our first witness is Sam Altman, the co-founder and CEO of OpenAI. OpenAI is one of the world's most advanced AI companies, known best for its ChatGPT product. Our second witness is Lisa Su, the Chair and CEO of Advanced Micro Devices, AMD. AMD develops high-performance processors, graphic chips, and AI accelerators that power artificial intelligence. And Dr. Su is also a Texan. Our third witness today is Michael Intrator, the CEO and co-founder of CoreWeave, an AI hyperscaler. CoreWeave is the world's largest purpose-built AI cloud platform. And our final witness is Brad Smith, the Vice Chair and President of Microsoft. I believe everyone is familiar with his company. Mr. Altman, you are recognized for your opening statement.\r\n\r\n**Sam Altman:** If you could turn on the volume. Sorry about that.\r\n\r\n**Senator Cruz:** And I do enjoy telling techies how to operate the tech.\r\n\r\n**Sam Altman:** Pretty embarrassing that I couldn't figure that out. Anyway, thank you, Chairman. Thank you, Ranking Member Cantwell. Thank you all, senators and fellow panelists. It's a real honor to be here. I was here about two years ago, and at that time, ChatGPT had recently launched. It was a curiosity in the world. People weren't sure what it was going to mean, what it was going to be used for. Today, we've made significant progress. ChatGPT is used by more than 500 million people a week. I just saw yesterday that, according to SimilarWeb, it's now the fifth biggest website on the internet globally, growing very quickly. But most of all, it's being used in really important ways. It's significantly increasing productivity. We hear scientists say they're two or three times more productive than they could be before. We hear people say they're getting medical advice or learning in ways they couldn't before. And it's really, it's no longer this thing that was going to come in the future, but it's here now, and people are really using it. We're very proud to be one of the leaders of this. We're very proud that America is leading in AI so significantly, and I think that's critical. What Senator Cruz said about the importance of innovation in America and that we have what happened with the internet happen again. I believe this will be at least as big as the internet, maybe bigger. That needs to happen.\r\n\r\nFor that to happen, investment in infrastructure is critical. I believe the next decade will be about abundant intelligence and abundant energy. Making sure that America leads in both of those, that we are able to usher in these dual revolutions that will change the world we live in, I think in incredibly positive ways, is critical. I got to go to Abilene, Texas yesterday, where we're building out what will be the largest AI training facility in the world. It's coming along beautifully. Super exciting to see. We need a lot more of that. There's a whole sort of AI factory, like a supply chain of energy, chips, standing up data centers, building the racks, and more. We've got to do that really well in the US so that we can continue to innovate, continue to lead, and continue to sort of shape this revolution.\r\n\r\nSpeaking of that, I was very inspired by what Chairman Cruz said, so I'd like to deviate from script here and tell a story. In my prepared written testimony, I covered the basics. So, if it's okay, I'd love to tell you a story. I grew up in St. Louis, and I was a computer nerd, and it was the time of the internet boom, and I thought it was the coolest thing ever. We kind of lived in this beautiful old brick house in this suburb of St. Louis, and I lived in the attic, and I had this computer, and I would stay up all night, and I would learn to program, and I got to kind of use the internet, and it was like a crazy time of tons of innovation. All sorts of stuff was happening. It was amazing, and it was all happening here. All the internet companies were in the US. I used a Mac that was built here. I used chips that were started, you know, near where I now live. And I learned about computers. I thought it was the coolest thing ever. And I can draw a straight line from that experience to founding OpenAI and getting to work on companies like Helion. The spirit of American innovation and supportive entrepreneurship, I don't think the internet could have happened anywhere else. And if that didn't happen, I don't think the AI revolution would have happened here. I am a child of the internet revolution. I have the great honor to be one of the parents, of the many parents, of the AI revolution. And I think it is no accident that that's happening in America again and again and again. But we need to make sure that we build our systems and that we set our policy in a way where that continues to happen. I think this is magic. I don't want to live in Europe either. I think America is just an incredible and special thing, and it will not only be the place where the AI revolution happens, but all the revolutions after. I was home visiting St. Louis recently, drove by our old house, and I kind of, it was at night, and I looked up, and in that top floor window, the light was on. And I thought, you know, hopefully, there's some kid in there staying up late at night playing with ChatGPT, figuring out how he or she is going to start whatever company comes next, and whatever the next thing is after AI will happen here too. That is, that is to me, the magic of this country. It's incredibly personally important, and I hope it keeps going. Thank you very much for having me.\r\n\r\n**Senator Cruz:** Thank you. Dr. Su.\r\n\r\n**Dr. Lisa Su:** Chairman Cruz, Ranking Member Cantwell, members of the committee, it is a real honor to be here on such an important topic. I am Chair and CEO of AMD. We are a US-headquartered semiconductor company founded 56 years ago, and we build high-performance computing chips for the modern economy. Every day, billions of people rely on our products and services powered by our technologies. But our chips are also extremely important to support critical missions, including powering defense systems and secure communications, as well as enabling breakthrough scientific research. I have to say, our proudest moments, though, are when we see amazing public-private partnerships, and our work in supercomputing is an example of that. Through more than a decade of partnership with the Department of Energy, AMD now powers the two fastest supercomputers in the world: one that is housed at Oak Ridge National Labs that was put into place in 2021, and the other at Lawrence Livermore National Labs that was just recently put into commission late last year. These systems are really critical from a national infrastructure standpoint and solve many, many large research issues as well as national security and scientific leadership.\r\n\r\nNow, in terms of AI, you know, there's so much that's been stated about AI. I really want to thank Chairman Cruz and Ranking Member Cantwell for having this hearing. I think it is a wonderful opportunity to talk about how we win. AI is truly the most transformative technology of our time. The United States leads today. But what I would like to say is, it is a race. Leadership is absolutely not guaranteed. It's a global race that will shape the outcome of national security and economic prosperity for many decades to come. Now, maintaining our lead actually requires excellence at every layer of the stack. So I'm really honored to be here with my panelists as well. We have deep partnerships with Microsoft and OpenAI that demonstrate how you need silicon, you need software, you need systems, and really the application layer to be successful.\r\n\r\nNow, in terms of what to do, I thought about what would be the most important things to say today, and I put them in, you know, five categories. I think the first and probably the foremost is we must continue to run faster. This is a race, and the race does not stand still. Nobody in the world stands still. We lead today because of the bold decisions that we've made and because of the innovation economy that we have, but we need to continue to run faster, and that means ensuring that we have computing available. I think Sam's story about Abilene is an excellent example of how when you allow the computing infrastructure to expand at the rate and pace that the private sector wants, you actually make tremendous progress.\r\n\r\nI would also like to mention the importance of open ecosystems. I think open ecosystems are really a cornerstone of US leadership, and that allows, frankly, ideas to come from everywhere and every part of the innovation cycle, reducing barriers to entry and strengthening security, as well as creating, frankly, a competitive marketplace for ideas.\r\n\r\nThird, you know, we are very happy to see the focus on a robust domestic supply chain. For us in the semiconductor world, we used to not get so much attention. Now we get a lot of attention, thanks to the importance of chips. And, you know, the fact is, we need more manufacturing in the US. The efforts so far have made good progress, but there's a lot more that can be done and that should be done in public-private partnership.\r\n\r\nFourth, we must invest in talent. You know, frankly, the United States should be the best place to study AI, to work in AI, to really move forward all of the innovations that we need. And I think again, this can also be done in significant public-private partnership.\r\n\r\nAnd then fifth, of course, in the area of export controls, we must, we totally understand as an industry, the importance of national security, and that is, you know, that goes without saying as a US company. But we also want to ensure, as Chairman Cruz and Ranking Member Cantwell stated, it is important to have widespread adoption of US technologies. We lead today because we have the best technology. However, if we're not able to, you know, fully have our technology adopted in the rest of the world, there will be other technologies that will come to play. They may not be as good as we are today, but frankly, usage really spurs innovation. And this is something that we certainly need to work with in public-private partnership.\r\n\r\nAnd I would frankly end by saying, you know, like Sam, I had a computer when I was growing up. I grew up in New York. I'm a little older than Sam, so my first computer was a Commodore 64, and then I graduated to the Apple II. But the fact is, this is the best place to do computing innovation in the world. We want it to stay that way with a really very rich and broad ecosystem. So thank you again for the opportunity to be here today.\r\n\r\n**Senator Cruz:** And I had an Apple II as well, with a shoebox of floppy discs, and somehow I ended up taking a wrong turn and ending up in politics instead. Mr. Intrator.\r\n\r\n**Michael Intrator:** I started out with a Vic 20. Chairman Cruz, Ranking Member Cantwell, and distinguished members of the committee, thank you for the opportunity to testify today. I'm honored to appear alongside my industry colleagues and partners. My name is Michael Intrator. I am the co-founder and CEO of CoreWeave, founded seven years ago. CoreWeave started like many innovative ventures, humbly in a garage, experimenting initially with graphics processing units, or GPUs, for cryptocurrency mining. Recognizing the transformational potential, we pivoted to support powerful AI applications, dramatically scaling the vision and operation. Today, CoreWeave stands at the forefront of America's AI infrastructure revolution, operating more than 30 data centers across 15 states. We manage more than 250,000 GPUs currently, using 360 megawatts of power. Over two short years, our revenue has surged by 12,000%, reaching $1.9 billion in 2024. As a result of this progress, CoreWeave became a publicly traded company on March 28th of 2025. CoreWeave's rapid growth is a testimony not only to the technology but also to the surging global demand for advanced AI infrastructure. Our infrastructure enables American businesses to rapidly translate AI aspirations into impactful economic realities. By empowering companies to accelerate innovation, we're fueling America's competitive edge while improving productivity and prosperity.\r\n\r\nModern AI requires specialized infrastructure, purpose-built computing capabilities that surpass traditional cloud computing in scale and performance. Today's general-purpose cloud was not built to support and scale the complexity of AI workloads. We cannot run a 21st-century economy on 20th-century infrastructure. AI workloads involve trillions of simultaneous calculations, demanding unprecedented computing power, advanced cooling systems, cutting-edge chip technology, ultra-high-speed networks, and accelerated storage. Since 2018, the computing power necessary for advanced AI models has multiplied approximately 100,000-fold. At CoreWeave, our facilities symbolize America's great tradition of innovation. Our data centers, built, maintained, and staffed by skilled American workers, embody how modern technology not only stimulates economic growth and enhances national security but also improves human lives.\r\n\r\nWe are at a critical juncture in the global AI competition. The nation that leads in infrastructure will set the global economic agenda and shape human outcomes for decades. Our largest competitor, China, recognizes the stakes and is expending significant resources to strengthen its position. I want to focus on four elements of policy that will help determine whether the US secures its leadership role in the AI race.\r\n\r\nFirst, strategic investment stability. AI infrastructure is deeply capital-intensive and requires a significant level of coordination across industry stakeholders. Stable, predictable policy frameworks, secure supply chains, and regulatory environments that foster innovation are crucial. Policymakers must provide clear and consistent policy and regulations across all jurisdictions that enable long-term investment and rapid scaling of AI technology.\r\n\r\nSecond, energy infrastructure development. To support the rapid deployment of AI infrastructure, America must ensure abundant and affordable supplies of energy. Careful reforms in permitting and regulatory processes are necessary to accelerate infrastructure projects, facilitate more rapid construction, interconnections, and energy for data centers.\r\n\r\nThird is global market access. Maintaining America's leadership also means ensuring our technology has fair access to global markets. Export controls and trade agreements can be calibrated to both address national security risks and support global diffusion of American AI technology.\r\n\r\nAnd finally, public-private partnerships and workforce development. America's unique advantage in AI is enhanced by our powerful tradition of public-private partnership. CoreWeave is proud to co-found the New Jersey AI Hub with Microsoft, Princeton University, and the New Jersey Economic Development Initiative. Initiatives like this develop critical work skills, foster innovation, and ensure economies and communities are prepared for the AI-driven future. America stands ready to lead the AI revolution, which will bring enormous benefits. It is a rare moment in time that we must meet. If government, industry, and all affected parties work together, the United States can win this race and seize the vast opportunity ahead of us. Thank you again for the opportunity to testify. I look forward to answering your questions.\r\n\r\n**Senator Cruz:** Thank you. Mr. Smith.\r\n\r\n**Brad Smith:** Chairman Cruz, Ranking Member Cantwell, members of the committee, thank you for the opportunity to be here today. Let me just build on what my three colleagues have said and offer a few thoughts. The first is, I just wanted to refer to the chart on this easel that shows the AI tech stack that was also in my written testimony. It makes a simple but, I think, important point: we're all in this together. If the United States is going to succeed in leading the world in AI, it requires infrastructure. It requires success at the platform level. It requires people who create applications. Interestingly, we at Microsoft get to work with all three of these leaders and their companies. Our success, each of our successes, depends on each other's success. And what's true of the four of us is true when you look across the country and around the world at open-source developers, people who are building power plants, electricians, and pipefitters who are going to work every single day.\r\n\r\nSo, what do we need from the Congress and the country in order to succeed? I think it's three things. I described them in my written testimony. First, as Chairman Cruz said, we need innovation. Innovation will go faster with, as Sam said, more infrastructure, faster permitting, more electricians. We need more innovation fueled, as Ranking Member Cantwell said, by support from our universities and the federal agencies that support basic research across the country \u2013 one of this country's crown jewels. We also need, as Chairman Cruz said, faster adoption, what people refer to as AI diffusion: the ability to put AI to work across every part of the American economy to boost productivity, to boost economic growth, to enable people to innovate in their work. And the number one ingredient for that, history shows time and time again, is skilling, investing in education. And finally, we need to export. If America is going to lead the world, we need to connect with the world. We need to remember, I believe, always that as a country, only 4.5% of the world's people live in the United States of America. Our global leadership relies on our ability to serve the world with the right approach to export controls and always, especially in technology, in our ability to sustain the trust of the rest of the world.\r\n\r\nUltimately, I think people who take the time, if they take the time to watch or read about this hearing, may wonder, what is this all about? What are we at this table trying to do? What do these two letters, AI, really mean to them? Are we who are working in this industry trying to build machines that are better than people, or are we trying to build machines that will help people become better? Emphatically, it is and needs to be the latter. Are we trying to build machines that will outperform people in all the jobs that they do today, or are we trying to build machines that will help people pursue better jobs and even more interesting careers in the future? Indisputably, it needs to be the second, not the first. And I believe that is what we are and can do together.\r\n\r\nAs somebody who's now spent almost 32 years in this industry, there are two things that always strike me. The first probably won't surprise you: never underestimate what technology can do, how quickly it can move, what it can accomplish. But the second is one that I think is too seldom discussed, even though every day it stares us in the face: never underestimate what people can do. Never underestimate human ambition. Never underestimate what a person can do if given a better technology tool and the ability to learn how to put it to use. That's the story of this industry. It's the story of the country. It is, as you heard, the story of Sam Altman. Not everybody becomes a Sam Altman or a Satya Nadella or a Bill Gates. Everybody deserves the opportunity to try. Tonight, across America, whether it's the attic of a house or the basement or just an everyday bedroom, there are kids with computers, with phones, with access to the internet, and now the ability to put AI to work. Let's invest in their education. Let's invest in the skills that the American public needs. Let's then invest in creating the future that the American public deserves. Thank you.\r\n\r\n**Senator Cruz:** Well, thank you, witnesses, for your testimony. And I'll start off with the first round of questions and move down the dais to our ranking member here. Thank you for your testimony. It certainly makes me sleep better at night, worried about Terminator and Skynet coming after us, knowing that you guys are behind the wheel. But in five words or less, starting with you, Mr. Smith, what are the five words you need to see from our government to make sure we win this AI race?\r\n\r\n**Brad Smith:** Um, more electricians. That's two words. Broader AI education. And no using ChatGPT as a phone-a-friend.\r\n\r\n**Senator Cruz:** Thank you.\r\n\r\n**Michael Intrator:** I would say that we need to focus on streamlining the ability to build large things.\r\n\r\n**Dr. Lisa Su:** Policies to help us run faster.\r\n\r\n**Sam Altman:** In the innovation race, allow supply chain sensible policy.\r\n\r\n**Senator Cruz:** That was good. So, what I hear there is something pretty similar to the races we've won before. Nuclear energy, for example. You know, the Germans and Austrians really led the innovation around that, but we won the race because we put a massive government effort collaborating with our universities and others to win that race. Space, you know, the Soviets put the first satellite up, put the first man in space, but we won the space race because we adopted a framework to ensure that we won. Aviation, automobiles, etc. So, what I hear from you is you do need support from our government, but you also need the government to stay out of your way so you can innovate and win this race. How do we incentivize companies to do business here in America to make sure we win this race in America, and America leads not just China but other non-state actors too? I mean, I think that the scariest thing about AI from a capability standpoint is it doesn't have to be a state actor to win this race. It's not like nuclear energy. It's not like space technology. I mean, a non-state actor could just as easily win this race and wield more power than anyone else. So how do we encourage innovators, investment to happen here in America to ensure we win this race? Mr. Altman, you want to start?\r\n\r\n**Sam Altman:** We were honored to announce back in January Project Stargate, a $500 billion investment in United States infrastructure. That is now well underway. As I mentioned, getting to see it yesterday in Abilene, the first site was incredible. We need a lot more of that. We need certainty on the ability to build out this entire supply chain, build the data centers, permit the electricity. We'd love to bring chip production here, network production here, server rack production here. And I think the world does want to invest. We have a lot of global investment flowing into the US to do this. We also want to make sure that other countries are able to build with our technology, use our models, and sort of be in our orbit and, you know, use US diffusion of technology here. So that's really important. We need to make sure that the highest skilled researchers that want to come work at US companies can come here and do that. We need to make sure that companies like OpenAI and others have legal clarity on how we're going to operate. Of course, there will be rules. Of course, there need to be some guardrails. This is a very impactful technology, but we need to be able to be competitive globally. We need to be able to train. We need to be able to understand how we're going to offer services and sort of where the rules of the road are going to be. So, clarity there. And I think an approach like the internet, which did lead to flourishing of this country in a very big way, we need that again.\r\n\r\n**Dr. Lisa Su:** I would add, I think computing is a foundation to all of this. We want to have more compute built in the US by US companies and ensure that we have a great environment for that. We want to ensure that our technology around the world is also used broadly and in the right ways. So I think the conversation about export controls and rules should just be simple, easy to follow, easy to enforce, and enable US AI platforms to be the foundation. And then certainly the comments around bringing manufacturing back home and ensuring that we have the right talent base are all extremely important elements of that.\r\n\r\n**Senator Cruz:** Are companies weighing doing business in AI in America versus China? Are the companies making that side-by-side comparison?\r\n\r\n**Dr. Lisa Su:** I think if you look across the world, there are, you know, countries and companies that will ask those questions. You know, if it's hard to obtain US technology, although US technology is the best, if it's hard to obtain, then, you know, there's a hunger for AI, and they will choose what is available. And if China is available, that will certainly be an outcome that we would not like to see.\r\n\r\n**Senator Cruz:** Well, I think I hear the words infrastructure, electricians, universities, regulatory framework, and I think those are things we can help with. I hear words like innovation and talent, and I hear Dr. Su say \"run faster.\" Those aren't things a government can manufacture. We can't manufacture talent. We can't make you run faster, but we can give you the tools to do that. And I think it's time that we create a framework so that you have the tools you need to win this race because you're going to be the ones that win it, not us. Thank you for your testimony. Ranking Member.\r\n\r\n**Senator Cantwell:** Thank you, Mr. Chairman. I'd like to continue that same theme generally about competitiveness. Do we need NIST to set standards? If you could just yes or no and just go down the line.\r\n\r\n**Sam Altman:** I don't think we need it. It can be helpful.\r\n\r\n**Dr. Lisa Su:** Yes.\r\n\r\n**Michael Intrator:** Yes.\r\n\r\n**Brad Smith:** Yes.\r\n\r\n**Senator Cantwell:** Okay. So in the context of what we're talking about here, we're really just talking, I don't know, Mr. Smith or Mr. Intrator or Dr. Su, any of you. The issue here is if we want to move fast, we want to create, just like with electricity, the standards by which we want to move fast here. I would just call it \"code for code\" is what we want, right? We want NIST to do something in the standard setting that will allow us to move much faster. Is that right, either Mr. Smith or Mr. Intrator?\r\n\r\n**Brad Smith:** What I would say is this: First of all, NIST is where standards go to be adopted, but it's not necessarily where they first go to be created. So we've got...\r\n\r\n**Senator Cantwell:** Thank you for that clarity. We're talking about an industry, you know, lots of different organizations, industry input, and then they're adopted. So yes, let's clarify that.\r\n\r\n**Brad Smith:** Let's clarify that. I think that's the way it works. Yes.\r\n\r\n**Senator Cantwell:** And but you think we need to do that, particularly if the United States wants to lead?\r\n\r\n**Brad Smith:** We will need industry standards. We will need American adoption of standards. And you are right, we will need US efforts to really ensure that the world buys into these standards.\r\n\r\n**Senator Cantwell:** Okay. Mr. Intrator?\r\n\r\n**Michael Intrator:** I think it's important that when you're working with standards, what that allows for is a common vocabulary, which allows for acceleration. And so, to the extent that we can step into that role and establish touchpoints where everyone can agree on specific things, that will lead to an acceleration both domestically and abroad. And I don't know if you know, drilling down more on what you think those are, but in general, you know, when I think about the internet and HTTP or HTML or any of the number, TCP/IP, we're talking about things that allowed us to move faster, and getting those standards established helped us do that.\r\n\r\nOn the export issue, Mr. Intrator, the issue of cloud sources shouldn't be left out. If we say, \"Let's go with Malaysia,\" Malaysia is going to tell us that they can certify that there's no diversion of these chips to China, and we basically have a way that we can make sure that this is understood and monitored. Then we also want access, right? We want access by US companies.\r\n\r\n**Michael Intrator:** Yeah, I think Lisa's point was excellent, right? At the end of the day, the world wants to be able to build and deploy artificial intelligence in a very broad way. And if we, you know, nature abhors a vacuum. If we do not step into that role, other technology will step into that role. If it is suboptimal, so be it. It's better to have something that is suboptimal than have nothing.\r\n\r\n**Senator Cantwell:** And so that is what... Well, we don't, we don't want a reoccurrence of a Huawei that develops faster and then has a government backdoor, and then we all have to raise opposition. I'm for a tech NATO. I'm for the five most sophisticated democracies and tech nations setting the rules of the road and saying, \"This is who you should buy from. Don't buy from anybody else who has a government backdoor. Not a good idea.\" So that's how we get leverage. You know, I'm not so hot on the president's tariff agenda for this very reason, because we're not building the alliances, we're creating the enemies. What I want to do is get the supply chain here, get the semiconductor flow here, lower the cost, and go as fast as we can.\r\n\r\n**Michael Intrator:** Yeah, I agree with that. I don't think that that's, I don't think anybody's not going to agree with that, right? I think that's an excellent objective. I just think that what will happen beyond the five NATO companies is that there will be a demand for artificial intelligence, and they will proceed with what they can proceed with.\r\n\r\n**Senator Cantwell:** Dr. Su, what is your view of this, about how we win, how we protect our objectives, but we're more aggressive on the export strategy?\r\n\r\n**Dr. Lisa Su:** Well, I think there is a clear recognition that we need an export strategy. And so having, you know, having this conversation is very important. And from our perspective, the idea is to ensure that our allies, and frankly, I use allies in the very broadest sense, get access to the great American technology that we have with the appropriate controls in place. And I think you can do both. To your earlier comment, Ranking Member Cantwell, about the need to have US technologies in those countries, I think those countries are actually very interested in doing that because we do have the best technology today. And using that to really build this broad AI ecosystem is really our opportunity.\r\n\r\n**Senator Cantwell:** I agree. Thank you so much. The senior senator from Ohio.\r\n\r\n**Senator Vance:** Thank you, Chairman. Make sure Senator Cruz heard that one. So, first of all, thank you for being here and taking the time. If I could, just real quickly, just confirm that I've heard what you said pretty unanimously, which is we need dramatically more power generation in this country. Is that correct? Alright. So, Dr. Su, you just recently did a partnership with TSMC to manufacture your chips here in America. Thank you. I think it's a little bit long overdue. I wish we had done more of that earlier. Those semiconductor fabs, high energy users?\r\n\r\n**Dr. Lisa Su:** Thank you, Senator. We are very pleased with our efforts together with the government on bringing more manufacturing back to the United States. To your question, certainly semiconductor manufacturing plants are high energy users, and we do need more power for both manufacturing as well as for data centers, as you mentioned.\r\n\r\n**Senator Vance:** And without chips, this just doesn't work. Like if we don't have the highest performance chips made here in the United States, this is not going to happen here, correct?\r\n\r\n**Dr. Lisa Su:** We absolutely need the highest performing chips, and we also need the entire ecosystem for chip manufacturing. So wafers are one piece, but there are many other pieces as well.\r\n\r\n**Senator Vance:** And are those chips powered by solar power and windmills?\r\n\r\n**Dr. Lisa Su:** Today they're not, but I think there are opportunities to certainly...\r\n\r\n**Senator Vance:** So, do you think it's outrageous that last year, because of the policies of the Biden administration, that 90% of new power generation in this country was windmills and solar panels, and we absolutely kneecapped American energy? We have a thousand years of natural gas sitting in Pennsylvania, Ohio, and West Virginia, and yet 90% of power generation in this country last year was solar panels and windmills. Does that make this country more competitive or less competitive? Anybody can jump into that one that wants to answer that.\r\n\r\n**Brad Smith:** Let me say two things. One, you're right, we need more electricity. I think our industry, it's worth remembering, is only going to account for 15% of the total additional electricity the country is going to need. We are going to need electricity from a variety of sources. Today in the United States, 56% of our electricity comes from carbon, 44% comes from carbon-free energy, meaning nuclear, wind, or solar. We need a broad-based approach, and we need a diversity of...\r\n\r\n**Senator Vance:** But again, 90% was energy that's not affordable, it's not abundant, and it's not reliable. Let me just shift gears. Mr. Altman, thank you for, first of all, creating your platform on an open basis and agreeing to stick to the principles of nonprofit status. I think that's very important. Do you think that the internet age did a good job between the beginning of the 90s through the 2000s of protecting children?\r\n\r\n**Sam Altman:** I would say not particularly.\r\n\r\n**Senator Vance:** Yeah. And you're a new father, correct?\r\n\r\n**Sam Altman:** Yes.\r\n\r\n**Senator Vance:** Congratulations. He's doing well?\r\n\r\n**Sam Altman:** He is. It's the most amazing thing ever.\r\n\r\n**Senator Vance:** Yeah. I don't think you want your child's best friend to be an AI bot.\r\n\r\n**Sam Altman:** I do not.\r\n\r\n**Senator Vance:** So, what can we do? How can we work together to protect children?\r\n\r\n**Sam Altman:** We've talked a lot about some of the things we're doing here. We're trying to learn the lessons of a previous generation, and you know, that's kind of the way it goes. People make mistakes, and you do it better next time. One thing we say a lot internally is we want to treat our adult users like adults. We want to give them a lot of flexibility. We want to let them use the service with a lot of freedom. And for children, there needs to be a much higher level of protection, which means the service won't do things that they might want. Now, we're still early, so sometimes people say, \"Oh, you're being too strict on the rules.\" And it's just, we can't perfectly tell this. But if we could draw a line and if we knew for sure when a user was a child or an adult, we would allow adults to be much more permissive, and we'd have tighter rules for children.\r\n\r\n**Senator Vance:** So, I think what I would ask is if you could have your team commit to having your teams work with our teams to make certain that we put together the right framework early on. I think that is maybe the best way we can move forward because we don't want to overregulate, but we can't repeat the mistakes of the internet and social media era where children got harmed.\r\n\r\n**Sam Altman:** We'd be delighted to work with you all. It's super important.\r\n\r\n**Senator Vance:** Thank you.\r\n\r\n**Sam Altman:** Can I say one more thing about what you said, this idea of AI and social relationships? I think this is a new thing that we need to pay a lot of attention to. People are relying on AI more and more for life advice, sort of emotional support, that kind of thing. It's a newer thing in recent months, but I, and I don't think it's all bad, but I think we have to understand it and watch it very carefully.\r\n\r\n**Senator Vance:** Alright. Thank you. And thank you for that commitment. It's very appreciated. I've talked to your team already. Good people. Great. Mr. Intrator, real quickly, can you talk about the intersection between the importance of a robust stablecoin ecosystem here in America and how that has a future with payments and how AI will factor into that? Because I don't think people see how this fits into the broader puzzle.\r\n\r\n**Michael Intrator:** So, thank you for the question. And we did start out as a crypto-based company, a hobby that kind of got away from us a little bit. Look, I think that stablecoins, crypto, AI, they share certain DNA in common, which is that they are attempts to build into a future where new technology will make things better for society. And there is a huge potential for us to use stablecoins, crypto, and AI in a combination for better outcomes.\r\n\r\n**Senator Vance:** Alright, thank you. And that was the quickest coup since 1959. Senator Klobuchar.\r\n\r\n**Senator Klobuchar:** Thank you very much, Senator Cruz. A lot of exciting things with AI, especially from a state like mine that's home to the Mayo Clinic, with the potential to unleash scientific research. While we've mapped the human genome and we have rare diseases that can be solved, so there's a lot of positive. But we all know, as you've all expressed, there are challenges that we need to get at with permitting reform. I'm a big believer in that. Energy development, thank you, Mr. Smith, for mentioning this with wind and solar and the potential for more fusion and nuclear, but wind and solar, the price going down dramatically in the last few years. And to get there, we're going to have to do a lot better. I think David Brooks put it the best when he said, \"I found it incredibly hard to write about AI because it is literally unknowable whether this technology is leading us to heaven or hell.\" We want it to lead us to heaven, and I think we do that by making sure we have some rules of the road in place so it doesn't get stymied or set backwards because of scams or because of use by people who want to do us harm.\r\n\r\nAs mentioned by Senator Cantwell, Senator Thune and I have teamed up on legislation to set up basic guardrails for the riskiest non-defense applications of AI. Mr. Altman, do you agree that a risk-based approach to regulation is the best way to place necessary guardrails for AI without stifling innovation?\r\n\r\n**Sam Altman:** I do. That makes a lot of sense to me.\r\n\r\n**Senator Klobuchar:** Okay, thanks. And did you figure that out in your attic?\r\n\r\n**Sam Altman:** No, that was a more recent...\r\n\r\n**Senator Klobuchar:** Just thank you. Very good. Just want to make sure. Our bill directs, Mr. Smith, the Commerce Department to develop ways of educating consumers on how to safely use AI systems. Do you agree that consumers need to be more educated? This was one of your answers to your five words, so I assume you do.\r\n\r\n**Brad Smith:** Yes. And I think it's incumbent upon us as companies and across the business community to contribute to that education as well.\r\n\r\n**Senator Klobuchar:** Okay, very good. Back to you, Mr. Altman. Americans rely on AI, as we know, increasingly on some high-impact problems. To make them be able to trust that, we need to make sure that we can trust the model outputs. The New York Times recently reported earlier this week that AI hallucinations \u2013 new word to me \u2013 where models generate incorrect or misleading results, are getting worse. That's their words. What standards or metrics does OpenAI use to evaluate the quality of its training data and model outputs for correctness?\r\n\r\n**Sam Altman:** On the whole, AI hallucinations are getting much better. We have not solved the problem entirely yet, but we've made pretty remarkable progress over the last few years. When we first launched ChatGPT, it would hallucinate things all the time. This idea of robustness, being sure you can trust the information, we've made huge progress there. We cite sources. The models have gotten much smarter. A lot of people use these systems all the time, and we were worried that if it was not 100%, you know, 0% accurate, which is still a challenge with these systems, it would cause a bunch of problems. But users are smart. People understand, you know, what these systems are good at, when to use them, when not. And as that robustness increases, which it will continue to do, people will use it for more and more things. But we've made, as an industry, we've made pretty remarkable progress in that direction over the last couple of years.\r\n\r\n**Senator Klobuchar:** Well, I know we'll be watching that. Another challenge that we've seen, and Senator Cruz and I worked on a bill together for quite a while, and that's the Take It Down Act. And that is that we are increasingly seeing internet activity where kids looking for a boyfriend or girlfriend, maybe they put out a real picture of themselves, it ends up being distributed at their school, or somehow someone tries to scam them for financial gain. Or it's AI, as we've increasingly seen, where it's not even someone's photos, but someone puts a fake body on there. And we've had about over 20 suicides in one year of young people because they felt like their life was ruined because they were going to be exposed in this way. So this bill we passed through the Senate and the House, the First Lady supported it, and it's headed to the President's desk. Could you talk about how we can build models that can better detect harmful deepfakes, Mr. Smith?\r\n\r\n**Brad Smith:** Yeah, I mean, we're doing that. OpenAI is doing that. A number of us are. And I think the goal is to, you first identify content that is generated by AI, and then often it is to identify what kind of content is harmful. And I think we've made a lot of strides in our ability to do both of those things. There's a lot of work that's going on across the private sector and in partnership with groups like NCMEC to then collaboratively identify that kind of content so it can be taken down. We've been doing this in some ways for 25 years since the internet, and we're going to need to do more of it.\r\n\r\n**Senator Klobuchar:** And on the issue, last question, Mr. Chair, since the last one was about your bill, I figured it's okay. The newspapers, and you testified before the Senate Judiciary Committee, Mr. Smith, about the bill Senator Kennedy and I had. I still think that there's an issue here about negotiating content rates. We've seen some action recently in Canada and other places. Can you talk about those evolving dynamics with AI developers and what's happening here to make sure that content providers and journalists get paid for their work?\r\n\r\n**Brad Smith:** Yeah, it's a complicated topic, but I'll just say a couple of things. First, I think we should all want to see newspapers in some form flourish across the country, including, say, rural counties that increasingly have become news deserts, newspapers have disappeared. Second, and it's been the issue that we discussed in the Judiciary Committee, there should be an opportunity for newspapers to get together and negotiate collectively. We've supported that. That will enable them to basically do better. Third, every time there's new technology, there is a new generation of a copyright debate. That is taking place now. Some of it will probably be decided by Congress, some by the courts. A lot of it is also being addressed through collaborative action. And we should hope for all of these things to, I'll just say, strike a balance. We want people to make a living creating content, and we want AI to advance by having access to data.\r\n\r\n**Senator Klobuchar:** Okay, thanks. I'll ask other questions on the record. Thank you, Mr. Chair.\r\n\r\n**Senator Cruz:** Thank you. You know, Senator Klobuchar asked whether AI will lead us to heaven or hell. It reminded me of a famous observation by Yale law professor Grant Gilmore that in heaven there is no law, and the lion will lie down with the lamb. In hell, there is nothing but law, and due process is meticulously observed. Let me ask you this, and this is to each of the four witnesses: In the race for AI, who's winning, America or China? If the answer is America, how close is China to us, and what do we do to make sure the answer remains America will win? Mr. Altman, we'll start with you.\r\n\r\n**Sam Altman:** It is our belief that the American models, including some models from our company, OpenAI, and Google and others, are the best models in the world. It's very hard to say how far ahead we are, but I would say not a huge amount of time. And I think to continue that leadership position and the influence that comes with that, and all of the incredible benefits of the world using American technology products and services, the things that my colleagues have spoken about here: the need to win in infrastructure, sensible regulation that does not slow us down, the sort of spirit of innovation and entrepreneurship that I think is a uniquely American thing in the world. None of this is rocket science. We just need to keep doing the things that have worked for so long and not make a silly mistake.\r\n\r\n**Dr. Lisa Su:** I'll answer in the realm of chips. I would say America is ahead in chips today. We have the best AI accelerators in the world. I think China, although they have restrictions given their ability to use advanced technologies, the one thing that's very important for us all to remember is there are multiple ways to do things. You know, having the best chips is great, but even if you don't have the best chips, you can get a lot done. So I think this conversation about how far behind China is, they are certainly catching up because there are many ways to do things. I think relative to what we can do, I will continue to say, really ensure that our spirit of innovation is allowed to work, and that is having very supportive government policies to do that, having very consistent policies, and allowing us to do what we do best, which is innovate at every layer of the stack.\r\n\r\n**Michael Intrator:** So, I'll speak to it from the physical infrastructure and software stack to deliver that. America is ahead, but it is the Achilles' heel from the perspective of the ability, as I started to say better, sorry about that. So, the ability to build very large solutions to the computing infrastructure component of this is an area that we're going to struggle with from a permitting and building large projects to be able to deliver the power to allow those building artificial intelligence to continue to move as fast as they can in the race that we're in.\r\n\r\n**Brad Smith:** I think the United States has a lead today in what is a close race, and a race that will likely remain close. The number one factor that will define whether the United States or China wins this race is whose technology is most broadly adopted in the rest of the world. This is a global market, and it will be defined, as technology markets typically are, by network effects. 18% of the people in the world live in China, 4% live in the United States, 78% live somewhere else. The lesson from Huawei and 5G is whoever gets there first will be difficult to supplant. We need to export with the right kinds of controls. We need to win the trust of the rest of the world. We need to have the financial architecture that gets not only to the countries that are industrialized but the nations, say, across Africa, where typically China and Huawei have done so well.\r\n\r\n**Senator Cruz:** So, some of my colleagues have made reference to standards as something that is desirable, and I will say standards is often a code word for regulations. And indeed, the EU's stifling standards concerning the internet is what killed tech in Europe. We are seeing now state legislatures mimicking the EU, such as California's SB 1047, which thankfully was overwhelmingly defeated but would have created essentially a California DMV for AI model registration. How harmful would it be to winning the race for AI if America goes down the road of the EU and creates a heavy-handed, prior approval, government regulatory process for AI?\r\n\r\n**Sam Altman:** I think that would be disastrous. To give a more specific answer to your previous question, which I think touches on why it would be so bad, there are three key inputs to these AI systems. There's compute, all the infrastructure we're talking about. There's algorithms that we all do research on. And there's data. If you don't have any one of those, you cannot succeed in making the best models. And as Brad said, the way for America to influence the world here is to have the technology that people most want to use and most adopt. The world uses iPhones and Google and Microsoft products, and that's wonderful. Like, that's how we have our influence. We don't want that to stop happening. So, systems that stop us on any of these areas, you know, if we have rules about what data we can train on that are not competitive with the rest of the world, then things can fall apart. If we are not able to build the infrastructure, and particularly if we're not able to manufacture the chips in this country, the rules can fall apart. If we can't build the products that people want that naturally win in the market, and I think people do want to use American products, we can make them the best. But if we're prevented from doing that, people will use a better product made from somebody else that doesn't have the sort of, you know, that is not stymied in the same way. So, I am nervous about standards being set too early. I'm totally fine, you know, with the position some of my colleagues took that standards, once the industry figures out what they should be, it's fine for them to be adopted by a government body and sort of made more official. But I believe the industry is moving quickly towards figuring out the right protocols and standards here, and we need the space to innovate and to move quickly.\r\n\r\n**Senator Cruz:** So if each of you could briefly answer that question, because my time's expired, so I want to be respectful of that.\r\n\r\n**Dr. Lisa Su:** I agree with the comments of Sam.\r\n\r\n**Michael Intrator:** I agree, and I would just say, and I think the point you're making is we have to be very careful not to have these pre-approval requirements, including at state levels, because that would really slow innovation in the country.\r\n\r\n**Brad Smith:** I think that a patchwork of regulatory overlays will cause friction in the ability to build and extend what we're doing.\r\n\r\n**Senator Cruz:** Thank you. Senator Schatz.\r\n\r\n**Senator Schatz:** Sorry, apologies. No problem, Chairman. Thank you for being here. I just want to follow up on the Chairman's question, and it may be an emerging consensus on the committee. Okay, I don't think there's anybody, even on this side of the dais, that's proposing a sort of European-style pre-approval. I think there are some people who would like to do nothing at all in the regulatory space, but I think most people understand that some guardrails \u2013 those are the words that you used, Mr. Altman \u2013 rules and guardrails, are necessary. Are you saying that self-regulation is sufficient at the current moment?\r\n\r\n**Sam<y_bin_46>:** No, I think some policy is good. I think it is easy for it to go too far. And as I've learned more about how the world works, I'm more afraid that it could go too far and have really bad consequences. But people want to use products that are generally safe. You know, when you get on an airplane, you kind of don't think about doing the safety testing yourself. You're like, \"This is...\" Well, maybe this is a bad time to use the airplane example. But you kind of want to just trust that you can get on.\r\n\r\n**Senator Schatz:** It's an excellent time to use the airplane example. But I think your point is exactly right, is that, look, there is a race, but we need to understand what we're racing for, right? And it also has to do with American values. It's not just a sort of commercial race so we can edge out our near-peer competitor, both in the public sector and the private sector. We're trying to win a race so that American values prevail internationally. Mr. Smith, I want to move on to another topic. It seems to me that on the consumer side, that one of the most basic rights of a user on the internet is to understand what they're looking at or listening to, and whether or not it was created solely by a person, a person using an AI, or automatically generated using AI. Do you think a labeling regime, not a prohibition on the use of AI, but just the disclosure, especially as it relates to images, music, creativity, do you think a label would be helpful for consumers?\r\n\r\n**Brad Smith:** Generally, yes. And I think that's what we in the industry have been working to create. I think you're right to make the distinction and focus especially on, say, images, video, audio files. There's a standard called C2PA that we and a number of companies now have been advancing. It has content credentials. It enables people to know where something was created, who created it, and I think you're right, to know whether it was created by a person, by AI, or a person with the help of, say, AI.\r\n\r\n**Senator Schatz:** I just want to use sort of common language, not the language that all of you use or that we've all learned to use. When you talk about the data as one of the three elements that makes a model work, data really is intellectual property. It is human innovation, human creativity. And I'm, I do think we may have a disagreement, and I agree with Senator Klobuchar about the need to understand that these models have been trained on data, but what we're really talking about is human achievement all the way up to now. And I have a deep worry. Look, I'm actually an optimist in the energy space and the public service space. Certainly in health innovation, there are a lot of really exciting opportunities here. But we got to pay people for their knowledge. And I am concerned that these models are going to be so successful in spitting out what appears to be knowledge that we're going to, on the back end, not pay people for all of the inputs, and we will have a sort of stalling out of these models. And you talked about a tension, but I'm trying to figure out what the tension really is, other than you'd like to pay as little as possible for these inputs. Go ahead, Mr. Smith.\r\n\r\n**Brad Smith:** Well, I, you had me until the last sentence.\r\n\r\n**Senator Schatz:** I know. Hey, look, we create intellectual property. We respect intellectual property. So we're emphatically of the view that intellectual property and the creation of it should be rewarded. Ultimately, intellectual property laws are always about drawing the line. It's really the line that you referred to. In copyright, there is expression that is protected. If you write a book and somebody copies it, then you are entitled to be paid. But there are ideas. If someone reads your book, if someone remembers that, you know, Shakespeare wrote a story about two teenagers who fell in love, then that's fair use.\r\n\r\n**Senator Schatz:** Then that, that's fair use. That's, that's why this country created it. That's what we need to focus on. With your permission, Chairman, I want to ask one final question.\r\n\r\n**Senator Cruz:** Proceed.\r\n\r\n**Senator Schatz:** Thank you. I'm actually quite excited about the prospect that in 20 years, people are going to say, \"Remember when you had to wait on the phone to talk to Kaiser Permanente or the VA?\" So I, just maybe Mr. Altman and Mr. Smith, I want you to, you know, a buddy of mine used to say, \"Paint a picture and paint me in it.\" Okay, for the government actually delivering services, I want you to describe what an AI agent or AI can do to kind of reduce those pain points that we accept as a fact of life in interacting with the government. It seems to me so much of what makes us irritated with the government is the lack of sorting data that exists somewhere, but we can't get access to it. So just very quickly, you have 15 seconds each for some cheerleading.\r\n\r\n**Sam Altman:** I can imagine a future where the US government offers an AI-powered service that makes it really easy to use all government services, to get great healthcare, to get great education. You have this thing in your pocket, and if you have any medical problem, you get an answer. If you need to, you know, appeal something on some processing with the government or file your taxes or whatever, you just do it instantly. You have an agent in your pocket fully integrated with the United States government, and life is easy.\r\n\r\n**Brad Smith:** Anything to add? Remember when you had to stand in line to renew your driver's license? Remember when you didn't know how to report a pothole that needed to be repaired on your street? Remember when you had a fender bender in a car and you had to fill out all these forms and talk to all these people to get insurance coverage? Now you can do it all with one AI system. You can use your phone. And by the way, you can do this today in Abu Dhabi. We need to bring it to America.\r\n\r\n**Senator Schatz:** Thank you.\r\n\r\n**Senator Budd:** Thank you, Chairman. Again, thank you all for being here. I've enjoyed various conversations with each of you. The ability for the US to deploy new energy generation capacity and upgrade its grid is, in many ways, the key to the race against China. Energy is how we can win, and it's also how we can lose. Permitting in this country, it takes too long. China's command and control system means that they will not fail to deploy the energy needed to achieve the scale necessary to develop the most advanced models, which will drive all to the benefit of AI. So I'm glad to be working with Senator Lummis on the FREE Act, which would set up a permit-by-rule structure, which would let large projects meet comprehensive standards at the front end instead of being dragged out on a case-by-case process. We all want to protect the environment, and we all want to maintain US economic and technological leadership. So, Mr. Intrator, what has CoreWeave's experience been in contracting power, and are you concerned that the current permitting system can make it hard for the US to achieve capital investment and the scale needed to win this AI race?\r\n\r\n**Michael Intrator:** So, as you said, access to power, access to scale power, is certainly one of the keys to our ability to win this race. There are others, but it is one that I spend a lot of time thinking about. I separated the comment into access to power and access to scale power because I do think that we are moving towards a period of this race where the size, the magnitude of the infrastructure that is being required to move our artificial intelligence, the labs that are building it, the companies that are building it forward at the velocity that's necessary, is going to be a specific challenge that really requires a lot of thought. We have a huge part of our organization focused on not just getting access to power, but getting access to the size and scale of power that's going to be able to build the infrastructure, you know, at the scale of Abilene or close to it, in order to, you know, allow this to move forward. It's tough, right? And it will get harder as we move through time because the existing infrastructure that does have opportunities, it has some level of elasticity, is going to be consumed. And once that is consumed, you're going to get down to kind of a first principle: how do we get power online now? And that's really going to be challenging within the regulatory environment as it currently is configured.\r\n\r\n**Senator Budd:** Thank you. Mr. Smith, a similar question. How is Microsoft trying to secure power for its data centers? I mean, we read about that in the news recently, but what does federal policy need to focus on to make sure that we don't lose this race because we can't get enough energy?\r\n\r\n**Brad Smith:** Well, we invest to bring more electricity generation onto the grid and then to bring it through the grid to our data centers. We probably have more permitting applications in more countries than quite possibly any company on the planet. Last time I looked at it, it was 872 applications in more than 40 countries. The number one challenge in the United States when it comes to permitting, interestingly enough, is not local, it's not state, it is the federal wetlands permit that is administered by the Army Corps of Engineers. We can typically get our local and state permits done in about 6 to 9 months. The national, the wetlands permit, is taking often 18 to 24 months. Both the outgoing Biden administration and the incoming Trump administration have focused on this. But if we could just solve that, we could accelerate a lot here in this country.\r\n\r\n**Senator Budd:** Very helpful. Thank you. Mr. Altman, much has been made about the Chinese open-source models like DeepSeek. We spoke about that a month or two ago. A concern that I have is that accessible Chinese models promoted by the Chinese Communist Party might be an attractive option for AI application developers to build on top of, particularly in developing world economies. So how important is US leadership in either open-source or closed AI models?\r\n\r\n**Sam Altman:** I think it's quite important to lead in both. We realize that we at OpenAI can do more to help here, so we're going to release an open-source model that we believe will be the leading model this summer because we want people to build on the US stack. In terms of closed-source models, a lot of the world uses our technology and the technology of our colleagues. We think we're in good shape there.\r\n\r\n**Senator Budd:** So how could federal policy further help encourage the AI ecosystem to be developed right here in the US?\r\n\r\n**Sam Altman:** Well, you touched on a great point with energy. I think it's hard to overstate how important energy is to the future here. Eventually, chips, network gear, that will be made by robots, and we'll make that very efficient, and we'll make that cheaper and cheaper. But an electron is an electron. Eventually, the cost of intelligence, the cost of AI, will converge to the cost of energy. And if it'll be, how much you can have, the abundance of it will be limited by the abundance of energy. So, in terms of long-term strategic investments for the US to make, I can't think of anything more important than energy. Yeah, you know, chips and all the other infrastructure also. But energy is where this, I think, this ends up.\r\n\r\n**Senator Budd:** Thank you, Chairman.\r\n\r\n**Senator Kim:** Yeah, thank you. Mr. Smith, I think I'd like to start with you because I thought your point about what exactly is the race, right? You keep talking about the race, and you framed it in a particular way, saying that it's about adoption in the rest of the world, the 78%. I guess I just wanted to ask you to tease that out some more in terms of understanding what role we could play in Congress, in government, in terms of trying to accelerate and champion that AI adoption internationally.\r\n\r\n**Brad Smith:** I think there are two things. The first is, it just shines a light on the importance of getting it right for export controls. Yeah. Which is the AI diffusion rule that's being discussed right now. And I think what it shows is we want to have, I believe as a country, the kinds of national security controls that ensure that, say, chips don't get diverted to China or get accessed by the wrong users, say in China, for the wrong reasons. And that is something that people have drafted at the same, in the Department of Commerce. At the same time, we need, I believe, to, say, get rid of the quantitative caps that were created for all of these Tier 2 countries because what they did was send a message to 120 nations that they couldn't necessarily count on us to provide the AI they want and need. And just think about it. I mean, if this is a critical part of your country's infrastructure, how can you make a bet on suppliers if you're not confident that they'll be able to fulfill your needs? So I think you in Congress and the Senate can help the White House and the Department of Commerce get this right.\r\n\r\n**Senator Kim:** Mr. Altman, I wanted your thoughts on this. Is that the right framing of the race? Is it about the adoption internationally in terms of other countries? I guess I'm trying to think through it. Like, part of what you just said in your previous response was that we want other nations to be able to build upon the US AI stack. Is that the right framework? Is that what we're thinking about? Or is it more about the consumer? Is it more about getting the rest of the world and the 78% of the population to adopt AI applications that are US-based, or is it interrelated?\r\n\r\n**Sam Altman:** I think it's heavily interrelated. To me, the stack is, you know, from the chips at the bottom to the applications on the top, and we want the whole world on the US stack. We want them to use US chips. We want them to use services like ChatGPT.\r\n\r\n**Senator Kim:** Does having other nations building on the infrastructure component of the stack, does that more or less guarantee, or at least have a high likelihood, that then the consumers in that country will be using our products and applications? Is that the sort of theory of the case?\r\n\r\n**Sam Altman:** It probably does make it marginally more likely, but I also think if someone's using a stack that we don't trust to train models, like, who knows what it's going to do? Who knows what sort of backdoors would be possible? Who knows what sort of, you know, data corruption issues could be possible? I think the AI stack is increasingly going to be a jointly designed system from the chip all the way up to the end consumer product, and, you know, lots of stuff in between. I think separating that won't work that well in practice. And we shouldn't want to, like, again, I think this point, this is a very critical point, that the leverage and the power the US gets from having iPhones be the mobile device people most want and Google being the search engine that people most want around the world is huge. We talk maybe less about how much people want to use chips and other infrastructure developed here, but I think it's no less important, and we should aim to have the entire US stack be adopted by as much of the world as possible.\r\n\r\n**Senator Kim:** Yeah. I mean, when we are looking at, you're talking about our investment into models and building of that nature, how are we doing in terms of development of the applications, the AI tools and applications, though, that are trying to embed in people's lives, you know, not necessarily just the overarching models? But do you feel like we're putting the level of intensity that we need to in terms of that type of development?\r\n\r\n**Sam Altman:** ChatGPT is the most adopted AI service in the world, not just in the United States, but in the world, by a quite significant margin. We're very proud that people like it. And we need to keep pushing on that. And I think it's important for all the reasons you just discussed. There are many other US companies building incredible products and services that are also getting globally adopted. This is what the US does best.\r\n\r\n**Senator Kim:** Yeah. Dr. Su, I want to just ask one last point to you. You, over and over again, each of you is talking about talent as this incredible power but also could be a bottleneck to us. How are we doing when it comes to development of talent in this country? If you were to give us a grade, what would you grade us at in terms of our development right now?\r\n\r\n**Dr. Lisa Su:** Thank you, Senator, for the question. Look, I think the smartest engineers are in the United States. We have a great base of talent. But what I will say is, we need more. We need more hardware developers, software developers, applications.\r\n\r\n**Senator Kim:** How wide is that delta? If we're talking about this as a race, as you did, you know, is that a space where we have a larger amount of delta, or is that a place where it's closing rapidly too?\r\n\r\n**Dr. Lisa Su:** Well, I think we do have a very talented, you know, overall talent base, but we also have the desire to have the best. And that includes not only, you know, US nationals, but also having the best, you know, international students, drawing the talent from that.\r\n\r\n**Senator Kim:** That's right.\r\n\r\n**Dr. Lisa Su:** I think high-skilled immigration is one of those areas where we want the best people in the world to be doing their work in the United States. And Senator, if I can just add something to your previous point about the cycle and what race we're trying to win. You know, technology is one of those things where you can have a very vicious positive cycle. So, in other words, when we lead and more people adopt, that means more developers that make our technology better, that increases our lead. So that's what we want, is to have our leadership just increase over time.\r\n\r\n**Senator Schmitt:** Thank you, Mr. Chairman. Mr. Altman, I'll start with you. I really enjoyed and was inspired by your story with the light on in the home you grew up in in St. Louis, and you talked about the spirit of innovation. That is the spirit of St. Louis, as a fellow St. Louis native. That's a good story to hear, and we just look forward to more investment in St. Louis from your company. That'd be great too. So I'll put a plug in for that. But I do want to ask you specifically, there's a lot made of sort of the comparison between the United States and the regulatory environment and what exists in Europe. What specifically, and I'll open this up to others, what specifically has gone wrong in Europe that we can draw some conclusions from?\r\n\r\n**Sam Altman:** First of all, we'd love to figure out how to invest more in St. Louis. I'd love an excuse to get to go home more often. I'll point out one example that I think is just very painful to users. When we launch a new feature or a major new model, we have what is now considered a little bit of an in-joke where we say, \"We have this great new thing, not available in the EU and a handful of other countries,\" because they have this long process before a model can go out. And there will be, I believe, great models and services that are quite safe and robust that we will be unable to offer in other regulatory regimes. And if you are trying to be competitive in this new world, and if you are consistently some number of months behind what other people in other countries get access to, that's an example that's extremely painful to users.\r\n\r\n**Senator Schmitt:** And you mentioned sort of your observation that the AI stack may get more vertically integrated. So how does that work then? Because right now, the best estimates, I suppose, right, is that, I don't know, China's two months to six months behind maybe on large language models. Hopefully, some of the advances we're seeing in the US, maybe there's a degree of separation. It's hard to know exactly, right, with DeepSeek. But then you get down to the chips, and that advantage is more like a couple of years, probably something like that. So if that's where we're headed, does that increase the US's advantage in your view, or does that sort of allow China to catch up quicker as we get more vertically integrated?\r\n\r\n**Sam Altman:** I think there's a lot of things that can increase US leadership, but we touched on this earlier, I think it's so important. There will be great chips made around the world. There will be great models trained around the world. If the United States companies can win on products and the sort of all of the positive feedback loops that come from how you can improve this once you know real users are using your products in their daily lives for their hardest tasks, that is something special that is not so easy to catch up with just by doing good chips and good models. So making sure that the US can win at the product level here, obviously, I'm talking my book a little bit, but I really do believe it is quite important. And that's in addition to all of the chips, infrastructure, algorithms, and data. I think this is a new area where the US is really winning and has a very strong compounding effect.\r\n\r\n**Senator Schmitt:** Thanks. Mr. Intrator, did I pronounce that correctly, by the way?\r\n\r\n**Michael Intrator:** Yep.\r\n\r\n**Senator Schmitt:** Okay, thank you. I want to turn a little bit, sort of staying on this regulatory environment. One of the things I think that's most concerning that's coming out of Europe is this sort of censorship regime that exists, not just online, but in real life. I mean, people are being arrested for things that they say online. And one of the concerns I have with AI, I suppose, is that if we end up with a place where it's somehow policing, quote-unquote, \"misinformation,\" and you know, I think even in NIST's most recent voluntary standards, one of the risks to be on the lookout for was the spread of misinformation. So the point of the question is, how do we make sure that, I think part of what's going wrong in Europe is it's a sort of a funneling of information, and in my view, whether I agree with the point of view or not, it ought to be out there. People can make their own decisions. You combat speech you don't agree with not by censoring it, but by with more speech. What are some lessons to be learned there and make sure that does not happen here?\r\n\r\n**Michael Intrator:** So, Europe is moving forward with its regulatory regime in a European way. And from our seat, where we have to make these enormous capital investments, one of the things about the approach that Europe is taking that we are deeply concerned about every day is the balkanization, to use, of how they go about allowing information to flow and how they go about regulating and how they go about with each component of their union having its own set of rules, which will be tremendously challenging in Europe as time goes on because it is really hard to make the magnitude of investments that we...\r\n\r\n**Senator Schmitt:** Beyond that, though, jurisdictionally, I'm talking about content now.\r\n\r\n**Michael Intrator:** Yeah, so we're not, our, the role of our company is really kind of below that. You know, and Sam and Microsoft, you're going to get a lot more attention paid to the content level because of the role that they play in the stack. It's not really where we are primarily focused. We're really focused on the investment side of it.\r\n\r\n**Senator Schmitt:** Yeah. If any of you would like to, Sam, if you or Mr. Altman, if you would like to respond to that, I'd like to get some answer.\r\n\r\n**Sam Altman:** I think, well, first of all, I strongly agree that people getting, you know, put in jail for stuff they say online is very not American, not what we should be doing. The AI is quite different than social media, at least in its current evolution. People are using these tools in a sort of one-on-one way instead of this massive thing online. So I think it's easy to make too many analogies, but it's a little bit dangerous to try to talk about AI and the things we're going to face here in the same way that we did for social media. But our stance is that we need to give adult users a lot of freedom to use AI in the way that they want to use it and to trust them to be responsible with the tool. And I know there's increasing pressure in other places around the world, and some in the US, to not do that. But I think this is like, this is a tool, and we need to make it a powerful and capable tool. We will, of course, put some guardrails in, very wide bounds. But I think we need to give a lot of freedom.\r\n\r\n**Senator Schmitt:** Yeah, I'm out of time, but there's a lot more questions there that we'll follow up with. Thank you.\r\n\r\n**Senator Hickenlooper:** Madam Chair, thank you. Senator Hickenlooper, I appreciate that line of questioning. I was ready for you to continue as well. I could have given you a minute or two. Mr. Smith, Microsoft has a long and deep history in transforming workplaces all over the world through software, from Windows operating system to its Office applications like PowerPoint, Excel, and now the AI-powered Copilot application. In software development, life cycles seem to be becoming increasingly shorter, updates becoming more frequent. What are the internal processes that Microsoft follows to evaluate Copilot's accuracy and performance before it was released, and what kind of independent review teams, other than Microsoft's own product developers, are involved in that? How, who do you bring in to help with that?\r\n\r\n**Brad Smith:** Well, first of all, since most of what we're talking about here, when you're talking about our Copilots, start with models that are developed at OpenAI, I would say OpenAI has its internal process. There is then a joint, what's called a DSB, a Deployment Safety Board, where we decide together whether something is safe to deploy, as the name implies. We then, at the applications level, have our own internal deployment safety board. We have a variety of engineering tools that we use to assess these features. We test these features. We have red teams, meaning sort of competing teams that often go to work to sort of attack the features. And then ultimately, the product is released when those tests are completed and the results are satisfactory.\r\n\r\n**Senator Hickenlooper:** Good, I like that. Well, let me go over to Mr. Altman. Obviously, you all have a natural incentive to ensure that the products are high quality and safe, but the field is so competitive. And, you know, in applied research and with rigorous testing, these constant improvements really are fundamental steps to the performance of a model. So risk assessments are that key tool. And I'm a big believer in evidence-based technical standards. I've been accused of being the only real scientist who's published peer-reviewed papers in the Senate. So, Mr. Altman, do you believe that under appropriate circumstances, independent evaluations based on standards, performed by qualified evaluators, and done voluntarily, could help validate the testing that you're performing internally and in conjunction with peer companies?\r\n\r\n**Sam Altman:** Thank you, Senator. And I think it's awesome that you have published peer-reviewed papers and would love to see more of that.\r\n\r\n**Senator Hickenlooper:** Well, listen, I was on the Maslow's triangle of science. I was near the bottom. I was a geologist, so that's, you know, not high up in that.\r\n\r\n**Sam Altman:** Geology is great. Yes, I think what you say is very important. It's an important part of our process today. External testing helps us find things that we may have missed internally. And as we're, we're very proud of our safety record on the whole. Not that we, you know, we've not been perfect, and we're continuing to learn new things, but I think we do have a process that is leading towards models that the public generally thinks are safe and robust to use. And we've developed a lot of techniques to be able to continue to deliver that. But external testers and red teamers are a critical part of that process, and I think they've helped us find many things in the models to improve.\r\n\r\n**Senator Hickenlooper:** And Mr. Smith, would you add anything to that?\r\n\r\n**Brad Smith:** No.\r\n\r\n**Senator Hickenlooper:** Okay, got it. Someone giving testimony who doesn't have something to add, that's a moment of scientific reflection. Dr. Su, the bipartisan CHIPS and Science Act, a historic effort to try and maintain US leadership in emerging technologies like semiconductors, but others as well. As the technology arms race continues globally, and you were talking about this, AMD plays a key role in delivering state-of-the-art designs, the best, for the new chips that are going to power electronics and the devices that are going to allow AI to become global. As scientists work around the clock to develop new breakthroughs and to try and increase and improve performance, but at the same time shorten R&D timelines, what do you see as the next frontier of chip technology in terms of energy efficiency, and how, and this not just based on the Chinese competitors, but how can we work together to improve direct-to-chip cooling for high-performance computing?\r\n\r\n**Dr. Lisa Su:** Well, thank you for the question, Senator. I would say, look, there is a tremendous amount of innovation that's going on in the semiconductor sector today. The CHIPS and Science Act was certainly helpful in raising the profile of chips in the United States. Relative to, you know, what are we doing to go faster and build better and more power-efficient chips, frankly, we're using AI extensively through our chip development cycles, and it does allow us to augment what are typically very long cycles, many years, several years for us to develop chips. We can shorten the time and also improve the efficiency. And there are lots and lots of great new technologies in terms of cooling technologies that are super important for us to build the large-scale systems that we talked about earlier today. So thank you for the question.\r\n\r\n**Senator Hickenlooper:** You bet. Alright, I'm out of time. I'll yield back to the chair.\r\n\r\n**Senator Cruz:** Thank you all. And Senator Hickenlooper, I will say, as a Texan whose parents were in the oil and gas business, I think geologists are awesome. We have a consensus. Senator Curtis.\r\n\r\n**Senator Curtis:** Thank you, Mr. Chairman. It's a delight to be here. Mr. Altman, I, you started kind of a one-upmanship on computers, and I will just tell you, in 1985, the month you were born, I was attending a class at Brigham Young University and carried in a laptop and was almost kicked out.\r\n\r\n**Sam Altman:** What laptop?\r\n\r\n**Senator Curtis:** It was a TRS-80.\r\n\r\n**Sam Altman:** Oh, awesome.\r\n\r\n**Senator Curtis:** Made by Radio Shack. I upgraded the memory from 4K to 8K. Ran on four AA batteries. And incredible. Yeah. So I'm very envious of your generation. Let me start with you, if I would. I think, you know, Utah would aspire to lead out with data centers and advanced technologies. Could you just address for states, and in Utah specifically, what it is that makes them attractive to projects like Stargate?\r\n\r\n**Sam Altman:** Yeah, and I know that we're having productive discussions about some potential sites in Utah. Power, cooling, fast permitting process, labor force that can build these things \u2013 the electricians, the construction workers, the entire stack. A state that wants to partner with us to move quickly. Texas really has been unbelievable on this. I think that would be a good thing for other states to study, but we'd be excited to try to figure something out.\r\n\r\n**Senator Curtis:** Thank you. I think I can speak for our state leaders, we would be excited as well. But as you know, this also brings challenges, and one of those challenges are the demands for energy. And what's your thoughts on how we protect ratepayers and kind of put a little bit of a firewall between them?\r\n\r\n**Sam Altman:** I mean, I think the best way is just much more supply, more generation. You know, I think if you make it easy to reasonably, profitably create a lot of additional generative capacity, the market will do that. That will not only not drive up rates because of the AI workload, hopefully, it'll drive it down for everything. And we've talked a lot about the importance of energy to AI. Energy is just really important to quality of life. One of the things that seems to me the most consistent throughout history is every time the cost of energy falls, the quality of life goes up. And so doing a lot to make energy cheaper. In the short term, I think this probably looks like more natural gas, although there are some applications where I think solar can really help. In the medium term, I hope it's advanced nuclear, fission, and fusion. More energy is important well beyond AI. You know, in some sense, we have these dual revolutions going of AI and energy: the ability to have new ideas and the ability to get them done, to make them happen in the physical world where we all live. Like, these are kind of the limiting reagents of prosperity, and let's have a lot more.\r\n\r\n**Senator Curtis:** Thank you. Mr. Smith, we've talked about how significant power is to the success here. What role do you think Microsoft and other tech leaders have in developing energy, and particularly the right type of energy?\r\n\r\n**Brad Smith:** I think we have a tremendous responsibility to contribute to the solution. And I think Sam helped with his list. I would highlight two things, and I just would, I guess, illustrate it with what we do everywhere, but most recently with a major site in southeastern Wisconsin. You know, we went from zero, basically, to becoming the largest industrial user of electricity in the state, roughly 400 megawatts. And, you know, so we worked with the local utility. We made the investment to help and really enable them to expand their electricity generation. Now, that electricity then needed to be delivered from their power plant through the grid to our data center. We went to the Public Utilities Commission, and we proposed a rate increase on ourselves because we thought it was important that we pay for that improvement to the grid so that the neighbors, so to speak, would not have to. And I think what it really illustrates is the collaborative partnerships that are needed to provide the capital, to do the construction, to improve the grid, and to be, I think, very sensitive to the community as a whole.\r\n\r\n**Senator Curtis:** Thank you. Mr. Altman, let me come back to you. I was a small business owner. I have a special spot in my heart for small business owners. Can we talk a little bit about ChatGPT and how that might assist small business owners? And let me paint a little broader picture. We've heard a lot about other tools that are perhaps out of favor, particularly with the US government, that are very helpful for small businesses. But I don't know if small businesses are fully understanding the platform that you have and how they might use it for marketing, for data research, and ways to help their small business be successful.\r\n\r\n**Sam Altman:** One of, there were all these moments as ChatGPT was beginning to take off where we would be like, \"Oh, we may have a hit on our hands.\" There's like, someone's using it for this and this, and that's, you know, strangers talking about it. You see someone using it in a coffee shop. But one of the ones that really sticks out for me is, pretty quickly after ChatGPT launched, like in the first six months, say, I was in an Uber, and the driver was making conversation. He's like, \"Have you heard of this thing called ChatGPT? It's amazing.\" And I was like, \"Yeah, like, what do you think about it?\" And he was using it to run basically his entire small business. He was like, \"I had,\" he ran a laundromat. He's like, \"I had all these problems, you know, couldn't find good people to write my ads, couldn't get legal documents reviewed, couldn't answer customer support emails.\" And he was like a mega early adopter, but he was one of these people that was using AI to make a small business work. And that was, we talked about that story a lot at the time. But it's nice to reflect on it again now. We've now heard that at scale from a lot of people, but that was one of those moments early on where we're like, \"Oh, this is maybe going to work.\"\r\n\r\n**Senator Curtis:** So, and I'm out of time, but just, Mark, this is more than just something that helps proofread emails. Right? And you don't need to comment because I'm out of time, but we'll, I think we would all agree with that. It is, and look forward to seeing these applications move forward. Mr. Chairman, I yield my time.\r\n\r\n**Senator Duckworth:** Thank you, Mr. Chairman. I thank the panel, all of you, for being here today. I want to begin by talking about the importance of partnerships between the private sector and our national laboratories in maintaining United States leadership in AI. Illinois is a proud home of two crown jewels of the national laboratories: Fermilab, America's premier particle physics and accelerator laboratory, and Argonne National Laboratory, home to the Aurora Supercomputer that will accelerate breakthroughs in AI, cancer research, and fundamental physics. There is nothing more important than sustaining and amplifying investments in our nation's incredible network of national labs. Yet, Donald Trump and Elon Musk, with the support of some Republicans in Congress, are plotting to take a chainsaw to the vital research initiatives being carried out across our country. This is a self-sabotaging attack, plain and simple. And if allowed to proceed, Trump and Musk will inflict lasting harm on our innovative capabilities and capacity that our enemies could only dream of achieving. Does anyone truly have confidence that had Doge been around decades ago, they would not have cut the project that created the internet as an example of wasteful, publicly funded research and development? So, my question to any member of the panel is the following: Can you explain the importance of the national lab system to maintaining our research edge and discuss any partnerships you've established or are currently pursuing, especially those threatened by massive cuts to the national labs' research?\r\n\r\n**Sam Altman:** We partner with the national labs, so maybe I could take a first stab at this. Also, Senator, I'd love to get to visit Fermilab someday. That would be like a real life... that would be very cool. There are many wonderful things that AI is going to do for the world, but the one that I am personally most excited about is the impact AI will have on scientific discovery. I believe that new scientific discovery is the most important input to the world getting better and people's quality of lives getting better over time. It is hard to overstate where we would be if, where we are because of scientific advancement, and where we would be without it. So we're thrilled to get to partner with the national labs on this. I think science has not been as efficient as it can be, and we're also thrilled to hear from scientists that they're, you know, multiples more effective than they used to be. And I think that AI tools will mean we can accomplish, at some point, a decade worth of scientific progress in a year for the same cost or even less. This will be one of the most important contributions, in my opinion, that AI makes to the world. And it's no longer theoretical. Like, the national labs are a great example. That's the only partnership where we've given a copy of our model weights to another organization. It's a very deep and important partnership to us, and I expect that that will really bear fruit.\r\n\r\n**Senator Duckworth:** Thank you. Anybody else on the panel?\r\n\r\n**Brad Smith:** Yeah, I think you highlight a very important issue. This country has 17 national labs administered by the Department of Energy and about 85 to 90 research universities. And together, they are the fabric of much of scientific discovery and have been since the Manhattan Project in World War II. We in the tech sector, we at Microsoft, work with most, almost all of them. And there's a particular cycle of innovation that the United States has mastered. You have curiosity-driven research in these institutions, and then the advances move out of those institutions into startups and into larger companies. And what I always find interesting is I meet with officials around the world, they have studied this, they seek to emulate it. And I always worry that in the United States, we run the risk of taking it for granted. We should never take this for granted. It is the foundation for the country's technological leadership.\r\n\r\n**Senator Duckworth:** Very much so. Dr. Su?\r\n\r\n**Dr. Lisa Su:** I just wanted to add to that. We are also very large supporters of the public-private partnerships with the national labs. I think the national labs have, in a way, always tried to look ahead of the curve, and you know, that's a great place for us to invest. We think they're a key piece. We have partnered with all of the national labs as well over the last decade, and you know, that continues to be a place where I think there can be significant public-private partnership.\r\n\r\n**Senator Duckworth:** Thank you. Mr. Intrator?\r\n\r\n**Michael Intrator:** I just think it would be really interesting to come to these AI factories and to walk through or travel through these institutions and identify all the different pieces of the science that leads back and was ultimately driven and founded on something that came out of those institutions because it's amazing, actually.\r\n\r\n**Senator Duckworth:** Thank you. And would any of the remaining three of you like to come to a lab in Illinois, either Fermilab or Argonne? I will give you personal tours. Alright, all four of you. It's done. Thank you, Mr. Chairman.\r\n\r\n**Senator Young:** Thank you, Mr. Chairman, for holding this important hearing on winning the AI race. It's good to see our panelists here. One of the things that I like to underscore whenever I talk about this issue is we are not just discussing a race to create jobs, not just discussing a race to figure out how to eke out more growth from our economy, although that's important. Not just trying to identify how humans can flourish more, especially Americans, through application of AI solutions to our daily lives in various ways. But this is an issue of national and economic security. I want folks at home to get that. I know all our panelists are highly conversant and knowledgeable about that.\r\n\r\nIn my discussions with you and many others, I've heard we need to work with like-minded partners and allies to win this race, and it's only going to be done collectively. I've heard here today from a number of you that this race is in part about getting market share, diffusion of our AI models and solutions into other countries. It is through that means, for me to perhaps elaborate on your thoughts, that we can see that our own values are advanced. These models, presumably, they'll be embedded with our values related to privacy and transparency and property rights and freedom of speech and religion, not the values of the Chinese Communist Party on each of those various fronts. And then if we can establish digital trade rules, digital cross-border agreements on digital trade with these other countries, we could conceivably erect higher barriers to entry for models that don't come embedded with our standards, models of, say, the Chinese Communist Party has given sanction to. So there's a geopolitical, national security overlay to this entire conversation, which is why I think the Chairman's emphasis on not overly constraining innovation or deployment is very important. But it's also why I think it's important that we be thinking about how to work with other countries in their standards development. And so that's where I want to begin asking questions. I'll start with Mr. Smith. If the United States doesn't adopt some standards through some entity, whether it's NIST or another federal entity or federally sanctioned entity, then won't other nations go ahead and feel the need to adopt their standards without any consultation with the United States?\r\n\r\n**Brad Smith:** I think it's a really important point you make, and it is the lesson from the evolution of privacy law. The United States didn't adopt a national privacy law. Europe did, twice. And most American companies of any size today apply across the United States work that complies with European privacy law. It's just more efficient. So I think the United States needs to be in the game internationally to influence the rest of the world. And you cannot be in the game if you do nothing. You must do something.\r\n\r\n**Senator Young:** So you take Senator Cruz's idea, a lightweight approach. Yes. And then you build support around it. So just to unpack that, and I'll stick with Mr. Smith, with apologies to everyone else because my time's limited. Would it be easier to shape the standards of other large economy countries that share most of our values if we already have a set of standards adopted?\r\n\r\n**Brad Smith:** Generally, yes. I think we always have to be careful because if you go too soon, you go before the standards have really come together. But you've got to have some kind of model that you can show the rest of the world and win support for.\r\n\r\n**Senator Young:** And then presumably standards could be harmonized, right? They're not set in and chiseled onto a tablet, so to speak, right?\r\n\r\n**Brad Smith:** No, that's indispensable. I mean, if our technology is going to go around the world, we need a set of laws or regulations that in effect create that basis for reciprocity and interoperability.\r\n\r\n**Senator Young:** Okay. I only have 25 seconds left. Are there any violent objections to Mr. Smith's position? Because that seems eminently reasonable to me. Seems consistent with the light-touch approach, but it also shows a certain sense of urgency that the United States needs to act. The last thing I'll say in my remaining 10 seconds is that I am planning on introducing legislation today called the AI Public Awareness and Education Campaign Act with several of my colleagues. And our aim is to have a whole-of-government approach to foster greater awareness of AI literacy and grow STEM opportunities to create the next generation of our workforce. And I'm looking forward to moving that forward. So it will be available for public review, critique, even accolades. And Mr. Chairman, I yield back.\r\n\r\n**Senator Blunt Rochester:** Thank you, Chairman Cruz, and thank you so much to the witnesses. This is such an important hearing. Five minutes will not suffice for me. I'll be submitting some questions for the record. I noticed that for Mr. Altman and Mr. Smith, when the question of \"paint me a picture of the future\" came up, you actually leaned up in your chair. There was a level of excitement, and that's how I am about the future. When I came into the House of Representatives in 2017, I started a Future of Work bipartisan caucus because I had a concern that, number one, there were certain groups of people that were going to be left behind, but there also, as a country, that we could be left behind. And I started, I had one event where we had everyone walk into the room and use a word cloud and tell me what you think of when you hear \"the future of work.\" The biggest word coming in the door was \"fear.\" The biggest word walking out the door was \"opportunity.\" And so, to me, this conversation is so vital to think about the opportunities, but also making sure that we are watching out for ethics, watching out for scams, watching out for that technology does not take over the human. And so I am just grateful for the conversation.\r\n\r\nAnd Mr. Altman, I listened to an interview that you gave with Lester Holt maybe a year or so ago, and you talked in that interview about how OpenAI, it wasn't initially even about making a product, it wasn't about the money. And so I know you are incorporated in Delaware, and I understand you've been working with our Attorney General during the previously proposed legislation to transition to a for-profit \u2013 not legislation, but to transition to for-profit. And this Monday, OpenAI decided to apply to become a public benefit corporation instead and to have the PBC govern your nonprofit arm. What went into this decision, and what considerations influenced the timing of the organizational change?\r\n\r\n**Sam Altman:** So, we never, thank you for the question, Senator, and the chance to explain this. It's a complicated thing that I think has gotten misrepresented, so this is a wonderful forum to talk about it. We never planned to have the nonprofit convert into anything. The nonprofit was always going to be the nonprofit. And we also planned for a PBC from the very beginning. There were a bunch of other considerations about, is it the PBC board that would control the nonprofit somehow, or how our capital structure was going to work, that there was a lot of speculation on, most of it inaccurate, in the press. But our plan has always been to have a robust nonprofit. We hope our nonprofit will be one of the best, maybe someday the best-resourced nonprofit in the world, and a PBC with the same mission that would make it possible for us to raise the capital needed to deliver these tools and services at the quality level and availability level that people want to use them at, but still stick to our mission, which we've been proud over the last almost decade of our progress towards. So we had a lot of productive conversations with a lot of stakeholders and a lot of lawyers and a lot of regulators about the best way to do this. It took longer than we thought it was going to. You know, I would have guessed that we would have been talking about this last year, but now we have a proposal that people seem pretty excited about, and we're trying to now advance.\r\n\r\n**Senator Blunt Rochester:** And Dr. Su, your company primarily operates in the physical hardware portion of the AI stack. I have a bill with Senators Cantwell and Blackburn called the Promoting Resilient Supply Chains Act, which authorizes the Department of Commerce to strengthen American supply chains for critical industries and emerging technologies. Dr. Su and others, semiconductor and chips manufacturing is critical to advancing the advancement of AI, but we're facing these global supply chain constraints. What specific policies, and I know you mentioned policies as well for supply chains, would we need to adopt to help American companies overcome the supply chain issues and compete internationally with our rivals?\r\n\r\n**Dr. Lisa Su:** Thank you, Senator, for the question. There's no question the semiconductor supply chain and overall supply chains are really critical for us to win the AI race. I think from a semiconductor standpoint, the efforts that have been made to move manufacturing back to the United States have been positive. I think there's a start, there's a lot more that we can do. And one of the most important aspects of it is really to think about it end-to-end. There are so many steps to go from beginning to end in a semiconductor supply chain, including advanced wafers, including packaging, including the backends and system test. All of those avenues need to have a footprint in the United States. And then we have many allies around the world which are, you know, very excellent partners as part of the global resiliency in the supply chain, and we would like to see those partnerships continue to flourish.\r\n\r\n**Senator Blunt Rochester:** And last question, if I can. Mr. Smith, how do you see the interdependence between the AI stack sections creating either vulnerabilities or opportunities in the AI supply chain?\r\n\r\n**Brad Smith:** I think they create more opportunities than vulnerabilities because it enables companies to do what they do best, and then we can work together. And, you know, the world today has an integrated supply chain for anything that you buy. We just don't think about it when we go to the grocery store. I think one of the strengths of the tech sector is that we have, I'll call it, a string of pearls: great companies in every layer of the stack. And we're going to need, frankly, more great companies, especially at the applications layer. And that is how we work together.\r\n\r\n**Senator Blunt Rochester:** Thank you so much. I am out of time, but we will be following up with questions for the record as well as individually. Thank you, and I yield back.\r\n\r\n**Senator Moran:** Chairman Lummis, thank you very much. Mr. Smith, Mr. Smith mentioned data privacy, which has been a topic of mine for a long time, and we've been unsuccessful in legislation being adopted, but I still have the goal of making certain that consumers have control over their own data. And I was going to ask you, Mr. Altman, how can we provide consumers with more control over how their data is used by AI companies while preserving the utility of the AI system? So how do you get more privacy and still get the benefits?\r\n\r\n**Sam Altman:** So, there's all of the standard privacy controls that companies like ours and others build and should. But there's a new area that I'd love to flag for your consideration, which is people are sharing more information with AI systems than I think they have with previous generations of technology. And the maximum utility of these systems happens when the model can get very personalized to you. So this is a wonderful thing, and we should find a way to enable it. But the fact that these AI systems will get to know you over the course of your life so well, I think, presents a new challenge and level of importance for how we think about privacy in the world of AI. How we're going to think about guaranteeing people privacy when they talk to an AI system about whatever's happened in their lives. How we make sure that when one system connects to another, it shares the appropriate information and doesn't share other information, and that users are in control of that. I believe this will become one of the most important issues with AI in the coming years as people come to integrate this technology more into their lives, and I think it is a great area for you all to think about and take quite seriously.\r\n\r\n**Senator Moran:** We do. We just don't have any success in finding the conclusions, but thank you for the encouragement. I chair a Commerce, Justice, Science appropriations subcommittee that funds the Department of Justice, and it plays a significant role in cybersecurity of our country. I just came up from a budget hearing with the FBI Director, Dr. Patel, in which we covered cybersecurity threats, AI. Can you, and I think this is true, AI can be used on both sides of a cybersecurity attack. It can be used to automate phishing, malware creation, but machine learning can also increase our ability to detect and respond to cyber threats. What should Congress think about allocation of federal resources for cybersecurity, and what should we consider when it comes to AI?\r\n\r\n**Brad Smith:** Well, I would say that, you know, AI, as you said, is both an offensive weapon and a defensive shield when it comes to cybersecurity. And as with many other things, the front line of this the last few years has been in Ukraine because Russia has such a sophisticated cyberattack capability. And, you know, what we've found as a company that's been involved in supporting Ukraine since literally the moment that war began is that AI is a game-changer. You know, we have intercepted attacks against Ukraine faster than a human could detect them, and we block those attacks from taking place. So you deploy AI into, call it, the front line of the products themselves. We have to recognize that it's ultimately the people who defend not just countries but companies and governments, the Chief Information Security Officers, or the CISOs. You know, so we've created what's called a Cybersecurity Copilot that basically automates for those individuals much of the workflow that takes their time so that they can be more effective and efficient.\r\n\r\nWhen it comes to federal appropriation, I think that, to put it simply, the United States government must remain at the forefront of having for itself the cybersecurity capabilities that it needs to defend the government. And every day, I mean, we are in government agencies today during this hearing, you know, pushing Chinese out of agencies and the like. And this will happen every day of every year from now to probably eternity. So we must keep the US government well-funded in this space. And I think we also need our intelligence agencies, and especially the NSA, to be well-funded so they can remain at the forefront when it comes to global leadership in this field.\r\n\r\n**Senator Moran:** Thank you for your observations and encouragement. My final question: rural areas, a place I come from, often lack high-speed broadband. And since many AI tools rely upon connectivity, I'm concerned that many parts of the country and many parts of Kansas may not be able to access the benefits that AI will bring to business, schools, healthcare, etc. What can the federal government do to be supportive of development and availability of on-device or low-broadband-width AI systems that do not rely on constant connectivity?\r\n\r\n**Sam Altman:** I'm generally pretty excited about what AI will do here because you can offload so much of the processing to the cloud and then ship a relatively small amount of data. If you think about, you know, ChatGPT is text comes in, there's like a brain that thinks about it really hard, and some text comes back. We can support people in low connectivity areas quite well with the same quality of service. Separately to that, I think getting great connectivity everywhere is important, but in the specific area of AI, I think we can actually address that gap quite well.\r\n\r\n**Senator Moran:** That's good to know. Thank you very much.\r\n\r\n**Senator Lujan:** Thank you, Madam Chair. And first, I want to begin by recognizing and thanking Mr. Altman and Mr. Smith for your organization's ongoing involvement in the NIST US AI Safety Institute, as well as Dr. Su and Mr. Altman for your ongoing partnerships with our national laboratories. Now, Dr. Su, Mr. Altman, can you explain how your partnership with the national labs supports scientific research? You explained this to a question that was asked by Senator Duckworth as well, but if you could just touch on that quickly.\r\n\r\n**Sam Altman:** Our latest models, like GPT-4o, are good at scientific reasoning. And so scientists are able to use these to help them review literature, come up with new ideas, propose experiments, analyze data in a way that the previous generations of models just couldn't. We've had the national labs and other scientists spend time with previous models, and they say, \"Oh, this is, you know, kind of cool, it's interesting,\" and it's not transforming. The things these new models are, the first time we're hearing from scientists at the national labs and elsewhere that this is a legitimate game-changer to their research output.\r\n\r\n**Senator Lujan:** Appreciate that. Dr. Su?\r\n\r\n**Dr. Lisa Su:** Yeah, I would add the same. I think our partnerships with the national labs have seen just tremendous opportunity. We have large-scale compute across the national labs, and the ability to really develop new applications that take advantage of, let's call it, traditional high-performance computing together with the new AI model capability that we just talked about is, I think, a great opportunity to substantially move forward the ability for scientific discovery.\r\n\r\n**Senator Lujan:** To both of you again, can you explain why federal investment in foundational research and standards bodies are crucial to your companies?\r\n\r\n**Sam Altman:** I think standards can help increase the rate of innovation, but it's important that the industry figure out what they should be first. I think a bad standard can really set things back, and we've seen many examples of that in history. I do think there's a new protocol to discover here at the level of importance of HTTP. This is just one example; there are many other things too. I believe the industry will figure that out through some fits and starts, and then I think officially adopting that can be helpful.\r\n\r\n**Dr. Lisa Su:** I believe public-private partnerships really enable us to think, let's call it, ahead of the curve. So there are lots of things that we do in industry, and we do them very, very well. However, the beauty of the national labs and federal research is it does allow, let's call it, a bit more blue-sky research, and I think that's a very positive add. So I think the key is how we can make sure that, you know, one federal dollar goes much, much further than that with a private investment on top of that.\r\n\r\n**Senator Lujan:** Yesterday, I reintroduced a piece of legislation called the Test AI Act, which has bipartisan support, which would simply improve the federal government's capacity to test and evaluate in this area as well. So I very much appreciate both your responses. But this is just one of many steps, I would argue, that is needed to ensure that the United States stays ahead. Now, despite strong support across the country, including from industry leaders here today, President Trump's annihilating budgets for basic research, and there are questions abound by so many. I'll argue that this will destroy our nation's competitive advantage. I simply just call on all my colleagues that we look at the investments to the National Science Foundation, National Institutes of Health, and Department of Energy Office of Science. Let's work together. If there are questions that we have, let's find ways to address those, but let's ensure that these investments are making a positive difference so that we have more successes and more hearings celebrating what we're celebrating today.\r\n\r\nNow, beyond your partnership with the federal government, I would like to know more about how you partner with local communities when building out centers. Data centers put a strain on energy and water resources. However, unlike other businesses, they do not introduce many long-term jobs and economic benefits necessarily. So, Mr. Smith, how many engineers do you have dedicated to model or hardware optimization to reduce energy use, and when you build a center, what initiatives do you have in place to reduce water use?\r\n\r\n**Brad Smith:** I don't know off the top of my head the number of engineers working on optimization, but I'd be happy to track down an answer and get it to you. Water use is a huge priority, especially, you know, in data centers, for example, in the southwestern United States and other countries around the world where water is in short supply. If you look at our data centers today, they run on liquid cooling. It's a closed-loop system. The liquid is a combination of, frankly, water and other chemicals, but basically, once it starts running, almost all of the water is recycled. So the amount of water that we consume is typically far, far smaller than what most people would estimate. We also have a commitment to water replenishment. You know, our goal is to be water positive, meaning that we're providing more water to the community than we are consuming. So, for example, across the United States today, we have more than 90 water replenishment projects, including one that focuses on the San Juan River in your state of New Mexico, which focuses on water security for the river. So I think it's a good example of how we can play a responsible role in addressing an issue that is of growing importance.\r\n\r\n**Senator Lujan:** Appreciate that. Mr. Intrator, same question.\r\n\r\n**Michael Intrator:** Yeah, I can't answer the question of how many engineers we have focused on it, but I will say that the ability to extract more computational power out of a given megawatt is of paramount importance to my company, to all of us in this room. And we spend an enormous amount of time integrating the most bleeding-edge technology, which is a step function more efficient in terms of its computational output than the legacy technology has historically done. You know, so moving to liquid cooling has just been an incredible improvement in efficiency. And ultimately, we face this problem from, you know, within a given data center, within a given power envelope, how much can we move the computational resources forward? And that's really an important part of what we do.\r\n\r\n**Senator Lujan:** I appreciate that. Mr. Chairman, I have other questions I'll submit to the record. Mr. Moran did ask one question, Mr. Altman, you responded to it, but can you all just answer yes or no: is it important to ensure that in order for AI to reach its full promise, that people across the country should be able to connect to fast, affordable internet? Dr. Su?\r\n\r\n**Dr. Lisa Su:** Yes.\r\n\r\n**Michael Intrator:** Yes.\r\n\r\n**Brad Smith:** Yes.\r\n\r\n**Sam Altman:** Yes.\r\n\r\n**Senator Lujan:** Thank you. Appreciate that. I yield back.\r\n\r\n**Senator Lummis:** Thank you, Mr. Chairman. And thank you all for coming today. I really have been amazed at the outstanding progress that continues to be made in this field. And I'm already seeing people in Wyoming that are using ChatGPT or Claude to improve their businesses, whether it's healthcare or mining or oil and gas or education, ranching even. I'm just really excited about what this opportunity brings to America. Now, as I see it, the world has presented us with two paths. On one hand, the EU has chosen to regulate first and ask questions later. The GDPR is already limiting European access to the most capable AI models. On the other hand, China appears to be fast-tracking AI development, standing up large amounts of energy very quickly in an attempt to outcompete America. So I'd like to ask a few questions about how we can make sure we get the full benefit of this technology and accelerate its development.\r\n\r\nSo, first question. Over the past year, we've seen many states, including California and Texas, consider their own AI frameworks, each one significantly burdensome in their own right. At the same time, our lead against China is shrinking to about only six months. So, first of all, Mr. Altman, could you please sketch out what the world could look like if the US were to have a patchwork regulatory framework and how that could impact our competitiveness?\r\n\r\n**Sam Altman:** I think it would be quite bad. I think it's very difficult to imagine us figuring out how to comply with 50 different sets of regulation. And in many of these states, there have been, you know, dozens of different bills proposed that I understand several of which could be passed. That will slow us down at a time where I don't think it's in anyone's interest for us to slow down. One federal framework that is light-touch, that we can understand, and that lets us, you know, move with the speed that this moment calls for seems important and fine. But the sort of every state takes a different approach here, I think, would be quite burdensome and significantly impair our ability to do what we need to do, and hopefully, you all want us to do too.\r\n\r\n**Senator Lummis:** Does anyone disagree with Mr. Altman's assessment of a patchwork? Thank you. I have some questions about the infrastructure that is going to be necessary to lead and compete in AI. So my next questions are for our infrastructure providers, Mr. Smith and Mr. Intrator. Is it Intrator or Intrator?\r\n\r\n**Michael Intrator:** That's correct, Intrator.\r\n\r\n**Senator Lummis:** Thank you. Could you elaborate on how current permitting processes have impacted your ability to rapidly deploy AI infrastructure? The more specific you can be, the better.\r\n\r\n**Michael Intrator:** So, a quick comment on the patchwork, and then I'll dive in here, is the investment that we're making on the infrastructure side is enormous. And the idea that you can make an investment that could then become trapped in a jurisdiction that has a particular type of regulation that would not allow you to make full use of it is really very, very suboptimal and makes the decision-making around infrastructure challenging. As far as the permitting goes, whenever this topic comes up, the discussion around permitting is excruciating. And it's excruciating from the ability to quickly build and to build large. And I think that is kind of from the data center forward, without even beginning the discussion from the data center back through the energy infrastructure that is necessary to be able to power these large investments at the scale that make them of relevance to moving artificial intelligence forward. I'm happy to spend more time kind of digging into more details, but probably do that directly.\r\n\r\n**Senator Lummis:** Okay. And I'll look forward to that conversation because I'm worried about Wyoming's very clean natural gas being something your industry is concerned about because President Trump likes natural gas, but President Biden didn't. And if you build huge data centers and another president comes along who's anti-natural gas, that's a concern for you as you're deciding how to deploy capital. Mr. Smith, do you agree?\r\n\r\n**Brad Smith:** Generally, I do. I mean, I would say we need consistency across administrations in this country. We need to find more opportunities for bipartisan agreement. And I'll just highlight that in Cheyenne, where we've long had a data center complex, you know, we do have backup generators that run on natural gas. So there are a variety of ways for us to put different energy supplies to good use.\r\n\r\n**Senator Lummis:** Are you exploring small modular nuclear?\r\n\r\n**Brad Smith:** Yes, including with people in Wyoming.\r\n\r\n**Senator Lummis:** Yeah. Thank you. Mr. Altman, I'm pleased to hear you are releasing an open... Oh, my time's up. Excuse me. It goes so fast.\r\n\r\n**Sam Altman:** I'd love to talk to you about it another time. We're very excited about it too.\r\n\r\n**Senator Lummis:** Yeah. Thank you. I yield back.\r\n\r\n**Senator Rosen:** Thank you, Chairman Cruz. I saw you ready to push the button, and anyway, time does go by very fast. Thank you for having this hearing. I really believe in the promise of AI. It's so exciting. And we have to ask the right questions in order to promote its growth on one hand, and how it can explore and create these new possibilities and pathways, and also how do we protect ourselves from bad actors or outcomes as best as we can know at the time. And Mr. Altman, thank you for spending some time with me yesterday. I look forward to continuing to work with you on this.\r\n\r\nSo I want to start a little bit today with DeepSeek and adversarial AI because in February, I introduced bipartisan legislation with Senator Husted to prohibit the using DeepSeek on government devices. And earlier this week, Senator Cassidy and I introduced a bill that would expand those prohibitions to include federal contractors. So, Mr. Smith, what should our approach be to AI models that are developed in or by adversarial countries like the PRC? Should we be concerned about our adversaries co-opting AI to promote a particular ideology, collect sensitive US data, and how are you combating this threat?\r\n\r\n**Brad Smith:** Well, I think you can take the DeepSeek example, and it illustrates it well. And I think it's just worth thinking about the fact that, you know, DeepSeek produced two things. They have a model that is an open-source model, and they have an application, the DeepSeek app. At Microsoft, we don't allow our employees to use the DeepSeek app. We did not put the DeepSeek app in our app store because of the kinds of concerns that you mentioned, namely data going back to China and the app creating the kinds of content that I think people would say were associated with Chinese propaganda. At the same time, because the model itself is an open-source model, it was possible for us to go in it, analyze it, and change the code in the model, which we and other people have the permission to do, to remove the harmful side effects. And so I think we have to always think about the different aspects of the technology. I will say, put security first, and, you know, then go forward from there.\r\n\r\n**Senator Rosen:** Thank you. I think we all know that data is the real power in our current world. He or she or whomever owns the data really can control a lot of what we do. But I want to move on and speak with you, Mr. Altman, about AI and antisemitism a little bit because earlier this year, ADL released a report showing that several major generative AI models have perpetuated dangerous antisemitic stereotypes and, sadly, conspiracy theories. So, Mr. Altman, what steps is industry taking to ensure that AI models don't perpetuate antisemitism? Will you consider collaborating with civil society to create kind of a standard benchmark for AI related to antisemitism, use it as a form of evaluation, and then maybe we could use those for other forms of hate as well?\r\n\r\n**Sam Altman:** We, of course, we do collaborate with civil society on this topic, and we are excited to continue to do so. We want our users to have freedom to use models in the way they want, but we also don't want them to be damaging to sort of the fabric of society or particular groups. There will always be some debate, and the question of free speech in the context of AI is novel, and I think it's different than what we faced before. We really do view these as tools for users one-on-one. But of course, we're not here to, you know, make horrible antisemitic products.\r\n\r\n**Senator Rosen:** Thank you. I want to move on to, Senator Lujan talked about data center energy use, water use, something we're all really concerned about. I want to put on top of that a little bit about data center security, add that to the mix. So last Congress, I actually got a bill passed into law, my bipartisan Federal Data Center Enhancement Act. It establishes cybersecurity and resiliency standards for federal data centers. And so to Mr. Smith, or I'm sorry, Dr. Su. Thank you, Dr. Su. I want to ask you a little bit about hardware. Are there ways the hardware, like the chips AMD designs, new chips that we're hoping to think about? I know my career in, as a software developer, we just know things have gotten smarter, faster, and the cooler they can be, the better we can compute. So how can we make our chips cooler? How can we make our data centers, our computing power more secure? And I know interoperability is sometimes a factor, but can you talk about this a little bit?\r\n\r\n**Dr. Lisa Su:** Sure. Thank you for the question, Senator. Look, I think all of those things are extremely important, as you said. So in our part of the energy efficiency, you know, power constraints that we have from a chip standpoint, you know, our job is to continue to make our chips more and more efficient every year. We've seen, you know, 30 times improvement over the last few years, and we will continue to focus in that area. And then to your comments about, you know, security and ensuring that our chips are secure and, you know, people are not somehow, you know, breaking into them, you know, those are also very high priorities in our overall development cycle for future generation chips as well.\r\n\r\n**Senator Rosen:** Well, thank you. I look forward to working with all of you again on these important issues. Mr. Chairman.\r\n\r\n**Senator Sullivan:** Thank you, Mr. Chairman. I want to thank the witnesses for the testimony today. I appreciate the Chairman calling this hearing, and I agree with Senator Cruz's opening statement about this is a matter of national economic and national security in terms of our race, however you want to call it, competition with China. So, I know this topic has been pressed, but I want to, I want to just get, I want to dig down a little bit deeper. Do you agree with that, all of you? I'm just going to ask some quick questions. That this is a huge issue of national security, economic security relative to China, and we as America need to win in that regard?\r\n\r\n**Sam Altman:** Very important.\r\n\r\n*(All witnesses nod in agreement)*\r\n\r\n**Senator Sullivan:** Everybody nodding their head. And then, I know that's been touched, but is the consensus among the witnesses that we are ahead right now, but it is a kind of tentative lead? What would be, very quickly, we'll start with you, Mr. Altman. What's your assessment on that? I know we've already talked about it, I just want to set the context for some of the questions.\r\n\r\n**Sam Altman:** Yeah, I believe we are leading the world right now. I believe we'll continue to do so. We want to make AI in the United States, and we want the whole world to get to benefit from that. I think that is the strongest thing for the United States. I think it's also the right thing to do for all the people of the world. And I really appreciate you all being with us here today because I think we'll need your help, and everything you're saying, or almost everything you're saying, sounds great.\r\n\r\n**Senator Sullivan:** So, as I ask this question, I'll ask if you guys think we're ahead, but then the key things, when you say \"we need your help,\" what would, very succinctly \u2013 sometimes we're not so smart up here \u2013 what would the key things be that you would need from the US government to help us maintain that lead and dominate this space, which is what I think we need to do? Mr. Altman, again to you, real quick on that.\r\n\r\n**Sam Altman:** We've talked a little bit about infrastructure, but I think we cannot overstate how important that is and the ability to have that whole supply chain, or as much of it as possible, in the United States. The previous technological revolutions have also been about infrastructure and the supply chain, but AI is different in terms of the magnitude of resources that we need. So projects like Stargate that we're doing in the US, things like bringing chip manufacturing, certainly chip design to the US, permitting power quickly \u2013 like, these are critical. If we don't get this right, I don't think anything else we do can help. On the model creation side, we've talked about the need for certainty on our ability to train and to have fair footing with the rest of the world to make sure we can remain competitive. The ability to offer products under a reasonable, fair, light-touch regulatory framework where we can go win in the market because the products will be so key to the sort of feedback loops and making them better and better, and the ability to deploy them quickly and win at the product level in addition to the model and infrastructure and data area is really quite important. The ability to bring the most talented people in the world here, the most talented researchers. We have a ton in the United States; there's more out in the world. We should try to get them all here, improving models here. I think those are some of the specifics.\r\n\r\n**Senator Sullivan:** Good, that's very helpful. Let me ask Mr. Smith. Two other ones that I want to touch on. I agree fully with Senator Lummis. I'm sure Senator Cruz has the same view. One of our comparative advantages over China, in my view, has to be energy, all-of-the-above energy. Hopefully, you've seen in Alaska we have a very large-scale LNG project that I think we're going to get off the ground here. We've been working on it for a long time. We will have a hundred-year supply of natural gas. So we want you guys all to come up to Alaska with your data centers. We got cold weather. We got a lot of cold weather. We got gas. We got land. We got water. We got it all.\r\n\r\n**Brad Smith:** That's very compelling.\r\n\r\n**Senator Sullivan:** So yeah, come on up. When this project's done, a hundred-year gas supply, a little colder than Texas. So, two questions that relate to our comparative advantage, Mr. Smith, and then any others want to jump in. Energy, do we think that is, I think it is. And then second, it's, I think, somewhat of a disadvantage. It frustrates me. Maybe you guys don't see this. We've had American finance companies, venture capital firms, banks, others that, remarkably, with all the opportunities we have in America, are helping fund some of these projects in China. I've been a real staunch opponent of Americans who have opportunities to invest in other places investing in Chinese AI, Chinese quantum, because we all know they're going to use that to help make their military more lethal. I mean, that's what they do. I was reading recently about this Benchmark Capital. I don't know these guys, but they evidently did a $75 million round for some AI company in China. Is that another problem as well, Mr. Smith? Advantage: energy. Problem: American companies financing our competition.\r\n\r\n**Brad Smith:** I would connect three things: energy, people, and access to capital. The US has huge resources in energy, but never underestimate the ability of China to build a lot of electrical power plants, maybe more and faster than any other country. So we are better off going into that with the mindset that we have to keep up and not take anything for granted. But then I would say the number one comparative advantage of the United States throughout the 50 years that have defined digital technology has been bringing the world's best people to our country and giving them access to venture capital. And we should continue to burnish both of those. And I think you're right to ask where else is venture capital going. I'll just say this: if we can keep bringing the best people to the United States, and if we can keep educating the best people in the United States, I believe the money will be here to enable them to succeed. But let's make sure we're continuing to bring the best people in the world and giving them the opportunity to build great companies here in the United States.\r\n\r\n**Senator Sullivan:** American Venture Capital Funds funding Chinese AI, is that in our national interest?\r\n\r\n**Brad Smith:** I think there's a really good question about whether it is, and I recognize that you all are quite rightly focused on that. I'll just keep saying, bring the people here, they will have access to the money, and we will outcompete the world.\r\n\r\n**Senator Sullivan:** Great. Thank you. Thank you, Mr. Chairman.\r\n\r\n**Senator Markey:** Thank you, Mr. Chairman, very much. I'd like to talk about the environmental impact of artificial intelligence. Artificial intelligence can help us combat climate change by improving weather forecasts and enabling us to better predict power supply and demand. But designing and training and deploying AI models also poses real risks for our environment. The massive data centers that are critical for AI development require substantial amounts of electricity, putting stress on the grid and potentially raising costs for consumers. These data centers also generate significant heat. Cooling them requires huge volumes of water, often in regions already facing droughts because of climate change. And some data centers have on-site backup diesel generators, which can cause respiratory and cardiovascular issues and can increase the risk of cancer for the surrounding community. The truth is, we know too little about both the environmental costs and benefits of AI. Mr. Smith, do you agree that it would be helpful for the government to conduct a comprehensive study on the environmental impact of artificial intelligence?\r\n\r\n**Brad Smith:** Generally, yes. One study was just completed last December, and I think it's worth updating periodically.\r\n\r\n**Senator Markey:** Do you think it would be helpful for the government to convene stakeholders, including from industry and academia, to help better measure AI's environmental impact?\r\n\r\n**Brad Smith:** I think, as well as many other things that need to be measured, yes, I think there's a role to be played.\r\n\r\n**Senator Markey:** Mr. Altman, do you agree that the federal government should help with studying and measuring the environmental impact of AI?\r\n\r\n**Sam Altman:** I think studying and measuring is usually a good thing. I do think that the conversation about the environmental impact of AI and the relative challenges and benefits has gotten somewhat out of whack. I am hopeful that AI, you know, we've been trying to address climate, environmental challenges unsuccessfully, or not successfully enough, for a long time. I think we need help. I think AI can help us do that.\r\n\r\n**Senator Markey:** We've proposed, or we're in the process of building a 10-gigawatt facility and got another... My question is, should the federal government be on an ongoing basis studying the impact of AI?\r\n\r\n**Sam Altman:** Sure. And I think you should use AI to help.\r\n\r\n**Senator Markey:** Well, so that's why in this Congress, I introduced the Artificial Intelligence Environmental Impacts Act to study both the positive and negative consequences of AI as the technology continues to develop, as models become more efficient, and as we build out the infrastructure we need to do it. Yes, AI may find a cure for cancer, it may. But AI also could help to contribute to a climate disaster. That's also equally true. Okay, so we need to just keep both of those things right on the table, especially as the Trump administration is ignoring the fact that last year, 94% of all new installed electrical generation capacity in the United States was wind, solar, and battery. And Trump has said he's going to destroy all incentives for continuation of that. Okay, that's something you have to weigh in on, make sure he does not do that. So I look forward to working with you on that.\r\n\r\nNow, I want to turn to AI's impact on disadvantaged communities. After all, we're not just talking about using artificial intelligence to write emails or plan grocery lists. We're talking about technology used to calculate a family's mortgage, screen an individual's job application, and determine a senior's medical care. When used in these situations, it is absolutely essential that AI-powered algorithms are free from bias and discrimination. So let's start with a simple question. Mr. Smith, can algorithms be biased and cause discrimination?\r\n\r\n**Brad Smith:** They can, which is why we test to avoid that outcome.\r\n\r\n**Senator Markey:** Okay. Same question, Mr. Altman. Can algorithms be biased and cause discrimination?\r\n\r\n**Sam Altman:** Of course.\r\n\r\n**Senator Markey:** Of course. Of course. Mr. Altman, does OpenAI work to guard against such bias and discrimination in ChatGPT?\r\n\r\n**Sam Altman:** Of course.\r\n\r\n**Senator Markey:** Of course. So, I'm glad to hear that because you recently stated that the government should not implement privacy regulations on AI, but instead, quote, \"respond very quickly as the problems emerge.\" And I am very deeply worried about that approach. We don't need to wait and see if poorly tested and trained algorithms will harm marginalized communities. Artificial intelligence is already supercharging the bias and discrimination prevalent in our society. Biased and discriminatory algorithms mean Black and Brown families are less likely to obtain a mortgage. It means people with disabilities are less likely to be recommended for a job opening. And it means women are less likely to receive scholarships for higher education. These are real harms that are happening right now. It is Congress's job to address these existing problems that come with the rapid development and deployment of AI. And it's why I'm the proud author of the AI Civil Rights Act, which would ensure that companies review and eliminate bias and discrimination in their algorithms before developing and deploying them. It has to happen simultaneously, and it will hold companies accountable when their algorithms cause harms against marginalized populations. I will be fighting to ensure AI does not stand for \"accelerating inequality\" in our nation. All of the protections we have in the real world should be moved to the virtual world because the same discriminations against women, Black, Brown communities, with disabilities, LGBTQ community, are going to move online, and we have to build in the protections against that bias right up front because otherwise, those same discriminatory practices will just migrate immediately. And the responsibility of the industry will be to work with Congress to make sure we put those protections on the books. Thank you, Mr. Chairman.\r\n\r\n**Senator Peters:** Thank you, Mr. Chairman. And thanks to all our witnesses. Thank you for being here. It's an incredibly important topic, and we appreciate your expertise as we're looking at making sure that the United States is the world leader in AI. Certainly, we've been talking about supply chains and infrastructure and all of those aspects, but one area that I want to particularly focus on is workforce and people, to make sure that we have the talent there. That's why I authored the AI Scholarship for Service Act and the AI Training Act. Both of those were signed into law in 2022. Earlier this year, I introduced my AI and Critical Technology Workforce Framework Act to continue the effort along those lines, and I'd love to work with each of you as we look at other legislation necessary to make sure we've got the workforce trained to take advantage of this amazing technology. I do want to do a shout-out to the University of Michigan that actually became the first university in the world to provide generative AI tools for their entire student body to prepare them for the workforce of tomorrow.\r\n\r\nSo, I want to talk a little bit about the workforce. But Mr. Altman, when we met last year in my office and had a great conversation, you said that upwards of 70% of jobs could be eliminated by AI. And you acknowledged the possible social disruption of this. If that's happening, we have to prepare for it. We're not going to stand in the way of the incredible opportunities here, but if this is indeed going to occur, we've got to be thinking pretty deeply about how that will be managed and make sure that everybody can benefit from AI, not just the select few that benefit. So talk to me about how you believe leaders in your industry can help mitigate job losses or deal with what could, as you described it last year, be a major social disruption.\r\n\r\n**Sam Altman:** The thing that I think is different this time than previous technological revolutions is the potential speed. Technological revolutions have impacted jobs and the economy for a long time. Some jobs go away, some new jobs get created, many jobs just get more efficient, and people are able to do more and earn more money and create more, and that's great. Over some period of time, society can adapt to a huge amount of job change, and you can look at the last couple of centuries and see how much that's happened. I don't know, I don't think anyone knows exactly how fast this is going to go, but it feels like it could be pretty fast. The most important thing, or one of the most important things I think we can do, is to put tools in the hands of people early. We have a principle that we call iterative deployment. We want people to be getting used to this technology as it's developed. We've been doing this now for almost five years since our first product launch. As society and this technology co-evolve, putting great, capable tools in the hands of a lot of people and letting them figure out the new things that they're going to do and create for each other and come up with, and provide sort of value back to the world on top of this new building block we have and the sort of scaffolding of society, that is, I think, the best thing we can do as OpenAI and as our industry to be, sort of, help smooth this transition.\r\n\r\nThe idea, we want to get to a point where AI isn't displacing work but actually enhancing work, that people are more productive and doing things that we probably can't even imagine what people will do. If we look 100 years ago, we have jobs that no one can imagine, and I don't think we can imagine the jobs on the other side of this. But even if you look today at what's happening with programming, which I'll pick because it's sort of my background and near and dear to my heart, what it means to be a programmer, and, you know, an effective programmer in May of 2025 is very different than what it meant last time I was here in May of 2023. These tools have really changed what a programmer is capable of, the amount of code and software that the world is going to get. And it's not like people don't hire software engineers anymore, right? They work in a different way, and they're way more productive.\r\n\r\n**Senator Peters:** Right, right. Dr. Su, we certainly talk a lot about open-source AI, but most of the conversation has been about software. However, making technology open and able to work together matters at every level, as you know, from chips that power the devices to the servers that are running behind the scenes. So my question for you is, you know, what are the benefits of open standards and system interoperability at the hardware level, not the software level, and what are the implications for innovation, national security, as well as resilience in the supply chain?\r\n\r\n**Dr. Lisa Su:** Yeah, thank you for the question, Senator. I think there are an incredible number of advantages to having an open ecosystem at the hardware and the software and the application level. You know, the idea is, there's no one organization or one group that has all the good ideas. And so enabling the ecosystem to work together so that you can choose the best solution at every level, and then also optimization across a broad set of constituents is a good thing. I think it's also very important for a single ecosystem. So, you know, we continue to be very forward-thinking in open standards as well as open ecosystems.\r\n\r\n**Senator Peters:** So your model is an open model. I understand Nvidia is a closed model. Is there, what are the advantages, disadvantages? What should we be thinking about?\r\n\r\n**Dr. Lisa Su:** I think the major advantage in an open model, and that is something that we very much support, is the idea that we can have innovation come from many different parties. And, you know, whether that is hardware innovation, so on the different chips, or that is system innovation on putting all these things together. And, you know, our goal is to make sure that we always have the best of the best, and there are many different ways, many different parties that can contribute to that. And that's why we are very forward-leaning in terms of open ecosystems.\r\n\r\n**Senator Peters:** Great. Thank you. Thank you, Mr. Chairman.\r\n\r\n**Senator Fetterman:** Thank you, Mr. Chairman. Hello. Mr. Smith, I'm a big supporter of energy. For me, energy security is national security. And of course, you know, renewables, I'm all about that, but of course, other things as well too, fossil. But also, that also includes nuclear. Of course, nuclear is important. And now, then there's that kind of energy transition. My focus is also that I want to make sure that ratepayers in Pennsylvania really aren't hit too hard throughout all of this. Now, the Washington Post reported that increasing electricity demand for the data centers is going to raise up residential power bills, perhaps as much by 20%. Now, that's really a concern for me and certainly for Pennsylvania families. Now, the data center, you know, has important jobs during construction and doing those things, and that's a great thing, of course. But they're not, I guess, mostly long-term, but those rates might last longer for that. And now, I've been very tracking the plan to reopen TMI. I mean, I had my own personal story. I had to grab my hamster and evacuate, you know, when that, during the meltdown in 1979. You might assume that I was anti-nuclear, and that is not, it's, I actually am very supportive of nuclear because that's an important part of the stack if you really want to have and address climate change. You can't turn your back on nuclear, in my opinion. But I know that's the power now for Microsoft's data center. So now, and I really appreciate that. But if I'm saying now, if we're able to commit that the power purchase agreement, you know, it's not going to raise electricity for Pennsylvania families.\r\n\r\n**Brad Smith:** And no, I think you raise a critical point. We have two principles that we follow when we're constructing these data centers. Number one, we will invest to bring onto the grid an amount of electricity that equals the amount of electricity that we will use so that we're not tapping a constricted supply. Number two, we will manage all of this in a way that ensures that our activity does not raise the price of electricity to the community. And so I was describing earlier how if there are improvements that need to be made to the grid, as there often are, we'll go to the utility commission, we will propose a change in the rate that we are charged so that we can pay for that improvement. I just think it's a fact of life because I think you highlight something critical. There's a lot of jobs when the construction takes place. There are jobs afterwards, but they are not as many. One will wear out the welcome quickly if we tax, in effect, the neighborhood by asking everyone to pay more for their electricity because we have arrived. We get it. We know we have to be a good and responsible member of the neighborhood.\r\n\r\n**Senator Fetterman:** Thank you. Well, and now, you know, one of the perks of being a senator that, for me anyway, I get an opportunity to meet people that have much more impressive kinds of jobs or careers that I've had. And now, Mr. Altman, now this is going to, I'm going to count this as a highlight. Recently, like, I know the work that you've done, you know, you're really one of the people that are moving AI. And now it's, it's an opportunity. I was excited to meet you. And now people, you know, people ask me, it's like, if you're going to talk about AI, and now I get to ask you, I mean, you're like the literal expert, you know. Some people are worried about AI or whatever, and I'm like, you know, what about the singularity? So, you know, the people like that, if you would address that, please.\r\n\r\n**Sam Altman:** Thank you, Senator, for the kind words and for normalizing hoodies in more spaces. I love to see that. I am incredibly excited about the rate of progress, but I also am cautious. And I would say, like, I don't know, I feel small next to it or something. I think this is beyond something that we all fully yet understand where it's going to go. This is, this is, I believe, among the biggest, maybe it'll turn out to be the biggest technological revolutions humanity will have ever produced. And I feel privileged to be here. I feel curious and interested in what's going to happen. But I do think things are going to change quite substantially. I think humans have a wonderful ability to adapt, and things that seem amazing will become the new normal very quickly. We'll figure out how to use these tools to just do things we could never do before, and I think it will be quite extraordinary. But these are going to be tools that are capable of things that we can't quite wrap our heads around. And some people call that, you know, as these tools start helping us to create next future iterations, some people call that singularity, some people call that the takeoff. Whatever it is, it feels like a sort of new era of human history. And I think it's tremendously exciting that we get to live through that, and we can make it a wonderful thing. But we've got to approach it with humility and some caution.\r\n\r\n**Senator Fetterman:** No, I mean, I just, for me, it's, it's been, I get a chance to ask questions to a lot of Edisons, you know, as well too. Like the kinds of things that you're all collectively involved in are going to transform our society, and people will look back 50, 60 years from now and see what's happened. So to me, over to the Chairman. Thank you.\r\n\r\n**Senator Klobuchar:** Thank you. Good thoughts, Senator Fetterman. Thank you. So, you guys have been sitting here so long that the Pope has been chosen.\r\n\r\n**Senator Cruz:** Wow.\r\n\r\n**Senator Klobuchar:** Well, we don't know who.\r\n\r\n**Senator Cruz:** Congratulations, Amy. White smoke has come up.\r\n\r\n**Senator Klobuchar:** Congratulations. You're welcome. Probably wouldn't work. But in any case, it was, I left for some other things, came back because I had one more question that I wanted to ask, and it's related to just the whole deepfake issue. Just because Senator Blackburn and Senator Coons and Senator Tillis and I have worked on this really hard, and they're, Blackburn and Coons are in the lead of the bill. But we have recently seen deepfake videos of Al Roker promoting, to remove more than 75,000 songs with unauthorized deepfakes, including voices of Harry Styles, Beyonce. I recently met, it's not just famous people. There is a Grammy-nominated artist from Minnesota, talked to him about what's going on with digital replicas. So there's a real concern, and it kind of gets at what Senator Schatz and I were talking about earlier with the news bill. But I just wanted to make you all aware of this legislation because there were some differences on this, and now we have gotten a coalition, including YouTube, supporting it, as well as the Recording Industry Association, Motion Picture Association, SAG-AFTRA. So it's a big deal. And I'm hoping it's something that you will all look at. But could you just comment, I would go to you, Mr. Smith, first, about protecting people from having their likenesses replicated through AI without permission? And even if you all pledge to do it, our obvious concern is that there will maybe be other companies that wouldn't. And that's why I think as we look at what these guardrails are, the protection of people's digital rights should be part of this. Mr. Smith?\r\n\r\n**Brad Smith:** Yeah. No, I think you're right to point to it. It has become a growing area of concern. You know, during the presidential election last year, both campaigns, both political parties were concerned about the potential for deepfakes to be created. We worked with both campaigns and both parties to address that. We see it being used in really ways that I would call abusive, you know, including of celebrities and the like. I think it starts with an ability to identify when something has been created by AI and is not a genuine, say, photographic or video image. And we do find that AI is much more capable at doing that than, say, the human eye and human judgment. I think it's right that there be certain guardrails, and some of these we can apply voluntarily. We've been doing that across the industry. OpenAI and Microsoft were both part of that last year. And there are certain uses that probably should be considered across the line and therefore should be unlawful. And I think that's where the kinds of initiatives that you're describing have a particularly important role to play.\r\n\r\n**Senator Klobuchar:** And could you look at that legislation?\r\n\r\n**Brad Smith:** Absolutely.\r\n\r\n**Senator Klobuchar:** Appreciate it. Mr. Altman, just same question, same thing.\r\n\r\n**Sam Altman:** Sorry. Of course, we'd be happy to look at the legislation. I think this is a big issue, and it's one coming quickly. I do not believe, I think there's a few areas to attack it. You can talk about AI that generates content, platforms that distribute it, how takedowns work, how we educate society, and how we build in robustness to expect this is going to happen. I do not believe it will be possible to stop the generation of the content. I think open-source, open-weight models are a great thing on the whole and something we need to pursue, but it does mean that there's going to be just a lot of these models floating around that can do this. The mass distribution, I think it's possible to put some more guardrails in place, and that seems important. But I don't want to neglect the societal education piece. I think with every new technology, there's some sort of, almost always, some sort of new scams that come. The sooner we can get people to understand these, be on the lookout for them, talk about this as a thing that's coming and then a thing that's happening, I think the better. People are very quickly understanding that content can be AI-generated and building new kinds of defenses in their own minds about it. But still, you know, if you get a call and it sounds exactly like someone you know and they're panicked and they need help, or if you see a video that was like the videos you talked about, this gets at us in a very deep psychological way. And I think we need to build societal resilience because this is coming.\r\n\r\n**Senator Klobuchar:** It's coming, but we can, there's got to be some ways to protect privacy rights, and you've got to have some way to either enforce it, damages, whatever, or there's just not going to be any consequences.\r\n\r\n**Sam Altman:** Absolutely, we should have all of that. Bad actors still don't always follow the laws, and so I think we need additional shields or whenever we can have them. But yes, we should absolutely protect that.\r\n\r\n**Senator Klobuchar:** Alright. Look forward to working with you on it. Thank you.\r\n\r\n**Senator Cruz:** So, I have to say, Senator Klobuchar's question about fakes and AI fakes made me feel guilty because I did, in fact, tweet out an AI-generated picture of Senator Fetterman as the Pope of Greenland. So I am guilty of doing so, although it may not be a fake, it may be real.\r\n\r\n**Senator Klobuchar:** Hey! Oh, whoa, whoa. Parody is allowed under the law. Parody is allowed. That is different than what I'm talking about.\r\n\r\n**Senator Cruz:** But Senator Fetterman should respond. Yeah, it may be real. It's a good shot, actually. Alright, I have a few more questions, and then we will wrap up. Mr. Altman, what has been the most surprising use for ChatGPT you've seen? What are applications that you're seeing that are surprising?\r\n\r\n**Sam Altman:** You know, people message ChatGPT billions of times per day, so they use it for all sorts of incredibly creative things. I will tell one personal story, which is, I mentioned earlier I recently had a newborn. Clearly, people did it, but I don't know how people figured out how to take care of newborns without ChatGPT. That has been a real lifesaver.\r\n\r\n**Senator Cruz:** So, I will tell you a story that I've told you before, but my teenage daughter several months ago sent me this long, detailed text, and it was emotional, and it was really well-written. And I actually commented, I'm like, \"Wow, this is really well-written.\" She said, \"Oh, I used ChatGPT to write it.\" I'm like, \"Wait, you're texting your dad, and you don't...\" It is something about the new generation that it is so seamlessly integrated into life that she's sending an email, she's doing whatever, and she doesn't even hesitate to think about going to ChatGPT to capture her thoughts.\r\n\r\n**Sam Altman:** I have complicated feelings about that.\r\n\r\n**Senator Cruz:** Well, use the app and then tell me what you're... Okay. Google just revealed that their search traffic on Safari declined for the first time ever. They didn't send me a Christmas card. Will ChatGPT replace Google as the primary search engine, and if so, when?\r\n\r\n**Sam Altman:** Probably not. I mean, I think some use cases that people use search engines for today are definitely better done on a service like ChatGPT. But Google is like a ferocious competitor. They have a very strong AI team, a lot of infrastructure, a very well-protected business. And they're making great progress putting AI into their search.\r\n\r\n**Senator Cruz:** Alright. So, a question that I have spent a lot of time talking to business leaders, CEOs in the tech space, AI. And one question that I've asked that I get different answers on, and I'm curious what the four of you say: How big a deal was DeepSeek? Is it a major, seismic, shocking development from China? Is it not that big a deal? Is it somewhere in between? And what's coming next? And let's each of the four of you answer.\r\n\r\n**Sam Altman:** Not a huge deal. There are two things about DeepSeek. One is that they made a good open-source model, and the other is that they made a consumer app that, for the first time, briefly surpassed ChatGPT as the most downloaded AI tool, maybe the most downloaded app overall. There are going to be a lot of good open-source models. And clearly, there are incredibly talented people working at DeepSeek doing great research, so I'd expect more great models to come. Hopefully, also us and some of our colleagues will put out great models too. On the consumer app, I think if the DeepSeek consumer app looked like it was going to beat ChatGPT and our American colleagues' apps as sort of the default AI systems that people use, that would be bad. But that does not currently look to us like what's happening.\r\n\r\n**Dr. Lisa Su:** I would say it's somewhere in between, Chairman Cruz. When you think about what we've learned, what we learned is, you know, there are different ways of doing things. So we have lots of incredibly innovative people in the United States. American models are clearly the best by far. However, when you have constraints that are placed, there are other ways of doing things, and I think we learned a few things in the process. I think the open-source nature of DeepSeek was one of the things that probably was most impactful in just terms of how much can be done in an open-source type of model and open ecosystem. But clearly, the United States is leading, and we need to continue, as we said, to accelerate innovation and adoption, as you started this hearing with.\r\n\r\n**Michael Intrator:** I think DeepSeek did a lot of things. One of the things that it did was it sort of raised the specter of China's AI capability to a much broader audience than was perhaps focused on it prior to that, right? And so you saw that kind of reverberate through the financial markets. You saw like broad-based reaction, and suddenly everyone knows what DeepSeek is and the fact that China is not theoretically in the race for AI dominance but actually is very much a formidable competitor. And so, you know, it was a starting gun in some ways for the broader population and kind of maybe the broader consciousness of the fact that this is not a fait accompli and that we're going to have to work as America together to kind of propel our solutions forward. And so I think that was one of the lasting impacts that we will see from that.\r\n\r\n**Brad Smith:** I would say, like Lisa, that somewhere in between. It wasn't shocking. I mean, it was one of a number of startups that we were following in China that we saw as having the potential to be innovative in this space. I do think there's a really interesting and important point that constraints encourage innovation in other ways. And I just think one of the interesting facts about DeepSeek is that of their, say, 200 or more employees \u2013 that was their size when they released these models \u2013 almost all of their employees, by design, were four years or less out of university. They wanted to hire people that would not bring to their work traditional ways of doing things.\r\n\r\n**Senator Cruz:** So the kids are taking over the world.\r\n\r\n**Brad Smith:** They do, every generation.\r\n\r\n**Senator Cruz:** Related to that, were you finished with that, Mr. Smith? Related to that, we talked at the outset about the AI diffusion rule being rescinded, which I'm glad. I think it was a bad rule. I think it was overly complex. I think it put on a number of our trading partners unfair restrictions. And so I'm glad the President is rescinding it. That doesn't necessarily mean that there should be no restrictions. And there are a variety of views on whether there, what the rules should be concerning AI diffusion. Nvidia has argued that we want American chips everywhere, even in China. Others have argued that we want to restrict at least the most advanced processors. I'm curious, each of the four of you, what do you think the rule should be, if anything, to replace the AI diffusion rule? And Mr. Altman, we'll start with you.\r\n\r\n**Sam Altman:** I also was glad to see that rescinded. I agree there will need to be some constraints, but I think if our, if the sort of mental model is winning diffusion instead of stopping diffusion, that directionally seems right. That doesn't mean there's no guardrails. It doesn't mean we say like, \"We're going to go build a bigger data center in some other country than the US.\" Our intention is to build our biggest and best data centers in the US, do training in the US, build the models here, have our core research here. But then we do want to build inference centers with our partners around the world, and we've been working with the US government on that. I think that'll be good. To this point that influence comes from people adopting US products and services up and down the stack. Maybe most obviously if they're using ChatGPT versus DeepSeek, but also if they're using US chips and US data center technology and all the amazing stuff Microsoft does, that's a win for us, and I think we should embrace that, but make sure that, you know, the most critical stuff, the creation of these models that will be so impactful, that that should still happen here.\r\n\r\n**Dr. Lisa Su:** I think we would totally agree with the concept that some restrictions are necessary. This is a matter of national security as much as it is about AI diffusion. That being the case, we were happy to see the rescinding as well. And, you know, we view this as an opportunity to really simplify, right? At the end of the day, you know, we've talked about the need to drive widespread adoption of our technology and our ecosystem. Simple rules that can be easily applied, that really allow our allies to, you know, protect our technology while still utilizing the best that the United States has to offer, I think is a good start in terms of where we're going. And, you know, again, this is an area where I think the devil's in the details, and it requires a lot of balance. And so, from an industry standpoint, you know, it's our job to put on the broader hat and work hand-in-hand with the administration and Congress to make our best recommendations so that it is a policy that has some stability as we go forward as well.\r\n\r\n**Michael Intrator:** So, I'll echo what Sam and Lisa said, but, you know, national security is paramount. And then once you've addressed the limitations around national security, the opportunity to work with regulators to put together a regulatory framework beyond that makes a lot of sense. And the diffusion rule didn't allow us that opportunity to participate fully enough to feel like we were going to come away with what would be an optimal outcome at this point.\r\n\r\n**Brad Smith:** I think we've all discussed the right recipe. Simplify. Eliminate these Tier 2 quantitative restrictions that undermine confidence in access to American technology. But enable even the most advanced GPUs the country has to be exported to data centers that are run by a trusted provider, that meet certain security standards \u2013 that means both physical and cybersecurity standards \u2013 that there is protection against diversion of the chips, and there are precautions against certain uses. And that means two things. One is that there are controls in place to ensure that, say, the PLA, the Chinese military, isn't accessing and using these advanced models or advanced chips, you know, in a data center regardless of the country that it's in. And there are certain harmful uses that one should want to prohibit and preclude, like using a model to create the next biological weapon. So I think there is a recipe that can be retained and can move forward and that strikes the right balance.\r\n\r\n**Senator Cruz:** Okay. Final question for each of you. Would you support a 10-year learning period on states issuing comprehensive AI regulation or some form of federal preemption to create an even playing field for AI developers and deployers?\r\n\r\n**Sam Altman:** I'm not sure what a 10-year learning period means, but I think having one federal approach focused on light touch and an even playing field sounds great to me.\r\n\r\n**Dr. Lisa Su:** Aligned federal approach with, you know, really thoughtful regulation would be very, very much appreciated.\r\n\r\n**Michael Intrator:** I agree with both of my colleagues.\r\n\r\n**Brad Smith:** Yeah, I think, you know, that builds obviously on the op-ed that you and Senator Graham published last year. And I think giving the country time \u2013 your analogy, your example was this worked for the internet. There are a lot of details that need to be hammered out, but giving the federal government the ability to lead, especially in areas around product safety and pre-release reviews and the like, would help this industry grow.\r\n\r\n**Senator Cruz:** Well, I want to thank each of the witnesses. This was a very interesting hearing. It was informative. These issues matter. You saw a great deal of interest on both sides of the aisle in this topic. And so I appreciate each of you are very busy and doing a lot of things, and I appreciate you being here today. Senators will have until the close of business on Thursday, May 15th, to submit questions for the record, and the witnesses will have until the end of the day on Thursday, May 29th, to respond to those questions. And with that, that concludes today's hearing. The committee stands adjourned."]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"caterpillar_selected_sources":["web"],"selected_github_repos":[],"serialization_metadata":{"custom_symbol_offsets":[]},"dictation":false,"request_id":"93cc89fd5da5ab5c-SIN","message_source":null,"timestamp_":"absolute","message_type":null},"recipient":"all","channel":null},"parent":"f797e1ba-b3a0-4164-91e4-c0e2cafd9cf1","children":["ddc127ff-2c35-4e74-ac02-e8dfb97abbf8"]},"ddc127ff-2c35-4e74-ac02-e8dfb97abbf8":{"id":"ddc127ff-2c35-4e74-ac02-e8dfb97abbf8","message":{"id":"ddc127ff-2c35-4e74-ac02-e8dfb97abbf8","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1746744880.64622,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"message_type":null,"model_slug":"gpt-4o","default_model_slug":"gpt-4o","parent_id":"f5603406-3b4a-4cab-a547-b1176691b415","request_id":"93cc89fd5da5ab5c-SIN","timestamp_":"absolute"},"recipient":"all","channel":null},"parent":"f5603406-3b4a-4cab-a547-b1176691b415","children":["761b91a0-504a-4e08-aa6c-49ba86bc2a7a"]},"761b91a0-504a-4e08-aa6c-49ba86bc2a7a":{"id":"761b91a0-504a-4e08-aa6c-49ba86bc2a7a","message":{"id":"761b91a0-504a-4e08-aa6c-49ba86bc2a7a","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1746744868.732033,"update_time":null,"content":{"content_type":"text","parts":["User is following US Senate hearings on AI policy and innovation, with a focus on competitiveness with China, energy infrastructure, open-source models, and regulatory frameworks."]},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200007]},"is_complete":true,"citations":[],"content_references":[],"message_type":null,"model_slug":"gpt-4o","default_model_slug":"gpt-4o","parent_id":"ddc127ff-2c35-4e74-ac02-e8dfb97abbf8","request_id":"93cc89fd5da5ab5c-SIN","timestamp_":"absolute"},"recipient":"bio","channel":null},"parent":"ddc127ff-2c35-4e74-ac02-e8dfb97abbf8","children":["53410ac4-cee4-4d69-8928-06d6934e5dbe"]},"53410ac4-cee4-4d69-8928-06d6934e5dbe":{"id":"53410ac4-cee4-4d69-8928-06d6934e5dbe","message":{"id":"53410ac4-cee4-4d69-8928-06d6934e5dbe","author":{"role":"tool","name":"bio","metadata":{}},"create_time":1746744880.646333,"update_time":null,"content":{"content_type":"text","parts":["Model set context write is pending confirmation by user. Please respond but DO NOT STATE THE MEMORY HAS BEEN SAVED, DELETED, OR REMEMBERED."]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"pending_memory_info":{"pending_message_id":"761b91a0-504a-4e08-aa6c-49ba86bc2a7a","is_pending":true,"pending_memory_content":"User is following US Senate hearings on AI policy and innovation, with a focus on competitiveness with China, energy infrastructure, open-source models, and regulatory frameworks."},"message_type":null,"model_slug":"gpt-4o","default_model_slug":"gpt-4o","parent_id":"761b91a0-504a-4e08-aa6c-49ba86bc2a7a","request_id":"93cc89fd5da5ab5c-SIN","timestamp_":"absolute"},"recipient":"assistant","channel":null},"parent":"761b91a0-504a-4e08-aa6c-49ba86bc2a7a","children":["9d8f5266-af6f-4da7-8adf-407a516c6c7f"]},"9d8f5266-af6f-4da7-8adf-407a516c6c7f":{"id":"9d8f5266-af6f-4da7-8adf-407a516c6c7f","message":{"id":"9d8f5266-af6f-4da7-8adf-407a516c6c7f","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1746744871.280916,"update_time":null,"content":{"content_type":"text","parts":["### **Synopsis of the Senate Hearing on U.S. AI Leadership**\n\n**Overview:**\nThe U.S. Senate Commerce Committee convened a high-profile hearing featuring testimony from OpenAI CEO Sam Altman, AMD CEO Dr. Lisa Su, CoreWeave CEO Michael Intrator, and Microsoft Vice Chair Brad Smith. The session explored how the U.S. can strengthen its AI leadership, maintain economic and national security, outpace China, and avoid overregulation that could stifle innovation.\n\n---\n\n### **Key Themes and Testimonies:**\n\n#### 1. **Geopolitical Stakes:**\n- **Senator Cruz** emphasized the need for U.S. dominance in AI to counter China\u2019s authoritarian model, criticizing EU-style regulations and Biden\u2019s executive orders as overreaching and damaging to competitiveness.\n- **Senator Cantwell** called for collaborative global standards and increased investments in U.S. infrastructure, computing power, and energy to maintain AI leadership.\n- **Altman**, **Su**, and **Smith** echoed concerns about China catching up and stressed the need for open ecosystems, global diffusion of American tech, and fast-paced innovation.\n\n#### 2. **Regulatory Philosophy:**\n- Strong consensus emerged among Republican senators and witnesses against \u201cpre-approval\u201d or heavy-handed AI regulations.\n- Witnesses advocated for:\n  - A **federal light-touch regulatory framework**, avoiding state-by-state fragmentation.\n  - **Industry-driven standards** with government validation (e.g., through NIST).\n  - A regulatory \u201csandbox\u201d to foster safe experimentation and agile development.\n\n#### 3. **Infrastructure and Energy Bottlenecks:**\n- **AI\u2019s scale-up requires massive compute infrastructure**, power generation, and grid upgrades.\n- **Intrator** and **Smith** identified permitting delays\u2014especially federal wetland permits\u2014as critical barriers to data center construction.\n- **Altman** stressed that **energy cost and abundance will define AI cost** in the long run and argued for long-term investment in natural gas and advanced nuclear (including fusion).\n- **Senator Fetterman** and others raised concerns about rising electricity costs for households due to AI power demands.\n\n#### 4. **Export Controls and Open-Source Diffusion:**\n- While **national security justifies export limits**, overly broad restrictions (like the rescinded AI Diffusion Rule) alienate allies and hurt global adoption of U.S. tech.\n- **Altman** announced OpenAI will release a leading open-source model to strengthen U.S. influence.\n- **Smith** advocated for a balanced framework that ensures global access while protecting against misuse (e.g., PLA use, bioweapon generation).\n\n#### 5. **Workforce and Talent:**\n- Witnesses warned of **severe talent shortages**, especially in AI engineering, hardware design, and electricity infrastructure.\n- **Su** and **Altman** called for reforms to attract and retain global talent and increase domestic STEM investment.\n- **Senator Peters** and others stressed the importance of training programs, AI literacy, and scholarships to broaden the talent pipeline.\n\n#### 6. **Children, Privacy, and Ethical Guardrails:**\n- **Senator Vance** and **Klobuchar** raised child protection concerns, asking companies to build better safeguards.\n- **Altman** agreed on the need for more stringent controls for children and highlighted emerging use of AI as emotional support.\n- **Senator Markey** and others pushed for transparency, content labeling, and anti-bias mechanisms, with **Altman** and **Smith** affirming their commitment to collaborating on standards.\n\n#### 7. **AI and Civil Society:**\n- Several senators expressed concern about AI\u2019s societal impact, from deepfakes and discrimination to job disruption.\n- **Altman** acknowledged that AI may eliminate up to 70% of jobs but could also significantly increase productivity and create new industries if deployed iteratively and responsibly.\n- Bipartisan interest emerged in **digital rights**, **deepfake legislation**, and **ensuring AI benefits rural and disadvantaged communities**.\n\n---\n\n### **Strategic Takeaways:**\n\n| Topic                        | Consensus/Viewpoint                                                                 |\n|-----------------------------|--------------------------------------------------------------------------------------|\n| **US vs China**             | U.S. is ahead but not by much; must lead via adoption, infrastructure, and standards |\n| **Regulation**              | Federal light-touch regulation preferred; avoid EU-style command-and-control         |\n| **Export Policy**           | Rescind diffusion rule; adopt simplified, targeted export controls                   |\n| **Infrastructure**          | Permitting reform and energy investment critical to competitiveness                  |\n| **Open Source**             | Important to counter China's diffusion; OpenAI to release a top-tier model           |\n| **AI Stack Control**        | Full-stack U.S. integration (chips to apps) gives a durable edge                     |\n| **Social Responsibility**   | Regulation needed for deepfakes, bias, child safety, and IP protection               |\n| **Scientific Partnerships** | National labs viewed as irreplaceable engines for public-private AI innovation       |\n\n---\n\n### **Overall Assessment:**\nThis was a substantive, bipartisan hearing reflecting high alignment across industry leaders and senators on:\n- Maintaining U.S. technological supremacy,\n- Avoiding regulatory overreach,\n- Rapidly scaling infrastructure,\n- Emphasizing workforce development, and\n- Supporting open global adoption of American AI.\n\nHowever, divisions remain on:\n- The **role of government in setting early standards**,\n- The balance between **openness and content safeguards**, and\n- The **pace and aggressiveness of export controls**.\n\nWould you like a distilled strategic policy memo from this hearing for use in research or advisory roles?"]},"status":"finished_successfully","end_turn":true,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200002]},"is_complete":true,"citations":[],"content_references":[],"message_type":null,"model_slug":"gpt-4o","default_model_slug":"gpt-4o","parent_id":"53410ac4-cee4-4d69-8928-06d6934e5dbe","request_id":"93cc89fd5da5ab5c-SIN","timestamp_":"absolute"},"recipient":"all","channel":null},"parent":"53410ac4-cee4-4d69-8928-06d6934e5dbe","children":["24fdc0f0-da88-4cd4-8926-1edf9b6db549"]},"24fdc0f0-da88-4cd4-8926-1edf9b6db549":{"id":"24fdc0f0-da88-4cd4-8926-1edf9b6db549","message":{"id":"24fdc0f0-da88-4cd4-8926-1edf9b6db549","author":{"role":"user","name":null,"metadata":{}},"create_time":1746744944.753,"update_time":null,"content":{"content_type":"text","parts":["yes please, a distilled strategic policy memo from this hearing for use in research"]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"caterpillar_selected_sources":["web"],"selected_github_repos":[],"serialization_metadata":{"custom_symbol_offsets":[]},"dictation":false,"request_id":"93cc8be02d0fab5c-SIN","message_source":null,"timestamp_":"absolute","message_type":null},"recipient":"all","channel":null},"parent":"9d8f5266-af6f-4da7-8adf-407a516c6c7f","children":["08dc0ecf-6c7b-4655-8983-b962fe8d3dc4"]},"08dc0ecf-6c7b-4655-8983-b962fe8d3dc4":{"id":"08dc0ecf-6c7b-4655-8983-b962fe8d3dc4","message":{"id":"08dc0ecf-6c7b-4655-8983-b962fe8d3dc4","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1746744945.088819,"update_time":null,"content":{"content_type":"text","parts":["Here is a **Distilled Strategic Policy Memo** based on the May 2025 U.S. Senate Commerce Committee hearing on Artificial Intelligence:\n\n---\n\n## **Strategic Policy Memo: U.S. AI Leadership and Innovation**\n**To:** Policymakers, Industry Leaders, Strategic Analysts  \n**From:** [Your Advisory Unit or Research Body]  \n**Date:** May 2025  \n**Subject:** Strategic Direction for U.S. Leadership in Artificial Intelligence  \n**Source:** Senate Commerce Committee Hearing (May 2025) with OpenAI, Microsoft, AMD, CoreWeave\n\n---\n\n### **Executive Summary:**\nThe U.S. is at a critical juncture in AI development and deployment. While American firms currently lead in AI model capabilities, semiconductor technology, and infrastructure buildout, that lead is narrow and eroding. Policymakers must adopt a dual mandate: **accelerate domestic innovation and adoption** while **exporting U.S.-anchored standards and technologies globally** to prevent adversaries (notably China) from dictating the AI future. Legislative and executive actions over the next 12\u201324 months will decisively shape the trajectory.\n\n---\n\n### **Strategic Imperatives and Recommendations**\n\n#### **1. Infrastructure: Accelerate AI Supply Chain Buildout**\n- **Issue:** Data centers require exponential increases in compute, energy, cooling, and physical infrastructure. Permitting delays\u2014particularly federal wetlands permits\u2014are crippling.\n- **Recommendations:**\n  - Enact **permitting reform** for AI infrastructure (e.g., FREE Act model).\n  - Expand DOE grants and fast-track **AI-priority energy projects** (fission, fusion, gas).\n  - Encourage **multi-state compacts** to coordinate power grid upgrades across regions.\n  - Incentivize AI chip production on U.S. soil via CHIPS Act extensions.\n\n#### **2. Regulatory Framework: One Federal Voice**\n- **Issue:** Fragmented regulatory landscape (state-led rules like CA SB 1047) threatens scalability.\n- **Recommendations:**\n  - Enact **federal preemption of state AI laws** for commercial applications.\n  - Create a **10-year national \"AI sandbox\" framework**, modeled on the 1996 internet deregulation.\n  - Task NIST with adopting\u2014**not originating**\u2014industry-defined standards for AI safety and performance.\n\n#### **3. Global Strategy: Win AI Diffusion via U.S. Stack**\n- **Issue:** China is aggressively promoting open-source LLMs (e.g., DeepSeek) to capture international developers and infrastructure markets.\n- **Recommendations:**\n  - Simplify export controls (replace flawed \"AI Diffusion Rule\") to allow:\n    - U.S. model inference in Tier 2 markets under secure hosting.\n    - Global access to U.S.-origin semiconductors and services under managed licensing.\n  - Promote **U.S.-aligned digital infrastructure alliances** (\"Tech NATO\") to counter Huawei-style AI infrastructure expansion.\n  - Launch a **government-industry AI diplomacy unit** within the State Department to push U.S. stack adoption (chips, cloud, APIs).\n\n#### **4. Talent and Workforce: Treat as Strategic Asset**\n- **Issue:** The U.S. faces critical shortages in AI engineers, electricians, and semiconductor specialists.\n- **Recommendations:**\n  - Expand STEM visas and green cards via a new \u201c**AI Talent Act**\u201d modeled on the CHIPS scientist exemption.\n  - Fund **state-based AI vocational academies** focused on electricians, data center operators, and AI ops.\n  - Mandate AI training in NSF and DOE-funded research fellowships.\n\n#### **5. Societal Stability: Guardrails Without Paralysis**\n- **Issue:** AI\u2019s rapid spread risks societal backlash due to misinformation, bias, and job displacement.\n- **Recommendations:**\n  - Require **risk-based evaluation regimes** for high-impact use cases (healthcare, finance, law enforcement).\n  - Support **standardized labeling protocols** for synthetic media (C2PA, watermarking).\n  - Mandate **youth protections** in commercial AI systems (age verification, usage caps).\n  - Establish an **AI Transition Commission** to model macroeconomic impacts of job disruption.\n\n#### **6. Open Source vs. National Security**\n- **Issue:** U.S. open-source leadership is at odds with security concerns about misuse by adversaries.\n- **Recommendations:**\n  - Encourage controlled release of open-source models by trusted U.S. firms (as OpenAI proposed).\n  - Restrict **export of open-weight models** above a certain capability threshold unless hosted domestically.\n  - Define clear **red lines** (e.g., bio-weapon generation, deepfake political interference) for government response to misuse.\n\n---\n\n### **Emerging Consensus**\nFrom both industry and bipartisan senators:\n| Issue                                | Policy Consensus                                           |\n|-------------------------------------|------------------------------------------------------------|\n| Export controls                     | Calibrate, don\u2019t suffocate; restrict China, not allies     |\n| Regulation                          | Federal light-touch; avoid EU-style command frameworks     |\n| Permitting reform                   | Urgently needed for energy + data center buildout          |\n| Infrastructure                      | Invest in power, chips, racks, and compute localization    |\n| Standards setting                   | Let industry lead; adopt via NIST or international treaties|\n| Talent and skilling                 | Immigration reform + domestic pipeline expansion           |\n\n---\n\n### **Risks if Inaction Persists**\n- **Loss of global AI market share** to China and non-democratic regimes.\n- **Supply chain constraints** (power, chips, labor) stalling innovation.\n- **Patchwork U.S. regulation** driving developers offshore.\n- **Technological disillusionment** due to misuse, discrimination, or misinformation.\n\n---\n\n### **Next Steps**\n1. Draft and pass a bipartisan **AI Infrastructure and Innovation Act** to:\n   - Fund large-scale compute, power grid, and domestic chip projects.\n   - Preempt patchwork state regulation.\n2. Establish a **Presidential AI Export Council** to manage trade-security AI conflicts.\n3. Create an **AI Standards and Safety Consortium**, with NIST, top labs, and civil society.\n4. Fast-track **AI education incentives** in community colleges and tech institutes.\n\n---\n\nWould you like this memo formatted into a 2-page PDF with citation footnotes and a policy summary table for distribution?"]},"status":"finished_successfully","end_turn":true,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200002]},"is_complete":true,"citations":[],"content_references":[],"message_type":null,"model_slug":"gpt-4o","default_model_slug":"gpt-4o","parent_id":"24fdc0f0-da88-4cd4-8926-1edf9b6db549","request_id":"93cc8be02d0fab5c-SIN","timestamp_":"absolute"},"recipient":"all","channel":null},"parent":"24fdc0f0-da88-4cd4-8926-1edf9b6db549","children":[]}}}