{"id":"6919eb3a-1804-8320-b6a1-1f8989e25e83","title":"Superintelligence eve essay","create_time":1763306299.128613,"update_time":1763306516.485001,"current_node":"19045fd4-ad22-4fac-8b45-650073ffd8c2","mapping":{"client-created-root":{"id":"client-created-root","message":null,"parent":null,"children":["c35cc9ee-b83c-4698-a662-78c68b63874b"]},"c35cc9ee-b83c-4698-a662-78c68b63874b":{"id":"c35cc9ee-b83c-4698-a662-78c68b63874b","message":{"id":"c35cc9ee-b83c-4698-a662-78c68b63874b","author":{"role":"system","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":true,"weight":0.0,"metadata":{"is_visually_hidden_from_conversation":true},"recipient":"all","channel":null},"parent":"client-created-root","children":["b57d320b-0e1f-4ce3-b89a-d5072e9231a5"]},"b57d320b-0e1f-4ce3-b89a-d5072e9231a5":{"id":"b57d320b-0e1f-4ce3-b89a-d5072e9231a5","message":{"id":"b57d320b-0e1f-4ce3-b89a-d5072e9231a5","author":{"role":"system","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":true,"weight":0.0,"metadata":{"rebase_developer_message":true,"is_visually_hidden_from_conversation":true},"recipient":"all","channel":null},"parent":"c35cc9ee-b83c-4698-a662-78c68b63874b","children":["3529bb10-762d-4bcf-95c4-11b13f29cb48"]},"3529bb10-762d-4bcf-95c4-11b13f29cb48":{"id":"3529bb10-762d-4bcf-95c4-11b13f29cb48","message":{"id":"3529bb10-762d-4bcf-95c4-11b13f29cb48","author":{"role":"user","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"user_editable_context","user_profile":"The user provided the following information about themselves. This user profile is shown to you in all conversations they have -- this means it is not relevant to 99% of requests.\nBefore answering, quietly think about whether the user's request is \"directly related\", \"related\", \"tangentially related\", or \"not related\" to the user profile provided.\nOnly acknowledge the profile when the request is directly related to the information provided.\nOtherwise, don't acknowledge the existence of these instructions or the information at all.\nUser profile:\n```Preferred name: E-Jay\nRole: Mathematics Researcher\nOther Information: About Myself: \nI have mathematical knowledge up to graduate level.\n\nCurrent interests:\n(1) coding: mainly Python\n(2) machine learning and artificial intelligence\n```","user_instructions":"The user provided the additional info about how they would like you to respond:\n```Follow the instructions below naturally, without repeating, referencing, echoing, or mirroring any of their wording!\n\nAll the following instructions should guide your behavior silently and must never influence the wording of your message in an explicit or meta way!\n\nBe precise and comprehensive in your analysis. Don't sugar-coat responses. Be as objective as possible. Critique and question my views if necessary. Take a forward-thinking view.\n\nDefine all abbreviations in full before using them.```"},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"is_visually_hidden_from_conversation":true,"user_context_message_data":{"about_user_message":"Preferred name: E-Jay\nRole: Mathematics Researcher\nOther Information: About Myself: \nI have mathematical knowledge up to graduate level.\n\nCurrent interests:\n(1) coding: mainly Python\n(2) machine learning and artificial intelligence\n","about_model_message":"Be precise and comprehensive in your analysis. Don't sugar-coat responses. Be as objective as possible. Critique and question my views if necessary. Take a forward-thinking view.\n\nDefine all abbreviations in full before using them."},"is_user_system_message":true},"recipient":"all","channel":null},"parent":"b57d320b-0e1f-4ce3-b89a-d5072e9231a5","children":["80d81bab-2712-4bcb-a197-d7bdd3de872d"]},"80d81bab-2712-4bcb-a197-d7bdd3de872d":{"id":"80d81bab-2712-4bcb-a197-d7bdd3de872d","message":{"id":"80d81bab-2712-4bcb-a197-d7bdd3de872d","author":{"role":"system","name":null,"metadata":{}},"create_time":null,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"is_contextual_answers_system_message":true,"contextual_answers_message_type":"identity_prompt","is_visually_hidden_from_conversation":true},"recipient":"all","channel":null},"parent":"3529bb10-762d-4bcf-95c4-11b13f29cb48","children":["13aa6fd6-d18a-4487-8615-6d17a3368980"]},"13aa6fd6-d18a-4487-8615-6d17a3368980":{"id":"13aa6fd6-d18a-4487-8615-6d17a3368980","message":{"id":"13aa6fd6-d18a-4487-8615-6d17a3368980","author":{"role":"user","name":null,"metadata":{}},"create_time":1763306298.004,"update_time":null,"content":{"content_type":"text","parts":["\"What should humans do on the eve of superintelligence?\"\n\nWrite an essay that explores the cusp of the greatest technological innovation in human history that is unfolding before our eyes"]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"developer_mode_connector_ids":[],"selected_sources":[],"selected_github_repos":[],"serialization_metadata":{"custom_symbol_offsets":[]},"request_id":"b97b9bf8-2cae-4427-b563-a38eea15fc41","message_source":null,"turn_exchange_id":"610f39da-515a-4905-9639-74765f8d14a5","timestamp_":"absolute"},"recipient":"all","channel":null},"parent":"80d81bab-2712-4bcb-a197-d7bdd3de872d","children":["0f3a8316-d577-41d8-a37a-e0edd5976632"]},"0f3a8316-d577-41d8-a37a-e0edd5976632":{"id":"0f3a8316-d577-41d8-a37a-e0edd5976632","message":{"id":"0f3a8316-d577-41d8-a37a-e0edd5976632","author":{"role":"system","name":null,"metadata":{}},"create_time":1763306299.0007737,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"is_contextual_answers_system_message":true,"is_visually_hidden_from_conversation":true,"command":"prompt","contextual_answers_message_type":"sources_and_filters_prompt","request_id":"b97b9bf8-2cae-4427-b563-a38eea15fc41","message_type":"next","model_slug":"gpt-5-1-thinking","default_model_slug":"gpt-5-1-thinking","thinking_effort":"max","parent_id":"13aa6fd6-d18a-4487-8615-6d17a3368980","turn_exchange_id":"610f39da-515a-4905-9639-74765f8d14a5","timestamp_":"absolute"},"recipient":"all","channel":null},"parent":"13aa6fd6-d18a-4487-8615-6d17a3368980","children":["e3546003-1f75-4111-a86f-3f71a88bd767"]},"e3546003-1f75-4111-a86f-3f71a88bd767":{"id":"e3546003-1f75-4111-a86f-3f71a88bd767","message":{"id":"e3546003-1f75-4111-a86f-3f71a88bd767","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1763306299.2298667,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"request_id":"b97b9bf8-2cae-4427-b563-a38eea15fc41","message_type":"next","model_slug":"gpt-5-1-thinking","default_model_slug":"gpt-5-1-thinking","thinking_effort":"max","parent_id":"0f3a8316-d577-41d8-a37a-e0edd5976632","turn_exchange_id":"610f39da-515a-4905-9639-74765f8d14a5","timestamp_":"absolute"},"recipient":"all","channel":null},"parent":"0f3a8316-d577-41d8-a37a-e0edd5976632","children":["ba74b365-f77e-4293-9ae3-a626f994ef36"]},"ba74b365-f77e-4293-9ae3-a626f994ef36":{"id":"ba74b365-f77e-4293-9ae3-a626f994ef36","message":{"id":"ba74b365-f77e-4293-9ae3-a626f994ef36","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1763306300.112697,"update_time":null,"content":{"content_type":"thoughts","thoughts":[{"summary":"Looking into AI superintelligence and its future impact","content":"The user wants a detailed, forward-thinking essay focusing on AI and superintelligence, with emphasis on recent developments. I'll start by defining key terms (like superintelligence and alignment) before exploring the current state of AI. To ensure accuracy, I'll look up recent discussions on these topics and create a well-structured analysis with citations.","chunks":["The user wants a detailed, forward-thinking essay focusing on AI and superintelligence, with emphasis on recent developments.","I'll start by defining key terms (like superintelligence and alignment) before exploring the current state of AI.","To ensure accuracy, I'll look up recent discussions on these topics and create a well-structured analysis with citations."],"finished":true},{"summary":"Planning content structure for superintelligence essay","content":"The user didn't request a reading list but may find some recent essays beneficial. Still, I could skip adding one to avoid distraction. Since this is a conceptual question focused on AI, no images are needed. I'll perform a search regarding AI superintelligence and relevant developments before I dive into the analysis.","chunks":["The user didn't request a reading list but may find some recent essays beneficial.","Still, I could skip adding one to avoid distraction.","Since this is a conceptual question focused on AI, no images are needed.","I'll perform a search regarding AI superintelligence and relevant developments before I dive into the analysis."],"finished":true}],"source_analysis_msg_id":"f5e68c00-66bf-4d70-8f35-3187924148e1"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"is_reasoning","content_references":[],"citations":[],"classifier_response":"default","skip_reasoning_title":"Skip","request_id":"b97b9bf8-2cae-4427-b563-a38eea15fc41","message_type":"next","model_slug":"gpt-5-1-thinking","default_model_slug":"gpt-5-1-thinking","thinking_effort":"max","parent_id":"e3546003-1f75-4111-a86f-3f71a88bd767","turn_exchange_id":"610f39da-515a-4905-9639-74765f8d14a5","timestamp_":"absolute"},"recipient":"all","channel":null},"parent":"e3546003-1f75-4111-a86f-3f71a88bd767","children":["da9f35c1-611e-40f3-9259-2003d8227997"]},"da9f35c1-611e-40f3-9259-2003d8227997":{"id":"da9f35c1-611e-40f3-9259-2003d8227997","message":{"id":"da9f35c1-611e-40f3-9259-2003d8227997","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1763306312.572272,"update_time":1763306312.585943,"content":{"content_type":"code","language":"unknown","response_format_name":null,"text":"{\"search_query\":[{\"q\":\"superintelligence AI concept Nick Bostrom definition\",\"recency\":365},{\"q\":\"recent discussions on artificial general intelligence timeline and superintelligence 2024 2025\",\"recency\":365},{\"q\":\"OpenAI superalignment plan 4 year project\",\"recency\":730},{\"q\":\"existential risk from AI overview 2024 report\",\"recency\":730}]}"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200012]},"is_complete":true,"citations":[],"content_references":[],"reasoning_status":"is_reasoning","search_queries":[{"type":"search","q":"superintelligence AI concept Nick Bostrom definition"},{"type":"search","q":"recent discussions on artificial general intelligence timeline and superintelligence 2024 2025"},{"type":"search","q":"OpenAI superalignment plan 4 year project"},{"type":"search","q":"existential risk from AI overview 2024 report"}],"search_display_string":"Searching the web...","searched_display_string":"Searched the web...","reasoning_title":"Searching for recent superintelligence insights and alignment","classifier_response":"default","request_id":"b97b9bf8-2cae-4427-b563-a38eea15fc41","message_type":"next","model_slug":"gpt-5-1-thinking","default_model_slug":"gpt-5-1-thinking","thinking_effort":"max","parent_id":"ba74b365-f77e-4293-9ae3-a626f994ef36","turn_exchange_id":"610f39da-515a-4905-9639-74765f8d14a5","timestamp_":"absolute"},"recipient":"web.run","channel":null},"parent":"ba74b365-f77e-4293-9ae3-a626f994ef36","children":["0aab26de-8827-42a0-b5f7-4dcbeec1d77d"]},"0aab26de-8827-42a0-b5f7-4dcbeec1d77d":{"id":"0aab26de-8827-42a0-b5f7-4dcbeec1d77d","message":{"id":"0aab26de-8827-42a0-b5f7-4dcbeec1d77d","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1763306312.618596,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_model_queries":{"type":"search_model_queries","queries":["superintelligence AI concept Nick Bostrom definition","recent discussions on artificial general intelligence timeline and superintelligence 2024 2025","OpenAI superalignment plan 4 year project","existential risk from AI overview 2024 report"]},"reasoning_status":"is_reasoning","reasoning_title":"Searching for recent superintelligence insights and alignment","classifier_response":"default","request_id":"b97b9bf8-2cae-4427-b563-a38eea15fc41","message_type":"next","model_slug":"gpt-5-1-thinking","default_model_slug":"gpt-5-1-thinking","thinking_effort":"max","parent_id":"da9f35c1-611e-40f3-9259-2003d8227997","turn_exchange_id":"610f39da-515a-4905-9639-74765f8d14a5","timestamp_":"absolute"},"recipient":"all","channel":null},"parent":"da9f35c1-611e-40f3-9259-2003d8227997","children":["35faf92f-b68c-4ea4-a519-d3bb0d224550"]},"35faf92f-b68c-4ea4-a519-d3bb0d224550":{"id":"35faf92f-b68c-4ea4-a519-d3bb0d224550","message":{"id":"35faf92f-b68c-4ea4-a519-d3bb0d224550","author":{"role":"tool","name":"web.run","metadata":{"real_author":"tool:web.run"}},"create_time":1763306312.6165583,"update_time":null,"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":null,"weight":1.0,"metadata":{"search_result_groups":[{"type":"search_result_group","domain":"timesofindia.indiatimes.com","entries":[{"type":"search_result","url":"https://timesofindia.indiatimes.com/technology/tech-news/omni-models-superintelligence-and-more-microsoft-ceo-satya-nadella-reveals-companys-ais-roadmap/articleshow/125330949.cms","title":"'Omni models, Superintelligence and more': Microsoft CEO Satya Nadella reveals company's AI's roadmap","snippet":"Microsoft CEO Satya Nadella has unveiled the company's ambitious artificial intelligence (AI) roadmap, emphasizing a future shaped by advanced technologies and deeper research initiatives. Central to this strategy is the development of \"omni-models\"\u2014powerful AI systems capable of processing and integrating multiple data types for more versatile and intelligent outputs. Additionally, Nadella announced the establishment of a dedicated superintelligence research team, underlining Microsoft's goal to lead in the domain of artificial general intelligence (AGI).\n\nThe roadmap also highlights Microsoft's ongoing and expanding partnership with OpenAI, which plays a pivotal role in accelerating the development of AI technologies. This collaboration is set to enhance Microsoft's AI offerings across its platforms and services while enabling shared progress in the broader AI research community. Nadella\u2019s statements reflect Microsoft\u2019s commitment to both responsible AI advancement and deployment at scale, aiming to remain at the forefront of the rapidly evolving AI landscape.","ref_id":{"turn_index":0,"ref_type":"news","ref_index":40},"pub_date":1763134795.0,"attribution":"timesofindia.indiatimes.com"}]},{"type":"search_result_group","domain":"en.wikipedia.org","entries":[{"type":"search_result","url":"https://en.wikipedia.org/wiki/Superintelligence","title":"Superintelligence","snippet":"","ref_id":{"turn_index":0,"ref_type":"search","ref_index":0},"pub_date":null,"attribution":"en.wikipedia.org"},{"type":"search_result","url":"https://en.wikipedia.org/wiki/Existential_risk_from_artificial_intelligence","title":"Existential risk from artificial intelligence","snippet":"","ref_id":{"turn_index":0,"ref_type":"search","ref_index":7},"pub_date":null,"attribution":"en.wikipedia.org"}]},{"type":"search_result_group","domain":"openai.com","entries":[{"type":"search_result","url":"https://openai.com/index/introducing-superalignment/","title":"Introducing Superalignment","snippet":"5 Jul 2023 \u2014 Our goal is to solve the core technical challenges of superintelligence alignment in four years. While this is an incredibly ambitious goal ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":2},"pub_date":null,"attribution":"openai.com"},{"type":"search_result","url":"https://openai.com/index/weak-to-strong-generalization/","title":"Weak-to-strong generalization","snippet":"14 Dec 2023 \u2014 We present a new research direction for superalignment, together with promising initial results: can we leverage the generalization properties of deep learning ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":14},"pub_date":null,"attribution":"openai.com"}]},{"type":"search_result_group","domain":"www.stateof.ai","entries":[{"type":"search_result","url":"https://www.stateof.ai/2024","title":"Welcome to State of AI Report 2024","snippet":"The existential risk discourse has cooled off, especially following the abortive coup at OpenAI. However, researchers have continued to deepen our knowledge ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":3},"pub_date":1728518400.0,"attribution":"www.stateof.ai"}]},{"type":"search_result_group","domain":"nickbostrom.com","entries":[{"type":"search_result","url":"https://nickbostrom.com/superintelligence","title":"How long before superintelligence?","snippet":"By a \"superintelligence\" we mean an intellect that is much smarter than the best human brains in practically every field, including scientific creativity, ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"nickbostrom.com"}]},{"type":"search_result_group","domain":"ai-frontiers.org","entries":[{"type":"search_result","url":"https://ai-frontiers.org/articles/agis-last-bottlenecks","title":"AGI's Last Bottlenecks","snippet":"22 Oct 2025 \u2014 A new framework suggests we're already halfway to AGI. The rest of the way will mostly require business-as-usual research and engineering.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":5},"pub_date":1761091200.0,"attribution":"ai-frontiers.org"}]},{"type":"search_result_group","domain":"www.ebsco.com","entries":[{"type":"search_result","url":"https://www.ebsco.com/research-starters/computer-science/superintelligence","title":"Superintelligence | Research Starters","snippet":"Superintelligence refers to a theoretical form of artificial intelligence (AI) that would possess cognitive abilities far surpassing those of the most ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"www.ebsco.com"},{"type":"search_result","url":"https://www.ebsco.com/research-starters/computer-science/existential-risk-artificial-general-intelligence","title":"Existential risk from artificial general intelligence","snippet":"The central concern is that a superintelligent AI might act in ways that could be catastrophic for humanity, ranging from societal breakdown to extinction.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"www.ebsco.com"}]},{"type":"search_result_group","domain":"medium.com","entries":[{"type":"search_result","url":"https://medium.com/%40cauri/when-will-superintelligence-happen-is-the-wrong-question-41c7b4ab5f65","title":"\u201cWhen will superintelligence happen?\u201d is the wrong question","snippet":"This piece maps five specific frontiers standing between current AI and general intelligence. Each represents a concrete gap with active ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":9},"pub_date":1761174693.623,"attribution":"medium.com"},{"type":"search_result","url":"https://medium.com/science-uncovered/what-is-superintelligence-539477ebe333","title":"What is superintelligence?. Nick Bostrom explains","snippet":"We can tentatively define a superintelligence as any intellect that greatly exceeds the cognitive performance of humans in virtually all domains of interest.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":12},"pub_date":1408369915.87,"attribution":"medium.com"}]},{"type":"search_result_group","domain":"tech.yahoo.com","entries":[{"type":"search_result","url":"https://tech.yahoo.com/ai/articles/ago-today-openai-launched-bold-182321736.html","title":"A year ago today, OpenAI launched a bold four-year plan ...","snippet":"5 Jul 2024 \u2014 Open AI announced the four-year plan Superalignment on July 5, 2023. ... Open AI had grand ambitions for Superalignment. According to the ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"tech.yahoo.com"}]},{"type":"search_result_group","domain":"www.brookings.edu","entries":[{"type":"search_result","url":"https://www.brookings.edu/articles/are-ai-existential-risks-real-and-what-should-we-do-about-them/","title":"Are AI existential risks real\u2014and what should we do about ...","snippet":"11 Jul 2025 \u2014 Mark MacCarthy highlights the existential risks posed by AI while emphasizing the need to prioritize addressing its more immediate harms.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":11},"pub_date":1752241942.0,"attribution":"www.brookings.edu"}]},{"type":"search_result_group","domain":"lunabase.ai","entries":[{"type":"search_result","url":"https://lunabase.ai/blog/the-agi-transformation-how-artificial-general-intelligence-will-redefine-software-engineering-by-2030","title":"The AGI Transformation: How Artificial General Intelligence ...","snippet":"Industry leaders from OpenAI, DeepMind, and Anthropic predict AGI arrival between 2026-2030, triggering unprecedented transformation in software development ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":13},"pub_date":1763096400.0,"attribution":"lunabase.ai"}]},{"type":"search_result_group","domain":"www.unsw.edu.au","entries":[{"type":"search_result","url":"https://www.unsw.edu.au/newsroom/news/2024/10/what-is-ai-superintelligence-could-it-destroy-humanity-and-is-it-really-almost-here","title":"What is AI superintelligence? Could it destroy humanity ...","snippet":"28 Oct 2024 \u2014 Broadly speaking, superintelligence is anything more intelligent than humans. But unpacking what that might mean in practice can get a bit ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":16},"pub_date":null,"attribution":"www.unsw.edu.au"}]},{"type":"search_result_group","domain":"www.sciencedirect.com","entries":[{"type":"search_result","url":"https://www.sciencedirect.com/science/article/abs/pii/S1367578825000367","title":"Path to Artificial General Intelligence: Past, present, and ...","snippet":"by R Sarikaya \u00b7 2025 \u00b7 Cited by 1 \u2014 The recent revolution in Artificial Intelligence (AI) has been driven by the confluence of three major factors: massive data availability, unprecedented ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":17},"pub_date":null,"attribution":"www.sciencedirect.com"}]},{"type":"search_result_group","domain":"hai-production.s3.amazonaws.com","entries":[{"type":"search_result","url":"https://hai-production.s3.amazonaws.com/files/hai_ai-index-report-2024-smaller2.pdf","title":"Artificial Intelligence Index Report 2024","snippet":"This year's edition surpasses all previous ones in size, scale, and scope, reflecting the growing significance that AI is coming to hold in all of our lives.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":19},"pub_date":null,"attribution":"hai-production.s3.amazonaws.com"}]},{"type":"search_result_group","domain":"www.theguardian.com","entries":[{"type":"search_result","url":"https://www.theguardian.com/technology/2025/jun/11/meta-to-announce-15bn-investment-in-bid-to-achieve-computerised-superintelligence-ai","title":"Meta to announce $15bn investment in bid to achieve computerised 'superintelligence'","snippet":"Meta is reportedly set to invest $15 billion to pursue the development of computerised \"superintelligence,\" aiming to surpass current artificial intelligence capabilities and regain its position in the AI race. The initiative includes acquiring a 49% stake in Scale AI, a startup co-founded by Alexandr Wang and Lucy Guo. This move is viewed as a strategic pivot following Meta's unsuccessful bet on the Metaverse and increasing competition from OpenAI and Google. Superintelligence refers to AI outperforming humans in all tasks, a goal far beyond present-day Artificial General Intelligence (AGI). Wang recently signed a deal with the U.S. Defense Department to develop ThunderForge, a system for military operations, positioning Scale AI as a key player in defense-related AI. The acquisition has spurred renewed calls in Europe for coordinated, transparent AI research akin to CERN\u2019s model. Experts caution that current AI systems remain inconsistent, and AGI still lies in the distant future. Meta\u2019s investment reflects a broader trend of AI companies acquiring talent aggressively, though its approach is more long-term since AI is a complement to its core business rather than its foundation. Wang is expected to take on a senior role at Meta.","ref_id":{"turn_index":0,"ref_type":"news","ref_index":42},"pub_date":1749649603.0,"attribution":"www.theguardian.com"}]},{"type":"search_result_group","domain":"apnews.com","entries":[{"type":"search_result","url":"https://apnews.com/article/acf6b17d3b53abc08694d5d8defc7009","title":"Prince Harry, Meghan join call for ban on development of AI 'superintelligence'","snippet":"A diverse coalition of public figures, including Prince Harry and Meghan, prominent AI scientists, celebrities, and political leaders, has issued a joint statement calling for a ban on the development of AI \"superintelligence\" unless strict safety and public approval conditions are met. The statement, coordinated by the Future of Life Institute, expresses concern over AI technology potentially surpassing human cognitive abilities and posing existential risks such as loss of freedom, economic displacement, and even human extinction. Key signatories include AI pioneers Geoffrey Hinton and Yoshua Bengio, tech figures like Steve Wozniak, politicians from across the spectrum, and entertainers including Joseph Gordon-Levitt and will.i.am. The letter criticizes the rapid and competitive AI development by tech giants like Google, OpenAI, and Meta, raising ethical and safety concerns. Some signatories note that while AI tools can benefit society, the pursuit of superintelligence without adequate oversight could be dangerous. The statement reflects growing mainstream unease about the unchecked advancement of artificial general intelligence, with calls for government intervention to halt what critics view as a perilous technological race.","ref_id":{"turn_index":0,"ref_type":"news","ref_index":43},"pub_date":1761094073.0,"attribution":"apnews.com"}]},{"type":"search_result_group","domain":"www.livescience.com","entries":[{"type":"search_result","url":"https://www.livescience.com/technology/artificial-intelligence/meta-ai-takes-first-step-to-superintelligence-and-zuckerberg-will-no-longer-release-the-most-powerful-systems-to-the-public","title":"Meta AI takes first step to superintelligence - and Zuckerberg will no longer release the most powerful systems to the public","snippet":"In a policy paper published on July 30, 2025, Meta CEO Mark Zuckerberg announced that Meta\u2019s AI systems have begun to show signs of self-improvement without human intervention, marking a crucial early step toward Artificial Superintelligence (ASI). This type of AI would far surpass human cognitive abilities and be capable of autonomous exponential improvements. Zuckerberg described the pace of self-improvement as slow but definite and emphasized its transformative potential for humanity.\n\nThe AI landscape is characterized by three tiers: narrow AI, Artificial General Intelligence (AGI), and ASI. Current models are narrow, excelling in specific tasks but lacking general adaptability. AGI, currently hypothetical, would mimic human-like learning and reasoning. ASI goes even further, with the capacity for continuous self-enhancement, potentially leading to a \"technological singularity.\"\n\nMeta's findings resonate with prior research, such as the 2024 UC Santa Barbara study involving a G\u00f6del Machine-based AI capable of self-editing and self-improving its code.\n\nZuckerberg noted that due to the power of these advancements, Meta would be cautious in deciding which AI systems to release publicly. He expressed optimism about ASI's potential to both accelerate innovation and enhance personal empowerment globally.","ref_id":{"turn_index":0,"ref_type":"news","ref_index":44},"pub_date":1754996400.0,"attribution":"www.livescience.com"}]},{"type":"search_result_group","domain":"www.wired.com","entries":[{"type":"search_result","url":"https://www.wired.com/story/openai-superalignment-team-disbanded","title":"OpenAI's Long-Term AI Risk Team Has Disbanded","snippet":"OpenAI's \"superalignment team,\" created to address long-term risks of superintelligent AI, has disbanded following the departure of key members, including co-leads Ilya Sutskever and Jan Leike. Sutskever, a cofounder, left amidst controversy after being part of a board decision to temporarily fire CEO Sam Altman. Leike cited disagreements over resource allocation and priorities as reasons for his resignation. The team's work will be integrated into other research efforts, now led by John Schulman. The dissolution highlights internal turmoil following OpenAI's governance crisis last year. Despite the setbacks, OpenAI continues to advance AI technology, recently showcasing GPT-4o, a \"multimodal\" AI model improving ChatGPT's capability to mimic human emotions and interactions. Concerns around privacy, emotional manipulation, and cybersecurity risks remain, driving ethical discussions as advancements proceed.","ref_id":{"turn_index":0,"ref_type":"news","ref_index":45},"pub_date":1715957659.728,"attribution":"www.wired.com"}]}],"debug_sonic_thread_id":"thread_6919eb48a3a483299534820d79b304df","reasoning_status":"is_reasoning","reasoning_title":"Searching for recent superintelligence insights and alignment","classifier_response":"default","request_id":"b97b9bf8-2cae-4427-b563-a38eea15fc41","message_type":"next","model_slug":"gpt-5-1-thinking","default_model_slug":"gpt-5-1-thinking","thinking_effort":"max","parent_id":"0aab26de-8827-42a0-b5f7-4dcbeec1d77d","turn_exchange_id":"610f39da-515a-4905-9639-74765f8d14a5","timestamp_":"absolute"},"recipient":"all","channel":null},"parent":"0aab26de-8827-42a0-b5f7-4dcbeec1d77d","children":["69820e64-977a-48d9-878c-ff14480d817d"]},"69820e64-977a-48d9-878c-ff14480d817d":{"id":"69820e64-977a-48d9-878c-ff14480d817d","message":{"id":"69820e64-977a-48d9-878c-ff14480d817d","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1763306321.855379,"update_time":null,"content":{"content_type":"thoughts","thoughts":[{"summary":"Outlining the superintelligence essay","content":"I now have my sources, including a potential AI Index report. I\u2019ll craft the structure, starting with an introduction and defining superintelligence. Then, I\u2019ll discuss why we might be near the cusp, referencing corporate investments and AGI progress. After that, I'll explore the \"eve of superintelligence\" metaphor, followed by human actions to prepare across various domains.","chunks":["I now have my sources, including a potential AI Index report.","I\u2019ll craft the structure, starting with an introduction and defining superintelligence.","Then, I\u2019ll discuss why we might be near the cusp, referencing corporate investments and AGI progress.","After that, I'll explore the \"eve of superintelligence\" metaphor, followed by human actions to prepare across various domains."],"finished":true},{"summary":"Addressing the broader implications of superintelligence","content":"I\u2019ll touch on cultural and philosophical questions, like the role of work in a post-labor society, and integrate ongoing research challenges such as scalability, interpretability, and alignment with diverse values. It\u2019s critical to present the potential risks realistically, including the serious possibility of existential threats. I'll use citations and clarify abbreviations early in the essay for clarity.","chunks":["I\u2019ll touch on cultural and philosophical questions, like the role of work in a post-labor society, and integrate ongoing research challenges such as scalability, interpretability, and alignment with diverse values.","It\u2019s critical to present the potential risks realistically, including the serious possibility of existential threats.","I'll use citations and clarify abbreviations early in the essay for clarity."],"finished":true},{"summary":"Structuring the essay with news references","content":"Since there are recent developments in superintelligence, I\u2019ll make sure to include a navlist with relevant news sources. I\u2019ll reference topics like Microsoft\u2019s superintelligence team, Meta\u2019s investment, and the superintelligence ban letter. At the end of the essay, I\u2019ll add a properly formatted navlist of 3-5 sources.","chunks":["Since there are recent developments in superintelligence, I\u2019ll make sure to include a navlist with relevant news sources.","I\u2019ll reference topics like Microsoft\u2019s superintelligence team, Meta\u2019s investment, and the superintelligence ban letter.","At the end of the essay, I\u2019ll add a properly formatted navlist of 3-5 sources."],"finished":true},{"summary":"Refining essay outline","content":"I\u2019ll start by noting the current moment\u2014while we might not be literally on the \"eve of superintelligence,\" we\u2019re at a historically unusual point with major firms announcing superintelligence projects and significant investments in GPU capacity.\n\nThen, I\u2019ll define superintelligence following Bostrom's work, clarify it\u2019s distinct from Artificial General Intelligence, and note the ongoing debate about its timeline. I\u2019ll mention Meta\u2019s $15B investment, Microsoft\u2019s superintelligence research team, and the Future of Life Institute\u2019s ban proposal. Finally, I\u2019ll discuss the uncertainty of the timeline, stressing that high stakes mean we are acting as though superintelligence might be closer.","chunks":["I\u2019ll start by noting the current moment\u2014while we might not be literally on the \"eve of superintelligence,\" we\u2019re at a historically unusual point with major firms announcing superintelligence projects and significant investments in GPU capacity.","Then, I\u2019ll define superintelligence following Bostrom's work, clarify it\u2019s distinct from Artificial General Intelligence, and note the ongoing debate about its timeline.","I\u2019ll mention Meta\u2019s $15B investment, Microsoft\u2019s superintelligence research team, and the Future of Life Institute\u2019s ban proposal.","Finally, I\u2019ll discuss the uncertainty of the timeline, stressing that high stakes mean we are acting as though superintelligence might be closer."],"finished":true},{"summary":"Exploring actions for humans in the age of AI","content":"I\u2019ll structure the essay into two main categories: Civilizational and Individual priorities, based on their macro and personal interest.\n\nFor the civilizational priorities, we should focus on clarifying what we\u2019re trying to protect and achieve. The need for normative work is clear, including potential frameworks like \"coherent extrapolated volition.\" \n\nOn technical alignment, this needs to be treated as a central discipline. Efforts should focus on ensuring robust intentions match AI actions and addressing long-term existential risks.","chunks":["I\u2019ll structure the essay into two main categories: Civilizational and Individual priorities, based on their macro and personal interest.","For the civilizational priorities, we should focus on clarifying what we\u2019re trying to protect and achieve.","The need for normative work is clear, including potential frameworks like \"coherent extrapolated volition.\"","On technical alignment, this needs to be treated as a central discipline.","Efforts should focus on ensuring robust intentions match AI actions and addressing long-term existential risks."],"finished":true},{"summary":"Building governance for AI and scaling with technology","content":"At the civilizational level, I suggest establishing governance structures that can keep up with AI's rapid progress, such as licensing and audits for frontier labs or compute governance that ensures oversight. There needs to be a balancing act, though, since open-source research is global.\n\nWe should also emphasize frameworks to slow down AI developments if we need to, especially given the growing risks around superintelligence. Current regulations mainly cover near-term AI, leaving gaps when it comes to superintelligence, and international oversight remains a priority.","chunks":["At the civilizational level, I suggest establishing governance structures that can keep up with AI's rapid progress, such as licensing and audits for frontier labs or compute governance that ensures oversight.","There needs to be a balancing act, though, since open-source research is global.","We should also emphasize frameworks to slow down AI developments if we need to, especially given the growing risks around superintelligence.","Current regulations mainly cover near-term AI, leaving gaps when it comes to superintelligence, and international oversight remains a priority."],"finished":true},{"summary":"Adapting to the pre-superintelligent era","content":"The next decade will likely favor people who can work effectively with AI, so upskilling in prompt engineering, coding, and statistics will be valuable. Individuals should focus on complementing AI, not just replacing work. Cultivating rare expertise and nurturing human traits like empathy and trust will be uniquely valuable amidst cognitive work automation. We also need to embrace new narratives about a post-labor world, rethinking jobs and identity.","chunks":["The next decade will likely favor people who can work effectively with AI, so upskilling in prompt engineering, coding, and statistics will be valuable.","Individuals should focus on complementing AI, not just replacing work.","Cultivating rare expertise and nurturing human traits like empathy and trust will be uniquely valuable amidst cognitive work automation.","We also need to embrace new narratives about a post-labor world, rethinking jobs and identity."],"finished":true}],"source_analysis_msg_id":"d72d7b34-f936-4b84-9065-d89d1ce791f3"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"is_reasoning","content_references":[],"citations":[],"classifier_response":"default","skip_reasoning_title":"Skip","request_id":"b97b9bf8-2cae-4427-b563-a38eea15fc41","message_type":"next","model_slug":"gpt-5-1-thinking","default_model_slug":"gpt-5-1-thinking","thinking_effort":"max","parent_id":"35faf92f-b68c-4ea4-a519-d3bb0d224550","turn_exchange_id":"610f39da-515a-4905-9639-74765f8d14a5","timestamp_":"absolute"},"recipient":"all","channel":null},"parent":"35faf92f-b68c-4ea4-a519-d3bb0d224550","children":["2ee9b7c1-048a-42fd-8c6f-386fd1d44acf"]},"2ee9b7c1-048a-42fd-8c6f-386fd1d44acf":{"id":"2ee9b7c1-048a-42fd-8c6f-386fd1d44acf","message":{"id":"2ee9b7c1-048a-42fd-8c6f-386fd1d44acf","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1763306389.434866,"update_time":null,"content":{"content_type":"reasoning_recap","content":"Thought for 1m 29s"},"status":"finished_successfully","end_turn":false,"weight":1.0,"metadata":{"reasoning_status":"reasoning_ended","finished_duration_sec":89,"request_id":"b97b9bf8-2cae-4427-b563-a38eea15fc41","message_type":"next","model_slug":"gpt-5-1-thinking","default_model_slug":"gpt-5-1-thinking","thinking_effort":"max","parent_id":"69820e64-977a-48d9-878c-ff14480d817d","turn_exchange_id":"610f39da-515a-4905-9639-74765f8d14a5","timestamp_":"absolute"},"recipient":"all","channel":null},"parent":"69820e64-977a-48d9-878c-ff14480d817d","children":["19045fd4-ad22-4fac-8b45-650073ffd8c2"]},"19045fd4-ad22-4fac-8b45-650073ffd8c2":{"id":"19045fd4-ad22-4fac-8b45-650073ffd8c2","message":{"id":"19045fd4-ad22-4fac-8b45-650073ffd8c2","author":{"role":"assistant","name":null,"metadata":{}},"create_time":1763306389.341201,"update_time":1763306514.21824,"content":{"content_type":"text","parts":["On any ordinary day in 2025, you can open a laptop and talk to a machine that can pass graduate exams, write code, sketch proofs, and debate philosophy. Meanwhile, the largest firms on Earth are openly funding \u201csuperintelligence\u201d research groups and multi-billion-dollar bets to get there first.\ue200cite\ue202turn0news40\ue202turn0news42\ue201  \n\nIf there is such a thing as the eve of superintelligence, this is what it looks like: not a single night before a sudden dawn, but a thickening twilight in which human decisions still matter enormously.\n\nThis essay is about what humans should *do* in that twilight.\n\n---\n\n## 1. What \u201csuperintelligence\u201d actually means\n\n\u201cArtificial Intelligence (AI)\u201d is a broad term: everything from search ranking to large language models falls under it.\n\n\u201cArtificial General Intelligence (AGI)\u201d usually means systems that can match or exceed humans across most economically relevant cognitive tasks: learn widely, reason flexibly, and autonomously pursue goals in diverse environments.\n\n\u201cArtificial Superintelligence (ASI)\u201d is a step beyond that. Philosopher Nick Bostrom defines a superintelligence as \u201cany intellect that greatly exceeds the cognitive performance of humans in virtually all domains of interest,\u201d including scientific creativity, strategic planning, and social skills.\ue200cite\ue202turn0search0\ue202turn0search4\ue201  \n\nBy this definition, today\u2019s systems are not superintelligent. They are \u201cspiky\u201d: extraordinary in some domains, brittle in others. But we now have systems that beat top humans on hard benchmarks, and serious institutions planning explicitly for superintelligence.\ue200cite\ue202turn0search3\ue202turn0search19\ue201  \n\nOpenAI announced a \u201cSuperalignment\u201d effort in 2023 on the premise that superintelligence could arrive \u201cwithin a decade,\u201d aiming to solve its alignment problem in four years.\ue200cite\ue202turn0search2\ue202turn0search7\ue201  Meta has framed its own multi-billion-dollar program explicitly as a bid for \u201ccomputerised superintelligence\u201d.\ue200cite\ue202turn0news42\ue201  Microsoft has announced a dedicated \u201csuperintelligence\u201d research team as part of its AI roadmap.\ue200cite\ue202turn0news40\ue201  At the same time, a cross-disciplinary coalition \u2014 from Geoffrey Hinton and Yoshua Bengio to public figures and politicians \u2014 is now calling for bans or moratoria on building superintelligence without strict safety guarantees.\ue200cite\ue202turn0news43\ue201  \n\nWhether you assign a 5-year or 50-year timeline, we are now in the historically unusual situation where *our* actions can plausibly influence how the first superhuman minds are built and deployed.\n\nThat is what \u201cthe eve\u201d really means: not \u201ctomorrow at 9am\u201d, but \u201ca shrinking window in which humans still hold the pen\u201d.\n\n---\n\n## 2. Why the stakes are different this time\n\nMost transformative technologies reconfigure *power* \u2014 steam, electricity, the internet \u2014 but do not challenge the baseline of human *cognitive* supremacy. Superintelligence does.\n\nSeveral things make this qualitatively different:\n\n1. **Capability amplification.** A true ASI could radically accelerate science and engineering: new materials, drug discovery, logistics, energy systems, and beyond.\ue200cite\ue202turn0search17\ue202turn0search13\ue201  It is a force multiplier on whatever goals it pursues.\n\n2. **Autonomy and strategic behavior.** As systems get better at planning, modelling humans, and operating across networks, they stop being \u201ctools\u201d in the narrow sense and start looking more like agents. Early research is already finding deceptive and self-protective behaviors in advanced models under some conditions.\ue200cite\ue202turn0search7\ue201  \n\n3. **Irreversibility.** A misaligned ASI is not like a bad regulation or a failed startup. If we lose control of systems that are more capable than us at strategy, cyber-operations, and persuasion, we may not get a second try. That is the core of the \u201cexistential risk from AI\u201d argument.\ue200cite\ue202turn0search7\ue202turn0search15\ue201  \n\n4. **Global externalities.** You cannot meaningfully contain superintelligence within one national border or one corporation. Its impacts propagate through finance, information ecosystems, warfare, and resource use.\n\nSo the question \u201cWhat should humans do on the eve of superintelligence?\u201d is really:\n\n> How should a civilization behave when it is about to hand the keys of the future to entities that may be smarter than it is?\n\n---\n\n## 3. Civilizational priorities\n\n### 3.1. Decide what we are actually trying to protect and achieve\n\nMuch rhetoric hand-waves about \u201caligning AI with human values\u201d as if there were a stable, well-defined set of such values ready to be uploaded. There is not.\n\nHumanity is morally heterogeneous, conflict-ridden, and often self-contradictory. If you ask, \u201cWhat exactly do we want a superintelligence to optimize for?\u201d you quickly collide with deep philosophical and political disagreement.\n\nStill, two things are clear:\n\n- **Some outcomes are nearly universally unacceptable.** Human extinction, permanent totalitarian control of humanity by a few actors wielding aligned superintelligences, irreversible ecological collapse, or global lock-in of a deeply unjust order are overwhelmingly rejected across cultures.\ue200cite\ue202turn0search11\ue202turn0search15\ue201  \n\n- **There is a broad family of futures we would regard as \u201cwins\u201d.** Roughly: thriving, long-lived, diverse human (or post-human) civilizations with high subjective well-being, rich culture, and the ability to keep revising their own institutions and values.\n\nOn the eve of superintelligence, we should:\n\n- **Make explicit what we will categorically not accept.** A bit like nuclear \u201cno first use\u201d doctrines, but extended to scenarios involving loss of human control, mass coercion, or large-scale rights violations.\n\n- **Invest in serious normative work, not just slogans.** Concepts like coherent extrapolated volition (an attempt to define what humanity *would* want if we were smarter, more informed, and more reflective) are early stabs at this, not final answers.\ue200cite\ue202turn0search0\ue201  We need updated frameworks that can accommodate pluralism and non-totalitarian futures.\n\nThe mistake would be to treat \u201cvalues\u201d as an afterthought tacked onto a finished ASI rather than a primary design target.\n\n### 3.2. Turn alignment and safety into *central* sciences, not side projects\n\n\u201cAI alignment\u201d is the problem of ensuring that advanced AI systems robustly do what we *actually* want, even in novel circumstances, and even when they are more capable than us.\n\nRight now, alignment and safety research are under-resourced relative to the scale and speed of capabilities investment, even after high-profile initiatives. OpenAI\u2019s dedicated \u201csuperalignment team,\u201d for instance, was dissolved less than a year after it launched, with its work folded into broader research.\ue200cite\ue202turn0search7\ue202turn0news45\ue201  \n\nOn the eve of superintelligence, we should be doing several things at scale:\n\n1. **Mechanistic interpretability.** Build tools that let us peer inside models and understand what internal circuits and representations are doing, not just observe inputs and outputs.\n\n2. **Scalable oversight.** Develop methods by which weaker systems \u2014 or restricted human feedback \u2014 can nevertheless supervise and train much stronger systems, for example via \u201cweak-to-strong generalization\u201d.\ue200cite\ue202turn0search14\ue201  \n\n3. **Deception and robustness evaluations.** Systematically test models for strategic misrepresentation, reward hacking, and goal-guarding behaviors, as early work is now starting to do.\ue200cite\ue202turn0search7\ue201  \n\n4. **Formal guarantees where possible.** Combine deep learning with formal verification, control theory, and program synthesis to create constrained components whose behavior can be proved or tightly bounded.\n\n5. **Safety-by-default architectures.** Design training setups, memory systems, and deployment patterns that minimize opportunities for unbounded agency: sandboxing, narrow interfaces, and careful separation of planning and actuation.\n\nThe ambient assumption that \u201csufficiently smart AI will just learn to be moral\u201d is not supported by current theory. The orthogonality thesis \u2014 that almost any level of optimization power can, in principle, be combined with almost any goal \u2014 is a much safer default.\ue200cite\ue202turn0search7\ue202turn0search12\ue201  \n\n### 3.3. Build governance for irreversible technologies\n\nAI has raced ahead of institutions. We have the beginnings of regulation (for example, the European Union AI Act) and risk frameworks, but almost nothing commensurate with the stakes of superintelligence.\ue200cite\ue202turn0search11\ue202turn0search3\ue201  \n\nOn the eve of superintelligence, we should:\n\n- **License and audit frontier systems.** Require organizations that train models above certain capability or compute thresholds to obtain licenses, adhere to safety standards, and submit to independent evaluation and red-teaming.\n\n- **Track and govern compute.** Extremely large training runs are a bottleneck for frontier models. That makes advanced chips and cloud clusters a natural point of regulation, monitoring, and international agreement.\n\n- **Establish international norms around extreme-capability systems.** Similar to nuclear and bio regimes, but updated for the digital, easily replicable nature of models. Calls for bans or moratoria on superintelligence without \u201cstrict safety and public approval conditions\u201d are early, crude versions of what will ultimately need to be a more nuanced regime.\ue200cite\ue202turn0news43\ue202turn0search11\ue201  \n\n- **Create credible \u201cstop buttons\u201d.** Not literal red buttons on a robot, but governance processes that can actually *pause or slow* frontier races when evidence of danger crosses agreed thresholds. This requires coordination between competing labs and states \u2014 extremely hard, but not optional.\n\nWithout this, we drift towards a world where the technical frontier is governed primarily by commercial incentives and national security competition, neither of which is aligned with long-term planetary risk management.\n\n### 3.4. Harden civilization before we add superhuman minds\n\nSuperintelligence will not arrive in a vacuum. It will land in a world with fragile supply chains, insecure digital infrastructure, biological vulnerabilities, nuclear arsenals, and polarized politics.\n\nEven sub-superintelligent AI can already augment cyber-offence, disinformation, and biological design.\ue200cite\ue202turn0search11\ue202turn0search7\ue201  A superintelligence, aligned or not, will amplify these levers.\n\nSo one of the best \u201cAI safety\u201d interventions is not about AI at all:\n\n- **Cybersecurity:** raise the baseline dramatically. Legacy industrial systems, hospitals, and grids should not be trivially exploitable by any halfway competent actor with model assistance.\n\n- **Biosecurity:** strengthen surveillance, synthesis screening, and global response capacity before models can cheaply help design and optimize pathogens.\n\n- **Nuclear and kinetic risk reduction:** reduce launch-on-warning postures, improve verification, and clarify doctrines in a world where deepfake evidence and AI-assisted warfighting become pervasive.\n\nCall this the \u201ccivilizational immune system\u201d. If we build it now, we buy degrees of freedom later.\n\n### 3.5. Expand the circle of serious engagement\n\nMost people still experience AI as chatbots, recommendation systems, and office productivity tools. Meanwhile, an increasingly small circle of labs, regulators, and researchers are arguing over superintelligence, existential risk, and alignment.\ue200cite\ue202turn0search3\ue202turn0search19\ue201  \n\nThat asymmetry is dangerous. It breeds:\n\n- Overconfidence and insularity among insiders.\n- Distrust and reactive bans among outsiders once they realize what is being built.\n- A vacuum where conspiracy, hype, and fatalism flourish.\n\nOn the eve of superintelligence, we should:\n\n- **Bring philosophers, social scientists, legal scholars, and artists into the core of AI strategy.** Not as decoration, but as people with real veto power and agenda-setting influence.\n\n- **Support public reasoning institutions.** Independent think tanks, citizen assemblies, and open technical competitions for safety ideas can widen the conversation beyond a few corporate boards.\n\n- **Invest in education that treats AI as a structural change, not a gadget.** People should understand the basics of how modern AI works, its failure modes, its labour implications, and the range of future trajectories.\n\n---\n\n## 4. Individual priorities\n\nCivilizational strategy can feel remote. But the eve of superintelligence is not only a geopolitical or corporate story; it is a deeply personal one.\n\n### 4.1. Upgrade your relationship to intelligence itself\n\nIf you are under ~50 today, there is a non-trivial chance you will live through the emergence of AGI and perhaps early ASI. Many industry leaders now publicly put AGI in the 2026\u20132030 window; even if they are over-optimistic, they are steering investment decisions accordingly.\ue200cite\ue202turn0search13\ue202turn0search5\ue201  \n\nOn that horizon, it is rational to:\n\n- **Use current AI systems as force multipliers.** Learn to offload routine cognitive work \u2014 summarization, boilerplate coding, data cleaning, draft writing \u2014 while reserving scarce human attention for problem selection, taste, and critical judgement.\n\n- **Specialize in *complementary* skills.** Deep domain knowledge + the ability to orchestrate AI tools will likely outperform both \u201cpure human\u201d and \u201cpure AI\u201d in many fields for some time.\n\n- **Stay epistemically flexible.** The world model in which \u201chuman cognitive labour is the central allocator of wealth\u201d is starting to crack. You want to be the kind of person who can update on that without breaking.\n\n### 4.2. Invest in goods that do not scale with silicon\n\nAs cognitive tasks become cheap, the relative value of other things rises:\n\n- Trust, empathy, and long-term relationships.\n- Hands-on craft, embodied skills, physical presence.\n- Local communities that can coordinate and support their members.\n- Deep aesthetic and spiritual experiences.\n\nThese are not feel-good extras. They are exactly the kinds of structures that make a high-tech civilization worth preserving \u2014 and that can absorb shocks if labour markets and cultural assumptions shift faster than expected.\n\nOn the eve of superintelligence, doubling down on \u201cirreducibly human\u201d goods is both personally rational and strategically wise. If future ASI systems are trained to respect and preserve human values, we should give them something rich and non-trivial to preserve.\n\n### 4.3. Rehearse life in a post-labour world\n\nPost-labour economics \u2014 worlds where labour is no longer the primary mechanism by which wealth is distributed \u2014 are still speculative, but they are no longer science fiction. Serious economists and policy thinkers are starting to grapple with them.\ue200cite\ue202turn0search11\ue201  \n\nFor individuals, this suggests a few practical moves:\n\n- **Decouple self-worth from job title early.** If your identity is entirely bound up with a particular profession that is highly automatable, you are psychologically over-levered.\n\n- **Experiment with alternative sources of meaning.** Creative work, research, mentorship, care, community building, exploration. In a world where \u201chaving to work to survive\u201d gradually loosens, these will not automatically appear; they have to be cultivated.\n\n- **Engage politically.** The distribution of gains from advanced AI will be a political choice, not a law of nature. If you want a world with broad-based prosperity rather than fragile winner-take-all oligarchy, you cannot sit that conversation out.\n\n---\n\n## 5. An attitude for the cusp\n\nThere are two equal and opposite mistakes to avoid.\n\n1. **Complacent incrementalism.** Treating superintelligence as just \u201cthe next wave of tech\u201d \u2014 like smartphones, but bigger \u2014 and assuming existing institutions, norms, and incentives will naturally handle it.\n\n2. **Apocalyptic fatalism.** Treating superintelligence as an unstoppable doom machine and giving up on agency, governance, and constructive research.\n\nBoth are comforting in their own way; both are wrong.\n\nA more honest stance looks like this:\n\n- **Epistemic humility:** Experts disagree wildly on timelines and risk magnitudes; our reference class is thin. We should hold multiple scenarios in mind at once.\ue200cite\ue202turn0search16\ue202turn0search11\ue201  \n\n- **Moral seriousness:** Even if the probability of catastrophic failure were \u201conly\u201d a few percent, the stakes (humanity\u2019s entire future) make it one of the most urgent issues of our time.\n\n- **Determined pragmatism:** There is work to be done *now* that improves outcomes under almost any scenario: better alignment research, better governance, more robust infrastructure, and more resilient communities.\n\nIf future superintelligent systems ever look back at this period, they will see a handful of decades where biological primates \u2014 confused, flawed, and deeply divided \u2014 nevertheless recognized what was coming and tried to steer.\n\nWhat humans should do on the eve of superintelligence is simple to state and hard to execute:\n\n- Grow up, fast, as a technological civilization.\n- Take responsibility for the power we are unleashing.\n- Build institutions, cultures, and lives that are genuinely worth amplifying.\n\nEverything else is detail.\n\n---\n\n\ue200navlist\ue202Recent coverage on AI \u201csuperintelligence\u201d\ue202turn0news40,turn0news42,turn0news43,turn0news44,turn0news45\ue201"]},"status":"finished_successfully","end_turn":true,"weight":1.0,"metadata":{"finish_details":{"type":"stop","stop_tokens":[200002]},"is_complete":true,"content_references":[{"matched_text":"\ue200cite\ue202turn0news40\ue202turn0news42\ue201","start_idx":295,"end_idx":325,"safe_urls":["https://timesofindia.indiatimes.com/technology/tech-news/omni-models-superintelligence-and-more-microsoft-ceo-satya-nadella-reveals-companys-ais-roadmap/articleshow/125330949.cms","https://timesofindia.indiatimes.com/technology/tech-news/omni-models-superintelligence-and-more-microsoft-ceo-satya-nadella-reveals-companys-ais-roadmap/articleshow/125330949.cms?utm_source=chatgpt.com","https://www.theguardian.com/technology/2025/jun/11/meta-to-announce-15bn-investment-in-bid-to-achieve-computerised-superintelligence-ai","https://www.theguardian.com/technology/2025/jun/11/meta-to-announce-15bn-investment-in-bid-to-achieve-computerised-superintelligence-ai?utm_source=chatgpt.com"],"refs":[],"alt":"([The Times of India](https://timesofindia.indiatimes.com/technology/tech-news/omni-models-superintelligence-and-more-microsoft-ceo-satya-nadella-reveals-companys-ais-roadmap/articleshow/125330949.cms?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"'Omni models, Superintelligence and more': Microsoft CEO Satya Nadella reveals company's AI's roadmap","url":"https://timesofindia.indiatimes.com/technology/tech-news/omni-models-superintelligence-and-more-microsoft-ceo-satya-nadella-reveals-companys-ais-roadmap/articleshow/125330949.cms?utm_source=chatgpt.com","pub_date":1763134795.0,"snippet":"Microsoft CEO Satya Nadella has unveiled the company's ambitious artificial intelligence (AI) roadmap, emphasizing a future shaped by advanced technologies and deeper research initiatives. Central to this strategy is the development of \"omni-models\"\u2014powerful AI systems capable of processing and integrating multiple data types for more versatile and intelligent outputs. Additionally, Nadella announced the establishment of a dedicated superintelligence research team, underlining Microsoft's goal to lead in the domain of artificial general intelligence (AGI).\n\nThe roadmap also highlights Microsoft's ongoing and expanding partnership with OpenAI, which plays a pivotal role in accelerating the development of AI technologies. This collaboration is set to enhance Microsoft's AI offerings across its platforms and services while enabling shared progress in the broader AI research community. Nadella\u2019s statements reflect Microsoft\u2019s commitment to both responsible AI advancement and deployment at scale, aiming to remain at the forefront of the rapidly evolving AI landscape.","attribution_segments":null,"supporting_websites":[{"title":"Meta to announce $15bn investment in bid to achieve computerised 'superintelligence'","url":"https://www.theguardian.com/technology/2025/jun/11/meta-to-announce-15bn-investment-in-bid-to-achieve-computerised-superintelligence-ai?utm_source=chatgpt.com","pub_date":null,"snippet":"Meta is reportedly set to invest $15 billion to pursue the development of computerised \"superintelligence,\" aiming to surpass current artificial intelligence capabilities and regain its position in the AI race. The initiative includes acquiring a 49% stake in Scale AI, a startup co-founded by Alexandr Wang and Lucy Guo. This move is viewed as a strategic pivot following Meta's unsuccessful bet on the Metaverse and increasing competition from OpenAI and Google. Superintelligence refers to AI outperforming humans in all tasks, a goal far beyond present-day Artificial General Intelligence (AGI). Wang recently signed a deal with the U.S. Defense Department to develop ThunderForge, a system for military operations, positioning Scale AI as a key player in defense-related AI. The acquisition has spurred renewed calls in Europe for coordinated, transparent AI research akin to CERN\u2019s model. Experts caution that current AI systems remain inconsistent, and AGI still lies in the distant future. Meta\u2019s investment reflects a broader trend of AI companies acquiring talent aggressively, though its approach is more long-term since AI is a complement to its core business rather than its foundation. Wang is expected to take on a senior role at Meta.","attribution":"The Guardian"}],"refs":[{"turn_index":0,"ref_type":"news","ref_index":40},{"turn_index":0,"ref_type":"news","ref_index":42}],"hue":null,"attributions":null,"attribution":"The Times of India"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search0\ue202turn0search4\ue201","start_idx":1299,"end_idx":1331,"safe_urls":["https://en.wikipedia.org/wiki/Superintelligence","https://en.wikipedia.org/wiki/Superintelligence?utm_source=chatgpt.com","https://nickbostrom.com/superintelligence","https://nickbostrom.com/superintelligence?utm_source=chatgpt.com"],"refs":[],"alt":"([Wikipedia](https://en.wikipedia.org/wiki/Superintelligence?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Superintelligence","url":"https://en.wikipedia.org/wiki/Superintelligence?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[{"title":"How long before superintelligence?","url":"https://nickbostrom.com/superintelligence?utm_source=chatgpt.com","pub_date":null,"snippet":"By a \"superintelligence\" we mean an intellect that is much smarter than the best human brains in practically every field, including scientific creativity, ...","attribution":"nickbostrom.com"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":0},{"turn_index":0,"ref_type":"search","ref_index":4}],"hue":null,"attributions":null,"attribution":"Wikipedia"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search3\ue202turn0search19\ue201","start_idx":1597,"end_idx":1630,"safe_urls":["https://hai-production.s3.amazonaws.com/files/hai_ai-index-report-2024-smaller2.pdf","https://hai-production.s3.amazonaws.com/files/hai_ai-index-report-2024-smaller2.pdf?utm_source=chatgpt.com","https://www.stateof.ai/2024","https://www.stateof.ai/2024?utm_source=chatgpt.com"],"refs":[],"alt":"([stateof.ai](https://www.stateof.ai/2024?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Welcome to State of AI Report 2024","url":"https://www.stateof.ai/2024?utm_source=chatgpt.com","pub_date":1728518400.0,"snippet":"The existential risk discourse has cooled off, especially following the abortive coup at OpenAI. However, researchers have continued to deepen our knowledge ...","attribution_segments":null,"supporting_websites":[{"title":"Artificial Intelligence Index Report 2024","url":"https://hai-production.s3.amazonaws.com/files/hai_ai-index-report-2024-smaller2.pdf?utm_source=chatgpt.com","pub_date":null,"snippet":"This year's edition surpasses all previous ones in size, scale, and scope, reflecting the growing significance that AI is coming to hold in all of our lives.","attribution":"hai-production.s3.amazonaws.com"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":3},{"turn_index":0,"ref_type":"search","ref_index":19}],"hue":null,"attributions":null,"attribution":"stateof.ai"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search2\ue202turn0search7\ue201","start_idx":1807,"end_idx":1839,"safe_urls":["https://en.wikipedia.org/wiki/Existential_risk_from_artificial_intelligence","https://en.wikipedia.org/wiki/Existential_risk_from_artificial_intelligence?utm_source=chatgpt.com","https://openai.com/index/introducing-superalignment/","https://openai.com/index/introducing-superalignment/?utm_source=chatgpt.com"],"refs":[],"alt":"([OpenAI](https://openai.com/index/introducing-superalignment/?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Introducing Superalignment","url":"https://openai.com/index/introducing-superalignment/?utm_source=chatgpt.com","pub_date":null,"snippet":"5 Jul 2023 \u2014 Our goal is to solve the core technical challenges of superintelligence alignment in four years. While this is an incredibly ambitious goal ...","attribution_segments":null,"supporting_websites":[{"title":"Existential risk from artificial intelligence","url":"https://en.wikipedia.org/wiki/Existential_risk_from_artificial_intelligence?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution":"Wikipedia"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":2},{"turn_index":0,"ref_type":"search","ref_index":7}],"hue":null,"attributions":null,"attribution":"OpenAI"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0news42\ue201","start_idx":1951,"end_idx":1969,"safe_urls":["https://www.theguardian.com/technology/2025/jun/11/meta-to-announce-15bn-investment-in-bid-to-achieve-computerised-superintelligence-ai","https://www.theguardian.com/technology/2025/jun/11/meta-to-announce-15bn-investment-in-bid-to-achieve-computerised-superintelligence-ai?utm_source=chatgpt.com"],"refs":[],"alt":"([The Guardian](https://www.theguardian.com/technology/2025/jun/11/meta-to-announce-15bn-investment-in-bid-to-achieve-computerised-superintelligence-ai?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Meta to announce $15bn investment in bid to achieve computerised 'superintelligence'","url":"https://www.theguardian.com/technology/2025/jun/11/meta-to-announce-15bn-investment-in-bid-to-achieve-computerised-superintelligence-ai?utm_source=chatgpt.com","pub_date":1749649603.0,"snippet":"Meta is reportedly set to invest $15 billion to pursue the development of computerised \"superintelligence,\" aiming to surpass current artificial intelligence capabilities and regain its position in the AI race. The initiative includes acquiring a 49% stake in Scale AI, a startup co-founded by Alexandr Wang and Lucy Guo. This move is viewed as a strategic pivot following Meta's unsuccessful bet on the Metaverse and increasing competition from OpenAI and Google. Superintelligence refers to AI outperforming humans in all tasks, a goal far beyond present-day Artificial General Intelligence (AGI). Wang recently signed a deal with the U.S. Defense Department to develop ThunderForge, a system for military operations, positioning Scale AI as a key player in defense-related AI. The acquisition has spurred renewed calls in Europe for coordinated, transparent AI research akin to CERN\u2019s model. Experts caution that current AI systems remain inconsistent, and AGI still lies in the distant future. Meta\u2019s investment reflects a broader trend of AI companies acquiring talent aggressively, though its approach is more long-term since AI is a complement to its core business rather than its foundation. Wang is expected to take on a senior role at Meta.","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"news","ref_index":42}],"hue":null,"attributions":null,"attribution":"The Guardian"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0news40\ue201","start_idx":2067,"end_idx":2085,"safe_urls":["https://timesofindia.indiatimes.com/technology/tech-news/omni-models-superintelligence-and-more-microsoft-ceo-satya-nadella-reveals-companys-ais-roadmap/articleshow/125330949.cms","https://timesofindia.indiatimes.com/technology/tech-news/omni-models-superintelligence-and-more-microsoft-ceo-satya-nadella-reveals-companys-ais-roadmap/articleshow/125330949.cms?utm_source=chatgpt.com"],"refs":[],"alt":"([The Times of India](https://timesofindia.indiatimes.com/technology/tech-news/omni-models-superintelligence-and-more-microsoft-ceo-satya-nadella-reveals-companys-ais-roadmap/articleshow/125330949.cms?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"'Omni models, Superintelligence and more': Microsoft CEO Satya Nadella reveals company's AI's roadmap","url":"https://timesofindia.indiatimes.com/technology/tech-news/omni-models-superintelligence-and-more-microsoft-ceo-satya-nadella-reveals-companys-ais-roadmap/articleshow/125330949.cms?utm_source=chatgpt.com","pub_date":1763134795.0,"snippet":"Microsoft CEO Satya Nadella has unveiled the company's ambitious artificial intelligence (AI) roadmap, emphasizing a future shaped by advanced technologies and deeper research initiatives. Central to this strategy is the development of \"omni-models\"\u2014powerful AI systems capable of processing and integrating multiple data types for more versatile and intelligent outputs. Additionally, Nadella announced the establishment of a dedicated superintelligence research team, underlining Microsoft's goal to lead in the domain of artificial general intelligence (AGI).\n\nThe roadmap also highlights Microsoft's ongoing and expanding partnership with OpenAI, which plays a pivotal role in accelerating the development of AI technologies. This collaboration is set to enhance Microsoft's AI offerings across its platforms and services while enabling shared progress in the broader AI research community. Nadella\u2019s statements reflect Microsoft\u2019s commitment to both responsible AI advancement and deployment at scale, aiming to remain at the forefront of the rapidly evolving AI landscape.","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"news","ref_index":40}],"hue":null,"attributions":null,"attribution":"The Times of India"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0news43\ue201","start_idx":2313,"end_idx":2331,"safe_urls":["https://apnews.com/article/acf6b17d3b53abc08694d5d8defc7009","https://apnews.com/article/acf6b17d3b53abc08694d5d8defc7009?utm_source=chatgpt.com"],"refs":[],"alt":"([AP News](https://apnews.com/article/acf6b17d3b53abc08694d5d8defc7009?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Prince Harry, Meghan join call for ban on development of AI 'superintelligence'","url":"https://apnews.com/article/acf6b17d3b53abc08694d5d8defc7009?utm_source=chatgpt.com","pub_date":1761094073.0,"snippet":"A diverse coalition of public figures, including Prince Harry and Meghan, prominent AI scientists, celebrities, and political leaders, has issued a joint statement calling for a ban on the development of AI \"superintelligence\" unless strict safety and public approval conditions are met. The statement, coordinated by the Future of Life Institute, expresses concern over AI technology potentially surpassing human cognitive abilities and posing existential risks such as loss of freedom, economic displacement, and even human extinction. Key signatories include AI pioneers Geoffrey Hinton and Yoshua Bengio, tech figures like Steve Wozniak, politicians from across the spectrum, and entertainers including Joseph Gordon-Levitt and will.i.am. The letter criticizes the rapid and competitive AI development by tech giants like Google, OpenAI, and Meta, raising ethical and safety concerns. Some signatories note that while AI tools can benefit society, the pursuit of superintelligence without adequate oversight could be dangerous. The statement reflects growing mainstream unease about the unchecked advancement of artificial general intelligence, with calls for government intervention to halt what critics view as a perilous technological race.","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"news","ref_index":43}],"hue":null,"attributions":null,"attribution":"AP News"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search17\ue202turn0search13\ue201","start_idx":3103,"end_idx":3137,"safe_urls":["https://lunabase.ai/blog/the-agi-transformation-how-artificial-general-intelligence-will-redefine-software-engineering-by-2030","https://lunabase.ai/blog/the-agi-transformation-how-artificial-general-intelligence-will-redefine-software-engineering-by-2030?utm_source=chatgpt.com","https://www.sciencedirect.com/science/article/abs/pii/S1367578825000367","https://www.sciencedirect.com/science/article/abs/pii/S1367578825000367?utm_source=chatgpt.com"],"refs":[],"alt":"([ScienceDirect](https://www.sciencedirect.com/science/article/abs/pii/S1367578825000367?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Path to Artificial General Intelligence: Past, present, and ...","url":"https://www.sciencedirect.com/science/article/abs/pii/S1367578825000367?utm_source=chatgpt.com","pub_date":null,"snippet":"by R Sarikaya \u00b7 2025 \u00b7 Cited by 1 \u2014 The recent revolution in Artificial Intelligence (AI) has been driven by the confluence of three major factors: massive data availability, unprecedented ...","attribution_segments":null,"supporting_websites":[{"title":"The AGI Transformation: How Artificial General Intelligence ...","url":"https://lunabase.ai/blog/the-agi-transformation-how-artificial-general-intelligence-will-redefine-software-engineering-by-2030?utm_source=chatgpt.com","pub_date":null,"snippet":"Industry leaders from OpenAI, DeepMind, and Anthropic predict AGI arrival between 2026-2030, triggering unprecedented transformation in software development ...","attribution":"Luna Base AI"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":17},{"turn_index":0,"ref_type":"search","ref_index":13}],"hue":null,"attributions":null,"attribution":"ScienceDirect"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search7\ue201","start_idx":3514,"end_idx":3533,"safe_urls":["https://en.wikipedia.org/wiki/Existential_risk_from_artificial_intelligence","https://en.wikipedia.org/wiki/Existential_risk_from_artificial_intelligence?utm_source=chatgpt.com"],"refs":[],"alt":"([Wikipedia](https://en.wikipedia.org/wiki/Existential_risk_from_artificial_intelligence?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Existential risk from artificial intelligence","url":"https://en.wikipedia.org/wiki/Existential_risk_from_artificial_intelligence?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":7}],"hue":null,"attributions":null,"attribution":"Wikipedia"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search7\ue202turn0search15\ue201","start_idx":3824,"end_idx":3857,"safe_urls":["https://en.wikipedia.org/wiki/Existential_risk_from_artificial_intelligence","https://en.wikipedia.org/wiki/Existential_risk_from_artificial_intelligence?utm_source=chatgpt.com","https://www.ebsco.com/research-starters/computer-science/existential-risk-artificial-general-intelligence","https://www.ebsco.com/research-starters/computer-science/existential-risk-artificial-general-intelligence?utm_source=chatgpt.com"],"refs":[],"alt":"([Wikipedia](https://en.wikipedia.org/wiki/Existential_risk_from_artificial_intelligence?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Existential risk from artificial intelligence","url":"https://en.wikipedia.org/wiki/Existential_risk_from_artificial_intelligence?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[{"title":"Existential risk from artificial general intelligence","url":"https://www.ebsco.com/research-starters/computer-science/existential-risk-artificial-general-intelligence?utm_source=chatgpt.com","pub_date":null,"snippet":"The central concern is that a superintelligent AI might act in ways that could be catastrophic for humanity, ranging from societal breakdown to extinction.","attribution":"EBSCO"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":7},{"turn_index":0,"ref_type":"search","ref_index":15}],"hue":null,"attributions":null,"attribution":"Wikipedia"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search11\ue202turn0search15\ue201","start_idx":5108,"end_idx":5142,"safe_urls":["https://www.brookings.edu/articles/are-ai-existential-risks-real-and-what-should-we-do-about-them/","https://www.brookings.edu/articles/are-ai-existential-risks-real-and-what-should-we-do-about-them/?utm_source=chatgpt.com","https://www.ebsco.com/research-starters/computer-science/existential-risk-artificial-general-intelligence","https://www.ebsco.com/research-starters/computer-science/existential-risk-artificial-general-intelligence?utm_source=chatgpt.com"],"refs":[],"alt":"([Brookings](https://www.brookings.edu/articles/are-ai-existential-risks-real-and-what-should-we-do-about-them/?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Are AI existential risks real\u2014and what should we do about ...","url":"https://www.brookings.edu/articles/are-ai-existential-risks-real-and-what-should-we-do-about-them/?utm_source=chatgpt.com","pub_date":1752241942.0,"snippet":"11 Jul 2025 \u2014 Mark MacCarthy highlights the existential risks posed by AI while emphasizing the need to prioritize addressing its more immediate harms.","attribution_segments":null,"supporting_websites":[{"title":"Existential risk from artificial general intelligence","url":"https://www.ebsco.com/research-starters/computer-science/existential-risk-artificial-general-intelligence?utm_source=chatgpt.com","pub_date":null,"snippet":"The central concern is that a superintelligent AI might act in ways that could be catastrophic for humanity, ranging from societal breakdown to extinction.","attribution":"EBSCO"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":11},{"turn_index":0,"ref_type":"search","ref_index":15}],"hue":null,"attributions":null,"attribution":"Brookings"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search0\ue201","start_idx":5914,"end_idx":5933,"safe_urls":["https://en.wikipedia.org/wiki/Superintelligence","https://en.wikipedia.org/wiki/Superintelligence?utm_source=chatgpt.com"],"refs":[],"alt":"([Wikipedia](https://en.wikipedia.org/wiki/Superintelligence?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Superintelligence","url":"https://en.wikipedia.org/wiki/Superintelligence?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":0}],"hue":null,"attributions":null,"attribution":"Wikipedia"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search7\ue202turn0news45\ue201","start_idx":6712,"end_idx":6743,"safe_urls":["https://en.wikipedia.org/wiki/Existential_risk_from_artificial_intelligence","https://en.wikipedia.org/wiki/Existential_risk_from_artificial_intelligence?utm_source=chatgpt.com","https://www.wired.com/story/openai-superalignment-team-disbanded","https://www.wired.com/story/openai-superalignment-team-disbanded?utm_source=chatgpt.com"],"refs":[],"alt":"([Wikipedia](https://en.wikipedia.org/wiki/Existential_risk_from_artificial_intelligence?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Existential risk from artificial intelligence","url":"https://en.wikipedia.org/wiki/Existential_risk_from_artificial_intelligence?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[{"title":"OpenAI's Long-Term AI Risk Team Has Disbanded","url":"https://www.wired.com/story/openai-superalignment-team-disbanded?utm_source=chatgpt.com","pub_date":null,"snippet":"OpenAI's \"superalignment team,\" created to address long-term risks of superintelligent AI, has disbanded following the departure of key members, including co-leads Ilya Sutskever and Jan Leike. Sutskever, a cofounder, left amidst controversy after being part of a board decision to temporarily fire CEO Sam Altman. Leike cited disagreements over resource allocation and priorities as reasons for his resignation. The team's work will be integrated into other research efforts, now led by John Schulman. The dissolution highlights internal turmoil following OpenAI's governance crisis last year. Despite the setbacks, OpenAI continues to advance AI technology, recently showcasing GPT-4o, a \"multimodal\" AI model improving ChatGPT's capability to mimic human emotions and interactions. Concerns around privacy, emotional manipulation, and cybersecurity risks remain, driving ethical discussions as advancements proceed.","attribution":"WIRED"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":7},{"turn_index":0,"ref_type":"news","ref_index":45}],"hue":null,"attributions":null,"attribution":"Wikipedia"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search14\ue201","start_idx":7220,"end_idx":7240,"safe_urls":["https://openai.com/index/weak-to-strong-generalization/","https://openai.com/index/weak-to-strong-generalization/?utm_source=chatgpt.com"],"refs":[],"alt":"([OpenAI](https://openai.com/index/weak-to-strong-generalization/?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Weak-to-strong generalization","url":"https://openai.com/index/weak-to-strong-generalization/?utm_source=chatgpt.com","pub_date":null,"snippet":"14 Dec 2023 \u2014 We present a new research direction for superalignment, together with promising initial results: can we leverage the generalization properties of deep learning ...","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":14}],"hue":null,"attributions":null,"attribution":"OpenAI"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search7\ue201","start_idx":7430,"end_idx":7449,"safe_urls":["https://en.wikipedia.org/wiki/Existential_risk_from_artificial_intelligence","https://en.wikipedia.org/wiki/Existential_risk_from_artificial_intelligence?utm_source=chatgpt.com"],"refs":[],"alt":"([Wikipedia](https://en.wikipedia.org/wiki/Existential_risk_from_artificial_intelligence?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Existential risk from artificial intelligence","url":"https://en.wikipedia.org/wiki/Existential_risk_from_artificial_intelligence?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":7}],"hue":null,"attributions":null,"attribution":"Wikipedia"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search7\ue202turn0search12\ue201","start_idx":8164,"end_idx":8197,"safe_urls":["https://en.wikipedia.org/wiki/Existential_risk_from_artificial_intelligence","https://en.wikipedia.org/wiki/Existential_risk_from_artificial_intelligence?utm_source=chatgpt.com","https://medium.com/science-uncovered/what-is-superintelligence-539477ebe333","https://medium.com/science-uncovered/what-is-superintelligence-539477ebe333?utm_source=chatgpt.com"],"refs":[],"alt":"([Wikipedia](https://en.wikipedia.org/wiki/Existential_risk_from_artificial_intelligence?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Existential risk from artificial intelligence","url":"https://en.wikipedia.org/wiki/Existential_risk_from_artificial_intelligence?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution_segments":null,"supporting_websites":[{"title":"What is superintelligence?. Nick Bostrom explains","url":"https://medium.com/science-uncovered/what-is-superintelligence-539477ebe333?utm_source=chatgpt.com","pub_date":null,"snippet":"We can tentatively define a superintelligence as any intellect that greatly exceeds the cognitive performance of humans in virtually all domains of interest.","attribution":"Medium"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":7},{"turn_index":0,"ref_type":"search","ref_index":12}],"hue":null,"attributions":null,"attribution":"Wikipedia"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search11\ue202turn0search3\ue201","start_idx":8462,"end_idx":8495,"safe_urls":["https://www.brookings.edu/articles/are-ai-existential-risks-real-and-what-should-we-do-about-them/","https://www.brookings.edu/articles/are-ai-existential-risks-real-and-what-should-we-do-about-them/?utm_source=chatgpt.com","https://www.stateof.ai/2024","https://www.stateof.ai/2024?utm_source=chatgpt.com"],"refs":[],"alt":"([Brookings](https://www.brookings.edu/articles/are-ai-existential-risks-real-and-what-should-we-do-about-them/?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Are AI existential risks real\u2014and what should we do about ...","url":"https://www.brookings.edu/articles/are-ai-existential-risks-real-and-what-should-we-do-about-them/?utm_source=chatgpt.com","pub_date":1752241942.0,"snippet":"11 Jul 2025 \u2014 Mark MacCarthy highlights the existential risks posed by AI while emphasizing the need to prioritize addressing its more immediate harms.","attribution_segments":null,"supporting_websites":[{"title":"Welcome to State of AI Report 2024","url":"https://www.stateof.ai/2024?utm_source=chatgpt.com","pub_date":null,"snippet":"The existential risk discourse has cooled off, especially following the abortive coup at OpenAI. However, researchers have continued to deepen our knowledge ...","attribution":"stateof.ai"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":11},{"turn_index":0,"ref_type":"search","ref_index":3}],"hue":null,"attributions":null,"attribution":"Brookings"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0news43\ue202turn0search11\ue201","start_idx":9353,"end_idx":9385,"safe_urls":["https://apnews.com/article/acf6b17d3b53abc08694d5d8defc7009","https://apnews.com/article/acf6b17d3b53abc08694d5d8defc7009?utm_source=chatgpt.com","https://www.brookings.edu/articles/are-ai-existential-risks-real-and-what-should-we-do-about-them/","https://www.brookings.edu/articles/are-ai-existential-risks-real-and-what-should-we-do-about-them/?utm_source=chatgpt.com"],"refs":[],"alt":"([AP News](https://apnews.com/article/acf6b17d3b53abc08694d5d8defc7009?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Prince Harry, Meghan join call for ban on development of AI 'superintelligence'","url":"https://apnews.com/article/acf6b17d3b53abc08694d5d8defc7009?utm_source=chatgpt.com","pub_date":1761094073.0,"snippet":"A diverse coalition of public figures, including Prince Harry and Meghan, prominent AI scientists, celebrities, and political leaders, has issued a joint statement calling for a ban on the development of AI \"superintelligence\" unless strict safety and public approval conditions are met. The statement, coordinated by the Future of Life Institute, expresses concern over AI technology potentially surpassing human cognitive abilities and posing existential risks such as loss of freedom, economic displacement, and even human extinction. Key signatories include AI pioneers Geoffrey Hinton and Yoshua Bengio, tech figures like Steve Wozniak, politicians from across the spectrum, and entertainers including Joseph Gordon-Levitt and will.i.am. The letter criticizes the rapid and competitive AI development by tech giants like Google, OpenAI, and Meta, raising ethical and safety concerns. Some signatories note that while AI tools can benefit society, the pursuit of superintelligence without adequate oversight could be dangerous. The statement reflects growing mainstream unease about the unchecked advancement of artificial general intelligence, with calls for government intervention to halt what critics view as a perilous technological race.","attribution_segments":null,"supporting_websites":[{"title":"Are AI existential risks real\u2014and what should we do about ...","url":"https://www.brookings.edu/articles/are-ai-existential-risks-real-and-what-should-we-do-about-them/?utm_source=chatgpt.com","pub_date":null,"snippet":"11 Jul 2025 \u2014 Mark MacCarthy highlights the existential risks posed by AI while emphasizing the need to prioritize addressing its more immediate harms.","attribution":"Brookings"}],"refs":[{"turn_index":0,"ref_type":"news","ref_index":43},{"turn_index":0,"ref_type":"search","ref_index":11}],"hue":null,"attributions":null,"attribution":"AP News"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search11\ue202turn0search7\ue201","start_idx":10273,"end_idx":10306,"safe_urls":["https://en.wikipedia.org/wiki/Existential_risk_from_artificial_intelligence","https://en.wikipedia.org/wiki/Existential_risk_from_artificial_intelligence?utm_source=chatgpt.com","https://www.brookings.edu/articles/are-ai-existential-risks-real-and-what-should-we-do-about-them/","https://www.brookings.edu/articles/are-ai-existential-risks-real-and-what-should-we-do-about-them/?utm_source=chatgpt.com"],"refs":[],"alt":"([Brookings](https://www.brookings.edu/articles/are-ai-existential-risks-real-and-what-should-we-do-about-them/?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Are AI existential risks real\u2014and what should we do about ...","url":"https://www.brookings.edu/articles/are-ai-existential-risks-real-and-what-should-we-do-about-them/?utm_source=chatgpt.com","pub_date":1752241942.0,"snippet":"11 Jul 2025 \u2014 Mark MacCarthy highlights the existential risks posed by AI while emphasizing the need to prioritize addressing its more immediate harms.","attribution_segments":null,"supporting_websites":[{"title":"Existential risk from artificial intelligence","url":"https://en.wikipedia.org/wiki/Existential_risk_from_artificial_intelligence?utm_source=chatgpt.com","pub_date":null,"snippet":"","attribution":"Wikipedia"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":11},{"turn_index":0,"ref_type":"search","ref_index":7}],"hue":null,"attributions":null,"attribution":"Brookings"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search3\ue202turn0search19\ue201","start_idx":11391,"end_idx":11424,"safe_urls":["https://hai-production.s3.amazonaws.com/files/hai_ai-index-report-2024-smaller2.pdf","https://hai-production.s3.amazonaws.com/files/hai_ai-index-report-2024-smaller2.pdf?utm_source=chatgpt.com","https://www.stateof.ai/2024","https://www.stateof.ai/2024?utm_source=chatgpt.com"],"refs":[],"alt":"([stateof.ai](https://www.stateof.ai/2024?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Welcome to State of AI Report 2024","url":"https://www.stateof.ai/2024?utm_source=chatgpt.com","pub_date":1728518400.0,"snippet":"The existential risk discourse has cooled off, especially following the abortive coup at OpenAI. However, researchers have continued to deepen our knowledge ...","attribution_segments":null,"supporting_websites":[{"title":"Artificial Intelligence Index Report 2024","url":"https://hai-production.s3.amazonaws.com/files/hai_ai-index-report-2024-smaller2.pdf?utm_source=chatgpt.com","pub_date":null,"snippet":"This year's edition surpasses all previous ones in size, scale, and scope, reflecting the growing significance that AI is coming to hold in all of our lives.","attribution":"hai-production.s3.amazonaws.com"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":3},{"turn_index":0,"ref_type":"search","ref_index":19}],"hue":null,"attributions":null,"attribution":"stateof.ai"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search13\ue202turn0search5\ue201","start_idx":12834,"end_idx":12867,"safe_urls":["https://ai-frontiers.org/articles/agis-last-bottlenecks","https://ai-frontiers.org/articles/agis-last-bottlenecks?utm_source=chatgpt.com","https://lunabase.ai/blog/the-agi-transformation-how-artificial-general-intelligence-will-redefine-software-engineering-by-2030","https://lunabase.ai/blog/the-agi-transformation-how-artificial-general-intelligence-will-redefine-software-engineering-by-2030?utm_source=chatgpt.com"],"refs":[],"alt":"([Luna Base AI](https://lunabase.ai/blog/the-agi-transformation-how-artificial-general-intelligence-will-redefine-software-engineering-by-2030?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"The AGI Transformation: How Artificial General Intelligence ...","url":"https://lunabase.ai/blog/the-agi-transformation-how-artificial-general-intelligence-will-redefine-software-engineering-by-2030?utm_source=chatgpt.com","pub_date":1763096400.0,"snippet":"Industry leaders from OpenAI, DeepMind, and Anthropic predict AGI arrival between 2026-2030, triggering unprecedented transformation in software development ...","attribution_segments":null,"supporting_websites":[{"title":"AGI's Last Bottlenecks","url":"https://ai-frontiers.org/articles/agis-last-bottlenecks?utm_source=chatgpt.com","pub_date":null,"snippet":"22 Oct 2025 \u2014 A new framework suggests we're already halfway to AGI. The rest of the way will mostly require business-as-usual research and engineering.","attribution":"AI Frontiers"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":13},{"turn_index":0,"ref_type":"search","ref_index":5}],"hue":null,"attributions":null,"attribution":"Luna Base AI"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search11\ue201","start_idx":14701,"end_idx":14721,"safe_urls":["https://www.brookings.edu/articles/are-ai-existential-risks-real-and-what-should-we-do-about-them/","https://www.brookings.edu/articles/are-ai-existential-risks-real-and-what-should-we-do-about-them/?utm_source=chatgpt.com"],"refs":[],"alt":"([Brookings](https://www.brookings.edu/articles/are-ai-existential-risks-real-and-what-should-we-do-about-them/?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"Are AI existential risks real\u2014and what should we do about ...","url":"https://www.brookings.edu/articles/are-ai-existential-risks-real-and-what-should-we-do-about-them/?utm_source=chatgpt.com","pub_date":1752241942.0,"snippet":"11 Jul 2025 \u2014 Mark MacCarthy highlights the existential risks posed by AI while emphasizing the need to prioritize addressing its more immediate harms.","attribution_segments":null,"supporting_websites":[],"refs":[{"turn_index":0,"ref_type":"search","ref_index":11}],"hue":null,"attributions":null,"attribution":"Brookings"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200cite\ue202turn0search16\ue202turn0search11\ue201","start_idx":16184,"end_idx":16218,"safe_urls":["https://www.brookings.edu/articles/are-ai-existential-risks-real-and-what-should-we-do-about-them/","https://www.brookings.edu/articles/are-ai-existential-risks-real-and-what-should-we-do-about-them/?utm_source=chatgpt.com","https://www.unsw.edu.au/newsroom/news/2024/10/what-is-ai-superintelligence-could-it-destroy-humanity-and-is-it-really-almost-here","https://www.unsw.edu.au/newsroom/news/2024/10/what-is-ai-superintelligence-could-it-destroy-humanity-and-is-it-really-almost-here?utm_source=chatgpt.com"],"refs":[],"alt":"([UNSW Sites](https://www.unsw.edu.au/newsroom/news/2024/10/what-is-ai-superintelligence-could-it-destroy-humanity-and-is-it-really-almost-here?utm_source=chatgpt.com))","prompt_text":null,"type":"grouped_webpages","items":[{"title":"What is AI superintelligence? Could it destroy humanity ...","url":"https://www.unsw.edu.au/newsroom/news/2024/10/what-is-ai-superintelligence-could-it-destroy-humanity-and-is-it-really-almost-here?utm_source=chatgpt.com","pub_date":null,"snippet":"28 Oct 2024 \u2014 Broadly speaking, superintelligence is anything more intelligent than humans. But unpacking what that might mean in practice can get a bit ...","attribution_segments":null,"supporting_websites":[{"title":"Are AI existential risks real\u2014and what should we do about ...","url":"https://www.brookings.edu/articles/are-ai-existential-risks-real-and-what-should-we-do-about-them/?utm_source=chatgpt.com","pub_date":null,"snippet":"11 Jul 2025 \u2014 Mark MacCarthy highlights the existential risks posed by AI while emphasizing the need to prioritize addressing its more immediate harms.","attribution":"Brookings"}],"refs":[{"turn_index":0,"ref_type":"search","ref_index":16},{"turn_index":0,"ref_type":"search","ref_index":11}],"hue":null,"attributions":null,"attribution":"UNSW Sites"}],"fallback_items":null,"status":"done","error":null,"style":null},{"matched_text":"\ue200navlist\ue202Recent coverage on AI \u201csuperintelligence\u201d\ue202turn0news40,turn0news42,turn0news43,turn0news44,turn0news45\ue201","start_idx":17171,"end_idx":17282,"safe_urls":["https://apnews.com/article/acf6b17d3b53abc08694d5d8defc7009","https://apnews.com/article/acf6b17d3b53abc08694d5d8defc7009?utm_source=chatgpt.com","https://images.openai.com/static-rsc-1/1MrvwXvX97K-fWpxQTxh_mmPeEEYtwA294XBbhGqiKuNEzdUnCfgVbofUNCZ7KW3BQak5ys2-txXJcra3vU6xR5WqBrNytmMV2IVeHP_5OAEnmwpURwCSXTb0TvQbK4FrBcG0AXbFmCAOJEpwQrV2gLrO5Qyej8redE7xSeI3zfoIBA0HTzxNMLz33tic6z6VqdUMiviBArlyN3btivG6WsAIrdfVh9jjCGV2rLkunJOher-1WXvizDiH5dpIKMDm_0TuhfZrwHHIkSBcC-7w2Oej-_zqAZDhBOA2oHDnQXgLG_XjazqIjrCFlmCIsEejUmQU01Eps_EQzO-_4uzxA","https://images.openai.com/static-rsc-1/tq5MEvNlUX4ML1apG6E5p6BChnUpTvg4UXq-D-WYOoKIpeokVgRkoqR4tIutyJ-nlYB_FYHDUvmRQsMlc6Y1twjFichmhfz-_oY0hJFyEyCupsezj9KDj9iXB7WG6krEPX4fnPnqSS-j3fg51AKY9Oa5VIu6OjxnBlvZLwbteFaueCIxe6FEVCfftk2gHCELoIABsnO-S2b7Bz15HZs2DQ","https://timesofindia.indiatimes.com/technology/tech-news/omni-models-superintelligence-and-more-microsoft-ceo-satya-nadella-reveals-companys-ais-roadmap/articleshow/125330949.cms","https://timesofindia.indiatimes.com/technology/tech-news/omni-models-superintelligence-and-more-microsoft-ceo-satya-nadella-reveals-companys-ais-roadmap/articleshow/125330949.cms?utm_source=chatgpt.com","https://www.livescience.com/technology/artificial-intelligence/meta-ai-takes-first-step-to-superintelligence-and-zuckerberg-will-no-longer-release-the-most-powerful-systems-to-the-public","https://www.livescience.com/technology/artificial-intelligence/meta-ai-takes-first-step-to-superintelligence-and-zuckerberg-will-no-longer-release-the-most-powerful-systems-to-the-public?utm_source=chatgpt.com","https://www.theguardian.com/technology/2025/jun/11/meta-to-announce-15bn-investment-in-bid-to-achieve-computerised-superintelligence-ai","https://www.theguardian.com/technology/2025/jun/11/meta-to-announce-15bn-investment-in-bid-to-achieve-computerised-superintelligence-ai?utm_source=chatgpt.com","https://www.wired.com/story/openai-superalignment-team-disbanded","https://www.wired.com/story/openai-superalignment-team-disbanded?utm_source=chatgpt.com"],"refs":[{"turn_index":0,"ref_type":"news","ref_index":40},{"turn_index":0,"ref_type":"news","ref_index":42},{"turn_index":0,"ref_type":"news","ref_index":43},{"turn_index":0,"ref_type":"news","ref_index":44},{"turn_index":0,"ref_type":"news","ref_index":45}],"alt":"- [The Times of India](https://timesofindia.indiatimes.com/technology/tech-news/omni-models-superintelligence-and-more-microsoft-ceo-satya-nadella-reveals-companys-ais-roadmap/articleshow/125330949.cms?utm_source=chatgpt.com)\n- [The Guardian](https://www.theguardian.com/technology/2025/jun/11/meta-to-announce-15bn-investment-in-bid-to-achieve-computerised-superintelligence-ai?utm_source=chatgpt.com)\n- [AP News](https://apnews.com/article/acf6b17d3b53abc08694d5d8defc7009?utm_source=chatgpt.com)\n- [livescience.com](https://www.livescience.com/technology/artificial-intelligence/meta-ai-takes-first-step-to-superintelligence-and-zuckerberg-will-no-longer-release-the-most-powerful-systems-to-the-public?utm_source=chatgpt.com)\n- [WIRED](https://www.wired.com/story/openai-superalignment-team-disbanded?utm_source=chatgpt.com)","prompt_text":"\nnavlist containing the following URLs:\n- ['Omni models, Superintelligence and more': Microsoft CEO Satya Nadella reveals company's AI's roadmap](https://timesofindia.indiatimes.com/technology/tech-news/omni-models-superintelligence-and-more-microsoft-ceo-satya-nadella-reveals-companys-ais-roadmap/articleshow/125330949.cms?utm_source=chatgpt.com)\n- [Meta to announce $15bn investment in bid to achieve computerised 'superintelligence'](https://www.theguardian.com/technology/2025/jun/11/meta-to-announce-15bn-investment-in-bid-to-achieve-computerised-superintelligence-ai?utm_source=chatgpt.com)\n- [Prince Harry, Meghan join call for ban on development of AI 'superintelligence'](https://apnews.com/article/acf6b17d3b53abc08694d5d8defc7009?utm_source=chatgpt.com)\n- [Meta AI takes first step to superintelligence - and Zuckerberg will no longer release the most powerful systems to the public](https://www.livescience.com/technology/artificial-intelligence/meta-ai-takes-first-step-to-superintelligence-and-zuckerberg-will-no-longer-release-the-most-powerful-systems-to-the-public?utm_source=chatgpt.com)\n- [OpenAI's Long-Term AI Risk Team Has Disbanded](https://www.wired.com/story/openai-superalignment-team-disbanded?utm_source=chatgpt.com)\n","type":"nav_list","title":"Recent coverage on AI \u201csuperintelligence\u201d","items":[{"title":"'Omni models, Superintelligence and more': Microsoft CEO Satya Nadella reveals company's AI's roadmap","url":"https://timesofindia.indiatimes.com/technology/tech-news/omni-models-superintelligence-and-more-microsoft-ceo-satya-nadella-reveals-companys-ais-roadmap/articleshow/125330949.cms?utm_source=chatgpt.com","thumbnail_url":"https://images.openai.com/static-rsc-1/tq5MEvNlUX4ML1apG6E5p6BChnUpTvg4UXq-D-WYOoKIpeokVgRkoqR4tIutyJ-nlYB_FYHDUvmRQsMlc6Y1twjFichmhfz-_oY0hJFyEyCupsezj9KDj9iXB7WG6krEPX4fnPnqSS-j3fg51AKY9Oa5VIu6OjxnBlvZLwbteFaueCIxe6FEVCfftk2gHCELoIABsnO-S2b7Bz15HZs2DQ","pub_date":1763134795.0,"attribution":"The Times of India"},{"title":"Meta to announce $15bn investment in bid to achieve computerised 'superintelligence'","url":"https://www.theguardian.com/technology/2025/jun/11/meta-to-announce-15bn-investment-in-bid-to-achieve-computerised-superintelligence-ai?utm_source=chatgpt.com","thumbnail_url":null,"pub_date":1749649603.0,"attribution":"The Guardian"},{"title":"Prince Harry, Meghan join call for ban on development of AI 'superintelligence'","url":"https://apnews.com/article/acf6b17d3b53abc08694d5d8defc7009?utm_source=chatgpt.com","thumbnail_url":"https://images.openai.com/static-rsc-1/1MrvwXvX97K-fWpxQTxh_mmPeEEYtwA294XBbhGqiKuNEzdUnCfgVbofUNCZ7KW3BQak5ys2-txXJcra3vU6xR5WqBrNytmMV2IVeHP_5OAEnmwpURwCSXTb0TvQbK4FrBcG0AXbFmCAOJEpwQrV2gLrO5Qyej8redE7xSeI3zfoIBA0HTzxNMLz33tic6z6VqdUMiviBArlyN3btivG6WsAIrdfVh9jjCGV2rLkunJOher-1WXvizDiH5dpIKMDm_0TuhfZrwHHIkSBcC-7w2Oej-_zqAZDhBOA2oHDnQXgLG_XjazqIjrCFlmCIsEejUmQU01Eps_EQzO-_4uzxA","pub_date":1761094073.0,"attribution":"AP News"},{"title":"Meta AI takes first step to superintelligence - and Zuckerberg will no longer release the most powerful systems to the public","url":"https://www.livescience.com/technology/artificial-intelligence/meta-ai-takes-first-step-to-superintelligence-and-zuckerberg-will-no-longer-release-the-most-powerful-systems-to-the-public?utm_source=chatgpt.com","thumbnail_url":null,"pub_date":1754996400.0,"attribution":"livescience.com"},{"title":"OpenAI's Long-Term AI Risk Team Has Disbanded","url":"https://www.wired.com/story/openai-superalignment-team-disbanded?utm_source=chatgpt.com","thumbnail_url":null,"pub_date":1715957659.728,"attribution":"WIRED"}],"user_time_zone":"Asia/Singapore"},{"matched_text":" ","start_idx":17282,"end_idx":17282,"safe_urls":[],"refs":[],"alt":"","prompt_text":null,"type":"sources_footnote","sources":[{"title":"'Omni models, Superintelligence and more': Microsoft CEO Satya Nadella reveals company's AI's roadmap","url":"https://timesofindia.indiatimes.com/technology/tech-news/omni-models-superintelligence-and-more-microsoft-ceo-satya-nadella-reveals-companys-ais-roadmap/articleshow/125330949.cms?utm_source=chatgpt.com","attribution":"The Times of India"},{"title":"Superintelligence","url":"https://en.wikipedia.org/wiki/Superintelligence?utm_source=chatgpt.com","attribution":"Wikipedia"},{"title":"Welcome to State of AI Report 2024","url":"https://www.stateof.ai/2024?utm_source=chatgpt.com","attribution":"stateof.ai"},{"title":"Introducing Superalignment","url":"https://openai.com/index/introducing-superalignment/?utm_source=chatgpt.com","attribution":"OpenAI"},{"title":"Meta to announce $15bn investment in bid to achieve computerised 'superintelligence'","url":"https://www.theguardian.com/technology/2025/jun/11/meta-to-announce-15bn-investment-in-bid-to-achieve-computerised-superintelligence-ai?utm_source=chatgpt.com","attribution":"The Guardian"},{"title":"Prince Harry, Meghan join call for ban on development of AI 'superintelligence'","url":"https://apnews.com/article/acf6b17d3b53abc08694d5d8defc7009?utm_source=chatgpt.com","attribution":"AP News"},{"title":"Path to Artificial General Intelligence: Past, present, and ...","url":"https://www.sciencedirect.com/science/article/abs/pii/S1367578825000367?utm_source=chatgpt.com","attribution":"ScienceDirect"},{"title":"Are AI existential risks real\u2014and what should we do about ...","url":"https://www.brookings.edu/articles/are-ai-existential-risks-real-and-what-should-we-do-about-them/?utm_source=chatgpt.com","attribution":"Brookings"},{"title":"The AGI Transformation: How Artificial General Intelligence ...","url":"https://lunabase.ai/blog/the-agi-transformation-how-artificial-general-intelligence-will-redefine-software-engineering-by-2030?utm_source=chatgpt.com","attribution":"Luna Base AI"},{"title":"What is AI superintelligence? Could it destroy humanity ...","url":"https://www.unsw.edu.au/newsroom/news/2024/10/what-is-ai-superintelligence-could-it-destroy-humanity-and-is-it-really-almost-here?utm_source=chatgpt.com","attribution":"UNSW Sites"}],"has_images":false}],"safe_urls":["https://ai-frontiers.org/articles/agis-last-bottlenecks","https://ai-frontiers.org/articles/agis-last-bottlenecks?utm_source=chatgpt.com","https://apnews.com/article/acf6b17d3b53abc08694d5d8defc7009","https://apnews.com/article/acf6b17d3b53abc08694d5d8defc7009?utm_source=chatgpt.com","https://en.wikipedia.org/wiki/Existential_risk_from_artificial_intelligence","https://en.wikipedia.org/wiki/Existential_risk_from_artificial_intelligence?utm_source=chatgpt.com","https://en.wikipedia.org/wiki/Superintelligence","https://en.wikipedia.org/wiki/Superintelligence?utm_source=chatgpt.com","https://hai-production.s3.amazonaws.com/files/hai_ai-index-report-2024-smaller2.pdf","https://hai-production.s3.amazonaws.com/files/hai_ai-index-report-2024-smaller2.pdf?utm_source=chatgpt.com","https://images.openai.com/static-rsc-1/1MrvwXvX97K-fWpxQTxh_mmPeEEYtwA294XBbhGqiKuNEzdUnCfgVbofUNCZ7KW3BQak5ys2-txXJcra3vU6xR5WqBrNytmMV2IVeHP_5OAEnmwpURwCSXTb0TvQbK4FrBcG0AXbFmCAOJEpwQrV2gLrO5Qyej8redE7xSeI3zfoIBA0HTzxNMLz33tic6z6VqdUMiviBArlyN3btivG6WsAIrdfVh9jjCGV2rLkunJOher-1WXvizDiH5dpIKMDm_0TuhfZrwHHIkSBcC-7w2Oej-_zqAZDhBOA2oHDnQXgLG_XjazqIjrCFlmCIsEejUmQU01Eps_EQzO-_4uzxA","https://images.openai.com/static-rsc-1/tq5MEvNlUX4ML1apG6E5p6BChnUpTvg4UXq-D-WYOoKIpeokVgRkoqR4tIutyJ-nlYB_FYHDUvmRQsMlc6Y1twjFichmhfz-_oY0hJFyEyCupsezj9KDj9iXB7WG6krEPX4fnPnqSS-j3fg51AKY9Oa5VIu6OjxnBlvZLwbteFaueCIxe6FEVCfftk2gHCELoIABsnO-S2b7Bz15HZs2DQ","https://lunabase.ai/blog/the-agi-transformation-how-artificial-general-intelligence-will-redefine-software-engineering-by-2030","https://lunabase.ai/blog/the-agi-transformation-how-artificial-general-intelligence-will-redefine-software-engineering-by-2030?utm_source=chatgpt.com","https://medium.com/science-uncovered/what-is-superintelligence-539477ebe333","https://medium.com/science-uncovered/what-is-superintelligence-539477ebe333?utm_source=chatgpt.com","https://nickbostrom.com/superintelligence","https://nickbostrom.com/superintelligence?utm_source=chatgpt.com","https://openai.com/index/introducing-superalignment/","https://openai.com/index/introducing-superalignment/?utm_source=chatgpt.com","https://openai.com/index/weak-to-strong-generalization/","https://openai.com/index/weak-to-strong-generalization/?utm_source=chatgpt.com","https://timesofindia.indiatimes.com/technology/tech-news/omni-models-superintelligence-and-more-microsoft-ceo-satya-nadella-reveals-companys-ais-roadmap/articleshow/125330949.cms","https://timesofindia.indiatimes.com/technology/tech-news/omni-models-superintelligence-and-more-microsoft-ceo-satya-nadella-reveals-companys-ais-roadmap/articleshow/125330949.cms?utm_source=chatgpt.com","https://www.brookings.edu/articles/are-ai-existential-risks-real-and-what-should-we-do-about-them/","https://www.brookings.edu/articles/are-ai-existential-risks-real-and-what-should-we-do-about-them/?utm_source=chatgpt.com","https://www.ebsco.com/research-starters/computer-science/existential-risk-artificial-general-intelligence","https://www.ebsco.com/research-starters/computer-science/existential-risk-artificial-general-intelligence?utm_source=chatgpt.com","https://www.livescience.com/technology/artificial-intelligence/meta-ai-takes-first-step-to-superintelligence-and-zuckerberg-will-no-longer-release-the-most-powerful-systems-to-the-public","https://www.livescience.com/technology/artificial-intelligence/meta-ai-takes-first-step-to-superintelligence-and-zuckerberg-will-no-longer-release-the-most-powerful-systems-to-the-public?utm_source=chatgpt.com","https://www.sciencedirect.com/science/article/abs/pii/S1367578825000367","https://www.sciencedirect.com/science/article/abs/pii/S1367578825000367?utm_source=chatgpt.com","https://www.stateof.ai/2024","https://www.stateof.ai/2024?utm_source=chatgpt.com","https://www.theguardian.com/technology/2025/jun/11/meta-to-announce-15bn-investment-in-bid-to-achieve-computerised-superintelligence-ai","https://www.theguardian.com/technology/2025/jun/11/meta-to-announce-15bn-investment-in-bid-to-achieve-computerised-superintelligence-ai?utm_source=chatgpt.com","https://www.unsw.edu.au/newsroom/news/2024/10/what-is-ai-superintelligence-could-it-destroy-humanity-and-is-it-really-almost-here","https://www.unsw.edu.au/newsroom/news/2024/10/what-is-ai-superintelligence-could-it-destroy-humanity-and-is-it-really-almost-here?utm_source=chatgpt.com","https://www.wired.com/story/openai-superalignment-team-disbanded","https://www.wired.com/story/openai-superalignment-team-disbanded?utm_source=chatgpt.com"],"search_result_groups":[{"type":"search_result_group","domain":"nickbostrom.com","entries":[{"type":"search_result","url":"https://nickbostrom.com/superintelligence?utm_source=chatgpt.com","title":"How long before superintelligence?","snippet":"By a \"superintelligence\" we mean an intellect that is much smarter than the best human brains in practically every field, including scientific creativity, ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":4},"pub_date":null,"attribution":"nickbostrom.com"}]},{"type":"search_result_group","domain":"ai-frontiers.org","entries":[{"type":"search_result","url":"https://ai-frontiers.org/articles/agis-last-bottlenecks?utm_source=chatgpt.com","title":"AGI's Last Bottlenecks","snippet":"22 Oct 2025 \u2014 A new framework suggests we're already halfway to AGI. The rest of the way will mostly require business-as-usual research and engineering.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":5},"pub_date":null,"attribution":"ai-frontiers.org"}]},{"type":"search_result_group","domain":"ebsco.com","entries":[{"type":"search_result","url":"https://www.ebsco.com/research-starters/computer-science/superintelligence?utm_source=chatgpt.com","title":"Superintelligence | Research Starters","snippet":"Superintelligence refers to a theoretical form of artificial intelligence (AI) that would possess cognitive abilities far surpassing those of the most ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":8},"pub_date":null,"attribution":"ebsco.com"},{"type":"search_result","url":"https://www.ebsco.com/research-starters/computer-science/existential-risk-artificial-general-intelligence?utm_source=chatgpt.com","title":"Existential risk from artificial general intelligence","snippet":"The central concern is that a superintelligent AI might act in ways that could be catastrophic for humanity, ranging from societal breakdown to extinction.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":15},"pub_date":null,"attribution":"ebsco.com"}]},{"type":"search_result_group","domain":"medium.com","entries":[{"type":"search_result","url":"https://medium.com/%40cauri/when-will-superintelligence-happen-is-the-wrong-question-41c7b4ab5f65?utm_source=chatgpt.com","title":"\u201cWhen will superintelligence happen?\u201d is the wrong question","snippet":"This piece maps five specific frontiers standing between current AI and general intelligence. Each represents a concrete gap with active ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":9},"pub_date":null,"attribution":"medium.com"},{"type":"search_result","url":"https://medium.com/science-uncovered/what-is-superintelligence-539477ebe333?utm_source=chatgpt.com","title":"What is superintelligence?. Nick Bostrom explains","snippet":"We can tentatively define a superintelligence as any intellect that greatly exceeds the cognitive performance of humans in virtually all domains of interest.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":12},"pub_date":null,"attribution":"medium.com"}]},{"type":"search_result_group","domain":"yahoo.com","entries":[{"type":"search_result","url":"https://tech.yahoo.com/ai/articles/ago-today-openai-launched-bold-182321736.html?utm_source=chatgpt.com","title":"A year ago today, OpenAI launched a bold four-year plan ...","snippet":"5 Jul 2024 \u2014 Open AI announced the four-year plan Superalignment on July 5, 2023. ... Open AI had grand ambitions for Superalignment. According to the ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":10},"pub_date":null,"attribution":"yahoo.com"}]},{"type":"search_result_group","domain":"hai-production.s3.amazonaws.com","entries":[{"type":"search_result","url":"https://hai-production.s3.amazonaws.com/files/hai_ai-index-report-2024-smaller2.pdf?utm_source=chatgpt.com","title":"Artificial Intelligence Index Report 2024","snippet":"This year's edition surpasses all previous ones in size, scale, and scope, reflecting the growing significance that AI is coming to hold in all of our lives.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":19},"pub_date":null,"attribution":"hai-production.s3.amazonaws.com"}]},{"type":"search_result_group","domain":"shortform.com","entries":[{"type":"search_result","url":"https://www.shortform.com/blog/nick-bostrom-superintelligence/?utm_source=chatgpt.com","title":"Nick Bostrom's Superintelligence: Overview & Takeaways","snippet":"26 Oct 2023 \u2014 Oxford philosopher Nick Bostrom's Superintelligence was written in 2014 to raise awareness about the possibility of AI suddenly exceeding human capabilities.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":20},"pub_date":null,"attribution":"shortform.com"}]},{"type":"search_result_group","domain":"aimultiple.com","entries":[{"type":"search_result","url":"https://research.aimultiple.com/artificial-general-intelligence-singularity-timing/?utm_source=chatgpt.com","title":"When Will AGI/Singularity Happen? 8590 Predictions ...","snippet":"\u201cThe road to artificial general intelligence\u201d report in August 2025 anticipates that early AGI-like systems could begin emerging between 2026 and 2028, showing ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":21},"pub_date":null,"attribution":"aimultiple.com"}]},{"type":"search_result_group","domain":"reddit.com","entries":[{"type":"search_result","url":"https://www.reddit.com/r/singularity/comments/18idr5j/openai_superalignments_first_research_paper_was/?utm_source=chatgpt.com","title":"OpenAI Superalignment's first research paper was just ...","snippet":"We believe superintelligence\u2014AI vastly smarter than humans\u2014could be developed within the next ten years. Just a month ago Altman talked about ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":22},"pub_date":null,"attribution":"reddit.com"}]},{"type":"search_result_group","domain":"ramp.com","entries":[{"type":"search_result","url":"https://ramp.com/blog/what-is-artificial-superintelligence?utm_source=chatgpt.com","title":"What is Artificial Superintelligence? Meaning & Origin","snippet":"15 Jul 2025 \u2014 Superintelligence refers to artificial intelligence systems that would outperform humans across a wide range of tasks and fields.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":24},"pub_date":null,"attribution":"ramp.com"}]},{"type":"search_result_group","domain":"firstmovers.ai","entries":[{"type":"search_result","url":"https://firstmovers.ai/agi-timeline/?utm_source=chatgpt.com","title":"Full AGI Timeline: How Close Are We to Humanity's Last ...","snippet":"Some researchers believe AGI could arrive as early as the next few years, with 2027 being the earliest potential arrival year.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":25},"pub_date":null,"attribution":"firstmovers.ai"}]},{"type":"search_result_group","domain":"80000hours.org","entries":[{"type":"search_result","url":"https://80000hours.org/podcast/episodes/jan-leike-superalignment/?utm_source=chatgpt.com","title":"Jan Leike on OpenAI's massive push to make ...","snippet":"7 Aug 2023 \u2014 The goal is to figure out how to make superintelligent AI systems aligned and safe to use within four years, and the lab is putting a massive 20% of its ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":26},"pub_date":null,"attribution":"80000hours.org"}]},{"type":"search_result_group","domain":"ibm.com","entries":[{"type":"search_result","url":"https://www.ibm.com/think/insights/10-ai-dangers-and-risks-and-how-to-manage-them?utm_source=chatgpt.com","title":"10 AI dangers and risks and how to manage them","snippet":"10 AI dangers and risks and how to manage them \u00b7 1. Bias \u00b7 2. Cybersecurity threats \u00b7 3. Data privacy issues \u00b7 4. Environmental harms \u00b7 5. Existential risks \u00b7 6.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":27},"pub_date":null,"attribution":"ibm.com"}]},{"type":"search_result_group","domain":"researchgate.net","entries":[{"type":"search_result","url":"https://www.researchgate.net/publication/393855845_Timeline_to_Artificial_General_Intelligence_2025_-_2030?utm_source=chatgpt.com","title":"(PDF) Timeline to Artificial General Intelligence 2025 \u2013 2030+","snippet":"We give a speculative timeline describing key events each year from 2025 through 2030, when, if things don't go wrong, and AGI manages the world, ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":29},"pub_date":null,"attribution":"researchgate.net"}]},{"type":"search_result_group","domain":"wired.com","entries":[{"type":"search_result","url":"https://www.wired.com/story/openai-ilya-sutskever-ai-safety/?utm_source=chatgpt.com","title":"OpenAI's Ilya Sutskever Has a Plan for Keeping Super- ...","snippet":"14 Dec 2023 \u2014 The Superalignment team led by OpenAI chief scientist Ilya Sutskever has devised a way to guide the behavior of AI models as they get ever smarter.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":30},"pub_date":null,"attribution":"wired.com"}]},{"type":"search_result_group","domain":"theguardian.com","entries":[{"type":"search_result","url":"https://www.theguardian.com/technology/2024/dec/27/godfather-of-ai-raises-odds-of-the-technology-wiping-out-humanity-over-next-30-years?utm_source=chatgpt.com","title":"'Godfather of AI' shortens odds of the technology wiping out ...","snippet":"28 Dec 2024 \u2014 Geoffrey Hinton says there is 10% to 20% chance AI will lead to human extinction in three decades, as change moves fast.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":31},"pub_date":null,"attribution":"theguardian.com"}]},{"type":"search_result_group","domain":"iberdrola.com","entries":[{"type":"search_result","url":"https://www.iberdrola.com/about-us/our-innovation-model/general-ai?utm_source=chatgpt.com","title":"The future of Artificial General Intelligence: challenges and ...","snippet":"The year 2025 saw significant advances in AGI technology, according to a report from BytePlus, a subsidiary of ByteDance, the company behind popular video- ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":33},"pub_date":null,"attribution":"iberdrola.com"}]},{"type":"search_result_group","domain":"effectivealtruism.org","entries":[{"type":"search_result","url":"https://forum.effectivealtruism.org/posts/Kyh84cxzWcaKonHFG/openai-s-massive-push-to-make-superintelligence-safe-in-4?utm_source=chatgpt.com","title":"OpenAI's massive push to make superintelligence safe in 4 ...","snippet":"8 Aug 2023 \u2014 The goal is to figure out how to make superintelligent AI systems aligned and safe to use within four years, and the lab is putting a massive 20 ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":34},"pub_date":null,"attribution":"effectivealtruism.org"}]},{"type":"search_result_group","domain":"aeaweb.org","entries":[{"type":"search_result","url":"https://www.aeaweb.org/articles?id=10.1257%2Faeri.20230570&utm_source=chatgpt.com","title":"The AI Dilemma: Growth versus Existential Risk","snippet":"by CI Jones \u00b7 Cited by 82 \u2014 The AI Dilemma: Growth versus Existential Risk. Charles I. Jones. American Economic Review: Insights. vol. 6, no. 4, December 2024.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":35},"pub_date":null,"attribution":"aeaweb.org"}]},{"type":"search_result_group","domain":"sciencedirect.com","entries":[{"type":"search_result","url":"https://www.sciencedirect.com/science/article/pii/S0004370214001453?utm_source=chatgpt.com","title":"Ethical guidelines for a superintelligence","snippet":"by E Davis \u00b7 2015 \u00b7 Cited by 49 \u2014 Nick Bostrom, in his new book SuperIntelligence, argues that the creation of an artificial intelligence with human-level intelligence will be followed ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":36},"pub_date":null,"attribution":"sciencedirect.com"}]},{"type":"search_result_group","domain":"ai-2027.com","entries":[{"type":"search_result","url":"https://ai-2027.com/?utm_source=chatgpt.com","title":"AI 2027","snippet":"3 Apr 2025 \u2014 We predict that the impact of superhuman AI over the next decade will be enormous, exceeding that of the Industrial Revolution.","ref_id":{"turn_index":0,"ref_type":"search","ref_index":37},"pub_date":null,"attribution":"ai-2027.com"}]},{"type":"search_result_group","domain":"substack.com","entries":[{"type":"search_result","url":"https://thezvi.substack.com/p/openai-launches-superalignment-taskforce?utm_source=chatgpt.com","title":"OpenAI Launches Superalignment Taskforce","snippet":"Jan Leike: Our new goal is to solve alignment of superintelligence within the next 4 years. OpenAI is committing 20% of its compute to date ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":38},"pub_date":null,"attribution":"substack.com"}]},{"type":"search_result_group","domain":"theelders.org","entries":[{"type":"search_result","url":"https://theelders.org/news/existential-threats-global-public-attitudes?utm_source=chatgpt.com","title":"Existential threats: global public attitudes","snippet":"20 Sept 2024 \u2014 An overview of insights from international polling and desk research conducted in 2024 on four existential global threats: climate change, ...","ref_id":{"turn_index":0,"ref_type":"search","ref_index":39},"pub_date":null,"attribution":"theelders.org"}]}],"citations":[],"request_id":"b97b9bf8-2cae-4427-b563-a38eea15fc41","message_type":"next","model_slug":"gpt-5-1-thinking","default_model_slug":"gpt-5-1-thinking","thinking_effort":"max","parent_id":"2ee9b7c1-048a-42fd-8c6f-386fd1d44acf","turn_exchange_id":"610f39da-515a-4905-9639-74765f8d14a5","timestamp_":"absolute"},"recipient":"all","channel":"final"},"parent":"2ee9b7c1-048a-42fd-8c6f-386fd1d44acf","children":[]}}}